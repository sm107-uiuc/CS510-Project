{"url": "https://medium.freecodecamp.org/how-you-can-train-an-ai-to-convert-your-design-mockups-into-html-and-css-cc7afd82fed4", "time": 1682988285.983735, "path": "medium.freecodecamp.org/how-you-can-train-an-ai-to-convert-your-design-mockups-into-html-and-css-cc7afd82fed4/", "webpage": {"metadata": {"title": "How you can train an AI to convert your design mockups into HTML and CSS", "h1": "How you can train an AI to convert your design mockups into HTML and CSS", "description": "by Emil Wallner How you can train an AI to convert your design mockups into HTML and CSS Within three years, deep learning will change front-end development. It will increase prototyping speed and lower the barrier for building software. The field took off last year when Tony Beltramelli introduced the"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1705.07962", "anchor_text": "pix2code paper", "paragraph_index": 1}, {"url": "https://airbnb.design/sketching-interfaces/", "anchor_text": "sketch2code", "paragraph_index": 1}, {"url": "https://github.com/emilwallner/Screenshot-to-code-in-Keras/blob/master/README.md", "anchor_text": "GitHub", "paragraph_index": 6}, {"url": "https://www.floydhub.com/emilwallner/projects/picturetocode", "anchor_text": "FloydHub", "paragraph_index": 6}, {"url": "https://arxiv.org/abs/1705.07962", "anchor_text": "pix2code paper", "paragraph_index": 7}, {"url": "https://machinelearningmastery.com/blog/page/2/", "anchor_text": "image caption tutorials", "paragraph_index": 7}, {"url": "https://docs.google.com/spreadsheets/d/1xXwarcQZAHluorveZsACtXRdmNFbwGtN3WMNhcTdEyQ/edit?usp=sharing", "anchor_text": "training data example", "paragraph_index": 12}, {"url": "https://machinelearningmastery.com/deep-learning-caption-generation-models/", "anchor_text": "other approaches", "paragraph_index": 13}, {"url": "https://docs.google.com/spreadsheets/d/1yneocsAb_w3-ZUdhwJ1odfsxR2kr-4e_c5FabQbNJrs/edit?usp=sharing", "anchor_text": "a Google Sheet", "paragraph_index": 17}, {"url": "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/", "anchor_text": "one hot encoding", "paragraph_index": 20}, {"url": "https://blog.floydhub.com/workspaces/", "anchor_text": "Workspace", "paragraph_index": 28}, {"url": "https://www.floydhub.com/?utm_medium=readme&utm_source=pix2code&utm_campaign=aug_2018", "anchor_text": "FloydHub", "paragraph_index": 28}, {"url": "https://www.floydhub.com/", "anchor_text": "2-min installation", "paragraph_index": 29}, {"url": "https://www.youtube.com/watch?v=byLQ9kgjTdQ&t=21s", "anchor_text": "my 5-minute walkthrough.", "paragraph_index": 29}, {"url": "https://blog.floydhub.com/colorizing-b&w-photos-with-neural-networks/", "anchor_text": "my earlier post", "paragraph_index": 31}, {"url": "https://docs.google.com/spreadsheets/d/1xXwarcQZAHluorveZsACtXRdmNFbwGtN3WMNhcTdEyQ/edit#gid=0", "anchor_text": "example", "paragraph_index": 37}, {"url": "https://arxiv.org/abs/1301.3781", "anchor_text": "Mikolov et al., 2013", "paragraph_index": 44}, {"url": "https://emilwallner.github.io/html/Original/", "anchor_text": "original website", "paragraph_index": 61}, {"url": "https://arxiv.org/abs/1705.07962", "anchor_text": "pix2code paper.", "paragraph_index": 62}, {"url": "https://getbootstrap.com/", "anchor_text": "bootstrap", "paragraph_index": 62}, {"url": "https://github.com/tonybeltramelli/pix2code/tree/master/datasets", "anchor_text": "The dataset", "paragraph_index": 64}, {"url": "https://blog.floydhub.com/colorizing-b&w-photos-with-neural-networks/", "anchor_text": "my previous article", "paragraph_index": 69}, {"url": "https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/", "anchor_text": "brilliant tutorial", "paragraph_index": 74}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Colah\u2019s tutorial", "paragraph_index": 78}, {"url": "http://blog.varunajayasiri.com/numpy_lstm.html", "anchor_text": "Numpy implementation", "paragraph_index": 78}, {"url": "https://www.youtube.com/watch?v=yCC09vCHzF8", "anchor_text": "Karphay\u2019s lecture", "paragraph_index": 78}, {"url": "https://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "write-up.", "paragraph_index": 78}, {"url": "https://en.wikipedia.org/wiki/BLEU", "anchor_text": "wiki page.", "paragraph_index": 81}, {"url": "https://arxiv.org/pdf/1502.03044.pdf", "anchor_text": "applying attention to LSTMs", "paragraph_index": 83}, {"url": "https://airbnb.design/sketching-interfaces/", "anchor_text": "Airbnb\u2019s design team", "paragraph_index": 86}, {"url": "https://www.uizard.io/", "anchor_text": "Uizard", "paragraph_index": 86}, {"url": "https://twitter.com/paulg/status/847844863727087616", "anchor_text": "Ecole 42", "paragraph_index": 89}, {"url": "https://twitter.com/EmilWallner", "anchor_text": "emilwallner", "paragraph_index": 90}, {"url": "https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/", "anchor_text": "Floydhub\u2019s", "paragraph_index": 91}, {"url": "https://www.freecodecamp.org/learn/", "anchor_text": "Get started", "paragraph_index": 93}, {"url": "https://www.freecodecamp.org/donate/", "anchor_text": "make a tax-deductible donation here", "paragraph_index": 96}], "all_paragraphs": ["Within three years, deep learning will change front-end development. It will increase prototyping speed and lower the barrier for building software.", "The field took off last year when Tony Beltramelli introduced the pix2code paper and Airbnb launched sketch2code.", "Currently, the largest barrier to automating front-end development is computing power. However, we can use current deep learning algorithms, along with synthesized training data, to start exploring artificial front-end automation right now.", "In this post, we\u2019ll teach a neural network how to code a basic a HTML and CSS website based on a picture of a design mockup. Here\u2019s a quick overview of the process:", "We\u2019ll build the neural network in three iterations.", "First, we\u2019ll make a bare minimum version to get a hang of the moving parts. The second version, HTML, will focus on automating all the steps and explaining the neural network layers. In the final version, Bootstrap, we\u2019ll create a model that can generalize and explore the LSTM layer.", "All the code is prepared on GitHub and FloydHub in Jupyter notebooks. All the FloydHub notebooks are inside the floydhub directory and the local equivalents are under local.", "The models are based on Beltramelli\u2018s pix2code paper and Jason Brownlee\u2019s image caption tutorials. The code is written in Python and Keras, a framework on top of TensorFlow.", "If you\u2019re new to deep learning, I\u2019d recommend getting a feel for Python, backpropagation, and convolutional neural networks. My three earlier posts on FloydHub\u2019s blog will get you started:", "Let\u2019s recap our goal. We want to build a neural network that will generate HTML/CSS markup that corresponds to a screenshot.", "When you train the neural network, you give it several screenshots with matching HTML.", "It learns by predicting all the matching HTML markup tags one by one. When it predicts the next markup tag, it receives the screenshot as well as all the correct markup tags until that point.", "Here is a simple training data example in a Google Sheet.", "Creating a model that predicts word by word is the most common approach today. There are other approaches, but that\u2019s the method we\u2019ll use throughout this tutorial.", "Notice that for each prediction it gets the same screenshot. So if it has to predict 20 words, it will get the same design mockup twenty times. For now, don\u2019t worry about how the neural network works. Focus on grasping the input and output of the neural network.", "Let\u2019s focus on the previous markup. Say we train the network to predict the sentence \u201cI can code.\u201d When it receives \u201cI,\u201d then it predicts \u201ccan.\u201d Next time it will receive \u201cI can\u201d and predict \u201ccode.\u201d It receives all the previous words and only has to predict the next word.", "The neural network creates features from the data. The network builds features to link the input data with the output data. It has to create representations to understand what is in each screenshot, the HTML syntax, that it has predicted. This builds the knowledge to predict the next tag.", "When you want to use the trained model for real-world usage, it\u2019s similar to when you train the model. The text is generated one by one with the same screenshot each time. Instead of feeding it with the correct HTML tags, it receives the markup it has generated so far. Then, it predicts the next markup tag. The prediction is initiated with a \u201cstart tag\u201d and stops when it predicts an \u201cend tag\u201d or reaches a max limit. Here\u2019s another example in a Google Sheet.", "Let\u2019s build a \u201chello world\u201d version. We\u2019ll feed a neural network a screenshot with a website displaying \u201cHello World!\u201d and teach it to generate the markup.", "First, the neural network maps the design mockup into a list of pixel values. From 0\u2013255 in three channels \u2014 red, blue, and green.", "To represent the markup in a way that the neural network understands, I use one hot encoding. Thus, the sentence \u201cI can code\u201d could be mapped like the below.", "In the above graphic, we include the start and end tag. These tags are cues for when the network starts its predictions and when to stop.", "For the input data, we will use sentences, starting with the first word and then adding each word one by one. The output data is always one word.", "Sentences follow the same logic as words. They also need the same input length. Instead of being capped by the vocabulary, they are bound by maximum sentence length. If it\u2019s shorter than the maximum length, you fill it up with empty words, a word with just zeros.", "As you see, words are printed from right to left. This forces each word to change position for each training round. This allows the model to learn the sequence instead of memorizing the position of each word.", "In the below graphic there are four predictions. Each row is one prediction. To the left are the images represented in their three color channels: red, green and blue and the previous words. Outside of the brackets are the predictions one by one, ending with a red square to mark the end.", "In the hello world version, we use three tokens: start, <HTML><center><H1>Hello World!<;/H1&gt;</center></HTML> and end. A token can be anything. It can be a character, word, or sentence. Character versions require a smaller vocabulary but constrain the neural network. Word level tokens tend to perform best.", "FloydHub is a training platform for deep learning. I came across them when I first started learning deep learning and I\u2019ve used them since for training and managing my deep learning experiments. You can run your first model within 30 seconds by clicking this button:", "It opens a Workspace on FloydHub where you will find the same environment and dataset used for the Bootstrap version. You can also find the trained models for testing.", "Or you can do a manual installation by following these steps: 2-min installation or my 5-minute walkthrough.", "All the notebooks are prepared inside the FloydHub directory. The local equivalents are under local. Once it\u2019s running, you can find the first notebook here: floydhub/Helloworld/helloworld.ipynb .", "If you want more detailed instructions and an explanation for the flags, check my earlier post.", "In this version, we\u2019ll automate many of the steps from the Hello World model. This section will focus on creating a scalable implementation and the moving pieces in the neural network.", "This version will not be able to predict HTML from random websites, but it\u2019s still a great setup to explore the dynamics of the problem.", "If we expand the components of the previous graphic it looks like this.", "There are two major sections. First, the encoder. This is where we create image features and previous markup features. Features are the building blocks that the network creates to connect the design mockups with the markup. At the end of the encoder, we glue the image features to each word in the previous markup.", "The decoder then takes the combined design and markup feature and creates a next tag feature. This feature is run through a fully connected neural network to predict the next tag.", "Since we need to insert one screenshot for each word, this becomes a bottleneck when training the network (example). Instead of using the images, we extract the information we need to generate the markup.", "The information is encoded into image features. This is done by using an already pre-trained convolutional neural network (CNN). The model is pre-trained on Imagenet.", "We extract the features from the layer before the final classification.", "We end up with 1536 eight by eight pixel images known as features. Although they are hard to understand for us, a neural network can extract the objects and position of the elements from these features.", "In the hello world version, we used a one-hot encoding to represent the markup. In this version, we\u2019ll use a word embedding for the input and keep the one-hot encoding for the output.", "The way we structure each sentence stays the same, but how we map each token is changed. One-hot encoding treats each word as an isolated unit. Instead, we convert each word in the input data to lists of digits. These represent the relationship between the markup tags.", "The dimension of this word embedding is eight but often varies between 50\u2013500 depending on the size of the vocabulary.", "The eight digits for each word are weights similar to a vanilla neural network. They are tuned to map how the words relate to each other (Mikolov et al., 2013).", "This is how we start developing markup features. Features are what the neural network develops to link the input data with the output data. For now, don\u2019t worry about what they are, we\u2019ll dig deeper into this in the next section.", "We\u2019ll take the word embeddings and run them through an LSTM and return a sequence of markup features. These are run through a Time distributed dense layer \u2014 think of it as a dense layer with multiple inputs and outputs.", "In parallel, the image features are first flattened. Regardless of how the digits were structured, they are transformed into one large list of numbers. Then we apply a dense layer on this layer to form a high-level feature. These image features are then concatenated to the markup features.", "This can be hard to wrap your mind around \u2014 so let\u2019s break it down.", "Here we run the word embeddings through the LSTM layer. In this graphic, all the sentences are padded to reach the maximum size of three tokens.", "To mix signals and find higher-level patterns, we apply a TimeDistributed dense layer to the markup features. TimeDistributed dense is the same as a dense layer, but with multiple inputs and outputs.", "In parallel, we prepare the images. We take all the mini image features and transform them into one long list. The information is not changed, just reorganized.", "Again, to mix signals and extract higher level notions, we apply a dense layer. Since we are only dealing with one input value, we can use a normal dense layer. To connect the image features to the markup features, we copy the image features.", "In this case, we have three markup features. Thus, we end up with an equal amount of image features and markup features.", "All the sentences are padded to create three markup features. Since we have prepared the image features, we can now add one image feature for each markup feature.", "After sticking one image feature to each markup feature, we end up with three image-markup features. This is the input we feed into the decoder.", "Here we use the combined image-markup features to predict the next tag.", "In the below example, we use three image-markup feature pairs and output one next tag feature.", "Note that the LSTM layer has the sequence set to false. Instead of returning the length of the input sequence, it only predicts one feature. In our case, it\u2019s a feature for the next tag. It contains the information for the final prediction.", "The dense layer works like a traditional feedforward neural network. It connects the 512 digits in the next tag feature with the 4 final predictions. Say we have 4 words in our vocabulary: start, hello, world, and end.", "The vocabulary prediction could be [0.1, 0.1, 0.1, 0.7]. The softmax activation in the dense layer distributes a probability from 0\u20131, with the sum of all predictions equal to 1. In this case, it predicts that the 4th word is the next tag. Then you translate the one-hot encoding [0, 0, 0, 1] into the mapped value, say \u201cend\u201d.", "If you can\u2019t see anything when you click these links, you can right click and click on \u201cView Page Source.\u201d Here is the original website for reference.", "In our final version, we\u2019ll use a dataset of generated bootstrap websites from the pix2code paper. By using Twitter\u2019s bootstrap, we can combine HTML and CSS and decrease the size of the vocabulary.", "We\u2019ll enable it to generate the markup for a screenshot it has not seen before. We\u2019ll also dig into how it builds knowledge about the screenshot and markup.", "Instead of training it on the bootstrap markup, we\u2019ll use 17 simplified tokens that we then translate into HTML and CSS. The dataset includes 1500 test screenshots and 250 validation images. For each screenshot there are on average 65 tokens, resulting in 96925 training examples.", "By tweaking the model in the pix2code paper, the model can predict the web components with 97% accuracy (BLEU 4-ngram greedy search, more on this later).", "Extracting features from pre-trained models works well in image captioning models. But after a few experiments, I realized that pix2code\u2019s end-to-end approach works better for this problem. The pre-trained models have not been trained on web data and are customized for classification.", "In this model, we replace the pre-trained image features with a light convolutional neural network. Instead of using max-pooling to increase information density, we increase the strides. This maintains the position and the color of the front-end elements.", "There are two core models that enable this: convolutional neural networks (CNN) and recurrent neural networks (RNN). The most common recurrent neural network is long-short term memory (LSTM), so that\u2019s what I\u2019ll refer to.", "There are plenty of great CNN tutorials, and I covered them in my previous article. Here, I\u2019ll focus on the LSTMs.", "One of the harder things to grasp about LSTMs is timesteps. A vanilla neural network can be thought of as two timesteps. If you give it \u201cHello,\u201d it predicts \u201cWorld.\u201d But it would struggle to predict more timesteps. In the below example, the input has four timesteps, one for each word.", "LSTMs are made for input with timesteps. It\u2019s a neural network customized for information in order. If you unroll our model it looks like this. For each downward step, you keep the same weights. You apply one set of weights to the previous output and another set to the new input.", "The weighted input and output are concatenated and added together with an activation. This is the output for that timestep. Since we reuse the weights, they draw information from several inputs and build knowledge of the sequence.", "Here is a simplified version of the process for each timestep in an LSTM.", "To get a feel for this logic, I\u2019d recommend building an RNN from scratch with Andrew Trask\u2019s brilliant tutorial.", "The number of units in each LSTM layer determines it\u2019s ability to memorize. This also corresponds to the size of each output feature. Again, a feature is a long list of numbers used to transfer information between layers.", "Each unit in the LSTM layer learns to keep track of different aspects of the syntax. Below is a visualization of a unit that keeps tracks of the information in the row div. This is the simplified markup we are using to train the bootstrap model.", "Each LSTM unit maintains a cell state. Think of the cell state as the memory. The weights and activations are used to modify the state in different ways. This enables the LSTM layers to fine-tune which information to keep and discard for each input.", "In addition to passing through an output feature for each input, it also forwards the cell states, one value for each unit in the LSTM. To get a feel for how the components within the LSTM interact, I recommend Colah\u2019s tutorial, Jayasiri\u2019s Numpy implementation, and Karphay\u2019s lecture and write-up.", "It\u2019s tricky to find a fair way to measure the accuracy. Say you compare word by word. If your prediction is one word out of sync, you might have 0% accuracy. If you remove one word which syncs the prediction, you might end up with 99/100.", "I used the BLEU score, best practice in machine translating and image captioning models. It breaks the sentence into four n-grams, from 1\u20134 word sequences. In the below prediction \u201ccat\u201d is supposed to be \u201ccode.\u201d", "You could increase the number of n-grams to make it harder. A four n-gram model is the model that best corresponds to human translations. I\u2019d recommend running a few examples with the below code and reading the wiki page.", "Front-end development is an ideal space to apply deep learning. It\u2019s easy to generate data, and the current deep learning algorithms can map most of the logic.", "One of the most exciting areas is applying attention to LSTMs. This will not just improve the accuracy, but enable us to visualize where the CNN puts its focus as it generates the markup.", "Attention is also key for communicating between markup, stylesheets, scripts and eventually the backend. Attention layers can keep track of variables, enabling the network to communicate between programming languages.", "But in the near feature, the biggest impact will come from building a scalable way to synthesize data. Then you can add fonts, colors, words, and animations step-by-step.", "So far, most progress is happening in taking sketches and turning them into template apps. In less then two years, we\u2019ll be able to draw an app on paper and have the corresponding front-end in less than a second. There are already two working prototypes built by Airbnb\u2019s design team and Uizard.", "Here are some experiments to get started.", "Huge thanks to Tony Beltramelli and Jon Gold for their research and ideas, and for answering questions. Thanks to Jason Brownlee for his stellar Keras tutorials (I included a few snippets from his tutorial in the core Keras implementation), and Beltramelli for providing the data. Also thanks to Qingping Hou, Charlie Harrington, Sai Soundararaj, Jannes Klaas, Claudio Cabral, Alain Demenet and Dylan Djian for reading drafts of this.", "This the fourth part of a multi-part blog series from Emil as he learns deep learning. Emil has spent a decade exploring human learning. He\u2019s worked for Oxford\u2019s business school, invested in education startups, and built an education technology business. Last year, he enrolled at Ecole 42 to apply his knowledge of human learning to machine learning.", "If you build something or get stuck, ping me below or on twitter: emilwallner. I\u2019d love to see what you are building.", "This was first published as a community post on Floydhub\u2019s blog.", "\n    If this article was helpful, tweet it.\n", "\n        Learn to code for free. freeCodeCamp's open source curriculum has helped more than 40,000 people get jobs as developers. Get started\n", "Our mission: to help people learn to code for free. We accomplish this by creating thousands of videos, articles, and interactive coding lessons - all freely available to the public. We also have thousands of freeCodeCamp study groups around the world.", "Donations to freeCodeCamp go toward our education initiatives, and help pay for servers, services, and staff.", "\n                    You can make a tax-deductible donation here.\n                "], "all_outgoing_urls": [{"url": "https://www.freecodecamp.org/news", "anchor_text": ""}, {"url": "https://forum.freecodecamp.org/", "anchor_text": "Forum"}, {"url": "https://www.freecodecamp.org/donate/", "anchor_text": "Donate"}, {"url": "https://medium.freecodecamp.org/news/tag/machine-learning/", "anchor_text": "#Machine Learning"}, {"url": "https://arxiv.org/abs/1705.07962", "anchor_text": "pix2code paper"}, {"url": "https://airbnb.design/sketching-interfaces/", "anchor_text": "sketch2code"}, {"url": "https://unsplash.com/photos/y0_vFxOHayg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Wesson Wang"}, {"url": "https://unsplash.com/search/photos/tech-maker?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://github.com/emilwallner/Screenshot-to-code-in-Keras/blob/master/README.md", "anchor_text": "GitHub"}, {"url": "https://www.floydhub.com/emilwallner/projects/picturetocode", "anchor_text": "FloydHub"}, {"url": "https://arxiv.org/abs/1705.07962", "anchor_text": "pix2code paper"}, {"url": "https://machinelearningmastery.com/blog/page/2/", "anchor_text": "image caption tutorials"}, {"url": "https://blog.floydhub.com/my-first-weekend-of-deep-learning/", "anchor_text": "My First Weekend Of Deep Learning"}, {"url": "https://blog.floydhub.com/coding-the-history-of-deep-learning/", "anchor_text": "Coding The History Of Deep Learning"}, {"url": "https://blog.floydhub.com/colorizing-b&w-photos-with-neural-networks/", "anchor_text": "Colorizing B&W Photos with Neural Networks"}, {"url": "https://docs.google.com/spreadsheets/d/1xXwarcQZAHluorveZsACtXRdmNFbwGtN3WMNhcTdEyQ/edit?usp=sharing", "anchor_text": "training data example"}, {"url": "https://machinelearningmastery.com/deep-learning-caption-generation-models/", "anchor_text": "other approaches"}, {"url": "https://docs.google.com/spreadsheets/d/1yneocsAb_w3-ZUdhwJ1odfsxR2kr-4e_c5FabQbNJrs/edit?usp=sharing", "anchor_text": "a Google Sheet"}, {"url": "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/", "anchor_text": "one hot encoding"}, {"url": "https://blog.floydhub.com/workspaces/", "anchor_text": "Workspace"}, {"url": "https://www.floydhub.com/?utm_medium=readme&utm_source=pix2code&utm_campaign=aug_2018", "anchor_text": "FloydHub"}, {"url": "https://www.floydhub.com/", "anchor_text": "2-min installation"}, {"url": "https://www.youtube.com/watch?v=byLQ9kgjTdQ&t=21s", "anchor_text": "my 5-minute walkthrough."}, {"url": "https://blog.floydhub.com/colorizing-b&w-photos-with-neural-networks/", "anchor_text": "my earlier post"}, {"url": "https://docs.google.com/spreadsheets/d/1xXwarcQZAHluorveZsACtXRdmNFbwGtN3WMNhcTdEyQ/edit#gid=0", "anchor_text": "example"}, {"url": "https://arxiv.org/abs/1301.3781", "anchor_text": "Mikolov et al., 2013"}, {"url": "https://emilwallner.github.io/html/250_epochs/", "anchor_text": "250 epochs"}, {"url": "https://emilwallner.github.io/html/350_epochs/", "anchor_text": "350 epochs"}, {"url": "https://emilwallner.github.io/html/450_epochs/", "anchor_text": "450 epochs"}, {"url": "https://emilwallner.github.io/html/550_epochs/", "anchor_text": "550 epochs"}, {"url": "https://emilwallner.github.io/html/Original/", "anchor_text": "original website"}, {"url": "http://course.fast.ai/lessons/lesson6.html", "anchor_text": "Fast.ai\u2019s video on RNNs"}, {"url": "https://arxiv.org/abs/1705.07962", "anchor_text": "pix2code paper."}, {"url": "https://getbootstrap.com/", "anchor_text": "bootstrap"}, {"url": "https://github.com/tonybeltramelli/pix2code/tree/master/datasets", "anchor_text": "The dataset"}, {"url": "https://blog.floydhub.com/colorizing-b&w-photos-with-neural-networks/", "anchor_text": "my previous article"}, {"url": "https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/", "anchor_text": "brilliant tutorial"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Colah\u2019s tutorial"}, {"url": "http://blog.varunajayasiri.com/numpy_lstm.html", "anchor_text": "Numpy implementation"}, {"url": "https://www.youtube.com/watch?v=yCC09vCHzF8", "anchor_text": "Karphay\u2019s lecture"}, {"url": "https://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "write-up."}, {"url": "https://en.wikipedia.org/wiki/BLEU", "anchor_text": "wiki page."}, {"url": "https://emilwallner.github.io/bootstrap/pred_1/", "anchor_text": "Generated website 1"}, {"url": "https://emilwallner.github.io/bootstrap/real_1/", "anchor_text": "Original 1"}, {"url": "https://emilwallner.github.io/bootstrap/pred_2/", "anchor_text": "Generated website 2"}, {"url": "https://emilwallner.github.io/bootstrap/real_2/", "anchor_text": "Original 2"}, {"url": "https://emilwallner.github.io/bootstrap/pred_3/", "anchor_text": "Generated website 3"}, {"url": "https://emilwallner.github.io/bootstrap/real_3/", "anchor_text": "Original 3"}, {"url": "https://emilwallner.github.io/bootstrap/pred_4/", "anchor_text": "Generated website 4"}, {"url": "https://emilwallner.github.io/bootstrap/real_4/", "anchor_text": "Original 4"}, {"url": "https://emilwallner.github.io/bootstrap/pred_5/", "anchor_text": "Generated website 5"}, {"url": "https://emilwallner.github.io/bootstrap/real_5/", "anchor_text": "Original 5"}, {"url": "https://arxiv.org/pdf/1502.03044.pdf", "anchor_text": "applying attention to LSTMs"}, {"url": "https://airbnb.design/sketching-interfaces/", "anchor_text": "Airbnb\u2019s design team"}, {"url": "https://www.uizard.io/", "anchor_text": "Uizard"}, {"url": "http://lstm.seas.harvard.edu/latex/", "anchor_text": "different dataset"}, {"url": "https://arxiv.org/abs/1502.03044", "anchor_text": "similar to this model"}, {"url": "https://twitter.com/paulg/status/847844863727087616", "anchor_text": "Ecole 42"}, {"url": "https://twitter.com/EmilWallner", "anchor_text": "emilwallner"}, {"url": "https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/", "anchor_text": "Floydhub\u2019s"}, {"url": "https://www.freecodecamp.org/learn/", "anchor_text": "Get started"}, {"url": "https://www.freecodecamp.org/donate/", "anchor_text": "make a tax-deductible donation here"}, {"url": "https://www.freecodecamp.org/news/what-is-a-framework-software-frameworks-definition/", "anchor_text": "What is a Framework?"}, {"url": "https://www.freecodecamp.org/news/what-is-a-computer-scientist-what-exactly-do-cs-majors-do/", "anchor_text": "What Do CS Majors Do?"}, {"url": "https://www.freecodecamp.org/news/discord-update-failed-how-to-fix-the-error-on-a-windows-10-pc/", "anchor_text": "Discord Update Failed"}, {"url": "https://www.freecodecamp.org/news/how-to-center-an-image-in-a-div-css/", "anchor_text": "Center an Image in CSS"}, {"url": "https://www.freecodecamp.org/news/what-does-mvc-mean-in-computer-science/", "anchor_text": "What is the MVC Model?"}, {"url": "https://www.freecodecamp.org/news/javascript-replaceall-replace-all-instances-of-a-string-in-js/", "anchor_text": "JavaScript replaceAll()"}, {"url": "https://www.freecodecamp.org/news/python-switch-statement-switch-case-example/", "anchor_text": "Python Switch Statement"}, {"url": "https://www.freecodecamp.org/news/python-string-replace-how-to-replace-a-character-in-a-string/", "anchor_text": "Python string.replace()"}, {"url": "https://www.freecodecamp.org/news/what-is-a-relational-database-rdbms-definition/", "anchor_text": "What is a Relational DB?"}, {"url": "https://www.freecodecamp.org/news/how-to-split-a-string-in-python/", "anchor_text": "Split a String in Python"}, {"url": "https://www.freecodecamp.org/news/sql-having-how-to-group-and-count-with-a-having-statement/", "anchor_text": "SQL HAVING"}, {"url": "https://www.freecodecamp.org/news/what-is-object-oriented-programming/", "anchor_text": "What is OOP?"}, {"url": "https://www.freecodecamp.org/news/html-textarea-how-to-add-text-box-to-your-website/", "anchor_text": "HTML textarea"}, {"url": "https://www.freecodecamp.org/news/nvm-for-windows-how-to-download-and-install-node-version-manager-in-windows-10/", "anchor_text": "NVM for Windows"}, {"url": "https://www.freecodecamp.org/news/git-revert-file-reverting-a-file-to-a-previous-commit/", "anchor_text": "Git Revert File"}, {"url": "https://www.freecodecamp.org/news/sql-aggregate-functions-how-to-group-by-in-mysql-and-postgresql/", "anchor_text": "GROUP BY in SQL"}, {"url": "https://www.freecodecamp.org/news/2d-array-in-java-two-dimensional-and-nested-arrays/", "anchor_text": "2D Array in Java"}, {"url": "https://www.freecodecamp.org/news/node-version-manager-nvm-install-guide/", "anchor_text": "How to Install NVM"}, {"url": "https://www.freecodecamp.org/news/how-to-calculate-percentage-in-excel-formula-for-percentages/", "anchor_text": "Percentages in Excel"}, {"url": "https://www.freecodecamp.org/news/javascript-timestamp-how-to-use-gettime-to-generate-timestamps-in-js/", "anchor_text": "JavaScript Timestamp"}, {"url": "https://www.freecodecamp.org/news/git-list-remote-branches/", "anchor_text": "Git List Remote Branches"}, {"url": "https://www.freecodecamp.org/news/git-delete-remote-branch/", "anchor_text": "Git Delete Remote Branch"}, {"url": "https://www.freecodecamp.org/news/what-does-a-software-developer-do-software-engineer-career-overview/", "anchor_text": "Software Developer Career"}, {"url": "https://www.freecodecamp.org/news/three-dots-operator-in-javascript/", "anchor_text": "Three Dots Operator in JS"}, {"url": "https://www.freecodecamp.org/news/javascript-date-format-how-to-format-a-date-in-js/", "anchor_text": "How to Format Dates in JS"}, {"url": "https://www.freecodecamp.org/news/how-to-remove-an-element-from-a-javascript-array-removing-a-specific-item-in-js/", "anchor_text": "Remove Item from Array JS"}, {"url": "https://www.freecodecamp.org/news/how-to-dual-boot-windows-10-and-ubuntu-linux-dual-booting-tutorial/", "anchor_text": "Dual Boot Windows + Ubuntu"}, {"url": "https://www.freecodecamp.org/news/how-to-round-to-2-decimal-places-in-python/", "anchor_text": "Python Round to 2 Decimals"}, {"url": "https://www.freecodecamp.org/news/string-to-number-in-javascript-convert-a-string-to-an-int-in-js/", "anchor_text": "String to Int in JavaScript"}, {"url": "https://www.freecodecamp.org/news/gitignore-file-how-to-ignore-files-and-folders-in-git/", "anchor_text": "What\u2019s the .gitignore File?"}, {"url": "https://www.freecodecamp.org/news/about/", "anchor_text": "About"}, {"url": "https://www.linkedin.com/school/free-code-camp/people/", "anchor_text": "Alumni Network"}, {"url": "https://github.com/freeCodeCamp/", "anchor_text": "Open Source"}, {"url": "https://www.freecodecamp.org/news/shop/", "anchor_text": "Shop"}, {"url": "https://www.freecodecamp.org/news/support/", "anchor_text": "Support"}, {"url": "https://www.freecodecamp.org/news/sponsors/", "anchor_text": "Sponsors"}, {"url": "https://www.freecodecamp.org/news/academic-honesty-policy/", "anchor_text": "Academic Honesty"}, {"url": "https://www.freecodecamp.org/news/code-of-conduct/", "anchor_text": "Code of Conduct"}, {"url": "https://www.freecodecamp.org/news/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.freecodecamp.org/news/terms-of-service/", "anchor_text": "Terms of Service"}, {"url": "https://www.freecodecamp.org/news/copyright-policy/", "anchor_text": "Copyright Policy"}]}, "scrape_status": {"code": "1"}}