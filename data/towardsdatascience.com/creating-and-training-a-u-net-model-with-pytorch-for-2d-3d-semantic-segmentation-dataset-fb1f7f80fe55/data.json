{"url": "https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55", "time": 1683017187.089132, "path": "towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55/", "webpage": {"metadata": {"title": "Creating and training a U-Net model with PyTorch for 2D & 3D semantic segmentation: Dataset building [1/4] | by Johannes Schmidt | Towards Data Science", "h1": "Creating and training a U-Net model with PyTorch for 2D & 3D semantic segmentation: Dataset building [1/4]", "description": "In this series (4 parts) we will perform semantic segmentation on images using plain PyTorch and the U-Net architecture. I will cover the following topics: For that I will use a sample of the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pytorch.org/docs/stable/torchvision/index.html", "anchor_text": "torchvision", "paragraph_index": 1}, {"url": "https://pillow.readthedocs.io/en/stable/", "anchor_text": "PIL", "paragraph_index": 1}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://www.jetbrains.com/de-de/pycharm/", "anchor_text": "PyCharm", "paragraph_index": 3}, {"url": "https://www.spyder-ide.org/", "anchor_text": "Spyder", "paragraph_index": 3}, {"url": "https://code.visualstudio.com/", "anchor_text": "Visual Studio Code", "paragraph_index": 3}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial", "anchor_text": "github", "paragraph_index": 3}, {"url": "https://github.com/ELEKTRONN/elektronn3", "anchor_text": "elektronn3", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-training-3-4-8242d31de234", "anchor_text": "part 3", "paragraph_index": 7}, {"url": "https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html#DataLoader", "anchor_text": "check them out", "paragraph_index": 10}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial/blob/master/transformations.py", "anchor_text": "transformations.py", "paragraph_index": 16}, {"url": "https://github.com/albumentations-team/albumentations", "anchor_text": "albumentations", "paragraph_index": 16}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial/blob/master/transformations.py", "anchor_text": "transformations.py", "paragraph_index": 19}, {"url": "https://drive.google.com/file/d/17j39-la-lJNaM2na-n0paMXf3ubPuUdo/view?usp=sharing", "anchor_text": "here", "paragraph_index": 20}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial/tree/master/Carvana", "anchor_text": "github repo", "paragraph_index": 20}, {"url": "https://docs.python.org/3/library/pathlib.html", "anchor_text": "here", "paragraph_index": 20}, {"url": "https://napari.org/", "anchor_text": "napar", "paragraph_index": 24}, {"url": "https://github.com/albumentations-team/albumentations", "anchor_text": "albumentations", "paragraph_index": 32}, {"url": "https://johschmidt42.medium.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862", "anchor_text": "next chapter", "paragraph_index": 35}, {"url": "http://M.Sc", "anchor_text": "M.Sc", "paragraph_index": 37}], "all_paragraphs": ["In this series (4 parts) we will perform semantic segmentation on images using plain PyTorch and the U-Net architecture. I will cover the following topics:", "For that I will use a sample of the infamous Carvana dataset (2D images), but the code and the methods work for 3D datasets as well. For example: I will not use the torchvision package, as most transformations and augmentations only work on 2D input with PIL. You can find the repo of this project here with a jupyter notebook for every part (and more).", "I was a master student in biology who started to learn programming with Python and ended up trying deep learning (semantic segmentation with U-Net) on electron tomograms (3D images) for my master thesis. In this process I not only learned quite a lot about deep learning, Python and programming but also how to better structure your project and code. This blog aims to share my experience and a tutorial to use plain PyTorch to efficiently use deep learning for your own semantic segmentation project.", "To bring more structure into your project, I recommend to create a new project and create several Python files, each having different classes and functions that can be imported and used. Personally, I like to use PyCharm for that but other IDEs such as Spyder or Visual Studio Code are also a good choice. I also prefer working with the IPython console within PyCharm instead of Jupyter notebooks. A combination of both can be very helpful though. If you prefer a single Jupyter Notebook, that\u2019s also fine, just bear in mind that it could get to be a long script. You can find the files and code on github. Most of the structure and code that I will be showing is inspired by the work of this project: elektronn3.", "Before we start creating our data generator, let\u2019s talk about the data first. What we would like to have is two directories, something like /Input and /Target. In the /Input directory, we find all input images and in the /Target directory the segmentation maps. Visualizing the images would look something like the image below. The labels are usually encoded with pixel values, meaning that all pixels of the same class have the same pixel value e.g. background=0, dog=1, cat=2 in the example below.", "The goal of the network is to predict such a segmentation map from a given input image.", "In deep learning, we want to feed our network with batches of data. Therefore, we would like to have a data generator that does the following:", "With PyTorch it is fairly easy to create such a data generator. We create a custom Dataset class, instantiate it and pass it to PyTorch\u2019s dataloader. Here is a simple example of such a dataset for a potential segmentation pipeline (Spoiler: In part 3 I will make use of the multiprocessing library and use caching to improve this dataset):", "The SegmentationDataSet class inherits from torch.data.Dataset . In the initialization method __init__, we expect a list of input paths and a list of target paths. The __getitem__ method simply reads an item from our input and target list using the skimage.imread() function. This will give us our input and target image as numpy.ndarrays. We then process our data with the transform function that expects an input and target pair and should return the processed data as numpy.ndarrays again. But I will come to that later. At the end, we just make sure that we end up having a torch.tensor of certain type for our input and target. In this case, this is usually torch.float32 and torch.int64 (long) for input and target, respectively. This dataset can be then used to create our dataloader (the data generator that we want). You may ask: How do we make sure that this dataset will output the correct target for every input image? If the input and target lists happen to have the same order, e.g. because input and target have the same name, the mapping should be correct.", "Let\u2019s try it out with a simple example:", "Here, we create an instance of our SegmentationDataSet class. For now, we don\u2019t want any transformation to happen on our data, so we leave transform=None . In the next step we create our data loader by passing our training_dataset as input. We choose to have an batch_size of 2 and to shuffle the data shuffle=True . There are some other useful arguments that can be passed in when instantiating the dataloader and you should check them out. The result could look something like this:", "There are some things to notice here:", "Because of this we need to transform the data a little bit.", "Note: If we omit the typecasting at the end of our SegmentationDataSet, the dataloader would still not output numpy.ndarrays but torch.tensors. As our input is read as a numpy.ndarray in uint8, it will also output a torch.tensor in uint8. For float32 we need to change the type.", "Let\u2019s create a new file, that we name transformations.py.", "In order to transform our data so that they meet the requirements of the network, we create a class FunctionWrapperDouble which can take any function and returns a partial (basically a function with defined arguments). This allows us to stack (functions) transformations in a list that we want to be applied on the data. To stack these functions I use the ComposeDouble class. The Double in these classes means that it is meant for a dataset with input-target pairs (like our case for semantic segmentation). There is also a Single version of these classes for the case that you want to just experiment with some input or target images (or visualize your dataset). So what we want, is to create an object, that comprises all the transformations that we want to apply to the data. We can then pass this object as an argument in our SegmentationDataSet instance. Confused? Let me show what I mean with an example:", "The transforms variable is an instance of the ComposeDouble class that comprises a list of transformations that is to be applied to the data! create_dense_target and normalize_01 are functions that I defined in transformations.py, while np.moveaxis is just a numpy function that simply moves the channel dimension C from last to second with the numpy library. It is important to note that these functions are expected to take in and output a np.ndarray ! This way, we can create and perform transformations including augmentations on arbitrary numpy.ndarrays . Or we could just write a wrapper class for other libraries, such as albumentations to make use of their transformations (more on that later). The __repr__ is just a printable representation of a object and makes it easier to understand what transformations and what arguments were used.", "Why the effort you may ask? Well, this makes it clear what transformations are performed on the data when we create the dataset. The ComposeDouble class just puts the different transformation together.", "Let\u2019s test it out with some random input-target-data.", "Here we also resize our input and target image by using the skimage.transform.resize(). And we linearly scale our input to the range [0, 1] using normalize01 . We could also normalize the input based on a mean and std of a given dataset with normalize from the transformations.py file, but this will do for now.", "Now let\u2019s put these pieces of code together to create a dataset for the Carvana dataset. We have our input images stored in Carvana/Input and our targets stored in Carvana/Targets. This is just a sample of the original dataset and can be downloaded here or found in the github repo. This sample consists of only 6 cars, but each car from 16 angles \u2014 96 images in total. I will be using the pathlib library to get the directory path of every input and target. If this library is new to you, you should check it out here.", "We import the SegmentationDataSet class and the transformations that we want to use. To get the input-target paths, I use the function get_filenames_of_path that will return a list of all items within a directory. We then stack our transformations inside the Compose object that we name transforms. Because training is usually performed with a training dataset and a validation dataset, we split our input and target lists with sklearn.model_selection.train_test_split(). We could do it manually too (and it makes more sense for this dataset), but that\u2019s ok for now. With these lists, we can create our datasets and the corresponding dataloaders. Now we should check if our datasets (training and validation) output the correct format! Since the datasets have a __getitem__ and method, we can treat them almost like a sequence object (e.g. list):", "To check if our dataloader functions the way we want, we can get a batch with:", "Everything seems to be in order now. Now let\u2019s visualize this result.", "In order to inspect our transformed images, we should visualize the input and it\u2019s respective target image. For 2D images, we could use matplotlib. For 3D images, however, it becomes a bit hacky and slow. But there is an alternative: napari. This is a fast, interactive multi-dimensional image viewer for python, that can be used in a jupyter notebook, an Ipython console or within a .py script.", "It\u2019s built on top of Qt (for the GUI), vispy (for performant GPU-based rendering), and the scientific Python stack (numpy, scipy). \u2014 napari", "To visualize our dataset, we should reverse some of the transformations we performed on the data, e.g. we would like to have an input image of shape [H, W, C], in the range of [0\u2013255] and as numpy.ndarray. Let\u2019s create a visual.py file in which we create a DatasetViewer class:", "I won\u2019t go into details about napari and the code here. This class basically allows us to view our the images and targets of our dataset by iterating over the dataset with custom keybindings (\u2019n\u2019 for next and \u2018b\u2019 for back)! Some comments on the transforms: The function re_normalize() scales the input image back to [0\u2013255]. We assume that our images and targets are torch.tensors and force them to be on the cpu and as np.ndarrays.", "You do not need to enter %gui qt before using napari in Ipython or witihn a Jupyter notebook in this case, because this will be evoked when intantiating the class with the enabel_gui_qt() function.", "This will open a GUI that will look something like this:", "When I press 'n' on the keyboard, I will get the next image-target pair from the dataset:", "Now that we have a solid codebase, let\u2019s expand our dataset with some augmentations.", "For 2D images, we don\u2019t have to implement everything from scratch with numpy. Instead, we could use a library like albumentations. For that, we just need to write a wrapper, like AlbuSeg2d. As an example, we could horizontally flip our training images and their respective targets. The validation images are usually not augmented, which makes it necessary to have different transformations for the training and validation dataset:", "We can then change the code for our dataset objects accordingly:", "The probability of a flipped image is p=0.5. When we visualize the image-target pairs again, we eventually get batches with horizontally flipped input-target pairs:", "We have created a data generator that can feed a network with batches of transformed/augmented data in the correct format. We also know how to visualize our dataset with the help of napari. This applies to 2D and 3D datasets. Now that we have spent some time on creating and visualizing the dataset, let\u2019s move on to model building in the next chapter.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data & Software Engineer at Datamesh GmbH. M.Sc. in Biology with exp. in artificial neural networks & deep learning. Very interested in software development."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffb1f7f80fe55&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://johschmidt42.medium.com/?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": ""}, {"url": "https://johschmidt42.medium.com/?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "Johannes Schmidt"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5022ff2e428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&user=Johannes+Schmidt&userId=b5022ff2e428&source=post_page-b5022ff2e428----fb1f7f80fe55---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb1f7f80fe55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb1f7f80fe55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55", "anchor_text": "Part I: Dataset building"}, {"url": "https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862", "anchor_text": "Part II: model building (U-Net)"}, {"url": "https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-training-3-4-8242d31de234", "anchor_text": "Part III: Training"}, {"url": "https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-inference-4-4-e52b074ddf6f", "anchor_text": "Part IV: Inference"}, {"url": "https://pytorch.org/docs/stable/torchvision/index.html", "anchor_text": "torchvision"}, {"url": "https://pillow.readthedocs.io/en/stable/", "anchor_text": "PIL"}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial", "anchor_text": "here"}, {"url": "https://www.jetbrains.com/de-de/pycharm/", "anchor_text": "PyCharm"}, {"url": "https://www.spyder-ide.org/", "anchor_text": "Spyder"}, {"url": "https://code.visualstudio.com/", "anchor_text": "Visual Studio Code"}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial", "anchor_text": "github"}, {"url": "https://github.com/ELEKTRONN/elektronn3", "anchor_text": "elektronn3"}, {"url": "https://d2l.ai", "anchor_text": "Dive into Deep Learning"}, {"url": "https://towardsdatascience.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-training-3-4-8242d31de234", "anchor_text": "part 3"}, {"url": "https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html#DataLoader", "anchor_text": "check them out"}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial/blob/master/transformations.py", "anchor_text": "transformations.py"}, {"url": "https://github.com/albumentations-team/albumentations", "anchor_text": "albumentations"}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial/blob/master/transformations.py", "anchor_text": "transformations.py"}, {"url": "https://drive.google.com/file/d/17j39-la-lJNaM2na-n0paMXf3ubPuUdo/view?usp=sharing", "anchor_text": "here"}, {"url": "https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial/tree/master/Carvana", "anchor_text": "github repo"}, {"url": "https://docs.python.org/3/library/pathlib.html", "anchor_text": "here"}, {"url": "https://napari.org/", "anchor_text": "napar"}, {"url": "https://github.com/albumentations-team/albumentations", "anchor_text": "albumentations"}, {"url": "https://johschmidt42.medium.com/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-model-building-6ab09d6a0862", "anchor_text": "next chapter"}, {"url": "https://johschmidt42.medium.com/membership", "anchor_text": "Join Medium with my referral link - Johannes SchmidtRead every story from Johannes Schmidt (and thousands of other writers on Medium). Your membership fee directly\u2026johschmidt42.medium.com"}, {"url": "https://medium.com/tag/unet?source=post_page-----fb1f7f80fe55---------------unet-----------------", "anchor_text": "Unet"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----fb1f7f80fe55---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----fb1f7f80fe55---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/semantic-segmentation?source=post_page-----fb1f7f80fe55---------------semantic_segmentation-----------------", "anchor_text": "Semantic Segmentation"}, {"url": "https://medium.com/tag/python?source=post_page-----fb1f7f80fe55---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb1f7f80fe55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&user=Johannes+Schmidt&userId=b5022ff2e428&source=-----fb1f7f80fe55---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb1f7f80fe55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&user=Johannes+Schmidt&userId=b5022ff2e428&source=-----fb1f7f80fe55---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb1f7f80fe55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffb1f7f80fe55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fb1f7f80fe55---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fb1f7f80fe55--------------------------------", "anchor_text": ""}, {"url": "https://johschmidt42.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://johschmidt42.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Johannes Schmidt"}, {"url": "https://johschmidt42.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "392 Followers"}, {"url": "http://M.Sc", "anchor_text": "M.Sc"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5022ff2e428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&user=Johannes+Schmidt&userId=b5022ff2e428&source=post_page-b5022ff2e428--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4ca5ac031e5a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55&newsletterV3=b5022ff2e428&newsletterV3Id=4ca5ac031e5a&user=Johannes+Schmidt&userId=b5022ff2e428&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}