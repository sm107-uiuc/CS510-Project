{"url": "https://towardsdatascience.com/targeting-and-removing-bad-training-data-8ccdac5e7cc3", "time": 1683016356.0294578, "path": "towardsdatascience.com/targeting-and-removing-bad-training-data-8ccdac5e7cc3/", "webpage": {"metadata": {"title": "Targeting and Removing Bad Training Data | by Kenichi Nakanishi | Towards Data Science", "h1": "Targeting and Removing Bad Training Data", "description": "In Part 1: Building an Image Database, we\u2019ve scraped the web for information on plants and how toxic they are to pets, cross-referenced the fields against a second database, then finally downloaded\u2026"}, "outgoing_paragraph_urls": [{"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-a29587f3f04c", "anchor_text": "Part 1: Building an Image Database", "paragraph_index": 0}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness", "paragraph_index": 1}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier", "anchor_text": "Github repo", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness", "paragraph_index": 40}, {"url": "https://medium.com/p/8ccdac5e7cc3#207f", "anchor_text": "Classification Interpretation with fast.ai", "paragraph_index": 46}, {"url": "https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness", "paragraph_index": 52}, {"url": "https://kenichinakanishi.medium.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf", "anchor_text": "Part 4: Exploring Convolutional Neural Network Architectures in fast.ai", "paragraph_index": 52}], "all_paragraphs": ["In Part 1: Building an Image Database, we\u2019ve scraped the web for information on plants and how toxic they are to pets, cross-referenced the fields against a second database, then finally downloaded unique images for each class through Google Images.", "In Part 2: Training with Controlled Randomness, we trained neural networks using the new fast.ai framework to identify the species of plant based on a picture. We implemented a way to seed randomness across the NumPy, PyTorch and random packages and flexible methods for marking images as training or validation samples across separate training runs. This helps us more fairly compare the effects of changing the other aspects of our classifier.", "As we found that many of our images have an adverse effect on the accuracy of our classifier, due to the diminishing relevancy of our Google Image search results turning up things like drawings, graphs and fact sheets. These put bad training examples into our pool, making our model worse at doing what we want it to do (classify a plant based on a natural photo.) We\u2019d like to remove these, but manually examining each of the 150 files across 500+ folders is a seriously daunting task. Automating this task with code or focusing a final manual clean is a much more sensible way to do things.", "The main goals herein will be examining how we can try to specifically target images that are bad for training (e.g. incorrectly labelled or bad examples of the class.) and measuring the effect of their removal on the overall training accuracy.", "All associated code can be found in my Github repo.", "fast.ai has a range of useful interpretation methods built-in for classification problems such as the one we are tackling. To make use of them, we first re-create a learner and load in the saved state we want to look in before preparing the interpretation class using ClassificationInterpretation.from_learner.", "Here we use a learner created and trained in Part 2: Training with Controlled Randomness that took in the entirety of the dataset, 150 images per class.", "fast.ai gives us an easy way to now look to generate a confusion matrix with interp.plot_confusion_matrix() or to look at the classes that were most often confused with each other using interp.most_confused(). However, with so many classes (here we have over 500 classes), we will crash the kernel trying to generate such a dense confusion matrix due to RAM limitations. Luckily, fast.ai has a useful interp.plot_top_losses()function that shows us just some of the images that suprised the model the most (leading to the largest losses).", "We can see that many of these image labels are simply incorrect, suggesting that one of the major issues with the dataset is mislabelling of images. A classification report detailing the F1 score for each class can help us identify classes that the model is struggling with.", "Using interp.print_classification_report() will print out the classification report. To manipulate the data, we should intercept this with a Jupyter magic command, and read that input back into a dataframe for interpretation.", "With this class_report DataFrame, we can see at a glance which classes have the most problems, and have a closer look at the images in their folders.", "Generating a plot of how the F1 score varies can also give us a sense of the scale of the issue.", "Interestingly, around 8 or so classes experience a sharp drop-off in F1 score. Let\u2019s take a quick look at a folder of images to assess what kinds of images might be causing these issues while training the classifier.", "Essentially, what we\u2019re looking for are images that possess significant differences from the kinds of images we imagine a user would take and use to identify a given plant. Scattered among the images in the Peperomia peltifolia folder, are many images with artificial components (text and/or drawings) and a number of misclassified or irrelevant (scientific drawings, seed samples) images. This is due to the relevancy of the Google Image search results dropping as more and more images are collected from a single query. Classes that are naturally have more available search results suffer less from this trend (see the Iris domestica images).", "Based on this investigation we can conclude two things:", "Let\u2019s first attempt to tackle #2 with a few automated processes.", "The first filtering step will use optical character recognition (OCR) to try to find text in each of our documents. Text can present a form of data leakage, given the most likely text to appear would have to do with the name of the plant the image is presenting. Besides this, in our imagined use case (identifying plants from a natural picture), text is unlikely to be present in any image.", "Tesseract is open-source software available for OCR that is straightforward to implement. Here, we use their image_to_string function to examine images after opening them with Pillow. As we\u2019ll later need to look at entire folders of images, we add a simple clause that tells the function whether or not it needs to use Pillow to open the image, before returning the text (if any) that was found.", "While configuring Tesseract, PSM refers to the Page Segmentation Mode, which affects how Tesseract splits images in lines of text and words. We use fully automatic segmentation herein (--psm 3) and also the default OCR engine mode (--oem 3).", "As many images contain some text along the top or bottom edges of the frame, we want to be able to crop the image and re-check if text still exists, enabling us to preserve as many images as possible. Failing that we will simply remove the image from the dataset (thus removing bad training examples).", "Now, we roll the optical_character_recognition and crop_image functions together into one we can use to iterate through a folder of images to search for text and optionally attempt to crop (here 10%) the top and bottom of the image and see if that removes the text, replacing the image if successful. As such, we can directly edit and retain any images that can be easily fixed with a small amount of cropping.", "At this stage, we save the results of the OCR process to a DataFrame for later examination and processing. This is done because while many of the images caught by the filter can be filtered out without much consequence, there are a significant number of images with no text at all that presented as false positives due to the arrangement of leaves, branches and/or white space.", "Unfortunately, examining images using OCR doesn\u2019t account for images that are artificial in other ways, leading us to the analysis of tonal distributions.", "Every image is made up many tones, which can vary across a range of hues and lightnesses. We can use this to create quantifiable metrics about the tonal distribution of each of our images and try to identify any commonalities between images that would be poor for training our classifier.", "To begin, let\u2019s examine how a neural network will \u2018see\u2019 our images. We can open up an image with PIL and convert it to a tensor.", "This shows that each image is just a single tensor with three channels \u2014 red, blue and green, stored in that order. We can isolate a single channel and have a closer look by converting it into to a colored DataFrame:", "Thinking along this line of approach, we can identify images that have large blocks of color with very little variation, as are typically seen in images that have artifically created elements such as text or drawings. Let\u2019s prepare some image histographs by taking the Hue and Lightness (from conversion to HLS) of each pixel in the image and plotting the z-axis as the population of pixels that exist for a given (hue and lightness) pair.", "Using the image_histogram function above, we can examine the tonal distribution of each image and plot it along side each raw image. The histogram shows the populations of each pixel with a given hue/lightness pairing. For example, in the below picture we can see that the most populous pixels in the histogram are the lighter greens and yellows, which is well reflected in the real image.", "In general, we see that natural photographs will possess a subtle jitter in the hue and lightness from pixel to pixel that is captured and encoded into the image. This leads to hue-lightness populations that are much flatter and more well-distributed, with a relatively larger number of hue-lightness pairings (on the order of 20 to 30 thousand).", "Even though these images appear predominantly green, the subtle color variations in a natural photo that prevent any particular shade of color from representing too large a proportion of pixels. In the above images, the 1000 most populous (intense) hue-lightness pairings represent less than 40% of the image, even in an image with an artificially whitened background.", "On the other hand, image with computer generated elements have specifically picked out a hue-lightness pairings when filling an area with a color, leading to artificially high population densities for a given hue-lightness pair. Additionally, artificial images that may contain as few as 1000 unique hue-lightness pairings, a far cry from the 20 to 30 thousand typically seen in a natural image.", "The image_histogram function also calculates a few simple metrics that we can use to later tag an image as artificial (for examination and later removal). Namely, we calculate the number of hue-lightness pairings that exist, take a number (color_width) of the most populous pairs and calculate the proportion of the image they represent. As can be seen above, those images possessing artificial components will have a larger proportion of the image made up of relatively fewer hue/lightness pairs. Let\u2019s use this characteristic to tag images as having an artificial color distribution!", "The key parameters here are color_width and threshold. If the given number (color_width) most populous hue/lightness pairings represent more than athreshold proportion of the overall image, we tag the image as possessing an artificial color distribution in the DataFrame returned by the function. Based empirical experimentation with our dataset, we are using 1000 pairs and a 70% threshold to detect artificial images, but these values will change depending on what kinds of images you\u2019re working with.", "Now we have a few useful metrics (presence of text and tonal distribution) that we can use to judge whether or not an image is artificial or not.", "This function aims to do two things:", "If no text was detected: Tag the image as possessing an artificial tonal distribution if the given number (color_width) most populous hue/lightness pairings represent more than athreshold proportion of the overall image, i.e. have an excessively shallow tonal distribution. Here we are using color_width=1000 pairs and a 70% threshold.", "If text was detected: As previously mentioned, the main issue with using only OCR to identify bad training examples was the regular occurrence of false positives. In order to filter these out, we use the find_artifical_colors function to prepare a DataFrame containing the proportion of pixels represented by the color_width most populous hue/lightness pairings of all images (by settingreturn_all to True). Then we run find_artifical_text and inner join the results into a single DataFrame that now contains the color proportion data.", "This allows us to threshold these images based on the color proportion at a separate level to those images with no text. Intuitively, images with falsely detected text will have a significantly more distributed tonal distribution than those who have text added (which typically have a singular font color). After empirical experimentation we arrive at a threshold level of 50% which works pretty well to remove any false positives from our find_artifical_text function. Then, given that text was detected, we require a lower text_threshold of 50% before the image is tagged as artificial. This allows natural images to escape tagging while still capturing most of the images that possess text. The text_threshold used here will determine how aggressive we are in attempting to weed out the false positives.", "Below are examples of (a) a false positive from OCR that would no longer be filtered out, and (b) a true positive, both from the folder of Zephyranthes drummondii images.", "Now that we\u2019ve chosen our parameters for image tagging, we can iterate through each of the folders, finding artificial images and removing them using Path.unlink().", "Now we can compare our new dataset with the raw dataset using the learner prepared in Part 2 of this series: Training with Controlled Randomness. After using the imports and creating the learner using the code discussed, we can compare the results of training while holding the randomness from train/validation, image augmentation and batch processing the same.", "Here we see that the automated image cleanup process detailed here has removed over 6000 images from the dataset, improving the Top-5 accuracy from 0.809 to 0.819. This indicates that we have indeed (in general) removed images that were poor training examples for each class. However \u2014 the results are still worse than simply using the first 50 or 100 images from the dataset!", "Examining the distribution of F1 scores across all classes reveals a few interesting things. While the F1 score has improved in general, the classes with the lowest F1 scores are actually performing worse than before.", "Let\u2019s take a closer look at the Peperomia peltifolia folder to figure out what\u2019s going on.", "It appears that the cleaning process has worked relatively well, with the majority of the images that were artificial/poor training examples having been removed from the folder. However, the process cannot identify and remove any of the misclassified images. This causes an overall reduction in the F1 score of the class because the removed images actually possessed many similarities, whereas many of the remaining images are misclassified and have little to no similarities.", "The best way to improve our accuracy at this point is to focus on removing these misclassified images with a little bit of manual cleanup.", "We don\u2019t want to have to look into each and every folder to delete misclassified images. A more efficient way to approach this problem is to focus our efforts on the classes with the most issues. As we explored in the first part of this post (Classification Interpretation with fast.ai), we can do this by looking at the top losses overall as well as the classes with the lowest F1 scores. By opening those folders and deleting images we deem to be misclassified or poor training examples we can quickly improve the performance of our classifier.", "I\u2019ve gone ahead and performed a number of manual cleaning steps using this method, then fed those datasets into identical training processes each time to see how our classifier improves.", "As we can see, the performance of our classifier rises dramatically each time we delete a few hundred images, despite only removing around 0.5% of the total dataset each time.", "Examining the distribution of F1 scores shows that the F1 score has improved in general, again excepting a few classes at the tail end of the distribution.", "These classes are the most challenging to classify as they typically refer to a higher classification (Dracanea vs. Dracanea fragrans) or a very specific species (Peperomia peltifolia vs Peperomia serpens). One way we could seek to improve the performance of these classes is to go out and specificially collect high-quality training images for each to allow the network to more easily distinguish between similar species. Currently, this won\u2019t affect our goal of classifying the toxicity of a given plant species, so we won\u2019t worry too much about it right now.", "Great! We\u2019ve improved the results of training using our baseline architecture (ResNet34) by cleaning up our dataset through automated (using OCR and analysis of tonal distribution), and guided manual means.", "Next, we will be using this refined dataset and building on our learner created in Part 2: Training with Controlled Randomness. Join me soon in Part 4: Exploring Convolutional Neural Network Architectures in fast.ai where we\u2019ll compare why, how and the effects of changes in network architecture(s).", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8ccdac5e7cc3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kenichinakanishi.medium.com/?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": ""}, {"url": "https://kenichinakanishi.medium.com/?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "Kenichi Nakanishi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9d8da6789697&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&user=Kenichi+Nakanishi&userId=9d8da6789697&source=post_page-9d8da6789697----8ccdac5e7cc3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ccdac5e7cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ccdac5e7cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://towardsdatascience.com/tagged/petsafe-plants-fastai", "anchor_text": "Classifying Pet-Safe Plants with fast.ai"}, {"url": "https://unsplash.com/@coleito", "anchor_text": "Cole Keister"}, {"url": "https://unsplash.com", "anchor_text": "Unsplash"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-a29587f3f04c", "anchor_text": "Part 1: Building an Image Database"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness"}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier", "anchor_text": "Github repo"}, {"url": "https://medium.com/p/8ccdac5e7cc3#207f", "anchor_text": "Classification Interpretation with fast.ai"}, {"url": "https://medium.com/p/8ccdac5e7cc3#26dd", "anchor_text": "Filtering using Optical Character Recognition"}, {"url": "https://medium.com/p/8ccdac5e7cc3#eb3f", "anchor_text": "Filtering using Tonal Distribution"}, {"url": "https://medium.com/p/8ccdac5e7cc3#1570", "anchor_text": "Automating Image Cleanup"}, {"url": "https://medium.com/p/8ccdac5e7cc3#1021", "anchor_text": "Manual Cleanup and Training Results"}, {"url": "https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness"}, {"url": "https://gist.github.com/kenichinakanishi/4327cff12ddc51f44903c07f384ce8d0", "anchor_text": "Code to generate image histograms from pixel HSL values."}, {"url": "https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness"}, {"url": "https://medium.com/p/8ccdac5e7cc3#207f", "anchor_text": "Classification Interpretation with fast.ai"}, {"url": "https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness"}, {"url": "https://kenichinakanishi.medium.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf", "anchor_text": "Part 4: Exploring Convolutional Neural Network Architectures in fast.ai"}, {"url": "https://medium.com/tag/fastai?source=post_page-----8ccdac5e7cc3---------------fastai-----------------", "anchor_text": "Fastai"}, {"url": "https://medium.com/tag/image-classification?source=post_page-----8ccdac5e7cc3---------------image_classification-----------------", "anchor_text": "Image Classification"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----8ccdac5e7cc3---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----8ccdac5e7cc3---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/petsafe-plants-fastai?source=post_page-----8ccdac5e7cc3---------------petsafe_plants_fastai-----------------", "anchor_text": "Petsafe Plants Fastai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8ccdac5e7cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&user=Kenichi+Nakanishi&userId=9d8da6789697&source=-----8ccdac5e7cc3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8ccdac5e7cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&user=Kenichi+Nakanishi&userId=9d8da6789697&source=-----8ccdac5e7cc3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ccdac5e7cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8ccdac5e7cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8ccdac5e7cc3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8ccdac5e7cc3--------------------------------", "anchor_text": ""}, {"url": "https://kenichinakanishi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kenichinakanishi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kenichi Nakanishi"}, {"url": "https://kenichinakanishi.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "33 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9d8da6789697&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&user=Kenichi+Nakanishi&userId=9d8da6789697&source=post_page-9d8da6789697--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F46e23b30274b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftargeting-and-removing-bad-training-data-8ccdac5e7cc3&newsletterV3=9d8da6789697&newsletterV3Id=46e23b30274b&user=Kenichi+Nakanishi&userId=9d8da6789697&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}