{"url": "https://towardsdatascience.com/visualizing-bayesian-priors-cec2fea3e386", "time": 1683004389.485127, "path": "towardsdatascience.com/visualizing-bayesian-priors-cec2fea3e386/", "webpage": {"metadata": {"title": "Visualizing Bayesian Priors. Ever wonder how priors affect your\u2026 | by Nicolas Bertagnolli | Towards Data Science", "h1": "Visualizing Bayesian Priors", "description": "Tutorial on Bayesian priors and bayesian statistics. How do priors affect the posterior distribution? How do gaussian, beta, and uniform priors look?"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/visualizing-gaussian-elimination-6cb6fdb59475", "anchor_text": "Gaussian Elimination", "paragraph_index": 19}, {"url": "https://www.linkedin.com/in/nicolas-bertagnolli-058aba81/", "anchor_text": "https://www.linkedin.com/in/nicolas-bertagnolli-058aba81/", "paragraph_index": 21}], "all_paragraphs": ["I\u2019ve been playing around a little with parameter estimation and Bayesian statistics and thought that I\u2019d make a quick little visualization of how prior beliefs affect our posterior distribution. In this tutorial, we will walk through thinking about whether or not a coin is fair. We will visualize how our estimate of the coin\u2019s fairness changes as we acquire more data and with respect to our prior beliefs. Let\u2019s get started!", "You\u2019re in Vegas watching people bet on the outcome of a coin toss. If it is heads then you win double your bet and if it is tails the house takes your money. This sounds like a good deal so you\u2019re immediately suspicious. Casinos don\u2019t want to give you a good deal. So you decide to count the number of times that you see each outcome and determine the value of the coin. Let H be the probability of getting heads using the Casino\u2019s coin, and let D be the data set of our tosses. Let\u2019s assume that we saw 100 coin tosses and out of those 100 tosses 40 of them were heads. What is the weighting of the coin? Naturally, you would say that H = 40/100 = .4 but how did you get that number? Let\u2019s walk through the derivation!", "We are estimating a coin toss which means that our data will take on one of two values with probabilities p and 1 - p. Thus we will assume that our data is generated by a Bernoulli distribution, or in other words, the likelihood of the data given a particular probability of heads is:", "Now we want to figure out what value of H maximizes this likelihood function. Since the natural logarithm will not affect our maximum we can solve for the maximum of the log instead. It will make the math easier, trust me.", "Now refer back to your good ol\u2019 Calculus I class, take a derivative and set it equal to 0 in order to identify the critical points.", "It appears that our intuition was correct, and the best estimate for the probability of heads is the number of heads tossed out of the total number of tosses.", "Wait, aren\u2019t we gambling in Vegas? We know these casinos are shady. We need to incorporate this information into our models. In our model, we assumed that the parameter could take any value between 0 and 1 with equal probability. This assumption about what values our parameters can take is called a prior and for this analysis, we assumed a uniform prior.", "This particular prior says that we have absolutely no information about what the probability of heads should look like. It is a good assumption if we don\u2019t know anything about our parameters, but in the case of a common quarter this might be a bad assumption because we know that common street coins are very close to fair. The prior is combined with the likelihood to generate the posterior distribution using Baye\u2019s rule.", "These priors have an important effect on our model when the sample size is small and their effect diminishes as the sample gets larger. Let\u2019s see this effect in action for a few different priors.", "We already know what our posterior looks like for a uniform prior but what about if we assume that the casino is playing by the rules and using a common street coin. Then we might assume a gaussian prior with mean .5 and a small standard deviation. Then our posterior distribution would be:", "For this implementation, I chose a mean of .5 because fair coins should be close to even and a standard deviation of 0.05 so that if the coin happens to be unfair it is going to sit between 0.4 and 0.6.", "Let\u2019s take a look at one more possible prior where we think there might be a high likelihood that the coin is extremely biased. In this case, we could use the beta distribution which would make our posterior:", "Notice how most of the probability is concentrated at the extremes. This fits with the idea that the coin is very likely to throw all heads or all tails. You can also see that this distribution doesn\u2019t have much bias in the fact that the variance is around .2. Much higher than that of the Gaussian at .05 or the uniform at .08.", "We can generate these posteriors in python using the following functions:", "Now let\u2019s look at how the priors affect our parameter estimation visually. For this experiment, we create a biased coin in Python with a probability of heads equal to 0.3. This coin is clearly biased and will usually throw tails. We then sample flips of this coin at some set intervals between 0 and 512 flips. These flips simulate an observation of the gambling game we\u2019ve been discussing. You can think of one of these plots as how certain we are of the fairness of the coin after N flips and our prior beliefs.", "Below I have plotted the evolution of the posterior with increasing evidence (Larger number of flips observed) let\u2019s take a look and see what we can learn. If we assume that we have absolutely no information about this coin we can assume a uniform prior. We can see that our estimate of the weighting of the coin is a uniform distribution with no flips. This makes sense because we have no data and just our assumptions about the coin. After about four flips we\u2019ve got something that looks like a Gaussian distribution that's maybe a little skewed toward .3 but hard to tell. After about 64 flips, we\u2019re pretty confident that the coin is biased, and after 128 we have more or less converged to the true biased weighting of the coin.", "Next, we examine what happens if we assume that the coin is fair by using a Gaussian distribution. At zero flips we have just our prior belief. The distribution hardly seems to change for the first few flips. This is because the assumption that our coin is fair is a pretty strong assumption and so it will take a lot of data to impact this belief. After about 32\u201364 flips we can see the distribution gradually sliding to the left toward the true weighting. But it\u2019s not really until 256\u2013512 flips that we\u2019ve really arrived at the true weighting.", "Lastly, we examine the belief that the coin is biased and we\u2019re in a seedy casino by using a beta prior. We see that this behaves very similarly to the uniform distribution, but that it swings far left earlier.", "A few other interesting things to notice, as the sample size increases all of the posteriors tend toward a normal distribution centered at 0.3. You can see clearly that the prior has a large effect when the sample size is small. Also as the sample size increases the likelihood begins to dominate and the prior becomes less important. Notice how the prior can affect the convergence rate of the posterior. For example, for both the uniform and beta prior after 64 flips the coins true bias falls within our 95% confidence interval, whereas for the Gaussian our true bias doesn\u2019t appear in our interval until around 256 flips.", "The takeaway message here is that if we start out not knowing much about our parameter, uniform, or beta distribution, it is easy to convince the model that the coin is biased. Whereas, if our model has a strong belief that the coin is fair, i.e. the Gaussian prior, then it will take much more data to convince it that the coin is in fact not fair. If you enjoyed this mathematical visualization you might also like my post on Gaussian Elimination.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "CAIO at mpathic. I\u2019m working on applying modern NLP techniques to improve communication. Let\u2019s connect https://www.linkedin.com/in/nicolas-bertagnolli-058aba81/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcec2fea3e386&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nbertagnolli.medium.com/?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": ""}, {"url": "https://nbertagnolli.medium.com/?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "Nicolas Bertagnolli"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa998d10e34d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&user=Nicolas+Bertagnolli&userId=a998d10e34d8&source=post_page-a998d10e34d8----cec2fea3e386---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcec2fea3e386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcec2fea3e386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/visualizing-gaussian-elimination-6cb6fdb59475", "anchor_text": "Gaussian Elimination"}, {"url": "http://www.nbertagnolli.com/jekyll/update/2016/03/05/Visualizing_Priors.html", "anchor_text": "http://www.nbertagnolli.com"}, {"url": "https://medium.com/tag/bayesian-statistics?source=post_page-----cec2fea3e386---------------bayesian_statistics-----------------", "anchor_text": "Bayesian Statistics"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----cec2fea3e386---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/statistics?source=post_page-----cec2fea3e386---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/python?source=post_page-----cec2fea3e386---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----cec2fea3e386---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcec2fea3e386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&user=Nicolas+Bertagnolli&userId=a998d10e34d8&source=-----cec2fea3e386---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcec2fea3e386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&user=Nicolas+Bertagnolli&userId=a998d10e34d8&source=-----cec2fea3e386---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcec2fea3e386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcec2fea3e386&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----cec2fea3e386---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cec2fea3e386--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----cec2fea3e386--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----cec2fea3e386--------------------------------", "anchor_text": ""}, {"url": "https://nbertagnolli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nbertagnolli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nicolas Bertagnolli"}, {"url": "https://nbertagnolli.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "286 Followers"}, {"url": "https://www.linkedin.com/in/nicolas-bertagnolli-058aba81/", "anchor_text": "https://www.linkedin.com/in/nicolas-bertagnolli-058aba81/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa998d10e34d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&user=Nicolas+Bertagnolli&userId=a998d10e34d8&source=post_page-a998d10e34d8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1205c8722589&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bayesian-priors-cec2fea3e386&newsletterV3=a998d10e34d8&newsletterV3Id=1205c8722589&user=Nicolas+Bertagnolli&userId=a998d10e34d8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}