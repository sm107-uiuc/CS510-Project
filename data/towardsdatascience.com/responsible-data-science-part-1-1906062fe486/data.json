{"url": "https://towardsdatascience.com/responsible-data-science-part-1-1906062fe486", "time": 1683002004.84758, "path": "towardsdatascience.com/responsible-data-science-part-1-1906062fe486/", "webpage": {"metadata": {"title": "The Hidden Dangers of Data Science | by Haohui | Towards Data Science", "h1": "The Hidden Dangers of Data Science", "description": "Data science, machine learning, artificial intelligence. These are all buzz words that have emerged in our society. We have grown increasingly reliant on these technologies, but this growing reliance\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.neowin.net/news/ai-supposedly-learns-to-identify-criminals-by-their-faces-takes-us-back-to-the-19th-century/", "anchor_text": "infer criminality based on facial images", "paragraph_index": 1}, {"url": "https://www.popsci.com/nsas-skynet-might-not-be-able-to-tell-what-makes-terrorist/", "anchor_text": "using machine learning to predict the cell phone usage of terrorists cell phone usage", "paragraph_index": 16}, {"url": "https://www.businessinsider.com/amazon-built-ai-to-hire-people-discriminated-against-women-2018-10", "anchor_text": "building an AI tool to hire people that discriminated against women", "paragraph_index": 24}], "all_paragraphs": ["Data science, machine learning, artificial intelligence. These are all buzz words that have emerged in our society. We have grown increasingly reliant on these technologies, but this growing reliance also raises questions about how justified we are in giving our complete trust to these technologies. Machine learning and deep learning are known famously to be a black box\u200a\u2014\u200awe feed data into the model and come up with some results that we just take for granted, without really questioning how these results were obtained, and whether the process is justified. This issue formed the backdrop of the keynote presentation by Professor Lise Getoor at the 2019 IEEE Big Data Conference held in Los Angeles on 10 December 2019, and I will now give an overview of the enlightening talk she gave.", "Data science has increasingly found itself in the spotlight, with increasing coverage and attention all over the world. But whenever we see data science in the news, it is mostly for something bad. For instance, many of us are familiar with the Cambridge Analytica scandal which harvested the personal data of millions of peoples\u2019 Facebook profiles without their consent and used it for political advertising purposes. Another example is how scientists proclaimed to have created a model able to infer criminality based on facial images.", "In the keynote speech, Professor Getoor mainly focused on responsible data science in machine learning, which I will now outline.", "Machine learning has undergone several revolutions, with several themes emerging over the past century, starting from Concept Learning, Statistical Learning, Optimization-based learning to Deep Learning.", "Concept Learning revolves around how machines can learn logically consistent hypothesis that can correctly label the positive and negative samples correctly. In the 1980s, machine learning moved towards statistical learning, in particular, probabilistic methods, with a focus on learning a hypothesis that maximizes probability and data likelihood. Next, machine learning moved towards optimization-based, for example, Support Vector Machines (SVM) where hypotheses minimize some loss function. Now we are in the neural-inspired learning age of deep learning which represents the hypothesis as a neural network.", "In essence, the goal of training in machine learning is to minimize the loss between the target label and the predicted label. This is formulated mathematically as such:", "During the testing phase, the learned model is tested to determine how well it is able to predict the predicted label. Error is then calculated by the sum of the loss between the target label and the predicted label, formulated mathematically as such:", "This seems relatively straight forward enough \u2014 train a model to reduce the loss and you are able to objectively quantify its performance by calculating the error.", "So what could possibly go wrong? It turns out, many.", "In total, Professor Getoor covered 7 issues that could go wrong: Formalization of the problem, dealing with high dimensional data, measuring error, interpretability in deep learning, causal modelling, bias and data dignity. These are what the problems are:", "It may seem as though coming up with the training objective is easy, but in fact, every time we train a model, we are making some frame of reference commitment to what the data are, what the labels are, and what the loss function is.", "Firstly, the transformation of raw data into feature vectors requires us to make a frame of reference commitment because raw data always contains much more social and historical context which cannot be represented by the feature vector. This means we would miss much of this important information from human data whenever we transform the raw data.", "Next, the choice of labels is also problematic, because who gets to define the labels? Labels can only be proxies for true data, never the real replacement.", "Lastly, the choice of loss function is important as well because different loss functions penalize errors differently, and trade-offs between the factors influencing model performance are often over-simplified and force-fitted into these loss functions which may not truly represent the task requirements.", "Therefore, there is a need for some criteria to evaluate if the chosen frame of reference is appropriate, with a criterion known as \u201cStructural Plausibility\u201d- that there should be a plausible scientific connection between the input features and the output label. If not, no matter how well your classifier performs, you should reject the hypothesis. For instance, the inferring of criminality based on facial images does not pass this test, because the purported \u201cscientific connection\u201d between the facial images (the input features) and the classification (the output label) is not scientific at all. Instead, it was based on the method in which the images were chosen. Non-criminal images were likely manually chosen by the experimenter to convey a positive impression. In contrast, the criminal images were likely selected neither by the individual depicted nor with the aim of casting an individual in a favourable light. Therefore, the model is essentially a \u201csmile detector\u201d and the connection purported to be discovered is not, in fact, a \u201cplausible scientific connection\u201d.", "The next problem with machine learning is the huge reliance on data, both for training and testing. The issue arises with high dimensional data, because the danger of overfitting is much higher. This is also followed by numerous problems:", "One example is how the NSA tried using machine learning to predict the cell phone usage of terrorists cell phone usage. This was highly problematic because they used 80 variables for each cell phone user with only 7 known terrorists. When they tried testing the model in the wild, it ended up identifying an Al Jazeera reporter covering Al Qaeda as a potential terrorist! This shows how high dimensional data often leaves us more prone to errors because the sample size requirement is much higher.", "The next issue that arises is the issue of measuring model performance. Researchers always proclaim that their new state-of-the-art models have reached XX accuracy or F1, and so on. However, such a claim always comes with many unspoken conditions, that the dataset has a well-defined population with both the training and test data being representative samples of the population. However, this almost never holds in practice. The image below illustrates the problem wonderfully:", "The learned model, represented in green above, may seem to fit the true model initially. However, upon further testing, it may become evident later on that the learned model does not actually represent the true model.", "Interpretability in deep learning has received an increased amount of interest in the past few years. This is important because although deep learning models may achieve excellent results, we cannot know for sure if the results are because the model has really learned the important features, or that the model actually learned the wrong features and it just so happened that the features remained unchanged for the images in the same category. The trouble comes when the wrong feature is changed while the important features remain the same. If the model learned the wrong features, it may then make a wrong prediction.", "One example is the paper titled \u201cWhy Should I Trust You\u201d Explaining the Predictions of Any Classifier\u201d by Ribeiro et al. in 2016. They trained a model to classify between a Husky and a Wolf, but it turned out to be classifying the snow and grass in the background of the picture. It turned out that the snow in the image was used to classify the image as \u2018wolf\u2019, whereas grass in the image was used to classify the image as \u2018husky\u2019. As a result, when a husky was pictured with a snow background, it was wrongly classified as a wolf.", "The issue of correlation versus causation is yet another topic discussed frequently, especially in statistics. The idea is that CORRELATION helps with prediction; if X and Y are positively correlated, then if we observe a high X, then we would expect to see high Y. On the other hand, CAUSATION is needed for decision making; if X and Y are causally connected, then if we manipulate the value of X while keeping everything else constant, then the value of Y will definitely change. The issue with confusing a correlation as causation is with CONFOUNDERS, where a correlation is often due to one or more confounding latent variables that is a hidden cause of both X and Y.", "For example, it may seem as though a rise in sales of ice creams would lead to a rise in the number of shark attacks. To the untrained eye, it may seem as though the rise in sales causes the rise in attacks. However, there is actually a confounder \u2014 the weather. It might just be the case that the hot weather was leading to a rise in ice cream sales as well as a rise in shark attacks (because more people go to the beach thanks to the good weather), and there was only a correlation and not causation between the sales of ice cream and rise in shark attacks.", "Bias in machine learning can be categorized into three categories \u2014 data bias, automation bias and algorithmic discrimination.", "Firstly, data bias refers to the choice of dataset. The contents of the dataset are affected by many factors ranging from selection bias, institutional bias and societal bias. As the saying goes, garbage in, garbage out. If the input to the system is biased, then the output will be biased. For instance, Amazon came under fire for building an AI tool to hire people that discriminated against women. The reason is simple \u2014 the training set contained mainly male resumes, hence the model began to learn that males would be better employees than females based merely on the sheer amount of male resumes.", "Secondly, automation bias refers to the preference that we human beings have for suggestions from automated decision-making systems and often ignore contradictory information. We tend to believe the decisions made by automated systems just because they are automated, without sparing additional thought for the validity and justifiability of these decisions. The danger then comes when decision makers start abdicating decision responsibility to algorithms. It is especially tempting to rely on algorithms for making hard decisions, hence this would affect accountability.", "Finally, algorithmic discrimination refers to the phenomenon whereby algorithms can amplify, operationalize and finally legitimize institutional bias. When algorithms legitimize these biases, we may reach a point whereby we no longer question these biases that we used to look on with suspicion and instead embrace them. This would be extremely dangerous to our society.", "This brings us to the problem of fairness. First of all, who is the fairness for? Different metrics matter to different stakeholders. For instance, a judge would want to minimize false negatives in trials, whereas a defendant would want to reduce the likelihood of false positives, of being convicted wrongly. When dealing with issues of fairness and bias, we must always keep in mind that fairness is a social and ethical concept and not a statistical concept. Bias is subjective and hence must be considered relative to the task.", "This is the last issue raised. Data is the new currency and the data we each produce are highly valuable. However, our data are frequently misused without our consent and awareness, for example in the Cambridge Analytica scandal. Hence, there is a need for data dignity, which is the ability to understand and control how your data is being used. There should be also a concept of \u201cdata as labor\u201d, which is the ability to get paid for use of your data. This is only right because data is the new currency of the world.", "We have gone through a brief overview of machine learning as well as covered the seven problems that could go wrong with machine learning. This is definitely food for thought as we ponder about how we often give our unquestioning trust to machine learning algorithms and the implications this can have on our society.", "A huge thanks to Professor Getoor for the wonderful and insightful keynote speech on responsible data science, it was truly enlightening.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine learning enthusiast working on the next big project"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1906062fe486&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1906062fe486--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1906062fe486--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@liuhh02?source=post_page-----1906062fe486--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@liuhh02?source=post_page-----1906062fe486--------------------------------", "anchor_text": "Haohui"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F500dff1f8d3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&user=Haohui&userId=500dff1f8d3b&source=post_page-500dff1f8d3b----1906062fe486---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1906062fe486&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1906062fe486&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/manfredsteger-1848497/", "anchor_text": "manfredsteger"}, {"url": "https://pixabay.com/vectors/pixel-cells-techbot-teach-o-bot-3947912/", "anchor_text": "Pixabay"}, {"url": "https://www.neowin.net/news/ai-supposedly-learns-to-identify-criminals-by-their-faces-takes-us-back-to-the-19th-century/", "anchor_text": "infer criminality based on facial images"}, {"url": "https://users.soe.ucsc.edu/~getoor/Talks/IEEE-Big-Data-Keynote-2019.pdf", "anchor_text": "IEEE Big Data 2019 Keynote"}, {"url": "https://users.soe.ucsc.edu/~getoor/Talks/IEEE-Big-Data-Keynote-2019.pdf", "anchor_text": "IEEE Big Data 2019 Keynote"}, {"url": "https://users.soe.ucsc.edu/~getoor/Talks/IEEE-Big-Data-Keynote-2019.pdf", "anchor_text": "IEEE Big Data 2019 Keynote"}, {"url": "https://www.popsci.com/nsas-skynet-might-not-be-able-to-tell-what-makes-terrorist/", "anchor_text": "using machine learning to predict the cell phone usage of terrorists cell phone usage"}, {"url": "https://users.soe.ucsc.edu/~getoor/Talks/IEEE-Big-Data-Keynote-2019.pdf", "anchor_text": "IEEE Big Data 2019 Keynote"}, {"url": "https://www.businessinsider.com/amazon-built-ai-to-hire-people-discriminated-against-women-2018-10", "anchor_text": "building an AI tool to hire people that discriminated against women"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1906062fe486---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1906062fe486---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----1906062fe486---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1906062fe486&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&user=Haohui&userId=500dff1f8d3b&source=-----1906062fe486---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1906062fe486&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&user=Haohui&userId=500dff1f8d3b&source=-----1906062fe486---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1906062fe486&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1906062fe486--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1906062fe486&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1906062fe486---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1906062fe486--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1906062fe486--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1906062fe486--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1906062fe486--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1906062fe486--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1906062fe486--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1906062fe486--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1906062fe486--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@liuhh02?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@liuhh02?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Haohui"}, {"url": "https://medium.com/@liuhh02/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "210 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F500dff1f8d3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&user=Haohui&userId=500dff1f8d3b&source=post_page-500dff1f8d3b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F64817874ddcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresponsible-data-science-part-1-1906062fe486&newsletterV3=500dff1f8d3b&newsletterV3Id=64817874ddcf&user=Haohui&userId=500dff1f8d3b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}