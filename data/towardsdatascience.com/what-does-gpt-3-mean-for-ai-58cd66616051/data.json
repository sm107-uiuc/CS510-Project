{"url": "https://towardsdatascience.com/what-does-gpt-3-mean-for-ai-58cd66616051", "time": 1683015096.722351, "path": "towardsdatascience.com/what-does-gpt-3-mean-for-ai-58cd66616051/", "webpage": {"metadata": {"title": "What does GPT-3 mean for AI?. 3 ways in which GPT-3 changes the rules\u2026 | by Archy de Berker | Towards Data Science", "h1": "What does GPT-3 mean for AI?", "description": "The biggest AI news of 2020 so far is the success of OpenAI\u2019s monstrous new language model, GPT-3. In this post, I\u2019m going to quickly summarize why GPT-3 has caused such a splash, before highlighting\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/2005.14165", "anchor_text": "OpenAI\u2019s monstrous new language model, GPT-3.", "paragraph_index": 0}, {"url": "http://jalammar.github.io/how-gpt3-works-visualizations-animations/", "anchor_text": "this visual guide", "paragraph_index": 3}, {"url": "https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html", "anchor_text": "Giving GPT-3 a Turing Test", "paragraph_index": 3}, {"url": "https://twitter.com/paulg", "anchor_text": "Paul Graham", "paragraph_index": 10}, {"url": "https://arxiv.org/list/cs.LG/recent", "anchor_text": "Arxiv", "paragraph_index": 12}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT model from Google", "paragraph_index": 13}, {"url": "https://huggingface.co/transformers/", "anchor_text": "Transformers library", "paragraph_index": 13}, {"url": "https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb", "anchor_text": "Google Colab", "paragraph_index": 13}, {"url": "https://lambdalabs.com/blog/demystifying-gpt-3/", "anchor_text": "Lambda Labs estimate that it would cost $4.6 million to train using cloud GPUs.", "paragraph_index": 15}, {"url": "http://v", "anchor_text": "OpenAI", "paragraph_index": 16}, {"url": "https://forms.office.com/Pages/ResponsePage.aspx?id=VsqMpNrmTkioFJyEllK8s0v5E5gdyQhOuZCXNuMR8i1UQjFWVTVUVEpGNkg3U1FNRDVVRFg3U0w4Vi4u", "anchor_text": "currently restricted", "paragraph_index": 18}, {"url": "https://www.youtube.com/watch?v=uZ0KNVU2fV0", "anchor_text": "Fyre festival", "paragraph_index": 18}, {"url": "https://www.youtube.com/watch?v=M4MMUpjcqkQ", "anchor_text": "Chopsticks", "paragraph_index": 22}, {"url": "https://jack-clark.net", "anchor_text": "Import AI 217", "paragraph_index": 28}, {"url": "https://arxiv.org/abs/2009.06367", "anchor_text": "GeDi model from Salesforce", "paragraph_index": 28}, {"url": "https://jack-clark.net/2020/10/05/import-ai-217-deepfaked-congressmen-and-deepfaked-kids-steering-gpt3-with-gedi-amazons-robots-versus-its-humans/", "anchor_text": "Import AI Issue 217", "paragraph_index": 30}, {"url": "https://www.oracle.com/index.html", "anchor_text": "Oracle", "paragraph_index": 31}, {"url": "https://www.sap.com/canada/index.html", "anchor_text": "SAP", "paragraph_index": 31}, {"url": "https://lambdalabs.com/blog/demystifying-gpt-3/", "anchor_text": "remember the price tag?", "paragraph_index": 39}, {"url": "https://www.gartner.com/en/documents/3981253/magic-quadrant-for-cloud-ai-developer-services", "anchor_text": "Cloud AI war", "paragraph_index": 42}, {"url": "https://www.nytimes.com/2018/04/19/technology/artificial-intelligence-salaries-openai.html", "anchor_text": "exorbitant salaries commanded by ML professionals", "paragraph_index": 43}], "all_paragraphs": ["The biggest AI news of 2020 so far is the success of OpenAI\u2019s monstrous new language model, GPT-3. In this post, I\u2019m going to quickly summarize why GPT-3 has caused such a splash, before highlighting 3 consequences for individuals and companies building things with AI.", "Why are people excited about GPT-3? Here\u2019s why, in 3 tweets:", "There are already lots of summary posts about GPT-3, so I won\u2019t rehash them here.", "For a great introduction to how the model works, check out this visual guide from the (reliably excellent) Jay Alammar. For a sober discussion of the model\u2019s abilities and limitations, see Kevin Lacker\u2019s Giving GPT-3 a Turing Test.", "In short, GPT-3 is a model which is trained to autocomplete sentences. It\u2019s been trained on huge chunks of the web. And it\u2019s learned lots of interesting stuff along the way.", "It turns out that memorizing lots of stuff is useful if you\u2019re trying to autocomplete sentences from the internet. For instance, if you\u2019re trying to finish phrases about Barack Obama, it\u2019s helpful to memorize a bunch of stuff about him. How else can you complete the sentence \u201cBarack Obama was born in ____\u201d?", "And so the model has learned a lot about Obama. And Trump. And anybody and everything which crops up regularly on the internet.", "In fact, it\u2019s not only learned facts, it\u2019s learned to create stuff. You can\u2019t create stuff by autocompleting sentences, but you can create stuff by autocompleting code. It turns out there\u2019s lots of code on the internet, so the model has learned to write semi-coherent code. For instance, it\u2019s learned to complete sentences which aren\u2019t written in normal prose. It can complete lines written in coding languages, like HTML & CSS.", "Most interestingly, the model has learned to autocomplete code when the start of the phrase is not in code. Let\u2019s look again at that interesting layout generation tweet:", "What\u2019s going on under the hood here? GPT-3 is being fed with natural language descriptions (the prompts being entered into the \u201cgenerate\u201d box), and it\u2019s autocompleting with code that roughly satisfies those descriptions. Presumably the model has learned to do this because during training it saw lots of tutorials, in which people write prose descriptions of what code is doing (\u201cand next, we\u2019re going to make a button that looks like a watermelon\u2026 <code for watermelon button>).", "These kind of demos have sent developers scrambling for API access and VC\u2019s scrambling for their cheque books. Cue Y Combinator\u2019s Paul Graham, one of Silicon Valley\u2019s elder statesmen:", "So what might this mean for people actually building things with AI?", "One of the features of the current surge in AI is that the code, and often the data, is free for anybody to use. The academic model for machine learning has coalesced around free preprints on open websites like Arxiv. Traditional peer review has been replaced by publishing your models and allowing others to tinker with them: basically now you can publish whatever you like, and if the code works, you\u2019ll get credit for it.", "For instance, the last big step forward in NLP was the BERT model from Google. The paper was swiftly followed by code, and you can now train or use BERT models for free with excellent packages like the Transformers library combined with free compute on Google Colab notebooks.", "GPT-3 is radically different in that it\u2019s way too large for hobbyists (or most companies) to train themselves, or to even run. Normally in deep learning, training models is expensive but using them is relatively cheap, and you can do it on your own laptop.", "Not the case here: the model takes about 350GB of memory to run, which is ~15x the amount of memory on my 2019 MacBook Pro. And you can completely forget about training it: Lambda Labs estimate that it would cost $4.6 million to train using cloud GPUs.", "So how do you access GPT-3? Via an API, which means that you send bits of text across the internet and OpenAI, the company that created GPT-3, runs the text through the model and sends you the response.", "This is a radical departure from running models on your own infrastructure. It means that:", "Moreover, access to the API is currently restricted. This creates a power dynamic where a small number of people have access and say nice things about GPT-3 in order to retain this hotly-contested privilege. Think a fashionable musical festival with limited tickets and lots of publicity. A bit like Fyre festival, maybe.", "The title of the paper in which GPT-3 was announced is \u201cLanguage models are few-shot learners\u201d. What the hell does this mean?", "Machine learning works by memorizing patterns. Historically, each model has been able to learn one set of patterns. For instance, we can learn a model to tell us whether a tweet is positive or negative. We do this by showing the model examples of positive and negative tweets, and teaching it \u201ctweets that look like this are positive, tweets that look like this are negative\u201d.", "If we want to learn a model which tells us whether a tweet is about bacon or not, that\u2019s a different model. You can\u2019t ask your \u201cpositive/negative\u201d model to form an opinion on bacon. You train a new one.", "This is a bit like somebody who can\u2019t really play the piano memorizing the hand movements for a particular song. Maybe they can play Chopsticks perfectly, and there\u2019s a bit of flexibility: they can play it louder, or faster, or more staccato. But they can\u2019t read sheet music and play you a new song.", "Compare this with somebody who can play the piano, for real. They have learned how to quickly learn a new piece. They take the music, practice it a few times, and then they can play it.", "This is what GPT-3 can do. It hasn\u2019t learned just to play one piece. It\u2019s learned how to learn to play new pieces quickly.", "That\u2019s what \u201cfew shot learning\u201d means. GPT-3 can learn to do a new task from a few examples. For example, it can learn to do addition, spelling correction, or translation, as visualized in the paper:", "Remember, this model was originally trained just to do autocomplete (that\u2019s what the purple arrow at the top represents).", "This is interesting because it cracks a massive challenge in applying AI in the real world: the cold-start problem. You can\u2019t create a compelling model until you have a bunch of training data. But you can\u2019t really get the data until you\u2019ve built something that people will use. It\u2019s a Catch-22.", "GPT-3 might be able to solve that problem, because it\u2019s able to do so many things out of the box. I think there\u2019s going to be a whole playbook for starting with a GPT-3 baseline for your product, and then figuring out how to layer proprietary data and models on top of it to improve it further. Jack Clark highlighted this in Import AI 217, describing the GeDi model from Salesforce:", "[It] is an example of how researchers are beginning to build plug-in tools, techniques, and augmentations, that can be attached to existing pre-trained models (e.g, GPT3) to provide more precise control over them", "Jack Clark, Import AI Issue 217", "The most valuable enterprise technology companies in recent decades have focused on storing and retrieving information. Most consumers are familiar with services that help you retrieve answers from the web \u2014 like Google- but you might be less familiar with the database technology that keep most of the economy ticking over, sold by companies like Oracle and SAP.", "If you\u2019ve worked with databases before, you\u2019ll know that you have to use special languages to communicate with them. For instance, to identify the most populous city in Canada, you might write something like:", "Which, for most of the population, is gobbledygook.", "But as you\u2019ll remember from the introduction, this is the kind of stuff that GPT-3 has learned incidentally. So you could probably just ask GPT-3 something like:", "This is big, because it\u2019s solving the problem of how to get stuff out of databases.", "But it also addresses how to get stuff into databases. Again, this is currently not very straightforward, and requires specialized knowledge.", "In AI, entering facts into databases is often called \u201cknowledge graph construction\u201d, and it\u2019s time consuming and difficult to automate. Google has been working on their Knowledge Graph since 2012 \u2014 it\u2019s the thing that powers those helpful info boxes that appear above Google results \u2014 but GPT-3 appears to have replicated much of the same content in just a few months of training, with no explicit effort.", "GPT-3 just bypasses the problem of \u201chow should I structure my database and how do I get all of my data into it\u201d. It won\u2019t replace all uses of databases \u2014 you\u2019d have to be a bit mad to get GPT-3 to store the reservations for your airline, for example- but for storing loosely structured data in a way that\u2019s easy to retrieve, it\u2019s going to be tremendously useful.", "For GPT-3 to be useful as a knowledge base, you need to be able to update the information easily. For instance, if the most populous city in Canada changes, we need a way to let GPT-3 know. This is going to be a very hot area of research; clearly you don\u2019t want to retrain the whole model again (remember the price tag?), but it\u2019d be nice to tweak it when the world changes.", "If we can convincingly solve the problem of knowledge update, then I think GPT-3 powered knowledge graphs could be incredibly helpful. Here\u2019s a few examples:", "AI has so far struggled to live up to its commercial promise. GPT-3 offers a refreshingly new approach which bypasses the data paradox which defeats so many early-stage AI projects.", "However, a single vendor controlling access to a model is a dramatic paradigm shift, and it\u2019s not clear how it will play out. OpenAI has not yet participated in the Cloud AI war being waged by Google, Amazon, and Microsoft, but it\u2019d be surprising if those companies didn\u2019t move to replicate the OpenAI GPT-3 service in some shape or form.", "Ultimately I think placing the model behind an API could have unexpected benefits in terms of creative applications of the technology. Arguably the field has been harmed by the exorbitant salaries commanded by ML professionals, which has inhibited the growth of early stage startups focused on building innovative things. If your early hires are so expensive the you need to spend all of your time fundraising, it\u2019s hard to focus on building software that provide value to users. Accessing the model via an API underlines the reality: it\u2019s not magic, it\u2019s a tool. And it\u2019s up to you to do something interesting with it.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Product manager & data scientist. Writing about AI, building things, and climate change."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F58cd66616051&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----58cd66616051--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----58cd66616051--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://archydeberker.medium.com/?source=post_page-----58cd66616051--------------------------------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=post_page-----58cd66616051--------------------------------", "anchor_text": "Archy de Berker"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff651916e4a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&user=Archy+de+Berker&userId=f651916e4a3f&source=post_page-f651916e4a3f----58cd66616051---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58cd66616051&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58cd66616051&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@syinq?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Susan Yin"}, {"url": "https://unsplash.com/s/photos/books?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/abs/2005.14165", "anchor_text": "OpenAI\u2019s monstrous new language model, GPT-3."}, {"url": "http://jalammar.github.io/how-gpt3-works-visualizations-animations/", "anchor_text": "this visual guide"}, {"url": "https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html", "anchor_text": "Giving GPT-3 a Turing Test"}, {"url": "https://twitter.com/paulg", "anchor_text": "Paul Graham"}, {"url": "https://unsplash.com/@timmossholder?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Tim Mossholder"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/list/cs.LG/recent", "anchor_text": "Arxiv"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT model from Google"}, {"url": "https://huggingface.co/transformers/", "anchor_text": "Transformers library"}, {"url": "https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb", "anchor_text": "Google Colab"}, {"url": "https://lambdalabs.com/blog/demystifying-gpt-3/", "anchor_text": "Lambda Labs estimate that it would cost $4.6 million to train using cloud GPUs."}, {"url": "http://v", "anchor_text": "OpenAI"}, {"url": "https://forms.office.com/Pages/ResponsePage.aspx?id=VsqMpNrmTkioFJyEllK8s0v5E5gdyQhOuZCXNuMR8i1UQjFWVTVUVEpGNkg3U1FNRDVVRFg3U0w4Vi4u", "anchor_text": "currently restricted"}, {"url": "https://www.youtube.com/watch?v=uZ0KNVU2fV0", "anchor_text": "Fyre festival"}, {"url": "https://www.youtube.com/watch?v=M4MMUpjcqkQ", "anchor_text": "Chopsticks"}, {"url": "https://giphy.com/gifs/outkast-andre-3000-stankonia-ms-jackson-wkLC089tCSKs4oSXDF/media", "anchor_text": "Giphy"}, {"url": "https://arxiv.org/pdf/2005.14165.pdf", "anchor_text": "original paper"}, {"url": "https://jack-clark.net", "anchor_text": "Import AI 217"}, {"url": "https://arxiv.org/abs/2009.06367", "anchor_text": "GeDi model from Salesforce"}, {"url": "https://jack-clark.net/2020/10/05/import-ai-217-deepfaked-congressmen-and-deepfaked-kids-steering-gpt3-with-gedi-amazons-robots-versus-its-humans/", "anchor_text": "Import AI Issue 217"}, {"url": "https://www.oracle.com/index.html", "anchor_text": "Oracle"}, {"url": "https://www.sap.com/canada/index.html", "anchor_text": "SAP"}, {"url": "https://en.wikipedia.org/wiki/Knowledge_Graph#/media/File:Google_Knowledge_Panel.png", "anchor_text": "Wikipedia."}, {"url": "https://lambdalabs.com/blog/demystifying-gpt-3/", "anchor_text": "remember the price tag?"}, {"url": "https://www.gartner.com/en/documents/3981253/magic-quadrant-for-cloud-ai-developer-services", "anchor_text": "Cloud AI war"}, {"url": "https://www.nytimes.com/2018/04/19/technology/artificial-intelligence-salaries-openai.html", "anchor_text": "exorbitant salaries commanded by ML professionals"}, {"url": "https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/", "anchor_text": "critique of GPT-3"}, {"url": "https://www.gwern.net/GPT-3", "anchor_text": "Experiments in creative writing with GPT-3"}, {"url": "https://twitter.com/mckaywrigley/status/1284110063498522624?s=20", "anchor_text": "lessons from dead people"}, {"url": "http://deberker.com/archy/what-does-gpt-3-mean-for-ai/", "anchor_text": "http://deberker.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----58cd66616051---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/startup?source=post_page-----58cd66616051---------------startup-----------------", "anchor_text": "Startup"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----58cd66616051---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/data-science?source=post_page-----58cd66616051---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----58cd66616051---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F58cd66616051&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&user=Archy+de+Berker&userId=f651916e4a3f&source=-----58cd66616051---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F58cd66616051&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&user=Archy+de+Berker&userId=f651916e4a3f&source=-----58cd66616051---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58cd66616051&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----58cd66616051--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F58cd66616051&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----58cd66616051---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----58cd66616051--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----58cd66616051--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----58cd66616051--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----58cd66616051--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----58cd66616051--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----58cd66616051--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----58cd66616051--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----58cd66616051--------------------------------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Archy de Berker"}, {"url": "https://archydeberker.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "321 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff651916e4a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&user=Archy+de+Berker&userId=f651916e4a3f&source=post_page-f651916e4a3f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1754fbd1852&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-does-gpt-3-mean-for-ai-58cd66616051&newsletterV3=f651916e4a3f&newsletterV3Id=b1754fbd1852&user=Archy+de+Berker&userId=f651916e4a3f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}