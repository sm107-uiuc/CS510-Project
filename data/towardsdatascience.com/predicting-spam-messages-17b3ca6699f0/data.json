{"url": "https://towardsdatascience.com/predicting-spam-messages-17b3ca6699f0", "time": 1683011454.383507, "path": "towardsdatascience.com/predicting-spam-messages-17b3ca6699f0/", "webpage": {"metadata": {"title": "Predicting Spam Messages. I used ML models and NLP techniques to\u2026 | by Lazr Galstyan | Towards Data Science", "h1": "Predicting Spam Messages", "description": "In this article, I try to predict spam messages. You can find all the python codes on my Github account provided at the end of the article. Nowadays, the first thing that comes to our mind when we\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=_bW4vEo1F4E&t=17s", "anchor_text": "scenes", "paragraph_index": 2}, {"url": "https://archive.ics.uci.edu/ml/datasets/sms+spam+collection", "anchor_text": "dataset", "paragraph_index": 3}, {"url": "https://www.youtube.com/watch?v=O2L2Uv9pdDA", "anchor_text": "video", "paragraph_index": 5}, {"url": "http://www.wearespam.com/", "anchor_text": "www.wearespam.com", "paragraph_index": 6}, {"url": "http://www.wearealsosmap.com/", "anchor_text": "www.wearealsosmap.com", "paragraph_index": 6}, {"url": "http://regexlib.com/Search.aspx", "anchor_text": "website", "paragraph_index": 7}, {"url": "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://github.com/Lazr-Galstyan/Predicting-Spam-Messages/blob/master/Predicting_Spam_Messages.ipynb", "anchor_text": "github", "paragraph_index": 18}], "all_paragraphs": ["In this article, I try to predict spam messages. You can find all the python codes on my Github account provided at the end of the article.", "Nowadays, the first thing that comes to our mind when we hear the word \u201cspam\u201d is a junk message. However, that was not the case eighty years ago. The term spam was created in 1937 by a man called Ken Daigneau to name Hormel Foods\u2019 new meat product. Ken won $100 prize for naming the new item. Some people think that spam stands for Spiced Ham, and many others believe that it stands for \u201cSpecially Processed American Meat.\u201d", "The word \u201cspam\u201d started to be considered as something \u201cannoying\u201d in the 1970s, after Monty Python\u2019s Flying Circus show, when in one of the \u201cscenes\u201d the Vikings begin singing the \u201cspam song\u201d and repeating the word \u201cspam\u201d all the time. Later, in the 1980s and 1990s, people were using the repetition of the word \u201cspam\u201d and sometimes even the whole song of Vikings to spam chats. Hence, people started associating the word \u201cspam\u201d with annoying junk messages.", "The goal of this article is to use different machine learning techniques to predict whether or not a message is spam. I used the dataset provided by UC Irvine, which contains around 5,500 text messages. Below is the structure of the article:", "First, let\u2019s do some exploratory data analysis. By checking the shape of the dataset, we can see that it has 5,572 observations and two columns. However, out of the 5,572 observations, there are only 5,169 unique values, which means that there are around 450 duplicate rows. I also checked for missing values, but found that none of the columns had any missing value. Below are the first five rows and the shape of the dataset:", "After removing the duplicates, the dataset has 5,169 observations, out of which 4,516 are ham, and 653 are spam. A relatively large number of ham messages means that if I take all the messages as ham, I will get around 87% accuracy. Some people use the accuracy of Naive Bayes (a very simple model) as a benchmark, but I will take the overall accuracy as a benchmark and will try to make models that can predict better with higher accuracy. In case you want to learn more about Naive Bayes, check this video.", "Before starting the modeling part, I need to work with the data and make it suitable for modeling. In this part, I need to convert the emails, web-addresses, money signs, phone numbers, and numbers to specific words and remove all the punctuation. To be more precise, imagine a spam message that has the following message \u201cuse www.wearespam.com link to get $1,000,000,\u201d and another spam message that contains \u201cuse www.wearealsosmap.com link to get $500,000\u201d expression. In this case, we do not want the algorithm to take into account the two different links or prize amounts, but to have them defined with specific words. After converting the text, the two sentences would look like \u201cuse webaddr link to get money number.\u201d Besides changing some words in the text, I normalized the lexicon and removed all the stopwords from the text. I will now provide more detail on each part to be more precise.", "Removing \u201cunnecessary\u201d words \u2014 As I already explained, we do not need to have different unique numbers in the text. Still, we need to know whether a specific message contains an email address, phone number, etc. You can use Python\u2019s Regular Expressions package to identify the emails and phone numbers in the text. Find more about the regular expressions on the following website.", "Normalize the lexicon \u2014 I performed the lemmatization technique for lexicon normalization. In this process, we bring the word to its \u201cbase\u201d level. For example, the words \u201cgo,\u201d \u201cgoes,\u201d and \u201cgoing\u201d have the same base, but are used differently. The other approach for lexicon normalization is stemming, but lemmatization has some advantages over stemming. For example, lemmatization transforms the word to its base with the use of vocabulary, whereas stemming works on the word, without taking into account its content. As a result, lemmatization can lead to a better transformation of the words, without changing the meanings. To learn more about lemmatization and stemming, check here.", "After cleaning the text, I need to see the most common words. The following chart shows that the most common word in the text is \u201cnumber.\u201d That is because I converted all the numbers to one word, and our text included too many different numbers.", "Finally, after removing the stopwords, the unnecessary words, and normalizing the lexicon, it is time to tokenize the text. Tokenization is the process of treating each word or a sequence of words as a specific unit. For example, after conducting unigram tokenization to the \u201cI like apple\u201d sentence, we get three separate tokens: [I], [like], and [apple]. I used unigram and bigram tokenization, because expressions, which include two words, can also be necessary for the analysis. For example, in the phrase \u201cgood morning,\u201d the two words together, not separately, are essential to capture the exact meaning of the expression. I did not tokenize with three and more words not to increase the number of variables and to minimize the usage of computing power. After tokenizing the text, I made a bag of words to start working with the data. By making the bag of words, we provide numeric value to the words. Bag of words calculates the occurrence of each token in the sentence. It is a simple technique and is easy to use. However, using only a BoW has its drawbacks as well. For example, BoW measures the occurrence of each word in the text, and more frequent words can get higher importance. For example, let\u2019s take the following two sentences: \u201cBombardment, barrage, curtain-fire, mines, gas, tanks, machine-guns, hand-grenades \u2014 words, words, words, but they hold the horror of the world\u201d (Erich Maria Remarque \u201cAll Quiet on the Western Front\u201d) and \u201cThis is a table.\u201d After making the bag of words, we see that the word \u201cwords\u201d is more common than \u201ctable,\u201d which means that \u201cwords\u201d will get more importance. To solve this issue, I used TF-IDF (Term Frequency-Inverse Document Frequency) weight. The weight provides the significance of each token, but it also considers the frequency of token in the corpus. To learn more about BoW and TF-IDF, you can check here.", "After tokenizing the data and calculating TF-IDF weights, I got the final dataset, which consists of 5169 rows and 37891 columns. That\u2019s a lot!!!", "As I have the data prepared, it is time to make the models. For my analysis, I used four different models: SVM, random forest, logistic regression, and XGBoost. I divided the dataset into two parts and used one to train the models and the other one to test their performance. To improve each model\u2019s performance, I tried different parameters and used Bayesian Optimization for hyperparameter tuning. I took different ranges of parameters and used cross-validation on the training dataset to find the best combination of the parameters. Later, I tested the models on the test dataset and used accuracy and AUC scores to compare their performances. Even though I used Bayesian Optimization for hyperparameter tuning, I want to quickly go through alternative methods, which are widely used as well. Possible substitutes for Bayesian Optimization are grid search and random search, but I used Bayesian Optimization because the other two have some drawbacks. I will briefly explain how each method works and what are their possible downsides.", "Below you can find the code of hyperparameter tuning for XGBoost:", "By knowing the optimal parameters for all the models and making the models, I found that Support Vector Machine (SVM) performs best for the prediction. It has 98% accuracy and AUC score of 0.92. The performance was not significantly different for XGBoost and Random Forest, but those models had lower accuracy and AUC. A relatively simple model, logistic regression, was not preforming well for predictions and had the lowest accuracy and AUC score among all. Also, by looking at the confusion matrix, we can see that most of the errors are associated with False Positives when the algorithm predicts the message to be spam, but in fact, it is ham. Below is the summary of results for SVM:", "In the end, I made ROC curves for all the models to visually see which one performs the best. Below you can find the ROC plot:", "Again you can see that SVM (the red line) has the best performance as it has the highest ROC score.", "In total, in this article I tried to see which model can help to better predict the spam messages. At first, I cleaned the data, did the necessary transformations with the text and convert word to numeric values to be able to make models. I used four models and got the highest accuracy and AUC score for SVM. The usage of the model can help many businesses to better understand which messages are spam. However, I believe that the predictions can be improved further by using more sophisticated models such as Neural Networks.", "You can find the Python codes used for this article on my github account.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Recent Duke graduate interested in data science and business analytics. Like playing chess and watching documentaries. Hala Madrid!!!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F17b3ca6699f0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@lazrgalstyan?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lazrgalstyan?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "Lazr Galstyan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6867e3c7d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&user=Lazr+Galstyan&userId=a6867e3c7d9e&source=post_page-a6867e3c7d9e----17b3ca6699f0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F17b3ca6699f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F17b3ca6699f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.youtube.com/watch?v=_bW4vEo1F4E&t=17s", "anchor_text": "scenes"}, {"url": "https://archive.ics.uci.edu/ml/datasets/sms+spam+collection", "anchor_text": "dataset"}, {"url": "https://www.youtube.com/watch?v=O2L2Uv9pdDA", "anchor_text": "video"}, {"url": "http://www.wearespam.com/", "anchor_text": "www.wearespam.com"}, {"url": "http://www.wearealsosmap.com/", "anchor_text": "www.wearealsosmap.com"}, {"url": "http://regexlib.com/Search.aspx", "anchor_text": "website"}, {"url": "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html", "anchor_text": "here"}, {"url": "https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/", "anchor_text": "here"}, {"url": "https://github.com/Lazr-Galstyan/Predicting-Spam-Messages/blob/master/Predicting_Spam_Messages.ipynb", "anchor_text": "github"}, {"url": "https://medium.com/tag/nlp?source=post_page-----17b3ca6699f0---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----17b3ca6699f0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----17b3ca6699f0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----17b3ca6699f0---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/business-analysis?source=post_page-----17b3ca6699f0---------------business_analysis-----------------", "anchor_text": "Business Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F17b3ca6699f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&user=Lazr+Galstyan&userId=a6867e3c7d9e&source=-----17b3ca6699f0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F17b3ca6699f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&user=Lazr+Galstyan&userId=a6867e3c7d9e&source=-----17b3ca6699f0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F17b3ca6699f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F17b3ca6699f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----17b3ca6699f0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----17b3ca6699f0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lazrgalstyan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lazrgalstyan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Lazr Galstyan"}, {"url": "https://medium.com/@lazrgalstyan/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "7 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6867e3c7d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&user=Lazr+Galstyan&userId=a6867e3c7d9e&source=post_page-a6867e3c7d9e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fa6867e3c7d9e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-spam-messages-17b3ca6699f0&user=Lazr+Galstyan&userId=a6867e3c7d9e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}