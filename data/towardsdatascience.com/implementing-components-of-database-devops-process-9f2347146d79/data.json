{"url": "https://towardsdatascience.com/implementing-components-of-database-devops-process-9f2347146d79", "time": 1683002262.500119, "path": "towardsdatascience.com/implementing-components-of-database-devops-process-9f2347146d79/", "webpage": {"metadata": {"title": "Implementing Components of Database DevOps Process | by Evgeniy Gribkov | Towards Data Science", "h1": "Implementing Components of Database DevOps Process", "description": "In recent years, database DevOps has become one of the most demanded processes. Even small companies can\u2019t really work effectively without it, and most IT companies have already implemented DevOps\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.devart.com/dbforge/sql/database-devops/", "anchor_text": "dbForge DevOps Automation for SQL Server", "paragraph_index": 19}, {"url": "https://www.devart.com/dbforge/sql/database-devops/sqlcomplete.html", "anchor_text": "SQL Complete", "paragraph_index": 20}, {"url": "https://www.devart.com/dbforge/sql/database-devops/source-control.html", "anchor_text": "Source Control", "paragraph_index": 20}, {"url": "https://www.devart.com/dbforge/sql/documenter/", "anchor_text": "Documentation", "paragraph_index": 20}, {"url": "https://www.devart.com/dbforge/sql/database-devops/test-data-management.html", "anchor_text": "Data Generator", "paragraph_index": 21}, {"url": "https://www.devart.com/dbforge/sql/database-devops/unit-testing.html", "anchor_text": "Unit Test", "paragraph_index": 21}, {"url": "https://www.devart.com/dbforge/sql/database-devops/database-schema-changes.html", "anchor_text": "Schema Compare", "paragraph_index": 22}, {"url": "https://www.devart.com/en/dbforge/sql/datacompare/", "anchor_text": "Data Compare", "paragraph_index": 22}, {"url": "https://www.devart.com/dbforge/sql/database-devops/continuous-intergation-export-import-data.html", "anchor_text": "dbForge Data Pump", "paragraph_index": 25}, {"url": "https://www.devart.com/dbforge/sql/event-profiler/", "anchor_text": "dbForge Event Profiler", "paragraph_index": 26}, {"url": "https://www.devart.com/dbforge/sql/studio/monitor.html", "anchor_text": "dbForge Monitor", "paragraph_index": 26}, {"url": "https://www.devart.com/dbforge/sql/sqlcomplete/", "anchor_text": "SQL Complete", "paragraph_index": 28}, {"url": "https://docs.devart.com/devops-automation-for-sql-server/powershell-cmdlets/export-devartdbproject.html", "anchor_text": "here", "paragraph_index": 44}], "all_paragraphs": ["In recent years, database DevOps has become one of the most demanded processes. Even small companies can\u2019t really work effectively without it, and most IT companies have already implemented DevOps database automation and made it a crucial part of their work process.", "The main role of the database DevOps process is to continuously deliver changes from development and testing environments to the production environment, monitoring the state of the production environment, and providing the ability to rollback changes when needed. After this, the changes are transferred to the production environment management service. Basically, the DevOps process connects the development and testing with various types of administration (system, database, etc.) and other production environments and system management processes. DevOps database automation specifically includes automation at all environments and makes development and admin tasks for a database simpler and safer.", "Usually, the database DevOps process is divided into two parts:", "1. Before production \u2014 everything that happens before actually committing changes to the production environments. This includes the following stages:", "1.1 Compiling and documenting the code", "1.2 Filling the database with test data and running auto tests", "1.3 Applying the changes from development environments to testing environments", "1.4 Filling the database with test data", "1.5 Deciding whether the changes are ready to be deployed to production environments", "The first part of the process is mostly facilitated by the work of developers and testers, with stage 1.3 being implemented by DevOps engineers. The stages 1.2 through 1.4 can be performed in any order based on task specification and how the DevOps process itself is established. The idea is to successfully pass all the steps from compiling the code to deciding if it\u2019s ready to be deployed to production.", "After stage 1.3, all sorts of testing are performed on the solution (stress, functional, integration testing, and others). If any major deviation from working criteria is detected (for example, if errors or performance issues are found), usually it is decided at stage 1.5 that the code is not ready to be deployed to production and so should be sent back to development. After this, the process starts over again from stage 1.1. Things are similar with stage 1.2.", "Stage 1.5 can also be failed due to reasons not related to stages 1.2 or 1.3. Only after stage 1.5 is passed, the DevOps process moves to the second (and the most important) part:", "2. Implementation \u2014 moving the solution to production. This includes the following stages:", "2.3 Rolling back the deployment or moving the changes to production environment management services.", "Stage 2.1 is usually started manually by combined efforts of DevOps specialists and production environment management service specialists to avoid issues on production. It would be nice to mention that stage 2.1 includes stage 1.3 \u2014 the only difference being that the changes are deployed to production. If deployment fails (stage 2.1), the issues are located and then either stage 2.1 is repeated or the DevOps process is returned to the beginning of part 1.", "On the other hand, if deployment is successful but primary monitoring fails, it is usually decided that the deployment should be rolled back (stage 2.3), with the DevOps process returned to its first part.", "Only if stages 2.1 and 2.2 are completely successful when assessed against all the necessary criteria and no issues are detected, the changes are handed to the production environment management service (stage 2.3) for continuous maintenance by the administration. This is where an iteration of the DevOps process ends.", "It\u2019s important to note that this process happens continuously, iteration by iteration, thus minimizing the time it takes to deliver the code from development environments to testing environments and vice versa or between development or testing environments. The DevOps process also shortens the time of delivery to production environments with the ability to monitor and rollback the changes.", "Let\u2019s look at how some components of the database DevOps process can be implemented. In this example, we\u2019ll use a database of potential employees.", "We\u2019ll look into the following aspects and how to generate PowerShell scripts for them to organize the database DevOps process. dbForge DevOps Automation for SQL Server and various dbForge tools will help us with this:", "1.1 Code compilation and documentation (SQL Complete, Source Control, Documentation)", "1.2 Filling the database with test data and running auto tests (Data Generator, Unit Test)", "1.3 Deploying the solution from development environments to testing environments (Schema Compare, Data Compare)", "1.4 Filling the database with test data", "1.5 Deciding whether the code is ready to be deployed to production (this is a managerial responsibility, so we won\u2019t be talking about it here)", "2.1 Deployment (database schema comparison, data comparison, dbForge Data Pump)", "2.2 Primary monitoring (dbForge Event Profiler, dbForge Monitor, dbForge Data Pump)", "2.3 Rolling back the deployment or handing the changes to the production environment management services (this can be done in multiple ways, so we will also omit its discussion, but transaction rollback can be performed using dbForge Transaction Log)", "We won\u2019t be delving into stage 1.1 and the second part too deeply in this article. However, one important feature of SQL Complete should be mentioned. Specifically, to format a folder with scripts, we can use the following PowerShell script:", "Here, $scriptFolder is the full path to the necessary folder with scripts that needs to be formatted. Also, the Invoke-DevartFormatScript cmdlet is used to invoke the formatting functionality of the SQL Complete tool. As we can see from the script, the cmdlet only has one parameter \u2014 the path to the folder that contains database schema creation or update scripts.", "Now we\u2019ll look in detail at the stages 1.2\u20131.4. As these stages can be performed in any order during the database DevOps process, we\u2019ll arrange them as follows:", "We\u2019ll need to either save a data generation project or create a new one with necessary parameters and save it as JobEmplDB.dgen.", "Now we can use the Invoke-DevartDatabaseTests cmdlet to invoke the data generation process according to the JobEmplDB.dgen project:", "Here, replace $ConnectionString with the connection string and $JobEmplDBFolder with the full name of the JobEmplDB.dgen file, i.e. the full path to this file including the actual file name and extension.", "Now, let\u2019s take a look at how we can use a PowerShell script to run auto tests.", "We\u2019ll use the Invoke-DevartExecuteScript and Invoke-DevartDatabaseTests cmdlets for this:", "The first cmdlet creates tests for the database from a folder, where:", "The second cmdlet runs unit tests against the database:", "The OutReportFileName $TestReportOutputFileName parameter is the path to the output test report file, and ReportFormat JUnit specifies the format of this file", "In the future, the Invoke-DevartDatabaseTests cmdlet will be divided into two separate parts \u2014 one for running auto tests, and the other for generating test data.", "To transfer the schema changes, we can use the following PowerShell script using the Invoke-DevartSyncDatabaseSchema cmdlet:", "Here, $sourceConnection is the connection string for the source database, and $targetConnection is the connection string for the target database. The $syncResult variable will contain the result of database schema synchronization.", "Currently, there is no cmdlet for synchronizing data between databases, but there will be one in the future.", "For now, we can use the Invoke-DevartDataImport cmdlet that launches dbForge Data Pump to transfer the data:", "Here, $connection is the connection string for the JobEmplDB database, and $importDataFileName is the full name of the file that is used to create import data. There is also a line of other useful cmdlets from Devart that will help implement various DevOps process components using PowerShell scripts. You can learn more about them here.", "As we can see, database changes (both in the schema and in the data) can be automatically transferred between environments with the help of dbForge Schema Compare and dbForge Data Compare (dbForge Data Compare can only work in manual mode for now). We can also use the dbForge Data Pump component cmdlets for the purpose of transferring data.", "With the help of PowerShell scripts, we can automate the entire DevOps process \u2014 starting from code compilation to deploying the code to production and primary monitoring.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am interested in everything related to the database and data. Professionally engaged in MS SQL Server as a developer and administrator."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9f2347146d79&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9f2347146d79--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9f2347146d79--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@gribkov.evg?source=post_page-----9f2347146d79--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gribkov.evg?source=post_page-----9f2347146d79--------------------------------", "anchor_text": "Evgeniy Gribkov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad6d87f14fe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&user=Evgeniy+Gribkov&userId=ad6d87f14fe8&source=post_page-ad6d87f14fe8----9f2347146d79---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f2347146d79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f2347146d79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.devart.com/dbforge/sql/database-devops/", "anchor_text": "dbForge DevOps Automation for SQL Server"}, {"url": "https://www.devart.com/dbforge/sql/database-devops/sqlcomplete.html", "anchor_text": "SQL Complete"}, {"url": "https://www.devart.com/dbforge/sql/database-devops/source-control.html", "anchor_text": "Source Control"}, {"url": "https://www.devart.com/dbforge/sql/documenter/", "anchor_text": "Documentation"}, {"url": "https://www.devart.com/dbforge/sql/database-devops/test-data-management.html", "anchor_text": "Data Generator"}, {"url": "https://www.devart.com/dbforge/sql/database-devops/unit-testing.html", "anchor_text": "Unit Test"}, {"url": "https://www.devart.com/dbforge/sql/database-devops/database-schema-changes.html", "anchor_text": "Schema Compare"}, {"url": "https://www.devart.com/en/dbforge/sql/datacompare/", "anchor_text": "Data Compare"}, {"url": "https://www.devart.com/dbforge/sql/database-devops/continuous-intergation-export-import-data.html", "anchor_text": "dbForge Data Pump"}, {"url": "https://www.devart.com/dbforge/sql/event-profiler/", "anchor_text": "dbForge Event Profiler"}, {"url": "https://www.devart.com/dbforge/sql/studio/monitor.html", "anchor_text": "dbForge Monitor"}, {"url": "https://www.devart.com/dbforge/sql/sqlcomplete/", "anchor_text": "SQL Complete"}, {"url": "https://docs.devart.com/devops-automation-for-sql-server/powershell-cmdlets/export-devartdbproject.html", "anchor_text": "here"}, {"url": "https://medium.com/tag/devops?source=post_page-----9f2347146d79---------------devops-----------------", "anchor_text": "DevOps"}, {"url": "https://medium.com/tag/powershell?source=post_page-----9f2347146d79---------------powershell-----------------", "anchor_text": "Powershell"}, {"url": "https://medium.com/tag/sql-server?source=post_page-----9f2347146d79---------------sql_server-----------------", "anchor_text": "Sql Server"}, {"url": "https://medium.com/tag/database?source=post_page-----9f2347146d79---------------database-----------------", "anchor_text": "Database"}, {"url": "https://medium.com/tag/database-administration?source=post_page-----9f2347146d79---------------database_administration-----------------", "anchor_text": "Database Administration"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9f2347146d79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&user=Evgeniy+Gribkov&userId=ad6d87f14fe8&source=-----9f2347146d79---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9f2347146d79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&user=Evgeniy+Gribkov&userId=ad6d87f14fe8&source=-----9f2347146d79---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f2347146d79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9f2347146d79--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9f2347146d79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9f2347146d79---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9f2347146d79--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9f2347146d79--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9f2347146d79--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9f2347146d79--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9f2347146d79--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9f2347146d79--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9f2347146d79--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9f2347146d79--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gribkov.evg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gribkov.evg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Evgeniy Gribkov"}, {"url": "https://medium.com/@gribkov.evg/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "42 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad6d87f14fe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&user=Evgeniy+Gribkov&userId=ad6d87f14fe8&source=post_page-ad6d87f14fe8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe2e084bc4fe5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-components-of-database-devops-process-9f2347146d79&newsletterV3=ad6d87f14fe8&newsletterV3Id=e2e084bc4fe5&user=Evgeniy+Gribkov&userId=ad6d87f14fe8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}