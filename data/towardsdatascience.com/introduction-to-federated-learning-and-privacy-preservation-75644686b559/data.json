{"url": "https://towardsdatascience.com/introduction-to-federated-learning-and-privacy-preservation-75644686b559", "time": 1682997221.155371, "path": "towardsdatascience.com/introduction-to-federated-learning-and-privacy-preservation-75644686b559/", "webpage": {"metadata": {"title": "Introduction to Federated Learning and Privacy Preservation | by Kapil Chandorikar | Towards Data Science", "h1": "Introduction to Federated Learning and Privacy Preservation", "description": "This article introduces the idea behind Federated Learning and Additive Secret Sharing through simple examples and illustration accompanied by code snippets using the PySyft framework."}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1811.04017", "anchor_text": "A generic framework for privacy preserving deep learning (2018)", "paragraph_index": 44}, {"url": "https://arxiv.org/abs/1811.03604", "anchor_text": "Federated Learning for Mobile Keyboard Prediction (2019)", "paragraph_index": 45}, {"url": "https://arxiv.org/abs/1902.01046", "anchor_text": "Towards Federated Learning at Scale: System Design (2019)", "paragraph_index": 46}, {"url": "https://ai.googleblog.com/2017/04/federated-learning-collaborative.html", "anchor_text": "Federated Learning: Collaborative Machine Learning without Centralized Training Data (2017)", "paragraph_index": 47}, {"url": "https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html", "anchor_text": "Learning with Privacy at Scale (2017)", "paragraph_index": 48}, {"url": "https://www.youtube.com/watch?v=89BGjQYA0uE", "anchor_text": "Federated Learning: Machine Learning on Decentralized Data (2019)", "paragraph_index": 49}], "all_paragraphs": ["Federated Learning involves training on a large corpus of high-quality decentralized data present on multiple client devices. The model is trained on client devices and thus there is no need for uploading the user\u2019s data. Keeping the personal data on the client\u2019s device enables them to have direct and physical control of their own data.", "The server trains the initial model on proxy data available beforehand. The initial model is sent to a select number of eligible client devices. The eligibility criterion makes sure that the user\u2019s experience is not spoiled in an attempt to train the model. An optimal number of client devices are selected to take part in the training process. After processing the user data, the model updates are shared with the server. The server aggregates these gradients and improves the global model.", "All the model updates are processed in memory and persist for a very short period of time on the server. The server then sends the improved model back to the client devices participating in the next round of training. After attaining a desired level of accuracy, the on-device models can be tweaked for the user\u2019s personalization. Then, they are no longer eligible to participate in the training. Throughout the entire process, the data does not leave the client\u2019s device.", "Federated learning differs from decentralized computation as:", "Federated Learning is one instance of the more general approach of \u201cbringing the code to the data, instead of the data to the code\u201d and addresses the fundamental problems of privacy, ownership, and locality of data.", "We will use PySyft to implement a federated learning model. PySyft is a Python library for secure and private deep learning.", "PySyft requires Python >= 3.6 and PyTorch 1.1.0. Make sure you meet these requirements.", "Let\u2019s start by importing the libraries and initializing the hook.", "This is done to override PyTorch\u2019s methods to execute commands on one worker that are called on tensors controlled by the local worker. It also allows us to move tensors between workers. Workers are explained below.", "Virtual workers are entities present on our local machine. They are used to model the behavior of actual workers.", "To work with workers distributed in a network, PySyft offers two types of workers:", "Web sockets workers can be instantiated from the browser with each worker on a separate tab.", "Here, Jake is our virtual worker which can be considered as a separate entity on a device. Let\u2019s send him some data.", "When we send a tensor to Jake, we are returned a pointer to that tensor. All the operations will be executed with this pointer. This pointer holds information about the data present on another machine. Now, x is a PointTensor.", "Use the get() method to get back the value of x from Jake\u2019s device. However, by doing so, the tensor on Jake\u2019s device gets erased.", "When we send the PointTensor x (pointing to a tensor on Jake\u2019s machine) to another worker - John, the whole chain is sent to John and a PointTensor pointing to the node on John\u2019s device is returned. The tensor is still present on Jake\u2019s device.", "The clear_objects() method removes all the objects from a worker.", "Suppose we wanted to move a tensor from Jake\u2019s machine to John\u2019s machine. We could do this by using the send() method to send the \u2018pointer to tensor\u2019 to John and let him call the get() method. PySfyt provides a remote_get() method to do this. There\u2019s also a convenience method - move(), to perform the operation.", "We can perform federated learning on client devices by following these steps:", "However, if someone intercepts the smarter model while it is shared with the server, he could perform reverse engineering and extract sensitive data about the dataset. Differential privacy methods address this issue and protect the data.", "When the updates are sent back to the server, the server should not be able to discriminate while aggregating the gradients. Let\u2019s use a form of cryptography called additive secret sharing.", "We want to encrypt these gradients (or model updates) before performing the aggregation so that no one will be able to see the gradients. We can achieve this by additive secret sharing.", "In secret sharing, we split a secret x into a multiple number of shares and distribute them among a group of secret-holders. The secret x can be constructed only when all the shares it was split into are available.", "For example, say we split x into 3 shares: x1, x2, and x3. We randomly initialize the first two shares and calculate the third share as x3 = x - (x1 + x2). We then distribute these shares among 3 secret-holders. The secret remains hidden as each individual holds onto only one share and has no idea of the total value.", "We can make it more secure by choosing the range for the value of the shares. Let Q, a large prime number, be the upper limit. Now the third share, x3, equals Q - (x1 + x2) % Q + x.", "The decryption process will be shares summed together modulus Q.", "Homomorphic encryption is a form of encryption that allows us to perform computation on encrypted operands, resulting in encrypted output. This encrypted output when decrypted matches with the result obtained by performing the same computation on the actual operands.", "The additive secret sharing technique already has a homomorphic property. If we split x into x1, x2, and x3, and y into y1, y2, and y3, then, x+y will be equal to the value obtained after decrypting the summation of the three shares: (x1+y1), (x2+y2) and (x3+y3).", "We are able to calculate the value of the aggregate function - addition, without knowing the values of x and y.", "PySyft provides a share() method to split the data into additive secret shares and send them to the specified workers. For working with decimal numbers, fix_precision() method is used to represent the decimals as integer values under the hood.", "The share() method is used to distribute the shares among several workers. Each worker specified then receives a share and has no idea of the actual value.", "As you can see, x now points to the three shares present on Jake\u2019s, John\u2019s and Secure_worker\u2019s machine respectively.", "Notice that the value of z obtained after adding x and y is stored in the three workers\u2019 machines. z is also encrypted.", "The value obtained after performing addition on encrypted shares is equal to that obtained by adding the actual numbers.", "Now, we\u2019ll implement the federated learning approach to train a simple neural network on the MNIST dataset using the two workers: Jake and John. There are only a few modifications necessary to apply the federated learning approach.", "In real-life applications, the data is present on client devices. To replicate the scenario, we send data to the VirtualWorkers.", "Notice that we have created the training dataset differently. The train_set.federate((jake, john)) creates a FederatedDataset wherein the train_set is split among Jake and John (our two VirtualWorkers). The FederatedDataset class is intended to be used like the PyTorch\u2019s Dataset class. Pass the created FederatedDataset to a federated data loader \u201cFederatedDataLoader\u201d to iterate over it in a federated manner. The batches then come from different devices.", "Since the data is present on the client device, we obtain its location through the location attribute. The important additions to the code are the steps to get back the improved model and the value of the loss from the client devices.", "That\u2019s it. We have trained a model using the federated learning approach. When compared to traditional training, it takes more time to train a model using the federated approach.", "Training the model on the client device protected the user\u2019s privacy. But, what about the model\u2019s privacy? Downloading the model can threaten the organization\u2019s intellectual property!", "Secure Multi-Party Computation, which consists of secret additive sharing, provides us with a way to perform model training without disclosing the model.", "To protect the weights of the model, we secret share the model among the client devices.", "For this to work, some changes are to be made to the above federated learning example.", "As illustrated in the SECRET SHARING USING PYSYFT section, now the model, the inputs, model outputs, weights, etc. will be encrypted as well. Working on encrypted inputs will yield encrypted output.", "[1] Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel Rueckert, Jonathan Passerat-Palmbach, A generic framework for privacy preserving deep learning (2018), arXiv", "[2] Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Fran\u00e7oise Beaufays, Sean Augenstein, Hubert Eichner, Chlo\u00e9 Kiddon, Daniel Ramage, Federated Learning for Mobile Keyboard Prediction (2019), arXiv", "[3] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Kone\u010dn\u00fd, Stefano Mazzocchi, H. Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage, Jason Roselander, Towards Federated Learning at Scale: System Design (2019), arXiv", "[4] Brendan McMahan, Daniel Ramage, Federated Learning: Collaborative Machine Learning without Centralized Training Data (2017), Google AI Blog", "[5] Differential Privacy Team at Apple, Learning with Privacy at Scale (2017), Apple Machine Learning Journal", "[6] Daniel Ramage, Emily Glanz, Federated Learning: Machine Learning on Decentralized Data (2019), Google I/O\u201919", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Hi! My name is Kapil Chandorikar. I\u2019m a Deep Learning enthusiast and love developing websites and Android applications."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F75644686b559&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----75644686b559--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----75644686b559--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kapilchandorikar?source=post_page-----75644686b559--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kapilchandorikar?source=post_page-----75644686b559--------------------------------", "anchor_text": "Kapil Chandorikar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fac557a986566&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&user=Kapil+Chandorikar&userId=ac557a986566&source=post_page-ac557a986566----75644686b559---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75644686b559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75644686b559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1811.04017", "anchor_text": "A generic framework for privacy preserving deep learning (2018)"}, {"url": "https://arxiv.org/abs/1811.03604", "anchor_text": "Federated Learning for Mobile Keyboard Prediction (2019)"}, {"url": "https://arxiv.org/abs/1902.01046", "anchor_text": "Towards Federated Learning at Scale: System Design (2019)"}, {"url": "https://ai.googleblog.com/2017/04/federated-learning-collaborative.html", "anchor_text": "Federated Learning: Collaborative Machine Learning without Centralized Training Data (2017)"}, {"url": "https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html", "anchor_text": "Learning with Privacy at Scale (2017)"}, {"url": "https://www.youtube.com/watch?v=89BGjQYA0uE", "anchor_text": "Federated Learning: Machine Learning on Decentralized Data (2019)"}, {"url": "https://github.com/OpenMined/PySyft/", "anchor_text": "PySyft"}, {"url": "https://medium.com/tag/privacy?source=post_page-----75644686b559---------------privacy-----------------", "anchor_text": "Privacy"}, {"url": "https://medium.com/tag/federated-learning?source=post_page-----75644686b559---------------federated_learning-----------------", "anchor_text": "Federated Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----75644686b559---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/privacy-preserving?source=post_page-----75644686b559---------------privacy_preserving-----------------", "anchor_text": "Privacy Preserving"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----75644686b559---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F75644686b559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&user=Kapil+Chandorikar&userId=ac557a986566&source=-----75644686b559---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F75644686b559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&user=Kapil+Chandorikar&userId=ac557a986566&source=-----75644686b559---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75644686b559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----75644686b559--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F75644686b559&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----75644686b559---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----75644686b559--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----75644686b559--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----75644686b559--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----75644686b559--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----75644686b559--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----75644686b559--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----75644686b559--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----75644686b559--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kapilchandorikar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kapilchandorikar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kapil Chandorikar"}, {"url": "https://medium.com/@kapilchandorikar/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "14 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fac557a986566&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&user=Kapil+Chandorikar&userId=ac557a986566&source=post_page-ac557a986566--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F864fe6435b91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-federated-learning-and-privacy-preservation-75644686b559&newsletterV3=ac557a986566&newsletterV3Id=864fe6435b91&user=Kapil+Chandorikar&userId=ac557a986566&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}