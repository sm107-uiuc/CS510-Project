{"url": "https://towardsdatascience.com/a-quantum-enhanced-lstm-layer-38a8c135dbfa", "time": 1683017888.062248, "path": "towardsdatascience.com/a-quantum-enhanced-lstm-layer-38a8c135dbfa/", "webpage": {"metadata": {"title": "A Quantum-Enhanced LSTM Layer. Using the PennyLane Quantum Machine\u2026 | by Riccardo Di Sipio | Towards Data Science", "h1": "A Quantum-Enhanced LSTM Layer", "description": "In recent years, Toronto-based startup company Xanadu has introduced a python framework called PennyLane which allows users to create hybrid Quantum Machine Learning (QML) models. While it\u2019s still\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.xanadu.ai/", "anchor_text": "Xanadu", "paragraph_index": 0}, {"url": "https://pennylane.ai/", "anchor_text": "PennyLane", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Quantum_supremacy#:~:text=In%20quantum%20computing%2C%20quantum%20supremacy,the%20usefulness%20of%20the%20problem).", "anchor_text": "advantage", "paragraph_index": 0}, {"url": "https://www.mckinsey.com/industries/pharmaceuticals-and-medical-products/our-insights/recalculating-the-future-of-drug-development-with-quantum-computing", "anchor_text": "drug discovery", "paragraph_index": 0}, {"url": "https://www.ibm.com/thought-leadership/institute-business-value/report/exploring-quantum-financial", "anchor_text": "finance", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Natural_language_processing", "anchor_text": "Natural Language Processing", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "Recurrent Neural Network", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Long_short-term_memory#:~:text=Long%20short%2Dterm%20memory%20(LSTM)%20is%20an%20artificial%20recurrent,the%20field%20of%20deep%20learning.&text=LSTM%20networks%20are%20well%2Dsuited,events%20in%20a%20time%20series.", "anchor_text": "Long Short-Term Memory", "paragraph_index": 1}, {"url": "http://jalammar.github.io/illustrated-transformer/", "anchor_text": "Transformer networks", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/2009.01783", "anchor_text": "arXiv:2009.01783", "paragraph_index": 1}, {"url": "https://arxiv.org/pdf/2006.14619.pdf", "anchor_text": "arXiv:2006.14619", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/toward-a-quantum-transformer-a51566ed42c2", "anchor_text": "Toward a Quantum Transformer", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/classifying-documents-with-quantum-enhanced-transfer-learning-8ee6d04f3ccd", "anchor_text": "Classifying Scientific Documents with Quantum-Enhanced Transfer Learning", "paragraph_index": 1}, {"url": "https://riccardo-disipio.medium.com/spooky-computers-at-cern-c08f8756444", "anchor_text": "Spooky Computers at CERN", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Sentiment_analysis#:~:text=Sentiment%20analysis%20(also%20known%20as,affective%20states%20and%20subjective%20information.", "anchor_text": "sentiment analysis", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Part-of-speech_tagging", "anchor_text": "part-of-speech tag", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Sigmoid_function", "anchor_text": "Sigmoid", "paragraph_index": 4}, {"url": "https://reference.wolfram.com/language/ref/Tanh.html#:~:text=Tanh%20is%20the%20hyperbolic%20tangent,of%20the%20natural%20logarithm%20Log.", "anchor_text": "Hyperbolic Tangent (tanh)", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Mean_squared_error", "anchor_text": "mean squared error", "paragraph_index": 5}, {"url": "https://pennylane.ai/qml/glossary/variational_circuit.html", "anchor_text": "Variational Quantum Circuit", "paragraph_index": 5}, {"url": "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html", "anchor_text": "example from PyTorch", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/softmax-function-simplified-714068bf8156", "anchor_text": "softmax", "paragraph_index": 8}, {"url": "https://pennylane.ai/", "anchor_text": "PennyLane", "paragraph_index": 10}, {"url": "https://www.tensorflow.org/quantum", "anchor_text": "TensorFlow Quantum", "paragraph_index": 10}, {"url": "https://www.youtube.com/playlist?list=PLnfLBUr5sAbDC_3B1GG3u7yjzUIBKf3pa", "anchor_text": "QTML 2020", "paragraph_index": 10}], "all_paragraphs": ["In recent years, Toronto-based startup company Xanadu has introduced a python framework called PennyLane which allows users to create hybrid Quantum Machine Learning (QML) models. While it\u2019s still too early to claim that quantum computing has taken over, there are some areas where it can give an advantage as for example in drug discovery or finance. One field that so far has been poorly explored in QML is Natural Language Processing (NLP), the sub-field of Artificial Intelligence that gives computers the ability to read, write and to some extent comprehend written text.", "As documents are usually presented as sequences of words, historically one of the most successful techniques to manipulate this kind of data has been the Recurrent Neural Network architecture, and in particular a variant called Long Short-Term Memory (LSTM). The \u201ctrick\u201d that makes these networks so popular in the analysis of sequential data is a combination of \u201cmemory\u201d and \u201cstatefulness\u201d that help with identifying which components of the input are relevant to compute the output. While the mathematics is quite thick as we\u2019ll see later on, suffices to say for now that LSTMs allowed machines to perform translations, classification and intent detection with state-of-the-art accuracy until the advent of Transformer networks. Still, it\u2019s interesting at least from an educational point of view to dig into LSTMs to see what good quantum computing may bring to the field. For a more thorough discussion, please refer to \u201cQuantum Long Short-Term Memory\u201d by Chen, Yoo and Fang (arXiv:2009.01783) and \u201cRecurrent Quantum Neural Networks\u201d by J. Bausch (arXiv:2006.14619). On the same subject, see also my other posts Toward a Quantum Transformer, Classifying Scientific Documents with Quantum-Enhanced Transfer Learning and Spooky Computers at CERN.", "To begin with, let\u2019s review the inner workings of a LSTM. We assume that the input x is composed of a sequence of t time-steps (e.g. words), each represented by a N-dimensional feature vector (in practical applications N can be large, e.g. 512). Also, the network stores a hidden array of vectors h and a state vector c that are updated for each element of the input sequence. For example, if we are only interested in a summary of the sequence (e.g. in a sentiment analysis), the last element of the array h will be returned. Instead, if we are interested in a representation of each element (e.g. to assign to each word a part-of-speech tag such as noun, verb, etc\u2026), we want to have access to every element of h.", "The calculation can be summarized in the formulas below:", "where v_t is a concatenation of the input element at step t and the hidden state at step t-1, i.e. v_t = [h_(t-1), x_t]. In the machine learning parlance, borrowed from electric circuit analysis, f_t is called forget gate, i_t is the input gate, C_t is the update gate and o_t is the output gate. The matrices W_f, W_i, W_C and W_o and the bias vectors b_f, b_i, b_C and b_o are the parameters that have be learned during the supervised training and implement the part of the calculation called linear dense layer that we want to replace with the quantum equivalent. As often the case, a non-linearity is introduced by the application of Sigmoid and Hyperbolic Tangent (tanh) functions to the output of these four dense layers, which effect is to determine whether a part of the input has to be considered (values close to 1) or ignored (values close to 0).", "A key concept in Quantum Machine Learning is that information is stored in units of information called qubits that are a so-called superposition of the states 0 and 1. Physically, they may represent for example the orientation of the spin of a particle with respect to the axis of a magnetic field, or the circulation of electric current in a superconductor. For practical purposes, these details can safely be ignored. What\u2019s important is to remember that the calculation is carried by first putting the input qubits into the initial state (e.g. a string such as 010010), then they are entangled between each other, rotated by an arbitrary angles, and finally observed (\u201cmeasured\u201d). The goal of the training is to find the rotation angles mentioned above that optimize some cost function such as the mean squared error (MSE) between the output and some pre-determined labels. This kind of quantum circuit is known as Variational Quantum Circuit. Using the PennyLane library, one can easily define a VQC as a series of AngleEmbedding and StronglyEntanglingLayers objects.", "One problem that may not be obvious at the onset is that while bits are cheap, qubits are expensive: it\u2019s hard to keep real qubits in superposition state, it\u2019s also hard to simulate them. So forget about designing a circuit with 12 qubits. Good news is, thanks to their own nature, fewer qubits are probably needed to perform the calculation. To cut a long story short, what we\u2019ll do here is to introduce a \u201cdressed quantum circuit\u201d, i.e. we sandwich the quantum layer between two classical linear layers to match the dimensionality. For example, if the feature dimension is 8 and the hidden dimension is 6, but we can only afford 4 qubits, what we need is a sequence like this:", "We need one classical layer to \u201csqueeze\u201d the input to match the number of qubits, and one classical layer to \u201cbloat\u201d the output of f_t, i_t, C_t and o_t. to match the dimension of the hidden vectors. Thus, overall we still have a number of classical parameters that have to be learned during the training. Putting all together, the core of the calculation looks like this:", "Does it work? To test if all the above makes sense, an intuitive but not trivial example is needed. In this case, I decided to adapt the part-of-speech (POS) tagging example from PyTorch to the case under consideration. The idea is pretty simple: we have a set of two sentences (\u201cThe dog ate the apple\u201d and \u201cEverybody read that book\u201d) whose words have been annotated with POS tags. For example, the first sentence is thus [\u201cDET\u201d, \u201cNN\u201d, \u201cV\u201d, \u201cDET\u201d, \u201cNN\u201d]. The idea is to pass the two sequences through the LSTM, which will output the hidden array of vectors [h_0, h_1, h_2, h_3, h_4], one for each word. A dense layer \u201chead\u201d is attached to the LSTM\u2019s outputs to calculate the probability that each word may be a determinant, noun or verb (for the curious, that is a softmax layer with dimension 3).", "Following the example from the PyTorch website, we train the two networks (classical and quantum LSTM) for 300 epochs. This is just a toy example and has to be taken as such, but still, the results are encouraging. The loss function decreases as a function of the training epoch, and after 300 epochs both networks are able to tag correctly the first sentence. Due to the complexity of the simulation of the quantum circuit, it took approximatively 15 minutes to finish the training, to be compared to a mere 8 seconds for the classical case. Also, looking at the plots, it seems that the quantum LSTM needed to be trained for longer, but that\u2019s enough for our purpose.", "To conclude, libraries such as PennyLane or TensorFlow Quantum offer a high-level of abstraction to define quantum/digital hybrid models for Quantum Machine Learning. This is a field that is rapidly expanding and more and more applications are being explored as one can happily see by attending topical conferences such as QTML 2020.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "NLP Machine Learning engineer at Ceridian. Formerly physicist at U Toronto, Bologna, CERN LHC/ATLAS."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F38a8c135dbfa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://riccardo-disipio.medium.com/?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": ""}, {"url": "https://riccardo-disipio.medium.com/?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "Riccardo Di Sipio"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4267d9884285&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&user=Riccardo+Di+Sipio&userId=4267d9884285&source=post_page-4267d9884285----38a8c135dbfa---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F38a8c135dbfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F38a8c135dbfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.xanadu.ai/", "anchor_text": "Xanadu"}, {"url": "https://pennylane.ai/", "anchor_text": "PennyLane"}, {"url": "https://en.wikipedia.org/wiki/Quantum_supremacy#:~:text=In%20quantum%20computing%2C%20quantum%20supremacy,the%20usefulness%20of%20the%20problem).", "anchor_text": "advantage"}, {"url": "https://www.mckinsey.com/industries/pharmaceuticals-and-medical-products/our-insights/recalculating-the-future-of-drug-development-with-quantum-computing", "anchor_text": "drug discovery"}, {"url": "https://www.ibm.com/thought-leadership/institute-business-value/report/exploring-quantum-financial", "anchor_text": "finance"}, {"url": "https://en.wikipedia.org/wiki/Natural_language_processing", "anchor_text": "Natural Language Processing"}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "Recurrent Neural Network"}, {"url": "https://en.wikipedia.org/wiki/Long_short-term_memory#:~:text=Long%20short%2Dterm%20memory%20(LSTM)%20is%20an%20artificial%20recurrent,the%20field%20of%20deep%20learning.&text=LSTM%20networks%20are%20well%2Dsuited,events%20in%20a%20time%20series.", "anchor_text": "Long Short-Term Memory"}, {"url": "http://jalammar.github.io/illustrated-transformer/", "anchor_text": "Transformer networks"}, {"url": "https://arxiv.org/abs/2009.01783", "anchor_text": "arXiv:2009.01783"}, {"url": "https://arxiv.org/pdf/2006.14619.pdf", "anchor_text": "arXiv:2006.14619"}, {"url": "https://towardsdatascience.com/toward-a-quantum-transformer-a51566ed42c2", "anchor_text": "Toward a Quantum Transformer"}, {"url": "https://towardsdatascience.com/classifying-documents-with-quantum-enhanced-transfer-learning-8ee6d04f3ccd", "anchor_text": "Classifying Scientific Documents with Quantum-Enhanced Transfer Learning"}, {"url": "https://riccardo-disipio.medium.com/spooky-computers-at-cern-c08f8756444", "anchor_text": "Spooky Computers at CERN"}, {"url": "https://en.wikipedia.org/wiki/Sentiment_analysis#:~:text=Sentiment%20analysis%20(also%20known%20as,affective%20states%20and%20subjective%20information.", "anchor_text": "sentiment analysis"}, {"url": "https://en.wikipedia.org/wiki/Part-of-speech_tagging", "anchor_text": "part-of-speech tag"}, {"url": "https://en.wikipedia.org/wiki/Long_short-term_memory", "anchor_text": "Wikipedia"}, {"url": "https://arxiv.org/abs/2009.01783", "anchor_text": "arXiv:2009.01783"}, {"url": "https://en.wikipedia.org/wiki/Sigmoid_function", "anchor_text": "Sigmoid"}, {"url": "https://reference.wolfram.com/language/ref/Tanh.html#:~:text=Tanh%20is%20the%20hyperbolic%20tangent,of%20the%20natural%20logarithm%20Log.", "anchor_text": "Hyperbolic Tangent (tanh)"}, {"url": "https://en.wikipedia.org/wiki/Mean_squared_error", "anchor_text": "mean squared error"}, {"url": "https://pennylane.ai/qml/glossary/variational_circuit.html", "anchor_text": "Variational Quantum Circuit"}, {"url": "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html", "anchor_text": "example from PyTorch"}, {"url": "https://towardsdatascience.com/softmax-function-simplified-714068bf8156", "anchor_text": "softmax"}, {"url": "https://pennylane.ai/", "anchor_text": "PennyLane"}, {"url": "https://www.tensorflow.org/quantum", "anchor_text": "TensorFlow Quantum"}, {"url": "https://www.youtube.com/playlist?list=PLnfLBUr5sAbDC_3B1GG3u7yjzUIBKf3pa", "anchor_text": "QTML 2020"}, {"url": "https://github.com/rdisipio/qlstm", "anchor_text": "https://github.com/rdisipio/qlstm"}, {"url": "https://medium.com/tag/quantum-machine-learning?source=post_page-----38a8c135dbfa---------------quantum_machine_learning-----------------", "anchor_text": "Quantum Machine Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----38a8c135dbfa---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----38a8c135dbfa---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/language-processing?source=post_page-----38a8c135dbfa---------------language_processing-----------------", "anchor_text": "Language Processing"}, {"url": "https://medium.com/tag/recurrent-neural-network?source=post_page-----38a8c135dbfa---------------recurrent_neural_network-----------------", "anchor_text": "Recurrent Neural Network"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F38a8c135dbfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&user=Riccardo+Di+Sipio&userId=4267d9884285&source=-----38a8c135dbfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F38a8c135dbfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&user=Riccardo+Di+Sipio&userId=4267d9884285&source=-----38a8c135dbfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F38a8c135dbfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F38a8c135dbfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----38a8c135dbfa---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----38a8c135dbfa--------------------------------", "anchor_text": ""}, {"url": "https://riccardo-disipio.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://riccardo-disipio.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Riccardo Di Sipio"}, {"url": "https://riccardo-disipio.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "554 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4267d9884285&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&user=Riccardo+Di+Sipio&userId=4267d9884285&source=post_page-4267d9884285--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb32833879b5a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quantum-enhanced-lstm-layer-38a8c135dbfa&newsletterV3=4267d9884285&newsletterV3Id=b32833879b5a&user=Riccardo+Di+Sipio&userId=4267d9884285&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}