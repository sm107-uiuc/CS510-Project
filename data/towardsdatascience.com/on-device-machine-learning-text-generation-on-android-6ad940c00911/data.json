{"url": "https://towardsdatascience.com/on-device-machine-learning-text-generation-on-android-6ad940c00911", "time": 1683002213.546402, "path": "towardsdatascience.com/on-device-machine-learning-text-generation-on-android-6ad940c00911/", "webpage": {"metadata": {"title": "On-Device Machine Learning: Text Generation on Android \ud83d\udcdd | by Pierric Cistac | Towards Data Science", "h1": "On-Device Machine Learning: Text Generation on Android \ud83d\udcdd", "description": "At Hugging Face, our goal is to solve and democratize Natural Language Processing (NLP). Currently, most of the models in production are running remotely on servers \u2014 for example at Google for\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.blog.google/products/search/search-language-understanding-bert", "anchor_text": "for example at Google for search", "paragraph_index": 0}, {"url": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2", "anchor_text": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2", "paragraph_index": 1}, {"url": "https://openai.com/blog/better-language-models/", "anchor_text": "GPT-2", "paragraph_index": 2}, {"url": "https://transformer.huggingface.co/doc/gpt2-large", "anchor_text": "this funny (scary?) tool", "paragraph_index": 2}, {"url": "https://www.tensorflow.org/lite", "anchor_text": "TensorFlow Lite", "paragraph_index": 3}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "\ud83e\udd17 Transformers", "paragraph_index": 4}, {"url": "https://medium.com/tensorflow/tensorflow-model-optimization-toolkit-float16-quantization-halves-model-size-cc113c75a2fa", "anchor_text": "quantize the weights (parameters) of the model", "paragraph_index": 4}, {"url": "https://www.tensorflow.org/lite/performance/post_training_quantization#weight_quantization", "anchor_text": "8-bit integer representations", "paragraph_index": 5}, {"url": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2#change-the-model", "anchor_text": "changing the default model", "paragraph_index": 5}, {"url": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2", "anchor_text": "The entire source code is available on GitHub", "paragraph_index": 6}, {"url": "https://github.com/huggingface/tflite-android-transformers/blob/master/gpt2/src/main/java/co/huggingface/android_transformers/gpt2/tokenization/GPT2ByteEncoderDecoder.kt#L3", "anchor_text": "a specific representation", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Byte_pair_encoding", "anchor_text": "Byte-Pair Encoding", "paragraph_index": 11}, {"url": "https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json", "anchor_text": "model vocabulary", "paragraph_index": 11}, {"url": "https://huggingface.co/transformers/model_doc/gpt2.html#tfgpt2lmheadmodel", "anchor_text": "many outputs", "paragraph_index": 17}, {"url": "https://www.wikiwand.com/en/Softmax_function", "anchor_text": "Softmax function", "paragraph_index": 21}, {"url": "https://kotlinlang.org/docs/reference/coroutines-overview.html", "anchor_text": "coroutines", "paragraph_index": 23}, {"url": "https://developer.android.com/topic/libraries/architecture/viewmodel", "anchor_text": "ViewModel", "paragraph_index": 23}, {"url": "https://developer.android.com/topic/libraries/architecture/coroutines", "anchor_text": "viewModelScope.launch", "paragraph_index": 24}, {"url": "https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-coroutine-dispatcher/index.html", "anchor_text": "see here for more details", "paragraph_index": 25}, {"url": "https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/yield.html", "anchor_text": "yield()", "paragraph_index": 30}, {"url": "https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/is-active.html", "anchor_text": "isActive property", "paragraph_index": 31}, {"url": "https://developer.android.com/topic/libraries/architecture/livedata", "anchor_text": "LiveData structure", "paragraph_index": 32}, {"url": "https://github.com/huggingface/tflite-android-transformers", "anchor_text": "the entire repository", "paragraph_index": 34}, {"url": "https://github.com/huggingface/swift-coreml-transformers", "anchor_text": "a repo with models and apps for iOS", "paragraph_index": 34}, {"url": "https://developer.apple.com/documentation/coreml", "anchor_text": "CoreML", "paragraph_index": 34}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "\ud83e\udd17 Transformers", "paragraph_index": 34}], "all_paragraphs": ["At Hugging Face, our goal is to solve and democratize Natural Language Processing (NLP). Currently, most of the models in production are running remotely on servers \u2014 for example at Google for search. Still, the improvement of hardware on mobile devices and the increasing focus on privacy make them more and more suitable to run offline.", "The goal of this article is to give a high-level view of the development of an Android application for text generation running entirely on-device. The code is available here: https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2", "GPT-2 is a model released in 2019 whose Natural Language Generation capabilities (NLG, a subset of NLP) were so impressive that the release of the biggest version was delayed for months. You can play with it using this funny (scary?) tool we released. In this app, we are going to use the smallest version of the model. Its generation capabilities are less impressive than the biggest one, but its size (500MB vs. 6GB) makes it way more suitable for mobile use!", "Before being able to run it on-device, we need to convert it to a suitable format, TensorFlow Lite (TFLite). To do so, we can run this Python script:", "This script makes use of our \ud83e\udd17 Transformers library to import the \u201craw\u201d model and then converts it to TFLite format. Note lines 15/16 of the script: Before running the conversion, we are using TFLite to specify that we want to quantize the weights (parameters) of the model to half-precision floating-point format. This results in a final size for our converted model of 237MB, i.e. half of the size of the original \u201cinput\u201d model \ud83c\udf89. The downside? A very minimal loss in accuracy, but it\u2019s definitely worth it on mobile given the saved space in storage!", "We could go even further in the compression of our model by doing a conversion of the weights to 8-bit integer representations, with a resulting size of only 128MB. But our tests with this version showed to be much slower on devices; thus we prefer here using the half-precision floating-point version. You can still experiment with the 8-bits version with our app by changing the default model.", "Now that we have converted our model, we can focus on actually building our app. The entire source code is available on GitHub, so here I\u2019m only going to focus on the most interesting parts.", "In the Python script, we specified (lines 6/7) that our model is going to take as input a bidimensional array of integers of shape [1, 64], i.e. something like this, where the inner array contains 64 elements:", "But what we\u2019re going to have in real life is a string, corresponding to the current text. We thus need to convert that string into integers, a.k.a. tokens. Roughly, we can say that a token is a numeral representation of a part of our string.", "Tokens are also what is returned by the model as output. Each run of the model allows us to determine the next token of our text, that we then pass with the previous text to our model for its next run, and so on\u2026", "We need something to convert our string to tokens, and tokens back to a string. That\u2019s the role of the Tokenizer. The two main functions of a Tokenizer are usually encode and decode.", "The encode function takes our starting/previous text as parameter, parses it using a regex, and then converts every character to a specific representation. It finally applies a Byte-Pair Encoding (BPE) algorithm whose output is mapped to integers thanks to the model vocabulary. \ud83e\udd2f", "The decode function does the reverse, mapping tokens to their vocabulary representation, and then decoding this representation to our final string.", "Now that we know how to encode and decode our text, we can call our model! This is the role of the following generate function:", "The function\u2019s inputs are the initial text and the number of tokens we want to generate (i.e., the number of times our model is called). The first step is to tokenize our text.", "Remember we said the input of the model was an array of shape [1, 64]? We need to strip our previous text tokens to keep only the last 64 ones maximum. That\u2019s our inputIds. It means that the generation of the next token only depends on those 64 previous tokens, ignoring any previous ones.", "We could specify a higher sequence length when we convert our model, but it would imply more computation at inference, slowing down our app. It\u2019s a trade-off between speed and \u201cquality\u201d of our generation. \ud83e\udd14", "We also need to create the data structures that our model will feed with its output. Our model has many outputs, but we\u2019re only interested in the first one, the \u201cpredictions\u201d.", "We\u2019re reaching here a limit in terms of expressiveness of Kotlin when it comes to multidimensional arrays; here is what it would be in Java:", "I\u2019m far from being a Java fanboy, but the right side of the expression seems easier to read to me!", "We can then \u2014 finally! \u2014 run our model by calling the TFLite interpreter:", "Once our \u201cpredictions\u201d array is filled by the interpreter, we need to determine the token that will be our \u201cnext\u201d one. There are many different ways of doing so; here we\u2019re first using Top-K filtering, selecting the k higher predictions. We\u2019re then applying a Softmax function to get a probability distribution of those values before finally selecting \u201cthe one\u201d through multinomial sampling.", "It\u2019s now time to link our model to the interface of our application! Running a model such as GPT-2 on device, even a quantized version, requires computing resources. If we do it wrong, we might end up with a UI freezing while the model is running, which is not very user-friendly! \ud83d\ude31", "To avoid such a bad result, we\u2019re going to make use of coroutines, a really nice way of doing non-blocking programming in Kotlin. Here is our (nearly) complete GPT2Client class, which is a ViewModel loaded from our main activity:", "The class first needs to load all the assets for our model and to initialize the TFLite interpreter. To do that without blocking the UI, in the init block we\u2019re launching a new coroutine thanks to viewModelScope.launch. Inside this coroutine, we\u2019re loading our model assets by calling 3 \u201cload\u201d methods. Here is the signature for loadModel:", "What\u2019s important here is the withContext(Dispatchers.IO) part. We\u2019re saying that we want to execute this method on a different thread than the main one, here using one designed for I/O operations (see here for more details).", "The \u201cbeauty\u201d of creating a coroutine through viewModelScope.launch is that it ties its lifetime to the one of the ViewModel. It ensures that when the ViewModel is cleared, the coroutine is canceled! \ud83d\ude4c", "Then, when the user clicks the \u201cTrigger autocomplete\u201d button in the app, the launchAutocomplete method is executed, creating another coroutine from which we\u2019re going to call our model.", "Inside this coroutine, we first make sure the initialization of the assets (initJob) is complete, then do the same for the potential previous model run (autocompleteJob), that we cancel if still running. We can then call our generate method:", "The dispatcher used for this method is not Dispatchers.IO since we\u2019re not doing any I/O operation here, but a more generic Dispatchers.Default which uses a common pool of shared background threads.", "Another interesting part of this method is the yield() method call at the end of the repeat block. This is what allows the method to check for an eventual cancellation. Without that, no cancellation would be possible, and we would have to wait until the end of the entire generation before being able to free the resources! \u2620\ufe0f Here we\u2019re checking for cancellation after each token generation.", "Another way of checking for cancellation would be to check the value of the isActive property", "The completed text is then displayed in the app \u201cautomagically\u201d thanks to the use of the LiveData structure (our completion property). \ud83e\uddd9\u200d\u2640\ufe0f", "That\u2019s it! At Hugging Face we believe that we\u2019re only at the beginning of the era of AI running on-device. With the continuous development of dedicated hardware and associated drivers and frameworks on one side and techniques like quantization and distillation on the other side, the capabilities of our smartphones promise to have a bright future, allowing the run of more complex models in a more efficient and performant way.", "You can check the entire repository if you want more Android examples. We also released a repo with models and apps for iOS making use of the Apple-specific CoreML framework. And if you\u2019re interested in more in-depth state-of-the-art NLP, our \ud83e\udd17 Transformers library is here!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer @huggingface \ud83e\udd17. Twitter @pierrci"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6ad940c00911&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6ad940c00911--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6ad940c00911--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@pierric?source=post_page-----6ad940c00911--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pierric?source=post_page-----6ad940c00911--------------------------------", "anchor_text": "Pierric Cistac"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa78169e66dc7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&user=Pierric+Cistac&userId=a78169e66dc7&source=post_page-a78169e66dc7----6ad940c00911---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6ad940c00911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6ad940c00911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@sebastian123?utm_source=medium&utm_medium=referral", "anchor_text": "Pereanu Sebastian"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.blog.google/products/search/search-language-understanding-bert", "anchor_text": "for example at Google for search"}, {"url": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2", "anchor_text": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2"}, {"url": "https://openai.com/blog/better-language-models/", "anchor_text": "GPT-2"}, {"url": "https://transformer.huggingface.co/doc/gpt2-large", "anchor_text": "this funny (scary?) tool"}, {"url": "https://www.tensorflow.org/lite", "anchor_text": "TensorFlow Lite"}, {"url": "https://pypi.org/project/tf-nightly/", "anchor_text": "tf-nightly"}, {"url": "https://pypi.org/project/transformers/", "anchor_text": "transformers"}, {"url": "https://colab.research.google.com/drive/18JPzizAH995pd0iFWx4Xdf-sqjmZwHUD", "anchor_text": "this colab notebook"}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "\ud83e\udd17 Transformers"}, {"url": "https://medium.com/tensorflow/tensorflow-model-optimization-toolkit-float16-quantization-halves-model-size-cc113c75a2fa", "anchor_text": "quantize the weights (parameters) of the model"}, {"url": "https://www.tensorflow.org/lite/performance/post_training_quantization#weight_quantization", "anchor_text": "8-bit integer representations"}, {"url": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2#change-the-model", "anchor_text": "changing the default model"}, {"url": "https://github.com/huggingface/tflite-android-transformers/tree/master/gpt2", "anchor_text": "The entire source code is available on GitHub"}, {"url": "https://github.com/huggingface/tflite-android-transformers/blob/master/gpt2/src/main/java/co/huggingface/android_transformers/gpt2/tokenization/GPT2Tokenizer.kt", "anchor_text": "here"}, {"url": "https://github.com/huggingface/tflite-android-transformers/blob/master/gpt2/src/main/java/co/huggingface/android_transformers/gpt2/tokenization/GPT2ByteEncoderDecoder.kt#L3", "anchor_text": "a specific representation"}, {"url": "https://en.wikipedia.org/wiki/Byte_pair_encoding", "anchor_text": "Byte-Pair Encoding"}, {"url": "https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json", "anchor_text": "model vocabulary"}, {"url": "https://github.com/huggingface/tflite-android-transformers/blob/master/gpt2/src/main/java/co/huggingface/android_transformers/gpt2/ml/GPT2Client.kt", "anchor_text": "Click here"}, {"url": "https://huggingface.co/transformers/model_doc/gpt2.html#tfgpt2lmheadmodel", "anchor_text": "many outputs"}, {"url": "https://www.wikiwand.com/en/Softmax_function", "anchor_text": "Softmax function"}, {"url": "https://kotlinlang.org/docs/reference/coroutines-overview.html", "anchor_text": "coroutines"}, {"url": "https://developer.android.com/topic/libraries/architecture/viewmodel", "anchor_text": "ViewModel"}, {"url": "https://github.com/huggingface/tflite-android-transformers/blob/master/gpt2/src/main/java/co/huggingface/android_transformers/gpt2/ml/GPT2Client.kt", "anchor_text": "check here"}, {"url": "https://developer.android.com/topic/libraries/architecture/coroutines", "anchor_text": "viewModelScope.launch"}, {"url": "https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-coroutine-dispatcher/index.html", "anchor_text": "see here for more details"}, {"url": "https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/yield.html", "anchor_text": "yield()"}, {"url": "https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/is-active.html", "anchor_text": "isActive property"}, {"url": "https://developer.android.com/topic/libraries/architecture/livedata", "anchor_text": "LiveData structure"}, {"url": "https://github.com/huggingface/tflite-android-transformers", "anchor_text": "the entire repository"}, {"url": "https://github.com/huggingface/swift-coreml-transformers", "anchor_text": "a repo with models and apps for iOS"}, {"url": "https://developer.apple.com/documentation/coreml", "anchor_text": "CoreML"}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "\ud83e\udd17 Transformers"}, {"url": "https://medium.com/tag/kotlin?source=post_page-----6ad940c00911---------------kotlin-----------------", "anchor_text": "Kotlin"}, {"url": "https://medium.com/tag/android?source=post_page-----6ad940c00911---------------android-----------------", "anchor_text": "Android"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----6ad940c00911---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/nlp?source=post_page-----6ad940c00911---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "http://creativecommons.org/licenses/by/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6ad940c00911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&user=Pierric+Cistac&userId=a78169e66dc7&source=-----6ad940c00911---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6ad940c00911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&user=Pierric+Cistac&userId=a78169e66dc7&source=-----6ad940c00911---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6ad940c00911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6ad940c00911--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6ad940c00911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6ad940c00911---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6ad940c00911--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6ad940c00911--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6ad940c00911--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6ad940c00911--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6ad940c00911--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6ad940c00911--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6ad940c00911--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6ad940c00911--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pierric?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pierric?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Pierric Cistac"}, {"url": "https://medium.com/@pierric/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "27 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa78169e66dc7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&user=Pierric+Cistac&userId=a78169e66dc7&source=post_page-a78169e66dc7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fa78169e66dc7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-device-machine-learning-text-generation-on-android-6ad940c00911&user=Pierric+Cistac&userId=a78169e66dc7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}