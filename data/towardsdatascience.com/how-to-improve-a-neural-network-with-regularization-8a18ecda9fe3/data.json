{"url": "https://towardsdatascience.com/how-to-improve-a-neural-network-with-regularization-8a18ecda9fe3", "time": 1682995366.944212, "path": "towardsdatascience.com/how-to-improve-a-neural-network-with-regularization-8a18ecda9fe3/", "webpage": {"metadata": {"title": "How to Improve a Neural Network With Regularization | by Marco Peixeiro | Towards Data Science", "h1": "How to Improve a Neural Network With Regularization", "description": "You just built your neural network and notice that it performs incredibly well on the training set, but not nearly as good on the test set. This is a sign of overfitting. Your neural network has a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber", "anchor_text": "YouTube channel", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/step-by-step-guide-to-building-your-own-neural-network-from-scratch-df64b1c5ab6e", "anchor_text": "cross-entropy loss function", "paragraph_index": 7}, {"url": "https://github.com/marcopeix/Deep_Learning_AI/blob/master/2.Improving%20Deep%20Neural%20Networks/1.Practical%20Aspects%20of%20Deep%20Learning/Regularization.ipynb", "anchor_text": "here", "paragraph_index": 23}, {"url": "https://github.com/marcopeix/Deep_Learning_AI/blob/master/2.Improving%20Deep%20Neural%20Networks/1.Practical%20Aspects%20of%20Deep%20Learning/Regularization.ipynb", "anchor_text": "libraries,", "paragraph_index": 24}], "all_paragraphs": ["You just built your neural network and notice that it performs incredibly well on the training set, but not nearly as good on the test set.", "This is a sign of overfitting. Your neural network has a very high variance and it cannot generalize well to data it has not been trained on.", "There are two common ways to address overfitting:", "Getting more data is sometimes impossible, and other times very expensive. Therefore, regularization is a common method to reduce overfitting and consequently improve the model\u2019s performance.", "In this post, L2 regularization and dropout will be introduced as regularization methods for neural networks. Then, we will code each method and see how it impacts the performance of a network!", "For hands-on video tutorials on machine learning, deep learning, and artificial intelligence, checkout my YouTube channel.", "Recall that in deep learning, we wish to minimize the following cost function:", "Where L can be any loss function (such as the cross-entropy loss function). Now, for L2 regularization we add a component that will penalize large weights.", "Where lambda is the regularization parameter. Notice the addition of the Frobenius norm, denoted by the subscript F. This is in fact equivalent to the squared norm of a matrix.", "Now, lambda is a parameter than can be tuned. Larger weight values will be more penalized if the value of lambda is large. Similarly, for a smaller value of lambda, the regularization effect is smaller.", "This makes sense, because the cost function must be minimized. By adding the squared norm of the weight matrix and multiplying it by the regularization parameters, large weights will be driven down in order to minimize the cost function.", "As aforementioned, adding the regularization component will drive the values of the weight matrix down. This will effectively decorrelate the neural network.", "Recall that we feed the activation function with the following weighted sum:", "By reducing the values in the weight matrix, z will also be reduced, which in turns decreases the effect of the activation function. Therefore, a less complex function will be fit to the data, effectively reducing overfitting.", "Dropout involves going over all the layers in a neural network and setting probability of keeping a certain nodes or not.", "Of course, the input layer and the output layer are kept the same.", "The probability of keeping each node is set at random. You only decide of the threshold: a value that will determine if the node is kept or not.", "For example, if you set the threshold to 0.7, then there is a probability of 30% that a node will be removed from the network.", "Therefore, this will result in a much smaller and simpler neural network, as shown below.", "It might seem to crazy to randomly remove nodes from a neural network to regularize it. Yet, it is a widely used method and it was proven to greatly improve the performance of neural networks. So, why does it work so well?", "Dropout means that the neural network cannot rely on any input node, since each have a random probability of being removed. Therefore, the neural network will be reluctant to give high weights to certain features, because they might disappear.", "Consequently, the weights are spread across all features, making them smaller. This effectively shrinks the model and regularizes it.", "Now, let\u2019s implement dropout and L2 regularization on some sample data to see how it impacts the performance of a neural network.", "Refer to the full notebook here.", "We start off by creating a sample dataset. After import the necessary libraries, we run the following piece of code:", "Great! This is a simple random dataset with two classes, and we will now attempt to write a neural network that will classify each data and generate a decision boundary.", "Now, we define a model template to accommodate regularization:", "Take the time to read the code and understand what it does. Notice the lambd variable that will be useful for L2 regularization. Also, the keep_prob variable will be used for dropout.", "Now, let\u2019s run a neural network without regularization that will act as a baseline performance.", "Not bad! Let\u2019s plot the decision boundary:", "In the plot above, you notice that the model is overfitting some parts of the data. We will use this as a baseline to see how regularization can improve the model\u2019s performance.", "Before using L2 regularization, we need to define a function to compute the cost that will accommodate regularization:", "Finally, we define backpropagation with regularization:", "Great! Now, we can use our model template with L2 regularization! Setting a lambda value of 0.7, we get:", "Awesome! We improved the test accuracy and you notice that the model is not overfitting the data anymore!", "Now, let\u2019s see if dropout can do even better.", "First, we need to redefine forward propagation, because we need to randomly cancel the effect of certain nodes:", "Of course, we must now define backpropagation for dropout:", "Great! Let\u2019s see how the model performs with dropout using a threshold of 0.8:", "Amazing! We achieved an even better accuracy with dropout!", "Good job! You learned how regularization can improve a neural network, and you implemented L2 regularization and dropout to improve a classification model!", "In a future post, I will show how to further improve a neural network by choosing the right optimization algorithm.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior data scientist | Author | Instructor. I write hands-on articles with a focus on practical skills."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8a18ecda9fe3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@marcopeixeiro?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "Marco Peixeiro"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd----8a18ecda9fe3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a18ecda9fe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a18ecda9fe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jruscello?utm_source=medium&utm_medium=referral", "anchor_text": "Jessica Ruscello"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber", "anchor_text": "YouTube channel"}, {"url": "https://towardsdatascience.com/step-by-step-guide-to-building-your-own-neural-network-from-scratch-df64b1c5ab6e", "anchor_text": "cross-entropy loss function"}, {"url": "https://github.com/marcopeix/Deep_Learning_AI/blob/master/2.Improving%20Deep%20Neural%20Networks/1.Practical%20Aspects%20of%20Deep%20Learning/Regularization.ipynb", "anchor_text": "here"}, {"url": "https://github.com/marcopeix/Deep_Learning_AI/blob/master/2.Improving%20Deep%20Neural%20Networks/1.Practical%20Aspects%20of%20Deep%20Learning/Regularization.ipynb", "anchor_text": "libraries,"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8a18ecda9fe3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8a18ecda9fe3---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----8a18ecda9fe3---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----8a18ecda9fe3---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/python?source=post_page-----8a18ecda9fe3---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8a18ecda9fe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----8a18ecda9fe3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8a18ecda9fe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----8a18ecda9fe3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a18ecda9fe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8a18ecda9fe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8a18ecda9fe3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8a18ecda9fe3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marco Peixeiro"}, {"url": "https://medium.com/@marcopeixeiro/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.6K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9835bccb3d51&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-improve-a-neural-network-with-regularization-8a18ecda9fe3&newsletterV3=741c1c8fcfbd&newsletterV3Id=9835bccb3d51&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.manning.com/books/time-series-forecasting-in-python-book", "anchor_text": "Time Series Forecasting in Python2022"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}