{"url": "https://towardsdatascience.com/lets-build-a-streaming-data-pipeline-e873d671fc57", "time": 1682996101.183406, "path": "towardsdatascience.com/lets-build-a-streaming-data-pipeline-e873d671fc57/", "webpage": {"metadata": {"title": "Let\u2019s Build a Streaming Data Pipeline | by Daniel Foley | Towards Data Science", "h1": "Let\u2019s Build a Streaming Data Pipeline", "description": "Today's post is based on a project I recently did in work. I was really excited to implement it and to write it up as a blog post as it gave me a chance to do some data engineering and also do\u2026"}, "outgoing_paragraph_urls": [{"url": "https://click.linksynergy.com/link?id=z2stMJEP3T4&offerid=759505.10508402250&type=2&murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fgcp-data-machine-learning", "anchor_text": "GCP Data Engineering specialization on Coursera", "paragraph_index": 1}, {"url": "https://cloud.google.com/terms/services", "anchor_text": "here", "paragraph_index": 5}, {"url": "https://faker.readthedocs.io/en/latest/index.html", "anchor_text": "documentation", "paragraph_index": 8}, {"url": "https://cloud.google.com/dataflow/docs/quickstarts/quickstart-python", "anchor_text": "page", "paragraph_index": 12}, {"url": "https://cloud.google.com/storage/docs/uploading-objects", "anchor_text": "here", "paragraph_index": 13}, {"url": "https://cloud.google.com/bigquery/docs/tables", "anchor_text": "link", "paragraph_index": 15}, {"url": "https://www.machinelearningplus.com/python/python-regex-tutorial-examples/", "anchor_text": "tutorial", "paragraph_index": 20}, {"url": "http://Data Engineering, Big Data, and Machine Learning on GCP", "anchor_text": "Data Engineering, Big Data, and Machine Learning on GCP", "paragraph_index": 27}], "all_paragraphs": ["Today's post is based on a project I recently did in work. I was really excited to implement it and to write it up as a blog post as it gave me a chance to do some data engineering and also do something that was quite valuable for my team. Not too long ago, I discovered that we had a relatively large amount of user log data relating to one of our data products stored on our systems. As it turns out nobody was really using this data so I immediately became interested in what we could learn if we started to regularly analyze it. There was a couple of problems, however. The first issue was that the data was stored in many different text files which were not immediately accessible for analysis. The second issue was that it was stored in a locked down system so I couldn't use any of my favorite tools to analyze the data.", "I considered how I could make this easier to access for us and really create some value by building this data source into some of our user engagement work. After thinking about this for a while I decided I would build a pipeline to feed this data into a cloud database so that I and the wider team could access it and start generating some insights. After having recently completed the GCP Data Engineering specialization on Coursera I was keen to start a project using some of the tools in the course.", "Right so putting the data into a cloud database seems like a reasonable way to deal with my first problem but what could I do about problem number 2? Well luckily, there was a way to transfer this data to an environment where I could access tools like Python and Google Cloud Platform (GCP). This was, however going to be a long process so I needed to do something that would allow me to develop while I waited for the data transfer. The solution I arrived at was to create some fake data using the Faker library in Python. I had never used the library before but quickly realized how useful it was. Taking this approach allowed me to start writing code and testing the pipeline without having the actual data.", "With that said, In this post, I will walk through how I built the pipeline described above using some of the technologies available on GCP. In particular, I will be using Apache Beam (python version), Dataflow, Pub/Sub, and Big Query to collect user logs, transform the data and feed it into a database for further analysis. For my use case, I only needed the batch functionality of beam since my data was not coming in real-time so Pub/Sub was not required. I will, however, focus on the streaming version since this is what you might commonly come across in practice.", "Google Cloud Platform provides a bunch of really useful tools for big data processing. Some of the tools I will be using include:", "There is a wide variety of tools available on GCP so it can be difficult to keep track of them all and what their purpose is but here is a summary of them for reference.", "Let\u2019s visualize the components of our pipeline using figure 1. At a high level, what we want to do is collect the user-generated data in real time, process it and feed it into BigQuery. The logs are generated when users interact with the product sending requests to the server which is then logged. This data can be particularly useful in understanding how users engage with our product and whether things are working correctly. In general, the pipeline will have the following steps:", "Beam makes this process very easy to do whether we have a streaming data source or if we have a CSV file and want to do a batch job. You will see later that there are only minimal changes to the code required to switch between the two. This is one of the advantages of using Beam.", "As I mentioned before, due to limited access to the data I decided to create fake data that was the same format as the actual data. This was a really useful exercise as I could develop the code and test the pipeline while I waited for the data. I suggest taking a look at the Faker documentation if you want to see what else the library has to offer. Our user data will in general look similar to the example below. Based on this format we can generate data line by line to simulate real-time data. These logs give us information such as the date, the type of request, the response from the server, the IP address, etc.", "Based on the line above we want to create our LINE variable using the 7 variables in the curly brackets below. We will also use these as variable names in our table schema a little later as well.", "If we were doing a batch job the code would be quite similar although we would need to create a bunch of samples over some time range. To use faker we just create an object and call the methods we need. In particular, faker was useful for generating IP addresses as well as websites. I used the following methods:", "Note: To run the pipeline and publish the user log data I used the google cloud shell as I was having problems running the pipeline using Python 3. Google cloud shell uses Python 2 which plays a bit nicer with Apache Beam.", "To be able to run the pipeline we need to do a bit of setup. For those of you who haven't used GCP before you will need to go through the 6 steps outlined on this page.", "After this, we will need to upload our scripts to Google cloud storage and copy them to over to our Google cloud shell. Uploading to cloud storage is pretty straightforward and explained here. To copy our files, we can open up the Google Cloud shell in the toolbar by clicking the first icon on the left in Figure 2 below.", "The commands we need to copy over the files and install the necessary libraries are listed below.", "After we have completed the set-up steps, the next thing we need to do is create a dataset and a table in BigQuery. There are a few different ways to do this but the easiest is to just use the google cloud console and first create a dataset. You can follow the steps in the following link to create a table and a schema. Our table will have 7 columns corresponding to the components of each user log. For ease, we will define all columns as strings apart from the timelocal variable and name them according to the variables we generated previously. Our table schema should look like figure 3.", "Pub/Sub is a vital component of our pipeline as it allows multiple independent applications to interact with each other. In particular, it acts as a middle man allowing us to send and receive messages between applications. The first thing we need to do is create a topic. This is pretty simple to do by going to Pub/Sub in the console and clicking CREATE TOPIC.", "The code below calls our script to generate log data defined above and then connects to and sends the logs to Pub/Sub. The only things we need to do are create a PublisherClient object, add the path to the topic using the topic_path method and call the publish function while passing the topic_path and data. Notice that we are importing generate_log_line from our stream_logs script so make sure these files are in the same folder or you will get an import error. We can then run this in our google console using:", "Once the file is running we should be able to see log data printing to the console like the figure below. This script will keep running until we use CTRL+C to kill it.", "Now that we have the initial set up out of the way we can get to the fun stuff and code up our pipeline using Beam and Python. To create a Beam pipeline we need to create a pipeline object (p). Once we have created the pipeline object we can apply multiple functions one after the other using the pipe (|) operator. In general, the workflow looks like the image below.", "In our code, we create two custom functions. The regex_clean function which searches the data and extracts the appropriate string based on the PATTERNS list using the re.search function. The function returns a comma-separated string. If you are not a regex expert I recommend looking at this tutorial and playing around in a notebook to test the code. After this, we define a custom ParDo function called Split which is a type of Beam transform for doing parallel processing. There is a specific way of doing this in Python where we have to create a class which inherits from the DoFn Beam class. The Split function takes the parsed string from the previous function and returns a list of dictionaries with keys equal to the column names in our BigQuery table. The one thing to note about this function is that I had to import datetime within the function for it to work. I was getting an error when I imported at the top of the file which was odd. This list then gets passed to the WriteToBigQuery function which just appends our data to the table. The code for both the Batch DataFlow job and the Streaming DataFlow job are provided below. The only difference between the batch and streaming code is that in the batch job we are reading a CSV from src_path using the ReadFromText function in Beam.", "We can execute the pipeline a few different ways. If we wanted to we could just run it locally from the terminal provided we have remotely logged in to GCP.", "We are going to be running it using DataFlow, however. We can do this using the command below while also setting the following mandatory options.", "While this command is running we can head over to the DataFlow tab in the google console and view our pipeline. When we click into the pipeline we should something like Figure 4. For debugging purposes, it can be quite helpful to go into the logs and then Stackdriver to view detailed logs. This has helped me figure out issues with the pipeline on a number of occasions.", "Right we should have our pipeline up and running with data flowing into our table. To confirm this, we can go over to BigQuery and view the data. After using the command below you should see the first few rows of the dataset. Now that we have our data stored in BigQuery we can do further analysis as well as share the data with colleagues and start answering and addressing business questions.", "Hopefully, this provides a useful example of creating a streaming data pipeline and also of finding ways of making data more accessible. Having the data in this format provides many benefits to us. We can now start answering useful questions like how many people use our product? Is the user base growing over time? What aspects of the product are people interacting with the most? and are there any errors happening when there shouldn't be? These are the types of questions that an organization will be interested in and based on these insights we can drive improvements to the product and improve user engagement.", "Beam is really useful for this type of exercise and there are a number of other interesting use cases as well. For example, you may want to analyze stock tick data in real-time and make trades based on the analysis, maybe you have sensor data coming in from vehicles and you want to figure out calculate the level of traffic. You could also, for example, be a games company collecting data on users and using this to create dashboards to track key metrics. Ok guys, so that\u2019s it for another post, thanks for reading and for those who want to see the full code, below is a link to my GitHub.", "Recommended Course: Data Engineering, Big Data, and Machine Learning on GCP", "Note some of the links in this post are affiliate links."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe873d671fc57&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@dannyf16?source=post_page-----e873d671fc57--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Daniel Foley"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa823d37636a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&user=Daniel+Foley&userId=a823d37636a4&source=post_page-a823d37636a4----e873d671fc57---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe873d671fc57&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&user=Daniel+Foley&userId=a823d37636a4&source=-----e873d671fc57---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe873d671fc57&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&source=-----e873d671fc57---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://click.linksynergy.com/link?id=z2stMJEP3T4&offerid=759505.10508402250&type=2&murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fgcp-data-machine-learning", "anchor_text": "GCP Data Engineering specialization on Coursera"}, {"url": "https://cloud.google.com/pubsub/", "anchor_text": "Pub/Sub"}, {"url": "https://cloud.google.com/dataflow/", "anchor_text": "DataFlow"}, {"url": "https://cloud.google.com/bigquery/", "anchor_text": "BigQuery"}, {"url": "https://beam.apache.org/", "anchor_text": "Apache Beam"}, {"url": "https://cloud.google.com/terms/services", "anchor_text": "here"}, {"url": "https://faker.readthedocs.io/en/latest/index.html", "anchor_text": "documentation"}, {"url": "https://cloud.google.com/dataflow/docs/quickstarts/quickstart-python", "anchor_text": "page"}, {"url": "https://cloud.google.com/storage/docs/uploading-objects", "anchor_text": "here"}, {"url": "https://cloud.google.com/bigquery/docs/tables", "anchor_text": "link"}, {"url": "https://www.machinelearningplus.com/python/python-regex-tutorial-examples/", "anchor_text": "tutorial"}, {"url": "http://Data Engineering, Big Data, and Machine Learning on GCP", "anchor_text": "Data Engineering, Big Data, and Machine Learning on GCP"}, {"url": "https://github.com/DFoly/User_log_pipeline", "anchor_text": "DFoly/User_log_pipelineCreating a Streaming Pipeline for user log data in Google Cloud Platform - DFoly/User_log_pipelinegithub.com"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----e873d671fc57---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----e873d671fc57---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e873d671fc57---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/google-cloud-platform?source=post_page-----e873d671fc57---------------google_cloud_platform-----------------", "anchor_text": "Google Cloud Platform"}, {"url": "https://medium.com/tag/programming?source=post_page-----e873d671fc57---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe873d671fc57&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&user=Daniel+Foley&userId=a823d37636a4&source=-----e873d671fc57---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe873d671fc57&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&user=Daniel+Foley&userId=a823d37636a4&source=-----e873d671fc57---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe873d671fc57&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=post_page-----e873d671fc57--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa823d37636a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&user=Daniel+Foley&userId=a823d37636a4&source=post_page-a823d37636a4----e873d671fc57---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fec905917d8b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&newsletterV3=a823d37636a4&newsletterV3Id=ec905917d8b1&user=Daniel+Foley&userId=a823d37636a4&source=-----e873d671fc57---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Written by Daniel Foley"}, {"url": "https://medium.com/@dannyf16/followers?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "1.8K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://www.linkedin.com/in/daniel-foley-1ab904a2/", "anchor_text": "https://www.linkedin.com/in/daniel-foley-1ab904a2/"}, {"url": "https://www.datascientistguide.com/", "anchor_text": "https://www.datascientistguide.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa823d37636a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&user=Daniel+Foley&userId=a823d37636a4&source=post_page-a823d37636a4----e873d671fc57---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fec905917d8b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flets-build-a-streaming-data-pipeline-e873d671fc57&newsletterV3=a823d37636a4&newsletterV3Id=ec905917d8b1&user=Daniel+Foley&userId=a823d37636a4&source=-----e873d671fc57---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/gaussian-mixture-modelling-gmm-833c88587c7f?source=author_recirc-----e873d671fc57----0---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=author_recirc-----e873d671fc57----0---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=author_recirc-----e873d671fc57----0---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Daniel Foley"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e873d671fc57----0---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/gaussian-mixture-modelling-gmm-833c88587c7f?source=author_recirc-----e873d671fc57----0---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Gaussian Mixture Modelling (GMM)Making Sense of Text Data using Unsupervised Learning"}, {"url": "https://towardsdatascience.com/gaussian-mixture-modelling-gmm-833c88587c7f?source=author_recirc-----e873d671fc57----0---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "\u00b711 min read\u00b7Mar 8, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F833c88587c7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgaussian-mixture-modelling-gmm-833c88587c7f&user=Daniel+Foley&userId=a823d37636a4&source=-----833c88587c7f----0-----------------clap_footer----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/gaussian-mixture-modelling-gmm-833c88587c7f?source=author_recirc-----e873d671fc57----0---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F833c88587c7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgaussian-mixture-modelling-gmm-833c88587c7f&source=-----e873d671fc57----0-----------------bookmark_preview----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e873d671fc57----1---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----e873d671fc57----1---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----e873d671fc57----1---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e873d671fc57----1---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e873d671fc57----1---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e873d671fc57----1---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e873d671fc57----1---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----e873d671fc57----1-----------------bookmark_preview----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e873d671fc57----2---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----e873d671fc57----2---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----e873d671fc57----2---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e873d671fc57----2---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e873d671fc57----2---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e873d671fc57----2---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e873d671fc57----2---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----e873d671fc57----2-----------------bookmark_preview----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7?source=author_recirc-----e873d671fc57----3---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=author_recirc-----e873d671fc57----3---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=author_recirc-----e873d671fc57----3---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Daniel Foley"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e873d671fc57----3---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7?source=author_recirc-----e873d671fc57----3---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "A Bayesian Approach to Time Series ForecastingToday we are going to implement a Bayesian linear regression in R from scratch and use it to forecast US GDP growth. This post is based on\u2026"}, {"url": "https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7?source=author_recirc-----e873d671fc57----3---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": "\u00b719 min read\u00b7Nov 10, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd97dd4168cb7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-bayesian-approach-to-time-series-forecasting-d97dd4168cb7&user=Daniel+Foley&userId=a823d37636a4&source=-----d97dd4168cb7----3-----------------clap_footer----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7?source=author_recirc-----e873d671fc57----3---------------------e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd97dd4168cb7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-bayesian-approach-to-time-series-forecasting-d97dd4168cb7&source=-----e873d671fc57----3-----------------bookmark_preview----e00ef3e2_0c2d_4c64_8924_ccf1f721b946-------", "anchor_text": ""}, {"url": "https://medium.com/@dannyf16?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "See all from Daniel Foley"}, {"url": "https://towardsdatascience.com/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----0-----------------clap_footer----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----e873d671fc57----0-----------------bookmark_preview----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Anuj Syal"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "12 Must-Have Skills to become a Data EngineerThe Essential Skills for a Successful Data Engineering Career"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "\u00b78 min read\u00b7Jan 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&user=Anuj+Syal&userId=df3997c527b4&source=-----35b100dbee0a----1-----------------clap_footer----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&source=-----e873d671fc57----1-----------------bookmark_preview----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/why-data-quality-is-harder-than-code-quality-a7ab78c9d9e?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/@arimbr?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/@arimbr?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Ari Bajo"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/why-data-quality-is-harder-than-code-quality-a7ab78c9d9e?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Why Data Quality Is Harder than Code QualityHow to detect, understand, fix, and reduce data quality issues."}, {"url": "https://towardsdatascience.com/why-data-quality-is-harder-than-code-quality-a7ab78c9d9e?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "\u00b710 min read\u00b7Nov 14, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa7ab78c9d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-data-quality-is-harder-than-code-quality-a7ab78c9d9e&user=Ari+Bajo&userId=5ad5ce9cd2&source=-----a7ab78c9d9e----0-----------------clap_footer----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/why-data-quality-is-harder-than-code-quality-a7ab78c9d9e?source=read_next_recirc-----e873d671fc57----0---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7ab78c9d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-data-quality-is-harder-than-code-quality-a7ab78c9d9e&source=-----e873d671fc57----0-----------------bookmark_preview----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Josue Luzardo Gebrim"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Data Quality in Python Pipelines!Discover What It Is And How To Achieve Data Quality In Your Data Streams!"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "\u00b714 min read\u00b7Mar 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&user=Josue+Luzardo+Gebrim&userId=9f59dfc0edf7&source=-----4ad1e8eb6603----1-----------------clap_footer----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----e873d671fc57----1---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&source=-----e873d671fc57----1-----------------bookmark_preview----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----e873d671fc57----2---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/@SeattleDataGuy?source=read_next_recirc-----e873d671fc57----2---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/@SeattleDataGuy?source=read_next_recirc-----e873d671fc57----2---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Ben Rogojan"}, {"url": "https://medium.com/coriers?source=read_next_recirc-----e873d671fc57----2---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "SeattleDataGuy By SeattleDataGuy"}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----e873d671fc57----2---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Data Engineering Vs Machine Learning PipelinesWhat\u2019s the difference?"}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----e873d671fc57----2---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "\u00b78 min read\u00b7Apr 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcoriers%2F82d0e1be410c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoriers%2Fdata-engineering-vs-machine-learning-pipelines-82d0e1be410c&user=Ben+Rogojan&userId=41cd8f154e82&source=-----82d0e1be410c----2-----------------clap_footer----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----e873d671fc57----2---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F82d0e1be410c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoriers%2Fdata-engineering-vs-machine-learning-pipelines-82d0e1be410c&source=-----e873d671fc57----2-----------------bookmark_preview----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----e873d671fc57----3---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----e873d671fc57----3---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----e873d671fc57----3---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----e873d671fc57----3---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----e873d671fc57----3---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----e873d671fc57----3---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----3-----------------clap_footer----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----e873d671fc57----3---------------------f0873b14_87e8_441f_89ba_b32cc0e4f96a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----e873d671fc57----3-----------------bookmark_preview----f0873b14_87e8_441f_89ba_b32cc0e4f96a-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e873d671fc57--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----e873d671fc57--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}