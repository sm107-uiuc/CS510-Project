{"url": "https://towardsdatascience.com/understanding-the-naive-bayes-classifier-16b6ee03ff7b", "time": 1683001048.943131, "path": "towardsdatascience.com/understanding-the-naive-bayes-classifier-16b6ee03ff7b/", "webpage": {"metadata": {"title": "Understanding The Naive Bayes Classifier | by Tony Yiu | Towards Data Science", "h1": "Understanding The Naive Bayes Classifier", "description": "Now that we\u2019ve fully explored Bayes\u2019 Theorem, let\u2019s check out a classification algorithm that utilizes it \u2014 the naive Bayes classifier. Classification, the process of quantitatively figuring out what\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b", "anchor_text": "ow that we\u2019ve fully explored Bayes\u2019 Theorem", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Naive_Bayes_classifier", "anchor_text": "according to Wikipedia", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/data-science-fundamentals-a-b-testing-cb371ceecc27", "anchor_text": "I wrote a post about hypothesis testing here", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b", "anchor_text": "Bayes\u2019 Theorem", "paragraph_index": 10}, {"url": "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b", "anchor_text": "previous post", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Chain_rule_(probability)", "anchor_text": "the chain rule of probability", "paragraph_index": 23}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "https://tonester524.medium.com/membership", "paragraph_index": 38}], "all_paragraphs": ["Now that we\u2019ve fully explored Bayes\u2019 Theorem, let\u2019s check out a classification algorithm that utilizes it \u2014 the naive Bayes classifier.", "Classification, the process of quantitatively figuring out what class (a.k.a. group) a given observation should be assigned to, is an important one in data science. Some example applications of classification include figuring out whether a patient is particularly at risk of a disease, identifying customers who are likely to churn, or flagging emails as spam.", "There are many classification algorithms out there, each with their own pros and cons. For example, if you just want predictive power, you would consider XGBoost or a Neural net. If you are more interested in understanding what factors and how those factors drive differentiation among your classes, you would consider using logistic regression.", "Naive Bayes is an algorithm that has been around for a while (since the 1960s according to Wikipedia). While it might lack some of the hype and firepower of more recently developed algorithms, it\u2019s a robust and versatile tool that has withstood the test of time (also its shortcomings are very well-understood which is often just as useful or even more so when building models) \u2014 so it\u2019s definitely worth learning more about.", "Let\u2019s step back first and frame our classification problem in Bayesian terms \u2014 where we have a set of prior beliefs and update our beliefs as we observe and collect evidence.", "In statistics, everything revolves around hypotheses. We make a hypothesis (an informed guess) about how the world works, and then we go about collecting evidence to test that hypothesis (if you would like to know the details, I wrote a post about hypothesis testing here).", "Classification models can be framed as a hypothesis as well. Let\u2019s first write out the objective and variables of our classification problem:", "OK, so that\u2019s classification \u2014 now let\u2019s examine classification through a Bayesian lens. Most classification algorithms make predictions by estimating (for each class) the probability that the observation belongs to that class. Then the class with the highest estimated probability is our prediction:", "Predict that the observed animal is a Dog!", "But how do we calculate these class probabilities? Conditional probabilities to the rescue! The conditional probability P(H|E) (where H is our hypothesis and E is our evidence) is the probability that our hypothesis is true given the evidence. For the cat example, our hypothesis H is that the observation is a cat. And our evidence E is that it is medium sized and not agile. We can write the conditional probability that it is a cat given our evidence as (the equation is read \u201cthe probability that the observation is a cat given that it is of medium size and is not agile\u201d):", "OK, that\u2019s cool and all but how do we actually solve for it? That\u2019s where Bayes\u2019 Theorem comes in \u2014 using it we can write:", "I used some of the terminology described in my previous post again here, but let me give a quick refresher:", "The issue with Bayes\u2019 Theorem is that it forces us to calculate a lot of probabilities, including some pretty difficult to estimate ones. But in the next section, we will see how naive Bayes, by making some clever assumptions, helps us greatly simplify things.", "Let\u2019s start with the normalizer. We don\u2019t need it for classification. To see why, let me write out all three formulas:", "Notice that the normalizer term (boxed in green) is the same across all three class probability equations. So basically it\u2019s a constant that we can safely omit. Let\u2019s see how we do that \u2014 in classification, we care more about relatives than absolutes. Recall that we make predictions by finding the most likely class (the class with the max likelihood). In order to do this, we make comparisons like this one:", "And because the denominator, P(Medium|NotAgile), is the same on both sides of our inequality, we can simplify our equation to:", "So (forgetting about hamsters for a minute) if the value on the left is bigger then we predict cat, otherwise we predict dog.", "Now comes the naive part of the algorithm, which I would argue is actually really clever and not naive at all. Naive Bayes makes a key simplifiying assumption that for a given class, all of our features (X variables such as size and agility) are independent of each other. In probability, the concept of independence means that the probability of event A occurring is the same whether or not B occurs \u2014 or if you are more familiar with statistics lingo like I am, we could say that A and B have zero correlation with each other. If A and B are independent, then their conditional probabilities simplify to:", "Let\u2019s see how this assumption helps us out. But before we can do that, we need to introduce some helpful math first (apologies for all the equations).", "A quick note on notation \u2014 P(A,B,C) means the probability of A and B and C all occurring at the same time (a.k.a. joint probability). P(A|B,C) is the probability of A occurring given that B and C have already occurred.", "From Bayes\u2019 Theorem and general probability we know that:", "So the numerator of Bayes\u2019 theorem (the product of the scaler and prior) is a joint probability. And because we canceled out the normalizer, the numerator is all that we care about. Going back to our animals example, recall that we simplified the cat part of our likelihood calculation to:", "The first probability, P(IsCat), is the prior and the second probability is the scaler \u2014 and as we just learned, the product of prior and scaler is a joint probability:", "And from the chain rule of probability, we know that:", "So we can rewrite our joint probability as:", "Almost there! This is where naive Bayes\u2019 simplifying assumption comes to save the day. Since we can assume that the features, size and agility, are independent (within a class), we know that:", "And our equation ultimately simplifies to:", "That\u2019s pretty cool. This means that we can estimate the likelihood of an observation belonging to a particular class, C, by scaling the prior by as many scalers as there are features:", "The plain English interpretation of all this is:", "Likelihood(Hamster) = High * Medium = Somewhat Likely", "Likelihood(Dog) = Low * Medium = Somewhat Low", "Likelihood(Cat) = Medium * Almost Zero = Not Likely", "So in this case, naive Bayes would predict hamster because it had the highest likelihood. That\u2019s naive Bayes in a nutshell \u2014 at a high level, naive Bayes is just applying a simplified version of Bayes\u2019 Theorem to every observation based on its features (and for each potential class). It\u2019s not rocket science, but in my opinion, it is powerful in its own simple way.", "A topic for further exploration is whether (and how) the naive Bayes classifier\u2019s assumption of feature independence hurts its performance relative to other algorithms. But the independence assumption is also one of its key advantages as it allows for quick training and predictions even on very large datasets. Also, naive Bayes has almost no hyperparameters to tune, so it usually generalizes well.", "One thing to note is that due to the feature independence assumption, the class probabilities output by naive Bayes can be pretty inaccurate. So if your end application requires precise estimates of probabilities, you will want to go with another algorithm.", "On the other hand, despite its naivet\u00e9, naive Bayes often does a reasonably good job of picking the right class \u2014 it may not be that good at estimating absolute probabilities, but it is pretty good at measuring relative likelihoods.", "More Data Science and Analytics Related Posts By Me:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist. Founder Alpha Beta Blog. Doing my best to explain the complex in plain English. Support my writing: https://tonester524.medium.com/membership"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F16b6ee03ff7b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tonester524.medium.com/?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "Tony Yiu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840a3210fbe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&user=Tony+Yiu&userId=840a3210fbe7&source=post_page-840a3210fbe7----16b6ee03ff7b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b6ee03ff7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b6ee03ff7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b", "anchor_text": "ow that we\u2019ve fully explored Bayes\u2019 Theorem"}, {"url": "https://en.wikipedia.org/wiki/Naive_Bayes_classifier", "anchor_text": "according to Wikipedia"}, {"url": "https://towardsdatascience.com/data-science-fundamentals-a-b-testing-cb371ceecc27", "anchor_text": "I wrote a post about hypothesis testing here"}, {"url": "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b", "anchor_text": "Bayes\u2019 Theorem"}, {"url": "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b", "anchor_text": "previous post"}, {"url": "https://en.wikipedia.org/wiki/Chain_rule_(probability)", "anchor_text": "the chain rule of probability"}, {"url": "https://unsplash.com/@sweetmangostudios?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Ricky Kharawala"}, {"url": "https://unsplash.com/s/photos/hamster?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/what-do-data-scientists-do-13526f678129", "anchor_text": "What Do Data Scientists Do?"}, {"url": "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b", "anchor_text": "Understanding Bayes\u2019 Theorem"}, {"url": "https://towardsdatascience.com/fun-with-the-binomial-distribution-96a5ecabf65b", "anchor_text": "The Binomial Distribution"}, {"url": "https://towardsdatascience.com/understanding-pca-fae3e243731d?source=post_page---------------------------", "anchor_text": "Understanding PCA"}, {"url": "https://towardsdatascience.com/the-curse-of-dimensionality-50dc6e49aa1e", "anchor_text": "The Curse Of Dimensionality"}, {"url": "https://towardsdatascience.com/understanding-neural-networks-19020b758230?source=post_page---------------------------", "anchor_text": "Understanding Neural Nets"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----16b6ee03ff7b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----16b6ee03ff7b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/technology?source=post_page-----16b6ee03ff7b---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----16b6ee03ff7b---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/education?source=post_page-----16b6ee03ff7b---------------education-----------------", "anchor_text": "Education"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16b6ee03ff7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&user=Tony+Yiu&userId=840a3210fbe7&source=-----16b6ee03ff7b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16b6ee03ff7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&user=Tony+Yiu&userId=840a3210fbe7&source=-----16b6ee03ff7b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b6ee03ff7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F16b6ee03ff7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----16b6ee03ff7b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----16b6ee03ff7b--------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tony Yiu"}, {"url": "https://tonester524.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "102K Followers"}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "https://tonester524.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840a3210fbe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&user=Tony+Yiu&userId=840a3210fbe7&source=post_page-840a3210fbe7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F78d3e392d884&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-naive-bayes-classifier-16b6ee03ff7b&newsletterV3=840a3210fbe7&newsletterV3Id=78d3e392d884&user=Tony+Yiu&userId=840a3210fbe7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}