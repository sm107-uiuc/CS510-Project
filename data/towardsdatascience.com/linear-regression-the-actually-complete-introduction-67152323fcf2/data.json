{"url": "https://towardsdatascience.com/linear-regression-the-actually-complete-introduction-67152323fcf2", "time": 1683009275.085772, "path": "towardsdatascience.com/linear-regression-the-actually-complete-introduction-67152323fcf2/", "webpage": {"metadata": {"title": "Linear Regression: The (Actually) Complete Introduction | by Aden Haussmann | Towards Data Science", "h1": "Linear Regression: The (Actually) Complete Introduction", "description": "I remember how excited I was the very first time I delved into the realm of Machine Learning. And the hype is understandable, what software engineering student wouldn\u2019t want to jump into one of the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.instagram.com/adenhaus/", "anchor_text": "Instagram", "paragraph_index": 41}, {"url": "https://medium.com/subscribe/@adenhaus", "anchor_text": "Subscribe", "paragraph_index": 42}, {"url": "https://medium.com/@adenhaus/membership", "anchor_text": "join", "paragraph_index": 42}], "all_paragraphs": ["I remember how excited I was the very first time I delved into the realm of Machine Learning. And the hype is understandable, what software engineering student wouldn\u2019t want to jump into one of the most exciting and relevant technologies of today?", "But as my interest grew, and I began to educate myself on the subject, I was often scared off by how technical some of the articles I read were. Fantastic articles, no doubt, but written from too advanced a perspective, even the ones aimed at beginners. On the other hand, so many were overly-pragmatic, neglecting theoretical explanations in favour of getting new learner\u2019s hands dirty as soon as possible. And while both are valuable, I feel that, as a fellow student, there is a gap I can fill here.", "My goal is to amalgamate all the information I wish I\u2019d had at my disposal when I started, outline the theory behind this simple Machine Learning algorithm, then give a thoroughly-explained practical example, in an accessible but comprehensive way. One student to another.", "So, welcome to the article I wish I could have read when I built my first Linear Regression model.", "Regression analysis is a set of statistical processes whereby we estimate the relationship between a dependent variable (y) for one or more given independent variables (x). In the context of Machine Learning, it is a subfield of supervised learning.", "There are several types of Regression, each describing a different mathematical relationship between the independent and dependent variables. Some common examples include Polynomial, Logistic and, the topic of this article, Linear.", "But how do you choose one? What\u2019s the difference? Well, as I said above, it depends on the data. Here is an example: Say, for instance, we wish to predict the progression of a disease as it sweeps through a population and gradually dies out. Naturally, as the number of days increases, so shall the number of cases \u2014 until they begin to fall, resulting in a parabolic shape. As you can see below, a straight line of best fit does not accurately predict the number of cases by day 100. A Polynomial Regression does though. But we\u2019ll go into that in the next article.", "Conversely, when we have data that moves in a trend as shown below, a straight line fits relatively accurately. This is a Linear Regression:", "So, Linear Regression is used when the relationship between the dependent and independent variables can be modelled quite accurately as a straight line.", "This will be our line of best fit, and you may remember its equation from high school:", "So, how do we find the equation of the line of best fit? By adjusting a set of parameters (W0 and W1) until we find their respective values that make the sum of the squared residuals (the difference between the actual and predicted values) of the model as small as possible.", "Let\u2019s go over some critical terminology before moving on. It\u2019s easy to get the terms confused, but understanding these metrics is crucial for determining a model\u2019s reliability.", "Essentially, variance is a measure of how inaccurate our line of best fit is, and is quantified by the R\u00b2 score. Our goal is to make the variance as small as possible, so the higher our R\u00b2 score, the better.", "Sometimes called the Cost function, it is used to express variance as the coefficient of determination R\u00b2 of the prediction, which ranges from 0 to 1, with 1 being a perfect fit.", "The average of the square of the errors (we square them so there are no negative values). The larger the number, the greater the error. Our goal is to minimise this.", "We will use the Ordinary Least Squares method, which is the simple, analytical and non-iterative solution. If we wanted to apply a more complex Machine Learning algorithm, say Support Vector Machine, then we\u2019d need to use Gradient Descent, which would give us an approximation of the OLS solution, done iteratively. But that is a topic for another article.", "So, with the above functions, we train our model until it learns the optimal coefficients that minimise the sum of the squared residuals. Once we\u2019ve trained our model on some data (say, the first 80% of the dataset), we\u2019ll test it on the rest of the data (the other 20%).", "Let\u2019s start at the very beginning, imports:", "Next, we load the dataset and create an object dx. The diabetes dataset comes with Scikit-Learn and consists of 10 physiological variables (age, sex, weight, blood pressure etc.) measured on 442 patients and an indication of the disease progression after one year. The goal is to predict disease progression from physiological variables.", "Now, the Scikit-Learn datasets return something called a Bunch which is similar to a dictionary. This Bunch has various attributes, one of which is data. This is the data matrix, which we wish to use. Another is target, which we will come to shortly. But we don\u2019t need all the data, so we select the features we want, and use numpy.newaxis to increase the array dimensionality from 1 to 2. We have now turned our array into a column vector.", "If that step was a little confusing, that\u2019s alright. The point is, we now have a 2D array containing the data, which is the necessary format. You really could achieve this with any dataset (custom lists or a .csv file) where you have data points with x and y values. So now ours looks something like this:", "Next, we split our dataset into training and testing sets \u2014 a fundamental part of Machine Learning. You will notice the .target attribute that I mentioned earlier. These are essentially the correct values, or response variables.", "At this point, a scatter plot would be helpful. Just by looking at it, we may be able to infer whether Linear Regression will provide an accurate model. I\u2019ll add some styling with rcParams to make it look a little more appealing, but don\u2019t worry about that.", "As you can probably tell, it does look as though a straight line could predict more-or-less where this trend is heading.", "Now comes the interesting part. We will create an object lr for the Linear Regression, and fit the data to it.", "All we have left to do is plot the line of best fit over the scatter plot:", "Congratulations! You have successfully trained and tested a Linear Regression model.", "But we can\u2019t pat ourselves on the back just yet\u2026", "At this stage, I feel we should go more in-depth. It is imperative we understand exactly what is going on under the hood.", "The LinearRegression() class is where the good stuff happens. This is where the linear model lr is fitted with coefficients that minimise the residual sum of squares between the predicted and target values, as I mentioned earlier.", "This class contains the .fit() function, which we can see being applied to the Linear Regression object lr. We pass the training data (x and y values) in as arguments and the function returns an instance of the object, now fitted with the data.", "Finally, we see .predict(), another function of the LinearRegression() class. This is the function that returns the predicted values, by calculating the equation for the line of best fit.", "The best way to understand these functions is to rewrite our program without them.", "This is where the Ordinary Least Squares algorithm begins. The first thing we\u2019ll need to do is find the gradient m and the y-intercept c of our line of best fit. Here are their respective formulas:", "We use numpy.mean to find the mean \u03bc. I\u2019ve implemented these two formulas as a single function:", "Note that now we don\u2019t have to change our array to be 2D like before, because we aren\u2019t using the .fit() function anymore. So amend the line where we previously used numpy.newaxis to look like this:", "Now when we plot the line of best fit, instead of using the .predict() function, we actually input our equation for the line of best fit, mx + c, as the y value.", "Congratulations for real this time! You just wrote a Linear Regression algorithm from scratch. Hopefully you now have a thorough understanding of the algorithm and its relevant functions.", "As a bonus, let\u2019s calculate the mean squared error and score (the coefficient of determination R\u00b2, as defined earlier, of the prediction) of our model.", "There you have it, a thorough introduction to Machine Learning\u2019s simplest algorithm, Linear Regression. I hope that, as a student myself, I was able to explain the concepts in a relatable and comprehensive manner.", "Just to recap what we covered:", "If you found the article helpful, I\u2019d love to engage with you! Follow me on Instagram for more Machine Learning, Software Engineering and Entrepreneurial content.", "Subscribe \ud83d\udcda to never miss a new article of me, and if you aren\u2019t a Medium member yet, join \ud83d\ude80 to read all of my, and thousands of other stories!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "21-year-old Computer Science student at The University of Edinburgh writing about programming, data science and business. Raised in South Africa."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F67152323fcf2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----67152323fcf2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----67152323fcf2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@adenhaus?source=post_page-----67152323fcf2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@adenhaus?source=post_page-----67152323fcf2--------------------------------", "anchor_text": "Aden Haussmann"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe634223302b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&user=Aden+Haussmann&userId=e634223302b0&source=post_page-e634223302b0----67152323fcf2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67152323fcf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67152323fcf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/polynomial-regression-the-only-introduction-youll-need-49a6fb2b86de", "anchor_text": "Polynomial Regression: The Only Introduction You\u2019ll NeedA deep-dive into the theory and application behind this Machine Learning algorithm in Python, by a studenttowardsdatascience.com"}, {"url": "https://www.instagram.com/adenhaus/", "anchor_text": "Instagram"}, {"url": "https://medium.com/subscribe/@adenhaus", "anchor_text": "Subscribe"}, {"url": "https://medium.com/@adenhaus/membership", "anchor_text": "join"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict", "anchor_text": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict"}, {"url": "https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html", "anchor_text": "https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes", "anchor_text": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes"}, {"url": "https://scikit-learn.org/stable/tutorial/basic/tutorial.html", "anchor_text": "https://scikit-learn.org/stable/tutorial/basic/tutorial.html"}, {"url": "https://realpython.com/linear-regression-in-python/#simple-linear-regression", "anchor_text": "https://realpython.com/linear-regression-in-python/#simple-linear-regression"}, {"url": "https://statisticsbyjim.com/regression/interpret-r-squared-regression/", "anchor_text": "https://statisticsbyjim.com/regression/interpret-r-squared-regression/"}, {"url": "https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/", "anchor_text": "https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----67152323fcf2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----67152323fcf2---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/scikit-learn?source=post_page-----67152323fcf2---------------scikit_learn-----------------", "anchor_text": "Scikit Learn"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----67152323fcf2---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/regression?source=post_page-----67152323fcf2---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F67152323fcf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&user=Aden+Haussmann&userId=e634223302b0&source=-----67152323fcf2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F67152323fcf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&user=Aden+Haussmann&userId=e634223302b0&source=-----67152323fcf2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67152323fcf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----67152323fcf2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F67152323fcf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----67152323fcf2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----67152323fcf2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----67152323fcf2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----67152323fcf2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----67152323fcf2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----67152323fcf2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----67152323fcf2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----67152323fcf2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----67152323fcf2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@adenhaus?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@adenhaus?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Aden Haussmann"}, {"url": "https://medium.com/@adenhaus/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "190 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe634223302b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&user=Aden+Haussmann&userId=e634223302b0&source=post_page-e634223302b0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc89ba036abb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-the-actually-complete-introduction-67152323fcf2&newsletterV3=e634223302b0&newsletterV3Id=c89ba036abb9&user=Aden+Haussmann&userId=e634223302b0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}