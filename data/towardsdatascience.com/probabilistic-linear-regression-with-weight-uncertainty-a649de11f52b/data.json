{"url": "https://towardsdatascience.com/probabilistic-linear-regression-with-weight-uncertainty-a649de11f52b", "time": 1683015385.709165, "path": "towardsdatascience.com/probabilistic-linear-regression-with-weight-uncertainty-a649de11f52b/", "webpage": {"metadata": {"title": "Probabilistic Linear Regression with Weight Uncertainty | by Ruben Winastwan | Towards Data Science", "h1": "Probabilistic Linear Regression with Weight Uncertainty", "description": "Linear regression is probably the first statistical approach that you\u2019ll ever encounter when you\u2019re learning data science and machine learning. So, I\u2019d take my chance to guess that this is not the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/uciml/autompg-dataset", "anchor_text": "car\u2019s MPG dataset", "paragraph_index": 10}], "all_paragraphs": ["Linear regression is probably the first statistical approach that you\u2019ll ever encounter when you\u2019re learning data science and machine learning. So, I\u2019d take my chance to guess that this is not the first time you\u2019re dealing with linear regression. Thus in this article, I want to talk about probabilistic linear regression instead of the typical/deterministic linear regression.", "But before that, let\u2019s briefly discuss the concept of deterministic linear regression to get us up to the speed to the main talking point of this article.", "Linear regression is a fundamental statistical approach to model the linear relationship between one or multiple input variables (or independent variables) with one or multiple output variables (or dependent variables).", "In the above equation, a is called the intercept, and b is called the slope. x is our independent variable, and y is our dependent variable, which the value we try to predict.", "The value for a and b need to be optimized with a gradient descent algorithm. Then, we obtain a regression line that shows the best fit between independent and dependent variables. With the regression line, we can predict the value of ywith any given input of x . Those are the steps on how the typical or deterministic linear regression algorithm is normally built.", "However, this deterministic linear regression algorithm doesn\u2019t really tell the complete story of both the data and the model. Why is that?", "In reality, there are two types of uncertainty that arise when we do linear regression analysis:", "I\u2019m going to elaborate more on these uncertainties as we go through the article. To take these uncertainties into account, probabilistic linear regression should be used instead of deterministic linear regression.", "In this article, we will talk about probabilistic linear regression and how it differs from the deterministic linear regression. We will first see how deterministic linear regression is built in TensorFlow, and then we will move on to build a probabilistic linear regression model with TensorFlow probability.", "First, let\u2019s start with loading the dataset that we will use in this article.", "The dataset that will be used in this article is car\u2019s MPG dataset. As usual, we can load the data with Pandas.", "Below is the statistical summary of the data.", "Next, we can look at the correlation between variables in the dataset with the code below.", "Now if we look at the correlation, the car\u2019s Miles per Gallon (MPG) and the car\u2019s weight has a strong negative correlation.", "In this article, I\u2019m going to do a simple linear regression analysis for visualization purpose. The independent variable will be the car\u2019s weight and the dependent variable will be the car\u2019s MPG.", "Now, let\u2019s split the data into training data and test data with Scikit-learn. After splitting the data, we can now scale both of the dependent and independent variables. This is to make sure that both variables are going to be on the same scale and this will also improve the convergence rate of our linear regression model.", "Now if we visualize the training data, we get the following visualization:", "Awesome! Next, let\u2019s move on to build our deterministic linear regression model with TensorFlow.", "It is very easy to build a simple linear regression model with TensorFlow. All we need to do to build the model is one single dense layer without any activation function. For the cost function, the mean squared error is normally used. In this example, I will use RMSprop as the optimizer and the model will be trained in 100 epochs. We can build and train the model in just a few lines of code as below.", "After we trained the model, let\u2019s take a look at the loss history of the model to check the loss convergence.", "It seems like the loss has converged. Now if we use the trained model to predict the test set, we can see the following regression line.", "As I mentioned earlier, it is very easy to build a simple linear regression model with TensorFlow. With the regression line, we can now approximate the car\u2019s MPG at any given input of the car\u2019s weight. As an example, let\u2019s say that the car\u2019s weight after feature scaling is 0.64. We can get the corresponding value of the car\u2019s MPG by passing this value to the trained model as follows.", "Now as you can see, the model predicts that the car\u2019s MPG would be 0.21. Simply put, for any given car\u2019s weight, we get a single deterministic value of the car\u2019s MPG", "However, that output value doesn\u2019t really tell the whole story. There are two things that we should pay attention here. First, we only have a limited amount of data points. Second, as we can see from the linear regression plot, most of the data points don\u2019t really lie on the regression line.", "Although we get the output value of 0.21, we know that the actual car\u2019s MPG is not precisely 0.21. It could be slightly below that, could be slightly above that. In other words, there is an uncertainty that needs to be taken into account. And this uncertainty is called aleatoric uncertainty.", "Deterministic linear regression fails to capture this aleatoric uncertainty of the data. To capture this aleatoric uncertainty, the probabilistic linear regression can be applied instead.", "Thanks to TensorFlow Probability, it is also very easy to build a probabilistic linear regression model. However, you need to install tensorflow_probability library first. You can install it using pip command as follows:", "The prerequisite to install this library is that you need to have TensorFlow version 2.3.0. So make sure you upgrade your TensorFlow version before installing TensorFlow Probability.", "In this section, we will build a probabilistic linear regression model that takes aleatoric uncertainty into account.", "The model is pretty much similar to the deterministic linear regression. However, instead of just using one single dense layer like before, we need to add one more layer as the final layer. This final layer converts the final output value from deterministic into a probability distribution.", "In this example, we will create a final layer that converts the output value into probability value that is normally distributed. Below is the implementation of that.", "Note that we applied one additional layer in the end with TensorFlow Probability layer. This layer will turn the two outputs of the previous dense layer (one for the mean and one for the standard deviation) into probability value which is normally distributed with a trainable mean (loc) and standard deviation (scale).", "We can use RMSprop as the optimizer, but you can use other optimizers if you wish. For the loss function, we need to use the negative log-likelihood.", "But why do we use the negative log-likelihood as the loss function?", "In order to fit a distribution to some data, we need to use the likelihood function. With likelihood function, we try to estimate the unknown parameters \u03b8 (for example, the mean and the standard deviation of normally distributed data) given the pattern that we\u2019ve seen in the data.", "The job for the optimizer in our probabilistic regression model is to find the maximum likelihood estimate for the unknown parameters. In other words, the model is trained to find the most likely parameter value given the pattern from our data.", "Maximizing the likelihood estimate is the same as minimizing the negative log-likelihood. In the optimization domain, often the objective is to minimizing the cost instead of maximizing it. That\u2019s why we use the negative log-likelihood as our cost function.", "Below is the implementation of the negative log-likelihood as our custom loss function.", "Now that we have built the model and define the optimizer as well as the loss function, let\u2019s compile and train the model.", "Now we can draw samples from the trained model. We can visualize the comparison between the test set and the samples generated from the model with the following code.", "As you can see from the visualization above, now for any given input value, the model won\u2019t return a deterministic value. Instead, it will return a distribution and it will draw a sample based on that distribution.", "If you compare the data points of the test set (blue points) to the data points predicted by the trained model (green points), you\u2019d probably believe that the green points come from the same distribution as the blue points.", "Next, we can also visualize the mean and the standard deviation of the distribution generated by the trained model, given the data in the training set. We can do this by applying the following code.", "We can see that the probabilistic linear regression model gives us more than the regression line. It also gives the approximation of the standard deviation of the data. It can be seen that roughly 95% of the data points of the test set lie within the two standard deviations.", "So far, we\u2019ve built a probabilistic regression model that takes into account the uncertainty that comes from the data or as we call it, aleatoric uncertainty.", "However, in reality, we also need to deal with the uncertainty that comes from the regression model itself. Due to the imperfection of the data, there is also uncertainty regarding the weight or slope of the regression parameter. This uncertainty is called epistemic uncertainty.", "The probabilistic model that we\u2019ve built so far only considers one deterministic weight. As you\u2019ve seen from the visualization, the model generates only one regression line and often this is not entirely accurate.", "In this section, we will improve our probabilistic regression model that takes both aleatoric and epistemic uncertainties into account.We can use the Bayesian perspective to introduce the uncertainty of the regression weights.", "First, we need to define our prior belief about what the weight distribution looks like before we see the data. Often, we don\u2019t know what to expect about this, right? To make it simple, let\u2019s assume that the distribution of the weight is normally distributed with a mean equal to 0 and a standard deviation equal to 1.", "Since we hard-coded the mean and the standard deviation, this prior belief is not trainable.", "Next, we need to define the posterior distribution of the regression weights. The posterior distribution shows how our belief has changed after seeing the pattern in the data. Thus, the parameters in this posterior distribution are trainable. Below is the code implementation to define our posterior distribution.", "Now the question is, what is this VariableLayers defined in the posterior function above? The idea behind this variable layers is that we try to approximate the true posterior distribution. Normally, it\u2019s not possible to derive the true posterior distribution, hence we need to approximate it.", "After defining the prior and the posterior function, now we can build our probabilistic linear regression model with weight uncertainty. Below is the code implementation for that.", "As you may notice, the only difference between this model and the previous probabilistic regression model is just the first layer. Instead of using a normal dense layer, we use the DenseVariational layer. In this layer, we pass our prior and posterior functions as the argument. The second layer is exactly the same as the previous model.", "Now it\u2019s time for us to compile and train the model.", "The optimizer and the cost function are still the same as the previous model. We use RMSprop as the optimizer and the negative log-likelihood as our cost function. Let\u2019s compile and train or model.", "Now it\u2019s time for us to visualize the weight or slope uncertainty of our regression model. Below is the code implementation to visualize the result.", "In the visualization above, you can see that the linear line (mean) as well as the standard deviation that has been generated by the posterior distribution of the trained model is different in each iteration. All of these lines are a plausible solution to fit the data points in the test set. However, due to epistemic uncertainty, we don\u2019t know which line would be the best one.", "Usually, the more the data points we have, the less the uncertainty of the regression line that we will see.", "And that\u2019s it! Now you\u2019ve seen how the probabilistic linear regression differs from the deterministic linear regression. With probabilistic linear regression, two types of uncertainty that arise from both the data (aleatoric) and the regression model (epistemic) can be taken into account.", "Taking these uncertainties into account is very important if we want to build a deep learning model where the inaccurate predictions lead to very serious negative consequences, for example in the field of autonomous driving and medical diagnosis.", "Normally, as we have more data points, the epistemic uncertainty of the model will be reduced.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science || Machine Learning || Computer Vision || NLP"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa649de11f52b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a649de11f52b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a649de11f52b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@marcellusruben?source=post_page-----a649de11f52b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcellusruben?source=post_page-----a649de11f52b--------------------------------", "anchor_text": "Ruben Winastwan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5dae9da73c9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&user=Ruben+Winastwan&userId=5dae9da73c9b&source=post_page-5dae9da73c9b----a649de11f52b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa649de11f52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa649de11f52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@wesleyphotography?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Wesley Tingey"}, {"url": "https://unsplash.com/s/photos/unsymmetry-line?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/uciml/autompg-dataset", "anchor_text": "car\u2019s MPG dataset"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a649de11f52b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a649de11f52b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/statistics?source=post_page-----a649de11f52b---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/bayesian-statistics?source=post_page-----a649de11f52b---------------bayesian_statistics-----------------", "anchor_text": "Bayesian Statistics"}, {"url": "https://medium.com/tag/regression?source=post_page-----a649de11f52b---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa649de11f52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----a649de11f52b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa649de11f52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----a649de11f52b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa649de11f52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a649de11f52b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa649de11f52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a649de11f52b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a649de11f52b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a649de11f52b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a649de11f52b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a649de11f52b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a649de11f52b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a649de11f52b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a649de11f52b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a649de11f52b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcellusruben?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcellusruben?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ruben Winastwan"}, {"url": "https://medium.com/@marcellusruben/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "925 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5dae9da73c9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&user=Ruben+Winastwan&userId=5dae9da73c9b&source=post_page-5dae9da73c9b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F46c6747bd93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-linear-regression-with-weight-uncertainty-a649de11f52b&newsletterV3=5dae9da73c9b&newsletterV3Id=46c6747bd93b&user=Ruben+Winastwan&userId=5dae9da73c9b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}