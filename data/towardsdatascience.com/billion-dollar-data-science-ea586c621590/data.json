{"url": "https://towardsdatascience.com/billion-dollar-data-science-ea586c621590", "time": 1683002962.5019782, "path": "towardsdatascience.com/billion-dollar-data-science-ea586c621590/", "webpage": {"metadata": {"title": "Billion Dollar Data Science. How to prevent costly failures in\u2026 | by Jason Capehart | Towards Data Science", "h1": "Billion Dollar Data Science", "description": "The intrinsic risk for predicting customer churn on a smartphone plan is not the same as pricing a trillion dollars of mortgage-backed securities or detecting a pedestrian in a crosswalk for a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Subprime_mortgage_crisis", "anchor_text": "mortgage-backed securities", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Long-Term_Capital_Management", "anchor_text": "Long Term Capital Management", "paragraph_index": 3}, {"url": "http://individual.utoronto.ca/michael_miller/courses/sv_f17/documents/rudner_1953.pdf", "anchor_text": "philosophy of science for hypothesis testing", "paragraph_index": 4}, {"url": "https://leon.bottou.org/slides/2challenges/2challenges.pdf", "anchor_text": "it may not match the operational conditions for a model", "paragraph_index": 10}, {"url": "https://arxiv.org/pdf/1905.01772.pdf", "anchor_text": "decomposed into parts", "paragraph_index": 21}, {"url": "https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf", "anchor_text": "Pros and Cons of End-to-End Learning", "paragraph_index": 21}, {"url": "https://www.stat.cmu.edu/~cshalizi/350/lectures/17/lecture-17.pdf", "anchor_text": "aren\u2019t easy to interpret for most real-world problems", "paragraph_index": 27}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "wide variety of ways to evaluate", "paragraph_index": 31}, {"url": "https://media.springernature.com/full/springer-static/image/art%3A10.1186%2F1471-2105-15-S6-S4/MediaObjects/12859_2014_Article_6393_Fig5_HTML.jpg", "anchor_text": "biclustering in bioinformatics", "paragraph_index": 31}, {"url": "http://www.wisdom.weizmann.ac.il/~vision/courses/2010_2/papers/datasets.pdf", "anchor_text": "cross-dataset generalization", "paragraph_index": 32}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43146.pdf", "anchor_text": "Machine Learning: The High Interest Credit Card of Technical Debt", "paragraph_index": 34}, {"url": "https://docs.python.org/3/library/pickle.html", "anchor_text": "pickle", "paragraph_index": 36}, {"url": "https://stat.ethz.ch/R-manual/R-devel/library/base/html/readRDS.html", "anchor_text": "rds", "paragraph_index": 36}, {"url": "https://www.tensorflow.org/guide/saved_model", "anchor_text": "TensorFlow", "paragraph_index": 36}, {"url": "https://spark.apache.org/mllib/", "anchor_text": "mllib", "paragraph_index": 36}, {"url": "http://dmg.org/pmml/v4-3/GeneralStructure.html", "anchor_text": "PMML", "paragraph_index": 36}, {"url": "https://onnx.ai/", "anchor_text": "ONNX", "paragraph_index": 36}, {"url": "https://github.com/onnx/onnxmltools", "anchor_text": "ONNXML", "paragraph_index": 36}, {"url": "https://leon.bottou.org/slides/2challenges/2challenges.pdf", "anchor_text": "Two Big Challenges in Machine Learning", "paragraph_index": 41}, {"url": "https://www.wired.com/2012/04/netflix-prize-costs/", "anchor_text": "the winning algorithm was never implemented", "paragraph_index": 42}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT", "paragraph_index": 48}, {"url": "https://christophm.github.io/interpretable-ml-book/agnostic.html", "anchor_text": "PDP, ICE, and SHAP plots", "paragraph_index": 50}, {"url": "http://uc-r.github.io/dalex", "anchor_text": "looking at residuals", "paragraph_index": 50}], "all_paragraphs": ["The intrinsic risk for predicting customer churn on a smartphone plan is not the same as pricing a trillion dollars of mortgage-backed securities or detecting a pedestrian in a crosswalk for a self-driving car. In the first situation a wrong decision has an opportunity cost, in the second it causes a financial crisis, and in the third someone could be hurt or killed. As data scientists we talk a lot about model selection, hyperparameter optimization, and performance metrics but rarely talk about how the seriousness of an application should affect how we approach our craft. After a decade in finance, I\u2019ve found there are 5 problems most frequently at the root of model failure. Knowing what they are and how to deal with them might help you avoid making a billion dollar mistake in data science.", "There are two concepts that are critical for a good evaluation of how a model will be used to make a decision: risk and reversibility. The first concept, risk, is more intuitive. The best way to measure risk is different for every decision, but it is always about understanding the reward for a correct decision and the cost of an incorrect decision. The second concept, reversibility, is about whether an incorrect decision can be changed after the fact. Decisions are almost never fully reversible because there\u2019s usually some cost incurred, even if it\u2019s non-monetary like lost time or a damaged reputation, but the extent to which a mistake can be reversed or mitigated changes the real cost of a poor choice.", "When I worked at the New York Times on comment moderation, the cost of a mistake from a machine learning model was clear and limited. A reader would post an obscene comment that the algorithm missed, other readers would report it to our team of comment moderation experts, and the comment would be removed. Even in the case of a systemic failure, it would take less than 24 hours to detect the failure and either fix the machine learning system or temporarily take the entire system offline. The risk created by a wrong decision was low because the likelihood of an obscene comment and the cost of displaying it were low. The model decision was also reversible because a moderator could remove the comment after it was displayed. In this sort of situation, data scientists should feel free to move fast and break things. The benefits of learning and experimentation through rapid iteration on models outweigh careful validation and checking before deployment.", "The situation one faces when building a risk model for a credit card is quite different. The first obvious indication of a serious problem from a model deployed today might not come for 6 months. Certain types of model failures could take 2 or 3 years to surface. By the time the problem is apparent \u2014 it\u2019s too late, the damage is done. Here each wrong decision is low risk because the loss is small in comparison to the size of a portfolio. But each decision is irreversible and the total cost before the feedback loop closes becomes high. If the failure is severe enough all that\u2019s left to do is watch the losses roll in until you slowly (or maybe very quickly) go out of business. Investors lose their money, the data science team puts everyone out of a job, and the company becomes a horror story like Long Term Capital Management about what happens when you give nerds too much power in a company.", "The general concept of risk in decision-making has long been recognized in the philosophy of science for hypothesis testing. Although applying a significance level of 0.95 is drilled into every Stats 101 student, it is equally absurd to require that level of confidence for an A/B test about the color of a button on a website as it would be terrifying to only require that level of confidence for a doctor to administer a risky drug. Still, at some point, a scientist has to make a judgement on what significance level is appropriate.", "Similarly, when we build a model we have to make a judgement call on how to balance the expediency and rigor of our approach. When a model is the primary input to a high risk decision, how should we strengthen our methods to minimize the chance of model failure?", "There\u2019s no general way to guarantee a model\u2019s performance, but out of the infinite number of ways models can fail \u2014 here are the top 5 failure modes I try to be aware of when I build or review a model.", "One of the most common, and often the easiest to overlook, problems in modeling is selection bias. The definition of selection bias differs by field, but roughly I mean any process by which training data is collected in a non-random way and diverges from the intended application. Most practical problems suffer from selection bias to some degree.", "Let\u2019s imagine we want to predict the price someone would sell their car for. A mild example of selection bias would be to mostly have data on cars and only some data on trucks and SUVs. A model built on that data set is likely to be more accurate for cars than SUVs, but the basic relationships between value, mileage, and age should hold up and give good predictions. A more serious form of selection bias would be to build a model based on data only from American cars and apply it to cars from Japanese manufacturers. The difference would be easy to overlook, but Japanese cars have a better track record and reputation for reliability, so price won\u2019t decrease as quickly with age or mileage.", "To avoid getting tripped up by selection bias, it\u2019s good to be in the habit of asking two questions before building a model:", "Question #1 is the most important because if we don\u2019t understand the selection process, we can\u2019t make adjustments to our model or data. The ideal situation is to work only on problems like those in the physical sciences where each unit of observation is identical (e.g. electrons or bacteria) and all the variables of interest are manipulated independently to make causal inference easy and ensure the model will generalize perfectly to the entire population. But for industry applications, data collection is rarely owned by the data scientist, it may not match the operational conditions for a model, and data is rarely collected solely for the purpose of scientific investigation. Since data from the physical sciences tends to be the exception, not the rule for data science practitioners, good questions to ask include:", "For our 2nd question on selection bias, if the selection process for the training data is meaningfully different from the application, the first step is to attempt to quantify the difference. In the case of unsupervised learning or transfer learning problems, we can still evaluate differences in the feature distributions in a univariate fashion (which is easier) or on the joint distribution (which is harder). For supervised learning problems we can also compare differences in the target or the relationship between predictors and the target between the sample data and application.", "When we want to model P(Y | X) and there are changes to the distribution of X there are a host of techniques under the general heading of covariate shift and, with a relatively flexible model, adjusting for covariate shift is tractable. When P(Y) changes (prior probability shift) then calibration is usually an easy fix. When a data selection process (whether that process is known, latent, or due to a non-stationary environment) changes the relationship we learn between X and Y (concept shift) there\u2019s often no clever, algorithmic way to escape the problem with only the available data. In that situation there are 5 sensible approaches:", "Most practical applications suffer from some degree of selection bias. The most important thing is to understand it in order to make a conscious decision about the risk the bias presents and how to mitigate it in the construction or application of the model.", "The concept of operationalization is how to turn a fuzzy, real world, goal into a quantifiable problem. A simple example is the hypothesis that \u201csmoking causes cancer\u201d. Even with such an intuitive idea we still have to make decisions on how to quantify the hypothesis. For example, should we restrict our definition of \u201csmoking\u201d to tobacco? If so, how much or how long does someone have to smoke to qualify as a \u201csmoker\u201d? Is our definition of cancer restricted to lung cancer? And so on.", "What makes operationalization tricky in data science is that the fault often lies not in the data or an algorithm, but in ourselves. Our predispositions from our technical training often lead us to approaches that are familiar and comfortable, even when they may not be the right choice for the problem. Sometimes the most important questions are also the least obvious. To set up a new problem there are two background questions that are always good to think through:", "Is it appropriate to frame this question as a data science problem at all?", "In industry, questions that are non-scientific, prohibitively expensive, or not actionable are asked all the time. Before trying to answer whether Michael Jordan or LeBron James is the greatest basketball player of all time, ask whether the question is worth answering and, if so, is data science the right way to get the answer?", "What methodologies could be used to frame the question?", "We all tend to default to the tools and techniques that are most familiar to us, which can be a mistake. The problem of identity theft is a great example. Framing the problem as both a classification problem and an anomaly detection problem can lead to a better outcome. When data is dependent or we need to make causal inferences we have to deal with these issues even if most techniques don\u2019t make those guarantees. The problem should dictate the method, never the other way around.", "Once the background questions are addressed we can evaluate the more obvious technical topics:", "Decomposition \u2014 should the problem be decomposed into parts? Though end-to-end learning can be tempting for complex problems, as Andrew Ng points out in the chapter of \u201cMachine Learning Yearning\u201d on the Pros and Cons of End-to-End Learning it can require vastly more data and be harder to analyze and improve.", "Features \u2014 based on knowledge of the domain, are all the relevant measurements present? To what extent are latent features likely to have an impact? Has irrelevant data been excluded? If dealing with people, could the data lead to unfair or discriminatory treatment?", "Target \u2014 is the target the closest possible approximation of the desired outcome? Whether it\u2019s a multi-armed bandit or a classifier, the choice to model on concepts that seem close to a person, like revenue and profit, can make an enormous difference to a model.", "Objective Function \u2014 does the objective function optimize the right tradeoffs with the right constraints? Though the idea of minimizing RMSE or logloss is ubiquitous in supervised learning there may be more suitable approaches (e.g. different loss functions, cost sensitive machine learning, structured prediction, multi-objective optimization).", "Performance Evaluation \u2014 even in an ideal situation where a lot of thought is put into the loss function for a supervised learning problem, the function that is optimized is rarely the practical problem at hand. It is still a simplification and that tends to be even more true for high risk models where there may be constraints on aspects of the problem that are difficult to quantify like interpretability, computational complexity, or interaction with other systems. The final evaluation of a high risk model has to go beyond simple summary statistics and be evaluated against the intended use as closely as possible.", "Operationalization is one of the most challenging parts of any data science problem because it ties together some of the most artful and technical aspects in the field. It can be hard to come up with a good conceptual representation for a problem even with domain knowledge. It is at least equally hard, if not harder, to come up with empirical measurements and a mathematical representation for that concept. The good news is that when a problem is operationalized correctly \u2014 everything else becomes much easier.", "One of the ways that high risk problems differ from low risk ones is that we almost always want some evidence that a model uses information in a way that is consistent with our understanding of reality. Though \u201cwhite box\u201d models are often proposed as an alternative to \u201cblack box\u201d models like neural networks or ensemble methods to provide that evidence, the reality is that linear or logistic regression models aren\u2019t easy to interpret for most real-world problems and require a lot more work to achieve a similar level of predictive accuracy. When complex models fail the problem is almost never the degree of flexibility of the model, but rather some abuse that treats the input data, the algorithm, or the model\u2019s use of the input data as a black box.", "Faithfulness \u2014 a model\u2019s ability to generalize as advertised \u2014 can be even more important than accuracy for a high risk decision. For any high risk model it is always prudent to:", "Understand the algorithm \u2014 this seems obvious, but is at the root of many failures. Every algorithm has advantages, disadvantages, and assumptions. Whether it\u2019s the scale of the features or the dimensionality of the data, a practical working knowledge of an algorithm\u2019s limitations is as important as a reasonable theoretical understanding.", "Understand the features \u2014 even in situations where learning the feature representation is part of the modeling task, it is critical to understand what the input data is and how it will be used. Two great examples of why this is important are:", "Understand how the model uses features: there are a wide variety of ways to evaluate how a model, even a \u201cblack box\u201d model, uses data. With sparse data, manual inspection of every feature is infeasible but taking advantage of exponential decay in feature importance or special structure in the problem (like biclustering in bioinformatics) can still demonstrate the principle drivers in a model are conceptually correct even when behavior in a high-dimensional space with a large number of competing factors is hard to understand.", "Respect the effect of dataset bias \u2014 a myopic focus on hyperparameter optimization can lead us to believe model performance has improved, even though cross-dataset generalization or generalization to an out-of-time holdout is poor. Models that are robust to a change in operating conditions can be more appropriate for high-risk applications.", "Of course, sometimes in lieu of understanding how a model works, it\u2019s enough to understand how a model breaks \u2014 which we\u2019ll talk about in #5 on Error Analysis.", "Even a model built the right way on the right data still faces the hurdle of deployment. For a model to be useful, the output of the model has to make it out of the lab and back into the real world. Machine Learning: The High Interest Credit Card of Technical Debt is the authoritative reference on software engineering best practices for machine learning systems and I highly recommend it, so instead I\u2019ll focus specifically on a few practical considerations for deployment of high risk applications", "Differences in the hardware of the development environment and the intended application tend to be the most difficult to deal with, particularly if there are differences in floating point arithmetic. Luckily most of us only have to concern ourselves with the software layer where virtual machines and containers have made life easier. Regardless of method, the environment details need to match: The OS, language and package versions, etc. all need to line up. Unit tests and integration tests for models will often miss edge cases that can be introduced by the same fully functioning line of code executing with a subtle difference in two unique environments.", "To store, share, or replicate a model, it needs to be serialized to persistent storage. Unfortunately model serialization is still challenging for many practical applications. Native serialization formats, like pickle in Python or rds in R, and tool-specific serialization formats, like those in TensorFlow or mllib, are convenient, but almost always create problems. Security can be an issue, it can be difficult or inadvisable as a model ages to recreate the right execution environment, and there may be no simple way to distribute the model to a different platform. Though PMML is the industry-standard serialization format because it is language- and platform-independent, it also has drawbacks. PMML\u2019s emphasis is on portability, not performance; there are also only a limited number of model types available and extending the format to new types of models or transformations is a non-trivial amount of work. ONNX and ONNXML have started to bridge the gap between serialization formats for deep learning models and standard machine learning models, but are still in active development. Because there\u2019s rarely an obvious answer for serialization, in the end, it\u2019s always a good habit to store the data for a model and its training parameters so that it can be recreated from scratch if necessary.", "In my experience, features cause more failures than any other aspect of model deployment.", "Feature engineering often happens in a development environment that does not exactly match the production environment. Sometimes features written in development even have to be translated into a different programming language for production. The translation of features to a production environment opens the potential for errors. Although writing a production implementation of all features and extracting them through a production system for development, this often isn\u2019t feasible due to constraints on time and existing systems. Often the best we can do is resort to testing the production implementation against the development implementation on a shared data set and require a match up to floating point precision.", "Regardless of whether the data is derived from a sensor or an ORM, it is rare that a modeler owns or maintains the creation of data. In addition to the idea of leakage we reviewed in the \u201cBlack Box Abuse\u201d section, this challenge can show up in a couple different ways:", "The challenge complexity poses is nefarious because it is hard to define and harder to measure. As a model increases in complexity i.e. the more parameters, features, and dependencies it has, or the less transparent it is, or the more it demanding it is on hardware, whether that\u2019s CPU, GPU, RAM, or memory \u2014 the harder it is to deploy and maintain.", "And as Leon Bottou explains in his talk on the Two Big Challenges in Machine Learning, another aspect of managing complexity is that a model cannot be considered in isolation. A model operates in a dynamic ecosystem, especially for modern businesses where a model may be influenced by the decisions or output of other models.", "If we go all the way back to the contest that started it all, the $1 million dollar Netflix prize, the winning algorithm was never implemented because the performance benefits didn\u2019t justify the complexity. Before deploying a new champion model the performance benefits should always be weighed against simpler alternatives \u2014 especially in high risk applications where the downside risks may greatly outweigh incremental performance improvements.", "Unlike the sections on \u201cSelection Bias\u201d, \u201cOperationalization\u201d, or \u201cBlack Box Abuse\u201d that are mostly concerned with design and creation, the good news about deployment is that as long as we have these issues in mind when we write tests and create monitoring, we can develop an explicit recipe to avoid these problems.", "All models fail. All models are a brittle, simplified version of reality. No matter how clever or how accurate a model is, it has flaws. But if we can anticipate how a model will perform and understand how a model will fail, we can use it safely.", "Even when we do a good job optimizing for the right decision, it is almost always the case that our evaluation of it is still a simplification. After building a champion model we can perform error analysis to audit a model\u2019s performance in a few different ways that can be inconvenient during the training phases.", "\u201cAll models are wrong, but some are useful\u201d \u2014 George Box", "When possible, it\u2019s best to evaluate a new model against a \u201cgold standard\u201d model with known, good performance. Although everyone is used to the paradigm of evaluating a new \u201cchallenger\u201d model against a \u201cchampion\u201d in training/testing, it\u2019s worth noting that because our goal in error analysis is to search for important flaws sometimes it\u2019s preferable to evaluate a challenger model against the most robust, stable model available as opposed to the top-performing champion.", "What\u2019s overlooked more often is what to do in situations where there isn\u2019t an obvious champion or gold standard to compare to. In that situation there are still a couple of options. One is to create a simpler model purely for the sake of comparison. For example, if you\u2019ve built a GAM, compare it to a logistic regression model on the same data. If there\u2019s enough data and the relationships are nonlinear the GAM should outperform the logistic regression everywhere. The same analogy holds for any problem \u2014 if you apply BERT to your NLP problem and it doesn\u2019t out perform a bag of words approach, there\u2019s a problem.", "When time or other constraints prevent a simple model from being a realistic option, we can fall back to random number generation \u2014 which can be a surprisingly effective reality check. Humans are famously bad at recognizing what \u201crandom\u201d looks like and data scientists are no exception. Injecting a random uniform feature into a dataset or simulating a \u201cmodel\u201d by drawing random numbers from a distribution whose parameters match the target at least shows what could happen purely due to chance.", "It isn\u2019t correct to call residual analysis a lost art, because statisticians haven\u2019t forgotten about it. That said, it does tend to be underused by practitioners who didn\u2019t have formal training in statistics and I get the impression most people consider residual analysis only to be useful for linear models. While PDP, ICE, and SHAP plots are all good ways to interpret a model and sanity-check how the model uses features, to understand where a model goes wrong \u2014 nothing beats looking at residuals. Not all residuals are created equal, especially if time is a relevant dimension in a problem. When we\u2019re lucky, examining residuals can suggest changes to feature representation, model type, or opportunities to ensemble models. At worst, residual analysis can demonstrate a model\u2019s overall metrics aren\u2019t hiding diabolical behavior on the residuals where a small proportion of big residuals are counterbalanced by small average residuals.", "Sometimes breaking down a machine learning system into components to analyze performance is only obvious in hindsight. To come back to our original examples, there are a number of ways pedestrian detection for an autonomous vehicle could wrong. A model could be good at detecting a person in an image, but not location in the scene. Or it could be overfit to people close to any sort of \u201cstriped\u201d pattern whether that\u2019s a striped crosswalk or a striped shirt. The same is true for predicting credit card default risk. Predicting the probability of default at a 2 year horizon has a number of components wrapped up together. A model might be simply be very good at predicting short-term risk in the first 6 or 12 months, and no better than random after that. Breaking down a system into its component parts to measure where errors arise helps us understand how it works and where it fails.", "Like with residuals, the theme of component analysis is detecting unexpected errors. If we anticipated at the outset of building our model that certain components were going to be more difficult to model, we might have shaped our training set differently, added features to avoid paradoxical relationships, or created sub-models. The plain truth of the matter is that our starting assumption is many of the things we could measure or optimize for simply don\u2019t matter. Even for models or machine learning systems where we deeply care about accuracy and reliability, it is not practical to model and test every hypothesis. It is often much easier to check performance is as expected and errors are random after the fact than it is to prepare for all possibilities upfront.", "Most models don\u2019t require an interrogation to the 3rd degree. Some do. When preparing to build any model it is always prudent to consider the risk and reversibility of the decision the model will be used for. If a model will be used to make high risk, irreversible decisions \u2014 we, as scientists, should increase our skepticism and the rigor of our methods. Unfortunately, these 5 common causes of model failure don\u2019t come close to covering every possible failure mode. But they do make for a healthy reminder to help any practitioner avoid preventable mistakes \u2026 maybe even a billion dollar one.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Jason Capehart is the Director of Data Science at Mission Lane where he applies data science to build fair and clear credit."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fea586c621590&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ea586c621590--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ea586c621590--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jason.capehart?source=post_page-----ea586c621590--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jason.capehart?source=post_page-----ea586c621590--------------------------------", "anchor_text": "Jason Capehart"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F192734e09a34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&user=Jason+Capehart&userId=192734e09a34&source=post_page-192734e09a34----ea586c621590---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea586c621590&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea586c621590&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Subprime_mortgage_crisis", "anchor_text": "mortgage-backed securities"}, {"url": "https://unsplash.com/@timbatec?utm_source=medium&utm_medium=referral", "anchor_text": "Pepi Stojanovski"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Long-Term_Capital_Management", "anchor_text": "Long Term Capital Management"}, {"url": "http://individual.utoronto.ca/michael_miller/courses/sv_f17/documents/rudner_1953.pdf", "anchor_text": "philosophy of science for hypothesis testing"}, {"url": "https://unsplash.com/@mparzuchowski?utm_source=medium&utm_medium=referral", "anchor_text": "Micha\u0142 Parzuchowski"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://leon.bottou.org/slides/2challenges/2challenges.pdf", "anchor_text": "it may not match the operational conditions for a model"}, {"url": "https://www.investopedia.com/terms/f/flash-crash.asp", "anchor_text": "market drops by more than 10% in less than 10 minutes."}, {"url": "https://leon.bottou.org/slides/invariances/invariances.pdf", "anchor_text": "identifying causal relationships resolves many problems selection bias creates"}, {"url": "https://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf", "anchor_text": "possible to identify them"}, {"url": "https://unsplash.com/@chne_?utm_source=medium&utm_medium=referral", "anchor_text": "Tachina Lee"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1905.01772.pdf", "anchor_text": "decomposed into parts"}, {"url": "https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf", "anchor_text": "Pros and Cons of End-to-End Learning"}, {"url": "https://unsplash.com/@lakhani?utm_source=medium&utm_medium=referral", "anchor_text": "Ali Shah Lakhani"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.stat.cmu.edu/~cshalizi/350/lectures/17/lecture-17.pdf", "anchor_text": "aren\u2019t easy to interpret for most real-world problems"}, {"url": "https://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf", "anchor_text": "Leakage"}, {"url": "https://arxiv.org/pdf/1908.09635.pdf", "anchor_text": "Discrimination"}, {"url": "https://github.com/drivendataorg/deon", "anchor_text": "as simple as a good checklist"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "wide variety of ways to evaluate"}, {"url": "https://media.springernature.com/full/springer-static/image/art%3A10.1186%2F1471-2105-15-S6-S4/MediaObjects/12859_2014_Article_6393_Fig5_HTML.jpg", "anchor_text": "biclustering in bioinformatics"}, {"url": "http://www.wisdom.weizmann.ac.il/~vision/courses/2010_2/papers/datasets.pdf", "anchor_text": "cross-dataset generalization"}, {"url": "https://unsplash.com/@kjarrett?utm_source=medium&utm_medium=referral", "anchor_text": "Kevin Jarrett"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43146.pdf", "anchor_text": "Machine Learning: The High Interest Credit Card of Technical Debt"}, {"url": "https://docs.python.org/3/library/pickle.html", "anchor_text": "pickle"}, {"url": "https://stat.ethz.ch/R-manual/R-devel/library/base/html/readRDS.html", "anchor_text": "rds"}, {"url": "https://www.tensorflow.org/guide/saved_model", "anchor_text": "TensorFlow"}, {"url": "https://spark.apache.org/mllib/", "anchor_text": "mllib"}, {"url": "http://dmg.org/pmml/v4-3/GeneralStructure.html", "anchor_text": "PMML"}, {"url": "https://onnx.ai/", "anchor_text": "ONNX"}, {"url": "https://github.com/onnx/onnxmltools", "anchor_text": "ONNXML"}, {"url": "https://leon.bottou.org/slides/2challenges/2challenges.pdf", "anchor_text": "Two Big Challenges in Machine Learning"}, {"url": "https://www.wired.com/2012/04/netflix-prize-costs/", "anchor_text": "the winning algorithm was never implemented"}, {"url": "https://unsplash.com/@srd844?utm_source=medium&utm_medium=referral", "anchor_text": "Stephen Dawson"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT"}, {"url": "https://christophm.github.io/interpretable-ml-book/agnostic.html", "anchor_text": "PDP, ICE, and SHAP plots"}, {"url": "http://uc-r.github.io/dalex", "anchor_text": "looking at residuals"}, {"url": "https://unsplash.com/@jeremythomasphoto?utm_source=medium&utm_medium=referral", "anchor_text": "Jeremy Thomas"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ea586c621590---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ea586c621590---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/finance?source=post_page-----ea586c621590---------------finance-----------------", "anchor_text": "Finance"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ea586c621590---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----ea586c621590---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea586c621590&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&user=Jason+Capehart&userId=192734e09a34&source=-----ea586c621590---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea586c621590&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&user=Jason+Capehart&userId=192734e09a34&source=-----ea586c621590---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea586c621590&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ea586c621590--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fea586c621590&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ea586c621590---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ea586c621590--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ea586c621590--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ea586c621590--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ea586c621590--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ea586c621590--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ea586c621590--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ea586c621590--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ea586c621590--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jason.capehart?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jason.capehart?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jason Capehart"}, {"url": "https://medium.com/@jason.capehart/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "57 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F192734e09a34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&user=Jason+Capehart&userId=192734e09a34&source=post_page-192734e09a34--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F192734e09a34%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbillion-dollar-data-science-ea586c621590&user=Jason+Capehart&userId=192734e09a34&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}