{"url": "https://towardsdatascience.com/a-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b", "time": 1683010198.685693, "path": "towardsdatascience.com/a-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b/", "webpage": {"metadata": {"title": "A Novel Approach to Feature Importance \u2014 Shapley Additive Explanations | by Prakhar Rathi | Towards Data Science", "h1": "A Novel Approach to Feature Importance \u2014 Shapley Additive Explanations", "description": "Machine learning interpretability is a topic of growing importance in this field. Interpret means to explain or to present in understandable terms. In the context of ML systems, interpretability is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/a-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b?source=friends_link&sk=631fdb6b8ee878e0f0172edfc4afbcea", "anchor_text": "here", "paragraph_index": 0}, {"url": "http://arxiv.org/abs/1702.08608", "anchor_text": "Finale Doshi-Velez", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/feature-selection-techniques-1bfab5fe0784", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Mark_Cuban", "anchor_text": "Mark Cuban", "paragraph_index": 7}, {"url": "https://github.com/prakharrathi25/artificial-intelligence-for-trading/blob/master/part2_ai_algorithms_in_trading/quizzes_and_exercises/21_feature_importance/tree_shap_solution.ipynb", "anchor_text": "this notebook", "paragraph_index": 20}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data", "anchor_text": "House Prices Dataset", "paragraph_index": 23}, {"url": "https://github.com/slundberg/shap", "anchor_text": "shap", "paragraph_index": 25}], "all_paragraphs": ["If you\u2019re stuck behind a paywall, click here to get my friend link and view this article.", "Machine learning interpretability is a topic of growing importance in this field. Interpret means to explain or to present in understandable terms. In the context of ML systems, interpretability is the ability to explain or to present in understandable terms to a human[Finale Doshi-Velez]. When investments are at stake, institutions prefer models which are explainable over models which might be giving relatively better accuracy. Actually, a better way to say this would be that when you\u2019re dealing with real-world problems, machine learning interpretability becomes a part of the metric for a good model.", "Don\u2019t be the person who treats machine learning and deep learning as black boxes and thinks that stacking layers will increase accuracy.", "It\u2019s often the case that in business case applications, companies may choose to use a simple linear model as opposed to a complex non-linear model for the sake of interpretability. When you build a model, you\u2019ll need to be able to understand how it's making the predictions. This helps you figure out when the model will work well and when it won\u2019t work well (and that is where it will need human intervention). Often, you might have to explain your model to your clients and investors, especially when you\u2019re managing their money using that model. It doesn\u2019t just stop with managing investments but goes much beyond that \u2014 when you are using AI in healthcare, security, education etc. Basically anywhere outside of your jupyter notebook, the model interpretability becomes an important factor. In this article, I will discuss one such aspect of machine learning interpretability \u2014 feature importance. However, within that, I will be discussing a more novel approach called Shapley Additives. I have given a theoretical, mathematical and code explanation of the same.", "Here are the different parts of this article. Feel free to skip ahead to the part which you need to access.", "There are many different ways of increasing your model understanding and feature importance is one of them. Feature importance helps you estimate how much each feature of your data contributed to the model\u2019s prediction. After performing feature importance tests, you can figure out which features are making the most impact on your model\u2019s decision making. You can act on this by removing the features which have a low impact on the model\u2019s predictions and focussing on making improvements to the more significant features. This can improve model performance significantly.", "There are many ways to calculate feature importance. Some of the basic methods which use statmodels and scikit-learn have been discussed in the article here. However, a lot of people have written about conventional methods, hence, I want to discuss a new approach called Shapely Additive Explanations (ShAP). This method is considered somewhat better than the traditional sckit-learn methods because many of these methods can be inconsistent, which means that the features that are most important may not always be given the highest feature importance score. One example is that in the tree-based models which might give two equally important features different scores based on what level of splitting was done using the features. The features which split the model first might be given higher importance. This is the motivation for using the latest feature attribution method, Shapley Additive Explanations.", "Let\u2019s start with an example to get some intuition behind this method. Let\u2019s say you\u2019re Mark Cuban and you own a basketball team, let\u2019s say, Dallas Mavericks and you have 3 players \u2014Dirk Nowitzki (A), Michael Finley (B), Jason Kidd (C). You want to determine how much each player contributes to the final score of the team and obviously this does not mean that we just calculate the number of baskets each of them scored because that might work here but won\u2019t work from a machine learning perspective. We want to be able to quantify how much impact their presence has on their team\u2019s performance that extends beyond just calculating the number of baskets each player might have scored. The second reason is that not all of them might be playing in the same position. One of the players might play at an offensive position and the other might play at a defensive position and we want to be able to take that into account as well.", "One approach is that you calculate the team\u2019s performance with and without Player A. The impact of player A can be the difference between the team\u2019s performance with and without player A.", "This can be extended to each of the players and we can calculate their importance individually. This is the main intuition behind Shapely Additive Explanations. We estimate how important a model is by seeing how well the model performs with and without that feature for every combination of features. It is important to note that Shapley Additive Explanations calculates the local feature importance for every observation which is different from the method used in scikit-learn which computes the global feature importance. You can understand that the importance of a feature may not be uniform across all data points. So, local feature importance calculates the importance of each feature for each data point. A global measure refers to a single ranking of all features for the model. Local feature importance becomes relevant in certain cases as well, like, loan application where each data point is an individual person to ensure fairness and equity. I can also think of a hybrid example, like, credit card fraud detection where each person has multiple transactions. While each person will have a different feature importance ranking, there needs to be a global measure for all transactions to detect outliers in the transactions. I am writing this article from a financial perspective in mind and for that global feature importance is more relevant. You can get the global measure by aggregating the local feature importances for each data point.", "Note:- This is just an example and comparing the player stats may not be the owner\u2019s job but I like Mark Cuban on Shark Tank and, hence, the example.", "This method calculates something called Shapley values and based on coalition game theory. It was first introduced in 2017 by Lundberg, Scott M. and Su-In Lee [1]. The feature values of a data instance act as players in a coalition. Shapley values tell us how to fairly distribute the \u201cpayout\u201d (= the prediction) among the features. A \u201cplayer\u201d can be an individual feature or a group of features.", "This value is the average marginal contribution of a feature value across all the possible combinations of features. Let\u2019s extend the previous example and look at the number of points the team scored in every match for a season. We want to know how much Player A contributes to the points the team scores in a match. We will, hence, calculate the contribution of the feature Player A when it is added to a coalition of Player B and Player C.", "Note:- For this experiment, we need to have all the trials already done with and without each player. I am assuming that in a season there are matches where we can get the relevant data because there must be at least one match where each player was not picked while the other two were. Secondly, this is just an example and the metric could be anything from point difference to tournament rankings. I have just taken the total points for the ease of explanation.", "Step 1: Combination of Player B and Player C without Player A", "For this case, we can take an average of the points scored in all matches where players B and C were playing and Player A wasn\u2019t. We can also just sample one random example but I think the average/median is a better measure. Let\u2019s say the average was equal to 65 points.", "Step 2: Combination of Player B, Player A and Player C", "In this step, we will take an average of all those matches where Players A, B and C were playing and let\u2019s say that value is equal to 85 points.", "Hence, the contribution of A is 85\u201365 = 20 points. Intuitive enough, right? If you took one random sample then you should perform this experiment multiple times and average the difference.", "The Shapley value is the average of all the marginal contributions to all possible coalitions. The computation time increases exponentially with the number of features. One solution to keep the computation time manageable is to compute contributions for only a few samples of the possible coalitions. [2]", "You can look at this notebook for a more detailed explanation. Enough theory! Let\u2019s get our hands dirty with some code.", "Start by importing the necessary libraries.", "Read the data and preprocess it.", "I am working on the House Prices Dataset but you can use this method for any dataset. I am not spending a lot of time on the preprocessing and imputation but it is highly recommended that you do.", "The next step is fitting the model on the dataset.", "For this section, I will be using the shap library. This is a very powerful library and you should check out their different plots. Start by loading the JS visualisation code to the library.", "Explain the model\u2019s predictions using shap. Collect the explainer and the shap_values.", "The above explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue. Note that this plot can only be made for one observation. For this example, I have taken the 4th observation.", "To get an overview of which features are most important for a model we can plot the SHAP values of every feature for every sample. The plot below sorts features by the sum of SHAP value magnitudes over all samples, and uses SHAP values to show the distribution of the impacts each feature has on the model output. The color represents the feature value (red high, blue low).", "We can also just take the mean absolute value of the SHAP values for each feature to get a standard bar plot (produces stacked bars for multi-class outputs):", "These plots tell us which features are the most important for a model and hence, we can make our machine learning models more interpretable and explanatory. This is a very important step in your data science journey.", "I hope you learned something from this article. Looking forward to hearing your comments.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I like to write about data science, machine learning and finance. I document personal experiences and projects. I love to hike and swim! Reading when not coding"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd18af30fc21b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://prakharrathi.medium.com/?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": ""}, {"url": "https://prakharrathi.medium.com/?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "Prakhar Rathi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe38d814dd2c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&user=Prakhar+Rathi&userId=e38d814dd2c2&source=post_page-e38d814dd2c2----d18af30fc21b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd18af30fc21b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd18af30fc21b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@wesleyphotography?utm_source=medium&utm_medium=referral", "anchor_text": "Wesley Tingey"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/a-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b?source=friends_link&sk=631fdb6b8ee878e0f0172edfc4afbcea", "anchor_text": "here"}, {"url": "http://arxiv.org/abs/1702.08608", "anchor_text": "Finale Doshi-Velez"}, {"url": "https://towardsdatascience.com/feature-selection-techniques-1bfab5fe0784", "anchor_text": "here"}, {"url": "https://pixabay.com/users/hans2609-1855995/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1339071", "anchor_text": "hans hans"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1339071", "anchor_text": "Pixabay"}, {"url": "https://en.wikipedia.org/wiki/Mark_Cuban", "anchor_text": "Mark Cuban"}, {"url": "https://github.com/prakharrathi25/artificial-intelligence-for-trading/blob/master/part2_ai_algorithms_in_trading/quizzes_and_exercises/21_feature_importance/tree_shap_solution.ipynb", "anchor_text": "this notebook"}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data", "anchor_text": "House Prices Dataset"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "shap"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "https://christophm.github.io/interpretable-ml-book/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d18af30fc21b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d18af30fc21b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/feature-importance?source=post_page-----d18af30fc21b---------------feature_importance-----------------", "anchor_text": "Feature Importance"}, {"url": "https://medium.com/tag/shapley-values?source=post_page-----d18af30fc21b---------------shapley_values-----------------", "anchor_text": "Shapley Values"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d18af30fc21b---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd18af30fc21b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&user=Prakhar+Rathi&userId=e38d814dd2c2&source=-----d18af30fc21b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd18af30fc21b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&user=Prakhar+Rathi&userId=e38d814dd2c2&source=-----d18af30fc21b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd18af30fc21b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd18af30fc21b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d18af30fc21b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d18af30fc21b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d18af30fc21b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d18af30fc21b--------------------------------", "anchor_text": ""}, {"url": "https://prakharrathi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://prakharrathi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Prakhar Rathi"}, {"url": "https://prakharrathi.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "353 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe38d814dd2c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&user=Prakhar+Rathi&userId=e38d814dd2c2&source=post_page-e38d814dd2c2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8c6bffff71d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b&newsletterV3=e38d814dd2c2&newsletterV3Id=8c6bffff71d6&user=Prakhar+Rathi&userId=e38d814dd2c2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}