{"url": "https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571", "time": 1682995143.857625, "path": "towardsdatascience.com/language-translation-with-rnns-d84d43b40571/", "webpage": {"metadata": {"title": "Language Translation with RNNs. Build a recurrent neural network (RNN)\u2026 | by Thomas Tracey | Towards Data Science", "h1": "Language Translation with RNNs", "description": "Versi\u00f3n en espa\u00f1ol \u2014 A Spanish translation of this post is available here, courtesy of the Ibidem Group. Much\u00edsimas gracias Chema Besc\u00f3s! This post explores my work on the final project of the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://ttracey.com/", "anchor_text": "Thomas Tracey", "paragraph_index": 0}, {"url": "https://github.com/tommytracey/AIND-Capstone/blob/master/README.md", "anchor_text": "posted on Github", "paragraph_index": 0}, {"url": "https://www.ibidem-translations.com/edu/rnn-machine-translation/", "anchor_text": "Versi\u00f3n en espa\u00f1ol", "paragraph_index": 1}, {"url": "https://www.ibidem-translations.com/edu/rnn-machine-translation/", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://www.ibidem-translations.com/spanish.php", "anchor_text": "Ibidem Group", "paragraph_index": 1}, {"url": "https://www.linkedin.com/in/josemariabescos/", "anchor_text": "Chema Besc\u00f3s", "paragraph_index": 1}, {"url": "https://github.com/tommytracey/AIND-Capstone", "anchor_text": "final project", "paragraph_index": 2}, {"url": "https://www.udacity.com/course/ai-artificial-intelligence-nanodegree--nd898", "anchor_text": "Udacity Artificial Intelligence Nanodegree", "paragraph_index": 2}, {"url": "https://github.com/tommytracey/AIND-Capstone", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://github.com/udacity/aind2-nlp-capstone", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://www.washingtonpost.com/news/innovations/wp/2016/10/03/google-translate-is-getting-really-really-accurate", "anchor_text": "switching to deep learning produced a 60% increase in translation accuracy", "paragraph_index": 7}, {"url": "https://translate.google.com/", "anchor_text": "Google Translate", "paragraph_index": 7}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "The Unreasonable Effectiveness of Recurrent Neural Networks", "paragraph_index": 16}, {"url": "https://github.com/tommytracey/AIND-Capstone/blob/master/machine_translation.ipynb", "anchor_text": "Jupyter notebook in the project repo", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/One-hot#cite_note-2", "anchor_text": "run at a faster clock rate than other encodings", "paragraph_index": 28}, {"url": "https://en.oxforddictionaries.com/explore/how-many-words-are-there-in-the-english-language/", "anchor_text": "Oxford English Dictionary has 172,000 words", "paragraph_index": 29}, {"url": "http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/", "anchor_text": "Google\u2019s word2vec", "paragraph_index": 29}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe", "paragraph_index": 33}, {"url": "https://mubaris.com/2017/12/14/word2vec/", "anchor_text": "word2vec", "paragraph_index": 33}, {"url": "https://machinelearningmastery.com/transfer-learning-for-deep-learning/", "anchor_text": "transfer learning", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be", "anchor_text": "This article", "paragraph_index": 44}, {"url": "https://github.com/tommytracey/AIND-Capstone/blob/master/machine_translation.ipynb", "anchor_text": "here in the notebook", "paragraph_index": 45}, {"url": "https://tommytracey.github.io/AIND-Capstone/machine_translation.html", "anchor_text": ".html version", "paragraph_index": 45}, {"url": "https://tommytracey.github.io/AIND-Capstone/machine_translation.html", "anchor_text": "notebook", "paragraph_index": 46}, {"url": "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html", "anchor_text": "Google AI Blog", "paragraph_index": 47}, {"url": "https://linkedin.com/in/thomastracey", "anchor_text": "here on LinkedIn", "paragraph_index": 49}, {"url": "https://ttracey.com", "anchor_text": "my portfolio here", "paragraph_index": 49}], "all_paragraphs": ["Aug 29, 2018 by Thomas Tracey, originally posted on Github", "Versi\u00f3n en espa\u00f1ol \u2014 A Spanish translation of this post is available here, courtesy of the Ibidem Group. Much\u00edsimas gracias Chema Besc\u00f3s!", "This post explores my work on the final project of the Udacity Artificial Intelligence Nanodegree program. My goal is to help other students and professionals who are in the early phases of building their intuition in machine learning (ML) and artificial intelligence (AI).", "With that said, please keep in mind that I am a product manager by trade (not an engineer or data scientist). So, what follows is meant to be a semi-technical yet approachable explanation of the ML concepts and algorithms in this project. If anything covered below is inaccurate or if you have constructive feedback, I\u2019d love to hear from you.", "My Github repo for this project can be found here. The original Udacity source repo for this project is located here.", "In this project, I build a deep neural network that functions as part of a machine translation pipeline. The pipeline accepts English text as input and returns the French translation. The goal is to achieve the highest translation accuracy possible.", "The ability to communicate with one another is a fundamental part of being human. There are nearly 7,000 different languages worldwide. As our world becomes increasingly connected, language translation provides a critical cultural and economic bridge between people from different countries and ethnic groups. Some of the more obvious use-cases include:", "To meet these needs, technology companies are investing heavily in machine translation. This investment and recent advancements in deep learning have yielded major improvements in translation quality. According to Google, switching to deep learning produced a 60% increase in translation accuracy compared to the phrase-based approach previously used in Google Translate. Today, Google and Microsoft can translate over 100 different languages and are approaching human-level accuracy for many of them.", "However, while machine translation has made lots of progress, it\u2019s still not perfect. \ud83d\ude2c", "To translate a corpus of English text to French, we need to build a recurrent neural network (RNN). Before diving into the implementation, let\u2019s first build some intuition of RNNs and why they\u2019re useful for NLP tasks.", "RNNs are designed to take sequences of text as inputs or return sequences of text as outputs, or both. They\u2019re called recurrent because the network\u2019s hidden layers have a loop in which the output and cell state from each time step become inputs at the next time step. This recurrence serves as a form of memory. It allows contextual information to flow through the network so that relevant outputs from previous time steps can be applied to network operations at the current time step.", "This is analogous to how we read. As you read this post, you\u2019re storing important pieces of information from previous words and sentences and using it as context to understand each new word and sentence.", "Other types of neural networks can\u2019t do this (yet). Imagine you\u2019re using a convolutional neural network (CNN) to perform object detection in a movie. Currently, there\u2019s no way for information from objects detected in previous scenes to inform the model\u2019s detection of objects in the current scene. For example, if a courtroom and judge were detected in a previous scene, that information could help correctly classify the judge\u2019s gavel in the current scene, instead of misclassifying it as a hammer or mallet. But CNNs don\u2019t allow this type of time-series context to flow through the network like RNNs do.", "Depending on the use-case, you\u2019ll want to set up your RNN to handle inputs and outputs differently. For this project, we\u2019ll use a many-to-many process where the input is a sequence of English words and the output is a sequence of French words (fourth from the left in the diagram below).", "Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN\u2019s state (more on this soon).", "From left to right: (1) Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). (2) Sequence output (e.g. image captioning takes an image and outputs a sentence of words). (3) Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). (4) Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French). (5) Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like.", "\u2014 Andrej Karpathy, The Unreasonable Effectiveness of Recurrent Neural Networks", "Below is a summary of the various preprocessing and modeling steps. The high-level steps include:", "For a more detailed walkthrough including the source code, check out the Jupyter notebook in the project repo.", "We use Keras for the frontend and TensorFlow for the backend in this project. I prefer using Keras on top of TensorFlow because the syntax is simpler, which makes building the model layers more intuitive. However, there is a trade-off with Keras as you lose the ability to do fine-grained customizations. But this won\u2019t affect the models we\u2019re building in this project.", "Here is a sample of the data. The inputs are sentences in English; the outputs are the corresponding translations in French.", "When we run a word count, we can see that the vocabulary for the dataset is quite small. This was by design for this project. This allows us to train the models in a reasonable time.", "No additional cleaning needs to be done at this point. The data has already been converted to lowercase and split so that there are spaces between all words and punctuation.", "Note: For other NLP projects you may need to perform additional steps such as: remove HTML tags, remove stop words, remove punctuation or convert to tag representations, label the parts of speech, or perform entity extraction.", "Next, we need to tokenize the data \u2014 i.e., convert the text to numerical values. This allows the neural network to perform operations on the input data. For this project, each word and punctuation mark will be given a unique ID. (For other NLP projects, it might make sense to assign each character a unique ID.)", "When we run the tokenizer, it creates a word index, which is then used to convert each sentence to a vector.", "When we feed our sequences of word IDs into the model, each sequence needs to be the same length. To achieve this, padding is added to any sequence that is shorter than the max length (i.e. shorter than the longest sentence).", "In this project, our input sequences will be a vector containing a series of integers. Each integer represents an English word (as seen above). However, in other projects, sometimes an additional step is performed to convert each integer into a one-hot encoded vector. We don\u2019t use one-hot encoding (OHE) in this project, but you\u2019ll see references to it in certain diagrams (like the one below). I just didn\u2019t want you to get confused.", "One of the advantages of OHE is efficiency since it can run at a faster clock rate than other encodings. The other advantage is that OHE better represents categorical data where there is no ordinal relationship between different values. For example, let\u2019s say we\u2019re classifying animals as either a mammal, reptile, fish, or bird. If we encode them as 1, 2, 3, 4 respectively, our model may assume there is a natural ordering between them, which there isn\u2019t. It\u2019s not useful to structure our data such that mammal comes before reptile and so forth. This can mislead our model and cause poor results. However, if we then apply one-hot encoding to these integers, changing them to binary representations \u2014 1000, 0100, 0010, 0001 respectively \u2014 then no ordinal relationship can be inferred by the model.", "But, one of the drawbacks of OHE is that the vectors can get very long and sparse. The length of the vector is determined by the vocabulary, i.e. the number of unique words in your text corpus. As we saw in the data examination step above, our vocabulary for this project is very small \u2014 only 227 English words and 355 French words. By comparison, the Oxford English Dictionary has 172,000 words. But, if we include various proper nouns, words tenses, and slang there could be millions of words in each language. For example, Google\u2019s word2vec is trained on a vocabulary of 3 million unique words. If we used OHE on this vocabulary, the vector for each word would include one positive value (1) surrounded by 2,999,999 zeros!", "And, since we\u2019re using embeddings (in the next step) to further encode the word representations, we don\u2019t need to bother with OHE. Any efficiency gains aren\u2019t worth it on a data set this small.", "First, let\u2019s breakdown the architecture of an RNN at a high level. Referring to the diagram above, there are a few parts of the model we need to be aware of:", "Embeddings allow us to capture more precise syntactic and semantic word relationships. This is achieved by projecting each word into n-dimensional space. Words with similar meanings occupy similar regions of this space; the closer two words are, the more similar they are. And often the vectors between words represent useful relationships, such as gender, verb tense, or even geopolitical relationships.", "Training embeddings on a large dataset from scratch requires a huge amount of data and computation. So, instead of doing it ourselves, we normally use a pre-trained embeddings package such as GloVe or word2vec. When used this way, embeddings are a form of transfer learning. However, since our dataset for this project has a small vocabulary and low syntactic variation, we\u2019ll use Keras to train the embeddings ourselves.", "Our sequence-to-sequence model links two recurrent networks: an encoder and decoder. The encoder summarizes the input into a context variable, also called the state. This context is then decoded and the output sequence is generated.", "Since both the encoder and decoder are recurrent, they have loops which process each part of the sequence at different time steps. To picture this, it\u2019s best to unroll the network so we can see what\u2019s happening at each time step.", "In the example below, it takes four timesteps to encode the entire input sequence. At each time step, the encoder \u201creads\u201d the input word and performs a transformation on its hidden state. Then it passes that hidden state to the next time step. Keep in mind that the hidden state represents the relevant context flowing through the network. The bigger the hidden state, the greater the learning capacity of the model, but also the greater the computation requirements. We\u2019ll talk more about the transformations within the hidden state when we cover gated recurrent units (GRU).", "For now, notice that for each time step after the first word in the sequence there are two inputs: the hidden state and a word from the sequence. For the encoder, it\u2019s the next word in the input sequence. For the decoder, it\u2019s the previous word from the output sequence.", "Also, remember that when we refer to a \u201cword,\u201d we really mean the vector representation of the word which comes from the embedding layer.", "Here\u2019s another way to visualize the encoder and decoder, except with a Mandarin input sequence.", "Now that we understand how context flows through the network via the hidden state, let\u2019s take it a step further by allowing that context to flow in both directions. This is what a bidirectional layer does.", "In the example above, the encoder only has historical context. But, providing future context can result in better model performance. This may seem counterintuitive to the way humans process language since we only read in one direction. However, humans often require future context to interpret what is being said. In other words, sometimes we don\u2019t understand a sentence until an important word or phrase is provided at the end. Happens this does whenever Yoda speaks. \ud83d\ude11 \ud83d\ude4f", "To implement this, we train two RNN layers simultaneously. The first layer is fed the input sequence as-is and the second is fed a reversed copy.", "Now let\u2019s make our RNN a little bit smarter. Instead of allowing all of the information from the hidden state to flow through the network, what if we could be more selective? Perhaps some of the information is more relevant, while other information should be discarded. This is essentially what a gated recurrent unit (GRU) does.", "There are two gates in a GRU: an update gate and reset gate. This article by Simeon Kostadinov, explains these in detail. To summarize, the update gate (z) helps the model determine how much information from previous time steps needs to be passed along to the future. Meanwhile, the reset gate (r) decides how much of the past information to forget.", "Now that we\u2019ve discussed the various parts of our model, let\u2019s take a look at the code. Again, all of the source code is available here in the notebook (.html version).", "The results from the final model can be found in cell 20 of the notebook.", "Context-free models such as word2vec or GloVe generate a single word embedding representation for each word in the vocabulary. For example, the word \u201cbank\u201d would have the same context-free representation in \u201cbank account\u201d and \u201cbank of the river.\u201d Contextual models instead generate a representation of each word that is based on the other words in the sentence. For example, in the sentence \u201cI accessed the bank account,\u201d a unidirectional contextual model would represent \u201cbank\u201d based on \u201cI accessed the\u201d but not \u201caccount.\u201d However, BERT represents \u201cbank\u201d using both its previous and next context \u2014 \u201cI accessed the \u2026 account\u201d \u2014 starting from the very bottom of a deep neural network, making it deeply bidirectional. \u2014 Jacob Devlin and Ming-Wei Chang, Google AI Blog", "I hope you found this useful. Again, if you have any feedback, I\u2019d love to hear it. Feel free to post in the comments.", "If you\u2019d like to discuss other collaboration or career opportunities you can find me here on LinkedIn or view my portfolio here."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd84d43b40571&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@thomastracey?source=post_page-----d84d43b40571--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Thomas Tracey"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F49cc733eeb2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&user=Thomas+Tracey&userId=49cc733eeb2e&source=post_page-49cc733eeb2e----d84d43b40571---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd84d43b40571&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&user=Thomas+Tracey&userId=49cc733eeb2e&source=-----d84d43b40571---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd84d43b40571&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&source=-----d84d43b40571---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://ttracey.com/", "anchor_text": "Thomas Tracey"}, {"url": "https://github.com/tommytracey/AIND-Capstone/blob/master/README.md", "anchor_text": "posted on Github"}, {"url": "https://www.ibidem-translations.com/edu/rnn-machine-translation/", "anchor_text": "Versi\u00f3n en espa\u00f1ol"}, {"url": "https://www.ibidem-translations.com/edu/rnn-machine-translation/", "anchor_text": "here"}, {"url": "https://www.ibidem-translations.com/spanish.php", "anchor_text": "Ibidem Group"}, {"url": "https://www.linkedin.com/in/josemariabescos/", "anchor_text": "Chema Besc\u00f3s"}, {"url": "https://github.com/tommytracey/AIND-Capstone", "anchor_text": "final project"}, {"url": "https://www.udacity.com/course/ai-artificial-intelligence-nanodegree--nd898", "anchor_text": "Udacity Artificial Intelligence Nanodegree"}, {"url": "https://github.com/tommytracey/AIND-Capstone", "anchor_text": "here"}, {"url": "https://github.com/udacity/aind2-nlp-capstone", "anchor_text": "here"}, {"url": "https://www.washingtonpost.com/news/innovations/wp/2016/10/03/google-translate-is-getting-really-really-accurate", "anchor_text": "switching to deep learning produced a 60% increase in translation accuracy"}, {"url": "https://translate.google.com/", "anchor_text": "Google Translate"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "Andrej Karpathy"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "The Unreasonable Effectiveness of Recurrent Neural Networks"}, {"url": "https://github.com/tommytracey/AIND-Capstone/blob/master/machine_translation.ipynb", "anchor_text": "Jupyter notebook in the project repo"}, {"url": "https://en.wikipedia.org/wiki/One-hot#cite_note-2", "anchor_text": "run at a faster clock rate than other encodings"}, {"url": "https://en.oxforddictionaries.com/explore/how-many-words-are-there-in-the-english-language/", "anchor_text": "Oxford English Dictionary has 172,000 words"}, {"url": "http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/", "anchor_text": "Google\u2019s word2vec"}, {"url": "https://cbail.github.io/textasdata/word2vec/rmarkdown/word2vec.html", "anchor_text": "Chris Bail"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe"}, {"url": "https://mubaris.com/2017/12/14/word2vec/", "anchor_text": "word2vec"}, {"url": "https://machinelearningmastery.com/transfer-learning-for-deep-learning/", "anchor_text": "transfer learning"}, {"url": "https://classroom.udacity.com/nanodegrees/nd101/parts/4f636f4e-f9e8-4d52-931f-a49a0c26b710/modules/c1558ffb-9afd-48fa-bf12-b8f29dcb18b0/lessons/43ccf91e-7055-4833-8acc-0e2cf77696e8/concepts/be468484-4bd5-4fb0-82d6-5f5697af07da", "anchor_text": "Udacity"}, {"url": "https://classroom.udacity.com/nanodegrees/nd101/parts/4f636f4e-f9e8-4d52-931f-a49a0c26b710/modules/c1558ffb-9afd-48fa-bf12-b8f29dcb18b0/lessons/43ccf91e-7055-4833-8acc-0e2cf77696e8/concepts/f999d8f6-b4c1-4cd0-811e-4767b127ae50", "anchor_text": "Udacity"}, {"url": "https://xiandong79.github.io/seq2seq-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86", "anchor_text": "xiandong79.github.io"}, {"url": "https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be", "anchor_text": "This article"}, {"url": "https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/gru/", "anchor_text": "analyticsvidhya.com"}, {"url": "https://github.com/tommytracey/AIND-Capstone/blob/master/machine_translation.ipynb", "anchor_text": "here in the notebook"}, {"url": "https://tommytracey.github.io/AIND-Capstone/machine_translation.html", "anchor_text": ".html version"}, {"url": "https://tommytracey.github.io/AIND-Capstone/machine_translation.html", "anchor_text": "notebook"}, {"url": "https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0", "anchor_text": "some limitations"}, {"url": "https://github.com/tommytracey/udacity/tree/master/deep-learning-nano/projects/4-language-translation#build-the-neural-network", "anchor_text": "already implemented it in TensorFlow in another project"}, {"url": "https://arxiv.org/abs/1701.03360", "anchor_text": "this paper"}, {"url": "http://www.mdpi.com/2078-2489/9/3/56/pdf", "anchor_text": "here"}, {"url": "https://mubaris.com/2017/12/14/word2vec/", "anchor_text": "word2vec"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe"}, {"url": "https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a", "anchor_text": "universal embeddings"}, {"url": "https://allennlp.org/elmo", "anchor_text": "ELMo"}, {"url": "https://allennlp.org", "anchor_text": "Allen Institute for AI"}, {"url": "https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html", "anchor_text": "Transformers"}, {"url": "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html", "anchor_text": "BERT"}, {"url": "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html", "anchor_text": "Google AI Blog"}, {"url": "https://linkedin.com/in/thomastracey", "anchor_text": "here on LinkedIn"}, {"url": "https://ttracey.com", "anchor_text": "my portfolio here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d84d43b40571---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/recurrent-neural-network?source=post_page-----d84d43b40571---------------recurrent_neural_network-----------------", "anchor_text": "Recurrent Neural Network"}, {"url": "https://medium.com/tag/language-translation?source=post_page-----d84d43b40571---------------language_translation-----------------", "anchor_text": "Language Translation"}, {"url": "https://medium.com/tag/udacity?source=post_page-----d84d43b40571---------------udacity-----------------", "anchor_text": "Udacity"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd84d43b40571&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&user=Thomas+Tracey&userId=49cc733eeb2e&source=-----d84d43b40571---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd84d43b40571&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&user=Thomas+Tracey&userId=49cc733eeb2e&source=-----d84d43b40571---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd84d43b40571&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=post_page-----d84d43b40571--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F49cc733eeb2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&user=Thomas+Tracey&userId=49cc733eeb2e&source=post_page-49cc733eeb2e----d84d43b40571---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fee46c6a88c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&newsletterV3=49cc733eeb2e&newsletterV3Id=ee46c6a88c92&user=Thomas+Tracey&userId=49cc733eeb2e&source=-----d84d43b40571---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Written by Thomas Tracey"}, {"url": "https://medium.com/@thomastracey/followers?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "183 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F49cc733eeb2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&user=Thomas+Tracey&userId=49cc733eeb2e&source=post_page-49cc733eeb2e----d84d43b40571---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fee46c6a88c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-translation-with-rnns-d84d43b40571&newsletterV3=49cc733eeb2e&newsletterV3Id=ee46c6a88c92&user=Thomas+Tracey&userId=49cc733eeb2e&source=-----d84d43b40571---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey/recognizing-traffic-signs-with-cnns-23a4ac66f7a7?source=author_recirc-----d84d43b40571----0---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=author_recirc-----d84d43b40571----0---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=author_recirc-----d84d43b40571----0---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Thomas Tracey"}, {"url": "https://medium.com/@thomastracey/recognizing-traffic-signs-with-cnns-23a4ac66f7a7?source=author_recirc-----d84d43b40571----0---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Recognizing Traffic Signs with CNNsBuild a convolutional neural network that recognizes EU traffic signs."}, {"url": "https://medium.com/@thomastracey/recognizing-traffic-signs-with-cnns-23a4ac66f7a7?source=author_recirc-----d84d43b40571----0---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "17 min read\u00b7Feb 24, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F23a4ac66f7a7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thomastracey%2Frecognizing-traffic-signs-with-cnns-23a4ac66f7a7&user=Thomas+Tracey&userId=49cc733eeb2e&source=-----23a4ac66f7a7----0-----------------clap_footer----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey/recognizing-traffic-signs-with-cnns-23a4ac66f7a7?source=author_recirc-----d84d43b40571----0---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23a4ac66f7a7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thomastracey%2Frecognizing-traffic-signs-with-cnns-23a4ac66f7a7&source=-----d84d43b40571----0-----------------bookmark_preview----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d84d43b40571----1---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d84d43b40571----1---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d84d43b40571----1---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d84d43b40571----1---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d84d43b40571----1---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d84d43b40571----1---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d84d43b40571----1---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----d84d43b40571----1-----------------bookmark_preview----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d84d43b40571----2---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d84d43b40571----2---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d84d43b40571----2---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d84d43b40571----2---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d84d43b40571----2---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d84d43b40571----2---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d84d43b40571----2---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d84d43b40571----2-----------------bookmark_preview----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/training-two-agents-to-play-tennis-8285ebfaec5f?source=author_recirc-----d84d43b40571----3---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=author_recirc-----d84d43b40571----3---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=author_recirc-----d84d43b40571----3---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Thomas Tracey"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d84d43b40571----3---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/training-two-agents-to-play-tennis-8285ebfaec5f?source=author_recirc-----d84d43b40571----3---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "Training Two Agents to Play TennisDeep Reinforcement Learning for Multi-Agent Collaboration & Competition"}, {"url": "https://towardsdatascience.com/training-two-agents-to-play-tennis-8285ebfaec5f?source=author_recirc-----d84d43b40571----3---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": "16 min read\u00b7Feb 22, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8285ebfaec5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-two-agents-to-play-tennis-8285ebfaec5f&user=Thomas+Tracey&userId=49cc733eeb2e&source=-----8285ebfaec5f----3-----------------clap_footer----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/training-two-agents-to-play-tennis-8285ebfaec5f?source=author_recirc-----d84d43b40571----3---------------------6d7851d3_a0b0_4198_89ee_2a42f108673f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8285ebfaec5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-two-agents-to-play-tennis-8285ebfaec5f&source=-----d84d43b40571----3-----------------bookmark_preview----6d7851d3_a0b0_4198_89ee_2a42f108673f-------", "anchor_text": ""}, {"url": "https://medium.com/@thomastracey?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "See all from Thomas Tracey"}, {"url": "https://towardsdatascience.com/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d84d43b40571----0-----------------bookmark_preview----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----d84d43b40571----1-----------------bookmark_preview----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "LucianoSphere"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Build ChatGPT-like Chatbots With Customized Knowledge for Your Websites, Using Simple ProgrammingLike ChatGPT but in a form that you can plug into your website and expand with any kind of tailored information by combining basic\u2026"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "\u00b711 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&user=LucianoSphere&userId=d28939b5ab78&source=-----f393206c6626----0-----------------clap_footer----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----d84d43b40571----0---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&source=-----d84d43b40571----0-----------------bookmark_preview----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d84d43b40571----1---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----d84d43b40571----1-----------------bookmark_preview----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d84d43b40571----2---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----d84d43b40571----2---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----d84d43b40571----2---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Andrea D'Agostino"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d84d43b40571----2---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d84d43b40571----2---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "How to Train a Word2Vec Model from Scratch with GensimIn this article we will explore Gensim, a very popular Python library for training text-based machine learning models, to train a Word2Vec\u2026"}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d84d43b40571----2---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "\u00b79 min read\u00b7Feb 6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc457d587e031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031&user=Andrea+D%27Agostino&userId=4e8f67b0b09b&source=-----c457d587e031----2-----------------clap_footer----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d84d43b40571----2---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc457d587e031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031&source=-----d84d43b40571----2-----------------bookmark_preview----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d84d43b40571----3---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----d84d43b40571----3---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----d84d43b40571----3---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Skanda Vivek"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d84d43b40571----3---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d84d43b40571----3---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "Fine-Tune Transformer Models For Question Answering On Custom DataA tutorial on fine-tuning the Hugging Face RoBERTa QA Model on custom data and obtaining significant performance boosts"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d84d43b40571----3---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": "\u00b75 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&user=Skanda+Vivek&userId=220d9bbb8014&source=-----513eaac37a80----3-----------------clap_footer----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d84d43b40571----3---------------------6332b5ce_0164_420f_b2cf_dd2ed5200de3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&source=-----d84d43b40571----3-----------------bookmark_preview----6332b5ce_0164_420f_b2cf_dd2ed5200de3-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d84d43b40571--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----d84d43b40571--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}