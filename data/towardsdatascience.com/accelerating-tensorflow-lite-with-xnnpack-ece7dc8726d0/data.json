{"url": "https://towardsdatascience.com/accelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0", "time": 1683009090.682584, "path": "towardsdatascience.com/accelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0/", "webpage": {"metadata": {"title": "Accelerating Tensorflow Lite with XNNPACK | by Pieterluitjens | Towards Data Science", "h1": "Accelerating Tensorflow Lite with XNNPACK", "description": "TL;DR: The new Tensorflow Lite XNNPACK delegate enables best in-class performance on x86 and ARM CPUs \u2014 over 10x faster than the default Tensorflow Lite backend in some cases. Tensorflow Lite is one\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.tensorflow.org/lite/guide/roadmap", "anchor_text": "roadmap", "paragraph_index": 1}, {"url": "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/xnnpack", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark#on-android", "anchor_text": "benchmark tool", "paragraph_index": 4}, {"url": "https://github.com/yaysummeriscoming/xnnpack_benchmarks", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://developer.android.com/about/dashboards", "anchor_text": "here", "paragraph_index": 12}, {"url": "https://github.com/tensorflow/tensorflow/issues/34536", "anchor_text": "next release", "paragraph_index": 15}, {"url": "https://github.com/yaysummeriscoming/mobilenet_v3_tflite", "anchor_text": "here", "paragraph_index": 18}, {"url": "https://github.com/yaysummeriscoming/xnnpack_benchmarks", "anchor_text": "here", "paragraph_index": 18}, {"url": "http://www.private-ai.com", "anchor_text": "www.private-ai.com", "paragraph_index": 20}], "all_paragraphs": ["TL;DR: The new Tensorflow Lite XNNPACK delegate enables best in-class performance on x86 and ARM CPUs \u2014 over 10x faster than the default Tensorflow Lite backend in some cases.", "Tensorflow Lite is one of my favourite software packages. It enables easy and fast deployment on a range of hardware and now comes with a wide range of delegates to accelerate inference \u2014 GPU, Core ML and Hexagon, to name a few. One drawback of Tensorflow Lite however is that it\u2019s been designed with mobile applications in mind, and therefore isn\u2019t optimised for Intel & AMD x86 processors. Better x86 support is on the Tensorflow Lite development roadmap, but for now Tensorflow Lite mostly relies on converting ARM Neon instructions to SSE via the Neon_2_SSE bridge.", "There is however a new Tensorflow Lite delegate for CPU-based floating-point computations, XNNPACK, that does feature x86 AVX and AVX-512 optimizations. In this post I\u2019ll walk you through using XNNPACK and show some benchmarks.", "Instructions for using XNNPACK can be found here. Most notably, there\u2019s now a build flag that will enable the XNNPACK delegate by default. This is handy, as until now it wasn\u2019t possible to load Tensorflow Lite delegates in Python. The command to build Tensorflow from source would look like:", "The Tensorflow Lite benchmark tool also now has a flag to enable the XNNPACK delegate. For example, to profile on your x86 machine, first build the profiler tool:", "Then run the profiler with the following command:", "It is important to ensure that models are suitable for XNNPACK, as it only supports a subset of all Tensorflow Lite operators. For example, the standard Keras implementations often use explicit padding layers and implement the top global pooling layer via the mean operator. When using the normal TFLite backend this only increases runtime by a few percentage points, but these operations aren\u2019t supported by XNNPACK, resulting in considerable overhead \u2014 30% in the case of MobileNet V2 with 8 threads(see below)!", "Padding is easily fixed by replacing the explicit padding layers with padding built into the convolution operations:", "The global average pooling layer can be replaced by a average pooling layer with a large kernel:", "Note that you will have to retrain the model. You can find fixed versions of these models in the repo accompanying this article here.", "Ok, so benchmarks! First I decided to test MobileNet V3 on my Galaxy S8:", "I tested using 1 thread over 1000 iterations, with 50 warm up iterations.", "As you can see, XNNPACK offers excellent performance, on top of the standard Tensorflow Lite CPU backend. It\u2019s worth noting that XNNPACK supports ARM Float 16 instructions included in newer ARMv8.2-A CPUs (e.g., A55), but unfortunately I don\u2019t have one on hand. The GPU backend is still faster, especially for larger models. However, it requires OpenGL ES 3.1 or higher, which is only available on ~2/3 of all Android devices (see market share here.", "Now on to x86. I decided to compare against Intel\u2019s OpenVino package using MobileNet V2 and ResNet50. For testing I used a Google Cloud N2 Cascade Lake instance, with 8 vCPUs. With 1 thread:", "As you can see, Tensorflow Lite using the XNNPACK delegate performs admirably, in some cases over 10x faster than the default Tensorflow Lite backend. Performance approaches that of OpenVino for MobileNet V2, but falls short for ResNet 50. I don\u2019t see this as a huge issue however, as depthwise convolution based architectures such as MobileNet V2 are far better suited for CPU deployment. XNNPACK also features better scaling over multiple CPU cores than the standard backend. Note that the TFLite benchmark tool corresponds to OpenVINO\u2019s latency mode, so it would be interesting to see what XNNPACK could deliver if configured for throughput.", "Tensorflow Lite can now offer great x86 performance via the new XNNPACK delegate, outperforming Intel\u2019s OpenVino package in some cases. The main drawback of XNNPACK is that it is designed for floating point computation only. 8-bit model quantization can easily result in a >2x performance increase, with an even higher increase when deployed on the new Intel Cascade Lake CPUs which support AVX-512 VNNI instructions. Support for 8-bit quantization on x86 is on the Tensorflow Lite roadmap, perhaps even in the next release.", "Similarly, for mobile deployments, XNNPACK outperforms the Tensorflow Lite default backend. Whilst the GPU delegate is still faster than XNNPACK, XNNPACK is useful on devices that don\u2019t support GPU computation.", "I\u2019m especially excited about XNNPACK because it simplifies the deployment process by allowing one to stay within the Tensorflow ecosystem. It is now possible to convert a model once with Tensorflow Lite and deploy to multiple platforms, reducing the number of different software packages required. It\u2019s also worth noting that AMD processors are becoming less of a rarity, and OpenVino is an Intel product. I tried to test on a Google Cloud N2D EYPC instance, but unfortunately, I couldn\u2019t get my quota increased.", "I hope you found this article helpful. The code to reproduce these benchmarks is located here and here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML Engineer focusing on edge & MLOps. Co-Founder and CTO of Private AI www.private-ai.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fece7dc8726d0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@pieterluitjens?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pieterluitjens?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "Pieterluitjens"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc9ecbc5d6813&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&user=Pieterluitjens&userId=c9ecbc5d6813&source=post_page-c9ecbc5d6813----ece7dc8726d0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fece7dc8726d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fece7dc8726d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.flickr.com/photos/spacex/49421604803https://www.flickr.com/photos/spacex/49421604803", "anchor_text": "Flickr"}, {"url": "https://www.tensorflow.org/lite/guide/roadmap", "anchor_text": "roadmap"}, {"url": "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/xnnpack", "anchor_text": "here"}, {"url": "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark#on-android", "anchor_text": "benchmark tool"}, {"url": "https://github.com/yaysummeriscoming/xnnpack_benchmarks", "anchor_text": "here"}, {"url": "https://developer.android.com/about/dashboards", "anchor_text": "here"}, {"url": "https://github.com/tensorflow/tensorflow/issues/34536", "anchor_text": "next release"}, {"url": "https://github.com/yaysummeriscoming/mobilenet_v3_tflite", "anchor_text": "here"}, {"url": "https://github.com/yaysummeriscoming/xnnpack_benchmarks", "anchor_text": "here"}, {"url": "https://medium.com/tag/tensorflow-lite?source=post_page-----ece7dc8726d0---------------tensorflow_lite-----------------", "anchor_text": "Tensorflow Lite"}, {"url": "https://medium.com/tag/ml-engineering?source=post_page-----ece7dc8726d0---------------ml_engineering-----------------", "anchor_text": "ML Engineering"}, {"url": "https://medium.com/tag/inference?source=post_page-----ece7dc8726d0---------------inference-----------------", "anchor_text": "Inference"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ece7dc8726d0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----ece7dc8726d0---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fece7dc8726d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&user=Pieterluitjens&userId=c9ecbc5d6813&source=-----ece7dc8726d0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fece7dc8726d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&user=Pieterluitjens&userId=c9ecbc5d6813&source=-----ece7dc8726d0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fece7dc8726d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fece7dc8726d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ece7dc8726d0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ece7dc8726d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pieterluitjens?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pieterluitjens?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Pieterluitjens"}, {"url": "https://medium.com/@pieterluitjens/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "44 Followers"}, {"url": "http://www.private-ai.com", "anchor_text": "www.private-ai.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc9ecbc5d6813&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&user=Pieterluitjens&userId=c9ecbc5d6813&source=post_page-c9ecbc5d6813--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa9ec15378f74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccelerating-tensorflow-lite-with-xnnpack-ece7dc8726d0&newsletterV3=c9ecbc5d6813&newsletterV3Id=a9ec15378f74&user=Pieterluitjens&userId=c9ecbc5d6813&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}