{"url": "https://towardsdatascience.com/a-different-kind-of-deep-learning-part-1-90fe6c52f1ab", "time": 1682994052.980681, "path": "towardsdatascience.com/a-different-kind-of-deep-learning-part-1-90fe6c52f1ab/", "webpage": {"metadata": {"title": "A different kind of (deep) learning: part 1 | by Gidi Shperber | Towards Data Science", "h1": "A different kind of (deep) learning: part 1", "description": "Deep learning has truly reshuffled things in machine learning field, and specifically in image recognition tasks. In 2012, Alex-net has initiated a (still far from ending) race towards solving, or at\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1811.11553.pdf", "anchor_text": "this", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1301.3781", "anchor_text": "word embeddings", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1603.08511.pdf", "anchor_text": "this", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/CIELAB_color_space", "anchor_text": "Lab", "paragraph_index": 17}, {"url": "https://arxiv.org/pdf/1603.08511.pdf", "anchor_text": "article", "paragraph_index": 22}, {"url": "https://people.cs.uchicago.edu/~larsson/colorization/", "anchor_text": "paper", "paragraph_index": 28}, {"url": "https://arxiv.org/abs/1505.05192", "anchor_text": "work", "paragraph_index": 34}, {"url": "https://en.wikipedia.org/wiki/Chromatic_aberration", "anchor_text": "chromatic aberration", "paragraph_index": 37}, {"url": "https://arxiv.org/pdf/1603.09246", "anchor_text": "paper", "paragraph_index": 38}, {"url": "https://arxiv.org/abs/1604.07379", "anchor_text": "article", "paragraph_index": 40}, {"url": "https://openreview.net/forum?id=S1v4N2l0-", "anchor_text": "paper", "paragraph_index": 42}], "all_paragraphs": ["Deep learning has truly reshuffled things in machine learning\u00a0field, and specifically in image recognition tasks. In 2012, Alex-net has initiated a (still far from ending) race towards solving, or at least significantly improving, computer vision tasks. And while the main idea is quite stable (use deep neural networks for everything) researchers took quite different paths:", "Each of these research paths improves training quality (speed, accuracy, sometimes generalization), but it seems that doing more of the same thing may result in some gradual improvements, but not a in significant breakthrough.", "On the other hand, growing body of work in deep learning shows that there are significant flaws in current methods, especially in terms of generalization, e.g this recent one: generalization failure when objects are rotated:", "So there seems to be a need of improvements that are a bit more aggressive. Or perhaps expanding the research spectrum to ideas that may be a bit riskier.", "Along with the aforementioned approaches, there are also directions which try to shift the learning paradigm. May it be:", "These approaches take some different training paradigms, try to be more creative, or mimic some human-like patterns. Although we are yet to have evidence from the above methods (and others) to reach a significant breakthroughs, they do reach some non-trivial results, and also teach us a lot about training process.", "In this and the following posts, I will try to discuss some of the most interesting approaches,\u00a0and\u00a0dub\u00a0the\u00a0series by the name \u201cDifferent kinds of (deep) learning\u201d. I by no means try to predict the future developments in deep learning, but merely to describe recent interesting works, that perhaps doesn\u2019t get the spotlight. This may serve the readers for a few purposes:", "The first part of this series will be about self supervised learning that was one of the main drivers for me to write this series.", "Imagine you have an agent that scours the web, and seamlessly learns from every image it encounters. This notion is quite intriguing, since if it will be realized, the greatest considered barrier for deep learning, the annotated data, will be (partially) removed.", "But how can it be done? well, it was first suggested in text: text is well structured by humans, therefore there are many concepts that can be learned from it without any annotations. Predicting the next/previous word is a prominent example, as done in word embeddings and language models tasks.", "In vision, doing such tricks is a bit more complex, since the vision data (images and videos) are not human created explicitly (well, some photographer may put certain amount of thought in his photography) but not every video, and definitely not every image has any kind of logicial structure that can be used to extract signal from.", "Isn\u2019t it just another form of unsupervised learning? indeed, but it has a special subtlety: since the tasks are supervised (e.g. classification) but no active annotation has taken place. This topic is\u00a0one\u00a0of\u00a0my\u00a0favorites, and has quickly became the main topic of this article. I can\u2019t promise that this specific paradigm will bring the best achievements to deep learning, but it is definitely already brought some great creative ideas.", "As said, the name of such tasks is Self Supervised Learning. Unlike \u201cweak annotations\u201d which mean images with different tags, headers, or captions, self-supervised task considered to have no annotations but the image itself. If you ask what can be learned from an image with no annotations, stay tuned.", "Perhaps the most intuitive signal in an image, is it\u2019s color. When there are 3 channels in most of computerized color representations, 1 or 2 can seamlessly be used as annotation.", "Since colorizing old images is an interesting task, there are many works that address it. However, if we consider fully automated colorization (which qualifies as self-supervised) the numbers dwindle down to quite a few.", "The colorization task in this case is formed as a \u201ccross channel encoder\u201d, which means that one (or some) channels in the image are used to encode other. This concept will be discussed further in later posts.", "The most noticeable colorization paper is this one, by Richard Zhang and Alexei Efros.", "The common way to address colorization tasks, is not using the standard RGB encoding, but using the Lab color space. In Lab colorspace, L stands for lightness (B&W intensity) and is used for predicting ab channels (a\u200a\u2014\u200agreen to red, b\u200a\u2014\u200ablue to yellow).", "As we will see in all tasks we discuss, self supervised learning is not as straightforward as we got used to in deep learning. There are some artifacts that interrupt the model achieving what it was designed to. Additionally, sometimes if training was not examined carefully, model will make \u201cshortcuts\u201d that will hinder it from generalizing to other tasks.", "Here are some challenges of the colorization task:", "1. Inherent ambiguity in colorization: It is clear that for some images there is more than one plausible colorization. This issue causes multiple problems either in training and evaluation:", "In the Donald Trump image below, the color of the curtains may either red or blue (and many others). Donald\u2019s tie can match (or not). Given different examples of ties and curtains in the dataset, the model will tend to average them, coloring such items in grey.", "Solution: In Zhang\u2019s article, the researchers treat the colorization as a classification problem instead of regression. Along with using a special loss function, their model predicts a probability distribution layer instead of the actual colors of the image, and then translates these probabilities to colors \u2014 out of 313 available colors in Lab space:", "2. Bias: Lab is not an evenly distributed space. most of solutions tend towards the lower values, due to high frequency of clouds, pavements etc.", "Solution: a reweight of loss function takes place to address this issue.", "3. Evaluation problem: Now that the model can predict different answers which are correct, e.g if the ground truth is blue and the model will choose red, in a standard evaluation it will be considered wrong.", "Solution: using different evaluation methods, among others: human post-hok classification \u2014 \u201cColorization Turing test\u201d, where people were asked to tell between the real image, and machine colorized one. Additionally, feeding the images into an image classifier, comparing the results with real images.", "The model scored 35% in the Colorization Turing test, which is\u2026 not so bad.", "In another recent paper, Larson et al worked concurrently to Zhang and Efros (both papers mention each other) and used spatially localized multi-layer slices (hyper- columns) and regression loss. They\u2019ve tried to overcome the ambiguity issue by predicting a color histogram, and sampling from it:", "This work, apart from using the LAB space, also tries to predict Hue/Chroma attributes, which is related to as \u201cHSV\u201d color space.", "Besides the color prediction, the next most evident (but also creative) task is learning things from image structure. More precisely, trying to predict something about image crops.", "The inspiration for this task came directly from word2vec, and perhaps we can call it the \u201cskip gram\u201d of images.", "However, in text, number of words is limited to the size of the vocabulary, and will probably not exceed 1 Million. While completing an image patch pixel by pixel resides in a much larger space. You may say that GANs do exactly that but:", "In this kinds of paradigm, the actual task doesn\u2019t emerge naturally: researchers have to come up with \u201cgames\u201d for the models to solve. Will go through some prominent examples:", "The easiest way to extract context from images was using jigsaw-like tasks. First one was a work by Doersch and Efros: patches were cropped from images, and model was trained to classify their relation. an illustration will best explain it:", "As in colorization, task was not straightforward. Specifically, model was looking for \u201cshortcuts\u201d: instead of actually learning the high level features and their relations, it may learn certain low level features, such as edges, and lighting relations. which tend to hint the image part.", "To Solve this problem, the researchers applied some jitter on the patches (As seen in the illustration)", "Another issue the researchers suffered from was the model predicting patch location by some lighting artifact \u2014 chromatic aberration. This means that in some cameras distribution of color varies in different parts of the image. Solution: this was partially handled by some color transformation, specifically shifting green and magenta towards grey.", "The next prominent result was this paper by Noroozi and Favaro, went all the way and used a harder problem, of solving full 9 part jigsaw, but reached a stronger performance in return:", "The researchers applied verification of good shuffling of patches and more then 1 shuffling sample per image.", "As said, word2vec in text fills in the missing word. Are there any attempts of doing this in vision? In a matter of fact, there are. In this article, Pathak et al (and of course Efros) have tried a few auto-encoder models to fill in a cropped space on images.", "Results show it is actually possible, especially with adding adversarial loss, which succeeded in avoiding handling multi modes (as discussed previously), thus preventing blurred, \u201caveraged\u201d result.", "Before we jump ahead to next level stuff, I want to mention this tidbit: rotation prediction. This paper approached took the creative approach of predicting image rotation.", "Rotation prediction, apart from being creative, is relatively fast, and doesn\u2019t require any kind of prepossessing as in other tasks we\u2019ve seen before, to overcome learning of trivial features.", "Paper also explores some \u201cAttention maps\u201d which show their network focuses on the important parts of images: heads, eyes, etc.", "Although reporting state of the art results on transfer learning to imageNet classification (most other works relate to pascal), some flaws were found in the paper by reviewers, so it has to be taken with a grain of salt.", "So after all this work, what do we get from it? sure, coloring B&W images is nice, and solving jigsaws may be a fun demo app, but the greater goal is to achieve better results, in the main tasks \u2014 especially classification, detection and segmentation.", "The most common benchmark is the VOC Pascal dataset, with current state of the art, when imagenet pretraining is used:", "Well, it seems we are not there yet. Although self-supervised data is practically unlimited, there have yet to be a work to challenge \u201cclassic\u201d Imagenet-based transfer learning results. However, there are a few nice results on specific tasks that we will discuss in later posts.", "Besides the standard generalization on to above tasks, the researchers exploit the specific features of this set of tasks to try and generalize some other tasks, such as image clustering (nearest neighbors, visual data mining, etc)", "Will the next big step will come from self-supervised learning? maybe, or maybe not, but I believe that exploring such different approaches significantly improves the deep learning field, and may indirectly positively influence the real breakthroughs. In the next post we will learn about more ideas and methods, that lead to some interesting and novel results.", "If you wish to read further, stay tuned (and follow me) for the next parts of this series. additionally, here are some resources that immensely helped me in studying and learning these topic:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F90fe6c52f1ab&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://gidishperber.medium.com/?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": ""}, {"url": "https://gidishperber.medium.com/?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "Gidi Shperber"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1dbbeb01604b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&user=Gidi+Shperber&userId=1dbbeb01604b&source=post_page-1dbbeb01604b----90fe6c52f1ab---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F90fe6c52f1ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F90fe6c52f1ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/1811.11553.pdf", "anchor_text": "this"}, {"url": "https://arxiv.org/abs/1301.3781", "anchor_text": "word embeddings"}, {"url": "https://arxiv.org/pdf/1603.08511.pdf", "anchor_text": "this"}, {"url": "https://en.wikipedia.org/wiki/CIELAB_color_space", "anchor_text": "Lab"}, {"url": "https://arxiv.org/pdf/1603.08511.pdf", "anchor_text": "article"}, {"url": "https://people.cs.uchicago.edu/~larsson/colorization/", "anchor_text": "paper"}, {"url": "https://arxiv.org/abs/1505.05192", "anchor_text": "work"}, {"url": "https://en.wikipedia.org/wiki/Chromatic_aberration", "anchor_text": "chromatic aberration"}, {"url": "https://arxiv.org/pdf/1603.09246", "anchor_text": "paper"}, {"url": "https://arxiv.org/abs/1604.07379", "anchor_text": "article"}, {"url": "https://openreview.net/forum?id=S1v4N2l0-", "anchor_text": "paper"}, {"url": "https://www.youtube.com/watch?v=YhYsvD6IfKE", "anchor_text": "here"}, {"url": "https://docs.google.com/viewer?url=http%3A%2F%2Fwinsty.net%2Ftalks%2Fself_supervised.pptx", "anchor_text": "deck"}, {"url": "https://towardsdatascience.com/a-different-kind-of-deep-learning-part-2-b447ff469255", "anchor_text": "Self Supervised learning: generative approaches"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----90fe6c52f1ab---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----90fe6c52f1ab---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----90fe6c52f1ab---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----90fe6c52f1ab---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F90fe6c52f1ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&user=Gidi+Shperber&userId=1dbbeb01604b&source=-----90fe6c52f1ab---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F90fe6c52f1ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&user=Gidi+Shperber&userId=1dbbeb01604b&source=-----90fe6c52f1ab---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F90fe6c52f1ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F90fe6c52f1ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----90fe6c52f1ab---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----90fe6c52f1ab--------------------------------", "anchor_text": ""}, {"url": "https://gidishperber.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://gidishperber.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Gidi Shperber"}, {"url": "https://gidishperber.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.8K Followers"}, {"url": "http://Shibumi.AI", "anchor_text": "Shibumi.AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1dbbeb01604b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&user=Gidi+Shperber&userId=1dbbeb01604b&source=post_page-1dbbeb01604b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Faa67cb16739c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-different-kind-of-deep-learning-part-1-90fe6c52f1ab&newsletterV3=1dbbeb01604b&newsletterV3Id=aa67cb16739c&user=Gidi+Shperber&userId=1dbbeb01604b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}