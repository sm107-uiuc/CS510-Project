{"url": "https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158", "time": 1683017666.875206, "path": "towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158/", "webpage": {"metadata": {"title": "Production Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical Performance | by Alejandro Saucedo | Towards Data Science", "h1": "Production Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical Performance", "description": "In this article we present an end-to-end example showcasing best practices, principles, patterns and techniques around monitoring of machine learning models in production. We will show how to adapt\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb", "anchor_text": "jupyter notebook provided", "paragraph_index": 6}, {"url": "https://www.cs.toronto.edu/~kriz/cifar.html", "anchor_text": "CIFAR10 dataset", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "Residual Network", "paragraph_index": 12}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html", "anchor_text": "Language Wrappers", "paragraph_index": 19}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/servers/overview.html", "anchor_text": "Prepackaged Model Servers", "paragraph_index": 19}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/servers/tensorflow.html", "anchor_text": "Tensorflow Prepackaged Model", "paragraph_index": 19}, {"url": "https://github.com/kubernetes-sigs/kind", "anchor_text": "KIND (Kubernetes in Docker)", "paragraph_index": 22}, {"url": "https://github.com/kubernetes/minikube", "anchor_text": "Minikube,", "paragraph_index": 22}, {"url": "https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb", "anchor_text": "Notebook for this example", "paragraph_index": 22}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html", "anchor_text": "Seldon documentation", "paragraph_index": 22}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/ingress/istio.html", "anchor_text": "the ingress", "paragraph_index": 28}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/examples/metrics.html#Install-Seldon-Analytics", "anchor_text": "Seldon Core Analytics package", "paragraph_index": 35}, {"url": "https://knative.dev/docs/eventing/", "anchor_text": "KNative Eventing", "paragraph_index": 39}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/analytics/log_level.html", "anchor_text": "forward payloads to further components", "paragraph_index": 40}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html", "anchor_text": "process events", "paragraph_index": 40}, {"url": "https://en.wikipedia.org/wiki/Root-mean-square_deviation", "anchor_text": "RMSE", "paragraph_index": 43}, {"url": "https://en.wikipedia.org/wiki/Relative_entropy", "anchor_text": "KL Divergence", "paragraph_index": 43}, {"url": "https://docs.seldon.io/projects/alibi-detect/en/stable/examples/od_vae_cifar10.html", "anchor_text": "Alibi Detect Variational Auto Encoder", "paragraph_index": 60}, {"url": "https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html", "anchor_text": "Kolmogorov-Smirnov data drift detector on CIFAR-10", "paragraph_index": 76}, {"url": "https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_image_imagenet.html", "anchor_text": "Anchor Explanation", "paragraph_index": 93}], "all_paragraphs": ["\u201cThe lifecycle of a machine learning model only begins once it\u2019s in production\u201d", "In this article we present an end-to-end example showcasing best practices, principles, patterns and techniques around monitoring of machine learning models in production. We will show how to adapt standard microservice monitoring techniques towards deployed machine learning models, as well as more advanced paradigms including concept drift, outlier detection and AI explainability.", "We will train an image classification machine learning model from scratch, deploy it as a microservice in Kubernetes, and introduce a broad range of advanced monitoring components. The monitoring components will include outlier detectors, drift detectors, AI explainers and metrics servers \u2014 we will cover the underlying architectural patterns used for each, which are developed with scale in mind, and designed to work efficiently across hundreds or thousands of heterogeneous machine learning models.", "You can also view this blog post in video form, which was presented as the keynote at the PyCon Hong Kong 2020 \u2014 the main delta is that the talk uses an Iris Sklearn model for the e2e example instead of the CIFAR10 Tensorflow model.", "In this article we present an end-to-end hands on example covering each of the high level concepts outlined in the sections below.", "We will be using the following open source frameworks in this tutorial:", "You can find the full code for this article in the jupyter notebook provided which will allow you to run all relevant steps throughout the model monitoring lifecycle.", "Monitoring of production machine learning is hard, and it becomes exponentially more complex once the number of models and advanced monitoring components grows. This is partly due to how different production machine learning systems are compared to traditional software microservice-based systems \u2014 some of these key differences are outlined below.", "The anatomy of production machine learning involves a broad range of complexities that range across the multiple stages of the model\u2019s lifecycle. This includes experimentation, scoring, hyperparameter tuning, serving, offline batch, streaming and beyond. Each of these stages involve potentially different systems with a broad range of heterogeneous tools. This is why it is key to ensure we not only learn how we are able to introduce model-specific metrics to monitor, but that we identify the higher level architectural patterns that can be used to enable the deployed models to be monitored effectively at scale. This is what we will cover in each of the sections below.", "We will be using the intuitive CIFAR10 dataset. This dataset consists of images that can be classified across one of 10 classes. The model will take as an input an array of shape 32x32x3 and as output an array with 10 probabilities for which of the classes it belongs to.", "We are able to load the data from the Tensorflow datasets \u2014 namely:", "In order for us to train and deploy our machine learning model, we will follow the traditional machine learning workflow outlined in the diagram below. We will be training a model which we will then be able to export and deploy.", "We will be using Tensorflow to train this model, leveraging the Residual Network which is arguably one of the most groundbreaking architectures as it makes it possible to train up to hundreds or even thousands of layers with good performance. For this tutorial we will be using the Resnet32 implementation, which fortunately we\u2019ll be able to use through the utilities provided by the Alibi Detect Package.", "Using my GPU this model took about 5 hours to train, luckily we will be able to use a pre-trained model which can be retrieved using the Alibi Detect fetch_tf_model utils.", "If you want to still train the CIFAR10 resnet32 tensorflow model, you can use the helper utilities provided by the Alibi Detect package as outlined below, or even just import the raw Network and train it yourself.", "We can now test the trained model on \u201cunseen data\u201d. We can test it using a CIFAR10 datapoint that would be classified as a truck. We can have a look at the datapoint by plotting it using Matplotlib.", "We can now process that datapoint through the model, which as you can imagine should be predicted as a \u201ctruck\u201d.", "We can find the class predicted by finding the index with the highest probability, which in this case it is index 9with a high probability of 99%. From the names of the classes (e.g. cifar_classes[ np.argmax( X_curr_pred )]) we can see that class 9 is \u201ctruck\u201d.", "We will be using Seldon Core for the deployment of our model into Kubernetes, which provides multiple options to convert our model into a fully fledged microservice exposing REST, GRPC and Kafka interfaces.", "The options we have to deploy models with Seldon Core include 1) the Language Wrappers to deploy our Python, Java, R, etc code classes, or 2) the Prepackaged Model Servers to deploy model artifacts directly. In this tutorial we will be using the Tensorflow Prepackaged Model server to deploy the Resnet32 model we were using earlier.", "This approach will allow us to take advantage of the cloud native architecture of Kubernetes which powers large scale microservice systems through horizontally scalable infrastructure. We will be able to learn about and leverage cloud native and microservice patterns adopted to machine learning throughout this tutorial.", "The diagram below summarises the options available to deploy model artifacts or the code itself, together with the abilities we have to deploy either a single model, or build complex inference graphs.", "As a side note, you can get set up you on Kubernetes using a development environment like KIND (Kubernetes in Docker) or Minikube, and then following the instructions in the Notebook for this example, or in the Seldon documentation. You will need to make sure you install Seldon with a respective ingress provider like Istio or Ambassador so you can send the REST requests.", "To simplify the tutorial, we have already uploaded the trained Tensorflow Resnet32 model, which can be found this public Google bucket: gs://seldon-models/tfserving/cifar10/resnet32. If you have trained your model, you are able to upload it to the bucket of your choice, which can be Google Bucket, Azure, S3 or local Minio. Specifically for Google you can do it using the gsutil command line with the command below:", "We can deploy our model with Seldon using the custom resource definition configuration file. Below is the script that converts the model artifact into a fully fledged microservice.", "We can now see that the model has been deployed and is currently running.", "We can now test our deployed model by sending the same image of the truck, and see if we still have the same prediction.", "We will be able to do this by sending a REST request as outlined below, and then print the results.", "The output of the code above is the JSON response of the POST request to the url that Seldon Core provides us through the ingress. We can see that the prediction is correctly resulting in the \u201ctruck\u201d class.", "The first monitoring pillar we will be covering is the good old performance monitoring, which is the traditional and standard monitoring features that you would find in the microservices and infrastructure world. Of course in our case we will be adopting it towards deployed machine learning models.", "Some high level principles of machine learning monitoring include:", "For this we will be able to introduce the first two core frameworks which are commonly used across production systems:", "Seldon Core provides integration with Prometheus and Elasticsearch out of the box for any model deployed. During this tutorial we will be referencing Elasticsearch but to simplify the intuitive grasp of several advanced monitoring concepts we will be using mainly Prometheus for metrics and Grafana for the visualisations.", "In the diagram below you can visualise how the exported microservice enables any containerised model to export both metrics and logs. The metrics are scraped by prometheus, and the logs are forwarded by the model into elasticsearch (which happens through the eventing infrastructure we cover in the next section. For explicitness it is worth mentioning that Seldon Core also supports Open Tracing metrics using Jaeger, which shows the latency throughout all microservice hops in the Seldon Core model graph.", "Some examples of performance monitoring metrics that are exposed by Seldon Core models, and that can be also added through further integrations include:", "For this tutorial you can set up Prometheus and Grafana by using the Seldon Core Analytics package that sets everything up for metrics to be collected in real time, and then visualised on the dashboards.", "We can now visualise the utilization metrics of the deployed models relative to their specific infrastructure. When deploying a model with Seldon you will have multiple attributes that you will want to take into consideration to ensure optimal processing of your models. This includes the allocated CPU, Memory and Filesystem store reserved for the application, but also the respective configuration for running processes and threads relative to the allocated resources and expected requests.", "Similarly, we are also able to monitor the usage of the model itself \u2014 every seldon model exposes model usage metrics such as requests-per-second, latency per request, success/error codes for models, etc. These are important as they are able to map into the mode advanced/specialised concepts of the underlying machine learning model. Large latency spikes could be diagnosed and explained based on the underlying requirements of the model. Similarly errors that the model displays are abstracted into simple HTTP error codes, which allows for standardisation of advanced ML components into microservice patterns that then can be managed more easily at scale by DevOps / IT managers.", "In order for us to be able to leverage the more advanced monitoring techniques, we will first introduce briefly the eventing infrastructure that allows Seldon to use advanced ML algorithms for monitoring of data asynchronously and in a scalable architecture.", "Seldon Core leverages KNative Eventing to enable Machine Learning models to forward the inputs and outputs of the model into the more advanced machine learning monitoring components like outlier detectors, concept drift detectors, etc.", "We will not be going into too much detail on the eventing infrastructure that KNative introduces, but if you are curious there are multiple hands on examples in the Seldon Core documentation in regards to how it leverages the KNative Eventing infrastructure to forward payloads to further components such as Elasticsearch, as well as how Seldon models can also be connected to process events.", "For this tutorial, we need to enable our model to forward all the payload inputs and ouputs processed by the model into the KNative Eventing broker, which will enable all other advanced monitoring components to subscribe to these events.", "The code below adds a \u201clogger\u201d attribute to the deployment configuration which specifies the broker location.", "Performance metrics are useful for general monitoring of microservices, however for the specialised world of machine learning, there are widely-known and widely-used metrics that are critical throughout the lifecycle of the model beyond the training phase. More common metrics can include accuracy, precision, recall, but also metrics like RMSE, KL Divergence, between many many more.", "The core theme of this article is not just to specify how these metrics can be calculated, as it\u2019s not an arduous task to enable an individual microservice to expose this through some Flask-wrapper magic. The key here is to identify scalable architectural patterns that we can introduce across hundreds or thousands of models. This means that we require a level of standardisation on the interfaces and patterns that are required to map the models into their relevant infrastructure.", "Some high level principles that revolve around more specialised machine learning metrics are the following:", "Given that we have these requirements, Seldon Core introduces a set of architectural patterns that allow us to introduce the concept of \u201cExtensible Metrics Servers\u201d. These metric servers contain out-of-the-box ways to process data that the model processes by subscribing to the respective eventing topics, to ultimately expose metrics such as:", "From an architectural perspective, this can be visualised more intuitively in the diagram above. This showcases how a single datapoint can be submitted through the model, and then processed by any respective Metric Servers. The metric servers can also process the \u201ccorrect/annotated\u201d labels once they are provided, which can be linked with the unique prediction ID that Seldon Core adds on every request. The specialised metrics are calculated and exposed by fetching the relevant data from the Elasticsearch store.", "Currently, Seldon Core provides the following set of out-of-the-box Metrics Servers:", "For this example we will be able to deploy a Metric Server of the type \u201cMulticlassOneHot\u201d \u2014 you can see the parameters used in the summarised code below, but you can find the full YAML in the jupyter notebook.", "Once we deploy our metrics server, we can now just send requests and feedback to our CIFAR10 model, through the same microservice endpoint. To simplify the workflow, we will not send asynchronous feedback (which would perform the comparisons with the elasticsearch data), but instead we\u2019ll send \u201cself-contained\u201d feedback requests, which contain the inference \u201cresponse\u201d and the inference \u201ctruth\u201d.", "The following function provides us with a way to send a bunch of feedback requests to achieve an approximate accuracy percent (number of correct vs incorrect predictions) for our usecase.", "Now we can first send feedback to get 90% accuracy, and then to make sure our graphs look pretty, we can send another batch request that would result in 40% accuracy.", "This now basically gives us the ability to visualise the metrics that the MetricsServer calculates in real time.", "From the dashboard above we can get a high level intuition of the type of metrics that we are able to get through this architectural pattern. The stateful statistical metrics above in particular require extra metadata to be provided asynchronously, however even though the metrics themselves may have very different ways of being calculated, we can see that the infrastructural and architectural requirements can be abstracted and standardised in order for these to be approached in a more scalable way.", "We will continue seeing this pattern as we delve further into the more advanced statistical monitoring techniques.", "For a more advanced monitoring technique, we will be leveraging the Alibi Detect library, particularly around some of the advanced outlier detector algorithms it provides. Seldon Core provides us with a way to perform the deployment of outlier detectors as an architectural pattern, but also provides us with a prepackaged server that is optimized to serve Alibi Detect outlier detector models.", "Some of the key principles for outlier detection include:", "In the case of outlier detectors it is especially important to allow for the calculations to be performed separate to the model, as these tend to be much heaver and may require more specialised components. An outlier detector that is deployed, may come with similar complexities to the ones from a machine learning model, so it\u2019s important that the same concepts of compliance, governance and lineage are covered with these advanced components.", "The diagram below shows how the requests are forwarded by the model using the eventing infrastructure. The outlier detector then processes the datapoint to calculate whether it\u2019s an outlier. The component is then able to store the outlier data in the respective request entry asynchronously, or alternatively it is able to expose the metrics to prometheus, which is what we will visualise in this section.", "For this example we will be using the Alibi Detect Variational Auto Encoder outlier detector technique. The outlier detector is trained on a batch of unlabeled but normal (inlier) data. The VAE detector tries to reconstruct the input it receives, if the input data cannot be reconstructed well, then it is flagged as an outlier.", "Alibi Detect provides us with utilities that allow us to export the outlier detector from scratch. We can fetch it using the fetch_detector function.", "If you want to train the outlier, you can do so by simply leveraging the OutlierVAE class together with the respective encoder and decoders.", "To test the outlier detector we can take the same picture of the truck and see how the outlier detector behaves if noise is added to the image increasingly. We will also be able to plot it using the Alibi Detect visualisation function plot_feature_outlier_image.", "We can create a set of modified images and run it through the outlier detector using the code below.", "We now have an array of modified samples in the variable all_X_mask , each with an increasing amount of noise. We can now run all these 10 through the outlier detector.", "When looking at the results, we can see that the first 3 were not marked as outliers, whereas the rest were marked as outliers \u2014 we can see it by printing the value print(od_preds[\u201cdata\u201d][\u201cis_outlier\u201d]). Which displays the array below, where 0 is non-outliers and 1 is outliers.", "We can now visualise how the outlier instance level score maps against the threshold, which reflects the results in the array above.", "Similarly we can dive deeper into the intuition of what the outlier detector score channels look like, as well as the reconstructed images, which should provide a clear picture of how its internals operate.", "We will now be able to productionise our outlier detector. We will be leveraging a similar architectural pattern to the one from the metric servers. Namely the Alibi Detect Seldon Core server, which will be listening to the inference input/output of the data. For every data point that goes through the model, the respective outlier detector will be able to process it.", "The main step required will be to first ensure the outlier detector we trained above is uploaded to an object store like Google bucket. We have already uploaded it to gs://seldon-models/alibi-detect/od/OutlierVAE/cifar10, but if you wish you can upload it and use your own model.", "Once we deploy our outlier detector, we will be able to send a bunch of requests, many which will be outliers and others that won\u2019t be.", "We can now visualise some outliers in the dashboard \u2014 for every data point there will be a new entry point and will include whether it would be an outlier or not.", "As time passes, data in real life production environments can change. Whilst this change is not drastic, it can be identified through drifts in the distribution of the data itself particularly in respect to the predicted outputs of the model.", "Key principles in drift detection include:", "In the concept of drift detection we deal with further complexities when compared to the outlier detection usecase. The main one being the requirement to run each drift prediction on a batch input as opposed to a single datapoint. The diagram below shows a similar workflow to the one outlied in the outlier detector pattern, the main difference is that it keeps a tumbling or sliding window of data to perform the processing against.", "For this example we will once again be using the Alibi Detect library, which provides us with the Kolmogorov-Smirnov data drift detector on CIFAR-10.", "For this technique will be able to use the KSDrift class to create and train the drift detector, which also requires a preprocessing step which uses an \u201cUntrained Autoencoder (UAE)\u201d.", "In order for us to test the outlier detector we will generate a set of detectors with corrupted data. Alibi Detect provides a great set of utilities that we can use to generate corruption/noise into images in an increasing way. In this case we will be using the following noise: [\u2018gaussian_noise\u2019, \u2018motion_blur\u2019, \u2018brightness\u2019, \u2018pixelate\u2019]. These will be generated with the code below.", "Below is one datapoint from the created corrupted dataset, which contains images with an increasing amount of corruption of the different types outlined above.", "We can now attempt to run a couple of datapoints to compute whether drift is detected or not. The initial batch will consist of datapoints from the original dataset.", "This as expected outputs: Drift? No!", "Similarly we can run it against the corrupted dataset.", "And we can see that all of them are marked as drift as expected:", "Now we can move towards deploying our drift detector following the architectural pattern provided above. Similar to the outlier detector we first have to make sure that the drift detector we trained above can be uploaded to an object store. We currently will be able to use the Google bucket that we have prepared under gs://seldon-models/alibi-detect/cd/ks/drift to perform the deployment.", "This will have a similar structure, the main difference is that we will also specify the desired batch size to use for the Alibi Detect server to keep as a buffer before running against the model. In this case we select a batch size of 1000.", "Now that we have deployerd our outlier detector, we first try sending 1000 requests from the normal dataset.", "Next we can send the corrupted data, which would result in drift detected after sending the 10k datapoints.", "We are able to visualise each of the different drift points detected in the Grafana dashboard.", "AI Explainability techniques are key to understanding the behaviour of complex black box machine learning models. There is a broad range of content that explores the different algorithmic techniques that can be used in different contexts. Our current focus in this context is to provide an intuition and a practical example of the architectural patterns that can allow for explainer components to be deployed at scale. Some key principles of model explainability include:", "There are a broad range of different techniques available around explainability, but it\u2019s important to understand the high level themes around the different types of Explainers. These include:", "For explainers as interfaces, these have similarities in the data flow patterns. Namely many of them require interacting with the data that the model processes, as well as the ability to interact with the model itself \u2014 for black box techniques it includes the inputs/outputs whereas for white-box techniques it includes the internals of the models themselves.", "From an architectural perspective, this involves primarily a separate microservice which instead of just receiving an inference request, it would be able to interact with the respective model and \u201creverse engineer\u201d the model by sending the relevant data. This is shown in the diagram above, but it will become more intuitive once we dive into the example.", "For the example, we will be using the Alibi Explain framework, and we will use the Anchor Explanation technique. This local explanation technique tells us what are the features in a particular data point with the highest predictive power.", "We can simply create our Anchor explainer by specifying the structure of our dataset, together with a lambda that allows the explainer to interact with the model\u2019s predict function.", "We are able to identify what are the anchors in our model that would predict in this case the image of the truck.", "We can visualise the anchors by displaying the output anchor of the explanation itself.", "We can see that the anchors of the image include the windshield and the wheels of the truck.", "Here you can see that the explainer interacts with our deployed model. When deploying the explainer we will be following the same principle but instead of using a lambda that runs the model locally, this will be a function that will call the remote model microservice.", "We will follow a similar approach where we\u2019ll just need to upload the image above to an object store bucket. Similar to the previous example, we have provided a bucket under gs://seldon-models/tfserving/cifar10/explainer-py36\u20130.5.2. We will now be able to deploy an explainer, which can be deployed as part of the CRD of the Seldon Deployment.", "We can check that the explainer is running with kubectl get pods | grep cifar , which should output both running pods:", "Similar to how we send a request to the model, we are able to send a request to the explainer path. This is where the explainer will interact with the model itself and print the reverse engineered explanation.", "We can see that the output of the explanation is the same as the one we saw above.", "Finally we can also see some of the metric related components that come out of the explainer themselves, which can then be visualised through dashboards.", "Similar to the other microservice based machine learning components deployed, the explainers also can expose these and other more specialised metrics for performance or advanced monitoring.", "Before wrapping up, one thing to outline is the importance of abstracting these advanced machine learning concepts into standardised architectural patterns. The reason why this is crucial is primarily to enable machine learning systems for scale, but also to allow for advanced integration of components across the stack.", "All the advanced architectures covered above not only are applicable across each of the advanced components, but it is also possible to enable for what we can refer to as \u201censemble patterns\u201d \u2014 that is, connecting advanced components on the outputs of other advanced components.", "It is also important to ensure there are structured and standardised architectural patterns also enable developers to provide the monitoring components, which are also advanced machine learning models, have the same level of governance, compliance and lineage required in order to manage the risk efficiently.", "These patterns are continuously being refined and evolved through the Seldon Core project, and advanced state of the art algorithms on outlier detection, concept drift, explainability, etc are improving continuously \u2014 if you are interested on furthering the discussion, please feel free to reach out. All the examples in this tutorial are open source, so suggestions are greatly appreciated.", "If you are interested in further hands on examples of scalable deployment strategies of machine learning models, you can check out:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Chief Scientist @ The Institute for Ethical AI & Machine learning | Engineering Director @ Seldon | Member at Large @ ACM | Building the future of production ML"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd9b1d02ac158&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278----d9b1d02ac158---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9b1d02ac158&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9b1d02ac158&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/notes-from-industry", "anchor_text": "Notes from Industry"}, {"url": "https://github.com/tensorflow/tensorflow", "anchor_text": "Tensorflow"}, {"url": "https://github.com/SeldonIO/alibi", "anchor_text": "Alibi Explain"}, {"url": "https://github.com/SeldonIO/alibi-detect", "anchor_text": "Albi Detect"}, {"url": "https://github.com/SeldonIO/seldon-core/", "anchor_text": "Seldon Core"}, {"url": "https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb", "anchor_text": "jupyter notebook provided"}, {"url": "https://www.cs.toronto.edu/~kriz/cifar.html", "anchor_text": "CIFAR10 dataset"}, {"url": "https://www.cs.toronto.edu/~kriz/cifar.html", "anchor_text": "CIFAR10 dataset"}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "Residual Network"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html", "anchor_text": "Language Wrappers"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/servers/overview.html", "anchor_text": "Prepackaged Model Servers"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/servers/tensorflow.html", "anchor_text": "Tensorflow Prepackaged Model"}, {"url": "https://github.com/kubernetes-sigs/kind", "anchor_text": "KIND (Kubernetes in Docker)"}, {"url": "https://github.com/kubernetes/minikube", "anchor_text": "Minikube,"}, {"url": "https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb", "anchor_text": "Notebook for this example"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html", "anchor_text": "Seldon documentation"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/ingress/istio.html", "anchor_text": "the ingress"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/examples/metrics.html#Install-Seldon-Analytics", "anchor_text": "Seldon Core Analytics package"}, {"url": "https://knative.dev/docs/eventing/", "anchor_text": "KNative Eventing"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/analytics/log_level.html", "anchor_text": "forward payloads to further components"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html", "anchor_text": "process events"}, {"url": "https://en.wikipedia.org/wiki/Root-mean-square_deviation", "anchor_text": "RMSE"}, {"url": "https://en.wikipedia.org/wiki/Relative_entropy", "anchor_text": "KL Divergence"}, {"url": "https://docs.seldon.io/projects/alibi-detect/en/stable/examples/od_vae_cifar10.html", "anchor_text": "Alibi Detect Variational Auto Encoder"}, {"url": "https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html", "anchor_text": "Kolmogorov-Smirnov data drift detector on CIFAR-10"}, {"url": "https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_image_imagenet.html", "anchor_text": "Anchor Explanation"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/examples/argo_workflows_batch.html", "anchor_text": "Batch Processing with Argo Workflows"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html", "anchor_text": "Serverless eventing with Knative"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/analytics/explainers.html", "anchor_text": "AI Explainability Patterns with Alibi"}, {"url": "https://docs.seldon.io/projects/seldon-core/en/latest/examples/sklearn_spacy_text_classifier_example.html", "anchor_text": "Seldon Model Containerisation Notebook"}, {"url": "https://github.com/SeldonIO/seldon-core/blob/master/examples/kafka/sklearn_spacy/README.ipynb", "anchor_text": "Kafka Seldon Core Stream Processing Deployment Notebook"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d9b1d02ac158---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/monitoring?source=post_page-----d9b1d02ac158---------------monitoring-----------------", "anchor_text": "Monitoring"}, {"url": "https://medium.com/tag/mlops?source=post_page-----d9b1d02ac158---------------mlops-----------------", "anchor_text": "Mlops"}, {"url": "https://medium.com/tag/alibi?source=post_page-----d9b1d02ac158---------------alibi-----------------", "anchor_text": "Alibi"}, {"url": "https://medium.com/tag/notes-from-industry?source=post_page-----d9b1d02ac158---------------notes_from_industry-----------------", "anchor_text": "Notes From Industry"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd9b1d02ac158&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&user=Alejandro+Saucedo&userId=32de426f7278&source=-----d9b1d02ac158---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd9b1d02ac158&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&user=Alejandro+Saucedo&userId=32de426f7278&source=-----d9b1d02ac158---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9b1d02ac158&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd9b1d02ac158&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d9b1d02ac158---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d9b1d02ac158--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/@AxSaucedo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "616 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1b4684c4c42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158&newsletterV3=32de426f7278&newsletterV3Id=b1b4684c4c42&user=Alejandro+Saucedo&userId=32de426f7278&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}