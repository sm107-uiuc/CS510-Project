{"url": "https://towardsdatascience.com/automate-data-cleaning-with-unsupervised-learning-2046ef59ac17", "time": 1683000394.203321, "path": "towardsdatascience.com/automate-data-cleaning-with-unsupervised-learning-2046ef59ac17/", "webpage": {"metadata": {"title": "Automate Data Cleaning with Unsupervised Learning | by Marco Cerliani | Towards Data Science", "h1": "Automate Data Cleaning with Unsupervised Learning", "description": "I like working with textual data. As for Computer Vision, in NLP nowadays there are a lot of ready accessible resources and opensource projects, which we can directly download or consume. Some of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/benhamner/nips-2015-papers#Papers.csv", "anchor_text": "dataset on Kaggle", "paragraph_index": 4}, {"url": "https://nips.cc/", "anchor_text": "Neural Information Processing Systems", "paragraph_index": 4}, {"url": "https://www.kaggle.com/pkugoodspeed/nlpword2vecembeddingspretrained", "anchor_text": "available here", "paragraph_index": 9}], "all_paragraphs": ["I like working with textual data. As for Computer Vision, in NLP nowadays there are a lot of ready accessible resources and opensource projects, which we can directly download or consume. Some of them are cool and permit us to speed up and bring to another level our projects.", "The most important thing we must not forget is that all these instruments aren\u2019t magic. Some of them declare high performances but they are nothing if we don\u2019t allow them to make the best. This is a hard truth especially in the NLP field, where we often face a high level of noise in the data which is very difficult to remove (more difficult than working with images).", "In this post, I propose my solution to improve the quality of textual data at my disposal. I develop a workflow which aims to clean data AUTOMATICALLY and in an UNSUPERVISED way. I say \u2018automatically\u2019 because it is useless to follow an unsupervised approach if we have to check manually all the time the data to understand what the model outputs. We need certainties and don\u2019t want to lose our time.", "Here, my goal is to \u2018clean\u2019 research papers. In this situation, cleaning means to hold the relevant part of the text, throwing away pieces containing not valuable information. In the subset of machine learning papers, I consider as relevant part the textual sentences and as useless the pieces containing, for the majority, algebra and notations. Direct access to these pieces can facilitate tasks such as topic modeling, summarization, clustering and so on.", "I found the \u2018NIPS 2015 Papers\u2019 dataset on Kaggle. I directly download the Paper.csv. This dataset contains 403 papers from NIPS 2015 (Neural Information Processing Systems; one of the top machine learning conferences in the world, covering topics from deep learning and computer vision to cognitive science and reinforcement learning).", "The power is provided by the usage of a pre-trained model for word embeddings and its relative deep vocabulary.", "I compute a standard preprocess removing numbers, not alphanumeric characters and stopwords from a single paper of interest. The key points here are provided by the creation of sentences/paragraphs. There are some packages which provide this functionality; I tried them but they didn\u2019t convince me so much. So I personally wrote my own simple functions which better meet my needs, when I deal with textual corpus coming from whole documents.", "A good numerical representation of sentences is fundamental for the success of the entire procedure. We want meaningful sentences to be similar and closer to each other in the embedded space, while at the same time, we want noisy sentences to be far away from the meaningful ones and also similar among them. To carry out this crucial step we make use of powerful pre-trained word embeddings, I\u2019ve chosen GloVe.", "We create sentence embeddings as a weighted mean of singular word embeddings. The weight is given by computing the TfIdf on the paper corpus composed by sentences. During ensembling, for each word in a particular sentence, we select the relative GloVe embedding (if present) and multiplicate it for the TfIdf word weight. The sum of weighted word embeddings in each sentence is normalized dividing by the sum of TfIdf word weights in the sentence.", "In order to make this process easy and light, I\u2019ve chosen Gensim to load and operate with GloVe. Gensim requires the .bin format of GloVe (available here together with the other file formats); feel free to operate with the reading methods which you prefer.", "Calculating the sentence embeddings in this way, we have already reached the first important result freely. Words which are not present in GloVe vocabulary (3000000 unique words) aren\u2019t taken into account (if not in GloVe it doesn\u2019t exist), i.e. they are extremely not common terms and we can consider them as noise. Now imagine a sentence of all uncommon token, it ends up with an embedding of all zeros and we can immediately exclude it.", "The creation of sentence embeddings, like above, is computed for every sentence in the corpus. We ended with an array of dimension (N,300) where N is the number of sentences and 300 is the GloVe embedding dimension. In order to manage them easily, we reduce their dimensions with PCA and apply, on the reduced space, an algorithm for unsupervised anomaly detection. Our anomalies are clearly located far away from the center of density.", "The detection of these abnormal points (sentences) is a perfect task for Isolation Forest. This ensemble model operates partitions of the space in subgroups: lower the number of splittings required to isolate a sample from the others and higher is the probability of this observation to be an anomaly.", "Our work is finished, we just have to check the results! In yellow we have the valuable sentences and outside the noisy text parts. To achieve this result, we only have to set the \u2018contamination parameter\u2019 which says us how severe we are in throwing away information. Below I\u2019ve attached an example from the paper I\u2019ve just analyzed. The first snippet shows valuable sentences, which contain useful information.", "The second snippet is a collection of sentences which probably contain a lot of noise.", "In this post, I develop a solution for text data cleaning automatically. Given a text corpus, we are able to select the most valuable sentences, throwing away noisy text parts. This solution aims to be not computationally expensive; we\u2019ve used pre-trained word embeddings and have fitted a simple algorithm for anomaly sentence detection. The whole workflow can be extended to a collection of text corpus always following an unsupervised approach.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2046ef59ac17&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@cerlymarco?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "Marco Cerliani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc843902314c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&user=Marco+Cerliani&userId=c843902314c7&source=post_page-c843902314c7----2046ef59ac17---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2046ef59ac17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2046ef59ac17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@karim_manjra?utm_source=medium&utm_medium=referral", "anchor_text": "Karim MANJRA"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/benhamner/nips-2015-papers#Papers.csv", "anchor_text": "dataset on Kaggle"}, {"url": "https://nips.cc/", "anchor_text": "Neural Information Processing Systems"}, {"url": "https://www.kaggle.com/benhamner/nips-2015-papers#Papers.csv", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/pkugoodspeed/nlpword2vecembeddingspretrained", "anchor_text": "available here"}, {"url": "https://github.com/cerlymarco/MEDIUM_NoteBook", "anchor_text": "CHECK MY GITHUB REPO"}, {"url": "https://www.linkedin.com/in/marco-cerliani-b0bba714b/", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2046ef59ac17---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2046ef59ac17---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/nlp?source=post_page-----2046ef59ac17---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/text-mining?source=post_page-----2046ef59ac17---------------text_mining-----------------", "anchor_text": "Text Mining"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----2046ef59ac17---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2046ef59ac17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&user=Marco+Cerliani&userId=c843902314c7&source=-----2046ef59ac17---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2046ef59ac17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&user=Marco+Cerliani&userId=c843902314c7&source=-----2046ef59ac17---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2046ef59ac17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2046ef59ac17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2046ef59ac17---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2046ef59ac17--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2046ef59ac17--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2046ef59ac17--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marco Cerliani"}, {"url": "https://medium.com/@cerlymarco/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "6K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc843902314c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&user=Marco+Cerliani&userId=c843902314c7&source=post_page-c843902314c7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe2412974851a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomate-data-cleaning-with-unsupervised-learning-2046ef59ac17&newsletterV3=c843902314c7&newsletterV3Id=e2412974851a&user=Marco+Cerliani&userId=c843902314c7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}