{"url": "https://towardsdatascience.com/how-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97", "time": 1683013421.7807732, "path": "towardsdatascience.com/how-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97/", "webpage": {"metadata": {"title": "How To Build A Real-time Data Pipeline For An Online Store Using Apache Beam, Pub/Sub, and SQL | by Aakash Rathor | Towards Data Science", "h1": "How To Build A Real-time Data Pipeline For An Online Store Using Apache Beam, Pub/Sub, and SQL", "description": "It is fascinating to see how malleable our data is becoming. Nowadays we have tools to convert highly nested and complex log data to simple rows format, tools to store and process petabytes of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://dash.plotly.com/introduction", "anchor_text": "Dash", "paragraph_index": 14}, {"url": "https://github.com/aakashrathore92/gcp-realtime-pipeline-project", "anchor_text": "Here", "paragraph_index": 14}, {"url": "https://github.com/aakashrathore92/gcp-realtime-pipeline-project", "anchor_text": "here", "paragraph_index": 26}, {"url": "https://datastudio.google.com", "anchor_text": "https://datastudio.google.com", "paragraph_index": 43}, {"url": "https://analytics.google.com/analytics/academy/course/10", "anchor_text": "here", "paragraph_index": 47}, {"url": "https://www.instagram.com/_aakash.rathore/", "anchor_text": "Instagram", "paragraph_index": 51}, {"url": "https://www.linkedin.com/in/aakash-data-engineer", "anchor_text": "LinkedIn", "paragraph_index": 51}], "all_paragraphs": ["It is fascinating to see how malleable our data is becoming. Nowadays we have tools to convert highly nested and complex log data to simple rows format, tools to store and process petabytes of transaction data, and tools to capture raw data as soon as it gets generated, to process and provide useful insights from it.", "In this article, I would like to share one such step-by-step process of generating, ingesting, processing, and finally utilizing real-time data from our own virtual online store.", "Pub/Sub is a messaging service available in the Google Cloud Platform. It can be considered as a managed version of Apache Kafka or Rabbitmq.", "A messaging service basically de-couples the system which produces data(virtual store application in our case) from the system which processes the data(Apache beam on Dataflow in our case).", "First, we need to create a service account in GCP which will allow us to access Pub/Sub from our application and Apache beam:", "Login into your GCP console and select the IAM & Admin from the left menu:", "Select the Service Accounts option and create a new service account:", "Provide the Pub/Sub Admin role to our service account:", "And finally, Create a key and download the private key JSON file for later use:", "Next, we will create a topic in Pub/Sub to publish our virtual store data into it and a subscriber to pull data from it using Apache Beam.", "Select Pub/Sub from the left menu of the GCP console.", "Select Topics from the sub-menu. From the top, select CREATE TOPIC. Enter a suitable name and click CREATE TOPIC.", "Now, select the Subscriptions option from the left and from the top, select CREATE SUBSCRIPTION. Enter a suitable name, select the topic from the drop-down (we created in the previous step) to which the subscriber will listen for the stream of data. After that click Create at the end, keeping other options as it is.", "Now we will create a virtual online store that will push the transaction data into the pub/sub Topic that we have created in previous steps.", "I have used Dash which is a tool created by Plotly to quickly build a web application using different prebuild UI components like button, text input, etc. A complete tutorial to build a web application is out of this article\u2019s scope since our main focus is to build a realtime pipeline. So you can just download the complete application from the GitHub repo Here.", "The only thing important is the script which publishes our data into the Pub/Sub topic:", "Let's start our online virtual store, after downloading the project from the Git create a virtual python environment and install all the packages using the requirement .txt file. Now open the folder in the terminal and run app.py file. You will see the below output:", "Go to your web browser and open localhost:8085. You will see the virtual store home page.", "Now the fun part lets order a few items and see how our data is getting published into the pub/sub topic and then pulled by the subscriber, that we have created earlier. Add some quantity for each item and click Submit:", "You can see in the terminal some transaction data in JSON format is getting printed every time you place an order. Same JSON data is pushed to the Pub/Sub Topic also. Let\u2019s pull the data from our subscriber, go to the pub/sub dashboard in GCP select the Subscriptions option from the left menu after that click on VIEW MESSAGES from the top and then click Pull to see the published data:", "At this stage, we are getting the data in real-time from our virtual online store to our Pub/Sub subscriber. Now we are going to write our pipeline in Apache Beam to unnest the data and convert it into row like format to store it in MySQL server. And finally, we will run our pipeline using GCP Dataflow runner.", "Before we start writing our data pipeline let\u2019s create a cloud SQL instance in GCP which will be our final destination to store processed data, you can use other cloud SQL services as well, I have written my pipeline for MySQL server.", "From the GCP console, select the SQL option from the left menu:", "Enter Instance Name and Password for the root user, leave other settings to default and click Create, Now sit back and relax it will take 5\u201310 min to start the instance:", "After the DB is up and running we need to create a database and table. Connect with your MySQL instance using any SQL client and run below queries:", "Till now have created our source (Pub/Sub Subscriber ) and Sink (MySQL), now we will create our data pipeline.", "Representation of directory for our pipeline is given below, you can clone the complete directory from my GitHub repo here:", "Let's start first with the configuration file pipeline_config.py ,this file contains all the configuration like Pub/Sub subscriber details, service account key path, MySQL DB connection details, and table details.", "Next is the main pipeline file, mainPipeline.py , this is the entry point for different runners (local, Dataflow, etc) for running the pipeline. In this pipeline script, we are reading data from the Pub/Sub, unnesting the data, and storing the final data in a relational database. Later we will visualize it using Google Data studio. Let's look at the code:", "First, let's run our pipeline in local:", "You will see the below output, this means our pipeline is now listening to Pub/Sub for incoming data.", "Let\u2019s place some orders from our virtual online store and see the output of the pipeline.", "After clicking submit you will immediately see the output in the pipeline terminal:", "As you can see our input was nested data in which all the items are nested in a single object, but our pipeline unnested the data into row level.", "As expected our single order is transformed into item wise row-level data and inserted in our database on the fly, in real-time.", "Now we will run our pipeline in GCP Dataflow, for this, we need to run below command:", "Make sure you create a staging bucket in GCP as I did and provide the link in the above command under \u201ctemp_location\u201d option and also create a setup.py in your directory with the below content, this will prevent ModuleNotFoundError.", "Sit back and relax it will take 5\u201310 min to start the pipeline in GCP dataflow. Now go to the GCP Dataflow dashboard to check if the server started or not.", "you can also see the different stages of the pipeline, click on the running job to see the details.", "Place some orders from the virtual store and test if the data is coming in DB or not. In my case, it is working as expected. Rows of data in MySQL table is getting inserted in real-time:", "Note: Closing our local terminal from which we deployed the pipeline in GCP won\u2019t affect the pipeline running in Dataflow on GCP. Make sure to terminate the pipeline from the GCP as well.", "Google Data Studio is a free tool for visualizing data. It enables users to create an interactive and effective reporting dashboard very quickly from different data sources.", "Let's connect our sink (MySQL server) to the Data Studio and create a dashboard on the top of our real-time data.", "Go to https://datastudio.google.com. Click on Create and select Data source.", "Give a name to your source at the top left corner and select Cloud SQL for MYSQL as source (If your MySQL database is not in GCP select only MySQL)", "Enter your DB credentials and click Authenticate. After that select CUSTOM QUERY, enter the query and select Connect at the top right corner.", "Data Studio will connect to the cloud SQL instance and show us the schema of our table. Now click on CREATE REPORT at the top right corner:", "Add charts and graphs as per your requirements. You can learn more about data studio here:", "I have created a basic, 2 chart dashboard which shows Item wise quantity sold and Item wise sales.", "My final Dashboard, which gets updated as soon as the orders are getting placed:", "In this article, I explained how real-time pipeline works. We have created all the components of a data pipeline, a source application which generates data in real-time, a buffer which ingests the data, an actual pipeline in Google cloud Platform which processes the data, a sink to store the processed data, and finally a dashboard to visualize our final data.", "Please leave your comment about this article below and in case you are facing issues in any of the steps specified above you can reach out to me through Instagram and LinkedIn.", "Working as a Data Engineer for earning money, and working with data for living my dream. I prefer Ubuntu over Windows and nano over notepad."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6424f33eba97&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@aakash_rathore?source=post_page-----6424f33eba97--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Aakash Rathor"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F40aef34c503d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&user=Aakash+Rathor&userId=40aef34c503d&source=post_page-40aef34c503d----6424f33eba97---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6424f33eba97&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&user=Aakash+Rathor&userId=40aef34c503d&source=-----6424f33eba97---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6424f33eba97&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&source=-----6424f33eba97---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://cloud.google.com/", "anchor_text": "here"}, {"url": "https://dash.plotly.com/introduction", "anchor_text": "Dash"}, {"url": "https://github.com/aakashrathore92/gcp-realtime-pipeline-project", "anchor_text": "Here"}, {"url": "https://github.com/aakashrathore92/gcp-realtime-pipeline-project", "anchor_text": "here"}, {"url": "https://datastudio.google.com", "anchor_text": "https://datastudio.google.com"}, {"url": "https://analytics.google.com/analytics/academy/course/10", "anchor_text": "here"}, {"url": "https://www.instagram.com/_aakash.rathore/", "anchor_text": "Instagram"}, {"url": "https://www.linkedin.com/in/aakash-data-engineer", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6424f33eba97---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----6424f33eba97---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----6424f33eba97---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/python?source=post_page-----6424f33eba97---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/google-cloud-platform?source=post_page-----6424f33eba97---------------google_cloud_platform-----------------", "anchor_text": "Google Cloud Platform"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6424f33eba97&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&user=Aakash+Rathor&userId=40aef34c503d&source=-----6424f33eba97---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6424f33eba97&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&user=Aakash+Rathor&userId=40aef34c503d&source=-----6424f33eba97---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6424f33eba97&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=post_page-----6424f33eba97--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F40aef34c503d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&user=Aakash+Rathor&userId=40aef34c503d&source=post_page-40aef34c503d----6424f33eba97---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcebab27f117d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&newsletterV3=40aef34c503d&newsletterV3Id=cebab27f117d&user=Aakash+Rathor&userId=40aef34c503d&source=-----6424f33eba97---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Written by Aakash Rathor"}, {"url": "https://medium.com/@aakash_rathore/followers?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "102 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F40aef34c503d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&user=Aakash+Rathor&userId=40aef34c503d&source=post_page-40aef34c503d----6424f33eba97---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcebab27f117d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-real-time-data-pipeline-for-an-online-store-using-apache-beam-pub-sub-and-sql-6424f33eba97&newsletterV3=40aef34c503d&newsletterV3Id=cebab27f117d&user=Aakash+Rathor&userId=40aef34c503d&source=-----6424f33eba97---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/run-multiple-services-in-single-docker-container-using-supervisor-b2ed53e3d1c0?source=author_recirc-----6424f33eba97----0---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=author_recirc-----6424f33eba97----0---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=author_recirc-----6424f33eba97----0---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Aakash Rathor"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6424f33eba97----0---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/run-multiple-services-in-single-docker-container-using-supervisor-b2ed53e3d1c0?source=author_recirc-----6424f33eba97----0---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Run Multiple Services In Single Docker Container Using SupervisorHave you ever faced this scenario where you want to run two or more lightweight services within the same container ?"}, {"url": "https://towardsdatascience.com/run-multiple-services-in-single-docker-container-using-supervisor-b2ed53e3d1c0?source=author_recirc-----6424f33eba97----0---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "\u00b75 min read\u00b7May 25, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2ed53e3d1c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frun-multiple-services-in-single-docker-container-using-supervisor-b2ed53e3d1c0&user=Aakash+Rathor&userId=40aef34c503d&source=-----b2ed53e3d1c0----0-----------------clap_footer----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/run-multiple-services-in-single-docker-container-using-supervisor-b2ed53e3d1c0?source=author_recirc-----6424f33eba97----0---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2ed53e3d1c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frun-multiple-services-in-single-docker-container-using-supervisor-b2ed53e3d1c0&source=-----6424f33eba97----0-----------------bookmark_preview----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6424f33eba97----1---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6424f33eba97----1---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6424f33eba97----1---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6424f33eba97----1---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6424f33eba97----1---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6424f33eba97----1---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6424f33eba97----1---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----6424f33eba97----1-----------------bookmark_preview----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----6424f33eba97----2---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----6424f33eba97----2---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----6424f33eba97----2---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6424f33eba97----2---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----6424f33eba97----2---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----6424f33eba97----2---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----6424f33eba97----2---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----6424f33eba97----2-----------------bookmark_preview----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/analytics-vidhya/improve-performance-of-mysql-queries-using-table-partitioning-b44ef80ab17f?source=author_recirc-----6424f33eba97----3---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=author_recirc-----6424f33eba97----3---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=author_recirc-----6424f33eba97----3---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Aakash Rathor"}, {"url": "https://medium.com/analytics-vidhya?source=author_recirc-----6424f33eba97----3---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Analytics Vidhya"}, {"url": "https://medium.com/analytics-vidhya/improve-performance-of-mysql-queries-using-table-partitioning-b44ef80ab17f?source=author_recirc-----6424f33eba97----3---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "Improve Performance Of MySQL Queries Using Table Partitioning.This is a small tutorial on how to improve performance of MySQL queries by using partitioning."}, {"url": "https://medium.com/analytics-vidhya/improve-performance-of-mysql-queries-using-table-partitioning-b44ef80ab17f?source=author_recirc-----6424f33eba97----3---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": "\u00b74 min read\u00b7Oct 21, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fanalytics-vidhya%2Fb44ef80ab17f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Fimprove-performance-of-mysql-queries-using-table-partitioning-b44ef80ab17f&user=Aakash+Rathor&userId=40aef34c503d&source=-----b44ef80ab17f----3-----------------clap_footer----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/analytics-vidhya/improve-performance-of-mysql-queries-using-table-partitioning-b44ef80ab17f?source=author_recirc-----6424f33eba97----3---------------------fea9dd47_d03b_4ed4_829e_acedd204adf4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb44ef80ab17f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Fimprove-performance-of-mysql-queries-using-table-partitioning-b44ef80ab17f&source=-----6424f33eba97----3-----------------bookmark_preview----fea9dd47_d03b_4ed4_829e_acedd204adf4-------", "anchor_text": ""}, {"url": "https://medium.com/@aakash_rathore?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "See all from Aakash Rathor"}, {"url": "https://towardsdatascience.com/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/automatically-updating-a-bigquery-table-using-an-external-api-and-a-cloud-function-c05423ca3ed?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://pl-bescond.medium.com/?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://pl-bescond.medium.com/?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Pierre-Louis Bescond"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/automatically-updating-a-bigquery-table-using-an-external-api-and-a-cloud-function-c05423ca3ed?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Automatically Updating a BigQuery Table Using an External API and a Cloud FunctionA step-by-step guide on building a fully automated process to regularly update a BigQuery table"}, {"url": "https://towardsdatascience.com/automatically-updating-a-bigquery-table-using-an-external-api-and-a-cloud-function-c05423ca3ed?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "\u00b78 min read\u00b7Dec 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc05423ca3ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-updating-a-bigquery-table-using-an-external-api-and-a-cloud-function-c05423ca3ed&user=Pierre-Louis+Bescond&userId=4ef7c1e10597&source=-----c05423ca3ed----0-----------------clap_footer----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/automatically-updating-a-bigquery-table-using-an-external-api-and-a-cloud-function-c05423ca3ed?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc05423ca3ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautomatically-updating-a-bigquery-table-using-an-external-api-and-a-cloud-function-c05423ca3ed&source=-----6424f33eba97----0-----------------bookmark_preview----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://cookjack248.medium.com/?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://cookjack248.medium.com/?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Jack C"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "dbt v1.5 \u2014 the 3 Big New ThingsData contracts, model versions, and model access"}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "6 min read\u00b74 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F660e59fd29cb&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fdbt-v1-5-the-3-big-new-things-660e59fd29cb&user=Jack+C&userId=1eb3d543fd09&source=-----660e59fd29cb----1-----------------clap_footer----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F660e59fd29cb&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fdbt-v1-5-the-3-big-new-things-660e59fd29cb&source=-----6424f33eba97----1-----------------bookmark_preview----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@amarachi.ogu/building-a-stock-data-workflow-with-google-cloud-composer-gcs-and-bigquery-9833c5c64313?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@amarachi.ogu?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@amarachi.ogu?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Amarachi Ogu"}, {"url": "https://medium.com/@amarachi.ogu/building-a-stock-data-workflow-with-google-cloud-composer-gcs-and-bigquery-9833c5c64313?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Building a Stock Data Workflow with Google Cloud Composer, Cloud Storage, and BigQueryRun Apache Airflow without having to manage the infrastructure"}, {"url": "https://medium.com/@amarachi.ogu/building-a-stock-data-workflow-with-google-cloud-composer-gcs-and-bigquery-9833c5c64313?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "8 min read\u00b7Feb 9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F9833c5c64313&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amarachi.ogu%2Fbuilding-a-stock-data-workflow-with-google-cloud-composer-gcs-and-bigquery-9833c5c64313&user=Amarachi+Ogu&userId=de631b24e202&source=-----9833c5c64313----0-----------------clap_footer----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@amarachi.ogu/building-a-stock-data-workflow-with-google-cloud-composer-gcs-and-bigquery-9833c5c64313?source=read_next_recirc-----6424f33eba97----0---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9833c5c64313&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40amarachi.ogu%2Fbuilding-a-stock-data-workflow-with-google-cloud-composer-gcs-and-bigquery-9833c5c64313&source=-----6424f33eba97----0-----------------bookmark_preview----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Josue Luzardo Gebrim"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Data Quality in Python Pipelines!Discover What It Is And How To Achieve Data Quality In Your Data Streams!"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "\u00b714 min read\u00b7Mar 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&user=Josue+Luzardo+Gebrim&userId=9f59dfc0edf7&source=-----4ad1e8eb6603----1-----------------clap_footer----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----6424f33eba97----1---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&source=-----6424f33eba97----1-----------------bookmark_preview----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@sahaabhik9/dynamic-inserts-in-google-bigquery-88b8ff9d2671?source=read_next_recirc-----6424f33eba97----2---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@sahaabhik9?source=read_next_recirc-----6424f33eba97----2---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@sahaabhik9?source=read_next_recirc-----6424f33eba97----2---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Abhik Saha"}, {"url": "https://medium.com/@sahaabhik9/dynamic-inserts-in-google-bigquery-88b8ff9d2671?source=read_next_recirc-----6424f33eba97----2---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Dynamic Inserts in Google BigQueryImagine a scenario in which you need to transfer data from tables in your development/testing dataset to tables in your production dataset\u2026"}, {"url": "https://medium.com/@sahaabhik9/dynamic-inserts-in-google-bigquery-88b8ff9d2671?source=read_next_recirc-----6424f33eba97----2---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "4 min read\u00b7Apr 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F88b8ff9d2671&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sahaabhik9%2Fdynamic-inserts-in-google-bigquery-88b8ff9d2671&user=Abhik+Saha&userId=e2bc6105615&source=-----88b8ff9d2671----2-----------------clap_footer----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/@sahaabhik9/dynamic-inserts-in-google-bigquery-88b8ff9d2671?source=read_next_recirc-----6424f33eba97----2---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F88b8ff9d2671&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sahaabhik9%2Fdynamic-inserts-in-google-bigquery-88b8ff9d2671&source=-----6424f33eba97----2-----------------bookmark_preview----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/essentials-for-working-with-firestore-in-python-372f859851f7?source=read_next_recirc-----6424f33eba97----3---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://lynn-kwong.medium.com/?source=read_next_recirc-----6424f33eba97----3---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://lynn-kwong.medium.com/?source=read_next_recirc-----6424f33eba97----3---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Lynn Kwong"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6424f33eba97----3---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/essentials-for-working-with-firestore-in-python-372f859851f7?source=read_next_recirc-----6424f33eba97----3---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "Essentials for Working With Firestore in PythonLearn to manage your Firebase app data in Python"}, {"url": "https://towardsdatascience.com/essentials-for-working-with-firestore-in-python-372f859851f7?source=read_next_recirc-----6424f33eba97----3---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": "\u00b711 min read\u00b7Nov 16, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F372f859851f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fessentials-for-working-with-firestore-in-python-372f859851f7&user=Lynn+Kwong&userId=f649eccbbc3d&source=-----372f859851f7----3-----------------clap_footer----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/essentials-for-working-with-firestore-in-python-372f859851f7?source=read_next_recirc-----6424f33eba97----3---------------------33d30d8e_f32c_4279_9b9c_f83219d38314-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F372f859851f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fessentials-for-working-with-firestore-in-python-372f859851f7&source=-----6424f33eba97----3-----------------bookmark_preview----33d30d8e_f32c_4279_9b9c_f83219d38314-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6424f33eba97--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----6424f33eba97--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}