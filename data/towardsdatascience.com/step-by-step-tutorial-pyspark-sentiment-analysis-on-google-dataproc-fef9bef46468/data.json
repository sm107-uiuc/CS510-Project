{"url": "https://towardsdatascience.com/step-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468", "time": 1682994364.856481, "path": "towardsdatascience.com/step-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468/", "webpage": {"metadata": {"title": "PySpark Sentiment Analysis on Google Dataproc | by Ricky Kim | Towards Data Science", "h1": "PySpark Sentiment Analysis on Google Dataproc", "description": "I recently had a chance to play around with Google Cloud Platform through a specialization course on Coursera; Data Engineering on Google Cloud Platform Specialization. Overall I learned a lot\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.coursera.org/specializations/gcp-data-machine-learning", "anchor_text": "Data Engineering on Google Cloud Platform Specialization", "paragraph_index": 0}, {"url": "https://medium.com/u/247b0630b5d6?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Lak Lakshmanan", "paragraph_index": 1}, {"url": "https://medium.com/u/247b0630b5d6?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Lak Lakshmanan", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/sentiment-analysis-with-pyspark-bc8e83f80c35", "anchor_text": "one of my previous posts", "paragraph_index": 4}, {"url": "https://cloud.google.com/sdk/", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://cloud.google.com/compute/docs/regions-zones/", "anchor_text": "here", "paragraph_index": 12}, {"url": "https://cloud.google.com/storage/docs/locations", "anchor_text": "here", "paragraph_index": 18}, {"url": "http://help.sentiment140.com/for-students/", "anchor_text": "http://help.sentiment140.com/for-students/", "paragraph_index": 22}], "all_paragraphs": ["I recently had a chance to play around with Google Cloud Platform through a specialization course on Coursera; Data Engineering on Google Cloud Platform Specialization. Overall I learned a lot through the courses, and it was such a good opportunity to try various services of Google Cloud Platform(GCP) for free while going through the assignments. Even though I\u2019m not using any of GCP\u2019s services at work at the moment, if I have a chance I\u2019d be happy to migrate some parts of my data works to GCP.", "However, one thing that the course lacks is room for your own creativity. The assignments of the course were more like tutorials than assignments. You basically follow along already written codes. Of course, you can still learn a lot by trying to read every single line of codes and understand what each line does in detail. Still, without applying what you have learned in your own problem-solving, it is difficult to make this knowledge completely yours. That\u2019s also what the instructor Lak Lakshmanan advised at the end of the course. (Shout out to Lak Lakshmanan, thank you for the great courses!)", "*In addition to short code blocks I will attach, you can find the link for the whole Git Repository at the end of this post.", "So I have decided to do some personal mini projects making use of various GCP services. Luckily, if you haven\u2019t tried GCP yet, Google generously offers a free trial which gives you $300 credit you can use over 12 months.", "The first project I tried is Spark sentiment analysis model training on Google Dataproc. There are a couple of reasons why I chose it as my first project on GCP. I already wrote about PySpark sentiment analysis in one of my previous posts, which means I can use it as a starting point and easily make this a standalone Python program. The other reason is I just wanted to try Google Dataproc! I was fascinated by how easy and fast it is to spin up a cluster on GCP and couldn\u2019t help myself from trying it outside the Coursera course.", "If you have clicked \u201cTRY GCP FREE\u201d, and fill in information such as your billing account (Even though you set up a billing account, you won\u2019t be charged unless you upgrade to a paid account), you will be directed to a page looks like below.", "On the top menu bar, you can see \u201cMy First Project\u201d next to Google Cloud Platform. In GCP, \u201cproject\u201d is the base-level entity to use GCP services, enable billing, etc. On the first login, you can see that Google automatically created a \u201cproject\u201d called \u201cMy First Project\u201d for you. Click on it to see ID of the current project, copy it or write it down, this will be used later. By clicking into \u201cBilling\u201d on the left-side menu from the web console home screen, \u201cMy First Project\u201d is automatically linked to the free credit you received.", "In GCP, there are many different services; Compute Engine, Cloud Storage, BigQuery, Cloud SQL, Cloud Dataproc to name a few. In order to use any of these services in your project, you first have to enable them.", "Put your mouse over \u201cAPIs & Services\u201d on the left-side menu, then click into \u201cLibrary\u201d. For this project, we will enable three APIs: Cloud Dataproc, Compute Engine, and Cloud Storage.", "In the API Library page, search the above mentioned three APIs one by one by typing the name in the search box. Clicking into the search result, and enable the API by clicking \u201cENABLE\u201d button on the screen.", "When I tried it myself, I only had to enable Cloud Dataproc API, since the other two (Compute Engine, Cloud Storage) were already enabled when I clicked into them. But if that\u2019s not the case for you, please enable Compute Engine API, Cloud Storage API.", "If this is your very first time to try GCP, you first might want to install the Google Cloud SDK so that you can interact with many services of GCP from the command-line. You can find more information on how to install from here.", "By following instructions from the link, you will be prompted to log in (use the Google account you used to start the free trial), then to select a project and compute zone (project: choose the project you enable the APIs from the above steps if there are more than one, compute zone: To decrease network latency, you might want to choose a zone that is close to you. You can check the physical locations of each zone from here.).", "Since you have installed Google Cloud SDK, you can either create a bucket from the command-line or from the web console.", "Click into \u201cStorage\u201d from left-side menu, then you\u2019ll see a page like the above. Click \u201cCreate bucket\u201d", "For convenience, enter project ID you checked at the end of \u201cCreating a Free Trial Account on GCP\u201d stage. You can just click \u201ccreate\u201d without changing any other details, or choose the same location as your project.", "Replace your_project_id with the project ID that you copied and run the below line on your terminal to set BUCKET_NAME variable to your project ID and make it available to sub-processes. (A Bash script you need to run later will make use of this)", "Then create a bucket by running gsutil mb command as below.", "The above command will create a bucket with the default settings. If you want to create a bucket in a specific region or multi-region, you can give it -l option to specify the region. You can see available bucket locations from here.", "Now clone the git repository I uploaded by running below command in terminal.", "Once you clone the repository, it will create a folder named pyspark_sa_gcp. Go into the folder and check what files are there.", "You will see three files in the directory: data_prep.sh, pyspark_sa.py, train_test_split.py. In order to download the training data and prepare for training let\u2019s run the Bash script data_prep.sh. Below is the content of the script and I have added comments to explain what each line does.", "The original dataset for training is \u201cSentiment140\u201d, which originated from Stanford University. The Dataset has 1.6million labelled tweets.50% of the data is with negative labels and the other 50% with positive labels. More info on the dataset can be found from the link. http://help.sentiment140.com/for-students/", "In the above Bash script, you can see it\u2019s calling a Python script train_test_split.py. Let\u2019s also take a look at what it does.", "Now we can run the Bash script to prepare the data. Once it\u2019s finished, it will have uploaded prepared data to the cloud storage bucket you created earlier. It will take 5~6 mins to upload the data.", "Go to the Storage from the left side menu and click into your bucket -> pyspark_nlp -> data. You will see two files are uploaded.", "Or you can also check the content of your bucket from your terminal by running below command.", "Cloud Dataproc is a Google cloud service for running Apache Spark and Apache Hadoop clusters. I have to say it is ridiculously simple and easy-to-use and it only takes a couple of minutes to spin up a cluster with Google Dataproc. Also, Google Dataproc offers autoscaling if you need, and you can adjust the cluster at any time, even when jobs are running on the cluster.", "Go to Dataproc from the left side menu (you have to scroll down a bit. It\u2019s under Big Data section) and click on \u201cClusters\u201d. Click \u201cCreate clusters\u201d, then you\u2019ll see a page like below.", "Give it a name (for convenience, I gave the project ID as its name), choose Region and Zone. To decrease the latency, it is a good idea to set the region to be the same as your bucket region. Here you need to change the default settings for worker nodes a little, as the free trial only gives you permission to run up to 8 cores. The default setting for a cluster is one master and two workers all with 4 CPUs each, which will exceed the 8 cores quota. So change the setting for your worker nodes to 2 CPUs, then click create at the bottom. After a couple of minutes of provisioning, you will see the cluster created with one master node (4 CPUs, 15GB memory, 500GB standard persistent disk) and two worker nodes (2 CPUs, 15GB memory, 500GB standard persistent disk each).", "Since we need to change the default setting a little bit, we need to add one more argument to the command, but it\u2019s simple enough. Let\u2019s create a cluster and give it the same name as the project ID, and set worker nodes to have 2 CPUs each.", "You can change the zone to be close to your bucket region.", "Finally, we are ready to run the training on Google Dataproc. The Python script (pyspark_sa.py) for the training is included in the Git repository you cloned earlier. Since I commented on the script to explain what each line does, I will not go through the code. The code is a slightly refactored version of what I have done in Jupyter Notebook for my previous post. Below are a few of my previous posts, in case you want to know more in detail about PySpark or NLP feature extraction.", "And let\u2019s take a look at what the Python script looks like.", "Since I commented inside the script to explain what each line does, I will not go through the code extensively. But in a nutshell, the above script will take three command line arguments: Cloud Storage location where the training and test data are stored, a Cloud storage directory to store prediction result of the test data, and finally a Cloud storage directory to store the trained model. When called, it will first do the preprocessing of the training data -> build a pipeline -> fit the pipeline -> and make predictions on the test data -> print the accuracy of the predictions -> save prediction result as CSV -> save fitted pipeline model -> load the saved model -> print the accuracy again on the test data (to see if the model is properly saved).", "In order to run this job through the web console, we need to first upload the Python script to our cloud storage so that we can point the job to read the script. Let\u2019s upload the script by running below command. (I\u2019m assuming that you are still on pyspark_sa_gcp directory on your terminal)", "Now click into Dataproc on the web console, and click \u201cJobs\u201d then click \u201cSUBMIT JOB\u201d.", "From the above screenshot replace the blurred parts of the texts to your project ID, then click \u201csubmit\u201d at the bottom. You can inspect the output of the machine by clicking into the job.", "The job is finished after 15 minutes, and by looking at the output, it seems like the cluster struggled a bit, but nonetheless, the prediction looks fine and the model seems to be saved properly.", "If you submit a job from the command-line, you don\u2019t even need to upload your script to Cloud Storage. It will be able to grab a local file and move to the Dataproc cluster to execute. (Again I\u2019m assuming that you are still on pyspark_sa_gcp directory on your terminal)", "Again the cluster seemed to struggle a bit, but still got the result and model saved properly. (I have tried to submit the same job on my paid account with 4 CPUs worker nodes, then it didn\u2019t throw any warnings)", "Go to your bucket, then go into pyspark_nlp folder. You will see that the results of the above Spark job have been saved into \u201cresult\u201d directory (for the prediction data frame), and \u201cmodel\u201d directory (fitted pipeline model).", "Finally, don\u2019t forget to delete the Dataproc cluster you have created to ensure it will not use up any more of your credit.", "Through this post, I went through how to train Spark ML model on Google Dataproc and save the trained model for later use. What I showed here is only a small part of what GCP is capable of and I encourage you to explore other services on GCP and play around with it.", "Thank you for reading. You can find the Git Repository of the scripts from the below link.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "The Rickest Ricky. Love data, beer, coffee, and good memes in no particular order."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffef9bef46468&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fef9bef46468--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rickykim78?source=post_page-----fef9bef46468--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickykim78?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Ricky Kim"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57a8aa301d13&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&user=Ricky+Kim&userId=57a8aa301d13&source=post_page-57a8aa301d13----fef9bef46468---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffef9bef46468&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffef9bef46468&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@sortino?utm_source=medium&utm_medium=referral", "anchor_text": "Joshua Sortino"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.coursera.org/specializations/gcp-data-machine-learning", "anchor_text": "Data Engineering on Google Cloud Platform Specialization"}, {"url": "https://medium.com/u/247b0630b5d6?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Lak Lakshmanan"}, {"url": "https://medium.com/u/247b0630b5d6?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Lak Lakshmanan"}, {"url": "https://brew.sh/", "anchor_text": "https://brew.sh/"}, {"url": "https://git-scm.com/book/en/v2/Getting-Started-Installing-Git", "anchor_text": "https://git-scm.com/book/en/v2/Getting-Started-Installing-Git"}, {"url": "https://cloud.google.com/gcp/", "anchor_text": "https://cloud.google.com/gcp/"}, {"url": "https://towardsdatascience.com/sentiment-analysis-with-pyspark-bc8e83f80c35", "anchor_text": "one of my previous posts"}, {"url": "https://cloud.google.com/sdk/", "anchor_text": "here"}, {"url": "https://cloud.google.com/sdk/", "anchor_text": "https://cloud.google.com/sdk/"}, {"url": "https://cloud.google.com/compute/docs/regions-zones/", "anchor_text": "here"}, {"url": "https://cloud.google.com/storage/docs/locations", "anchor_text": "here"}, {"url": "https://github.com/tthustla/pyspark_sa_gcp.git", "anchor_text": "https://github.com/tthustla/pyspark_sa_gcp.git"}, {"url": "http://help.sentiment140.com/for-students/", "anchor_text": "http://help.sentiment140.com/for-students/"}, {"url": "https://towardsdatascience.com/sentiment-analysis-with-pyspark-bc8e83f80c35", "anchor_text": "Sentiment Analysis with PySpark"}, {"url": "https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-4-count-vectorizer-b3f4944e51b5", "anchor_text": "Another Twitter Sentiment Analysis with Python-Part 4 (Count Vectorizer, Confusion Matrix)"}, {"url": "https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-5-50b4e87d9bdd", "anchor_text": "Another Twitter Sentiment Analysis with Python-Part 5(TFIDF Vectorizer)"}, {"url": "https://github.com/tthustla/pyspark_sa_gcp", "anchor_text": "https://github.com/tthustla/pyspark_sa_gcp"}, {"url": "https://medium.com/tag/google-cloud-platform?source=post_page-----fef9bef46468---------------google_cloud_platform-----------------", "anchor_text": "Google Cloud Platform"}, {"url": "https://medium.com/tag/apache-spark?source=post_page-----fef9bef46468---------------apache_spark-----------------", "anchor_text": "Apache Spark"}, {"url": "https://medium.com/tag/google-dataproc?source=post_page-----fef9bef46468---------------google_dataproc-----------------", "anchor_text": "Google Dataproc"}, {"url": "https://medium.com/tag/sentiment-analysis?source=post_page-----fef9bef46468---------------sentiment_analysis-----------------", "anchor_text": "Sentiment Analysis"}, {"url": "https://medium.com/tag/python?source=post_page-----fef9bef46468---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffef9bef46468&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&user=Ricky+Kim&userId=57a8aa301d13&source=-----fef9bef46468---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffef9bef46468&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&user=Ricky+Kim&userId=57a8aa301d13&source=-----fef9bef46468---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffef9bef46468&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffef9bef46468&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fef9bef46468---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fef9bef46468--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fef9bef46468--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fef9bef46468--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fef9bef46468--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fef9bef46468--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickykim78?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickykim78?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ricky Kim"}, {"url": "https://medium.com/@rickykim78/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.6K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57a8aa301d13&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&user=Ricky+Kim&userId=57a8aa301d13&source=post_page-57a8aa301d13--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F90941e4c1749&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468&newsletterV3=57a8aa301d13&newsletterV3Id=90941e4c1749&user=Ricky+Kim&userId=57a8aa301d13&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}