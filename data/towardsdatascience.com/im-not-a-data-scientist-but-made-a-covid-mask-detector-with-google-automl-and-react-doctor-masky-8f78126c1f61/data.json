{"url": "https://towardsdatascience.com/im-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61", "time": 1683016963.574869, "path": "towardsdatascience.com/im-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61/", "webpage": {"metadata": {"title": "I\u2019m not a data scientist but made a COVID mask detector \u2014 Doctor Masky | by Will Ockelmann-Wagner | Towards Data Science", "h1": "I\u2019m not a data scientist but made a COVID mask detector \u2014 Doctor Masky", "description": "Neural-network-based object detection is a powerful technique that\u2019s getting easier and easier to take advantage of. With Google\u2019s Cloud AutoML computer vision service (as well as similar services\u2026"}, "outgoing_paragraph_urls": [{"url": "https://cloud.google.com/automl", "anchor_text": "Cloud AutoML", "paragraph_index": 0}, {"url": "https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/", "anchor_text": "Custom Vision", "paragraph_index": 0}, {"url": "https://ae.studio", "anchor_text": "AE Studio", "paragraph_index": 2}, {"url": "http://mrdeeplearning.com", "anchor_text": "Mr. Deep Learning", "paragraph_index": 2}, {"url": "https://doctormasky.com", "anchor_text": "doctormasky.com", "paragraph_index": 4}, {"url": "https://github.com/agencyenterprise/masky", "anchor_text": "on GitHub", "paragraph_index": 4}, {"url": "https://github.com/tensorflow/tfjs/tree/master/tfjs-automl", "anchor_text": "tfjs-automl", "paragraph_index": 6}, {"url": "https://cloud.google.com/vision/automl/docs/edge-quickstart", "anchor_text": "edge device model quickstart docs", "paragraph_index": 9}, {"url": "https://cloud.google.com/vision/automl/pricing#automl-vision-edge", "anchor_text": "docs", "paragraph_index": 9}, {"url": "https://www.flickr.com/", "anchor_text": "Flikr", "paragraph_index": 10}, {"url": "https://www.kaggle.com/datasets", "anchor_text": "Kaggle", "paragraph_index": 10}, {"url": "https://cloud.google.com/vision/automl/object-detection/docs/evaluate", "anchor_text": "The docs", "paragraph_index": 16}, {"url": "https://cloud.google.com/storage/docs/access-control/making-data-public#buckets", "anchor_text": "the Google Storage docs", "paragraph_index": 17}, {"url": "https://reactjs.org/docs/create-a-new-react-app.html", "anchor_text": "Create React App", "paragraph_index": 18}, {"url": "https://github.com/tensorflow/tfjs", "anchor_text": "tfjs", "paragraph_index": 19}, {"url": "https://github.com/tensorflow/tfjs/tree/master/tfjs-automl", "anchor_text": "tfjs-automl", "paragraph_index": 19}, {"url": "https://emotion.sh/", "anchor_text": "Emotion", "paragraph_index": 20}, {"url": "https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia", "anchor_text": "navigator.mediaDevices.getUserMedia", "paragraph_index": 21}, {"url": "https://www.tensorflow.org/js/guide/platform_environment#shader_compilation_texture_uploads", "anchor_text": "warm up", "paragraph_index": 38}, {"url": "https://doctormasky.com/", "anchor_text": "doctormasky.com", "paragraph_index": 46}, {"url": "https://doctormasky.com", "anchor_text": "doctormasky.com", "paragraph_index": 54}, {"url": "https://github.com/agencyenterprise/masky/blob/master/src/components/Detector.tsx", "anchor_text": "final code", "paragraph_index": 54}, {"url": "https://ae.studio/#robot-here", "anchor_text": "actual data scientists at AE", "paragraph_index": 55}], "all_paragraphs": ["Neural-network-based object detection is a powerful technique that\u2019s getting easier and easier to take advantage of. With Google\u2019s Cloud AutoML computer vision service (as well as similar services like Microsoft\u2019s Custom Vision), it\u2019s now simple and cheap to train a powerful object detection model and deploy it as a client-side React app. And best of all, you don\u2019t need to hire a data scientist to do it \u2014 the model training is code-free, so any application developer can train a model and focus on doing what they do best, which is building useful and fun applications!", "Given the current state of the world with COVID-19, I thought it would be an interesting test case to try building a mask detector \u2014 something that could take a video stream, and report back on the locations of people in a frame who are wearing masks, and of those who aren\u2019t. This could potentially be pretty useful to deploy in businesses trying to enforce mask mandates, and ride sharing services are already using something similar to check that drivers and riders are wearing masks.", "This seemed like a great idea, except for the small detail that I didn\u2019t actually know how to do that. Luckily I work at AE Studio, where we take an Agile approach to building both traditional software applications and data science solutions for our clients. So I talked with AE\u2019s head of data science, Mr. Deep Learning himself, Ed Chen, to help me figure out what the simplest MVP could be.", "What we found was that it\u2019s now surprisingly simple for a single developer to build a high-quality on-device object detection system, without any special knowledge or large data sets. This app doesn\u2019t snitch on anyone \u2014 it keeps all data on the client, and reacts when it detects a masked or unmasked face.", "If you don\u2019t want to peek behind the curtain, then feel free to skip ahead to check out our full-fledged mask detector at doctormasky.com. Or, if you want to skip the explanations and jump into the code, the repo is on GitHub. Otherwise, read on!", "The end-to-end workflow for building a client-side object detector goes like this:", "On the webapp side, you can use Google\u2019s tfjs-automl library to download and initialize your model. Then you connect to the device\u2019s camera, set up a video element to both show the user and to process the data into a video stream to periodically send to the model. The model will report back with the locations and labels of detected objects. You can use that to draw SVG images around the detected objects, play sounds, send the detected objects to some other service, or whatever else you want to do with that information. And in this case, we\u2019re using React to set up the app and handle the data flow and SVG drawing.", "If that sounds like something you want to do, then read on to learn how to make it happen!", "So first you need to upload example images of each object type you want to detect (in this case, people wearing masks and people without masks). The more images the better, but because AutoML uses transfer learning from a pre-trained object detection model, even just 30 examples for each class will probably give you decent results \u2014 though a hundred of each class would be better. Once you\u2019ve uploaded the images, you use Google\u2019s UI to manually draw bounding boxes around the objects (faces with and without masks in our case) in each image, and label each bounding box with its associated class. After all your data is labeled, you just tell Google to train the model, and come back in a couple hours. When it\u2019s done, you\u2019ll have a model to deploy as an API, or to use for client-side detection. The second option is what we\u2019ll focus on today.", "Before you create a model, you\u2019ll have to set up a Google Cloud project, add billing, and enable the AutoML and Cloud Storage APIs. You can follow Google\u2019s edge device model quickstart docs to get all that set up. You do have to provide a credit card to enable the API, but the first 15 node hours (training is run on multiple nodes in parallel) of training is free. See the docs for more pricing information. You can train a basic model in a few node hours, so the first few training runs will be free, and it\u2019s $18 per node hour after that.", "Once you\u2019ve got the AutoML Vision set up, you can start adding images! Sourcing the right images can be the hardest part of training a model. Flikr is a good source for Creative-Commons-licensed images. Depending on what objects you\u2019re trying to detect, you could also take the images yourself, or use a public dataset from somewhere like Kaggle. In any case, make sure you get a variety of angles and backgrounds to make sure the model has a robust training set to learn from. And if you\u2019re doing something like face detection, make sure you train on a diverse set of people, or your model won\u2019t perform well on everyone.", "With your images collected, you can create a new AutoML dataset to import into. Create a new dataset, and choose Object Detection. Classification can also be useful if you don\u2019t need the specific location of the detected items, but for any kind of AR experience you\u2019re probably going to want those bounding boxes.", "Next, click on your new dataset and go to the Import tab. This will let you upload the new images. If there\u2019s in an existing Google Storage bucket, you can import them directly too.", "With the images imported, go to the Images tab, click on an image, and start drawing bounding boxes! For this project we need two labels \u2014 mask and face. Make sure to pick the correct label in the top left area of the screen. If there are multiple objects in the image, you can mark each one with its own bounding box.", "Finally, it\u2019s time to train your model! Go to the Train tab, and click Start Training. You\u2019ll have to pick either a Cloud Hosted or Edge model. For this tutorial you want Edge, since we\u2019ll be running inferences on the user\u2019s device. I\u2019d also pick \u201cOptimize for faster predictions\u201d, since inferences will be running pretty frequently on the video stream. Finally you\u2019ll have to pick a node hour budget. When getting started, I\u2019d go for only an hour or two, to keep in the free tier. If you have more budget, then you can go for a full 24 hours. In any case, the training will stop as soon as the model converges, and you\u2019ll only be billed for the hours you actually use.", "Then just click Start Training. You\u2019ll get an email when it\u2019s done. In the meantime, you can go do something else, or start looking at the React half of the project! Once you get that email, congrats, you just trained a neural network!", "Once the model is trained, you can tune a couple parameters \u2014 the Confidence Threshold (predictions below that confidence level won\u2019t be reported) and the IoU Threshold (predicted boxes that overlap by more than that amount won\u2019t be reported). You pass those parameters to the AutoML library at runtime, so you can play with your dataset in the Evaluate tab to find the right settings for your model to minimize false positives and false negatives. The docs have a good dive into how to use the evaluation tab. For our dataset, a 0.65 Confidence Threshold and a 0.5 IoU Threshold seemed about right.", "The last step is to actually get the model. Click the TensorFlow.js option on the Test & Use tab, and export it to a bucket. You can then download it and add it to your react project. Or, just make the bucket public (see the Google Storage docs for how to do that), and you can reference it directly from your React code! Speaking of which, it\u2019s now time to start writing some React.", "Step one with a React project, as always, Create React App. We\u2019ll call the project Masky, so the command is npx create-react-app masky (or npx create-react-app masky \u2014 template typescript, if you want a TypeScript app).", "Then, you\u2019ll need to add tfjs for client-side inference, and tfjs-automl to use the AutoML model.", "For this tutorial we\u2019re also using Emotion, but feel free to use whatever styling solution you\u2019d like.", "The basic flow of a webcam-connected TF.js app works like this \u2014 you connect to the user\u2019s webcam with navigator.mediaDevices.getUserMedia, and send the stream to a video element. Once the webcam is connected, you can start a timer to periodically send a ref of the video element to the model. It'll report back with the locations of detected objects (if any). Then you can use that data to show a message on the screen, or use SVGs to render bounding boxes, little COVID viruses, or whatever you want on top of the video. So, there's some state to manage here, and because the setup process takes a few seconds you'll probably want to show status messages to the user so they don't think the app is broken. Let's get to work!", "You can start by adding a video element, plus some styling to make it take up the whole screen but leave room for status messages. The video stream will be different dimensions depending on the device, so it\u2019s a good idea to use absolute positioning to center it in a parent div. Also make sure to add autoPlay, muted, and playsInline to the video element, or the video stream won\u2019t actually start.", "Also, make sure to add transform: scaleX(-1); to the video CSS - that flips the video, so it acts like a mirror. Otherwise moving your head left will move your on-screen head to the right, which feels weird.", "We\u2019ll also set up the wrapping div to change color based on what\u2019s detected \u2014 green for masks, red for unmasked faces.", "With the styling out of the way, we can actually get the webcam stream set up. That\u2019ll require a hook to manage the state, which will handle connecting to the camera and connecting the camera to the video element\u2019s ref.", "This will use navigator.mediaDevices.getUserMedia({video: { facingMode: 'user' }}) to get the video stream. The facingMode tells the browser which camera to use if the device has more than one, like a smartphone. Then we'll create an HTMLVideoElement ref that we'll pass to the video element, and will use that to pass the camera stream to the video.", "Finally, the hook will return the ref to be sent to the video, and a status string that\u2019s helpful for letting the user know how the setup process is going. There\u2019s also a little error handling code, but in practice, I haven\u2019t seen any errors.", "With that code written, we can add the hook to the App component, and pass the ref to the <video>.", "Now run yarn start to serve the app, and you should see yourself. Hello world!", "Now you can see yourself, give yourself a high five! But we still don\u2019t know if you\u2019re wearing your mask or not. Let\u2019s fix that. To do this next part, you\u2019ll need a trained model, so you\u2019ll have to wait for that to finish training, if it hasn\u2019t already.", "tfjs-automl is really simple to use, and loading the model is no exception. You just have to call automl.loadObjectDetection, which will return a Promise of a model. A simple React hook will do the job nicely:", "You just need to pass the URL of the model.json to useDetectionModel. The model.json will then tell the library about the other files it\u2019ll need to download. If you\u2019re hosting the model in a Google Storage bucket (and have it set up as a public bucket), then you can pass in its URL. Otherwise, you can add the model to the public directory of the app and pass a relative URL here.", "When you refresh the page, you should now see the model.json, a dict.txt, and some shard files get downloaded. You\u2019re ready to detect!", "Now that the model is loaded and the camera is connected, it\u2019s time to bring them together. The automl library makes it pretty easy, but there\u2019s still some work to do to manage the state. So it\u2019s time for another custom hook. This one will take the videoRef that we\u2019ll use to get frames from, the model, and an interval to run the model on. Detection is pretty fast, but no so fast that you\u2019ll want to run it on every frame. I found once a second to be fine for this application.", "The first thing to deal with is that you can\u2019t start detecting until the camera and video and initialized \u2014 otherwise the model will throw an error. So we\u2019ll add a useState hook to track when the video is ready, as well as a useState for actually holding the current detection state.", "Then you can just call onVideoReady when the video is initialized:", "With that bit of state management set up, we can actually start doing detections. It\u2019s surprisingly straightforward \u2014 using setInterval, just call model.detect with videoRef.current on a timer, and save the result with setDetections. It really couldn't be simpler. We'll also pass the Confidence Threshold from the model evaluation phase (0.65 in this case) to model.detect.", "There is one more thing to think about \u2014 the first prediction actually takes a few extra seconds to compile, but after that it\u2019s much faster. So to speed things up, we can \u201c warm up\u201d the model while the video is connecting, and then it\u2019ll be ready to immediately start doing quick detections. To do that, you just need to pass an empty tensor to the model:", "and then call that function in a useEffect when the model is set up:", "And that\u2019s it! Add a console.log(detections) to the hook for now, and when the app reloads, you should see it connect and then start logging bounding box locations, tagged as either face or mask. Neat!", "So getting the detection locations is cool, but the user can\u2019t actually see the result yet. The first thing we can show the user is a status \u2014 is there anyone without a mask on screen? If there is, we\u2019ll set the whole thing to be a scary red color. In the first style step, we set the PredictionWrapper div up to handling the styling part, so now it's time to use that!", "Every detected object has a label, so we just have to count up the detected faces and masks, and use that to calculate a status:", "To tell the user what that color means, it\u2019d also be nice to have a status message. That message will let the user know that the model is getting set up, then show what the model has detected. It will just take the video and detection status values, and return a message.", "Then we can use those functions in the component to color the whole site and show the message:", "With all that set up, you\u2019ve got yourself a working on-device mask classifier!", "A classifier is already pretty useful. But we trained a detector, not a classifier, so the model knows specifically where the mask-less offenders are. The doctormasky.com app draws viruses on maskless faces, but to keep it simple for this tutorial, we\u2019ll just draw boxes around the detected faces. You could do that with simple divs or a canvas, but an easy approach is with an inline SVG.", "Here\u2019s the plan: we\u2019ll absolutely position an SVG container that covers the video, and has the same viewBox size as the video. Then, we can use the label and position data returned from the model to draw boxes with the right colors around detected faces.", "Step one is to draw the SVG, and set its viewBox to match the video. That\u2019ll mean that the video coordinates will match the svg coordinate system, which will make everything easier.", "Usually using videoRef.current.videoWidth to get an element size isn't a good idea, since it's not updated when the screen changes. In this case, there will be a render cycle every second when there's a new detection, which will fetch the data. So, we won't worry about it.", "Also, note we need the same transform: scaleX(-1); style as on the video. If you forget this, bounding boxes will be on the wrong side of the screen, which is a very weird experience.", "With the SVG set up, it\u2019s simple to draw SVG rectangles around the detected bounding boxes:", "And that\u2019s really it! Aligning the SVG with the video means you can use the automl bounding boxes without any special processing.", "And with that, we\u2019re done! You\u2019ve trained an object detection neural network, exported it to run on edge devices to protect your users\u2019 privacy, hooked the model into a live video stream, and even arguably made a simple Augmented Reality app. And of course, you helped fight COVID-19. Not bad!", "The final doctormasky.com is a little fancier, with sound (hi Cardi B!) and graphics. If you want to see how all that works, you can take a look at the final code \u2014 but it\u2019s built on the same principals that just went through.", "There\u2019s all kinds of things you could do with this detection tech \u2014 if you want to build a webapp that understands what it\u2019s looking at, now you\u2019ve got the tools. And if you\u2019d like help setting up the next big ML app (or any other application), the actual data scientists at AE who know what they\u2019re doing are here to help!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Tech Lead at AE Studio. Into Elixir, RxJS, ReasonML, Svelte, and other things that will be big next year."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8f78126c1f61&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://will-wow.medium.com/?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": ""}, {"url": "https://will-wow.medium.com/?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "Will Ockelmann-Wagner"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2ea4bde76f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&user=Will+Ockelmann-Wagner&userId=2ea4bde76f7&source=post_page-2ea4bde76f7----8f78126c1f61---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f78126c1f61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f78126c1f61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://cloud.google.com/automl", "anchor_text": "Cloud AutoML"}, {"url": "https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/", "anchor_text": "Custom Vision"}, {"url": "https://ae.studio", "anchor_text": "AE Studio"}, {"url": "http://mrdeeplearning.com", "anchor_text": "Mr. Deep Learning"}, {"url": "https://doctormasky.com", "anchor_text": "doctormasky.com"}, {"url": "https://github.com/agencyenterprise/masky", "anchor_text": "on GitHub"}, {"url": "https://github.com/tensorflow/tfjs/tree/master/tfjs-automl", "anchor_text": "tfjs-automl"}, {"url": "https://cloud.google.com/vision/automl/docs/edge-quickstart", "anchor_text": "edge device model quickstart docs"}, {"url": "https://cloud.google.com/vision/automl/pricing#automl-vision-edge", "anchor_text": "docs"}, {"url": "https://www.flickr.com/", "anchor_text": "Flikr"}, {"url": "https://www.kaggle.com/datasets", "anchor_text": "Kaggle"}, {"url": "https://cloud.google.com/vision/automl/object-detection/docs/evaluate", "anchor_text": "The docs"}, {"url": "https://cloud.google.com/storage/docs/access-control/making-data-public#buckets", "anchor_text": "the Google Storage docs"}, {"url": "https://reactjs.org/docs/create-a-new-react-app.html", "anchor_text": "Create React App"}, {"url": "https://github.com/tensorflow/tfjs", "anchor_text": "tfjs"}, {"url": "https://github.com/tensorflow/tfjs/tree/master/tfjs-automl", "anchor_text": "tfjs-automl"}, {"url": "https://emotion.sh/", "anchor_text": "Emotion"}, {"url": "https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia", "anchor_text": "navigator.mediaDevices.getUserMedia"}, {"url": "https://www.tensorflow.org/js/guide/platform_environment#shader_compilation_texture_uploads", "anchor_text": "warm up"}, {"url": "https://doctormasky.com/", "anchor_text": "doctormasky.com"}, {"url": "https://doctormasky.com", "anchor_text": "doctormasky.com"}, {"url": "https://github.com/agencyenterprise/masky/blob/master/src/components/Detector.tsx", "anchor_text": "final code"}, {"url": "https://ae.studio/#robot-here", "anchor_text": "actual data scientists at AE"}, {"url": "https://blog.ae.studio/doctor-masky/", "anchor_text": "https://blog.ae.studio"}, {"url": "https://medium.com/tag/object-detection?source=post_page-----8f78126c1f61---------------object_detection-----------------", "anchor_text": "Object Detection"}, {"url": "https://medium.com/tag/automl-vision?source=post_page-----8f78126c1f61---------------automl_vision-----------------", "anchor_text": "Automl Vision"}, {"url": "https://medium.com/tag/react?source=post_page-----8f78126c1f61---------------react-----------------", "anchor_text": "React"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----8f78126c1f61---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----8f78126c1f61---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8f78126c1f61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&user=Will+Ockelmann-Wagner&userId=2ea4bde76f7&source=-----8f78126c1f61---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8f78126c1f61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&user=Will+Ockelmann-Wagner&userId=2ea4bde76f7&source=-----8f78126c1f61---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f78126c1f61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8f78126c1f61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8f78126c1f61---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8f78126c1f61--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8f78126c1f61--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8f78126c1f61--------------------------------", "anchor_text": ""}, {"url": "https://will-wow.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://will-wow.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Will Ockelmann-Wagner"}, {"url": "https://will-wow.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "7 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2ea4bde76f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&user=Will+Ockelmann-Wagner&userId=2ea4bde76f7&source=post_page-2ea4bde76f7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F2ea4bde76f7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fim-not-a-data-scientist-but-made-a-covid-mask-detector-with-google-automl-and-react-doctor-masky-8f78126c1f61&user=Will+Ockelmann-Wagner&userId=2ea4bde76f7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}