{"url": "https://towardsdatascience.com/transcribing-interview-data-from-video-to-text-with-python-5cdb6689eea1", "time": 1683017355.469467, "path": "towardsdatascience.com/transcribing-interview-data-from-video-to-text-with-python-5cdb6689eea1/", "webpage": {"metadata": {"title": "Transcribing interview data from video to text with Python | by Alan Davies | Towards Data Science", "h1": "Transcribing interview data from video to text with Python", "description": "Occasionally I have the need to interview participants for various research projects. Often grant funding for such projects will cover transcription costs. Human transcribers remain the gold standard\u2026"}, "outgoing_paragraph_urls": [{"url": "https://build-system.fman.io/qt-designer-download", "anchor_text": "https://build-system.fman.io/qt-designer-download", "paragraph_index": 16}], "all_paragraphs": ["Occasionally I have the need to interview participants for various research projects. Often grant funding for such projects will cover transcription costs. Human transcribers remain the gold standard for this sort of work and usually do an excellent job. You could of course transcribe your own interviews but this can be a very time consuming and laborious task. Some qualitative researchers also advocate transcribing your own interviews as a way of becoming more familiar with the data.", "There also exist various software for this task, including free trials and software with various pricing models. Creating a script to do this yourself using Python is also relatively easy. Faced with having to transcribe several fairly lengthy interviews (> 1 hour each) carried out online, I decided to create a simple program with a graphical interface to manage this process. This short blog describes and implements the basic concept as a single script and then shows how we can add a Graphical User Interface (GUI) and use threads to improve performance.", "This assumes the reader has some experience with Python and is familiar with concepts like Object Orientated Programming (OOP). The example uses Python 3.x and PyQt5.", "For this we need 3 modules, speech_recognition, wave and moviepy. These can be installed in the standard way using pip.", "They can then be imported into the Python file along with the other required modules:", "For now, we will hard code the mp4 video file to import and the audio file we will create when converting the video to audio:", "Next, we can use the AudioFileClip class from the moviepy.editor to convert the video to audio. This will convert the video to audio, specifically a wav file.", "The next step is to convert this audio file into text. The issue with this is that there is a limit of around 10 MB for single requests sent to the API. This means we need to transcribe the audio in stages. To do this it would be helpful to first to know the duration of the audio file so that we can divide it up into manageable chunks.", "The contextlib.closing works with the with statement to inform the context manager when the code block is entered and exited. Here we open the wav file using the wave library and obtain the number of frames and the framerate with which we can calculate the duration of the file.", "This can now be divided into some suitable number for transcribing the file in chunks. In this example, we used 60 seconds.", "Next, we can create an instance of the speech recognizer", "Finally, we can convert the audio to text. The record function can use a duration (in seconds). Subsequent record lines in the with statement will continue where the last left off. Here we use an offset to capture the next 60-second chunk and write the transcribed text to a text file. To recognize the speech we use recognize_google. There are alternatives such as recognize_bing(), recognize_wit() and recognize_google_cloud(). We can write the transcribed text to a text file. We add an extra space so the subsequent sentences have spaces between them.", "The full script can be seen below:", "Adding a Graphical User Interface (GUI)", "The basic script works but it would be more useful if we could add a GUI. This can help with locating files and adding features like a progress bar to monitor progress for large transcriptions. We can also display the transcribed text in a text box on the screen rather than using the console. I mostly use web frameworks like Flask for building front ends and add GUI elements using HTML, CSS so this was the first time I had attempted to make a non-web-based GUI in Python. After doing a bit of research on which tools to use, I came across PyQt. Qt is a cross-platform framework (written in C++) that provides an open-source toolkit for creating GUIs.", "The latest version of this is PyQt5, which provides a set of useful libraries for generating GUIs and can be installed with pip like so:", "Another useful tool associated with Qt is the QT Designer tool for Windows or Mac (which can be downloaded from: https://build-system.fman.io/qt-designer-download). This allows one to drag and drop common user interface (UI) elements onto a window to generate a front end visually. The image below shows the simple front end generated for the transcription application.", "Here we have a simple menu with \u201cFile\u201d which contains \u201cOpen mp4 video recording\u201d and \u201cnew\u201d. We also have an \u201cAbout\u201d option which contains an \u201cAbout vid2text\u201d. There is a label on the main window to display the video file that was selected by the user. The user can type in a file name in the box below for the transcription to be written to. Next we have the transcribe button which is disabled by default until a video file is selected. Under this there is a progress bar to update the user on the current progress of the transcription. This is followed by a text box to display the text of the transcription. Finally there is a label at the bottom of the screen to show various messages to the users.", "Once the front end has been constructed visually using the designer, we can save the file as a *.ui file. Using the command line (e.g. the terminal or Anaconda prompt) we can run the following command to generate Python code from the ui file.", "When we run the following code, it produces Python code for the GUI we designed with the QT Designer as shown below. The \u2013o writes the output to a file and \u2013x generates additional code to test the class.", "If we run the Python file, it will launch a window that looks just the UI we created. Apart from generating the various UI components there is no other functionality. We need to add this ourselves. To add the functionality from the earlier simple script, we can start with the menu items by connecting a click on the menu to a class method. Here we write the name of the method (i.e. self.open_audio_file) we want to call without the parentheses (round brackets) using triggered.connect().", "It would be better if we could open a file dialog box and let the user choose a file to work with. To implement a file dialog box, we can us QFileDialog which first needs to be imported from PyQt5 QtWidgets.", "The corresponding method uses the QFileDialog to launch a file dialog box so the user can select the required video file. The selected file name and path can be stored in the file_name variable. This returns a tuple with the first element containing the file name/path. We can check it ends in mp4 and if so we can then enable the transcribe button. Next, we can store the filename in the self.mp4_file_name variable. We also clear the message label in case it contained a previous error message. Finally, we can then update the label to display the selected file. If the file does not end in mp4, we can display a suitable message to the user asking them to select an mp4 file.", "When a user clicks on the menu item we launch a file dialog box for the user to select the appropriate file.", "Next, we can create a link to a method to start the transcription. For this we can use clicked.connect and pass in the method we want to call, in this case process_and_transcribe_audio.", "This method disables the transcription button so it can\u2019t be pressed again until the transcription is completed. It then calls two further methods, one to convert the video to audio and the next to transcribe into text.", "First, we need to import the AudioFileClip class from moviepy.", "Next, we can add an initialize method to the class. Here we can set some variables to store the mp4 file name, the output file and the audio (wav) file name that we will convert the video file into.", "The convert method works as before and produces the speech.wav audio file for the transcript.", "Once converted into audio format, we can now start the transcription. Here we get the filename from the text the user entered into the output file name text box.", "We get the text from the textbox using the toPlainText() method. If they don\u2019t enter anything we can use the default name \u201cmy_speech_file.txt\u201d. We check this by looking for the length of text entered, which should be greater than 0. The core transcription code works as before. After this we set the progress bar to 100%, re-enable the transcribe button and clear any messages from the message label.", "We also created a method to determine the length of the audio file (self.get_audio_duration) in the same way as before, as well as a method to update the value of the progress bar.", "When we run the code, the GUI freezes and says \u201cnot responding\u201d. We can\u2019t close the app, or interact with it in any way. The progress bar also won\u2019t update until the task is complete rendering it useless.", "This is especially noticeable with larger recordings (an hour plus). Obviously, this doesn\u2019t look very good and provides a terrible user experience. One way to overcome this is to run these tasks as background tasks.", "To overcome this issue we can use threads. Threads (threads of execution) let us run tasks simultaneously, so rather than locking the GUI until finished, we can instead run this task in the background. Here we use QThreads, these are more or less similar in functionality to Python threads but integrate better with Qt.", "There are two processes that tend to take some time in this application. The first is the conversion of video to audio; the second is the transcription itself. We can use threads for both of these to improve the performance.", "Let\u2019s start off with a thread for the video to audio conversion. Here we make a new class called convertVideoToAudioThread using QThread. We can pass any variables we need to interact with into the initialization function __init__, in this case the mp4 file name and audio output file name.", "We can then place the main video to audio conversion code in a run method.", "It\u2019s worth noting that we don\u2019t call the run method directly when using threads, instead, it is run by using the threads start() method. Finally, we can add a class destructor that uses the wait() method to block the thread. The del method is called when an object is garbage collected.", "We can then update the convert_mp4_to_wav method to use the thread. Here we also add some messages to update the user about what the application is doing. We then create a thread called convert_thread and create an instance of the convertVideoToAudioThread passing in the mp4 and audio filenames. To start the thread we use the start() method which will execute the run method. Finally, we can call another method when the thread has finished using the finished.connect() method. Here we use it to call our finished_converting() method.", "The finished converting method displays a message to the user that the conversion is complete and then runs the transcribe_audio() method. We will also create a thread for the main transcription as well.", "We create a transcriptionThread class to deal with transcribing. This works in much the same way as the initial thread with a few extra features.", "We also added a try, except. This is because if the speech recognizer cannot recognize an input, i.e. due to some background noise; it will generate an UnknownValueError which will terminate the program. The change_value = pyqtSignal(int) is used to emit a signal (an integer) while the thread is running which we can use to update the progress bar. In the run method the line:", "This emits the value of the for loop counter. This change in value is picked up by the threads change_value method which in turn calls the set_progress_value method:", "We can then modify the transcribe_audio function to use the new thread.", "The image below shows the final version. The progress bar updates to show the transcription progress. When complete we load the text file contents into the text area, which automatically adds scroll bars if needed.", "Finally, we can add functionality to the new and about menu options. New simply clears the text fields and resets the progress bar. The about option makes use of QMessageBox to display a message with the authors details. We can set the text, title and an icon, in this case, an information icon.", "The output of which looks like this:", "The final code can be seen here:", "This application provides a very basic example with minimal functionality. This could be improved in many ways, such as providing an option to load either an mp4 ort wav file, being able to choose different speech recognizers and displaying additional information such as file size/duration. Simple applications can be improved with graphical user interfaces which are easy to add in Python using tools like PyQt and QT Designer, we can also overcome performance issues using threading and making computationally expensive tasks run in the background so as not to impact the user experience.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior Lecturer Health Data Science University of Manchester, UK"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5cdb6689eea1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://alandavies6386.medium.com/?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": ""}, {"url": "https://alandavies6386.medium.com/?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "Alan Davies"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fecfe914b6d83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&user=Alan+Davies&userId=ecfe914b6d83&source=post_page-ecfe914b6d83----5cdb6689eea1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cdb6689eea1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cdb6689eea1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://build-system.fman.io/qt-designer-download", "anchor_text": "https://build-system.fman.io/qt-designer-download"}, {"url": "https://medium.com/tag/speech-recognition?source=post_page-----5cdb6689eea1---------------speech_recognition-----------------", "anchor_text": "Speech Recognition"}, {"url": "https://medium.com/tag/threads?source=post_page-----5cdb6689eea1---------------threads-----------------", "anchor_text": "Threads"}, {"url": "https://medium.com/tag/interviews-and-insights?source=post_page-----5cdb6689eea1---------------interviews_and_insights-----------------", "anchor_text": "Interviews And Insights"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----5cdb6689eea1---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----5cdb6689eea1---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5cdb6689eea1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&user=Alan+Davies&userId=ecfe914b6d83&source=-----5cdb6689eea1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5cdb6689eea1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&user=Alan+Davies&userId=ecfe914b6d83&source=-----5cdb6689eea1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cdb6689eea1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5cdb6689eea1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5cdb6689eea1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5cdb6689eea1--------------------------------", "anchor_text": ""}, {"url": "https://alandavies6386.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://alandavies6386.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alan Davies"}, {"url": "https://alandavies6386.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "134 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fecfe914b6d83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&user=Alan+Davies&userId=ecfe914b6d83&source=post_page-ecfe914b6d83--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F104e499b7a8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranscribing-interview-data-from-video-to-text-with-python-5cdb6689eea1&newsletterV3=ecfe914b6d83&newsletterV3Id=104e499b7a8c&user=Alan+Davies&userId=ecfe914b6d83&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}