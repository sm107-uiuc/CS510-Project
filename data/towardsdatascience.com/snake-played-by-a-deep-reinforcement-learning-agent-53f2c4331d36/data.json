{"url": "https://towardsdatascience.com/snake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36", "time": 1683012179.323328, "path": "towardsdatascience.com/snake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36/", "webpage": {"metadata": {"title": "Snake Played by a Deep Reinforcement Learning Agent | by Hennie de Harder | Towards Data Science", "h1": "Snake Played by a Deep Reinforcement Learning Agent", "description": "Ever since I watched the Netflix documentary AlphaGo, I have been fascinated by Reinforcement Learning. Reinforcement Learning is comparable with learning in real life: you see something, you do\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/henniedeharder/snake", "anchor_text": "my GitHub", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1312.5602.pdf", "anchor_text": "Playing Atari with Deep Reinforcement Learning", "paragraph_index": 38}, {"url": "https://hennie-de-harder.medium.com/subscribe", "anchor_text": "subscribe", "paragraph_index": 39}], "all_paragraphs": ["Ever since I watched the Netflix documentary AlphaGo, I have been fascinated by Reinforcement Learning. Reinforcement Learning is comparable with learning in real life: you see something, you do something, and your act has positive or negative consequences. You learn from the consequences and adjust your actions accordingly. Reinforcement Learning has many applications, like autonomous driving, robotics, trading and gaming. In this post, I will show how the computer can learn to play the game Snake using Deep Reinforcement Learning.", "If you are familiar with Deep Reinforcement Learning, you can skip the following two sections.", "The concept behind Reinforcement Learning (RL) is easy to grasp. An agent learns by interacting with an environment. The agent chooses an action, and receives feedback from the environment in the form of states (or observations) and rewards. This cycle continues forever or until the agent ends in a terminal state. Then a new episode of learning starts. Schematically, it looks like this:", "The goal of the agent is to maximize the sum of the rewards during an episode. In the beginning of the learning phase the agent explores a lot: it tries different actions in the same state. It needs this information to find the best actions possible for the states. When the learning continues, exploration decreases. Instead, the agent will exploit his moves: this means he will choose the action that maximizes the reward, based on his experience.", "Deep Learning uses artificial neural networks to map inputs to outputs. Deep Learning is powerful, because it can approximate any function with only one hidden layer\u00b9. How does it work? The network exists of layers with nodes. The first layer is the input layer. Then the hidden layers transform the data with weights and activation functions. The last layer is the output layer, where the target is predicted. By adjusting the weights the network can learn patterns and improve its predictions.", "As the name suggests, Deep Reinforcement Learning is a combination of Deep Learning and Reinforcement Learning. By using the states as the input, values for actions as the output and the rewards for adjusting the weights in the right direction, the agent learns to predict the best action for a given state.", "Let\u2019s apply these techniques to the famous game Snake. I bet you know the game, the goal is to grab as many apples as possible while not walking into a wall or the snake\u2019s body. I build the game in Python with the turtle library.", "To prepare the game for a RL agent, let\u2019s formalize the problem. Defining the actions is easy. The agent can choose between going up, right, down or left. The rewards and state space are a bit harder. There are multiple solutions, and one will work better than the other. For now, let\u2019s try the following. If the snake grabs an apple, give a reward of 10. If the snake dies, the reward is -100. To help the agent, give a reward of 1 if the snake comes closer to the apple, and a reward of -1 if the snake moves away from the apple.", "There are a lot of options for the state: you can choose to give scaled coordinates of the snake and the apple or to give directions to the location of the apple. An important thing to do is to add the location of obstacles (the wall and body) so the agent learns to avoid dying. Below a summary of actions, state and rewards. Later in the article you can see how adjustments to the state affect performance.", "By adding some methods to the Snake program, it\u2019s possible to create a Reinforcement Learning environment. The added methods are: reset(self), step(self, action) and get_state(self) . Besides this it\u2019s necessary to calculate the reward every time the agent takes a step (check out run_game(self)).", "The agent uses a Deep Q Network to find the best actions. The parameters are:", "If you are interested in the code, you can find it on my GitHub.", "Now it is time for the key question! Does the agent learn to play the game? Let\u2019s find out by observing how the agent interacts with the environment.", "The first games, the agent has no clue:", "The first apple! It still seems like the agent doesn\u2019t know what he is doing\u2026", "End of game 13 and beginning of game 14:", "The agent learns: it doesn\u2019t take the shortest path but finds his way to the apples.", "Wow, the agent avoids the body of the snake and finds a fast way to the apples, after playing only 30 games!", "The agent learns to play snake (with experience replay), but maybe it\u2019s possible to change the state space and achieve similar or better performance. Let\u2019s try the following four state spaces:", "Can you make a guess and rank them from the best state space to the worst after playing 50 games?", "Here is a graph with the performance using the different state spaces:", "It is clear that using the state space with the directions (the original state space) learns fast and achieves the highest return. But the state space using the coordinates is improving, and maybe it can reach the same performance when it trains longer. A reason for the slow learning might be the number of possible states: 20\u2074*2\u2074*4 = 1,024,000 different states are possible (the snake canvas is 20*20 steps, there are 2\u2074 options for obstacles, and 4 options for the current direction). For the original state space the number of possible states is equal to: 3\u00b2*2\u2074*4 = 576 (3 options each for above/below and left/right). 576 is more than 1,700 times smaller than 1,024,000. This influences the learning process.", "What about the rewards? Is there a better way to program them?", "Recall that our rewards were formatted like this:", "Blooper #1: Walk in CirclesWhat if we change the reward -1 to 1? By doing this, the agent will receive a reward of 1 every time it survives a time step. This can slow down learning in the beginning, but in the end the agent won\u2019t die, and that\u2019s a pretty important part of the game!", "Well, does it work? The agent quickly learns how to avoid dying:", "Blooper #2: Hit the WallNext try: change the reward for coming closer to the apple to -1, and the reward of grabbing an apple to 100, what will happen? You might think: the agent receives a -1 for every time step, so it will run to the apples as fast as possible! This could be the truth, but there\u2019s another thing that might happen\u2026", "One secret behind fast learning of the agent (only needs 30 games) is experience replay. In experience replay the agent stores previous experiences and uses these experiences to learn faster. At every normal step, a number of replay steps (batch_size parameter) is performed. This works so well for Snake because given the same state action pair, there is low variance in reward and next state.", "Blooper #3: No Experience ReplayIs experience replay really that important? Let\u2019s remove it! For this experiment a reward of 100 for eating an apple is used.", "This is the agent without using experience replay after playing 2500 games:", "After 3000 games, the highest number of apples caught in one game is 2.", "After 10000 games, the highest number is 3\u2026 Was this 3 learning or was it luck?", "It seems indeed that experience replay helps a lot, at least for these parameters, rewards and this state space. How many replay steps per step are necessary? The answers might surprise you. To answer this question we can play with the batch_size parameter (mentioned in the section Creating the Environment and the Agent). In the original experiment the value of batch_size was 500.", "An overview of returns with different experience replay batch sizes:", "Even with batch size 2 the agent learns to play the game. In the graph you can see the impact of increasing the batch size, the same performance is reached more than 100 games earlier if batch size 4 is used instead of batch size 2.", "The solution presented in this article gives results. The agent learns to play snake and achieves a high score (number of apples eaten) between 40 and 60 after playing 50 games. That is way better than a random agent!", "The attentive reader would say: \u2018The maximum score for this game is 399. Why doesn\u2019t the agent achieve a score of anything close to 399? There\u2019s a huge difference between 60 and 399!\u2019 That\u2019s right! And there is a problem with the solution from this article: the agent does not learn to avoid enclosing. The agent learns to avoid obstacles directly surrounding the snake\u2019s head, but it can\u2019t see the whole game. So the agent will enclose itself and die, especially when the snake is longer.", "An interesting way to solve this problem is to use pixels and Convolutional Neural Networks in the state space\u00b2. Then it is possible for the agent to \u2018see\u2019 the whole game, instead of just nearby obstacles. It can learn to recognize the places it should go to avoid enclosing and get the maximum score.", "[2] Mnih et al, Playing Atari with Deep Reinforcement Learning (2013)", "Don\u2019t forget to subscribe if you\u2019d like to get an email whenever I publish a new article. \u2764", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "\ud83d\udcc8 Data Scientist with a passion for math \ud83d\udcbb Currently working at IKEA and BigData Republic \ud83d\udca1 I share tips & tricks and fun side projects"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F53f2c4331d36&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://hennie-de-harder.medium.com/?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": ""}, {"url": "https://hennie-de-harder.medium.com/?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "Hennie de Harder"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffb96be98b7b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&user=Hennie+de+Harder&userId=fb96be98b7b9&source=post_page-fb96be98b7b9----53f2c4331d36---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F53f2c4331d36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F53f2c4331d36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/henniedeharder/snake", "anchor_text": "my GitHub"}, {"url": "https://towardsdatascience.com/how-i-learned-my-computer-to-play-spot-it-using-opencv-and-deep-learning-ad1f017a3ec3", "anchor_text": "How I taught my computer to play Spot it! using OpenCV and Deep LearningSome fun with computer vision and CNNs with a small dataset.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/solving-nonograms-with-120-lines-of-code-a7c6e0f627e4", "anchor_text": "Solving Nonograms with 120 Lines of CodePuzzles, combinations and solution gifs.towardsdatascience.com"}, {"url": "https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/notes/Sonia_Hornik.pdf", "anchor_text": "Multilayer feedforward networks are universal approximators"}, {"url": "https://arxiv.org/pdf/1312.5602.pdf", "anchor_text": "Playing Atari with Deep Reinforcement Learning"}, {"url": "https://hennie-de-harder.medium.com/subscribe", "anchor_text": "subscribe"}, {"url": "https://medium.com/tag/deep-q-learning?source=post_page-----53f2c4331d36---------------deep_q_learning-----------------", "anchor_text": "Deep Q Learning"}, {"url": "https://medium.com/tag/snake?source=post_page-----53f2c4331d36---------------snake-----------------", "anchor_text": "Snake"}, {"url": "https://medium.com/tag/experience-replay?source=post_page-----53f2c4331d36---------------experience_replay-----------------", "anchor_text": "Experience Replay"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----53f2c4331d36---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-neural-network?source=post_page-----53f2c4331d36---------------artificial_neural_network-----------------", "anchor_text": "Artificial Neural Network"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F53f2c4331d36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&user=Hennie+de+Harder&userId=fb96be98b7b9&source=-----53f2c4331d36---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F53f2c4331d36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&user=Hennie+de+Harder&userId=fb96be98b7b9&source=-----53f2c4331d36---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F53f2c4331d36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F53f2c4331d36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----53f2c4331d36---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----53f2c4331d36--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----53f2c4331d36--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----53f2c4331d36--------------------------------", "anchor_text": ""}, {"url": "https://hennie-de-harder.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://hennie-de-harder.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Hennie de Harder"}, {"url": "https://hennie-de-harder.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffb96be98b7b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&user=Hennie+de+Harder&userId=fb96be98b7b9&source=post_page-fb96be98b7b9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F262470d3fe9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsnake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36&newsletterV3=fb96be98b7b9&newsletterV3Id=262470d3fe9a&user=Hennie+de+Harder&userId=fb96be98b7b9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}