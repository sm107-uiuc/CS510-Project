{"url": "https://towardsdatascience.com/gans-a-different-perspective-3f2648da6a28", "time": 1683015405.21276, "path": "towardsdatascience.com/gans-a-different-perspective-3f2648da6a28/", "webpage": {"metadata": {"title": "GANs: A Different Perspective. An intuitive and hassle-free\u2026 | by Alireza Koochali | Towards Data Science", "h1": "GANs: A Different Perspective", "description": "Generative Adversarial Networks (GANs) are one of the hottest topics in the modern AI field. In this article, we will look at GANs from a different perspective i.e., rather than viewing GANs as a\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Generative Adversarial Networks (GANs) are one of the hottest topics in the modern AI field. In this article, we will look at GANs from a different perspective i.e., rather than viewing GANs as a generator of beautiful images but as a probability distributions transformer function. We will explore the GAN\u2019s core idea without getting ourselves tangled with implementation and complicated mathematics. We start by analyzing the type of problem we have at hand. Then we perceive how the requirements of the solution shape the GAN idea.", "Assume that we own an amusement park. In this park, we have a machine that takes 10 dollars in and randomly returns an item with a value between 1 dollar to 100 dollars. The machine is very popular among visitors since they win very cool and expensive stuff from time to time. Additionally, the machine is quite profitable for us. Hence, the machine\u2019s giveaway selection logic hit exactly the sweet spot where it secures both our and customers\u2019 satisfaction.", "Consequently, we want to add more of this machine to gain even more profit. However, there is one problem. The machine is super expensive. Hence, we are interested to build our machine. To do so, we need to figure out the machine\u2019s item selection logic. Obviously, the key argument for selecting an item is its value. If an item is expensive it should be less probable to be selected to guarantee our profit. However, if we decrease the probability of selecting expensive items aggressively, it will result in visitors\u2019 dissatisfaction. Therefore, our goal is to learn the probability distribution of items\u2019 value as precisely as possible. To start with, we have a list of the previous machine\u2019s giveaways with their corresponding prices. First, we attempt to look at the distribution of giveaways. If the distribution were similar to a well-known probability distribution the problem is solved. We use that probability distribution as the heart of our new machine\u2019s item selection logic. We sample from this distribution to determine which item to return.", "However, if we encounter a complex distribution of giveaways, we need to devise a method to learn the probability distribution of a generative process given only the samples from the distribution.", "In other words, we need a model that looks at our data and figures out the machine logic. The main takeaway is that \u201clearning the probability distribution of data is the main task of the data generation.\u201d", "Let\u2019s portray our goals on an abstract level. To begin with, we have a set of data that we call them real data from this point on. Our goal is forging artificial data which are similar to real data. The artificial data is normally referred to as fake data. Therefore, we need a model that looks at real data and generates realistic fake data. Pretty clear target. Now, We need to move from our abstract target toward a more detailed description of our task and desirably connect it to something more familiar. To do so, we need to change our perspective on the problem. First, we need to get familiar with the transform function. Assume that we have a set of samples from a probability distribution. By applying a transform function we can transform these samples from their original distribution to the desired target distribution. Theoretically, we can transform from any source distribution to any target distribution. However, calculating these transform functions is not always analytically possible.", "Now, let\u2019s go back to our problem. We can reframe our generation problem as a transformation task. We start with a known distribution. Normally, we select a Gaussian distribution with mean 0 and standard deviation 1. We call this distribution \u201clatent space\u201d. Now, we need to define a transform function that transforms samples from our latent space to data space. In other words, our transform function takes a sample from the latent space and outputs a sample in the data space aka a data point. And Voil\u00e0! We generate data! There is only one problem. It is not possible to define this function analytically. However, don\u2019t we use neural networks to approximate complex functions that are impossible to define analytically? Yes, we do and that\u2019s exactly what we are going to do. We use a neural network to approximate our transform function. We call this neural network \u201cGenerator\u201d since, in the end, it will generate data. Quite sensible.", "Now that it comes to using a neural network, we need to define a loss function to train our network. The loss function is the key to proper training and realistic data generation. Therefore, we need to define it precisely in alignment with our goals.", "In general, the loss function evaluates how well our neural network is performing regarding our goal and provides feedback (in the form of gradients) to the model to improve itself. Here, we need a loss function to measure how well our generated data follow real data distribution. In other words, we want a loss function that can tell us how realistic our fake data are. Still, we don\u2019t have any information about real data distribution. This was our main problem from the beginning. However, we can achieve the same goal using discrimination between real data and fake data.", "Assume our loss function can differentiate between real data and fake data.", "Then, we can provide our fake data to this function. For those fake samples which are indistinguishable from real data, we don\u2019t need to do anything. For the other fake samples, the loss function would provide feedback to update and improve our generator.", "In more concrete terms, we can use a classifier as the loss function that can classify between real and fake data. If a generated data point is classified as real, it means it is similar to real data, and we do not need to take any further action. For those fake samples which are identified as generated data, we would ask the loss function how should we update our generator to make these sample look more realistic. The loss function provides the answer in the form of a gradient to update weights in our neural network.", "It seems we have found the final piece of our solution! However, we have to take care of yet another problem. While our suggested loss function satisfies our requirements, it is not straightforward to implement it in practice. Hence, our loss function is a complex function that we can define its characteristics, but we cannot directly implement it. Look like a dead end. But what holds us back to approximate this loss function using a neural network? Nothing! So, let\u2019s do it. We can use a classifier neural network as our loss function. We call this network \u201cDiscriminator\u201d because it discriminates between real and fake data. Very sensible naming.", "Best of all, we are quite familiar with using neural networks for classification. We know how to train them, their loss function and how should their input and output look like. However, training two neural networks simultaneously is not something conventional. Now, the final question is, how should we train all of these networks together.", "If we had the perfect classifier before we start training our generator, our training would become very straightforward. Unfortunately, at the beginning of the training process, our discriminator is as clueless as our generator. Even worse, we cannot train the discriminator before starting to train the generator since we need fake data to train the discriminator. As you can see, these two networks dependent on each other for training. The generator needs feedback from the discriminator to improve and the discriminator needs to be kept updated with improvements of the generator. Therefore, we train them interchangeably. For one batch, we train discriminator to classify real and fake samples. Then for one batch, we train the generator to generate samples that are identified as real by the discriminator. This method is called \u201cAdversarial training\u201d. When we use adversarial training for the data generation task, we get Generative Adversarial Network or in short GAN.", "However, when we look at the training procedure, we do not see \u201cadversary\u201d per se. To find out where does the term \u201cadversarial training\u201d comes from, we should look closely at the objectives of two networks. The goal of the discriminator is to classify real and fake data as accurately as possible. Therefore, in the discriminator training phase, the discriminator attempts to identify the fake samples correctly. On the other hand, we train the generator to generate realistic fake data. To pass the authenticity test, the generator should convince the discriminator that its generated data are real. In other words, the generator tries to fool the discriminator while the discriminator attempts to not be fooled by the generator. These contradicting objectives set the training process into motion.", "During the training, both networks improve with regard to their goals. Finally, at some point, the generator becomes so good that the discriminator cannot differentiate between fake and real data and that\u2019s the point where we are done with training.", "GANs are a beautiful yet complex solution for a very difficult problem. With GAN, we have a fast, efficient, and precise answer for a long-lasting problem and it paves the way for many thrilling applications. However, before jump into the application, we should be aware of the GANs\u2019 common problems. First of all, the generator is a neural network and by definition, it is a black-box. While a trained generator embeds information regarding real data distribution into its weight, we do not have access to it explicitly. When we are dealing with low dimension data, we can retrieve this information via sampling but for higher dimensionalities, we cannot do anything. Furthermore, unlike other neural networks, the GANs loss function provides little information about training progress. During the training, we need to check samples of generators manually to inspect training progress. Finally, as previously mentioned, the training takes place through the fight between generator and discriminator. If they stop fighting each other, the training process will step, and unfortunately, they often stop fighting after some time. Many reasons can contribute to this problem. For example, if one of the networks improves much faster than the other one, it can overpower the other network and the training would stop. Thus, network architectures should be balanced. But what does the balance mean? There is no straightforward answer to this question. Normally, one should find them through trial and error. Therefore, the GAN training process is quite unstable. There are lots of solutions suggested for stability problems however they mostly solve one and add another or require some specific conditions to be satisfied. In short, improving GAN\u2019s training progress is still an open problem and the research community around it is very active.", "Let\u2019s get back to our expensive machine in the beginning. That machine symbolizes all expensive data generation processes in terms of time and resources. Assume we have a mid-size dataset of people\u2019s faces and for an application, we need a bigger dataset. We can pick up our camera and taking pictures of people and add them to the dataset. However, this is a time-consuming process. Now, if we train a GAN on the available images, we can generate hundreds of images in a matter of seconds. Hence, data augmentation is one of the most prominent applications of GANs.", "Data scarcity is not the only motivation. Let\u2019s get back to the people\u2019s faces dataset. If we want to use those photos, we will most probably run into a problem regarding privacy concerns. But what if we use fake images of people who do not actually exist? perfectly fine! No one will be concerned. Thus, the GANs provide a neat solution for privacy concerns around the data.GAN\u2019s research community is very active right now and every day a new application or improvement is proposed. Still, there is a lot that remained to be discovered. This is just the tip of the iceberg.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Ph.D. student @ FLaP, a joint lab between DFKI and IAV. \\\\Deep Learning//"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3f2648da6a28&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@alireza.koochali?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alireza.koochali?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "Alireza Koochali"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F62301102a72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&user=Alireza+Koochali&userId=62301102a72&source=post_page-62301102a72----3f2648da6a28---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f2648da6a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f2648da6a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3f2648da6a28---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----3f2648da6a28---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----3f2648da6a28---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/probability-distributions?source=post_page-----3f2648da6a28---------------probability_distributions-----------------", "anchor_text": "Probability Distributions"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----3f2648da6a28---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3f2648da6a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&user=Alireza+Koochali&userId=62301102a72&source=-----3f2648da6a28---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3f2648da6a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&user=Alireza+Koochali&userId=62301102a72&source=-----3f2648da6a28---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f2648da6a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3f2648da6a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3f2648da6a28---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3f2648da6a28--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3f2648da6a28--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3f2648da6a28--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alireza.koochali?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alireza.koochali?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alireza Koochali"}, {"url": "https://medium.com/@alireza.koochali/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "17 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F62301102a72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&user=Alireza+Koochali&userId=62301102a72&source=post_page-62301102a72--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd71903e1596c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-a-different-perspective-3f2648da6a28&newsletterV3=62301102a72&newsletterV3Id=d71903e1596c&user=Alireza+Koochali&userId=62301102a72&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}