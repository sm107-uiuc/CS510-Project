{"url": "https://towardsdatascience.com/a-gentle-introduction-to-exploratory-data-analysis-f11d843b8184", "time": 1682994625.618689, "path": "towardsdatascience.com/a-gentle-introduction-to-exploratory-data-analysis-f11d843b8184/", "webpage": {"metadata": {"title": "A Gentle Introduction to Exploratory Data Analysis | by Daniel Bourke | Towards Data Science", "h1": "A Gentle Introduction to Exploratory Data Analysis", "description": "Pink singlet, dyed red hair, plated grey beard, no shoes, John Lennon glasses. What a character. Imagine the stories he\u2019d have. He parked his moped and walked into the cafe. This cafe is a local\u2026"}, "outgoing_paragraph_urls": [{"url": "http://maxkelsen.com", "anchor_text": "Max Kelsen", "paragraph_index": 2}, {"url": "http://bit.ly/AIMastersDegree", "anchor_text": "my own AI Masters Degree", "paragraph_index": 19}, {"url": "https://github.com/dformoso/sklearn-classification/blob/master/Data%20Science%20Workbook%20-%20Census%20Income%20Dataset.ipynb", "anchor_text": "the link", "paragraph_index": 29}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html", "anchor_text": ".LabelEncoder()", "paragraph_index": 85}, {"url": "https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4", "anchor_text": "more advanced methods", "paragraph_index": 114}, {"url": "https://en.wikipedia.org/wiki/Zipf%27s_law", "anchor_text": "Zipf\u2019s law", "paragraph_index": 119}, {"url": "http://bit.ly/yourfirstkagglesubmission", "anchor_text": "notebook on GitHub", "paragraph_index": 165}, {"url": "http://twitter.com/mrdbourke", "anchor_text": "Twitter", "paragraph_index": 167}, {"url": "http://linkedin.com/in/mrdbourke", "anchor_text": "LinkedIn", "paragraph_index": 167}, {"url": "http://bit.ly/DanielBourkeOnYouTube", "anchor_text": "YouTube", "paragraph_index": 167}, {"url": "http://nutrify.app", "anchor_text": "nutrify.app", "paragraph_index": 169}, {"url": "http://zerotomastery.io", "anchor_text": "zerotomastery.io", "paragraph_index": 169}, {"url": "http://mrdbourke.com", "anchor_text": "mrdbourke.com", "paragraph_index": 169}], "all_paragraphs": ["Pink singlet, dyed red hair, plated grey beard, no shoes, John Lennon glasses. What a character. Imagine the stories he\u2019d have. He parked his moped and walked into the cafe.", "This cafe is a local favourite. But the chairs aren\u2019t very comfortable. So I\u2019ll keep this short (spoiler: by short, I mean short compared to the amount of time you\u2019ll actually spend doing EDA).", "When I first started as a Machine Learning Engineer at Max Kelsen, I\u2019d never heard of EDA. There are a bunch of acronyms I\u2019ve never heard of.", "I later learned EDA stands for exploratory data analysis.", "It\u2019s what you do when you first encounter a data set. But it\u2019s not a once off process.", "The past few weeks I\u2019ve been working on a machine learning project. Everything was going well. I had a model trained on a small amount of the data. The results were pretty good.", "It was time to step it up and add more data. So I did. Then it broke.", "I filled up the memory on the cloud computer I was working on. I tried again. Same issue.", "There was a memory leak somewhere. I missed something. What changed?", "Maybe the next sample of data I pulled in had something different to the first. It did. There was an outlier. One sample which had 68 times the amount of purchases as the mean (100).", "Back to my code. It wasn\u2019t robust to outliers. It took the outliers value and applied to the rest of the samples and padded them with zeros.", "Instead of having 10 million samples with a length of 100, they all had a length of 6800. And most of that data was zeroes.", "I changed the code. Reran the model and training began. The memory leak was patched.", "The guy with the pink singlet came over. He tells me his name is Johnny.", "\u2018The girls got up me for not saying hello.\u2019", "We laughed. The girls here are really nice. The regulars get teased. Johnny is a regular. He told me he has his own farm at home. And his toenails were painted pink and yellow, alternating, pink, yellow, pink, yellow.", "What happened? Why the break in the EDA story?", "Apart from introducing you to the legend of Johnny, I wanted to give an example of how you can think the road ahead is clear but really, there\u2019s a detour.", "EDA is one big detour. There\u2019s no real structured way to do it. It\u2019s an iterative process.", "When I started learning machine learning and data science, much of it (all of it) was through online courses. I used them to create my own AI Masters Degree. All of them provided excellent curriculum along with excellent datasets.", "The datasets were excellent because they were ready to be used with machine learning algorithms right out of the box.", "You\u2019d download the data, choose your algorithm, call the .fit() function, pass it the data and all of a sudden the loss value would start going down and you\u2019d be left with an accuracy metric. Magic.", "This was how the majority of my learning went. Then I got a job as a machine learning engineer. I thought, finally, I can apply what I\u2019ve been learning to real-world problems.", "The client sent us the data. I looked at it. WTF was this?", "Words, time stamps, more words, rows with missing data, columns, lots of columns. Where were the numbers?", "\u2018How do I deal with this data?\u2019 I asked Athon.", "\u2018You\u2019ll have to do some feature engineering and encode the categorical variables,\u2019 he said, \u2018I\u2019ll Slack you a link.\u2019", "I went to my digital mentor. Google. \u2018What is feature engineering?\u2019", "Google again. \u2018What are categorical variables?\u2019", "Athon sent the link. I opened it.", "There it was. The next bridge I had to cross. EDA.", "You do exploratory data analysis to learn more about the more before you ever run a machine learning model.", "You create your own mental model of the data so when you run a machine learning model to make predictions, you\u2019ll be able to recognise whether they\u2019re BS or not.", "Rather than answer all your questions about EDA, I designed this post to spark your curiosity. To get you to think about questions you can ask of a dataset.", "How do you explore a mountain range?", "Do you walk straight to the top?", "How about along the base and try and find the best path?", "It depends on what you\u2019re trying to achieve. If you want to get to the top, it\u2019s probably good to start climbing sometime soon. But it\u2019s also probably good to spend some time looking for the best route.", "Exploring data is the same. What questions are you trying to solve? Or better, what assumptions are you trying to prove wrong?", "You could spend all day debating these. But best to start with something simple, prove it wrong and add complexity as required.", "You\u2019ve been learning data science and machine learning online. You\u2019ve heard of Kaggle. You\u2019ve read the articles saying how valuable it is to practice your skills on their problems.", "Despite all the good things you\u2019ve heard about Kaggle. You haven\u2019t made a submission yet.", "You decide it\u2019s time to enter a competition of your own.", "You\u2019re on the Kaggle website. You go to the \u2018Start Here\u2019 section. There\u2019s a dataset containing information about passengers on the Titanic. You download it and load up a Jupyter Notebook.", "What question are you trying to solve?", "\u2018Can I predict survival rates of passengers on the Titanic, based on data from other passengers?\u2019", "This seems like a good guiding light.", "If a checklist is good enough for pilots to use every flight, it\u2019s good enough for data scientists to use with every dataset.", "1. What question(s) are you trying to solve (or prove wrong)?2. What kind of data do you have and how do you treat different types?3. What\u2019s missing from the data and how do you deal with it?4. Where are the outliers and why should you care about them?5. How can you add, change or remove features to get more out of your data?", "We\u2019ll go through each of these.", "I put an (s) in the subtitle. Ignore it. Start with one. Don\u2019t worry, more will come along as you go.", "For our Titanic dataset example it\u2019s:", "Can we predict survivors on the Titanic based on data from other passengers?", "Too many questions will clutter your thought space. Humans aren\u2019t good at computing multiple things at once. We\u2019ll leave that to the machines.", "You\u2019ve imported the Titanic training dataset.", "Column by column, there\u2019s: numbers, numbers, numbers, words, words, numbers, numbers, numbers, letters and numbers, numbers, letters and numbers and NaNs, letters. Similar to Johnny\u2019s toenails.", "Let\u2019s separate the features (columns) out into three boxes, numerical, categorical and not sure.", "In the numerical bucket we have, PassengerId, Survived, Pclass, Age, SibSp, Parch and Fare.", "The categorical bucket contains Sex and Embarked.", "And in not sure we have Name, Ticket and Cabin.", "Now we\u2019ve broken the columns down into separate buckets, let\u2019s examine each one.", "\u2018Can we predict survivors on the Titanic based on data from other passengers?\u2019", "From this, can you figure out which column we\u2019re trying to predict?", "The Survivedcolumn. And because it\u2019s the column we\u2019re trying to predict, we\u2019ll take it out of the numerical bucket and leave it for the time being.", "PassengerId,Pclass, Age, SibSp, Parch and Fare.", "Think for a second. If you were trying to predict whether someone survived on the Titanic, do you think their unique PassengerIdwould really help with your cause?", "Probably not. So we\u2019ll leave this column to the side for now too. EDA doesn\u2019t always have to be done with code, you can use your model of the world to begin with and use code to see if it\u2019s right later.", "How about Pclass, SibSp and Parch?", "These are numbers but there\u2019s something different about them. Can you pick it up?", "What does Pclass, SibSp and Parch even mean? Maybe we should\u2019ve read the docs more before trying to build a model so quickly.", "Pclassis the ticket class, 1 = 1st class, 2 = 2nd class and 3 = 3rd class. SibSp is the number of siblings a passenger has on board. And Parch is the number of parents someone had on board.", "This information was pretty easy to find. But what if you had a dataset you\u2019d never seen before. What if a real estate agent wanted help predicting house prices in their city. You check out their data and find a bunch of columns which you don\u2019t understand.", "They respond. \u2018Tnum is the number of toilets in a property.\u2019", "When you\u2019re dealing with a new dataset, you won\u2019t always have information available about it as Kaggle provides. This is where you\u2019ll want to seek the knowledge of an SME.", "SME stands for subject matter expert. If you\u2019re working on a project dealing with real estate data, part of your EDA might involve talking with and asking questions of a real estate agent. Not only could this save you time, but it could also influence future questions you ask of the data.", "Since no one from the Titanic is alive anymore (RIP (rest in peace) Millvina Dean, the last survivor), we\u2019ll have to become our own SMEs.", "There\u2019s something else unique about Pclass, SibSp and Parch. Even though they\u2019re all numbers, they\u2019re also categories.", "Think about it like this. If you can group data together in your head fairly easily, there\u2019s a chance it\u2019s part of a category.", "The Pclasscolumn could be labelled, First, Second and Third and it would maintain the same meaning as 1, 2 and 3.", "Remember how machine learning algorithms love numbers? Since Pclass, SibSp and Parch are already all in numerical form, we\u2019ll leave them how they are. The same goes for Age.", "In our categorical bucket, we have Sex and Embarked.", "These are categorical variables because you can separate passengers who were female from those who were male. Or those who embarked on C from those who embarked from S.", "To train a machine learning model, we\u2019ll need a way of converting these to numbers.", "How would you do this for Sex and Embarked?", "Perhaps you could do something similar for Sex. Female = 1 and male = 2.", "We can change these using the .LabelEncoder() function from the sklearn library.", "We\u2019ve made some good progress towards turning our categorical data into all numbers but what about the rest of the columns?", "Name, Ticket and Cabin are left.", "If you were on The Titanic, do you think your name would\u2019ve influenced your chance of survival?", "It\u2019s unlikely. But what other information could you extract from someone's name?", "What if you gave each person a number depending on whether their title was Mr., Mrs. or Miss.?", "You could create another column called Title. In this column, those with Mr. = 1, Mrs. = 2 and Miss. = 3.", "What you\u2019ve done is created a new feature out of an existing feature. This is called feature engineering.", "Converting titles to numbers is a relatively simple feature to create. And depending on the data you have, feature engineering can get as extravagant as you like.", "How does this new feature affect the model down the line? This will be something you\u2019ll have to investigate.", "For now, we won\u2019t worry about the Name column to make a prediction.", "The first few examples don\u2019t look very consistent at all. What else is there?", "These aren\u2019t very consistent either. But think again. Do you think the ticket number would provide much insight as to whether someone survived?", "Maybe if the ticket number related to what class the person was riding in, it would have an effect but we already have that information in Pclass.", "To save time, we\u2019ll forget the Ticket column for now.", "Your first pass of EDA on a dataset should have the goal of not only raising more questions about the data but to get a model built using the least amount of information possible so you\u2019ve got have a baseline to work from.", "Now, what do we do with Cabin?", "You know, since I\u2019ve already seen the data, my spidey-senses are telling me it\u2019s a perfect example for the next section.", "The Cabin column looks like Johnny\u2019s shoes. Not there. There are a fair few missing values in Age too.", "How do you predict something when there\u2019s no data?", "So what are our options when dealing with missing data?", "The quickest and easiest way would be to remove every row with missing values. Or remove the Cabin and Age column entirely.", "But there\u2019s a problem here. Machine learning models like more data. Removing large amounts of data will likely decrease the ability of our model to predict whether a passenger survived or not.", "Imputing values. In other words, filling up the missing data with values calculated from other data.", "How would you do this for the Age column?", "Could you fill missing values with average age?", "There are drawbacks to this kind of value filling. Imagine you had 1000 total rows, 500 of which are missing values. You decide to fill the 500 missing rows with the average age of 36.", "Your data becomes heavily stacked with the age of 36. How would that influence predictions on people 36-years-old? Or any other age?", "Maybe for every person with a missing age value, you could find other similar people in the dataset and use their age. But this is time-consuming and also has drawbacks.", "There are far more advanced methods for filling missing data out of scope for this post. It should be noted, there is no perfect way to fill missing values.", "If the missing values in the Age column is a leaky drain pipe the Cabin column is a cracked dam. Beyond saving. For your first model, Cabin is a feature you\u2019d leave out.", "\u2018Did you check the distribution?\u2019 Athon asked.", "\u2018I did with the first set of data but not the second set\u2026\u2019", "There it was. The rest of the data was being shaped to match the outlier.", "If you look at the number of occurrences of unique values within a dataset, one of the most common patterns you\u2019ll find is Zipf\u2019s law. It looks like this.", "Remembering Zipf\u2019s law can help to think about outliers (values towards the end of the tail which don\u2019t occur often are potential outliers).", "The definition of an outlier will be different for every dataset. As a general rule of thumb, you may consider anything more than 3 standard deviations away from the mean might be considered an outlier.", "Distribution. Distribution. Distribution. Distribution. Four times is enough (I\u2019m trying to remind myself here).", "During your first pass of EDA, you should be checking what the distribution of each of your features is.", "A distribution plot will help represent the spread of different values of data you have across. And more importantly, help to identify potential outliers.", "Why should you care about outliers?", "Keeping outliers in your dataset may turn out in your model overfitting (being too accurate). Removing all the outliers may result in your model being too generalised (it doesn\u2019t do well on anything out of the ordinary). As always, best to experiment iteratively to find the best way to deal with outliers.", "The Titanic dataset only has 10 features. But what if your dataset has hundreds? Or thousands? Or more? This isn\u2019t uncommon.", "During your exploratory data analysis process, once you\u2019ve started to form an understanding AND you\u2019ve got an idea of the distributions AND you\u2019ve found some outliers AND you\u2019ve dealt with them, the next biggest chunk of your time will be spent on feature engineering.", "Feature engineering can be broken down into three categories: adding, removing and changing.", "The Titanic dataset started out in pretty good shape. So far, we\u2019ve only had to change a few features to be numerical in nature.", "However, data in the wild is different.", "Say you\u2019re working on a problem trying to predict the changes in banana stock requirements of a large supermarket chain across the year.", "Your dataset contains a historical record of stock levels and previous purchase orders. You're able to model these well but you find there are a few times throughout the year where stock levels change irrationally. Through your research, you find during a yearly country-wide celebration, banana week, the stock levels of bananas plummet. This makes sense. To keep up with the festivities, people buy more bananas.", "To compensate for banana week and help the model learn when it occurs, you might add a column to your data set with banana week or not banana week.", "Adding a feature like this might not be so simple. You could find adding the feature does nothing at all since the information you\u2019ve added is already hidden within the data. As in, the purchase orders for the past few years during banana week are already higher than other weeks.", "We\u2019ve done this as well with the Titanic dataset. We dropped the Cabin column because it was missing so many values before we even ran a model.", "But what about if you\u2019ve already run a model using the features left over?", "This is where feature contribution comes in. Feature contribution is a way of figuring out how much each feature influences the model.", "Knowing how much a feature contributes to a model can give you direction as to where to go next with your feature engineering.", "In our Titanic example, we can see the contribution of Sex and Pclass were the highest. Why do think this is?", "What if you had more than 10 features? How about 100? You could do the same thing. Make a graph showing the feature contributions of 100 different features.", "Zipf\u2019s law back at it again. The top features have far more to contribute than the bottom features.", "Seeing this, you might decide to cut the lesser contributing features and improve the ones contributing more.", "Removing features reduces the dimensionality of your data. It means your model has fewer connections to make to figure out the best way of fitting the data.", "You might find removing features means your model can get the same (or better) results on fewer data and in less time.", "Like Johnny is a regular at the cafe I\u2019m at, feature engineering is a regular part of every data science project.", "Finally. We\u2019ve been through a bunch of steps to get our data ready to run some models.", "If you\u2019re like me, when you started learning data science, this is the part you learned first. All the stuff above had already been done by someone else. All you had to was fit a model on it.", "Our Titanic dataset is small. So we can afford to run a multitude of models on it to figure out which is the best to use.", "Notice how I put an (s) in the subtitle, you can pay attention to this one.", "Running multiple models is fine on our small Titanic dataset. But might not be the best for larger datasets.", "Once you\u2019ve had some practice with different datasets, you\u2019ll start to figure out what kind of model usually works best. For example, most recent Kaggle competitions have been won with ensembles (combinations) of different gradient boosted tree algorithms.", "Once you\u2019ve built a few models and figured out which is best, you can start to optimise the best one through hyperparameter tuning. Think of hyperparameter tuning as adjusting the dials on your oven when cooking your favourite dish. Out of the box, the preset setting on the oven works pretty well but out of experience you\u2019ve found lowering the temperature and increasing the fan speed brings tastier results.", "It\u2019s the same with machine learning algorithms. Many of them work great out of the box. But with a little tweaking of their parameters, they work even better.", "But no matter what, even the best machine learning algorithm won\u2019t result in a great model without adequate data preparation.", "EDA and model building is a repeating circle.", "I left the cafe. My ass was sore.", "At the start of this article, I said I\u2019d keep it short. You know how that turned out. It will be the same as your EDA iterations. When you think you\u2019re done. There\u2019s more.", "We covered a non-exhaustive EDA checklist with the Titanic Kaggle dataset as an example.", "Start with the simplest hypothesis possible. Add complexity as needed.", "Is your data numerical, categorical or something else? How do you deal with each kind?", "Why is the data missing? Missing data can be a sign in itself. You\u2019ll never be able to replace it with anything as good as the original but you can try.", "Distribution. Distribution. Distribution. Three times is enough for the summary. Where are the outliers in your data? Do you need them or are they damaging your model?", "The default rule of thumb is more data = good. And following this works well quite often. But is there anything you can remove get the same results? Start simple. Less but better.", "There are examples of everything we\u2019ve discussed here (and more) in the notebook on GitHub and a video of me going through the notebook step by step on YouTube (the coding starts at 5:05).", "If you\u2019ve got something on your mind you think this article is missing, leave a response below or send me a note.", "Otherwise, you can find me on Twitter, LinkedIn and YouTube.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Building nutrify.app, teaching ML @ zerotomastery.io, broadcasting from mrdbourke.com."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff11d843b8184&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f11d843b8184--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f11d843b8184--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mrdbourke.medium.com/?source=post_page-----f11d843b8184--------------------------------", "anchor_text": ""}, {"url": "https://mrdbourke.medium.com/?source=post_page-----f11d843b8184--------------------------------", "anchor_text": "Daniel Bourke"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbc019e228f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&user=Daniel+Bourke&userId=dbc019e228f5&source=post_page-dbc019e228f5----f11d843b8184---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff11d843b8184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff11d843b8184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://maxkelsen.com", "anchor_text": "Max Kelsen"}, {"url": "http://bit.ly/AIMastersDegree", "anchor_text": "my own AI Masters Degree"}, {"url": "https://github.com/dformoso/sklearn-classification/blob/master/Data%20Science%20Workbook%20-%20Census%20Income%20Dataset.ipynb", "anchor_text": "the link"}, {"url": "http://bit.ly/yourfirstkagglesubmission", "anchor_text": "open this Juypter Notebook"}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "Kaggle Titanic Training Dataset"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html", "anchor_text": ".LabelEncoder()"}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "data description page"}, {"url": "https://github.com/ResidentMario/missingno", "anchor_text": "missingno library"}, {"url": "https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4", "anchor_text": "more advanced methods"}, {"url": "https://en.wikipedia.org/wiki/Zipf%27s_law", "anchor_text": "Zipf\u2019s law"}, {"url": "http://bit.ly/yourfirstkagglesubmission", "anchor_text": "notebook on GitHub"}, {"url": "http://bit.ly/yourfirstkagglesubmission", "anchor_text": "notebook I\u2019ve created"}, {"url": "https://github.com/dformoso/sklearn-classification/blob/master/Data%20Science%20Workbook%20-%20Census%20Income%20Dataset.ipynb", "anchor_text": "Daniel Formoso's notebook"}, {"url": "http://twitter.com/mrdbourke", "anchor_text": "Twitter"}, {"url": "http://linkedin.com/in/mrdbourke", "anchor_text": "LinkedIn"}, {"url": "http://bit.ly/DanielBourkeOnYouTube", "anchor_text": "YouTube"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f11d843b8184---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/exploratory-data-analysis?source=post_page-----f11d843b8184---------------exploratory_data_analysis-----------------", "anchor_text": "Exploratory Data Analysis"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f11d843b8184---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data?source=post_page-----f11d843b8184---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----f11d843b8184---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff11d843b8184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&user=Daniel+Bourke&userId=dbc019e228f5&source=-----f11d843b8184---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff11d843b8184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&user=Daniel+Bourke&userId=dbc019e228f5&source=-----f11d843b8184---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff11d843b8184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f11d843b8184--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff11d843b8184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f11d843b8184---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f11d843b8184--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f11d843b8184--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f11d843b8184--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f11d843b8184--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f11d843b8184--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f11d843b8184--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f11d843b8184--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f11d843b8184--------------------------------", "anchor_text": ""}, {"url": "https://mrdbourke.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mrdbourke.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Daniel Bourke"}, {"url": "https://mrdbourke.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "17.6K Followers"}, {"url": "http://nutrify.app", "anchor_text": "nutrify.app"}, {"url": "http://zerotomastery.io", "anchor_text": "zerotomastery.io"}, {"url": "http://mrdbourke.com", "anchor_text": "mrdbourke.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbc019e228f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&user=Daniel+Bourke&userId=dbc019e228f5&source=post_page-dbc019e228f5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd39f6683b6e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-exploratory-data-analysis-f11d843b8184&newsletterV3=dbc019e228f5&newsletterV3Id=d39f6683b6e2&user=Daniel+Bourke&userId=dbc019e228f5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}