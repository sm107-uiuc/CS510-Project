{"url": "https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010", "time": 1682996065.5435781, "path": "towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010/", "webpage": {"metadata": {"title": "Intuitive Guide to Understanding GloVe Embeddings | by Thushan Ganegedara | Towards Data Science", "h1": "Intuitive Guide to Understanding GloVe Embeddings", "description": "In this article, you will learn about GloVe, a very powerful word vector learning technique. This article will focus explaining the why GloVe is better and the motivation behind the cost function of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39", "anchor_text": "A", "paragraph_index": 2}, {"url": "http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/", "anchor_text": "C", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7", "anchor_text": "D", "paragraph_index": 2}, {"url": "http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/", "anchor_text": "K", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158", "anchor_text": "L", "paragraph_index": 2}, {"url": "https://medium.com/p/bee5af0c01aa", "anchor_text": "M", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee", "anchor_text": "N", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "W", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Latent_semantic_analysis", "anchor_text": "latent semantic analysis", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "here", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Homomorphism", "anchor_text": "homomorphism", "paragraph_index": 33}, {"url": "https://github.com/thushv89/exercises_thushv_dot_com/blob/master/glove_light_on_math_ml/glove_light_on_math_ml.ipynb", "anchor_text": "[here", "paragraph_index": 45}, {"url": "https://www.manning.com/books/tensorflow-in-action", "anchor_text": "(Book) TensorFlow 2 in Action \u2014 Manning", "paragraph_index": 48}, {"url": "https://www.datacamp.com/courses/machine-translation-in-python", "anchor_text": "(Video Course) Machine Translation in Python", "paragraph_index": 49}, {"url": "https://www.amazon.com.au/Natural-Language-Processing-TensorFlow-Ganegedara/dp/1788478312/ref=sr_1_25?dchild=1&keywords=nlp+with+tensorflow&qid=1603009947&sr=8-25", "anchor_text": "(Book) Natural Language processing in TensorFlow 1", "paragraph_index": 50}, {"url": "https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/", "anchor_text": "DeepLearningHero", "paragraph_index": 51}, {"url": "https://nlp.stanford.edu/pubs/glove.pdf", "anchor_text": "Original paper", "paragraph_index": 52}], "all_paragraphs": ["In this article, you will learn about GloVe, a very powerful word vector learning technique. This article will focus explaining the why GloVe is better and the motivation behind the cost function of GloVe which is the most crucial part of the algorithm. . The code will be discussed in detail in a later article.", "To visit my previous articles in this series use the following letters.", "A B C D* E F G H I J K L* M N O P Q R S T U V W X Y Z", "GloVe is a word vector technique that rode the wave of word vectors after a brief silence. Just to refresh, word vectors put words to a nice vector space, where similar words cluster together and different words repel. The advantage of GloVe is that, unlike Word2vec, GloVe does not rely just on local statistics (local context information of words), but incorporates global statistics (word co-occurrence) to obtain word vectors. But keep in mind that there\u2019s quite a bit of synergy between the GloVe and Word2vec.", "And don\u2019t be surprised to hear that the idea of using global statistics to derive semantic relationships between words goes a long way back. Back to, latent semantic analysis (LSA). That\u2019s just a fun fact. Let\u2019s move on.", "What\u2019s the fundamental idea behind Word2vec?", "You shall know a word by the company it keeps \u2014 J.R. Firth", "Word vectors were built on this idea. Basically, you get a large corpus, and make a dataset of tuples, where each tuple contains (some word x, a word in the context of x). Then you would use your old friend, a neural network, to learn to predict the context word of x, given the word x. If you\u2019d like more information on Word2vec, refer to my article here.", "Given the conspicuous performance of Word2vec, why not stick with it? The reason doesn\u2019t lie in performance, but the fundamentals of the solution formulation. Remember that, Word2vec relies only on local information of language. That is, the semantics learnt for a given word, is only affected by the surrounding words.", "The cat sat on the mat", "If you use Word2vec, it wouldn\u2019t capture information like,", "is \u201cthe\u201d a special context of the words \u201ccat\u201d and \u201cmat\u201d ?", "This can be suboptimal, especially in the eye of theoreticians.", "GloVe stands for \u201cGlobal Vectors\u201d. And as mentioned earlier, GloVe captures both global statistics and local statistics of a corpus, in order to come up with word vectors. But do we need both global and local statistics?", "Turns out, it each type of statistic has their own advantage. For example, Word2vec which captures local statistics do very well in analogy tasks. However a method like LSA which uses only global statistics does not do that well in analogy tasks. However since Word2vec method suffers from certain limitations (like what we discussed above) due to using local statistics only.", "GloVe method is built on an important idea,", "You can derive semantic relationships between words from the co-occurrence matrix.", "Given a corpus having V words, the co-occurrence matrix X will be a V x V matrix, where the i th row and j th column of X, X_ij denotes how many times word i has co-occurred with word j. An example co-occurrence matrix might look as follows.", "How do we get a metric that measures semantic similarity between words from this? For that, you will need three words at a time. Let me concretely lay down this statement.", "Here P_ik denotes the probability of seeing word i and k together, which is computed by dividing the number of times i and k appeared together (X_ik) by the total number of times word i appeared in the corpus (X_i).", "You can see that given two words, i.e. ice and steam, if the third word k (also called the \u201cprobe word\u201d),", "So, if we can find a way to incorporate P_ik/P_jk to computing word vectors we will be achieving the goal of using global statistics when learning word vectors.", "If you enjoyed it so far, buckle up. It\u2019s about to get rough! It is not very apparent how we can arrive at a word vector algorithm because,", "Answering these three questions is the main contribution of GloVe. Now let\u2019s go through GloVe step by step and see how answering these three questions gives us a word vector algorithm.", "I am using the following notation which is slightly different from the paper due to difficulties rendering Latex on Medium.", "Answering the first question is easy. Just assume it. Assume that there is a function F which takes in word vectors of i,j and k which outputs the ratio we\u2019re interested in.", "You should get a bit curious by now, because we see two embedding layers playing (w and u). So why two? The paper says, often both these layers will perform equivalently and will only differ by the different random initialization. However having two layers help the model to reduce overfitting.", "Now back to the function. Word vectors are linear systems. For example, you can perform arithmetic in embedding space, e.g.", "Therefore, let\u2019s change the above equation to the following,", "Why does w_i \u2014 w_j suit here? In fact, you can derive the nice properties you observe about P_ik/P_jk in the embedding space. Let me elaborate.", "So you can see how the distance (dashed line) changes as different words are considered. And the distance between two given words i and k, correlated with the reciprocal of the P_{ik}. And why was this the case? It is because we always computed distances w.r.t the word vector w_i \u2014 w_j (i.e. the red line). So it is not a bad idea to start with w_i \u2014 w_j.", "With one problem solved, we move on to the next. How do we make LHS a scalar? There\u2019s a pretty straight forward answer to this. That is to introduce a transpose and a dot product between the two entities the following way.", "If you assume a word vector as a Dx1 matrix, (w_i \u2014 w_j)* will be 1xD shaped which gives a scalar when multiplied with u_k.", "Next, if we assume F has a certain property (i.e. homomorphism between additive group and the multiplicative group) which gives,", "In other words this particular homomorphism ensures that the subtraction F(A-B) can also be represented as a division F(A)/F(B) and get the same result. And therefore,", "Okey, I was being sneaky. Just because F(A)/F(B) = G(A)/G(B) you cannot say F(A) = G(A). Because F(A)/F(B)=2F(A)/2F(B), doesn\u2019t mean F(A)=2F(A). And it is not clear (at least to me) from the original paper why this is assumed. But let me give you some intuition why this would be a safe assumption. If we are to define the above relationship correctly, it would be,", "But with this, you also get F(w_j* u_k) = c P_jk for any j. So if the similarity between i and k grow by c, the similarity between j and k (for any j) will also grow by c. This means (in a way) that the all word vectors will scale up/down by a factor c, which won\u2019t do any harm as the relative topography is preserved.", "Moving on, if we assume F=exp, the above homomorphism property is satisfied. Then let us set,", "Next, X_i is independent of k, we move log(X_i) to LHS,", "Note that the above equation would have symmetry if not for the term log(X_i), i.e. i and k can be swapped. We can add a bias b_i which would absorb log(X_i) and add another b_k to restore symmetry. So, we\u2019ll get a bit creative and express log(X_i) in neural network parlance we get,", "where b_i and b_k are biases of the network.", "In an ideal setting, where you have perfect word vectors, the above expression will be zero. In other words, that\u2019s our goal or objective. So we will be setting the LHS expression as our cost function.", "Note that the square makes this a mean square cost function. No harm done to the original findings. Also k has been replaced with j.", "But your work does not stop here, you still have to patch up an important theoretical problem. Ponder what would happen if X_ik = 0. If you kick off a little experiment with the above cost function, you will be seeing the most hated 3 letters for an ML practitioner, i.e. NaN. Because log(0) is undefined. The easy fix would be to use log(1+X_ik) known as Laplacian smoothing. But the luminaries behind the GloVe paper propose a sleeker way of doing this. That is to introduce a weighting function.", "That wraps everything. GloVe is a word vector technique that leverages both global and local statistics of a corpus in order to come up with a principled loss function which uses both these. GloVe does this by solving three important problems.", "The code for implementing GloVe with Keras is provided [here]", "If you enjoy the stories I share about data science and machine learning, consider becoming a member!", "Checkout my work on the subject.", "[1] (Book) TensorFlow 2 in Action \u2014 Manning", "[2] (Video Course) Machine Translation in Python \u2014 DataCamp", "[3] (Book) Natural Language processing in TensorFlow 1 \u2014 Packt", "If you are keen to see my videos on various machine learning/deep learning topics make sure to join DeepLearningHero.", "[1] GloVe: Global Vectors for Word Representation (Original paper)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Google Developer Expert (ML) | ML @ Canva | Educator & Author\ud83d\udcd7| PhD\ud83d\udc68\ud83c\udffe\u200d\ud83c\udf93. Youtube: @DeepLearningHero Twitter:@thush89, LinkedIN: thushan.ganegedara"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb13b4f19c010&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://thushv89.medium.com/?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "Thushan Ganegedara"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0b045d5681&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&user=Thushan+Ganegedara&userId=6f0b045d5681&source=post_page-6f0b045d5681----b13b4f19c010---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/light-on-math", "anchor_text": "Light on Math Machine Learning"}, {"url": "https://unsplash.com/photos/2OCh8tuNsBo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Jelleke Vanooteghem"}, {"url": "https://unsplash.com/search/photos/words?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://github.com/thushv89/exercises_thushv_dot_com/blob/master/glove_light_on_math_ml/glove_light_on_math_ml.ipynb", "anchor_text": "[here"}, {"url": "https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39", "anchor_text": "A"}, {"url": "http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/", "anchor_text": "C"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7", "anchor_text": "D"}, {"url": "http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/", "anchor_text": "K"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158", "anchor_text": "L"}, {"url": "https://medium.com/p/bee5af0c01aa", "anchor_text": "M"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee", "anchor_text": "N"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "W"}, {"url": "https://medium.com/p/bee5af0c01aa", "anchor_text": "M \u2014 Matrix factorization"}, {"url": "https://en.wikipedia.org/wiki/Latent_semantic_analysis", "anchor_text": "latent semantic analysis"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Homomorphism", "anchor_text": "homomorphism"}, {"url": "https://github.com/thushv89/exercises_thushv_dot_com/blob/master/glove_light_on_math_ml/glove_light_on_math_ml.ipynb", "anchor_text": "[here"}, {"url": "https://thushv89.medium.com/membership", "anchor_text": "Join Medium with my referral link - Thushan GanegedaraAs a Medium member, a portion of your membership fee goes to writers you read, and you get full access to every story\u2026thushv89.medium.com"}, {"url": "https://www.manning.com/books/tensorflow-in-action", "anchor_text": "(Book) TensorFlow 2 in Action \u2014 Manning"}, {"url": "https://www.datacamp.com/courses/machine-translation-in-python", "anchor_text": "(Video Course) Machine Translation in Python"}, {"url": "https://www.amazon.com.au/Natural-Language-Processing-TensorFlow-Ganegedara/dp/1788478312/ref=sr_1_25?dchild=1&keywords=nlp+with+tensorflow&qid=1603009947&sr=8-25", "anchor_text": "(Book) Natural Language processing in TensorFlow 1"}, {"url": "https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/", "anchor_text": "DeepLearningHero"}, {"url": "https://nlp.stanford.edu/pubs/glove.pdf", "anchor_text": "Original paper"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b13b4f19c010---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/light-on-math?source=post_page-----b13b4f19c010---------------light_on_math-----------------", "anchor_text": "Light On Math"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b13b4f19c010---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----b13b4f19c010---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----b13b4f19c010---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----b13b4f19c010---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----b13b4f19c010---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b13b4f19c010---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b13b4f19c010--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b13b4f19c010--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b13b4f19c010--------------------------------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Thushan Ganegedara"}, {"url": "https://thushv89.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.5K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0b045d5681&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&user=Thushan+Ganegedara&userId=6f0b045d5681&source=post_page-6f0b045d5681--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F31796fe71410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&newsletterV3=6f0b045d5681&newsletterV3Id=31796fe71410&user=Thushan+Ganegedara&userId=6f0b045d5681&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.manning.com/books/tensorflow-in-action", "anchor_text": "TensorFlow 2. 0 in Action2021"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}