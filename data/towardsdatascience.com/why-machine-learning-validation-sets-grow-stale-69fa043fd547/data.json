{"url": "https://towardsdatascience.com/why-machine-learning-validation-sets-grow-stale-69fa043fd547", "time": 1683003541.679737, "path": "towardsdatascience.com/why-machine-learning-validation-sets-grow-stale-69fa043fd547/", "webpage": {"metadata": {"title": "Why Machine Learning Validation Sets Grow Stale | by Ray Heberer | Towards Data Science", "h1": "Why Machine Learning Validation Sets Grow Stale", "description": "One of the first things you learn when entering into the world of data science is the importance of having separate datasets for training and validating your machine learning models. How is it then\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets", "anchor_text": "separate datasets", "paragraph_index": 0}, {"url": "https://link.springer.com/article/10.1007/s41066-017-0049-2", "anchor_text": "outdated rules of thumb", "paragraph_index": 1}, {"url": "https://ruder.io/optimizing-gradient-descent/#visualizationofalgorithms", "anchor_text": "articles on gradient-based optimization", "paragraph_index": 6}, {"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "related research", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Fitness_landscape", "anchor_text": "fitness landscapes", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Projection_(mathematics)", "anchor_text": "projection", "paragraph_index": 19}, {"url": "https://en.wikipedia.org/wiki/George_E._P._Box", "anchor_text": "George Box", "paragraph_index": 28}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html", "anchor_text": "Gradient Boosting regression model", "paragraph_index": 33}, {"url": "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html", "anchor_text": "Boston House Prices", "paragraph_index": 36}, {"url": "https://medium.com/@rayheberer/black-magic-and-hyperparameter-tuning-ef875eb31712", "anchor_text": "second attempt", "paragraph_index": 40}, {"url": "https://towardsdatascience.com/training-validation-and-test-phases-in-ai-explained-in-a-way-youll-never-forget-744be50154e8", "anchor_text": "an interesting take", "paragraph_index": 42}], "all_paragraphs": ["One of the first things you learn when entering into the world of data science is the importance of having separate datasets for training and validating your machine learning models. How is it then, that this concept seems so hard to master?", "Despite the fact that there is a simple intuition behind why we partition datasets, there are a few barriers to deep understanding that plague the industry. One is the persistence of outdated rules of thumb like the \u201c70\u201330 train-test split\u201d or other legacies from the dark ages before big data.", "Another is the surprising lack of good answers to a question many of us have upon learning that we should have a separate validation set in addition to a test set, which we can use for hyperparameter tuning. That question being: \u201cif we can overfit to the test set just by tuning hyperparameters, can\u2019t we overfit to the validation set?\u201d", "The answer is: yes, of course. Eventually, you will overfit to a validation set, and it will be said to have gone \u201cstale.\u201d Today I would like to explore some ways of thinking about why this happens. I hope that by doing so, we can chart a path to deeper understanding of overfitting and data partitioning beyond the two propositional statements people are expected to know for interviews.", "First, we\u2019ll explore the concept of loss landscapes and how the relationship between a sample\u2019s landscape and the population\u2019s can be used to understand validation set leakage. Along the way, we\u2019ll develop a useful mental model based on a few simplifying assumptions. Finally, we\u2019ll put our understanding to the test through a quick experiment (code included below).", "A Simple Idea Given Name: Loss Landscapes", "Chances are that if you\u2019re familiar with machine learning, you\u2019re familiar with the concept of loss landscapes. Especially if you\u2019ve looked into neural networks and gradient descent, and have read one of those articles on gradient-based optimization with gorgeous visualizations and animations.", "A loss landscape is just a function. Specifically, the loss or error of a machine learning model as a function of its parameters.", "If you feel like this idea is too simple to be given special attention, I get where you\u2019re coming from. But \u201closs landscape\u201d really is the name given to this class of functions, and knowing it allows you to easily look up all sorts of cool content and related research, even if you already understand the underlying concept.", "The main point is that a loss landscape is a function that can be traversed, whether by gradient descent or by other methods (e.g. simulated annealing, evolutionary methods). Naming it as such allows us to think of it in terms of our physical intuitions, even though the functions you\u2019ll be dealing with will often be in higher-dimensional spaces.", "While we most often think of loss landscapes as a function of the parameters of a model, it\u2019s also appropriate to think of them as a function of the hyperparameters.", "Note that while the loss can be explicitly calculated from the data and model parameters, the link between the loss and model hyperparameters is less direct. If this bothers you, recall that biologists use fitness landscapes to think about reproductive success as a function of genetic factors. Think of loss as a function of hyperparameters (and data) as a \u201cmodel fitness landscape\u201d if you must.", "Now the key idea to realize is that there will be separate loss landscapes for each partition of the dataset. The loss landscapes of the training set, validation set, and test set will all be different. Hopefully very similar if the data has been partitioned well such that each set is a representative sample, but still different.", "Most importantly, all of the data on hand will have different loss landscapes than that of the underlying \u201cpopulation\u201d of data out there in the wild. The reason we have both a validation and a test set is because if the validation set truly leaks information over time, we still need some data to function as an unbiased estimate of how our model will perform in the wild.", "One way to think about hyperparameter tuning is as the act of traversing the loss landscape of the validation set data as a function of the hyperparameters. Let\u2019s start by imagining an \u201cideal\u201d landscape in order to build intuition.", "Towards a Mental Model: Imagining Independent Hyperparameters", "Of course, our ideal loss landscape is going to be one where the hyperparameters are \u201cindependent.\u201d By this I mean, there are no interaction terms in their relationship to the loss. Such function will have contours that do not stick out diagonally. It\u2019s a little easier to show what I mean:", "The reason this family of loss landscapes is ideal is that when dealing with them, the problem of tuning many hyperparameters can be decomposed into the act of individually tuning one hyperparameter at a time. Since the optimal value of any one hyperparameter is independent of the values of any of the other hyperparameters, we can adjust them all in sequence rather than in parallel.", "In other words, think of each hyperparameter as a knob. All we have to do is touch every knob once, tuning until we find the sweet spot for each particular knob before moving on.", "And associated with every knob is a projection of the loss landscape. This slice of our function will have just one independent variable: the hyperparameter we are tuning.", "Here\u2019s where things get interesting. Recall that each dataset has its own loss landscape. Now imagine overlaying the projections of these functions next to each knob being tuned. Let\u2019s choose the loss landscape of the validation data, which is used to decide on the optimal hyperparameter values, and the hypothetical loss landscape of the full population of data, which is what we really want our model to do as well as possible on and is what our test set is an estimate of (if sampled properly).", "What happens every time we turn a knob to its optimal value, according to the validation set data?", "Chances are, the two loss landscapes aren\u2019t quite aligned. Every time we tune one value so that its slice of the validation loss is at a peak, chances are we\u2019ve overshot the peak for the \u201cpopulation\u201d loss landscape. The more we tune, the more peaks we overshoot a little. This leads to a growing gap between validation set and real-world (estimated by test set) performance.", "And that\u2019s it! That\u2019s why validation sets grow stale and leak information, or at least a helpful way of thinking about it.", "Here the especially perceptive reader might ask: \u201cbut if the validation and population loss landscapes aren\u2019t aligned overall, why would the peaks be less aligned than other points?\u201d It\u2019s a good question, and it begins to test the limits of the mental model we\u2019ve developed.", "To answer this, consider the validation performance with respect to a single hyperparameter. Now think of every value along that objective function as having a contribution from generalizable features, and a contribution from quirks of the validation set\u2019s data.", "As you move to more optimal values, chances are that the contribution from each of these components grows. In order to improve validation performance without suffering any degradation in results on the test set and the wild, it would require that improvement to come solely from the generalizable component.", "I also pose this question to you in return: what if one of your hyperparameters being optimized actually has little to do with learning generalizable features from the data (e.g. random_state)? What would be the effects of optimizing validation loss with respect to something like this?", "At the end of the day, what we\u2019ve gone through here is a mental model, and is therefore subject to the famous George Box aphorism:", "All models are wrong, but some are useful.", "This being the case, I hope that it is a useful way of thinking about the mechanism behind how overfitting to the validation set can occur.", "Getting Our Hands Dirty: Simulating Validation Set Leakage", "As a data scientist, it wouldn\u2019t sit right with me to expound upon an idea without testing it somehow. Requiring hyperparameters to not have any interaction effects is a little strict. While it was useful in order to develop a mental model, it would be nice to have some empirical results that show that the ideas developed extend to less ideal scenarios.", "Below, I run a quick experiment relating the amount of tuning performed on a Gradient Boosting regression model, and the gap between validation set and test set performance. I chose to work with gradient boosting because they are a popular class of models with plenty of hyperparameters.", "What we expect to see, given our understanding of validation set leakage, is a growing performance gap given more tuning. In my experiment, \u201cmore\u201d tuning is defined by running more iterations of a randomized search through 5 different hyperparameters. More iterations implies a better chance of finding a more optimal result on the validation set. If the mental model that part of this optimality comes from non-generalizable quirks of the validation data is true, then we expect that not all of these performance gains will also show up on the test data.", "Before showing my results, I\u2019d like to come clean about an important way that this experiment is biased towards supporting my thesis:", "I\u2019m using small amounts of data for both training and validation. Of course, validation set leakage is mitigated by having a large validation set, so choosing the small Boston House Prices dataset makes it easy to demonstrate over-tuning to a small validation set.", "You should be skeptical that these results hold on anything other than the particular dataset I chose! I encourage you to come up with experiments of your own, and share your results with the rest of us.", "As you can see, when we put more and more effort into optimizing our hyperparameters and selecting models based on validation set performance, the gap between validation and test set performance grows.", "This would be more pronounced if we had tuned a subset of hyperparameters, then come back later with another set, or tried switching the family of models used. Every decision informed by a sample of the data (the validation set) would slowly encode that sample\u2019s random fluctuations into our product.", "This is actually my second attempt at explaining the relationship between hyperparameter tuning and the phenomenon of overfitting to validation sets. For an idea with relatively simple underlying intuitions, it is surprisingly difficult to explain in detail.", "I believe part of the problem is that our collective knowledge is still dominated by interview-answer style assertions like \u201cyou overfit to the validation data\u201d and \u201cthe validation set leaks information\u201d that aren\u2019t backed by visual or empirical intuitions.", "While this article is one attempt at filling this need for more in-depth and elementary explanations, there is still room for more angles and ways of thinking. Cassie Kozyrkov recently wrote an interesting take on the dataset partitions using analogies to teaching and Mr. Bean. I\u2019m excited to see what else the data community can come up with.", "Diagrams provided by my lovely girlfriend, Megan.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist at Proximate Research. A little interested in a lot of things, a lot interested in a little."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F69fa043fd547&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----69fa043fd547--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----69fa043fd547--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://rayheberer.medium.com/?source=post_page-----69fa043fd547--------------------------------", "anchor_text": ""}, {"url": "https://rayheberer.medium.com/?source=post_page-----69fa043fd547--------------------------------", "anchor_text": "Ray Heberer"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6efdc3f1390&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&user=Ray+Heberer&userId=d6efdc3f1390&source=post_page-d6efdc3f1390----69fa043fd547---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69fa043fd547&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69fa043fd547&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@chuttersnap?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "chuttersnap"}, {"url": "https://unsplash.com/s/photos/mixing-board?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets", "anchor_text": "separate datasets"}, {"url": "https://link.springer.com/article/10.1007/s41066-017-0049-2", "anchor_text": "outdated rules of thumb"}, {"url": "https://gist.github.com/rayheberer/bd2d94443e77b9734d52a7a4c736bbf3", "anchor_text": "Code."}, {"url": "https://ruder.io/optimizing-gradient-descent/#visualizationofalgorithms", "anchor_text": "articles on gradient-based optimization"}, {"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "related research"}, {"url": "https://unsplash.com/@staticlaw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Fabrizio Conti"}, {"url": "https://unsplash.com/s/photos/valley?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Fitness_landscape", "anchor_text": "fitness landscapes"}, {"url": "https://en.wikipedia.org/wiki/Projection_(mathematics)", "anchor_text": "projection"}, {"url": "https://en.wikipedia.org/wiki/George_E._P._Box", "anchor_text": "George Box"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html", "anchor_text": "Gradient Boosting regression model"}, {"url": "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html", "anchor_text": "Boston House Prices"}, {"url": "https://medium.com/@rayheberer/black-magic-and-hyperparameter-tuning-ef875eb31712", "anchor_text": "second attempt"}, {"url": "https://towardsdatascience.com/training-validation-and-test-phases-in-ai-explained-in-a-way-youll-never-forget-744be50154e8", "anchor_text": "an interesting take"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----69fa043fd547---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----69fa043fd547---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----69fa043fd547---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/big-data?source=post_page-----69fa043fd547---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/python?source=post_page-----69fa043fd547---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F69fa043fd547&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&user=Ray+Heberer&userId=d6efdc3f1390&source=-----69fa043fd547---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F69fa043fd547&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&user=Ray+Heberer&userId=d6efdc3f1390&source=-----69fa043fd547---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69fa043fd547&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----69fa043fd547--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F69fa043fd547&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----69fa043fd547---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----69fa043fd547--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----69fa043fd547--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----69fa043fd547--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----69fa043fd547--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----69fa043fd547--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----69fa043fd547--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----69fa043fd547--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----69fa043fd547--------------------------------", "anchor_text": ""}, {"url": "https://rayheberer.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://rayheberer.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ray Heberer"}, {"url": "https://rayheberer.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "362 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6efdc3f1390&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&user=Ray+Heberer&userId=d6efdc3f1390&source=post_page-d6efdc3f1390--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Facb0180c171c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-machine-learning-validation-sets-grow-stale-69fa043fd547&newsletterV3=d6efdc3f1390&newsletterV3Id=acb0180c171c&user=Ray+Heberer&userId=d6efdc3f1390&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}