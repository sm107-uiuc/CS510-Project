{"url": "https://towardsdatascience.com/rip-correlation-introducing-the-predictive-power-score-3d90808b9598", "time": 1683006259.219111, "path": "towardsdatascience.com/rip-correlation-introducing-the-predictive-power-score-3d90808b9598/", "webpage": {"metadata": {"title": "RIP correlation. Introducing the Predictive Power Score | by Florian Wetschoreck | Towards Data Science", "h1": "RIP correlation. Introducing the Predictive Power Score", "description": "It is Friday afternoon and your boss tells you that the data delivery surprisingly arrived early \u2014 after only 4 weeks of back and forth. This was the missing piece for your predictive model. You\u2019re\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/8080labs/ppscore", "anchor_text": "Python library named ppscore", "paragraph_index": 22}, {"url": "https://github.com/8080labs/ppscore", "anchor_text": "read through the calculation details", "paragraph_index": 23}, {"url": "https://bamboolib.8080labs.com/", "anchor_text": "bamboolib", "paragraph_index": 29}, {"url": "http://eepurl.com/g0ddnH", "anchor_text": "subscribe here", "paragraph_index": 30}], "all_paragraphs": ["It is Friday afternoon and your boss tells you that the data delivery surprisingly arrived early \u2014 after only 4 weeks of back and forth. This was the missing piece for your predictive model. You\u2019re excited but also a little bit anxious because you know what\u2019s next: exploring the data. All. 45. Columns. This will take many hours but you know it\u2019s worth it because without data understanding you are walking blind. One obvious step is to have a look at all the univariate column distributions. But this won\u2019t be enough.", "You ask yourself: what relationships exist between columns?", "To answer this question, you just repeat the typical drill: calculate a correlation matrix and check for some surprising relationships. Whenever you are surprised, you take a moment to plot a scatterplot of the two columns at hand and see if you can make any sense of it. Hopefully you can but too often you cannot because you don\u2019t even know what the columns mean in the first place. But this is a story for another day.", "After inspecting the correlation matrix you move on and you don\u2019t even know what you don\u2019t know (scary).", "Let\u2019s take a moment to review the correlation. The score ranges from -1 to 1 and indicates if there is a strong linear relationship \u2014 either in a positive or negative direction. So far so good. However, there are many non-linear relationships that the score simply won\u2019t detect. For example, a sinus wave, a quadratic curve or a mysterious step function. The score will just be 0, saying: \u201cNothing interesting here\u201d. Also, correlation is only defined for numeric columns. So, let\u2019s drop all the categoric columns. In my last project more than 60% of the columns were categoric, but hey. Never mind. And no, I won\u2019t convert the columns because they are not ordinal and OneHotEncoding will create a matrix that has more values than there are atoms in the universe.", "If you are a little bit too well educated you know that the correlation matrix is symmetric. So you basically can throw away one half of it. Great, we saved ourselves some work there! Or did we? Symmetry means that the correlation is the same whether you calculate the correlation of A and B or the correlation of B and A. However, relationships in the real world are rarely symmetric. More often, relationships are asymmetric. Here is an example: The last time I checked, my zip code of 60327 tells strangers quite reliably that I am living in Frankfurt, Germany. But when I only tell them my city, somehow they are never able to deduce the correct zip code. Pff \u2026 amateurs. Another example is this: a column with 3 unique values will never be able to perfectly predict another column with 100 unique values. But the opposite might be true. Clearly, asymmetry is important because it is so common in the real world.", "Thinking about those shortcomings of correlation, I started to wonder: can we do better?", "The requirements: One day last year, I was dreaming about a score that would tell me if there is any relationship between two columns \u2014 no matter if the relationship is linear, non-linear, gaussian or only known by aliens. Of course, the score should be asymmetric because I want to detect all the weird relationships between cities and zip codes. The score should be 0 if there is no relationship and the score should be 1 if there is a perfect relationship. And as the icing on the cake, the score should be able to handle categoric and numeric columns out of the box. Summing it up for all my academic friends: an asymmetric, data-type-agnostic score for predictive relationships between two columns that ranges from 0 to 1.", "First of all, there is not the one and only way to calculate the predictive power score. In fact, there are many possible ways to calculate a score that satisfies the requirements mentioned before. So, let\u2019s rather think of the predictive power score as a framework for a family of scores.", "Let\u2019s say we have two columns and want to calculate the predictive power score of A predicting B. In this case, we treat B as our target variable and A as our (only) feature. We can now calculate a cross-validated Decision Tree and calculate a suitable evaluation metric. When the target is numeric we can use a Decision Tree Regressor and calculate the Mean Absolute Error (MAE). When the target is categoric, we can use a Decision Tree Classifier and calculate the weighted F1. You might also use other scores like the ROC etc but let\u2019s put those doubts aside for a second because we have another problem:", "Most evaluation metrics are meaningless if you don\u2019t compare them to a baseline", "I guess you all know the situation: you tell your grandma that your new model has a F1 score of 0.9 and somehow she is not as excited as you are. In fact, this is very smart of her because she does not know if anyone can score 0.9 or if you are the first human being who ever scored higher than 0.5 after millions of awesome KAGGLErs tried. So, we need to \u201cnormalize\u201d our evaluation score. And how do you normalize a score? You define a lower and an upper limit and put the score into perspective. So what should the lower and upper limit be? Let\u2019s start with the upper limit because this is usually easier: a perfect F1 is 1. A perfect MAE is 0. Boom! Done. But what about the lower limit? Actually, we cannot answer this in absolute terms.", "The lower limit depends on the evaluation metric and your data set. It is the value that a naive predictor achieves.", "If you achieve a F1 score of 0.9 this might be super bad or really good. If your super fancy cancer detection model always predicts \u201cbenign\u201d and it still scores 0.9 on that highly skewed dataset then 0.9 is obviously not so good. So, we need to calculate a score for a very naive model. But what is a naive model? For a classification problem, always predicting the most common class is pretty naive. For a regression problem, always predicting the median value is pretty naive.", "Getting back to the example of the zip codes and the city name. Imagine both columns are categoric. First, we want to calculate the PPS of zip code to city. We use the weighted F1 score because city is categoric. Our cross-validated Decision Tree Classifier achieves a score of 0.95 F1. We calculate a baseline score via always predicting the most common city and achieve a score of 0.1 F1. If you normalize the score, you will get a final PPS of 0.94 after applying the following normalization formula: (0.95\u20130.1) / (1\u20130.1). As we can see, a PPS score of 0.94 is rather high, so the zip code seems to have a good predictive power towards the city. However, if we calculate the PPS in the opposite direction, we might achieve a PPS of close to 0 because the Decision Tree Classifier is not substantially better than just always predicting the most common zip code.", "Please note: the normalization formula for the MAE is different from the F1. For MAE lower is better and the best value is 0.", "In order to get a better feeling for the PPS and its differences to the correlation, let\u2019s have a look at the following two examples:", "Let\u2019s use a typical quadratic relationship: the feature x is a uniform variable ranging from -2 to 2 and the target y is the square of x plus some error. In this case, x can predict y very well because there is a clear non-linear, quadratic relationship \u2014 after all that\u2019s how we generated the data. However, this is not true in the other direction from y to x. For example, if y is 4, it is impossible to predict whether x was roughly 2 or -2. Thus, the predictive relationship is asymmetric and the scores should reflect this.", "What are the values of the scores in this example? If you don\u2019t already know what you are looking for, the correlation will leave you hanging because the correlation is 0. Both from x to y and from y to x because the correlation is symmetric. However, the PPS from x to y is 0.67, detecting the non-linear relationship and saving the day. Nevertheless, the PPS is not 1 because there exists some error in the relationship. In the other direction, the PPS from y to x is 0 because your prediction cannot be better than the naive baseline and thus the score is 0.", "Let\u2019s compare the correlation matrix to the PPS matrix on the Titanic dataset. \u201cThe Titanic dataset? Again??\u201d I know, you probably think you already have seen everything about the Titanic dataset but maybe the PPS will give you some new insights.", "After we learned about the advantages of the PPS, let\u2019s see where we can use the PPS in the real life.", "Disclaimer: There are use cases for both the PPS and the correlation. The PPS clearly has some advantages over correlation for finding predictive patterns in the data. However, once the patterns are found, the correlation is still a great way of communicating found linear relationships.", "If you are still following along you are one of the rare human beings who still have an attention span \u2014 you crazy beast! If you can\u2019t wait to see what the PPS will reveal on your own data, we have some good news for you: we open-sourced an implementation of the PPS as a Python library named ppscore.", "Before using the Python library, please take a moment to read through the calculation details", "Calculating the PPS for a given pandas dataframe:", "You can also calculate the whole PPS matrix:", "Although the PPS has many advantages over the correlation, there is some drawback: it takes longer to calculate. But how bad is it? Does it take multiple weeks or are we done in a couple of minutes or even seconds? When calculating a single PPS using the Python library, the time should be no problem because it usually takes around 10\u2013500ms. The calculation time mostly depends on the data types, the number of rows and the used implementation. However, when calculating the whole PPS matrix for 40 columns this results in 40*40=1600 individual calculations which might take 1\u201310 minutes. So you might want to start the calculation of the PPS matrix in the background and go on that summer vacation you always dreamed of! \ud83c\udfd6 \ufe0fFor our projects and datasets the computational performance was always good enough but of course there is room for improvement. Fortunately, we see many ways how the calculation of the PPS can be improved to achieve speed gains of a factor of 10\u2013100. For example, using intelligent sampling, heuristics or different implementations of the PPS. If you like the PPS and are in need of a faster calculation, please reach out to us.", "We made it \u2014 you are excited and want to show the PPS to your colleagues. However, you know they are always so critical about new methods. That\u2019s why you better be prepared to know the limitations of the PPS:", "After years of using the correlation we were so bold (or crazy?) to suggest an alternative that can detect linear and non-linear relationships. The PPS can be applied to numeric and categoric columns and it is asymmetric. We proposed an implementation and open-sourced a Python package. In addition, we showed the differences to the correlation on some examples and discussed some new insights that we can derive from the PPS matrix.", "Now it is up to you to decide what you think about the PPS and if you want to use it on your own projects. We have been using the PPS for over a year as part of the library bamboolib where the PPS is essential to add some advanced features and thus we wanted to share the PPS with the broader community. Therefore, we hope to receive your feedback about the concept and we would be thrilled if you try the PPS on your own data. In case that there might be a positive reception, we are happy to hear about your requests for adjustments or improvements to the implementation. As we mentioned before, there are many ways on how to improve the speed and on how to adjust the PPS for more specific use cases.", "Newsletter: if you want to hear more about the PPS and our other upcoming Data Science projects and tools, you can subscribe here. We will not write about paid products, you can unsubscribe anytime and \u2014 sad that we even have to mention this \u2014 we will never give away your email.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Co-Creator of bamboolib and pyforest. Always trying to create better tools for Python Data Scientists."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3d90808b9598&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3d90808b9598--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3d90808b9598--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@florian.wetschoreck?source=post_page-----3d90808b9598--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@florian.wetschoreck?source=post_page-----3d90808b9598--------------------------------", "anchor_text": "Florian Wetschoreck"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6ed760f28120&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&user=Florian+Wetschoreck&userId=6ed760f28120&source=post_page-6ed760f28120----3d90808b9598---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d90808b9598&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d90808b9598&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/8080labs/ppscore", "anchor_text": "open-source"}, {"url": "https://en.wikipedia.org/wiki/Correlation_and_dependence", "anchor_text": "image by Denis Boigelot"}, {"url": "https://github.com/8080labs/ppscore", "anchor_text": "Python library named ppscore"}, {"url": "https://github.com/8080labs/ppscore", "anchor_text": "read through the calculation details"}, {"url": "https://bamboolib.8080labs.com/", "anchor_text": "bamboolib"}, {"url": "https://github.com/8080labs/ppscore", "anchor_text": "https://github.com/8080labs/ppscore"}, {"url": "http://eepurl.com/g0ddnH", "anchor_text": "subscribe here"}, {"url": "https://8080labs.com/blog/posts/rip-correlation-introducing-the-predictive-power-score-pps/", "anchor_text": "https://8080labs.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----3d90808b9598---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/exploratory-data-analysis?source=post_page-----3d90808b9598---------------exploratory_data_analysis-----------------", "anchor_text": "Exploratory Data Analysis"}, {"url": "https://medium.com/tag/correlation?source=post_page-----3d90808b9598---------------correlation-----------------", "anchor_text": "Correlation"}, {"url": "https://medium.com/tag/python?source=post_page-----3d90808b9598---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/open-source?source=post_page-----3d90808b9598---------------open_source-----------------", "anchor_text": "Open Source"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3d90808b9598&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&user=Florian+Wetschoreck&userId=6ed760f28120&source=-----3d90808b9598---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3d90808b9598&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&user=Florian+Wetschoreck&userId=6ed760f28120&source=-----3d90808b9598---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d90808b9598&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3d90808b9598--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3d90808b9598&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3d90808b9598---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3d90808b9598--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3d90808b9598--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3d90808b9598--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3d90808b9598--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3d90808b9598--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3d90808b9598--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3d90808b9598--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3d90808b9598--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@florian.wetschoreck?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@florian.wetschoreck?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Florian Wetschoreck"}, {"url": "https://medium.com/@florian.wetschoreck/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "965 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6ed760f28120&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&user=Florian+Wetschoreck&userId=6ed760f28120&source=post_page-6ed760f28120--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F19e9758cd771&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frip-correlation-introducing-the-predictive-power-score-3d90808b9598&newsletterV3=6ed760f28120&newsletterV3Id=19e9758cd771&user=Florian+Wetschoreck&userId=6ed760f28120&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}