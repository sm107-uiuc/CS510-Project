{"url": "https://towardsdatascience.com/how-are-decision-trees-built-a8e5af57ce8", "time": 1683010679.332351, "path": "towardsdatascience.com/how-are-decision-trees-built-a8e5af57ce8/", "webpage": {"metadata": {"title": "How are decision trees built?. Introductory guide to build a decision\u2026 | by Zolzaya Luvsandorj | Towards Data Science", "h1": "How are decision trees built?", "description": "Wouldn\u2019t it be awesome to understand the underlying principles used to build a decision tree? In this post, I will demonstrate how to build a decision tree, in particular a classification tree, using\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.imdb.com/title/tt0108778/", "anchor_text": "Friends", "paragraph_index": 1}, {"url": "https://zluvsand.medium.com/membership", "anchor_text": "my referral link", "paragraph_index": 38}, {"url": "https://www.google.com/search?q=ross+geller&rlz=1C1CHBF_enAU847AU848&oq=ross+geller&aqs=chrome..69i57j0l7.4197j0j7&sourceid=chrome&ie=UTF-8", "anchor_text": "Ross Geller on Google", "paragraph_index": 39}, {"url": "https://towardsdatascience.com/transforming-variables-in-a-pandas-dataframe-bce2c6ef91a1", "anchor_text": "How to transform variables in a pandas DataFrame", "paragraph_index": 40}, {"url": "https://medium.com/@zluvsand/two-simple-ways-to-scrape-text-from-wikipedia-in-python-9ce07426579b", "anchor_text": "Two simple ways to scrape text from Wikipedia in Python", "paragraph_index": 40}, {"url": "https://towardsdatascience.com/simple-wordcloud-in-python-2ae54a9f58e5", "anchor_text": "Simple wordcloud in Python", "paragraph_index": 40}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96", "anchor_text": "Introduction to NLP \u2014 Part 1: Preprocessing text in Python", "paragraph_index": 40}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc", "anchor_text": "Introduction to NLP \u2014 Part 2: Difference between lemmatisation and stemming", "paragraph_index": 40}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc", "anchor_text": "Introduction to NLP \u2014 Part 3: TF-IDF explained", "paragraph_index": 40}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267", "anchor_text": "Introduction to NLP \u2014 Part 4: Supervised text classification model in Python", "paragraph_index": 40}, {"url": "https://zluvsand.github.io/", "anchor_text": "https://zluvsand.github.io/", "paragraph_index": 42}], "all_paragraphs": ["Wouldn\u2019t it be awesome to understand the underlying principles used to build a decision tree? In this post, I will demonstrate how to build a decision tree, in particular a classification tree, using two different criterion: gini impurity and entropy supplemented by a step-by-step explanation. I hope you will have a better appreciation of how decision trees are built by the end of this post! \ud83c\udf93", "To keep things manageable and hopefully a bit of fun, we will create a tiny fictitious data inspired by the 6 main characters from the sitcom Friends:", "Let\u2019s entertain the idea that this data is correct for the purpose of this post. We will build a decision tree to classify if a character is a parent using the rest of the columns. In other words, we will build a classification tree with the following inputs and output:\u25fc \ufe0finputs | features: was_on_a_break, is_married, has_pet\u25fc\ufe0f output | target: is_parent", "If you enjoy math, I encourage you to manually calculate alongside this guide to make most of this blog. In this section, those characters who are parents are abbreviated as pa and the non-parents are abbreviated as np for brevity.", "Decision trees are built by recursively splitting into binary nodes from top-down. We can find the best split for a node with the following steps:STEP 1: Calculate gini impurity (here onwards gini) for the node to split fromSTEP 2: Find all possible splitsSTEP 3: Calculate gini for both nodes for each splitSTEP 4: Calculate the weighted average gini for each splitSTEP 5: Determine the best split: the one with lowest weighted average giniSTEP 6: Calculate information gain: split if information gain is positive", "The very top node that includes everyone from the training data is known as root node. Let\u2019s determine the best split for the root node with the steps.", "\ud83d\udeaa STEP 1: Calculate the gini at a root node\u2797 Formula:", "We can simplify this generic formula to the following and calculate the gini:", "We know that there were 2 non-parents and 4 parents among the 6 characters. Using this information, we found the gini to be 0.444 at the root node. Root node can therefore be summarised as below:", "\ud83d\udeaa STEP 2: Find all possible splits from the root nodeThere are three ways to split using any of the three features. For instance, we could split the 6 characters into 2 groups: one group for those with pets and another group for those without. Same goes for the other two features.", "\ud83d\udeaa STEP 3: Calculate gini for both nodes for each splitLet\u2019s calculate the gini for each node for the three splits.", "\ud83d\udcccExercise: See if you can calculate gini for all 6 nodes before proceeding.", "\ud83d\udd11 Answer: Using the same logic from step 1, we find the gini for each node as follows:", "\ud83d\udeaa STEP 4: Calculate the weighted average gini for each splitNow, we need to find the weighted average gini, denoted as w_gini, for each split. Taking was_on_a_break as an example, we compute the w_gini as follows:", "\u2797 Formula: left: node of the left, right: node on the right", "\ud83d\udcccExercise: See if you can calculate the weighted gini for the other two.", "\ud83d\udd11 Answer: Do your answers match to these?", "\ud83d\udeaa STEP 5: Determine the best split (lowest weighted average gini)By inspecting the results from the previous step, using is_married for splitting gives us the lowest weighted average gini. We can intuitively make sense of this decision if we look at the table from step 3 as well. When splitting on is_married, the tree is able to split half of the data into a pure node on the left. This node is pure because it only contains parents. Gini is 0 for the purest node and 0.5 for the impurest node (e.g. right nodes for the other splits).", "\ud83d\udeaa STEP 6: Calculate information gain: if positive, \ud83d\udc49 splitWe learnt that it\u2019s best to use is_married if we were to split. Now let\u2019s see if we gain any information from splitting. Information gain is defined as the difference between the gini at the top node to split from and the weighted average gini from the bottom nodes.", "Information gain is positive. In other words, we gain information by splitting. Therefore, the correct decision is to split using is_married from the root node.", "We have just learned how a split is determined. \u2b50\ufe0f Let\u2019s repeat the same steps to build the rest of the tree. Time to assess the split for the mustard nodes!", "Perhaps we could start from the easier one: the left node containing married ones. We see that all married characters are parents and therefore gini=0. If we split from this node, we won\u2019t gain any information even if the weighted gini is 0 from the split. Therefore, the correct decision is not to split. In this case, this node is considered as a terminal node, the one that doesn\u2019t split further. On the other hand, we have some work to do for the non-married characters in the other node on the right. The best way to make this knowledge stick is to practice yourself, why not try applying what we just learned with the exercise below:", "\ud83d\udcccExercise: Complete all the steps to find the correct split for the right node", "\ud83d\udd11 Answer: STEP 1: We already know the answer from previous split: 0.444STEP 2: We could split either using was_on_a_break or has_petSTEP 3 & STEP 4: See the image belowSTEP 5: The best split is to use was_on_a_break with w_gini of 0STEP 6: Information gain is 0.444 - 0=0.444, so the correct decision is to split.", "Combining the outputs, the final decision tree looks like this:", "Yay\u2755 We have built a simple decision tree.", "Let\u2019s understand what would change if we used entropy instead of gini. The steps remain the same, except we calculate entropy each time. \u2797 Formula:", "We can simplify this generic formula to:", "If we complete all the steps using entropy starting from the root node again, the outputs for steps 1, 3 and 4 change to those below:", "With this output, it appears that is_married is yet again the best split from the root node. Information gain is assessed in a similar way:", "It makes sense to split given that we gain information. Let\u2019s continue the same steps for the bottom nodes like before.", "Because the left node for married characters are pure, we don\u2019t need to split from that anymore. But we will try to improve the right node by following the steps. Outputs to steps 1, 3 and 4 would look like below:", "This is the final tree \ud83c\udf34:", "Did you notice that gini is 0.5 and entropy is 1 for the impurest case where the node is split evenly between the two classes whereas they are both 0 for the purest node that consists of only one class?", "If you are keen to practice more to consolidate your learning, feel free to use your own small dataset to build a simple decision tree. You can check your tree against sklearn output using the sample script below:", "In practice, more robust algorithms that use decision tree as a building block are perhaps more commonly used as a predictive model than decision trees themselves.", "Decision trees tend to overfit easily if you are not careful. We could argue that was_on_a_break was not a good feature to use because it happened to be a very specific feature that only applies to the records in the training data. Therefore, using this feature to build a model can lead the model overfit to the noise in the training data.", "Regardless, I think it is still valuable to understand the underlying principles used in building decision trees. \u2728", "Would you like to access more content like this? Medium members get unlimited access to any articles on Medium. If you become a member using my referral link, a portion of your membership fee will directly go to support me.", "Fun fact: Have you heard of Google\u2019s easter eggs for Friends? Search for Ross Geller on Google and click on the small couch on the right side just underneath his picture. \ud83d\ude4a This feature is available for the other 5 characters, too!", "Thank you for reading my post. I hope that you have learned something \u2702\ufe0f. In case you are interested, here are links to the my other posts:\u25fc\ufe0f How to transform variables in a pandas DataFrame\u25fc\ufe0f Two simple ways to scrape text from Wikipedia in Python\u25fc\ufe0f Simple wordcloud in Python\u25fc\ufe0f\ufe0f Introduction to NLP \u2014 Part 1: Preprocessing text in Python\u25fc\ufe0f Introduction to NLP \u2014 Part 2: Difference between lemmatisation and stemming\u25fc\ufe0f Introduction to NLP \u2014 Part 3: TF-IDF explained\u25fc\ufe0f Introduction to NLP \u2014 Part 4: Supervised text classification model in Python", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist \ud83d\udca1| Growth Mindset \ud83d\udd11 | Math Lover \ud83d\udd22 | Melbourne, AU \ud83d\udc28 | https://zluvsand.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa8e5af57ce8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://zluvsand.medium.com/?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": ""}, {"url": "https://zluvsand.medium.com/?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "Zolzaya Luvsandorj"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bca2b935223&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=post_page-5bca2b935223----a8e5af57ce8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8e5af57ce8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8e5af57ce8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.imdb.com/title/tt0108778/", "anchor_text": "Friends"}, {"url": "https://unsplash.com/@aaronburden?utm_source=medium&utm_medium=referral", "anchor_text": "Aaron Burden"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://zluvsand.medium.com/membership", "anchor_text": "my referral link"}, {"url": "https://www.google.com/search?q=ross+geller&rlz=1C1CHBF_enAU847AU848&oq=ross+geller&aqs=chrome..69i57j0l7.4197j0j7&sourceid=chrome&ie=UTF-8", "anchor_text": "Ross Geller on Google"}, {"url": "https://towardsdatascience.com/transforming-variables-in-a-pandas-dataframe-bce2c6ef91a1", "anchor_text": "How to transform variables in a pandas DataFrame"}, {"url": "https://medium.com/@zluvsand/two-simple-ways-to-scrape-text-from-wikipedia-in-python-9ce07426579b", "anchor_text": "Two simple ways to scrape text from Wikipedia in Python"}, {"url": "https://towardsdatascience.com/simple-wordcloud-in-python-2ae54a9f58e5", "anchor_text": "Simple wordcloud in Python"}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96", "anchor_text": "Introduction to NLP \u2014 Part 1: Preprocessing text in Python"}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc", "anchor_text": "Introduction to NLP \u2014 Part 2: Difference between lemmatisation and stemming"}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc", "anchor_text": "Introduction to NLP \u2014 Part 3: TF-IDF explained"}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267", "anchor_text": "Introduction to NLP \u2014 Part 4: Supervised text classification model in Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a8e5af57ce8---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/decision-tree?source=post_page-----a8e5af57ce8---------------decision_tree-----------------", "anchor_text": "Decision Tree"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a8e5af57ce8---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/classification?source=post_page-----a8e5af57ce8---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/supervised-learning?source=post_page-----a8e5af57ce8---------------supervised_learning-----------------", "anchor_text": "Supervised Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8e5af57ce8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=-----a8e5af57ce8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8e5af57ce8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=-----a8e5af57ce8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8e5af57ce8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa8e5af57ce8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a8e5af57ce8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a8e5af57ce8--------------------------------", "anchor_text": ""}, {"url": "https://zluvsand.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://zluvsand.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Zolzaya Luvsandorj"}, {"url": "https://zluvsand.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.3K Followers"}, {"url": "https://zluvsand.github.io/", "anchor_text": "https://zluvsand.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bca2b935223&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=post_page-5bca2b935223--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea8899bb3fba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-are-decision-trees-built-a8e5af57ce8&newsletterV3=5bca2b935223&newsletterV3Id=ea8899bb3fba&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}