{"url": "https://towardsdatascience.com/neurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525", "time": 1683017328.175701, "path": "towardsdatascience.com/neurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525/", "webpage": {"metadata": {"title": "NeurIPS 2020 Papers: Takeaways of a Deep Learning Engineer\u2014 Computer Vision | by Prabhu Prakash Kagitha | Towards Data Science", "h1": "NeurIPS 2020 Papers: Takeaways of a Deep Learning Engineer\u2014 Computer Vision", "description": "I went through all the titles of NeurIPS 2020 papers (more than 1900!) and read abstracts of 175 papers, and extracted DL engineer relevant insights from the following papers."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["As mentioned in part 1\u2014 the most important thing:) \u2014 I went through all the titles of NeurIPS 2020 papers (more than 1900!) and read abstracts of 175 papers, and extracted DL engineer relevant insights from the following papers.", "This is part 2. See the part 1 below.", "Using other datasets to better solve the target dataset is ubiquitous in deep learning practice. It could be supervised pre-training (Classification; ImageNet pre-trained) or self-supervised pre-training (SimCLR on unlabeled data) or self-training.", "(Self-training is a process where an intermediate model (teacher model), which is trained on target dataset, is used to create \u2018labels\u2019 (thus called pseudo labels) for another dataset and then the final model (student model) is trained with both target dataset and the pseudo labeled dataset.)", "Building on the previous work, the current work shows that the usefulness of ImageNet pre-training (starting with pre-trained weights rather than random) or self-supervised pre-training decreases with the size of the target dataset and the strength of the data augmentation. ImageNet pretraining didn\u2019t help, rather hurt in some cases, the model when training on COCO dataset for object detection.", "But, self-training helped in both low-data and high-data regime and with both strong and weak data augmentation strategies. It helped when pre-training didn\u2019t help and showed improvement on it when it did.", "Takeaway: When you want to leverage other datasets in training a model on a target dataset, use self-training rather than ImageNet pretraining. But keep in mind that self-training takes more resources than just initializing your model with ImageNet pre-trained weights.", "Different object detection models employ different intermediate representations from which the bounding box predictions are made.", "For example, RetinaNet uses a bounding box (anchors) representational format, where it creates feature maps for each bounding box instance created by anchor boxes at each position of the feature grid. If a feature grid is of H x W, takes RetinaNet takes 9 anchor boxes (pre-specified aspect ratios) for each position of the feature grid giving us 9 x H x W bounding box instances to do IOU thresholding, predicting the classes and sub-pixel offsets, and do NMS on top among other things to get the final set of bounding boxes for an image.", "FCOS and CenterNet use a center point as representation formats and estimates bounding boxes by predicting x and y dimensional offsets from the center point. And it has all the other processing steps very similar in objective with RetinaNet or any other object detection models.", "CornerNet instead uses corner points as representation format (top left and bottom right) and creates a bounding box with those corner points.", "Different representations are prevalent in object detection because each representation is good at some specific thing compared to all others. Bounding box representation is better aligned with annotation formats of datasets and is better at classification. Center point representation is better for detecting small objects. Corner point representation is better at localization.", "This current work aims to combine the strengths of all these different representations. For a particular object detection model, they improve the features of its primary representation, bounding box for RetinaNet, by also taking into account features from other auxiliary representations, here, they are center points and corner points.", "The author proposed a Transformer model. When given a feature vector of primary representation for a location on a feature grid (query) it calculates attention weights with feature vectors of auxiliary representations at relevant locations and returns a weighted average of these auxiliary representations.", "The model, called Bridging Visual Representations (BVR), will use both the feature vector for primary representation and the weighted average of feature vectors from auxiliary representations to do classification and localization thus combining the strengths and expressive power of different representational choices.", "Takeaway: This is the state-of-the-art model and it makes sense. Any approach which combines the strengths of multiple solutions non-trivially would be valuable for a long time. Use this method when you train your next object detection model. (Too many good things for object detection!)", "Without a downstream task, it is hard to quantitatively evaluate image representations, i.e. the clusters formed with image representations for their semantic coherence and natural language describability.", "This work formulates these tasks, learnability and describability of the clusters, as a forced-prediction problem and evaluates humans as predictors avoiding the issue of subjectivity which is a major problem with existing approaches. (Even though clusters are coherent, sometimes they can\u2019t be described and even though they are describable different person might use different words and phrases).", "After seeing a few samples of a cluster, a human should able to discriminate images of that cluster among images of other clusters. This means that clusters are separated in a human-interpretable way. The extent to which a human can do this is the metric for learnability.", "After seeing the description of a cluster, a human should able to discriminate images of that cluster among images of other clusters. This means the given cluster is describable. (Description is sampled randomly from a manually populated set of descriptions for that cluster). The extent to which a human can do this is the metric for describability.", "Authors also created a model to get automated descriptions for a cluster so that it could replace the human in the above describability metric.", "Takeaway: If you have clusters of images with no labels, the extent to which you could discriminate other images as the same class or not, after seeing the images of a particular cluster, is a good metric to see whether your clusters are separated. The same goes for describability.", "There are a lot of outstanding problems to deal with in object detection. Prominent among them dealt with this work are:", "And this is how they deal with it:", "Takeaway: Stability when training and having fewer hyper-parameters to tune is much desired in practive. I can remember a lot scenarios where results are not reproducable. This type of work would be more valuable for a deep learning engineer and I recommend one using it when training your next object detection model.", "Labeling in the medical image domain is cost-intensive and have a large inter-observer variability. A method that combines annotations from different annotators while modeling an annotator across images so that we can train with only a few annotations per image is desirable. This is that method.", "Given an image with 3 ground truth masks labeled by three different annotators A1, A2, and A3, this work, which also models biases of each annotator, tries to predict three different versions of segmentation masks one for each annotator and tries to backpropagate the loss between these 3 predicted masks and 3 ground truth masks.", "As these annotator-specific segmentation masks are created with distortion (confusion matrix for each annotator) from the estimated true label which is predicted first, we would take the segmentation mask of the estimated true label as the prediction from the model during inference.", "Takeaway: If your application has more inter-observer variability and you have the bandwidth to get multiple annotations per image, this seems to be the go-to right now\u00a0to\u00a0get\u00a0one\u00a0ground\u00a0truth out of many.", "Predicting segmentation maps for a complete object when it is occluded is called Amodal Object Completion.", "This work presents Amodel-VAE, which encodes the partial mask into a latent vector and predicts a complete mask decoding that latent vector. This work doesn\u2019t require full-object segmentation annotations for training making it desirable as previous works needed complete segmentation masks annotated.", "To train without complete masks, they carefully train Amodel-VAE in three stages.", "Takeaway: Practically, knowing the complete locations of objects in occlusion would help to track multiple people and decrease Id-swaps that we see even in SOTA tracking models. It should be interesting if you want to smart photoshop as well. More importantly, this is kind of a problem where use cases are limited only by our creativity.", "Automated data augmentation needs to find the probability of each transformation and the magnitude to be used for each of these transformations.", "With large possible values for probabilities and magnitudes for each of the transformations, search space becomes intractable. Recent method AutoAugment used RL to find an optimal sequence of transformations and their magnitudes. More recent variants of AutoAugment tried to make use of more efficient learning algorithms to find the optimal sequence of transformations efficiently.", "Nonetheless, the number of iterations of training a model with a set of transformations to find the optimal probability and magnitude values for transformations is still intractable in practice if we are doing it on large-scale models and large-scale datasets. So, proxy tasks are set up, with small models and less data among other tweaks, representative of the target task. Optimal probabilities and magnitudes are found on proxy tasks and are used for the target task.", "But that these proxy tasks are not actually representative of the complete target tasks. This work showed that the \u201coptimal magnitude of augmentation depends on the size of the model and the training set.\u201d", "Now, to make this optimal policy search feasible, this current work proposed RandAugment which is just a grid search on two parameters with ~30 orders of magnitude smaller search space. This is, for sure, one of the few simple-but-powerful and back-to-basics kinds of work you could find.", "First, RandAugment picks transformations with uniform probability. Because they observed that optimal policies from AutoAugment are making the dataset visually diverse rather than selecting a preferred set of particular transformations (different probabilities for different transformations).", "Second, RandAugment has the same magnitude for all the transformations. Because they observed that optimal policies from an AutoAugment variant had similar magnitudes for all the transformations.", "After these adjustments, automated data augmentation became a simple hyperparameter tuning task which could be done with a grid search and the whole algorithm might be written comfortably in 3 lines.", "Takeaway: Automated data augmentation evolved to a point that it is feasible to use in our \u2018everyday\u2019 models. If you have resources to do hyperparameter tuning, tune these two parameters (N and M for number of transformations and their global magnitude) as well and get state-of-the-art results.", "Let\u2019s assume you want to test your model on a rotated image and images in your training set are never rotated or rotation data augmentation is not used while training. The best possible thing we could do is to do the rotation now at test time to make the images not rotated. And with 10 commonly used and naturally occurring transformations this could happen without you knowing.", "So, what is the solution? While training, have a separate network that predicts the loss of a model for each of the transformations if applied to the image.", "Using this model, apply only the transformations which give lower loss values at test time.", "Takeaway: Didn\u2019t train your model with necessary data augmentations? Want the best possible results on the test set? Use the above test-time Augmentation.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Storyteller of art and science. Deep learning & Cognitive science. Reach me at prakashkagitha@gmail.com to discuss research or collaboration or consulting."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fef5ea1abe525&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://prakashkagitha.medium.com/?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": ""}, {"url": "https://prakashkagitha.medium.com/?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "Prabhu Prakash Kagitha"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33b5e848c750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&user=Prabhu+Prakash+Kagitha&userId=33b5e848c750&source=post_page-33b5e848c750----ef5ea1abe525---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fef5ea1abe525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fef5ea1abe525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/neurips-2020-papers-a-deep-learning-engineers-takeaway-4f3066523151", "anchor_text": "NeurIPS 2020 Papers: Takeaways of a Deep Learning Engineer (Part 1 of 3)Techniques and insights for applied deep learning from papers published at NeurIPS 2020.towardsdatascience.com"}, {"url": "https://neurips.cc/virtual/2020/public/poster_27e9661e033a73a6ad8cefcde965c54d.html", "anchor_text": "Rethinking Pre-training and Self-training"}, {"url": "https://neurips.cc/virtual/2020/public/poster_27e9661e033a73a6ad8cefcde965c54d.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_27e9661e033a73a6ad8cefcde965c54d.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_27e9661e033a73a6ad8cefcde965c54d.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_9d684c589d67031a627ad33d59db65e5.html", "anchor_text": "RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder"}, {"url": "https://neurips.cc/virtual/2020/public/poster_9d684c589d67031a627ad33d59db65e5.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_9d684c589d67031a627ad33d59db65e5.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_9d684c589d67031a627ad33d59db65e5.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_98dce83da57b0395e163467c9dae521b.html", "anchor_text": "Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning"}, {"url": "https://neurips.cc/virtual/2020/public/poster_98dce83da57b0395e163467c9dae521b.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_98dce83da57b0395e163467c9dae521b.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_b2eeb7362ef83deff5c7813a67e14f0a.html", "anchor_text": "A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection"}, {"url": "https://neurips.cc/virtual/2020/public/poster_b2eeb7362ef83deff5c7813a67e14f0a.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_b2eeb7362ef83deff5c7813a67e14f0a.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_b2eeb7362ef83deff5c7813a67e14f0a.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_b2eeb7362ef83deff5c7813a67e14f0a.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_b5d17ed2b502da15aa727af0d51508d6.html", "anchor_text": "Disentangling Human Error from the Ground Truth in Segmentation of Medical Images"}, {"url": "https://neurips.cc/virtual/2020/public/poster_b5d17ed2b502da15aa727af0d51508d6.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_bacadc62d6e67d7897cef027fa2d416c.html", "anchor_text": "Variational Amodal Object Completion"}, {"url": "https://neurips.cc/virtual/2020/public/poster_bacadc62d6e67d7897cef027fa2d416c.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_bacadc62d6e67d7897cef027fa2d416c.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_d85b63ef0ccb114d0a3bb7b7d808028f.html", "anchor_text": "RandAugment: Practical Automated Data Augmentation with a Reduced Search Space"}, {"url": "https://neurips.cc/virtual/2020/public/poster_d85b63ef0ccb114d0a3bb7b7d808028f.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_d85b63ef0ccb114d0a3bb7b7d808028f.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_d85b63ef0ccb114d0a3bb7b7d808028f.html", "anchor_text": "current paper"}, {"url": "https://neurips.cc/virtual/2020/public/poster_2ba596643cbbbc20318224181fa46b28.html", "anchor_text": "https://neurips.cc/virtual/2020/public/poster_2ba596643cbbbc20318224181fa46b28.html"}, {"url": "https://neurips.cc/virtual/2020/public/poster_2ba596643cbbbc20318224181fa46b28.html", "anchor_text": "current paper"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----ef5ea1abe525---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ef5ea1abe525---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ef5ea1abe525---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fef5ea1abe525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&user=Prabhu+Prakash+Kagitha&userId=33b5e848c750&source=-----ef5ea1abe525---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fef5ea1abe525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&user=Prabhu+Prakash+Kagitha&userId=33b5e848c750&source=-----ef5ea1abe525---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fef5ea1abe525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fef5ea1abe525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ef5ea1abe525---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ef5ea1abe525--------------------------------", "anchor_text": ""}, {"url": "https://prakashkagitha.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://prakashkagitha.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Prabhu Prakash Kagitha"}, {"url": "https://prakashkagitha.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "271 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33b5e848c750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&user=Prabhu+Prakash+Kagitha&userId=33b5e848c750&source=post_page-33b5e848c750--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffcc497467df6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneurips-2020-papers-takeaways-of-a-deep-learning-engineer-part-2-of-3-computer-vision-ef5ea1abe525&newsletterV3=33b5e848c750&newsletterV3Id=fcc497467df6&user=Prabhu+Prakash+Kagitha&userId=33b5e848c750&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}