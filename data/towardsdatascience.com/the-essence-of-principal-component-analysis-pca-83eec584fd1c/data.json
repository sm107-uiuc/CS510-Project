{"url": "https://towardsdatascience.com/the-essence-of-principal-component-analysis-pca-83eec584fd1c", "time": 1683011585.728836, "path": "towardsdatascience.com/the-essence-of-principal-component-analysis-pca-83eec584fd1c/", "webpage": {"metadata": {"title": "The Essence of Principal Component Analysis (PCA) | by Taresh | Towards Data Science", "h1": "The Essence of Principal Component Analysis (PCA)", "description": "PCA is the simplest of the true eigenvector-based multivariate analyses. It is most commonly used as a dimensionality-reduction technique, reducing the dimensionality of large data-sets while still\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab", "anchor_text": "Linear Algebra", "paragraph_index": 5}], "all_paragraphs": ["PCA is the simplest of the true eigenvector-based multivariate analyses. It is most commonly used as a dimensionality-reduction technique, reducing the dimensionality of large data-sets while still explaining most of the variance in the data. Seems cute, doesn\u2019t it?", "With this article, I strive to make the idea of PCA intuitive. To understand this article, you should know- Elementary Linear Algebra and High-School Statistics. So, let\u2019s get started.", "The curse of dimensionality refers to the unfavorable consequences of dealing with multi-dimensional studies. Let\u2019s take a simple example- consider having sampled N data points, where each data point is a d dimensional vector. Now, for the same N, data becomes sparse as we add dimensions. Think of having randomly distributed N points on a line vs N points on a plane, which of the two will have a higher density? The answer is quite intuitive, the line (refer to these figures).", "Fine, as we add dimensions to our data, we make it sparse, but why is that a problem? If we lack enough density in our data, we can never be sure of our predictions. For us to train a model to predict results with decent accuracy, the data must be well represented or we run the risk of overfitting. Although we live in the realm of big data, a compromise in the density can only be tackled by an exponential increase in the data (N), which might not be available. Another problem with high-dimensional data is that we can\u2019t easily visualize data beyond 3 dimensions. Distances lose meaning in higher dimensions.", "So, if we can find a way to reduce the dimensionality of our data while retaining most of the information, we\u2019ll be able to deal with our data much more efficiently.", "This is one of the most fascinating ideas in Linear Algebra. By multiplying a matrix to a vector, we linearly transform that vector. If you feel like your grip on basic linear algebra is a little loose, I strongly recommend that you watch 3b1b\u2019s series on Linear Algebra.", "A non-trivial vector whose span doesn\u2019t change upon being multiplied by a matrix is an eigenvector of that matrix. Now, let me clarify two things here- firstly, the span loosely means the direction of that vector and secondly, although the direction doesn\u2019t change, the magnitude can. How stretched or squished the eigenvector becomes i.e. the factor by which the magnitude changes upon multiplication is called the eigenvalue of that eigenvector. Eigenvectors make linear transformations easy to understand. They are the axes along which a linear transformation acts. Now, how can we find such vector/s for a matrix?", "Consider, a matrix M. Let \u03bb be an eigenvalue and v\u0305 be an eigenvector of a matrix M-", "Since v\u0305 is a non-trivial matrix", "\u21d2 for all eigenvalues (\u03bb) satisfying this equation, find corresponding eigenvectors (v\u0305)", "Now, let me tell you a bizarre fact- if you multiply the matrix M to any vector several times, the result is almost along the span of the eigenvector with the largest eigenvalue! The first time that I came across this fact, it blew my mind because irrespective of the vector, the answer\u2019s span remains unchanged.", "(M x M x M\u2026x M) a\u0305 \u2248 \u03b1 v\u0305, where \u03b1 is a constant, a\u0305 is a random vector and v\u0305 is the eigenvector with the largest |\u03bb| (eigenvalue).", "An important thing to observe here is that M^k is also a matrix. So, if we multiply a matrix often enough to itself, we end up with a matrix that transforms every vector to the same span.", "I recommend that you try writing this code yourself and observe how changing the value of k ( keep it > 20) changes the matrix M_k but the property withholds.", "Now, let\u2019s come to the reason behind this seemingly absurd property. The reason has to do with the following equation-", "M\u1d4f = S x (\u039b\u1d4f) x inverse(S), i.e. eigenvectors can represent any power of a matrix M easily.", "\u039b is a diagonal matrix with all the eigenvalues", "S is the null space of (M \u2014 \u03bbI), for all \u03bb\u2019s i.e. matrix S, is the matrix of all eigenvectors.", "M x S = S x \u039b ; (by the eigenvalue-vector defintion)", "\u21d2 M x M = S x \u039b x inverse(S) x S x \u039b x inverse(S)", "Thus this can be done again and again to get-", "However, this equation doesn\u2019t seem to explain the magic! It does\u2026 but it\u2019s hidden in plain sight.", "Consider a vector a\u0305 \u2208 \u211d(n), matrix M \u2208 \u211d(n x n). The algorithm to update a is-", "originally, a\u0305 = c1( v\u03051 ) + c2 ( v\u03052 ) + \u2026 cn ( v\u0305n ), where v\u0305i is the eigenvector with the ith largest eigenvalue and ci is the corresponding constant. The eigenvectors span \u211d(n).", "Now, my intention to bring this property up (besides amazing you) was to highlight the importance of the eigenvalue-vector pairs. Think of them this way, the importance of every eigenvector towards explaining the information in a matrix is directly related to how big its eigenvalue is.", "Assuming that you are at peace with the last statement in the eigenvector section, most of the work here is done! All that\u2019s left is a few basic formulas.", "Here as the steps for performing PCA-", "5. Project your data on the chosen eigenvectors.", "Here\u2019s the thing about eigenvectors, they are not always orthogonal to each other. However, if the matrix is symmetric i.e. the transpose of the matrix is equal to itself, the eigenvectors of such a matrix are orthogonal. Now, notice the covariance matrix. Yes, it\u2019s symmetric! This means that our eigenvectors are orthogonal to each other. Why is that a good thing? I\u2019ll leave this as a question for you to research. Let me know your ideas in the comments section.", "Thus, using Principal Component Analysis we transformed a 4-dimensional dataset into 3-dimensions(which are orthogonal)whilst retaining over 99% of the variance.", "Let\u2019s have a look at the 3 eigenvectors that we had chosen before-", "Now, what do these 4-dimensional vectors signify? Recall that we had 4 dimensions before- sex (a\u0305) age(b\u0305), educ(c\u0305), and hours(d\u0305). So,", "Thus, the final vectors are not along any of the original dimensions. They are linear combinations of all of them. When we project our data, these vectors become our new dimensions (axes).", "Let\u2019s make this idea more intuitive by projecting our standardized data matrix (X) on an identity matrix (I_4) to get a matrix (A).", "Notice that the matrices A and X are the same. This is because by multiplying X to an identity matrix, we didn\u2019t change any dimensions!", "Thanks for making it this far. I hope that this article was worth your time and you now understand PCA intuitively. Please let me know your suggestions and questions in the comments section.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Electrical and Electronics Engineering (EEE) Undergraduate at BITS Pilani | Mathematics and Machine Learning Enthusiast"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F83eec584fd1c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@taresh531?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@taresh531?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "Taresh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F36cfd311cae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&user=Taresh&userId=36cfd311cae8&source=post_page-36cfd311cae8----83eec584fd1c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83eec584fd1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83eec584fd1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@syl_charron66?utm_source=medium&utm_medium=referral", "anchor_text": "sylvie charron"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab", "anchor_text": "Linear Algebra"}, {"url": "https://medium.com/tag/data-science?source=post_page-----83eec584fd1c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/linear-algebra?source=post_page-----83eec584fd1c---------------linear_algebra-----------------", "anchor_text": "Linear Algebra"}, {"url": "https://medium.com/tag/eigenvectors?source=post_page-----83eec584fd1c---------------eigenvectors-----------------", "anchor_text": "Eigenvectors"}, {"url": "https://medium.com/tag/dimensionality-reduction?source=post_page-----83eec584fd1c---------------dimensionality_reduction-----------------", "anchor_text": "Dimensionality Reduction"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----83eec584fd1c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F83eec584fd1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&user=Taresh&userId=36cfd311cae8&source=-----83eec584fd1c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F83eec584fd1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&user=Taresh&userId=36cfd311cae8&source=-----83eec584fd1c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83eec584fd1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F83eec584fd1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----83eec584fd1c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----83eec584fd1c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----83eec584fd1c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----83eec584fd1c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@taresh531?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@taresh531?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Taresh"}, {"url": "https://medium.com/@taresh531/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F36cfd311cae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&user=Taresh&userId=36cfd311cae8&source=post_page-36cfd311cae8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F36cfd311cae8%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-essence-of-principal-component-analysis-pca-83eec584fd1c&user=Taresh&userId=36cfd311cae8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}