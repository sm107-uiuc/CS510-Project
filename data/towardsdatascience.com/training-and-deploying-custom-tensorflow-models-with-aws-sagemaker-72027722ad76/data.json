{"url": "https://towardsdatascience.com/training-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76", "time": 1683017557.27453, "path": "towardsdatascience.com/training-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76/", "webpage": {"metadata": {"title": "Training and Deploying Custom TensorFlow Models with AWS SageMaker | by Ram Vegiraju | Towards Data Science", "h1": "Training and Deploying Custom TensorFlow Models with AWS SageMaker", "description": "Building deep learning models and pipelines locally can prove to be very computationally expensive. This has led to a rise in popularity for cloud computing providers such as AWS, Microsoft Azure\u2026"}, "outgoing_paragraph_urls": [{"url": "https://aws.amazon.com/sagemaker/", "anchor_text": "SageMaker", "paragraph_index": 0}, {"url": "https://aws.amazon.com/console/", "anchor_text": "link", "paragraph_index": 1}, {"url": "https://aws.amazon.com/sagemaker/", "anchor_text": "AWS SageMaker", "paragraph_index": 2}, {"url": "https://aws.amazon.com/s3/", "anchor_text": "AWS S3", "paragraph_index": 3}, {"url": "https://aws.amazon.com/lambda/", "anchor_text": "AWS Lambda", "paragraph_index": 4}, {"url": "https://boto3.amazonaws.com/v1/documentation/api/latest/index.html", "anchor_text": "Boto3", "paragraph_index": 5}, {"url": "https://aws.amazon.com/iam/", "anchor_text": "Identity Access and Management (IAM)", "paragraph_index": 6}, {"url": "https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html", "anchor_text": "Bucket Naming rules", "paragraph_index": 7}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html", "anchor_text": "Notebook Instance", "paragraph_index": 8}, {"url": "https://aws.amazon.com/sagemaker/pricing/", "anchor_text": "different instances types", "paragraph_index": 8}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-resource.html", "anchor_text": "Github repository", "paragraph_index": 10}, {"url": "https://www.kaggle.com/uciml/iris", "anchor_text": "Iris dataset", "paragraph_index": 11}, {"url": "https://github.com/aws/sagemaker-containers#list-of-provided-environment-variables-by-sagemaker-containers", "anchor_text": "linked", "paragraph_index": 18}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-deploy-model.html", "anchor_text": "endpoint", "paragraph_index": 27}, {"url": "https://www.linkedin.com/in/ram-vegiraju-81272b162/", "anchor_text": "Linkedln", "paragraph_index": 33}], "all_paragraphs": ["Building deep learning models and pipelines locally can prove to be very computationally expensive. This has led to a rise in popularity for cloud computing providers such as AWS, Microsoft Azure, and more. SageMaker is Amazon\u2019s main Machine Learning service that enables developers to build, train, and deploy models at scale. SageMaker offers a Jupyter Notebook like environment that allows for developers to build custom models with frameworks such as Tensorflow, PyTorch, and MXNet. Training the model however is not as simple as running a cell in a traditional Jupyter Notebook. I wanted to walk through an end to end example of building and training a custom TensorFlow 2.0 model on the popular Iris dataset.", "NOTE: For those of you new to AWS, make sure you make an account at the following link if you want to follow along. I\u2019ll also provide a list of services we\u2019ll be using along with more in-depth definitions. If you\u2019re already familiar with these services, feel free to skip ahead to the code demonstration.", "AWS SageMaker: Allows for the building, training, and deploying of custom ML models, has support for both Python and R languages. Also includes various pre-trained AWS models that can be used for specific tasks.", "AWS S3: Amazon\u2019s primary storage service, we will be using this service to store our training data and model artifacts/information.", "AWS Lambda: A serverless computing service, that allows developers to run code without managing or provisioning servers. We will not be using this in today\u2019s example, but it can be used as a model inference function when you are incorporating your ML solution in a web-app or front-end of some sort.", "Boto3: AWS Software Development Kit (SDK) for Python developers, can use this within your SageMaker notebook to access different services such as S3.", "Identity Access and Management (IAM): Lets you manage access of AWS services through permissions and roles. We will be creating a role for your SageMaker Instance.", "To get started, we will create an S3 Bucket. This will store our training data and model artifacts after we have trained the model. Go to the S3 service in the AWS Console and click Create Bucket. We will be naming our bucket \u201ctf-iris-data\u201d. If you choose to name your bucket otherwise make sure it is all lowercase, as according to S3 Bucket Naming rules.", "There\u2019s no need to adjust any other settings for our case, so go ahead and click create bucket at the end. After the bucket has been created, move to the SageMaker service and click Notebook Instances. Here we will create our Notebook Instance, \u201ciris-TF-customModel\u201d, which serves as an ML compute instance that allows for us to work with Jupyter Notebooks and the rest of our code. When creating our Notebook Instance, one configuration we need to be aware of is Instance Type. SageMaker offers different instances types that are compute/memory intensive and come at varying prices. For example, if we had a large dataset that required heavy preprocessing a compute-intensive instance such as c4 or c5 would be recommended. For our code along we have a relatively small dataset and simple model architecture, so we\u2019ll go ahead with the default ml.t2.medium instance.", "Most importantly what we need to look at is the IAM role we are assigning our Notebook. We want SageMaker to be able to access S3 for training and storing model artifacts so we need to make sure of this. Click on the first drop-down of the Permissions portion and click create a new role. Click access to any S3 bucket and then create the role.", "We will not be adjusting any other configurations, but you can link the Notebook Instance to a Github repository as well if you wish. Click create Notebook Instance and after a few minutes it should be up and running. Open either Jupyter or JupyterLab (prettier IDE for developers) and we can start coding.", "Once you\u2019ve arrived at your Jupyter Notebook setup, towards the top right you can click new to create a Notebook with the framework and language version you will be using. For this example, we are working with conda_tensorflow_p36 (python 3.6 & TF 2.0). Next we can upload the Iris dataset, clicking the Upload tab. You should now have a Jupyter Notebook and our dataset ready to go in our environment.", "Let\u2019s take a look at our dataset and import the requisite libraries needed. Ensure that your TensorFlow Version is 2.0 or above.", "Our dataset length is 150, we will be using an 80\u201320 split to create train/test files to upload to our S3 bucket.", "You should now see train and test files in your project directory along with your Notebook and original data file.", "Now that we have our training data, we can upload it to S3 to access when we are ready to train our model (SageMaker TensorflowEstimator wants our training data in a S3 bucket to be able to train our model).", "Our prefix is the S3 bucket name we have created, and the key/subfolder is training, this is where our S3 training data will be located. Store this path in a variable as it is crucial for later.", "Now to the fun part, we can code out our model in TensorFlow for training. First upload a blank Python file, called train.py to the project directory. This file will contain the code building our model and serve as the training script that we feed SageMaker\u2019s TensorFlow Estimator. Let\u2019s first import all the libraries we\u2019ll need to preprocess and build our model.", "While the script may look similar to our local TensorFlow training scripts, a key difference to note is that we can incorporate environment variables such as training directory and number of GPUs. I\u2019ve linked a list of all the different environmental variables that you can access. Along with these environmental variables, we can also feed hyperparameters such epochs, learning rate, and batch size as arguments and provide default values for the model.", "NOTE: It\u2019s good practice to keep all of our model building in the if __name__ == \u2018__main__\u2019 block as our training script is being imported by SageMaker.", "Now that we have our arguments ready we can read in our data and preprocess the data so that it is ready for our model.", "Now that our data is ready, we can build our TF model.", "The last step we need in our training script is ensuring that our model\u2019s saved and has its artifacts are stored in S3.", "Now that our training script is ready, we can return to our Notebook. There\u2019s two more features that we need to have ready for our Estimator: SageMaker IAM role and TensorFlow Version.", "Once you\u2019ve ensured that your TF Version is 2.0 or above and have an IAM role we can create an instance of the SageMaker TensorFlow Estimator and start inputting our training script and features.", "When fitting the estimator we pass in the path to our training data that we uploaded earlier to S3. Depending on the size of your dataset and Notebook instance the time to train can differ, but for our case it should only be a few minutes. If your training job was successful you should see the number of epochs you\u2019ve inputted appear in the output logs of the cell with metrics such as loss and validation loss. At the end you should get a small message that your training job has been completed.", "To further ensure that your model has successfully trained if you go back to the SageMaker services and click on a tab called Training Jobs you should see your training job completed successfully.", "Now that we have a trained model, we can test it on points of data for inference. To be able to get inference we need to create a model endpoint for us to access.", "The endpoint should take a little time to create and you can verify by going to the SageMaker service and seeing if your endpoint is up and running.", "Now that we have an endpoint we can access our tf_predictor value to test the model on a new data point. I picked the first point of the test set and inputted the four features the model evaluates to see the result.", "We can now compare this to the test set to cross check what the resulting value was and we see that our model was accurate.", "NOTE: A lot of the power of SageMaker comes from how easily we can incorporate it with other AWS services. Often times SageMaker endpoints are hooked to an AWS Lambda function which is connected to a REST API in Amazon API GW. A common AWS workflow you\u2019ll see is a front-end with a REST API hitting your Lambda function which brings back results from your model you\u2019ve built in SageMaker.", "To access all the code for the demonstration, go to the link posted above. SageMaker allows developers to stitch together deep-learning pipelines and build models at a large scale. One of the largest takeaways with SageMaker or any ML service with a cloud provider is understanding the design and architecture behind the services. Most of your time will be spent on setting up the model environment and having the proper roles/security for each service or feature you are incorporating into your project. Having a good knowledge of these features is crucial to ensuring your project runs smoothly end to end.", "I hope that this article has been useful for anyone trying to work with AWS and SageMaker for their ML projects. Feel free to leave any feedback in the comments or connect with me on Linkedln if interested in chatting about ML & Data Science. Thank you for reading!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F72027722ad76&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----72027722ad76--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----72027722ad76--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ram-vegiraju.medium.com/?source=post_page-----72027722ad76--------------------------------", "anchor_text": ""}, {"url": "https://ram-vegiraju.medium.com/?source=post_page-----72027722ad76--------------------------------", "anchor_text": "Ram Vegiraju"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b----72027722ad76---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F72027722ad76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F72027722ad76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/rymh7EZPqRs", "anchor_text": "Unsplash"}, {"url": "https://aws.amazon.com/sagemaker/", "anchor_text": "SageMaker"}, {"url": "https://aws.amazon.com/console/", "anchor_text": "link"}, {"url": "https://aws.amazon.com/sagemaker/", "anchor_text": "AWS SageMaker"}, {"url": "https://aws.amazon.com/s3/", "anchor_text": "AWS S3"}, {"url": "https://aws.amazon.com/lambda/", "anchor_text": "AWS Lambda"}, {"url": "https://boto3.amazonaws.com/v1/documentation/api/latest/index.html", "anchor_text": "Boto3"}, {"url": "https://aws.amazon.com/iam/", "anchor_text": "Identity Access and Management (IAM)"}, {"url": "https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html", "anchor_text": "Bucket Naming rules"}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html", "anchor_text": "Notebook Instance"}, {"url": "https://aws.amazon.com/sagemaker/pricing/", "anchor_text": "different instances types"}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-resource.html", "anchor_text": "Github repository"}, {"url": "https://www.kaggle.com/uciml/iris", "anchor_text": "Iris dataset"}, {"url": "https://github.com/aws/sagemaker-containers#list-of-provided-environment-variables-by-sagemaker-containers", "anchor_text": "linked"}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-deploy-model.html", "anchor_text": "endpoint"}, {"url": "https://diagrams.mingrammer.com/docs/nodes/aws", "anchor_text": "Diagrams AP"}, {"url": "https://github.com/RamVegiraju/AWSSageMaker-CustomTFModel", "anchor_text": "RamVegiraju/AWSSageMaker-CustomTFModelTraining and deploying a custom Tensorflow 2.0 Model on AWS Sagemaker GitHub is home to over 50 million developers\u2026github.com"}, {"url": "https://www.linkedin.com/in/ram-vegiraju-81272b162/", "anchor_text": "Linkedln"}, {"url": "https://medium.com/tag/aws?source=post_page-----72027722ad76---------------aws-----------------", "anchor_text": "AWS"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----72027722ad76---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----72027722ad76---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----72027722ad76---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----72027722ad76---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F72027722ad76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----72027722ad76---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F72027722ad76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----72027722ad76---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F72027722ad76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----72027722ad76--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F72027722ad76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----72027722ad76---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----72027722ad76--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----72027722ad76--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----72027722ad76--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----72027722ad76--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----72027722ad76--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----72027722ad76--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----72027722ad76--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----72027722ad76--------------------------------", "anchor_text": ""}, {"url": "https://ram-vegiraju.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ram-vegiraju.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ram Vegiraju"}, {"url": "https://ram-vegiraju.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "455 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa5283d2ade1f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-and-deploying-custom-tensorflow-models-with-aws-sagemaker-72027722ad76&newsletterV3=6e49569edd2b&newsletterV3Id=a5283d2ade1f&user=Ram+Vegiraju&userId=6e49569edd2b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}