{"url": "https://towardsdatascience.com/home-value-prediction-2de1c293853c", "time": 1682995639.075131, "path": "towardsdatascience.com/home-value-prediction-2de1c293853c/", "webpage": {"metadata": {"title": "Home Value Prediction. Predicting real estate value using\u2026 | by Nate Jermain | Towards Data Science", "h1": "Home Value Prediction", "description": "How do companies like Zillow offer price estimates for homes that are not for sale? They collect data on the characteristics of each property and use machine learning algorithms to make predictions\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/njermain", "anchor_text": "github.com/njermain", "paragraph_index": 40}], "all_paragraphs": ["How do companies like Zillow offer price estimates for homes that are not for sale? They collect data on the characteristics of each property and use machine learning algorithms to make predictions. In this article, I\u2019ll demonstrate a similar analysis using a data set included in Kaggle\u2019s \u201cHouse Prices\u201d competition.", "First, lets take a look at the response variable \u201cSale Price\u201d. It\u2019s positively skewed; most houses sold for between $100,000 and $250,000, but some sold for substantially more.", "The data set contains 80 features that describe characteristics of the property, including the number of bathrooms, basement square footage, year built, garage square footage, etc. The heat map (Figure 2) shows the correlation among each feature and the response variable \u201cSalePrice\u201d. This gives us information about the feature importance in predicting the Sale Price and indicates where there may be multicolinearity. The overall quality of the home \u201cOverallQual\u201d is highly correlated with Sale Price, not surprisingly. In contrast, the year the home was sold \u201cYrSold\u201d has little correlation with the Sale Price.", "There are lots of NAs in this data set; some features are almost all NAs, while there are many that have just a few.", "We can remove features that offer little information such as Utilities.", "All but one property is assigned the \u201cAllpub\u201d category for Utilities, so we can just remove that feature. Due to the lack of variation, the feature has little correlation with our response Sale Price (Figure 2), so we\u2019re not that worried about losing it.", "Few NAs are random, in that the lack of information usually has something to do with the the record itself, and not simply because of a collection error. For example, NA recorded for GarageType probably means there isn\u2019t a garage on the property. In this data set there are both categorical and continuous features pertaining to garages. We can fill them in accordingly with 0 and \u201cNone\u201d for properties that have NAs for those features, indicating a lack of garage space.", "NAs for other features don\u2019t have a clear explanation associated with the lack of information. In this case, we can observe the frequency of occurrence for each record, and choose the most probable value. Lets look at the frequency distribution for the feature \u201cMSZoning\u201d describing the zoning classification.", "The classification for residential low density (RL) is by far the most common. A pragmatic approach to addressing the four NAs in this feature will be to simply replace NAs with \u201cRL\u201d.", "To maximize the performance of our model, we want to normalize our features and response variable. As we saw in Figure 1, our response variable is positively skewed. By applying a log transformation, Sale Price now resembles a normal distribution (Figure 4).", "We\u2019ll have to check all the continuous features for skew as well.", "Skewness is going to vary a lot between all these features we want to transform. A box cox transformation provides a flexible way of transforming features that may each require an alternate approach. The function boxcox will estimate the optimal lambda value (a parameter in the transformation) and return the transformed feature.", "Finally, we\u2019ll need to one-hot encode (or dummy code) our categorical variables so they can be interpreted by the model.", "We\u2019re going to fit two widely applied machine learning models to the training data and evaluate their relative performance using cross-validation.", "To insure our random forest regressor model has attributes that maximize its predictive capabilities, we\u2019re going to optimize the hyperparameter values. We want to estimate the optimal values for:", "n_estimators: number of trees in the forest", "max_features: maximum number of features to consider at each split", "max_depth: maximum number of splits in any tree", "min_samples_split: minimum number of samples required to split a node", "min_samples_leaf: minimum number of samples required at each leaf node", "bootstrap: whether the data set is bootstrapped or whether the whole data set is used for each tree", "If we used GridSearchCV from sci-kit learn to identify the optimal hyperparameters, we would be evaluating 6,480 candidate models and 32,400 fits with cross-validation of five folds. That would be very computationally expensive, so instead we\u2019ll use RandomizedSearchCV that evaluates a specified number of candidate models (n_iter) with randomly selected hyperparameters from our defined parameter space. We\u2019re going to do k-fold cross-validation using five folds.", "Now we have a model with attributes best suited for our data.", "We want a precise measurement of how the home prices predicted by the model differed from the actual prices of the homes sold. We\u2019ll calculate the root mean squared error (RMSE)for the model through k-fold cross-validation. Given five folds, we\u2019ll use the mean RMSE value of each of the five sets of model fits.", "The random forest model does fairly well, with a mean RMSE of .149.", "Lets try another model to see if we can obtain better predictions.", "We\u2019ll conduct the same evaluation using RandomizedSearchCV to identify the optimal hyperparameters. The gradient boosting regressor we\u2019ll use from \u201cxgboost\u201d has the following hyperparameters we\u2019ll want to optimize:", "subsample: percentage of samples per tree", "max_depth: maximum number of levels in each tree", "min_child_weight: minimum sum of weights of all observations required in a child", "colsample_bytree: percentage of features used per tree", "learning_rate: learning rate or step size shrinkage", "gamma: minimum reduction of the cost function required to make a split", "Using the same approach employed for the random forest model, we\u2019ll run the randomized hyperparameter search using k-fold cross-validation.", "We can now calculate the RMSE for the tuned model and compare xgboost\u2019s performance to the random forest model.", "Our gradient boosting regression model exhibited superior performance to the random forest model with a RMSE value of 0.131.", "I took a pragmatic approach to modeling in this analysis; there are additional modeling techniques that can marginally increase the prediction accuracy such as stacking or applying a suite of alternate models (e.g. Lasso, ElasticNet, KernalRidge).", "We\u2019ll just apply the best model from this analysis (gradient boosting regression) to the test set and evaluate its performance.", "The Gradient Boosting Regression model performed with a RMSE value of 0.1308 on the test set, not bad!", "We can make reasonable predictions about the price a house will sell for based on characteristics of the property. Key steps include assigning appropriate values for NAs, normalizing variables, optimizing hyperparameters for candidate models, and choosing the best model.", "I appreciate any feedback and constructive criticism. The code associated with this analysis can be found on github.com/njermain", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2de1c293853c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2de1c293853c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2de1c293853c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nwjermain?source=post_page-----2de1c293853c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nwjermain?source=post_page-----2de1c293853c--------------------------------", "anchor_text": "Nate Jermain"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc90ac583b8a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&user=Nate+Jermain&userId=c90ac583b8a3&source=post_page-c90ac583b8a3----2de1c293853c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2de1c293853c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2de1c293853c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/njermain", "anchor_text": "github.com/njermain"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2de1c293853c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2de1c293853c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----2de1c293853c---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/random-forest?source=post_page-----2de1c293853c---------------random_forest-----------------", "anchor_text": "Random Forest"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----2de1c293853c---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2de1c293853c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&user=Nate+Jermain&userId=c90ac583b8a3&source=-----2de1c293853c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2de1c293853c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&user=Nate+Jermain&userId=c90ac583b8a3&source=-----2de1c293853c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2de1c293853c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2de1c293853c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2de1c293853c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2de1c293853c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2de1c293853c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2de1c293853c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2de1c293853c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2de1c293853c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2de1c293853c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2de1c293853c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2de1c293853c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2de1c293853c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nwjermain?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nwjermain?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nate Jermain"}, {"url": "https://medium.com/@nwjermain/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "35 Followers"}, {"url": "http://linkedin.com/in/njermain/", "anchor_text": "linkedin.com/in/njermain/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc90ac583b8a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&user=Nate+Jermain&userId=c90ac583b8a3&source=post_page-c90ac583b8a3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fc90ac583b8a3%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhome-value-prediction-2de1c293853c&user=Nate+Jermain&userId=c90ac583b8a3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}