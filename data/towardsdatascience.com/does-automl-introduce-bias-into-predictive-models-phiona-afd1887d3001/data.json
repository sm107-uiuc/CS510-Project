{"url": "https://towardsdatascience.com/does-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001", "time": 1683005184.084519, "path": "towardsdatascience.com/does-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001/", "webpage": {"metadata": {"title": "Does AutoML Introduce Bias into Predictive Models? | by Stephen West | Towards Data Science", "h1": "Does AutoML Introduce Bias into Predictive Models?", "description": "The past few years has seen incredible velocity in data-focused automation capabilities- from robotic process automation, to computer vision, to AutoML. All of these technologies have significantly\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.gartner.com/en/newsroom/press-releases/2019-07-15-gartner-survey-reveals-leading-organizations-expect-t", "anchor_text": "looking to build out machine learning capabilities", "paragraph_index": 3}, {"url": "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=2ahUKEwiJk7Ou-urnAhUFUa0KHYf1AAEQFjACegQIARAB&url=https%3A%2F%2Fwww.nytimes.com%2F2019%2F11%2F10%2Fbusiness%2FApple-credit-card-investigation.html&usg=AOvVaw0Ezv9NZSgG2NofQbCEbVnI", "anchor_text": "hot water", "paragraph_index": 6}, {"url": "https://www.propublica.org/article/minority-neighborhoods-higher-car-insurance-premiums-white-areas-same-risk", "anchor_text": "recent research has shown", "paragraph_index": 6}, {"url": "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&cad=rja&uact=8&ved=2ahUKEwjCg-7f-urnAhVOC6wKHQQdCnQQFjADegQIAxAB&url=https%3A%2F%2Fhbr.org%2F2018%2F08%2Fwhat-data-scientists-really-do-according-to-35-data-scientists&usg=AOvVaw2ut3nKxalzHk0wmhTVD1ZA", "anchor_text": "80% percent of the time", "paragraph_index": 8}, {"url": "https://phiona.com", "anchor_text": "https://phiona.com", "paragraph_index": 18}], "all_paragraphs": ["The past few years has seen incredible velocity in data-focused automation capabilities- from robotic process automation, to computer vision, to AutoML. All of these technologies have significantly increased productivity across multiple industries by reducing the amount of manual effort required for humans to complete tasks. Yet as these technologies improve, humans get further and further away from the actual processes that these solutions intend to replace. Furthering this distance threatens to erode the potential benefit that automation provides; a machine that cannot reason or feel creates unintended consequences by entrenching discriminatory biases within data as well as increasing the number of unexplainable outcomes (the \u201cblack box\u201d effect) it produces. It is incredibly important to build technologies that maintain a \u201chuman in the loop\u201d to ensure that these consequences don\u2019t become pervasive.", "This current trend in automation isn\u2019t just an abstraction problem, where tools put a prettier or easier to use interface on top of what usually would be scripted code. Software has always been evolving over time to simplify the amount of effort required to produce it. Very rarely are developers building their own compilers anymore.", "But today, many software tools move beyond the synergy of front-end and back-end architecture; increasingly, applications require data generated from somewhere (the singular user, the entire userbase, or another system) as the critical component for delivering value within the software application. Algorithms are built to make sense of the millions of data points ingested, and push forward a personal predictive value to ensure the consumer of the information finds it useful. These algorithms are incredibly complex to build, but when done correctly, can be akin to magic when presented to the untrained eye.", "It\u2019s no wonder that so many corporations are looking to build out machine learning capabilities over the next few years. The ability to target individual consumers with personalized value, generated automatically with no human intervention, has the potential to transform the way that companies do business. The stories of companies tripling their revenue by making the right recommendations at the right time, or doctors able to proactively reach out to patients that might have certain clinical risks, seem to be a triumph of technology and a view into the future. Humans are finally able to use mathematics and tools to predict actions in advance at scale, rather than reactively respond one at a time.", "These predictions are only possible because of massive datasets that our applications are generating each second of the day. Algorithms generally become more predictive with more data underlying their logic, and everything from our credit card transaction history, to our medical records, to our smartphone taps and scrolls, can be used to build ever larger datasets to drive these models.", "Undoubtedly, these algorithms\u2019 sophistication can create incredible value for society, if used in the correct way. With the current level of advancement in machine learning techniques, one could argue that the data scientists building these models are able to (mostly) balance the power of prediction with the potential privacy and discrimination implications of using personal data to fuel those predictions.", "Yet multiple examples exist of organizations that don\u2019t consider discriminatory biases. Goldman Sachs was in hot water in 2019 for discriminating against women applying for credit cards, both in the approval process as well as for the amount of credit they received. Insurance companies have been using data to assess risks for decades, and recent research has shown that people who live in primarily minority-populated neighborhoods pay more for car insurance than those who live in white neighborhoods, despite the overall risk levels being the same.", "Both of these examples show the possibility that exists when discrimination is knowingly or unknowingly introduced into datasets that are meant to, ostensibly, provide a dispassionate recommendation for a product or service. The problem with these algorithmic models is twofold- not only are their making discriminatory recommendations, but they\u2019re also the definition of a black box- we humans don\u2019t necessarily understand why they\u2019re making those flawed recommendations in the first place.", "Algorithms, by definition, use the data that they have at their disposal to generate answers. \u201cBetter\u201d answers can be generated with greater breadth of data (ex: transactions information combined with smartphone usage data) or with greater depth of data (ex: twenty years of credit card payment history). \u201cWorse\u201d answers arise when using dirty data, or, as it\u2019s often referred to: garbage in, garbage out. Getting data to a certain level of cleanliness requires a significant amount of work- some estimates have cleaning tasks taking 80% percent of the time working with data.", "Data cleaning work is generally pretty manual in nature- it\u2019s finding the right datasets to use and combine, combing through the rows and the columns to find errors to correct, and writing scripts or Excel formulas to counteract the issues. The amount of skilled human intervention required to do this work consistently well is significant, and the reality is that it\u2019s not a very glamorous job, especially for the specialized workers who do it. But since it\u2019s 80% of data work, someone has to do it.", "This process is where the potential issues with discriminatory bias can seep in- a well-versed data analyst can recognize that building out a dataset for a predictive model that includes a data column for gender, race, or income (or potentially, all three), may result in the algorithm seeing race or gender as the most likely predictor for a high car insurance premium. Humans that are building and cleaning the dataset can understand that that methodology and outcome can create significant societal issues, because they\u2019re the ones that have to live in a world where these discriminatory recommendations create unequal and unfair outcomes.", "So, the human data analyst can choose to omit those columns, reducing the likelihood that the algorithm creates a discriminatory outcome based primarily on demographics. But, will a machine know to omit these columns?", "The market response to the level of complexity required for machine learning work has been to automate it as much as possible. Make it as easy as possible! Drop a dataset in, and we\u2019ll automatically clean it and make it ready for one of the few dozen or so algorithms that may get you the prediction you want! Seems pretty nice- being able to drop data in and get a prediction with, let\u2019s say, a 75% likelihood back.", "But what goes into this process? It\u2019s the classic example of the black box effect leading to an unintended outcome- we have no idea what steps are going on behind the scenes. Is the cleaning process script removing all rows in survey data where a respondent declined to note their race (blank values could potentially skew results)? Is the script removing legitimately high medical test results because the remaining test results were generally lower than average? If you don\u2019t know the answers to these questions, can you trust the result that you receive? If the result of the algorithm is discriminatory, is it sufficient to defend it by saying you don\u2019t know all of the factors that went into the result?", "This AutoML example is the conundrum that we have with excessive automation. Initially, humans are the ones building the datasets and training the algorithms to the point that the automation is a close enough approximation. But when we seek to take out the human-generated steps that underpin the automation, we potentially reach unintended consequences. While many people believe that the danger of automation is in general artificial intelligence creating the next Terminator or some other low likelihood scenario, the danger is probably less bombastic but no less perilous: the data work has been automated to a point where no one even recognizes how the generated recommendations are including biases anymore because we\u2019ve become so dependent on machines doing the thinking for us.", "The focus of machine learning and the more unevenly defined term artificial intelligence has been on replacing human work. Maybe instead it\u2019s better to build solutions that augment, rather than replace, human capabilities within the scope of data work. Computers, as of yet, don\u2019t have the ability to understand the context of certain data types- while there might be a binary understanding of certain information being personally identifiable information (PII) or not, a computer does not recognize why that information is considered PII. A human must make that determination.", "Therefore, it may be advantageous to figure out places within an automation framework where humans can add the most value from their judgment and understanding, even if the work is being performed by the scripts and algorithms. We\u2019re already performing a lot of this \u201chuman in the loop\u201d work, even in the context of machine learning. Human in the loop might look more like autopilot in an airplane than a self-driving car, where there are certain parts of data work that can be categorically determined won\u2019t introduce bias (removing write spaces around text, for example), and others that might, which is where a human would step in.", "The discussion around what is appropriate and how the technology will improve will certainly evolve as we have better and better tools to work with information. In the meantime, it\u2019s important to not completely lurch one way or another haphazardly- we don\u2019t have to manually make changes to each cell in Excel, or hand off our work to AutoML.", "Phiona is an augmented data management platform that empowers non-technical users to make data work less work: our technology flags areas where cleaning and standardization may be required- saving hours of time manually combing through data without sacrificing control over the data preparation process. You can see more at https://phiona.com.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fafd1887d3001&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----afd1887d3001--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----afd1887d3001--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@stephenbwest13?source=post_page-----afd1887d3001--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stephenbwest13?source=post_page-----afd1887d3001--------------------------------", "anchor_text": "Stephen West"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df75aefb29f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&user=Stephen+West&userId=1df75aefb29f&source=post_page-1df75aefb29f----afd1887d3001---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fafd1887d3001&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fafd1887d3001&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@lensinkmitchel", "anchor_text": "@lensinkmitchel,"}, {"url": "https://unsplash.com/photos/Ismnr6WSHCU", "anchor_text": "Unsplash"}, {"url": "https://www.gartner.com/en/newsroom/press-releases/2019-07-15-gartner-survey-reveals-leading-organizations-expect-t", "anchor_text": "looking to build out machine learning capabilities"}, {"url": "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=2ahUKEwiJk7Ou-urnAhUFUa0KHYf1AAEQFjACegQIARAB&url=https%3A%2F%2Fwww.nytimes.com%2F2019%2F11%2F10%2Fbusiness%2FApple-credit-card-investigation.html&usg=AOvVaw0Ezv9NZSgG2NofQbCEbVnI", "anchor_text": "hot water"}, {"url": "https://www.propublica.org/article/minority-neighborhoods-higher-car-insurance-premiums-white-areas-same-risk", "anchor_text": "recent research has shown"}, {"url": "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&cad=rja&uact=8&ved=2ahUKEwjCg-7f-urnAhVOC6wKHQQdCnQQFjADegQIAxAB&url=https%3A%2F%2Fhbr.org%2F2018%2F08%2Fwhat-data-scientists-really-do-according-to-35-data-scientists&usg=AOvVaw2ut3nKxalzHk0wmhTVD1ZA", "anchor_text": "80% percent of the time"}, {"url": "https://phiona.com", "anchor_text": "https://phiona.com"}, {"url": "https://phiona.com/blog/automl-bias", "anchor_text": "https://phiona.com"}, {"url": "https://medium.com/tag/automl?source=post_page-----afd1887d3001---------------automl-----------------", "anchor_text": "Automl"}, {"url": "https://medium.com/tag/bias?source=post_page-----afd1887d3001---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----afd1887d3001---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data?source=post_page-----afd1887d3001---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/data-science?source=post_page-----afd1887d3001---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fafd1887d3001&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&user=Stephen+West&userId=1df75aefb29f&source=-----afd1887d3001---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fafd1887d3001&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&user=Stephen+West&userId=1df75aefb29f&source=-----afd1887d3001---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fafd1887d3001&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----afd1887d3001--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fafd1887d3001&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----afd1887d3001---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----afd1887d3001--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----afd1887d3001--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----afd1887d3001--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----afd1887d3001--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----afd1887d3001--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----afd1887d3001--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----afd1887d3001--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----afd1887d3001--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stephenbwest13?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stephenbwest13?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Stephen West"}, {"url": "https://medium.com/@stephenbwest13/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df75aefb29f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&user=Stephen+West&userId=1df75aefb29f&source=post_page-1df75aefb29f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F1df75aefb29f%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdoes-automl-introduce-bias-into-predictive-models-phiona-afd1887d3001&user=Stephen+West&userId=1df75aefb29f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}