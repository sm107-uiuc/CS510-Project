{"url": "https://towardsdatascience.com/visual-interpretability-for-convolutional-neural-networks-2453856210ce", "time": 1682994389.889622, "path": "towardsdatascience.com/visual-interpretability-for-convolutional-neural-networks-2453856210ce/", "webpage": {"metadata": {"title": "Visual Interpretability for Convolutional Neural Networks | by Himanshu Rawlani | Towards Data Science", "h1": "Visual Interpretability for Convolutional Neural Networks", "description": "Understanding how image classifiers work and what happens when we feed an image into a CNN. We will implement various visualization techniques like Grad-CAM, deconvolutions, heatmaps, etc."}, "outgoing_paragraph_urls": [{"url": "http://gradcam.cloudcv.org/", "anchor_text": "http://gradcam.cloudcv.org/", "paragraph_index": 18}], "all_paragraphs": ["UPDATE: I have covered this blog post in detail, in a talk delivered, at PyData meetup. You can watch the YouTube video below.", "In application programming, we have debugging and error checking statements like print, assert, try-catch, etc. But when it comes to deep neural networks, debugging becomes a bit tricky. Fortunately, Convolutional Neural Networks (ConvNets or CNNs) have inputs (images) which are visually interpretable by humans so we have various techniques for understanding how they work, what do they learn and why they work in a given manner. Whereas for other deep neural network architectures visualizations are even more difficult. Nonetheless, visualizing convnets gives us good intuition about the world of neural networks. In this post, we will go deeper in convnets and understand how image classifiers work and what actually happens when we feed a 224x224x3 image into a convnet.", "Specifically, we will try out various visualization techniques to understand:", "\u201cFor all the progress made, it seems like almost all important questions in AI remain unanswered. Many have not even been properly asked yet.\u201d \u2014 Fran\u00e7ois Chollet", "This post assumes that the reader has a basic understanding of forward propagation in convnets and their architectural components (like convolutions, pooling and activation functions). Throughout the post, we\u2019ll be using VGG16 model for visualizations. The Jupyter notebook for each visualization is written in Keras and is available in my GitHub repository:", "Let\u2019s see how does a VGG16 model look like:", "The output of each convolutional block is passed through an activation function (ReLU in this case).", "In this technique, given an input image, we will simply plot what each filter has extracted (output features) after a convolution operation in each layer. Eg. In VGG16, the input layer dimension is 224x224x3 and the output dimension after the first convolution operation is 224x224x64 (see block1_conv1). Here, 64 is the number of filters which are used to extract input features after 1st convolution operation, so we will just plot these sixty-four 224x224 outputs.", "To elaborate on points 2 and 3, we can compare these insights with how our own visual perception works: When we look at an object (say bicycle) we don\u2019t sit and observe each and every detail of the object (like handle grip, mudguard, wheel spikes, etc.). All we see is an object with two wheels being joined by a metallic rod. Hence, if we were told to draw a bicycle it would be a simple sketch which just conveys the idea of two wheels and a metallic rod. This information is enough for us to decide that the given object is a bicycle.", "Something similar is happening in deep neural networks as well. They act as information distillation pipeline where the input image is being converted to a domain which is visually less interpretable (by removing irrelevant information) but mathematically useful for convnet to make a choice from the output classes in its last layer.", "The visualization we saw above was the output of the convolution operation. A convolution operation in its most basic terms is the correlation between the filters/kernels and the input image. The filter which matches the most with the given input region will produce an output which will be higher in magnitude (compared to the output from other filters). By visualizing filters we get an idea of what pattern each layer has learned to extract from the input.", "We start with some random noise as the input image and pass it through the convnet. We take the output of a given layer whose filters we want to visualize and find the mean of each filter in that layer. This step of finding mean of each filter forms our loss function. Eg. block1_conv1 has input 224x224x3 and output as 224x224x64, hence it has 64 filters. Here, we find mean of each 224x224 filter along x and y-direction and we do this for all the 64 filters. In each step, we take one filter, calculate its mean (i.e. loss) and update our input image such that the output of this filter is maximized. We use gradient ascent to update our input image so as to maximize the loss (response of a specific filter). The resulting input image would be one that the chosen filter is maximally responsive to.", "This visualization of the trained model not only gives insight into its operation but also helps in diagnosing and selecting better architectures. The ZF Net (2013) [1] paper used this technique to visualize first and second layer filters of AlexNet (2012) [2] architecture. They found that the first layer filters were a mix of extremely high and low-frequency information, with little coverage of the mid frequencies (low frequencies in images means pixel values that are changing slowly over space, while high-frequency content means pixel values that are rapidly changing in space). Additionally, the 2nd layer visualization showed aliasing artifacts caused by the large stride used in the 1st layer convolutions.", "They solved these problems by reducing the 1st layer filter size from 11x11 to 7x7 and made the stride of the convolution 2, rather than 4. The new architecture retained much more information in the 1st and 2nd layer features. More importantly, it also improved the classification performance.", "Deconvolutional Network (deconvnet), was proposed by Zeiler et al., 2011 [3]. A deconvnet can be thought of as a convnet model that uses the same components (filtering, pooling) but in reverse, so instead of mapping pixels to features, deconvnets projects the feature activations (convolution outputs) back to the input pixel space.", "To visualize a convnet, a deconvnet is attached to each of its layers, providing a continuous path back to image pixels. To start, an input image is presented to the convnet and features are computed throughout the layers. To examine a given convnet activation, we set all other activations in the layer to zero and pass the feature maps as input to the attached deconvnet layer. Then we successively (i) unpool, (ii) rectify and (iii) filter to reconstruct the activity in the layer beneath that gave rise to the chosen activation. This is then repeated until input pixel space is reached. Refer section 2.1 of ZF Net paper [1] for more details on unpooling, rectification and filtering.", "For a given layer, we take the output of top 4 filters having the highest activation (in magnitude). We use a similar function to calculate the activation magnitude as we did for visualizing filter (loss function). Over there we calculated mean over all the dimensions, but here we calculate the sum along all the dimensions and sort the filters in descending order. Eg. To get top 4 filters activated for a given input image for block1_conv1, we find the sum of the output of all sixty-four 224x224 filters along x and y-direction, sort them in descending order and feed the top 4 outputs to our deconvnet. This gives us 4 different variations of the input image as seen by these filters.", "Projecting the feature activations back to the input space gives us similar insights as to what the filters in those layers were activated upon. We see some of the projections having prominent horizontal edges and some having prominent vertical edges. Some of the projections cover eyes, nose, mouth and some cover entire face. Projecting each of the top activations separately down to pixel space reveals the different structures, in the input image, that excite a given feature map.", "In this technique, we use GradCAM and try to understand which parts of the input image led a convnet to a particular classification decision. The general category of techniques is called \u201cClass Activation Map\u201d (CAM) visualization and consists in producing heatmaps of \u201cclass activation\u201d over input images. A \u201cclass activation\u201d heatmap is a 2D grid of scores associated with a specific output class, computed for every location in an input image, indicating how important each location is with respect to the class considered. This helps us in debugging the decision process of a convolutional neural network. We can also use the same technique to locate specific objects in the image. Check out this demo: http://gradcam.cloudcv.org/", "In GradCAM, we take the output of a convolution layer given an input image and weigh every channel in that output by the gradient of the predicted class. Let\u2019s say we fed the convnet some input image and got \u2018elephant\u2019 as the prediction. The last prediction layer can be considered a function with some input (output of block5_conv3 in this case). So, if f is the prediction layer and x is the output of block5_conv3 then the output of the prediction layer can be given as y where y=f(x). Similarly, we can prove that block5_conv3 is a function g with some input (output of block5_conv2 in this case). Let\u2019s consider output of block5_conv2 as z then x (output of block5_conv3) can be given as x=g(z) and so on\u2026", "Using the above analogy, we can consider the output of the prediction layer having input as all of its previous layers (in a nested manner). We take the partial differentiation of the predicted output w.r.t. each channel in some previous layer (the layer for which we want heatmap visualization) which gives us how important is each channel for the predicted output. We then multiply each channel with their corresponding gradient (importance), to weigh each channel responsible for the predicted output, and calculate channel wise mean to get a heatmap for that layer.", "When we see the heatmaps of different layers we see that different parts of the image are being activated. This is because earlier layers have filters which are looking at various parts of the image. But the class prediction largely depends on the activations of the layers just before prediction and hence, visualizing heatmaps of the layer just before prediction layer (block5_conv3 in this case) tells us which portion of the input image led to a particular prediction."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2453856210ce&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@himanshurawlani?source=post_page-----2453856210ce--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2453856210ce--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Himanshu Rawlani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F52b8b739a77b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&user=Himanshu+Rawlani&userId=52b8b739a77b&source=post_page-52b8b739a77b----2453856210ce---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2453856210ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&user=Himanshu+Rawlani&userId=52b8b739a77b&source=-----2453856210ce---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2453856210ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&source=-----2453856210ce---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@pluyar?utm_source=medium&utm_medium=referral", "anchor_text": "Shane Aldendorff"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/himanshurawlani/convnet-interpretability-keras", "anchor_text": "himanshurawlani/convnet-interpretability-kerasVisualizing VGG16 Convolutional Neural Network using Keras - himanshurawlani/convnet-interpretability-kerasgithub.com"}, {"url": "http://gradcam.cloudcv.org/", "anchor_text": "http://gradcam.cloudcv.org/"}, {"url": "https://www.youtube.com/watch?v=COjUB9Izk6E", "anchor_text": "https://www.youtube.com/watch?v=COjUB9Izk6E"}, {"url": "https://distill.pub/2018/building-blocks/", "anchor_text": "https://distill.pub/2018/building-blocks/"}, {"url": "http://yosinski.com/deepvis", "anchor_text": "http://yosinski.com/deepvis"}, {"url": "http://cs231n.github.io/understanding-cnn/", "anchor_text": "http://cs231n.github.io/understanding-cnn/"}, {"url": "https://cs.stanford.edu/people/karpathy/convnetjs/", "anchor_text": "https://cs.stanford.edu/people/karpathy/convnetjs/"}, {"url": "https://arxiv.org/abs/1311.2901v3", "anchor_text": "https://arxiv.org/abs/1311.2901v3"}, {"url": "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks", "anchor_text": "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks"}, {"url": "https://ieeexplore.ieee.org/document/6126474", "anchor_text": "https://ieeexplore.ieee.org/document/6126474"}, {"url": "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb", "anchor_text": "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb"}, {"url": "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html", "anchor_text": "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"}, {"url": "https://medium.com/tag/visualization?source=post_page-----2453856210ce---------------visualization-----------------", "anchor_text": "Visualization"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----2453856210ce---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----2453856210ce---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2453856210ce---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/keras?source=post_page-----2453856210ce---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2453856210ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&user=Himanshu+Rawlani&userId=52b8b739a77b&source=-----2453856210ce---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2453856210ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&user=Himanshu+Rawlani&userId=52b8b739a77b&source=-----2453856210ce---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2453856210ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=post_page-----2453856210ce--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2453856210ce--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F52b8b739a77b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&user=Himanshu+Rawlani&userId=52b8b739a77b&source=post_page-52b8b739a77b----2453856210ce---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1bc332dbc854&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&newsletterV3=52b8b739a77b&newsletterV3Id=1bc332dbc854&user=Himanshu+Rawlani&userId=52b8b739a77b&source=-----2453856210ce---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Written by Himanshu Rawlani"}, {"url": "https://medium.com/@himanshurawlani/followers?source=post_page-----2453856210ce--------------------------------", "anchor_text": "349 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F52b8b739a77b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&user=Himanshu+Rawlani&userId=52b8b739a77b&source=post_page-52b8b739a77b----2453856210ce---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1bc332dbc854&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-interpretability-for-convolutional-neural-networks-2453856210ce&newsletterV3=52b8b739a77b&newsletterV3Id=1bc332dbc854&user=Himanshu+Rawlani&userId=52b8b739a77b&source=-----2453856210ce---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/implementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b?source=author_recirc-----2453856210ce----0---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=author_recirc-----2453856210ce----0---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=author_recirc-----2453856210ce----0---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Himanshu Rawlani"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2453856210ce----0---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/implementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b?source=author_recirc-----2453856210ce----0---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Implementing a fully convolutional network (FCN) in TensorFlow 2A tutorial on building, training and deploying a small and simple FCN network for image classification in TensorFlow using Keras"}, {"url": "https://towardsdatascience.com/implementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b?source=author_recirc-----2453856210ce----0---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "11 min read\u00b7Jan 1, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c46fb61de3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b&user=Himanshu+Rawlani&userId=52b8b739a77b&source=-----3c46fb61de3b----0-----------------clap_footer----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/implementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b?source=author_recirc-----2453856210ce----0---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c46fb61de3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b&source=-----2453856210ce----0-----------------bookmark_preview----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2453856210ce----1---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2453856210ce----1---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2453856210ce----1---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2453856210ce----1---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2453856210ce----1---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2453856210ce----1---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2453856210ce----1---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----2453856210ce----1-----------------bookmark_preview----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2453856210ce----2---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----2453856210ce----2---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----2453856210ce----2---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2453856210ce----2---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2453856210ce----2---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2453856210ce----2---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2453856210ce----2---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----2453856210ce----2-----------------bookmark_preview----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda?source=author_recirc-----2453856210ce----3---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=author_recirc-----2453856210ce----3---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=author_recirc-----2453856210ce----3---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Himanshu Rawlani"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2453856210ce----3---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda?source=author_recirc-----2453856210ce----3---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "Hyperparameter tuning with Keras and Ray TuneA practical tutorial on choosing the best hyperparameters for your machine learning model using Bayesian optimization."}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda?source=author_recirc-----2453856210ce----3---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": "12 min read\u00b7Sep 11, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1353e6586fda&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda&user=Himanshu+Rawlani&userId=52b8b739a77b&source=-----1353e6586fda----3-----------------clap_footer----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda?source=author_recirc-----2453856210ce----3---------------------2f51b24c_3a6e_464d_a833_3f68cb6e964f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1353e6586fda&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda&source=-----2453856210ce----3-----------------bookmark_preview----2f51b24c_3a6e_464d_a833_3f68cb6e964f-------", "anchor_text": ""}, {"url": "https://medium.com/@himanshurawlani?source=post_page-----2453856210ce--------------------------------", "anchor_text": "See all from Himanshu Rawlani"}, {"url": "https://towardsdatascience.com/?source=post_page-----2453856210ce--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----2453856210ce----0-----------------bookmark_preview----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----1-----------------clap_footer----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----2453856210ce----1-----------------bookmark_preview----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996/what-are-precision-and-recall-terminologies-84f8df304a35?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "vinay"}, {"url": "https://medium.com/@vinaychaudhari1996/what-are-precision-and-recall-terminologies-84f8df304a35?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "What are Precision and Recall terminologies?Precision and recall are two important concepts in the field of machine learning."}, {"url": "https://medium.com/@vinaychaudhari1996/what-are-precision-and-recall-terminologies-84f8df304a35?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "\u00b72 min read\u00b7Dec 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F84f8df304a35&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vinaychaudhari1996%2Fwhat-are-precision-and-recall-terminologies-84f8df304a35&user=vinay&userId=6a7f4791df03&source=-----84f8df304a35----0-----------------clap_footer----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996/what-are-precision-and-recall-terminologies-84f8df304a35?source=read_next_recirc-----2453856210ce----0---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F84f8df304a35&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vinaychaudhari1996%2Fwhat-are-precision-and-recall-terminologies-84f8df304a35&source=-----2453856210ce----0-----------------bookmark_preview----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Conor O'Sullivan"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Augmenting Images for Deep LearningUsing Python to augment data by flipping, adjusting brightness, color jitter and random noise"}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "\u00b712 min read\u00b7Nov 17, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3f1ea92a891c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-images-for-deep-learning-3f1ea92a891c&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=-----3f1ea92a891c----1-----------------clap_footer----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----2453856210ce----1---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f1ea92a891c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-images-for-deep-learning-3f1ea92a891c&source=-----2453856210ce----1-----------------bookmark_preview----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----2453856210ce----2---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----2453856210ce----2---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----2453856210ce----2---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Aaweg-I"}, {"url": "https://medium.com/aaweg-i-nterview?source=read_next_recirc-----2453856210ce----2---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Aaweg Interview"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----2453856210ce----2---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Can you explain Jaccard\u2019s Index? How does it differ from Dice Coefficient?In object detection, there are two distinct tasks to measure:"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----2453856210ce----2---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "\u00b76 min read\u00b7Nov 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faaweg-i-nterview%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&user=Aaweg-I&userId=5a024f90bf10&source=-----861c4a496b2b----2-----------------clap_footer----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----2453856210ce----2---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&source=-----2453856210ce----2-----------------bookmark_preview----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----2453856210ce----3---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----2453856210ce----3---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----2453856210ce----3---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----2453856210ce----3---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----2453856210ce----3---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----2453856210ce----3---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----3-----------------clap_footer----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----2453856210ce----3---------------------494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----2453856210ce----3-----------------bookmark_preview----494a7c9b_7d74_4186_83ee_4ad71f07c7c7-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----2453856210ce--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2453856210ce--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----2453856210ce--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}