{"url": "https://towardsdatascience.com/scraping-from-all-over-wikipedia-4aecadcedf11", "time": 1683010858.347285, "path": "towardsdatascience.com/scraping-from-all-over-wikipedia-4aecadcedf11/", "webpage": {"metadata": {"title": "Scraping from all over Wikipedia. How to automatically scrape from\u2026 | by Kate Christensen | Towards Data Science", "h1": "Scraping from all over Wikipedia", "description": "Last week I wrote about how to scrape data from a table on Wikipedia (here\u2019s the link to get caught up). In the article, I scraped data from a table on this page, which had the contestants\u2019 name\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/using-beautifulsoup-on-wikipedia-dd0c620d5861?source=friends_link&sk=ba9fd2d3ddd3d5dc2fab2433f6848b81", "anchor_text": "here\u2019s the link to get caught up", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/using-beautifulsoup-on-wikipedia-dd0c620d5861?source=friends_link&sk=ba9fd2d3ddd3d5dc2fab2433f6848b81", "anchor_text": "this page", "paragraph_index": 0}], "all_paragraphs": ["Last week I wrote about how to scrape data from a table on Wikipedia (here\u2019s the link to get caught up). In the article, I scraped data from a table on this page, which had the contestants\u2019 name, age, occupation, and where they were from season one of the Great British Bake Off. The end result was the following dictionary:", "As you can see, the contestants\u2019 full names are the keys and the values are a list containing their age and a url snippet containing the url of the wikipedia page about their hometown. Now, I could have easily just gotten the name of the town and called it a day. However, that wouldn\u2019t be helpful if I intend to run a model of some kind on the data I scrape. When you\u2019re gathering data to use for a model, the more actual numerical data you can collect, the better. Therefore, instead of just collecting the name of the place, it would be more useful to collect some statistics about the place, like population or density.", "Of course, that information isn\u2019t directly on the GBBO wiki because that\u2019s not relevant to that specific page, and that\u2019s why they link to the page of the town itself. Therefore, this means if we want to collect that information, we have to go to each page and scrape that information ourselves. You could go through every single town page and manually do that, but that\u2019ll likely get tedious fast. That\u2019s why I worked to develop a script that automatically goes to each page and scrapes that information. This way, the actual execution goes a lot faster and is a lot more efficient.", "To start off, here\u2019s the full function I wrote to scrape town population and density:", "Now we\u2019re going to go back in there and explain what\u2019s actually going on here.", "Line two I have the following dictionary:", "If you see at the end, the second item in the list that is returned is stats_dict. By having that dictionary with empty values, we make sure that in the event something is weird on the page being scraped from, we still get something, and from there we can troubleshoot individual items with issues.", "This ensures that the value being passed through is a string, because if it isn\u2019t, the rest of the function obviously won\u2019t work. Lines 5\u20138 are the following", "These create the full url, request the url, and make the soup that we will use for scraping information.", "The next line is the for loop that all the population and density finding goes under", "This essentially says to look at all of the items tagged \u2018th,\u2019 which is where population and density info is typically put under. Lines 11\u201317 are about finding the density info and lines 19\u201326 are about finding the population info. Here\u2019s an explanation of how I found the density info:", "Lines 11 and 12 are the following:", "This is following the initial for loop looking at all the items tagged \u2018th\u2019, so this says if the text for something tagged as a header is \u2018Density\u2019, meaning look for the header labeled density. The next line is saying if the sibling of the thing labeled density has text, do the following.", "Note: through this process, you\u2019re going to notice there\u2019s a lot of if statements. This is because there are occasionally slight differences in how different pages are formatted. To a page viewer, this doesn\u2019t really diminish their experience a whole lot. However, when you\u2019re working with a script, a slightly different arrangement could mean an error for you. Therefore, you have to do a lot of, \u201cif this thing exists, do this\u201d instead of just telling the function to do something.", "Going back to that last if statement, this first line here is saying, \u201cnow that we know this thing exists, that item is the string with the density info.\u201d The next two lines split up the text into all its individual parts, and then takes the section that has the person per kilometer info, since we want to make sure our units are consistent for the numbers we get. The following two lines actually extract the data (the first line spills over a bit):", "The first line is what actually accesses the number. In short, it uses regex to split the text, if that item can be split, then takes the first item in that list, which is the number itself, then it replaces the comma in the text with nothing, then turns that final number from a string into an integer. The next line goes back to that initially empty dictionary and updates the density entry with that number collected in the previous line.", "And voila, we have our density! Now on to the population, which I found to be a bit more tricky because the formatting varied a touch more than it did with density.", "Like density, we start out looking for item tagged as a header whose text is \u2018Population.\u2019 However, after this, we start to diverge from the path we took to obtain town density. Before we get into the code itself, I want to demonstrate exactly why it may look a little more complicated than you might initially think it should:", "Here is the Wikipedia page for Essex, hometown of Annetha Mills:", "Here we see essentially what we saw with density, the number we\u2019re searching for is in the sibling\u2019s text. However, that\u2019s not how it\u2019s consistently formatted. If we look at Bradford, hometown of Edward \u201cEdd\u201d Kimber:", "The number of the population is in the parent\u2019s sibling text. Therefore our next lines are a bit different:", "Essentially, if the item doesn\u2019t have a sibling, go up to the parent, find the parent\u2019s sibling, then get the text from the parent\u2019s sibling, split it up, and find the number. That number is now the value for the population, or \u2018pop\u2019, entry in the stats_dict. Then the next condition is the following:", "In this case, if the item has a sibling, but that sibling\u2019s text starts with a percent sign, just pass over it because that won\u2019t have the info you\u2019re looking for. Finally, if the item has a sibling, and that sibling\u2019s text does not start with a percent sign we have the following:", "This is not nearly as complicated as before. Basically, take the item\u2019s sibling, get its text (pop_str), split that text, take the first item in the split list (the item that contains the number), take out the comma in the number, then turn that into an integer. That is now assigned as the \u2018pop\u2019 value in the stats_dict. At long last we have our return statement:", "This returns a list where the first item is just the name of the place from the initial url snippet. I keep this name in in the event density or pop come out as a None value. If that does happen, I can go look at the page myself and scrape it manually. The second item in that list is the stats_dict that contains the density and population info.", "Now we that we have a function, it\u2019s time to use it.", "Our final product from my last article, the dictionary shown at the beginning of this one, will be named \u201ccontestant_name_age_town.\u201d", "The first three lines say for each list in the values of the dictionary, the town is the last item in that list, and that list should now be extended using the area_stats function, which will return a list of the place name and stats about that place. Finally, now that we have all the area stats, we can take out the url snippet. All of this turns this dictionary:", "Now we actually have some useful area stats and we didn\u2019t have to individually comb through every single page to find that info!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4aecadcedf11&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@katec125?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@katec125?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "Kate Christensen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F103f2c837773&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&user=Kate+Christensen&userId=103f2c837773&source=post_page-103f2c837773----4aecadcedf11---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4aecadcedf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4aecadcedf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@sharonmccutcheon?utm_source=medium&utm_medium=referral", "anchor_text": "Sharon McCutcheon"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/using-beautifulsoup-on-wikipedia-dd0c620d5861?source=friends_link&sk=ba9fd2d3ddd3d5dc2fab2433f6848b81", "anchor_text": "here\u2019s the link to get caught up"}, {"url": "https://towardsdatascience.com/using-beautifulsoup-on-wikipedia-dd0c620d5861?source=friends_link&sk=ba9fd2d3ddd3d5dc2fab2433f6848b81", "anchor_text": "this page"}, {"url": "https://en.wikipedia.org/wiki/Essex", "anchor_text": "https://en.wikipedia.org/wiki/Essex"}, {"url": "https://en.wikipedia.org/wiki/Bradford", "anchor_text": "https://en.wikipedia.org/wiki/Bradford"}, {"url": "https://medium.com/tag/programming?source=post_page-----4aecadcedf11---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/technology?source=post_page-----4aecadcedf11---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/python?source=post_page-----4aecadcedf11---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4aecadcedf11---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4aecadcedf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&user=Kate+Christensen&userId=103f2c837773&source=-----4aecadcedf11---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4aecadcedf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&user=Kate+Christensen&userId=103f2c837773&source=-----4aecadcedf11---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4aecadcedf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4aecadcedf11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4aecadcedf11---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4aecadcedf11--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4aecadcedf11--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4aecadcedf11--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@katec125?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@katec125?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kate Christensen"}, {"url": "https://medium.com/@katec125/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "129 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F103f2c837773&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&user=Kate+Christensen&userId=103f2c837773&source=post_page-103f2c837773--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7f9729f0c45c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-from-all-over-wikipedia-4aecadcedf11&newsletterV3=103f2c837773&newsletterV3Id=7f9729f0c45c&user=Kate+Christensen&userId=103f2c837773&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}