{"url": "https://towardsdatascience.com/lstms-networks-e9e0dfc0b4f9", "time": 1683018296.327523, "path": "towardsdatascience.com/lstms-networks-e9e0dfc0b4f9/", "webpage": {"metadata": {"title": "LSTMs Networks. Understanding Intuition mathematics | by Namrata Kapoor | Towards Data Science", "h1": "LSTMs Networks", "description": "In my last blog we discussed about shortcomings of RNN which had vanishing gradient problem, which results in not learning longer sequences, responsible for short term memory. LSTMs and GRUs are seen\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/recurrent-neural-network-4129195bcb24", "anchor_text": "blog", "paragraph_index": 0}], "all_paragraphs": ["In my last blog we discussed about shortcomings of RNN which had vanishing gradient problem, which results in not learning longer sequences, responsible for short term memory.", "LSTMs and GRUs are seen as solution to short term memories. Now let\u2019s see the functioning of it to understand it.", "These have a mechanism of gates which manage the flow of information.", "These gates decide which sequence of information to keep or throw away. It is used to store relevant information and forget the information not required.", "Almost all state of art of RNN implementation are achieved by LSTMs or GRUs.", "These models are used in speech recognition, speech synthesis, and text generation and even to make relevant caption for an image or video.", "To understand it, let\u2019s take an example of a movie review:", "\u201cAmazing movie! Movie was full of new surprises, audience had to hold back till the last minute to watch it. There was hardly any boring moment. \u201c", "Only certain keywords from a review can be remembered to judge if the review was good or bad. We don\u2019t need to memorize the whole review for its analysis.", "In above review only words like amazing, surprises would be remembered and rest can be forgotten to make relevant predictions.", "This is similar to what LSTM (Long Short Term Memory) or GRU does, just to keep relevant information and forget about irrelevant or non-scoring information.", "In RNN, the words are fed into each cell as machine readable vectors and also the hidden state from last RNN, both of these are in form of vectors which are combined and fed into a tanh activation function.", "At each step previous hidden state is passed into the memory to keep the historical state.", "Tanh activation function regulates the values in neural network and keeps them in between 1 and -1. It is done so that the values do not explode after so many mathematical transformations in each step.", "Also by use of tanh a lot less computational resources are used if compared to if no tanh is used.", "In LSTM , it passes information sequentially forward with hidden state and words as vectors.", "It also gets an extra input as cell state, which regulates the memory function of them.", "Cell state is maintained from first state to last state so as to keep the long term memory. In its journey cell states are added or removed depending on the gate. Gates are responsible for forgetting or keeping the relevant information, let\u2019s see how gates does that.", "Gates have sigmoid activation function, sigmoid translates the values in between 0 to 1 instead of -1 to 1 which means any vector multiplied with 1 will be same vector, hence remembering information, while when multiplied with zero will be zero which means forgetting information.", "The neural network hence keeps relevant information and forgets unimportant one.", "Let\u2019s discuss now about each gate:", "Function:Forget gate is responsible for forgetting irrelevant information from previous cell state.", "The equation to calculate forget state is as below, Wf being weight assign to this state and bf is bias assigned here.", "2) To update the before cell state we have input gate, in which the combined vectors of input state and hidden state are passed to sigmoid function to see which values to keep and forget.", "The same input is given to tanh function to regularize the values between -1 to 1.", "Now the output from sigmoid functions are multiplied by regularized values of tanh. The values from sigmoid decides which values to keep from tanh function.", "Function: In this step LSTMs what new information we\u2019re going to store in the cell state.", "Input state: Sigmoid function decides which values we\u2019ll update.", "Next candidate state decides on what new values to be added to it.", "The combination of both decides on what will be the next cell state.", "3) Soul of LSTMs lies in Cell State. It is kind of like a conveyor line. It runs straight to other cell with just minor changes like addition or multiplication from resulting vectors. It\u2019s very easy for information to just flow along it. In Cell state first of all previous cell state values are multiplied by forget gate factors.", "Then we do addition of these values to the output values of input gate. This value will be passed to next cell as cell state.", "Function: This equation states how much LSTMs are going to forget from previous cell(ft) state and how much it is updated (it) and added (~Ct) with scaled up new values.", "4) The hidden state for the next cell is calculated as last hidden state and input value vectors are combined together to be given to sigmoid function in output gate.", "The current cell state is passed through tanh function to regularize the values again, these two values are then multiplied to know which values to keep and given to hidden state, which will be taken forward to the next well.", "The calculated cell state and hidden state is then given to the next cell for processing.", "Function: Hidden state will be based on cell state, but will be a filtered for relevant information. It runs through sigmoid layer to decide which part of cell state to be taken, then Cell state is run through tanh to regularize values between -1 to 1 and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.", "The review after applying LSTM will have only important information like:", "\u201cAmazing movie! Movie was full of new surprises, audience had to hold back till the last minute to watch it. There was hardly any boring moment. \u201c", "from above example, which is important information about subject or verb being talked about.", "While LSTMs have an upper hand on simple vanilla RNNs, they do have some disadvantages like:", "a) These are a bit difficult to train.", "b) Very long gradient paths like for 100 words has 100 layer network.", "c) Needs labelled data for the task they do.", "d) Transfer learning doesn\u2019t work well on it.", "e) Can be a bit slow.", "These were resolved by many advance models like attention models or transformers. We will discuss more on this in my next blog.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science Professional | Technical Blogger | Artificial Intelligence | NLP | Chatbots and more"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe9e0dfc0b4f9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://namratakapoor1.medium.com/?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": ""}, {"url": "https://namratakapoor1.medium.com/?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "Namrata Kapoor"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae90d36721ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&user=Namrata+Kapoor&userId=ae90d36721ac&source=post_page-ae90d36721ac----e9e0dfc0b4f9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9e0dfc0b4f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9e0dfc0b4f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/waC5u2V772c?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink", "anchor_text": "Source"}, {"url": "https://towardsdatascience.com/recurrent-neural-network-4129195bcb24", "anchor_text": "blog"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"}, {"url": "https://www.numpyninja.com/post/understanding-lstms", "anchor_text": "https://www.numpyninja.com"}, {"url": "https://medium.com/tag/nlp?source=post_page-----e9e0dfc0b4f9---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e9e0dfc0b4f9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e9e0dfc0b4f9---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e9e0dfc0b4f9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9e0dfc0b4f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&user=Namrata+Kapoor&userId=ae90d36721ac&source=-----e9e0dfc0b4f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9e0dfc0b4f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&user=Namrata+Kapoor&userId=ae90d36721ac&source=-----e9e0dfc0b4f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9e0dfc0b4f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe9e0dfc0b4f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e9e0dfc0b4f9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e9e0dfc0b4f9--------------------------------", "anchor_text": ""}, {"url": "https://namratakapoor1.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://namratakapoor1.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Namrata Kapoor"}, {"url": "https://namratakapoor1.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "211 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae90d36721ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&user=Namrata+Kapoor&userId=ae90d36721ac&source=post_page-ae90d36721ac--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fccc842effc8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstms-networks-e9e0dfc0b4f9&newsletterV3=ae90d36721ac&newsletterV3Id=ccc842effc8c&user=Namrata+Kapoor&userId=ae90d36721ac&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}