{"url": "https://towardsdatascience.com/how-to-extract-online-data-using-python-8d072f522d86", "time": 1682996936.986718, "path": "towardsdatascience.com/how-to-extract-online-data-using-python-8d072f522d86/", "webpage": {"metadata": {"title": "How to extract online data using Python | by Euge Inzaugarat | Towards Data Science", "h1": "How to extract online data using Python", "description": "But the more I read, the more I began to understand that like magic, you need to know what to look for to understand the trick. What is a web scraper anyway? A web scraper is a program that\u2026"}, "outgoing_paragraph_urls": [{"url": "https://devhints.io/xpath", "anchor_text": "syntax works", "paragraph_index": 44}, {"url": "http://www.mainwebsite.com/topic1.", "anchor_text": "www.mainwebsite.com/topic1", "paragraph_index": 73}, {"url": "http://www.mainwebsite.com/topic1.", "anchor_text": ".", "paragraph_index": 73}, {"url": "https://pythontips.com/2013/09/29/the-python-yield-keyword-explained/", "anchor_text": "yield", "paragraph_index": 74}], "all_paragraphs": ["\u201cI would be nice to have all the documents of the website\u201d \u2014 One of her colleagues said", "\u201cYeah, that could give us a lot of information\u201d \u2014 Said another colleague", "\u201cCan you do the scraper?\u201d \u2014 They both turn to look at her", "\u201cEhhhh\u2026 I could\u2026.\u201d \u2014 She started mumbling", "\u201c\u2026.try\u201d \u2014She finished saying but it was too late", "She had never done a scraper in her life. So she was pretty overwhelmed at the moment.", "\u201cI don\u2019t know what to do\u201d \u2014 She called me crying \u2014 \u201cI think that it is too hard for me to do it\u201d", "\u201cYou don\u2019t worry! We can do it together\u201d \u2014 I said", "I understood her completely. The first time I had to code a scraper I felt lost as well.", "It was like I was watching a magic trick. I remember when I start reading about scraping.", "\u201cWeb scrapers\u2026mm\u2026 HTML tags\u2026mm\u2026 spiders\u2026 What\u2026.?\u201d \u2014 It sounded like a foreign language to me", "But the more I read, the more I began to understand that like magic, you need to know what to look for to understand the trick.", "What is a web scraper anyway? A web scraper is a program that automatically gathers data off of websites.", "We can collect all the content of a website or just specific data about a topic or element. This will depend on the parameters we set in our script. This versatility is the beauty of web scrapers.", "Let\u2019s set a hypothetical example. We want to scrape data from a website which URL is https://www.mainwebsite.com. Particularly, this website contains different documents. We are interested in getting their text.", "In the main page, we find three subsections as you can see in the drawing below.", "Clicking topic1, for example, we\u2019ll take us to another page (https://www.mainwebsite.com/topic1) where we can find a list of documents we are interested in.", "If we click on document1, we\u2019ll end up on another page (https://www.mainwebsite.com/topic1/document1/date) where we can obtain the content of that document.", "If we were to do it manually, we would copy and paste the content in a file. Instead, we are going to automate this process.", "We saw the path we need to follow to get our data. Now, we should find a way to tell the web scraper where to look for the information.", "There is a lot of data on the website, such as images, links to other pages, and headers, we are not interested in. As a consequence, we need to be very specific.", "Here is where we start to unravel the magic trick. Let\u2019s dissect it then.", "1HTML stands for Hypertext Markup Language. Along with Cascading Style Sheets (CSS) and Javascript, it is used for structuring and presenting content on interactive websites.", "You don\u2019t need to learn how to code using HTML to build a scraper. But you should know how to identify HTML tags and elements.", "Why? Because the data will have a specific HTML tag. And we can extract this data by just showing the scraper the correct HTML element to look for.", "An HTML tag consists of a tag name enclosed by angular brackets. Frequently, you need an opening and an ending tag that frame a particular piece of text.", "The opening tag consists of a name, followed by optional attributes. The ending tag consists of the same name preceded by a forward slash (/).", "Each tag name refers to a particular element. We would pay attention to the following tags: <p> for paragraphs; <a> or anchor tag for hyperlinks; <img> for images; <h1>, <h2>, etc. for text headers; <div> for dividers, <tr> for table rows, and <td> for table columns.", "Most tags also take id or class attributes. The id specifies a unique id for that HTML tag within the HTML document. The class is used to define which style that tag would take.", "In this case, we want to extract \u201c28th June 2019 Edition\u201d, the content of the HTML element. We would tell the scraper: look for all <h6> elements and give me the one with class \u201ctext-primary\u201d.", "If there is more than one element with these characteristics, we would need to be more specific. Indicating the ID attribute can accomplish this.", "OK. But where do I look for this information on a website?", "This is an easy step: Right-click anywhere on the webpage. A small window will appear. Next, you click Inspect like in the image below.", "You\u2019ll have access to the website source code, the images, the CSS, the fonts and icons it uses, the Javascript code.", "Moreover, you can use the cursor selector (see the images below) to select an item in the website.", "As a consequence, the HTML element corresponding to the selected item will be highlighted.", "In the above diagram, we can observe what a typical HTML structure looks like.", "Normally, all the content is included inside the opening and closing body tags. Every element has its own tags.", "Some HTML elements are nested inside others giving a hierarchy. This can be represented in a tree.", "If we move from left to right in the tree, we move forwards generations. If we move top to bottom, we move between the same generation or between siblings when they come from the same parent element.", "Pay attention to the two <div> elements. They are siblings because they share <body> as a parent. They are the second descendant of html element. Each of them has children. The first <div> has two children. Its first child is a paragraph containing \u201cWeb scraping is useful!\u201d element. However, this element is not a descendant of the second <div>. This is due to the fact that you can not follow a path from this div element to the paragraph element.", "These relationships will help us also when indicating the desired element to the web scraper.", "2XPath stands for XML Path Language. What does it have to do with web scraping? We\u2019ll learn how to identify HTML elements. But the question that arises now is how do I point out the element to the scraper? And the answer is XPath.", "XPath is a special syntax that can be used to navigate through elements and attributes in an XML document. Also, it will help us get a path to a certain HTML element and extract its content.", "Let\u2019s see how this syntax works.", "/ is used to move forward one generation, tag-names gives the direction to which element, [] tell us which of the siblings to choose, // looks for all future generations, @ selects attributes, * is a wildcard indicating we want to ignore tag types.", "If we see the following XPath:", "we would understand that from all (//) the div elements with class \u201cfirst\u201d (div[@class=\"first\"]), we want the second ([2]) paragraph (p) element.", "Fortunately, web browsers have an easy way to get the XPath of an element.", "When you are inspecting the website, right-click in the highlighted element. A small window will be displayed. You can then copy the XPath.", "3Scrapy is a Python framework designed for crawling web sites and extracting structured data. It was specially designed for web scraping but nowadays it can also be used to extract data using APIs.", "In order to install Scrapy, you need to have Python installed. It is advisable to work only with Python 3. Python 2 is going to be deprecated in January 2020.", "To install Scrapy, you can do it using pip:", "One important aspect of Scrapy is that it uses Twisted, a popular event-driven networking framework for Python. Twisted works asynchronously for concurrency.", "What does this mean? Synchronous means that you have to wait for a job to be completed in order to start a new job. Asynchronous means you can move to another job before the previous job has finished.", "4Spiders. Because of this characteristic, Scrapy can crawl a group of URLs in a very short time. Consequently, instead of scraping on a single website, Scrapy works with spiders.", "Spiders are classes we define and Scrapy uses to crawl multiple pages following links and scrape information.", "Spiders must meet certain requirements to work correctly. They must subclass scrapy.Spider, and define the initial requests to make. Also, they can determine how to follow in the pages and how to parse the downloaded page content.", "Let\u2019s see these requirements in detail:", "Now, we have dissected all the components of a web scraper.", "We\u2019ll bring our initial example of the website with URL https://www.mainwebsite.com.", "First, we\u2019ll design our file architecture.", "We\u2019ve created a master folder called scraper where we are going to store all the files related to our scraper.", "Then, we\u2019ll collect all the scraped data in JSON files. Each of those files will be saved in the JSON folder.", "The common folder has another folder called spiders. There, we\u2019ll save one file for each spider. And we\u2019ll create one spider for each topic. So, in total three spiders.", "Now, it\u2019s time to understand the files we\u2019ve created.", "Let\u2019s start with the settings.py. The Scrapy settings allow us to customize the behavior of all Scrapy components, including the core, extensions, pipelines, and spiders themselves.", "There, we can specify The name of the bot implemented by the Scrapy project, a list of modules where Scrapy will look for spiders and whether the HTTP cache will be enabled, among others.", "Now, we arrive at the main two files.", "AWe\u2019ll start by the topic1.py spider. We\u2019ll examine only one example as they are all very similar.", "The first thing that we need to do is import all the needed libraries.", "Obviously, we need to import scrapy. The re module will allow us to extract information using regular expressions. The json module will help us when saving information. The os module is useful to handle directories.", "We stated before that a spider has to inherit from the scrapy.Spider. So we'll create a class called FirstSpider that subclass it. We\u2019ll assign the name topic1. Then, we\u2019ll define the allowed_domains list.", "We also need to create the start_request() method to initialize the requests. Inside the method, we define a list of URL for the requests. In our case, this list only contains the URL www.mainwebsite.com/topic1. Then, we are going to make a request with scrapy.Request.", "We\u2019ll use yield instead of return. We\u2019ll tell scrapy to handle the downloaded content using the parse() method inside the callback argument.", "Until now, you might think that the explanation about HTML and XPath was quite useless. Well, now it\u2019s the moment we\u2019ll need it.", "After we define our method to start the initial request, we need to define the method that will handle our downloaded information.", "So in other words, we need to decide what we want to do with all the data. What information is worth it to save.", "For this, let\u2019s suppose this is the HTML structure of our website.", "As you can see in the picture, the highlighted element is the element we need to get to extract our links.", "Let\u2019s construct our path to get there. From all (//) thediv elements that have the class col-md-12 (div[@class='col-md-12']), we need the attribute href from the a children (a/@href).", "In our parse method, we'll use response.xpath() to indicate the path and extract() to extract the content of every element.", "We are expecting to get a list of links. We want to extract what is shown in those links. The spider will need to follow each of them and parse their content using a second parse method that we\u2019ll call parse_first.", "Notice that this time we are sending the links using follow in the response variable instead of creating a Request.", "Next, the parse_first method has to be defined to tell the spider how to follow the links.", "We are going to extract the title and the body of the document.", "After exploring the HTML structure of one document, we\u2019ll get any element which id is titleDocument, and all paragraphs that are a child of any element which id is BodyDocument.", "Because we don\u2019t care about which tag they have we\u2019ll use the *.", "After getting each paragraph, we are going to append them to a list.", "After that, we\u2019ll join all the paragraphs in the text list together. We\u2019ll extract the date. Finally, we\u2019ll define a dictionary with the date, title and text.", "Lastly, we\u2019ll save the data into a JSON file.", "Here it\u2019s the definition of the function extractdate where we\u2019ll use regular expressions to extract the date.", "BIt\u2019s time to investigate the scraper.py file. Not only we need to create spiders, but also we need to launch them.", "First, we\u2019ll import the required modules from Scrapy. CrawlerProcess will initiate the crawling process and settings will allow us to arrange the settings.", "We\u2019ll also import the three spider class created for each topic.", "After that, we initiate a crawling process", "We tell the process which spiders to use and finally, we\u2019ll start the crawling.", "Perfect! We now have our scraper built!!!", "But wait how do we actually start scraping our website?", "In the terminal, we navigate with command line to our scraper folder (using cd). Once inside, we just launch the spiders with the python3 command you can see in the picture.", "And voil\u00e0! The spiders are crawling the website!", "Here, I listed a couple of very nice resources and courses to learn more about web scraping:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8d072f522d86&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8d072f522d86--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8d072f522d86--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://eugeniainzaugarat.medium.com/?source=post_page-----8d072f522d86--------------------------------", "anchor_text": ""}, {"url": "https://eugeniainzaugarat.medium.com/?source=post_page-----8d072f522d86--------------------------------", "anchor_text": "Euge Inzaugarat"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5515433d5913&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&user=Euge+Inzaugarat&userId=5515433d5913&source=post_page-5515433d5913----8d072f522d86---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d072f522d86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d072f522d86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@aaronburden?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Aaron Burden"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://devhints.io/xpath", "anchor_text": "syntax works"}, {"url": "http://www.mainwebsite.com/topic1.", "anchor_text": "www.mainwebsite.com/topic1"}, {"url": "http://www.mainwebsite.com/topic1.", "anchor_text": "."}, {"url": "https://pythontips.com/2013/09/29/the-python-yield-keyword-explained/", "anchor_text": "yield"}, {"url": "https://www.datacamp.com/courses/web-scraping-with-python", "anchor_text": "DataCamp Course."}, {"url": "https://realpython.com/python-web-scraping-practical-introduction/", "anchor_text": "Web Scraping tutorial"}, {"url": "https://docs.scrapy.org/en/latest/", "anchor_text": "Scrapy documentation"}, {"url": "https://medium.com/actualize-network/modern-html-explained-for-dinosaurs-65e56af2981", "anchor_text": "HTML long"}, {"url": "https://www.freecodecamp.org/news/learn-html-in-5-minutes-ccd378d2ab72/", "anchor_text": "short"}, {"url": "https://medium.com/tag/web-development?source=post_page-----8d072f522d86---------------web_development-----------------", "anchor_text": "Web Development"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8d072f522d86---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----8d072f522d86---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data?source=post_page-----8d072f522d86---------------data-----------------", "anchor_text": "Data"}, {"url": "https://creativecommons.org/licenses/by-sa/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d072f522d86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&user=Euge+Inzaugarat&userId=5515433d5913&source=-----8d072f522d86---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d072f522d86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&user=Euge+Inzaugarat&userId=5515433d5913&source=-----8d072f522d86---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d072f522d86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8d072f522d86--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8d072f522d86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8d072f522d86---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8d072f522d86--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8d072f522d86--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8d072f522d86--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8d072f522d86--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8d072f522d86--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8d072f522d86--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8d072f522d86--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8d072f522d86--------------------------------", "anchor_text": ""}, {"url": "https://eugeniainzaugarat.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://eugeniainzaugarat.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Euge Inzaugarat"}, {"url": "https://eugeniainzaugarat.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "640 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5515433d5913&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&user=Euge+Inzaugarat&userId=5515433d5913&source=post_page-5515433d5913--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1ad8e6e46454&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-online-data-using-python-8d072f522d86&newsletterV3=5515433d5913&newsletterV3Id=1ad8e6e46454&user=Euge+Inzaugarat&userId=5515433d5913&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}