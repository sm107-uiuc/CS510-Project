{"url": "https://towardsdatascience.com/how-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6", "time": 1683007428.1665459, "path": "towardsdatascience.com/how-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6/", "webpage": {"metadata": {"title": "How to use reinforcement learning to play tic-tac-toe | by Rickard Karlsson | Towards Data Science", "h1": "How to use reinforcement learning to play tic-tac-toe", "description": "How to use Q-learning to teach an agent to play the game of tic-tac-toe. A fundamental algorithm within reinforcement learning."}, "outgoing_paragraph_urls": [{"url": "https://github.com/RickardKarl/bill-the-bot", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://twitter.com/RdKarlsson", "anchor_text": "Twitter", "paragraph_index": 16}], "all_paragraphs": ["Q-learning is a brilliant and fundamental method of reinforcement learning that has shown a lot of success recently thanks to the deep learning revolution. Although this tutorial will not explain what is known as deep Q-learning, we will go through the original Q-learning algorithm to teach an agent how to play a game of tic-tac-toe. Despite its simplicity, we will see that it can give excellent results.", "First, we will go through some of the necessary background knowledge to get a quick overview of reinforcement learning, then will we present the Q-learning algorithm and lastly how to implement it to teach an agent to play tic-tac-toe.", "To understand this tutorial it is not necessary to have any previous knowledge about reinforcement learning but it will help to have a basic understanding of calculus and linear algebra. Lastly, I am sharing my own Github repository where I have the things that I explain which you are free to check out, click here if you are interested.", "The goal of reinforcement learning is to optimize an agent\u2019s behaviour according to some reward function when it is operating in an environment of different states. For this tutorial, the environment is the game of tic-tac-toe which has clearly defined actions and the agent has to decide what actions to pick to win the game. Moreover, the agent will get rewards for winning the game which encourages it to learn good strategies in the game.", "A common framework for reinforcement learning is the (finite) Markov Decision Process (MDP). It helps us define a set of actions and states on which the agent\u2019s decision-making is based.", "The transition function gives the probability of moving from a state s to s\u2019 when performing action a. This is necessary when we are in an environment where there is uncertainty about whether an action always produces the desired outcome. However, in the case of tic-tac-toe, we know exactly what each action will do so we will not be using this.", "The MDP framework helps us formalize the problem to identify which actions, depending on the current state, will maximize the agent\u2019s total reward during the game. The reward function R(s,a) will be very simple:", "In reinforcement learning, we find to find an optimal policy that the agent uses to decide which actions to pick. Since we are using Q-learning, we will simply denote our policy as the action a that maximises a function Q(s,a) when the agent is in state s. This is the core of Q-learning, so let\u2019s how we would compute this function.", "The interpretation of Q(s,a) is that Q is the expected reward given at the end of the game if the agent picks action a in state s. Since the agent wants to maximise its reward, it wants to choose the action that maximises Q.", "To compute Q(s,a), the agent has to explore all possible pairs of states and actions while getting feedback from the reward function R(s,a). In the case of tic-tac-toe, we update Q(s,a) iteratively by letting the agent play many games against an opponent. With the Q-learning algorithm, the equation that is used to update Q is the following:", "This equation is based on the well-known equation within reinforcement learning called the Bellman equation. Let\u2019s see how to use this equation to teach our agent.", "To get a trained agent, we need to learn the values of Q(s,a). This will be done by letting two agents play against each other. We will introduce a probability \u03b5 that each agent picks a random action, otherwise, it will pick the best action according to Q(s,a). In this way, we ensure to balance the learning such that the agents sometimes explore new actions and other times exploit the information that the agent already has learnt.", "This training phase can be described by the following pseudocode of the Q-learning algorithm:", "Notice that the number of iterations N must be relatively large, I have been using around 500,000. Also, Q(s,a) can be implemented as a Python dict, or as a two-dimensional array if we represent (s,a) as integers. Lastly, it is possible to vary the probability \u03b5 over time to emphasise more random exploration in earlier iterations which might speed up the learning.", "After you have trained your agent with the algorithm, you may save the values of Q(s,a) and load it when you want to play against the agent. Then, the agent just has to follow the optimal policy by picking actions that maximise Q(s,a). Although the agent does not become very intelligent because of how simple the game of tic-tac-toe is, it is still fun to try this out if you want to learn how to implement Q-learning and see that it works.", "To summarise, this tutorial has first explained the Markov Decision Process (MDP) framework and how it is used in reinforcement learning. We have modelled the game of tic-tac-toe using states, actions and a reward function. On top of that, we defined the function Q(s,a) that quantifies the expected reward by picking action a in state s, and showed the formula to compute Q(s,a) by repeatedly playing the game.", "I hope that you enjoyed this tutorial, if you have any questions then you are welcome to contact me here or through Twitter. And lastly, if you want to see how this works in practice then check out my implementation in my Github repository linked below.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD student at TU Delft. From Sweden. Previous intern at NASA. Interested in climate change and statistics, mixed with AI/ML."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9604130e56f6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9604130e56f6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9604130e56f6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rickard.karlsson?source=post_page-----9604130e56f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickard.karlsson?source=post_page-----9604130e56f6--------------------------------", "anchor_text": "Rickard Karlsson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F161a88e93144&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&user=Rickard+Karlsson&userId=161a88e93144&source=post_page-161a88e93144----9604130e56f6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9604130e56f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9604130e56f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/RickardKarl/bill-the-bot", "anchor_text": "here"}, {"url": "https://twitter.com/RdKarlsson", "anchor_text": "Twitter"}, {"url": "https://github.com/RickardKarl/bill-the-bot", "anchor_text": "https://github.com/RickardKarl/bill-the-bot"}, {"url": "https://medium.com/tag/tic-tac-toe?source=post_page-----9604130e56f6---------------tic_tac_toe-----------------", "anchor_text": "Tic Tac Toe"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----9604130e56f6---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9604130e56f6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/tutorial?source=post_page-----9604130e56f6---------------tutorial-----------------", "anchor_text": "Tutorial"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9604130e56f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&user=Rickard+Karlsson&userId=161a88e93144&source=-----9604130e56f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9604130e56f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&user=Rickard+Karlsson&userId=161a88e93144&source=-----9604130e56f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9604130e56f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9604130e56f6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9604130e56f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9604130e56f6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9604130e56f6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9604130e56f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9604130e56f6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9604130e56f6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9604130e56f6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9604130e56f6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9604130e56f6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9604130e56f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickard.karlsson?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickard.karlsson?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rickard Karlsson"}, {"url": "https://medium.com/@rickard.karlsson/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "10 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F161a88e93144&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&user=Rickard+Karlsson&userId=161a88e93144&source=post_page-161a88e93144--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa770a24d94e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-play-tic-tac-toe-using-reinforcement-learning-9604130e56f6&newsletterV3=161a88e93144&newsletterV3Id=a770a24d94e0&user=Rickard+Karlsson&userId=161a88e93144&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}