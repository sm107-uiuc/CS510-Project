{"url": "https://towardsdatascience.com/daily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96", "time": 1683009824.048152, "path": "towardsdatascience.com/daily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96/", "webpage": {"metadata": {"title": "Daily Inspirational Quotes from Your Favorite Author using Deep Learning | by Chuxin Huang | Towards Data Science", "h1": "Daily Inspirational Quotes from Your Favorite Author using Deep Learning", "description": "I\u2019ve always been a big fan of Japanese literature, and Haruki Murakami comes out on the top of my mind as the most renowned contemporary of Japanese authors. Murakami\u2019s stories often have very vivid\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Haruki_Murakami", "anchor_text": "Haruki Murakami", "paragraph_index": 0}, {"url": "https://www.goodreads.com/search?q=%E6%9D%91%E4%B8%8A%E3%83%A9%E3%83%82%E3%82%AA&qid=", "anchor_text": "Murakami Radio", "paragraph_index": 1}, {"url": "https://medium.com/u/3f15d28c014e?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Paul Tune", "paragraph_index": 4}, {"url": "https://www.newyorker.com/magazine/2013/10/28/samsa-in-love", "anchor_text": "Samsa in Love", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/The_Metamorphosis", "anchor_text": "The Metamorphosis", "paragraph_index": 9}, {"url": "https://lithub.com/haruki-murakami-the-moment-i-became-a-novelist/", "anchor_text": "The Moment I Became a Novelist", "paragraph_index": 10}, {"url": "https://www.goodreads.com/book/show/226973.Hear_the_Wind_Sing", "anchor_text": "Hear the Wind Sing", "paragraph_index": 12}, {"url": "https://www.goodreads.com/book/show/11297.Norwegian_Wood", "anchor_text": "Norwegian Wood", "paragraph_index": 13}, {"url": "https://openai.com/blog/better-language-models/", "anchor_text": "GPT-2", "paragraph_index": 19}, {"url": "https://openai.com/", "anchor_text": "OpenAI", "paragraph_index": 19}, {"url": "https://commoncrawl.org/", "anchor_text": "Common Crawl", "paragraph_index": 19}, {"url": "https://twitter.com/JayAlammar", "anchor_text": "Jay Alammar", "paragraph_index": 26}, {"url": "https://github.com/minimaxir/gpt-2-simple", "anchor_text": "work from Max Woolf", "paragraph_index": 27}, {"url": "https://huggingface.co/", "anchor_text": "Hugging Face", "paragraph_index": 27}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "Transformer", "paragraph_index": 27}, {"url": "https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py", "anchor_text": "script", "paragraph_index": 27}, {"url": "https://twitter.com/radio_murakami", "anchor_text": "here", "paragraph_index": 38}, {"url": "https://open.spotify.com/playlist/7LxqhxqClpyc76C85V7Zs2?si=uPpo5mSPQtmx58XRPu1ZbA", "anchor_text": "playlist", "paragraph_index": 40}, {"url": "https://medium.com/u/3f15d28c014e?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Paul Tune", "paragraph_index": 41}, {"url": "https://twitter.com/ptuls", "anchor_text": "Twitter", "paragraph_index": 41}, {"url": "http://paultune.com", "anchor_text": "website", "paragraph_index": 41}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "link", "paragraph_index": 42}], "all_paragraphs": ["I\u2019ve always been a big fan of Japanese literature, and Haruki Murakami comes out on the top of my mind as the most renowned contemporary of Japanese authors.", "Murakami\u2019s stories often have very vivid and clever descriptions of scenes, despite the mundanity of a daily routine. Not only is this captured in his novels, but also in his short stories and musings, such as those published in his book series Murakami Radio (coincidentally, the origin of our bot\u2019s name).", "For me, it\u2019s that very strong sense of relatability: there is an essence of humanity in the words he chooses to describe his characters and the environments they are in.", "What got me thinking was whether his style could be emulated. As a lot of his work is yet to be translated into English, especially his short essays with great humor, wouldn\u2019t it be nice if we can have a bot that writes like your favorite author from whoever you are inspired from every single day? If Murakami himself could discover his own \u201cstyle of Japanese\u201d by expressing his feelings and thoughts with a limited set of words and grammatical structures, but effectively linking them in a skillful manner, can a machine learn from this pattern and compose simple yet beautiful phrases?", "My friend Paul Tune and I thought it would be a fun project to try to build a Murakami bot using GPT-2 to try to capture his tone and style, all within Twitter\u2019s character limits.", "After presenting an overview of the idea, in the rest of the article, I will detail the development process of Radio Murakami bot, from raw data collection, training using GPT-2, iterations and showcase some deep and relatable tweets by the bot.", "Also, it\u2019s true: the subtitle is generated by our bot!", "Most readers in the Western world are unfamiliar with Haruki Murakami.", "Murakami was born in Kyoto in 1949, during the post-World War II economic boom. He has always loved music, especially jazz, so he opened a jazz bar in Tokyo with his wife. He ran the bar for 7 years.", "As a child, Murakami grew up reading many Western works, from Franz Kafka, Charles Dickens to Kurt Vonnegut. One of his short stories, Samsa in Love is the sequel to the story of Gregor Samsa, the protagonist of Kafka\u2019s The Metamorphosis.", "Murakami\u2019s writing career only began at 29, as he described in the article The Moment I Became a Novelist. In a baseball game between the Yakult Swallows and the Hiroshima Carp on one bright April afternoon in 1978, as he said -", "\u201cThe satisfying crack when the bat met the ball resounded throughout Jingu Stadium. Scattered applause rose around me. In that instant, for no reason and on no grounds whatsoever, the thought suddenly struck me: I think I can write a novel.\u201d", "After the game, he went to Shinjuku to buy writing paper and a fountain pen. A little over six months later, his first novel Hear the Wind Sing was published in 1979.", "Murakami only had a major breakthrough with his work, Norwegian Wood, a reference to the John Lennon song of the same name, in 1988. It was very popular with younger Japanese, and was eventually translated to English for a Western audience.", "Arguably, the most tedious and challenging part of any data science project is the preparation of data. This is no different in this case.", "We almost scoured the entire web for any of the interviews available in English as we want the bot to talk and write with a direct touch from Murakami. The training data we have include:", "There\u2019s a caveat here. All of Murakami\u2019s work is translated by various people from Japanese into English. As a result, the original meaning of sentences in Japanese and subtly in the choice of words may not be fully captured, which arguably is what Japanese language is famous for.", "Fortunately, Murakami\u2019s style is more Westernized compared to his peers, which means that capturing meaning in English might potentially not be as difficult as other Japanese authors.", "The entire dataset collected for training is over 10 MB, and was further cleaned up manually by removing any non-English, non-Murakami related texts from interviews and quotes. There was also a lot of duplication in selected quotes by users on Goodreads, which we had to review and remove. We also have a separate training set of quotes, which we explain below.", "Here we use the GPT-2 model\u00b9 developed by OpenAI, which is a causal (unidirectional) transformer pre-trained on a dataset of 8 million web pages and over 1.5 billion parameters from Common Crawl. GPT-2 is trained with an objective to predict the next words in a sentence, which is very similar to the autocomplete feature on our phones, but in a more sophisticated way.", "The causal direction implies that the model can generate text in a sequential manner by predicting the next word given a word! Perfect for a bot.", "Unlike the autocomplete feature, GPT-2 can handle sentence context which allows it to know the difference of a word when used in a sentence. Take the word fly in the following sentences for instance,", "\u201cThe fly fell into the diner\u2019s soup.\u201d", "\u201cThe invention of the airplane allowed people to fly.\u201d", "In this case, while the word fly is spelt the same, one denotes an insect (noun) while the other denotes an action (verb). By training on whole sentences and paragraphs, GPT-2 learns context, allowing it to differentiate the use of a word like fly in different contexts. This is an example of a homonym, a word which sounds the same but is unrelated in meaning. A word-based model such as Word2Vec\u00b3 cannot capture such context.", "We used the medium size of GPT-2 with 345M parameters to train the Radio Murakami bot. Below is an illustration showing the distinctions among different size of GPT-2 models:", "The heavy-lifting part of the model training has already been done in the pre-trained model itself, and GPT-2 already has a really good grasp of the English language. It takes text inputs as a sequence of tokens, and predicts the next output token in sequence, each having a probability as weights, in this way learning in a self-supervised manner. If you\u2019re interested in finding out more about how the model works, Jay Alammar has a well-illustrated article visualizing the underlying mechanism of GPT-2\u00b2.", "Initially, training involved writing a script that was clobbered with work from Max Woolf but with gradually improved functionality from the Hugging Face\u2019s Transformer package, we used this script for training. The package also has functions that make it easy for sampling from the trained model.", "Training the model was simple: all we had to do was to load the dataset into the model. With about 8 epochs or so, the model was trained and ready to be deployed!", "One of the main challenges was getting the quotes down to Twitter-sized quotes. This turns out to be more difficult than expected. Once our initial model was trained on the novels, it learns how to generate prose from a novel and not a pithy tweet instead, which is what we want.", "Here\u2019s an example output of a novel-trained model:", "\u201cThe sunlight shone down, the smell of flowers filling the air. I could see the gentle curve of the shore, the white sand. The sound of waves, rustling of leaves, the distant cry of cicadas.\u201d", "Whilst this makes for a great descriptive filler in a Murakami novel, it makes for a bad quote generator! We had to generate, review and curate a lot more samples to get what we wanted for the bot using this initial model.", "In order to do better, we curated a set of quotes with tweet-like qualities as our dataset. By training the model on this dataset, the model is able to produce better quality output. Prior to this, the model used to generate excerpts that looks like a sampled prose from a Murakami novel. Now it produces a quote that someone would pick out from the novels. We also experimented by putting in the best generated by a model into the next training of the model, and this seemed to help, though we are aware of the self-reinforcing bias.", "Even so, it is challenging to find quotes that are somewhat profound, and even more challenging to find one that Murakami would be proud of. We still currently act as humans-in-the-loop for curation, but are currently still experimenting with more advanced methods.", "Currently tweets from the Radio Murakami bot are generated from the trained GPT-2 model. We use a seed text as manual input and the completed sentences are then semi-curated by us. Like Murakami, it tweets intriguing descriptions of everyday life and other musings.", "Here are some of our favorites:", "It is also capable of discussing current affairs sometimes, though in a subtle way:", "If you\u2019d like some Murakami goodness delivered to you daily, you can follow the bot here \ud83e\udd16!", "There are a few more things we\u2019d like to look at \u2014", "P.S. I was enjoying this playlist while writing this. Hope you\u2019d enjoy it too \ud83c\udfa7", "This piece was co-authored with Paul Tune. You can follow him on Twitter or checkout his personal website!", "[4] Devlin J., Chang M. W., Lee K., Toutanova K., \u201cBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u201d, 2018. (link)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data @ Canva, prev leveraged finance"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F73534c55ed96&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----73534c55ed96--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@chuxinhuang?source=post_page-----73534c55ed96--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chuxinhuang?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Chuxin Huang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc24e60cd1bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&user=Chuxin+Huang&userId=c24e60cd1bf2&source=post_page-c24e60cd1bf2----73534c55ed96---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F73534c55ed96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F73534c55ed96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://radiomurakami.live/", "anchor_text": "https://radiomurakami.live/"}, {"url": "https://en.wikipedia.org/wiki/Haruki_Murakami", "anchor_text": "Haruki Murakami"}, {"url": "https://www.goodreads.com/search?q=%E6%9D%91%E4%B8%8A%E3%83%A9%E3%83%82%E3%82%AA&qid=", "anchor_text": "Murakami Radio"}, {"url": "https://medium.com/u/3f15d28c014e?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Paul Tune"}, {"url": "https://www.newyorker.com/magazine/2013/10/28/samsa-in-love", "anchor_text": "Samsa in Love"}, {"url": "https://en.wikipedia.org/wiki/The_Metamorphosis", "anchor_text": "The Metamorphosis"}, {"url": "https://lithub.com/haruki-murakami-the-moment-i-became-a-novelist/", "anchor_text": "The Moment I Became a Novelist"}, {"url": "https://www.goodreads.com/book/show/226973.Hear_the_Wind_Sing", "anchor_text": "Hear the Wind Sing"}, {"url": "https://www.goodreads.com/book/show/11297.Norwegian_Wood", "anchor_text": "Norwegian Wood"}, {"url": "https://www.goodreads.com/book/show/10357575-1q84", "anchor_text": "1Q84"}, {"url": "https://www.goodreads.com/book/show/11297.Norwegian_Wood?from_search=true&from_srp=true&qid=33rRMLaJvl&rank=1", "anchor_text": "Norwegian Wood"}, {"url": "https://www.newyorker.com/contributors/haruki-murakami", "anchor_text": "The New Yorker"}, {"url": "https://www.goodreads.com/author/quotes/3354.Haruki_Murakami", "anchor_text": "Goodreads"}, {"url": "https://quotecatalog.com/communicator/haruki-murakami/", "anchor_text": "Quote Catalog"}, {"url": "https://openai.com/blog/better-language-models/", "anchor_text": "GPT-2"}, {"url": "https://openai.com/", "anchor_text": "OpenAI"}, {"url": "https://commoncrawl.org/", "anchor_text": "Common Crawl"}, {"url": "http://jalammar.github.io/illustrated-gpt2/", "anchor_text": "http://jalammar.github.io/illustrated-gpt2/"}, {"url": "https://twitter.com/JayAlammar", "anchor_text": "Jay Alammar"}, {"url": "https://github.com/minimaxir/gpt-2-simple", "anchor_text": "work from Max Woolf"}, {"url": "https://huggingface.co/", "anchor_text": "Hugging Face"}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "Transformer"}, {"url": "https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py", "anchor_text": "script"}, {"url": "https://twitter.com/radio_murakami/status/1223388001100804099", "anchor_text": "https://twitter.com/radio_murakami/status/1223388001100804099"}, {"url": "https://twitter.com/radio_murakami/status/1234984420278325248", "anchor_text": "https://twitter.com/radio_murakami/status/1234984420278325248"}, {"url": "https://twitter.com/radio_murakami/status/1225924725437804544", "anchor_text": "https://twitter.com/radio_murakami/status/1225924725437804544"}, {"url": "https://twitter.com/radio_murakami/status/1228823823916683264", "anchor_text": "https://twitter.com/radio_murakami/status/1228823823916683264"}, {"url": "https://twitter.com/radio_murakami/status/1265077706053554178", "anchor_text": "https://twitter.com/radio_murakami/status/1265077706053554178"}, {"url": "https://twitter.com/radio_murakami/status/1255655622932074503", "anchor_text": "https://twitter.com/radio_murakami/status/1255655622932074503"}, {"url": "https://twitter.com/radio_murakami", "anchor_text": "here"}, {"url": "https://github.com/google-research/bert", "anchor_text": "BERT"}, {"url": "https://radiomurakami.live/", "anchor_text": "here"}, {"url": "https://open.spotify.com/playlist/7LxqhxqClpyc76C85V7Zs2?si=uPpo5mSPQtmx58XRPu1ZbA", "anchor_text": "playlist"}, {"url": "https://medium.com/u/3f15d28c014e?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Paul Tune"}, {"url": "https://twitter.com/ptuls", "anchor_text": "Twitter"}, {"url": "http://paultune.com", "anchor_text": "website"}, {"url": "https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf", "anchor_text": "link"}, {"url": "http://jalammar.github.io/illustrated-gpt2/", "anchor_text": "link"}, {"url": "https://dl.acm.org/doi/pdf/10.1145/3366423.3380281", "anchor_text": "link"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "link"}, {"url": "https://medium.com/tag/data-science?source=post_page-----73534c55ed96---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----73534c55ed96---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----73534c55ed96---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/haruki-murakami?source=post_page-----73534c55ed96---------------haruki_murakami-----------------", "anchor_text": "Haruki Murakami"}, {"url": "https://medium.com/tag/tds-narrated?source=post_page-----73534c55ed96---------------tds_narrated-----------------", "anchor_text": "Tds Narrated"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F73534c55ed96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&user=Chuxin+Huang&userId=c24e60cd1bf2&source=-----73534c55ed96---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F73534c55ed96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&user=Chuxin+Huang&userId=c24e60cd1bf2&source=-----73534c55ed96---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F73534c55ed96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F73534c55ed96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----73534c55ed96---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----73534c55ed96--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----73534c55ed96--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----73534c55ed96--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----73534c55ed96--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----73534c55ed96--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chuxinhuang?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chuxinhuang?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Chuxin Huang"}, {"url": "https://medium.com/@chuxinhuang/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "133 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc24e60cd1bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&user=Chuxin+Huang&userId=c24e60cd1bf2&source=post_page-c24e60cd1bf2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2a80f781b8f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdaily-inspirational-quotes-from-your-favorite-author-using-deep-learning-73534c55ed96&newsletterV3=c24e60cd1bf2&newsletterV3Id=2a80f781b8f5&user=Chuxin+Huang&userId=c24e60cd1bf2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}