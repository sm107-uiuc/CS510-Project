{"url": "https://towardsdatascience.com/stress-free-machine-learning-e4d0a411a56a", "time": 1683016629.038214, "path": "towardsdatascience.com/stress-free-machine-learning-e4d0a411a56a/", "webpage": {"metadata": {"title": "Stress-Free Machine Learning. How to build models quickly without\u2026 | by Ilia Zaitsev | Towards Data Science", "h1": "Stress-Free Machine Learning", "description": "Building machine learning models isn\u2019t easy. Heavy datasets and tricky data formats. A ton of hyper-parameters, models, optimization algorithms. Not talking about generic programming adventures like\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/devforfu/lightning_example", "anchor_text": "the repository", "paragraph_index": 4}, {"url": "https://wandb.ai/devforfu/lightning", "anchor_text": "there", "paragraph_index": 4}, {"url": "https://www.anaconda.com/products/individual", "anchor_text": "Anaconda", "paragraph_index": 5}, {"url": "https://pytorch.org/ecosystem/", "anchor_text": "PyTorch and its ecosystem", "paragraph_index": 11}, {"url": "https://pytorch.org/docs/stable/torchvision/datasets.html", "anchor_text": "already provided", "paragraph_index": 12}, {"url": "https://github.com/PyTorchLightning/pytorch-lightning", "anchor_text": "PyTorch-Lightning library", "paragraph_index": 21}, {"url": "https://github.com/devforfu/lightning_example/blob/master/lightning/experiments/__init__.py#L26", "anchor_text": "BaseExperiment", "paragraph_index": 23}, {"url": "https://github.com/PyTorchLightning/pytorch-lightning-bolts", "anchor_text": "PyTorch Lightning Bolts", "paragraph_index": 23}, {"url": "https://github.com/devforfu/lightning_example", "anchor_text": "the repository", "paragraph_index": 26}, {"url": "https://www.wandb.com/", "anchor_text": "Weights & Biases", "paragraph_index": 31}, {"url": "https://wandb.ai/devforfu/lightning", "anchor_text": "this link", "paragraph_index": 36}, {"url": "https://iliazaitsev.me/", "anchor_text": "my blog", "paragraph_index": 40}], "all_paragraphs": ["Building machine learning models isn\u2019t easy. Heavy datasets and tricky data formats. A ton of hyper-parameters, models, optimization algorithms. Not talking about generic programming adventures like debugging, handling exceptions, and logging.", "It is especially true for the R&D (Research and Development) style of work when models, approaches (and sometimes, even the data itself!) can change very quickly. You wouldn\u2019t like to invest a large amount of time and effort to build something that could become irrelevant very soon. But you also don\u2019t want to turn your project into a pile of Jupyter notebooks and ad hoc scripts, with a ton of files scattered here and there across the file system. All these train_model.py, train_model_adam.ipynb, train_model_adam_v2.py, train_model_final.pth \u2014 I bet you know what I'm talking about. Is there a better way?", "In this post, I would like to share an approach that worked for me pretty well during several quickly evolving projects I\u2019ve worked on recently. It is structured in the following way.", "If these points sound interesting to you, let\u2019s dive deeper! We\u2019ll pick up a couple of image datasets and try to find a model architecture that works best for them all.", "TL;DR: Please access the repository with the code used in this post to run an end-to-end training process using all tips and tricks described here. All generated plots are available there.", "This step is probably the most simple one. When it is needed to create an isolated programming environment, Python\u2019s ecosystem gives you plenty of choices. Usually, for Machine Learning projects, I go with Anaconda. Here you can specify a Python interpreter version, and a list of packages to install.", "Note, that conda has many distribution channels. In case if you\u2019re trying to install a package and the installation command fails, try using -c keys as shown above and include additional channels into the search. In cases when a package isn\u2019t available on any channel, you can always fall back to pip.", "The conda manager supports exporting the environment into a YAML file. It includes the exact versions and distribution channels where the packages are installed from. When the environment ready, you can run the following command to get a snapshot of your setup.", "The egrep command strips your local installation path from the environment definition. Use the following command to re-create your environment.", "Add this file to a repository, and now you can easily re-create your environment on any other machine!", "Of course, there are other ways to set up a Python\u2019s environment, like going with commonly used virtualenv. I personally find conda manager more convenient and robust when dealing with scientific packages. (Though it could be just a matter of habit and personal taste, of course).", "I like to work with PyTorch and its ecosystem a lot, and one of the reasons why is the approach adopted there to access the data. As you may know, the library relies on a very straightforward and easy to implement Dataset interface representing a randomly accessed array. The following snippet shows a trivial way to implement it.", "Though simple, this conception actually provides a developer with great flexibility. The samples could be taken from a folder with files, or fetched from some structured storage, like an HDF5 file, Redis database, or even an S3 bucket. What\u2019s even more convenient, in some cases, you don\u2019t even need to implement this interface yourself: the majority of widely-used image datasets are already provided as a part of the torchvision library.", "Note that torchvision datasets implement data downloading on your behalf. You don\u2019t need to do it \u201cmanually\u201d \u2014 only pass the download=True option to the class\u2019s initializer,", "and it is always a good idea to automate as many aspects of your setup as you can: creating a virtual environment, downloading the data, setting up folders and environment variables.", "So it is a very convenient feature. Imagine that you want to deploy your code on a different machine. If this functionality weren\u2019t implemented, you would need to download the data with wget or curl and put it into a proper location. All these little actions consume time and distract from the actual work on your models. Even if your dataset isn\u2019t implemented, it is easy to do it from scratch as our trivial example above shows.", "Let\u2019s pick the following widely-known datasets:", "Each of them is implemented as a part of the torchvision package. But before we can feed these datasets into a training loop, we should wrap them with DataLoader objects that convert a set of samples into tensor batches. The following snippet shows a convenience function that takes a path to the folder with data and the name of a dataset and makes all required preparations to initialize data loaders. If data is not there, a dataset class will download it.", "Here we use the DATASET_FACTORY dictionary that stores mapping from dataset names to factory classes. Each class uses the same interface so it is easy to implement dispatching.", "Note that the FashionMNIST dataset is slightly different from the first two: its samples are single-channel grayscale images instead of three-channels colored images represented in CIFAR. Therefore, we should take care of this and adapt the samples accordingly. The most simple way is to include an additional transformation that duplicates channels three times. (See the next section showing how it's done).", "That\u2019s it! Now we\u2019re ready to start experimenting.", "The datasets are ready. Now we should set up a training loop. We use the PyTorch-Lightning library for this purpose. It ships many neat training features right out of the box including model snapshots, early stopping, metrics logging, and many more! So sounds like a great solution to get rid of some boilerplate code.", "In order to use this library, we only need to inherit from its LightningModule base class and define some callback methods. I\u2019ll not describe these steps in detail here as soon as mastering PyTorch-Lightning is itself a topic for a series of posts. The only thing I would like to highlight is that from my experience, it seems to be a good idea to write a simple base class that implements the required hooks and use it as your base instead of LightningModule. Then you can implement your experiments in a very straightforward way, as the following example shows.", "Here the BaseExperiment class inherits from LightningModule and does some basic logic common for all our experiments. (Check out PyTorch Lightning Bolts repository to see how this idea is implemented for more realistic scenarios). The module creates a very simplistic model as a baseline for our experiments.", "What is also important, the library exposes its parameters via CLI. So we can easily tune our training process. Usually, I try to expose everything as a CLI option to simplify automation. A drawback of this approach is that the argument\u2019s parser becomes very large. To tackle this challenge a bit, we can split it up into smaller groups as the snippet below shows.", "See how create_default_parser function combines several CLI groups together, including the Trainer parameters as well. Then we can run a training process and override any training parameter, including scheduler, optimizer, the number of training epochs, early stopping criterion, etc.", "Now we can easily launch an experiment using a shell command similar to the one shown below. (See the repository for the full-featured end-to-end example that uses a bit more involved training script and one more experiment class using pre-trained ResNet models).", "Ok, the training process is set up. We have our experimenting code and can easily add new architectures and datasets! It is time to take the final crucial step: organize logging that would help us to track the model\u2019s quality, and also to keep in a single place all its configurations.", "Everyone who works with data modeling knows how fragile things could be. One parameter change here, another option or feature switched off there \u2014 and a promising model turns into something mediocre and unreliable.", "Machine Learning pipelines can be very sensitive to even a minor change in the parameters. So it makes sense to log every small piece of information.", "Tracking parameters in a notepad or Excel sheet works for some cases, but this approach is fragile. (Probably as fragile as storing your code\u2019s backups in archives instead of proper version control\u2026). Storing the tracked metrics as CSV or JSON files works but requires additional effort to analyze them after training is done. So there should be a better way, right?", "Fortunately, the field of Data Science and Machine Learning is mature enough to equip us with a set of convenient tools making the situation much better. The Weights & Biases platform is one of them. It helps in tracking the performance metrics computed during the experiment and stores them in the cloud. It also allows you to store configurations, CLI arguments, and actually any other information you provide.", "The following image is static but plots rendered on W&B are interactive and updated in real-time as the training process goes on. Also, the platform supports several plotting primitives, not only line plots!", "Again, in addition to the training metrics, W&B stores information about your experiment\u2019s configuration as the following picture shows. So you have all the information at hand. (Even such technical details like OS version or path to the interpreter\u2019s executable).", "Moreover, you can easily compare metrics generated during different experiment runs showing them on the same canvas. It makes the process of comparing different experiments and models with each other almost effortless.", "And to top it off, the platform provides basic reporting functionality, so we can easily convert our metrics plots into a dashboard describing the behavior of our models.", "Follow this link and try out the interactive plots and reports yourself!", "Writing the ML code fast doesn\u2019t mean to write it ugly. Making it clearer and better structured will save you time and make your experiments reliable, easy to modify, and reproduce.", "Sure enough, there are many other nice tools and practices that I didn\u2019t mention in the post: (1) training loop libraries like ignite, catalyst, or fastai; (2) ML experiments tracking systems like mlflow ; (3) good old tensorboard logging that allows for tracking metrics and experiment parameters similarly to how it is done with wandb. Also, we didn\u2019t cover DevOps topics here. Nevertheless, I hope the post was helpful to you and gave some new insights.", "And what is about your approach? Feel free to share your thoughts and best practices in the commentaries to this post!", "Are you interested in Python programming? Can\u2019t live without Machine Learning? Have read everything else on the Internet? Check out my blog where I share various technical topics and thoughts!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Developer & AI Enthusiast. Working with Machine Learning, Data Science, and Data Analytics. Writing posts every once in a while."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe4d0a411a56a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@iliazaitsev?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@iliazaitsev?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "Ilia Zaitsev"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59449609fea0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&user=Ilia+Zaitsev&userId=59449609fea0&source=post_page-59449609fea0----e4d0a411a56a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4d0a411a56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4d0a411a56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/devforfu/lightning_example", "anchor_text": "the repository"}, {"url": "https://wandb.ai/devforfu/lightning", "anchor_text": "there"}, {"url": "https://unsplash.com/@madhumadhavan?utm_source=medium&utm_medium=referral", "anchor_text": "Madhu Madhavan"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.anaconda.com/products/individual", "anchor_text": "Anaconda"}, {"url": "https://pytorch.org/ecosystem/", "anchor_text": "PyTorch and its ecosystem"}, {"url": "https://pytorch.org/docs/stable/torchvision/datasets.html", "anchor_text": "already provided"}, {"url": "https://github.com/PyTorchLightning/pytorch-lightning", "anchor_text": "PyTorch-Lightning library"}, {"url": "https://github.com/devforfu/lightning_example/blob/master/lightning/experiments/__init__.py#L26", "anchor_text": "BaseExperiment"}, {"url": "https://github.com/PyTorchLightning/pytorch-lightning-bolts", "anchor_text": "PyTorch Lightning Bolts"}, {"url": "https://github.com/devforfu/lightning_example", "anchor_text": "the repository"}, {"url": "https://www.wandb.com/", "anchor_text": "Weights & Biases"}, {"url": "https://wandb.ai/devforfu/lightning", "anchor_text": "this link"}, {"url": "https://wandb.ai/devforfu/lightning", "anchor_text": "devforfu/lightningWeights & Biases projectwandb.ai"}, {"url": "https://iliazaitsev.me/", "anchor_text": "my blog"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e4d0a411a56a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----e4d0a411a56a---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e4d0a411a56a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----e4d0a411a56a---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/best-practices?source=post_page-----e4d0a411a56a---------------best_practices-----------------", "anchor_text": "Best Practices"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe4d0a411a56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&user=Ilia+Zaitsev&userId=59449609fea0&source=-----e4d0a411a56a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe4d0a411a56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&user=Ilia+Zaitsev&userId=59449609fea0&source=-----e4d0a411a56a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4d0a411a56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe4d0a411a56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e4d0a411a56a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e4d0a411a56a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@iliazaitsev?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@iliazaitsev?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ilia Zaitsev"}, {"url": "https://medium.com/@iliazaitsev/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "401 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59449609fea0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&user=Ilia+Zaitsev&userId=59449609fea0&source=post_page-59449609fea0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1fca54e4aa9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstress-free-machine-learning-e4d0a411a56a&newsletterV3=59449609fea0&newsletterV3Id=b1fca54e4aa9&user=Ilia+Zaitsev&userId=59449609fea0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}