{"url": "https://towardsdatascience.com/improving-deep-neural-networks-d5d096065276", "time": 1683011205.25771, "path": "towardsdatascience.com/improving-deep-neural-networks-d5d096065276/", "webpage": {"metadata": {"title": "Improving Deep Neural Networks. Andrew Ng\u2019s advice for Hyperparameter\u2026 | by Ahilan Srivishnumohan | Towards Data Science", "h1": "Improving Deep Neural Networks", "description": "I have recently been going through Coursera\u2019s Deep Learning Specialisation course, designed and taught by Andrew Ng. The second sub-course is Improving Deep Neural Networks: Hyperparameter Tuning\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["I have recently been going through Coursera\u2019s Deep Learning Specialisation course, designed and taught by Andrew Ng. The second sub-course is Improving Deep Neural Networks: Hyperparameter Tuning, Regularisation, and Optimisation. Before I started this sub-course I had already done all of those steps for traditional machine learning algorithms in my previous projects. I\u2019ve tuned hyperparameters for decision trees such as max_depth and min_samples_leaf, and for SVMs tuned C, kernel, and gamma. For regularisation I have applied Ridge (L2 penalty), Lasso (L1 penalty), and ElasticNet (L1 and L2) to regression models. So I thought it would not be much more than translating those concepts over to neural networks. Well, I was somewhat right, but given how Andrew Ng explains the mathematics and visually represents the inner-workings of these optimisation methods, I have a much greater understanding from a fundamental level.", "In this article I want to go over some of Andrew\u2019s explanations for these techniques, accompanied with some mathematics and diagrams.", "Here are a few popular hyperparameters that are tuned for deep networks:", "There are others specific to optimisation techniques, for instance, you have \u03b21, \u03b22, and \u03b5 for the Adam optimisation.", "Let\u2019s say for a model we have more than one hyperparameter we are tuning, one hyperparameter probably will have more of an influence on train/validation accuracy than another hyperparameter. In this case, we may want to try a wider variety of values for the more impactful hyperparameter, but also at the same time, we don\u2019t want to run too many models as it is time consuming.", "For this example let us say we are optimising two different hyperparameters, \u03b1 and \u03b5. We know \u03b1 is more important and needs to be tuned by trying out as many different values as possible. Then again you still want to try 5 different \u03b5 values as well. So, if I choose to try 5 different \u03b1 values, that comes to 25 different models. We have run 25 models with different combinations of 5 \u03b1 and 5 \u03b5.", "But we want to try more \u03b1 values without increasing the number of models. Here is Andrew\u2019s solution:", "For this, we use a random search, where we choose 25 different random values of each \u03b1 and \u03b5, and each pair of values is used for each model. Now we have to only run 25 models but we get to try 25 different values of \u03b1 instead of the 5 we did in a grid search.", "Bonus: Using a coarse to fine can help further to improve tuning. This involves zooming into a smaller region of the hyperparameters which performed best and then creating more models within that region to more precisely tune those hyperparameters.", "When trying out different hyperparameter values, choosing the correct scale can be difficult, especially trying to make sure you thoroughly search within a range of really large numbers and a range of really small numbers.", "Learning rate is a hyperparameter that can vary so much based on the model, it can between 0.000001 and 0.000002, or between 0.8 and 0.9. It is very hard to search fairly between these two different ranges at once when looking at a linear scale, but we can solve this issue with using the log scale.", "Here is a little bit of mathematics with a numpy function to demonstrate how this works for a random value for \u03b1.", "Overfitting can be a huge problem with models due to high variance, this can be solved by getting more training data, but that\u2019s not always possible, so a great alternative is regularisation.", "Regularisation utilises one of two penalty techniques, L1 and L2, with neural networks L2 is predominantly used.", "We must first look at the cost function for a neural network:", "And then add the L2 penalty term, which includes the Frobenius Norm:", "With L2 regularisation the weight reduces not only by the learning rate and backpropagation but also by the middle term which includes the regularisation hyperparameter \u03bb (lambda). The larger \u03bb is the smaller w becomes.", "We see that L2 regularisation uses the \u03bb penalty to reduce the weights w, but how does this reduce variance and prevent overfitting of the model?", "If w is small the size of z will drop too, if z is a large positive number it will become smaller, if it is a large negative number it will become larger, nearing to 0. When passing z through the activation function we have a more linear effect (as you can see the image below, the tanh curve is more linear near 0).", "Here g(z) is roughly linear for the tanh activation function. Decision boundaries of a \u2018line of best fit\u2019 would be less complex and closer to linear, this will iron out the overfitting in the training data.", "This was a small part of Andrew Ng\u2019s Deep Learning Specialisation course which I found very useful and wanted to write about, but the course offers a lot more. I would highly recommend going through the course if you are interested in learning deep neural networks, and want to understand everything from a fundamental level with thorough mathematical justification for all the processes, with coding exercises.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am an ex-software engineer with a passion for all things AI."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd5d096065276&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d5d096065276--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d5d096065276--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@candyahs?source=post_page-----d5d096065276--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@candyahs?source=post_page-----d5d096065276--------------------------------", "anchor_text": "Ahilan Srivishnumohan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea67e9d4a942&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&user=Ahilan+Srivishnumohan&userId=ea67e9d4a942&source=post_page-ea67e9d4a942----d5d096065276---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd5d096065276&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd5d096065276&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@pawelkadysz", "anchor_text": "Pawel Kadysz"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d5d096065276---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/andrew-ng?source=post_page-----d5d096065276---------------andrew_ng-----------------", "anchor_text": "Andrew Ng"}, {"url": "https://medium.com/tag/hyperparameter-tuning?source=post_page-----d5d096065276---------------hyperparameter_tuning-----------------", "anchor_text": "Hyperparameter Tuning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----d5d096065276---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/coursera?source=post_page-----d5d096065276---------------coursera-----------------", "anchor_text": "Coursera"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd5d096065276&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&user=Ahilan+Srivishnumohan&userId=ea67e9d4a942&source=-----d5d096065276---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd5d096065276&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&user=Ahilan+Srivishnumohan&userId=ea67e9d4a942&source=-----d5d096065276---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd5d096065276&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d5d096065276--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd5d096065276&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d5d096065276---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d5d096065276--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d5d096065276--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d5d096065276--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d5d096065276--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d5d096065276--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d5d096065276--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d5d096065276--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d5d096065276--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@candyahs?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@candyahs?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ahilan Srivishnumohan"}, {"url": "https://medium.com/@candyahs/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "79 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea67e9d4a942&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&user=Ahilan+Srivishnumohan&userId=ea67e9d4a942&source=post_page-ea67e9d4a942--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fea67e9d4a942%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-deep-neural-networks-d5d096065276&user=Ahilan+Srivishnumohan&userId=ea67e9d4a942&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}