{"url": "https://towardsdatascience.com/how-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631", "time": 1683004039.732697, "path": "towardsdatascience.com/how-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631/", "webpage": {"metadata": {"title": "How to deploy Apache Airflow with Celery on AWS | by Axel Furlan | Towards Data Science", "h1": "How to deploy Apache Airflow with Celery on AWS", "description": "Disclaimer: this post assumes basic knowledge of Airflow, AWS ECS, VPC (security groups, etc) and Docker. I suggest an architecture that may not be perfect nor the best in your particular case. In\u2026"}, "outgoing_paragraph_urls": [{"url": "https://aws.amazon.com/fargate/", "anchor_text": "AWS Fargate", "paragraph_index": 9}, {"url": "https://www.zdnet.com/article/stop-saying-the-cloud-is-just-someone-elses-computer-because-its-not/", "anchor_text": "cool post", "paragraph_index": 10}, {"url": "https://www.zdnet.com/meet-the-team/uk/mary-branscombe/", "anchor_text": "Mary Branscombe", "paragraph_index": 11}, {"url": "https://aws.amazon.com/es/autoscaling/", "anchor_text": "auto-scaling", "paragraph_index": 12}, {"url": "https://aws.amazon.com/rds/", "anchor_text": "RDS", "paragraph_index": 13}, {"url": "https://hub.docker.com/r/puckel/docker-airflow", "anchor_text": "Puckel\u2019s Airflow", "paragraph_index": 14}, {"url": "https://github.com/puckel/docker-airflow/blob/master/docker-compose-CeleryExecutor.yml", "anchor_text": "Puckel\u2019s docker-compose celery YAML file", "paragraph_index": 19}, {"url": "https://en.wikipedia.org/wiki/Don%27t_repeat_yourself", "anchor_text": "DRY", "paragraph_index": 23}, {"url": "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html", "anchor_text": "this", "paragraph_index": 24}, {"url": "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html", "anchor_text": "here", "paragraph_index": 38}, {"url": "https://docs.aws.amazon.com/AmazonECS/latest/userguide/specifying-sensitive-data.html", "anchor_text": "here", "paragraph_index": 40}, {"url": "https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html", "anchor_text": "AWS Documentation", "paragraph_index": 47}, {"url": "https://www.linkedin.com/in/axelfurlan/", "anchor_text": "https://www.linkedin.com/in/axelfurlan/", "paragraph_index": 62}], "all_paragraphs": ["Disclaimer: this post assumes basic knowledge of Airflow, AWS ECS, VPC (security groups, etc) and Docker. I suggest an architecture that may not be perfect nor the best in your particular case. In that case, make what you want from this lecture.", "Where I work, we use Apache Airflow extensively. We have approximately 15 DAGs, that may not seem like a lot, but some of them have many steps (tasks) that involve downloading big SQL backups, transforming some values using Python and re-uploading them into our warehouse.", "At first, we started using the Sequential Executor (no parallelism, just 1 task running at a time) due to the easy setup and lack of many DAGs. As time went on, DAGs kept increasing and some of them presented the opportunity to make use of parallelism, so with some configurations, we started using the Local Executor.", "You may ask\u2026Why the whole thing doesn\u2019t cut it anymore?", "Well, both cases had only 1 container deployed in AWS ECS doing everything: serving the web UI, scheduling the jobs and worker processes executing them. This wasn\u2019t scalable, the only option we had was scaling vertically (you know, adding more vCPU, more RAM and such). There was not another option.", "Furthermore, if something in the container fails, the whole thing fails (no high availability). Also, the whole service must be public for the webserver to be accessible through the internet. If you want to make certain components private (such as the scheduler and workers) this is NOT possible here.", "There isn\u2019t any guide talking about how to deploy Airflow in AWS, or making use of their extensive offer of services. It\u2019s easy to deploy the whole thing locally using docker-compose or in an EC2, but is it really what you want? What about completely isolated nodes talking to each other inside the same VPC? Making private what needs to be private and public what needs to be public?", "This whole diagram might be complicated at a first glance, and maybe even frightening but don\u2019t worry. What you have to understand from this is probably just the following:", "Principally, AWS ECS and Fargate are the stars in this.", "Amazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service [\u2026] You can choose to run your ECS clusters using AWS Fargate, which is serverless compute for containers. Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design.", "A nice analogy about serverless computing is this one I read in this cool post:", "Serverless computing is like driverless cars; there\u2019s still a driver, just not one you can see. You don\u2019t need to ask if the driver is hungry, tired, drunk or needs to stop for a bathroom break. If we ever let driverless cars drive on our roads it will be because we don\u2019t have to care about the driver, just the fact that they will take us where we want to go \u2014 Mary Branscombe", "I like to say that ECS is just a chill Kubernetes, without much to configure it\u2019s ready to deploy your apps using just the Docker image and some extra settings\u2013such as how much CPU or RAM you want your app to be able to use, if you want auto-scaling, use a Load Balancer out of the box and what-not.", "We should also set up a metadata database, for that we\u2019re going to use the convenient RDS.", "Before anything else, we have to set which Docker image we\u2019re gonna use and set it as a base image to build on top of it. For this, I\u2019ve used Puckel\u2019s Airflow. This docker image gives you all you need to set up Airflow in any of the 3 main executors. With over 5 million downloads, it\u2019s safe to say that this guy has done a great job.", "Let\u2019s create our custom Dockerfile. I\u2019ve used the following:", "I added a personal airflow.cfg (which has configurations for s3 logging and SMTP server credentials), a custom entrypoint.sh and a dags folder that has all my DAGs. In this case, . is already defined in the base image to be /usr/local/airflow using the instruction WORKDIR.", "I got rid of some lines in the base image\u2019s entrypoint that were conditions serving the different executors and just made it for Celery only, also getting rid of an annoying wait_for_port function that somehow didn\u2019t work.", "What this whole thing does is first, sets up useful environment variables and then, depending on the command given in docker run, follows a switch that executes different portions of code. Let\u2019s say, if you\u2019re launching a worker, it\u2019s going to install your Python requirements and then execute the worker process. If it\u2019s the webserver, it\u2019ll install requirements as well but also it\u2019s going to initialize the database with airflow initdb command and then open the webserver for Airflow\u2019s UI.", "If you want to test the whole thing and make sure everything works, you can do so with Puckel\u2019s docker-compose celery YAML file.", "After a while, you should be able to access localhost:8080 and see Airflow\u2019s dashboard. You might as well access localhost:5555 and see Flower as well. From this point, run some example DAGs\u2013or even yours\u2013and see for yourself how things are processed from a trigger in the webserver, the scheduler grabbing the task and sending it to queue, and finally, a worker picking it up and running it.", "For this tutorial, we\u2019re going to keep it simple and use AWS ECR. ECR is just a Docker image repository.", "ECR is integrated with ECS out of the box.", "To create a repository, hop into the ECR console and click on Create repository and choose whatever name you feel adequate. Tip: you can have a repository for your staging Airflow and one for production. Remember, all Airflow processes are going to use the same image to avoid redundancy and be DRY.", "Now enter your new fresh repository and click on View push commands. That\u2019ll walk you through pushing your Airflow image to the repo. If an error comes up during the first step, like unable to locate credentials you probably haven\u2019t set your awscli credentials, look at this.", "Once you pushed the image and see it in the ECR console, you\u2019re ready for the next step!", "Let\u2019s start by creating an ECS Cluster, go to Services and choose ECS.", "Probably as this is your first time, you\u2019re gonna see a screen presenting the service to you and an easy first cluster button. What you need to do here is just create a Network Only cluster.", "At this point, you will probably have a window that looks like this. This right here is a matter of choice to you, whether you use the same VPC as the rest of your instances or create another one specifically for this cluster\u2013I did the latter. If you choose to do that, I think just 1 subnet will be sufficient.", "We\u2019re going to set up a PostgreSQL 9.6 micro instance database. If you\u2019re familiar with how to do this, feel free to do it and skip to the next step.", "Go to Services -> RDS. Go to databases section and Create database. Select the PostgreSQL logo, go for Version 9.6.X, whatever minor version is fine. Now, I\u2019m still deliberating on if I\u2019m super cheap or the airflow metadata database doesn\u2019t really need to be THAT robust, so I opted for a free tier micro instance. If you find that that isn\u2019t enough for you, it\u2019s easy to upgrade later so don\u2019t worry.", "Next configurations are up to you, whatever instance name, username, password, just make sure it\u2019s going to be created in the same cluster that ECS uses.", "Great, we have our empty cluster now. Let\u2019s create our task definitions.", "Task definitions are like blueprints, they define how your service is going to be executed\u2013which container is it going to use, how much CPU and RAM is assigned to it, which ports are mapped, what environment variables does it have, etc.", "Go to Task Definitions at the left panel and click in Create new Task Definition.", "Remember, we want Fargate, so select it and hit Next step.", "From now on, we\u2019ll have to create a task definition for the webserver, the scheduler, and the workers.", "I\u2019ll walk you through all the necessary configurations you must provide for every task to work correctly.", "Task Definition Name: identifier name. Choose something descriptive like airflow-webserver, airflow-worker, etc.Task Role: the IAM role the task is going to be injected in the container. Choose one that has permissions for what your task must do\u2013extract secrets from secrets manager, log with awslogs log driver, query buckets from S3. If you\u2019re not sure, just use the basic ecsTaskExecutionRole , if it\u2019s not present in the dropdown check here.Network Mode: awsvpc since we\u2019re using Fargate.Task execution role: the role that\u2019s going to be able to pull the image from AWS ECR and log in Cloudwatch. ecsTaskExecutionRole has both these policies.Task size: almost completely depends on you. Most of your resources will on the workers, hence they\u2019re gonna do all the dirty work. Just to offer a guide, these are my configurations:", "Under the ENVIRONMENT section, in Command, choose webserver , flower , worker or scheduler depending on which task you\u2019re creating.", "You can also make use of environment variables! You can either use value to hardcode the env or use valueFrom to use Secrets Manager or AWS Parameter Store. But please, don\u2019t inject secrets without security measures. More info here.", "For ALL services except flower, you MUST set POSTGRES_ variables, the ones we referenced in the entrypoint.sh remember? Without those, the services are going to fail miserably trying to connect to a non-existent database.", "For the scheduler and worker task definitions, you have to set REDIS_HOST. You can set either the IP or an internal DNS as I did here. We\u2019re not setting user and password authentication, I don\u2019t think it\u2019s necessary since the service itself is private. Feel free to do so though.", "We\u2019re officially done with the Task definition! Hang on, from now on it\u2019s gonna be waaaaay easier.", "Go to your ECS cluster, in Services tab click on Create.", "After a while, all services should look like this. Don\u2019t worry if some service is not working. We\u2019ll sort out connections between all of them in the next section.", "What we should do now is ensure each service receives information from the corresponding sources. We\u2019re going to set their security groups.", "A security group acts as a virtual firewall for your instance to control inbound and outbound traffic. When you launch an instance in a VPC, you can assign up to five security groups to the instance. Security groups act at the instance level, not the subnet level. Therefore, each instance in a subnet in your VPC can be assigned to a different set of security groups.\u2013AWS Documentation", "Below is the official documentation of the Airflow Celery architecture:", "I\u2019m going to borrow some lines from Airflow\u2019s documentation:", "The above should be reflected in the security groups.", "Go to VPC service in AWS, select Security groups. In the setting up of all services, I asked you to identify them with an appropriate name, this is so you can filter them and provide the configurations easily.", "From here, select each group and set their correct Inbound Rules. Take for example Redis:", "Redis Server is running on port 6379 (the one we enabled in the task definition). The architecture diagram shows us that it should be accessible by the workers and the scheduler. We also include flower to check the broker status. Hence, we include rows for each source security group of those instances.", "Remember, follow the diagram and set all services\u2019 security groups accordingly. This ensures that every connection between the services, that is supposed to be allowed, is. As you can see, the database should accept connections from every Airflow process.", "Testing is easy, just access the webserver and flower. Launch an example DAG and see in flower how the Active counter is increasing and decreasing fast when tasks are being executed.", "Don\u2019t worry, if something\u2019s not working, go check the logs of failing container tasks and do a little research, the solution should come up quickly.", "If you\u2019re still having failures, there\u2019s probably something you forgot to do (or that I forgot to tell you lol). Feel free to comment and I\u2019ll do my best to help you!", "This is it! Your Airflow cluster is ready! I know I know\u2026this was long and maybe even a little confusing, but hey! You managed to do it! \ud83d\udc4f\ud83d\udc4f\ud83d\ude04.", "This was a long trip for me, I went through a lot of problems, errors, exceptions setting up my own cluster. I really hope I helped you have fewer headaches with this guide.", "Until then, thank you and goodbye! \ud83d\udc4b\ud83d\udc4b\ud83d\udc4b", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Working as a Data Engineer. Data science amateur. Constantly wanting to travel far. https://www.linkedin.com/in/axelfurlan/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fce2518dbf631&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@axelfurlan_17621?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@axelfurlan_17621?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "Axel Furlan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4b2ad5f659bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&user=Axel+Furlan&userId=4b2ad5f659bd&source=post_page-4b2ad5f659bd----ce2518dbf631---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce2518dbf631&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce2518dbf631&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/es/photos/parque-e%C3%B3lico-energ%C3%ADa-verde-1209335/", "anchor_text": ""}, {"url": "https://pixabay.com/photos/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1209335", "anchor_text": "Free-Photos"}, {"url": "https://pixabay.com/es/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1209335", "anchor_text": "Pixabay"}, {"url": "http://lucidchart.com/", "anchor_text": "Lucichart"}, {"url": "https://cloudacademy.com/blog/aws-security-groups-instance-level-security/", "anchor_text": "security group"}, {"url": "https://aws.amazon.com/fargate/", "anchor_text": "AWS Fargate"}, {"url": "https://www.zdnet.com/article/stop-saying-the-cloud-is-just-someone-elses-computer-because-its-not/", "anchor_text": "cool post"}, {"url": "https://www.zdnet.com/meet-the-team/uk/mary-branscombe/", "anchor_text": "Mary Branscombe"}, {"url": "https://aws.amazon.com/es/autoscaling/", "anchor_text": "auto-scaling"}, {"url": "https://aws.amazon.com/rds/", "anchor_text": "RDS"}, {"url": "https://hub.docker.com/r/puckel/docker-airflow", "anchor_text": "Puckel\u2019s Airflow"}, {"url": "https://github.com/puckel/docker-airflow/blob/master/docker-compose-CeleryExecutor.yml", "anchor_text": "Puckel\u2019s docker-compose celery YAML file"}, {"url": "https://aws.amazon.com/ecr/", "anchor_text": "AWS ECR"}, {"url": "https://en.wikipedia.org/wiki/Don%27t_repeat_yourself", "anchor_text": "DRY"}, {"url": "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html", "anchor_text": "this"}, {"url": "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html", "anchor_text": "here"}, {"url": "https://docs.aws.amazon.com/AmazonECS/latest/userguide/specifying-sensitive-data.html", "anchor_text": "here"}, {"url": "https://forums.aws.amazon.com/thread.jspa?messageID=931880", "anchor_text": "It\u2019s not currently possible"}, {"url": "https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html", "anchor_text": "here"}, {"url": "https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html", "anchor_text": "AWS Documentation"}, {"url": "https://airflow.apache.org/docs/stable/executor/celery.html?highlight=celery", "anchor_text": "Source"}, {"url": "https://airflow.apache.org/docs/stable/executor/celery.html?highlight=celery", "anchor_text": "Source"}, {"url": "https://unsplash.com/@ayahya09?utm_source=medium&utm_medium=referral", "anchor_text": "Ali Yahya"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/aws?source=post_page-----ce2518dbf631---------------aws-----------------", "anchor_text": "AWS"}, {"url": "https://medium.com/tag/airflow?source=post_page-----ce2518dbf631---------------airflow-----------------", "anchor_text": "Airflow"}, {"url": "https://medium.com/tag/apache?source=post_page-----ce2518dbf631---------------apache-----------------", "anchor_text": "Apache"}, {"url": "https://medium.com/tag/ecs?source=post_page-----ce2518dbf631---------------ecs-----------------", "anchor_text": "Ecs"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----ce2518dbf631---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce2518dbf631&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&user=Axel+Furlan&userId=4b2ad5f659bd&source=-----ce2518dbf631---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce2518dbf631&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&user=Axel+Furlan&userId=4b2ad5f659bd&source=-----ce2518dbf631---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce2518dbf631&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fce2518dbf631&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ce2518dbf631---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ce2518dbf631--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ce2518dbf631--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ce2518dbf631--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@axelfurlan_17621?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@axelfurlan_17621?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Axel Furlan"}, {"url": "https://medium.com/@axelfurlan_17621/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "226 Followers"}, {"url": "https://www.linkedin.com/in/axelfurlan/", "anchor_text": "https://www.linkedin.com/in/axelfurlan/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4b2ad5f659bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&user=Axel+Furlan&userId=4b2ad5f659bd&source=post_page-4b2ad5f659bd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fce2814aca92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-apache-airflow-with-celery-on-aws-ce2518dbf631&newsletterV3=4b2ad5f659bd&newsletterV3Id=ce2814aca92&user=Axel+Furlan&userId=4b2ad5f659bd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}