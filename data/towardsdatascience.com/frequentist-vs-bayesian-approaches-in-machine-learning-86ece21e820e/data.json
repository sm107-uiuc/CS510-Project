{"url": "https://towardsdatascience.com/frequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e", "time": 1683013141.254399, "path": "towardsdatascience.com/frequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e/", "webpage": {"metadata": {"title": "Frequentists vs. Bayesians in Machine Learning | Towards Data Science", "h1": "Frequentist vs. Bayesian Approaches in Machine Learning", "description": "Frequentists vs. Bayesians in the context of machine learning, illustrated with two algorithms: linear regression and Bayesian linear regression."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/generative-vs-2528de43a836", "anchor_text": "discriminative and generative models", "paragraph_index": 27}, {"url": "https://lingpipe-blog.com/2013/04/12/generative-vs-discriminative-bayesian-vs-frequentist/", "anchor_text": "this post", "paragraph_index": 27}], "all_paragraphs": ["There has always been a debate between Bayesian and frequentist statistical inference. Frequentists dominated statistical practice during the 20th century. Many common machine learning algorithms like linear regression and logistic regression use frequentist methods to perform statistical inference. While Bayesians dominated statistical practice before the 20th century, in recent years many algorithms in the Bayesian schools like Expectation-Maximization, Bayesian Neural Networks and Markov Chain Monte Carlo have gained popularity in machine learning.", "In this article, we will talk about their differences and connections in the context of machine learning. We will also use two algorithms for illustration: linear regression and Bayesian linear regression.", "For simplicity, we will use \u03b8 to denote the model parameter(s) throughout this article.", "Frequentist methods assume the observed data is sampled from some distribution. We call this data distribution the likelihood: P(Data|\u03b8), where \u03b8 is treated as is constant and the goal is to find the \u03b8 that would maximize the likelihood. For example, in logistic regression the data is assumed to be sampled from Bernoulli distribution, and in linear regression the data is assumed to be sample from Gaussian distribution.", "Bayesian methods assume the probabilities for both data and hypotheses(parameters specifying the distribution of the data). In Bayesians, \u03b8 is a variable, and the assumptions include a prior distribution of the hypotheses P(\u03b8), and a likelihood of data P(Data|\u03b8). The main critique of Bayesian inference is the subjectivity of the prior as different priors may arrive at different posteriors and conclusions.", "Frequentists use maximum likelihood estimation(MLE) to obtain a point estimation of the parameters \u03b8. The log-likelihood is expressed as:", "The parameters \u03b8 are estimated by maximizing the log-likelihood, or minimizing the negative log likelihood(loss function):", "Instead of a point estimate, Bayesians estimate a full posterior distribution of the parameters using the Bayes\u2019 formula:", "You might have noticed the computation of the denominator can be NP-hard because it has an integral (or summation in the case of classification) over all possible values of \u03b8. You might also wonder if we can have a point estimate of \u03b8, just like what MLE does. That\u2019s where Maximum A Posteriori(MAP) estimation comes into play. MAP bypasses the cumbersome computation of the posterior distribution and instead tries to find the point estimates of \u03b8 that maximize the posterior distribution.", "Since logarithmic functions are monotonic, we can rewrite the above equation in the log space and decompose it into 2 parts: maximizing the likelihood and maximizing the prior distribution:", "Doesn\u2019t this look similar to MLE?", "In fact, the connection between these two is that MAP can be treated as performing MLE on a regularized loss function where the prior corresponds to the regularization term. For example, if we assume the prior distribution to be Gaussian, MAP is equal to MLE with L2 regularization; if we assume the prior distribution to be Laplace, MAP is equal to MLE with L1 regularization.", "There is another method to get a point estimate of the posterior distribution: Expected A Posteriori(EAP) estimation. The difference between MAP and EAP is that MAP gets the mode(maximum) of the posterior distribution whereas EAP gets the expected value of the posterior distribution.", "The main difference between frequentist and Bayesian approaches is the way they measure uncertainty in parameter estimation.", "As we mentioned earlier, frequentists use MLE to get point estimates of unknown parameters and they don\u2019t assign probabilities to possible parameter values. Therefore, to measure uncertainty, Frequentists rely on null hypothesis and confidence intervals. However, it\u2019s important to point out that confidence intervals don\u2019t directly translate to probabilities of hypothesis. For example, with a confidence interval of 95%, it only means 95% of the confidence intervals you\u2019ve generated will cover the true estimate, but it\u2019s incorrect to say that it covers the true estimate with a probability of 95% .", "Bayesians, on the other hand, have a full posterior distribution over the possible parameter values and this allows them to get uncertainty of the estimate by integrating the full posterior distribution.", "Bayesians are usually more computationally intensive than frequentists due to integration over many parameters. There are some approaches to reduce the computational intensity by using conjugate priors or approximating the posterior distribution using sampling methods or variational inference.", "In this section, we will see how to train and make predictions with two algorithms: linear regression and Bayesian linear regression.", "We assume the below form of a linear regression model where the intercept is incorporated in the parameter \u03b8:", "The data is assumed to be distributed according to Gaussian distribution:", "Using MLE to maximize the log likelihood, we can get the point estimate of \u03b8 as shown below:", "Once we\u2019ve learned the parameters \u03b8 from the training data, we can directly use it to make predictions with new data:", "As mentioned earlier, the Bayesian way is to make assumptions for both the prior and likelihood:", "Using these assumptions and the Bayes\u2019 formula, we can get the posterior distribution:", "At prediction time, we use the posterior distribution and the likelihood to calculate the posterior predictive distribution:", "Notice that the estimation for both the parameters and predictions are full distributions. Of course, if we only need a point estimate, we can always use MAP or EAP.", "The main goal of machine learning is to make predictions using the parameters learned from training data. Whether we should achieve the goal using frequentist or Bayesian approach depends on :", "On a side note, we discussed discriminative and generative models earlier. A common misconception is to label discriminative models as frequentist and generative models as Bayesian. In fact, both frequentist and Bayesian approaches can be used for discriminative or generative models. You can refer to this post for more clarification.", "I hope you enjoyed reading this article. :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F86ece21e820e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----86ece21e820e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----86ece21e820e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://siwei-xu.medium.com/?source=post_page-----86ece21e820e--------------------------------", "anchor_text": ""}, {"url": "https://siwei-xu.medium.com/?source=post_page-----86ece21e820e--------------------------------", "anchor_text": "Siwei Causevic"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F301dc9114da0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&user=Siwei+Causevic&userId=301dc9114da0&source=post_page-301dc9114da0----86ece21e820e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86ece21e820e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86ece21e820e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/generative-vs-2528de43a836", "anchor_text": "discriminative and generative models"}, {"url": "https://lingpipe-blog.com/2013/04/12/generative-vs-discriminative-bayesian-vs-frequentist/", "anchor_text": "this post"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----86ece21e820e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/bayesian-machine-learning?source=post_page-----86ece21e820e---------------bayesian_machine_learning-----------------", "anchor_text": "Bayesian Machine Learning"}, {"url": "https://medium.com/tag/bayesian-statistics?source=post_page-----86ece21e820e---------------bayesian_statistics-----------------", "anchor_text": "Bayesian Statistics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----86ece21e820e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----86ece21e820e---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F86ece21e820e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&user=Siwei+Causevic&userId=301dc9114da0&source=-----86ece21e820e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F86ece21e820e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&user=Siwei+Causevic&userId=301dc9114da0&source=-----86ece21e820e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86ece21e820e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----86ece21e820e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F86ece21e820e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----86ece21e820e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----86ece21e820e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----86ece21e820e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----86ece21e820e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----86ece21e820e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----86ece21e820e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----86ece21e820e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----86ece21e820e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----86ece21e820e--------------------------------", "anchor_text": ""}, {"url": "https://siwei-xu.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://siwei-xu.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Siwei Causevic"}, {"url": "https://siwei-xu.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "381 Followers"}, {"url": "https://www.linkedin.com/in/siwei-causevic/", "anchor_text": "https://www.linkedin.com/in/siwei-causevic/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F301dc9114da0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&user=Siwei+Causevic&userId=301dc9114da0&source=post_page-301dc9114da0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3374c04371d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrequentist-vs-bayesian-approaches-in-machine-learning-86ece21e820e&newsletterV3=301dc9114da0&newsletterV3Id=3374c04371d5&user=Siwei+Causevic&userId=301dc9114da0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}