{"url": "https://towardsdatascience.com/autoencoding-generative-adversarial-networks-16082512b583", "time": 1683006012.9074051, "path": "towardsdatascience.com/autoencoding-generative-adversarial-networks-16082512b583/", "webpage": {"metadata": {"title": "Autoencoding Generative Adversarial Networks | by Conor Lazarou | Towards Data Science", "h1": "Autoencoding Generative Adversarial Networks", "description": "GANs are hard to train. When they work, they work wonders, but anyone who\u2019s tried to train one themselves knows they\u2019re damn finicky bastards. Two of the most common problems in GAN training are mode\u2026"}, "outgoing_paragraph_urls": [{"url": "https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/", "anchor_text": "they work wonders", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/2004.05472", "anchor_text": "a recent paper", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Injective_function", "anchor_text": "injective", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Surjective_function", "anchor_text": "surjective", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1703.10593", "anchor_text": "CycleGAN", "paragraph_index": 4}, {"url": "https://www.gwern.net/Faces", "anchor_text": "way better results", "paragraph_index": 9}, {"url": "https://www.youtube.com/watch?v=djsEKYuiRFE", "anchor_text": "boom", "paragraph_index": 11}, {"url": "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html", "anchor_text": "CelebA", "paragraph_index": 13}, {"url": "https://www.forbes.com/sites/bernardmarr/2019/06/12/artificial-intelligence-explained-what-are-generative-adversarial-networks-gans/#b915f137e007", "anchor_text": "blind forger", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "Variational Autoencoder / GANs", "paragraph_index": 18}, {"url": "https://www.kaggle.com/soumikrakshit/anime-faces", "anchor_text": "Kaggle", "paragraph_index": 18}, {"url": "https://arxiv.org/abs/2004.05472", "anchor_text": "here", "paragraph_index": 18}, {"url": "http://flatland.ai", "anchor_text": "flatland.ai", "paragraph_index": 20}], "all_paragraphs": ["GANs are hard to train. When they work, they work wonders, but anyone who\u2019s tried to train one themselves knows they\u2019re damn finicky bastards. Two of the most common problems in GAN training are mode collapse and lack of convergence. In mode collapse, the generator learns to only generate a handful of samples; in generating \u201chandwritten\u201d digits, a GAN undergoing mode collapse might only learn to draw sevens, albeit highly-realistic sevens. With lack of convergence, the healthy competition between the generator and the discriminator sours, usually with the discriminator becoming much better than the generator; when the discriminator is able to easily and completely discern between real and generated samples, the generator doesn\u2019t get useful feedback and isn\u2019t able to improve.", "In a recent paper, I proposed a technique which appears to stabilize GAN training and addresses both of the above issues. A side-effect of this technique is that it allows for efficient and direct interpolation between real samples. In this article, I aim to step through the key ideas of the paper and illustrate why I think the AEGAN technique has the potential to be a very useful tool in the GAN trainer\u2019s toolbox.", "GANs learn a mapping from some latent space Z (the random noise) to some sample space X (the dataset, usually images). These mappings are naturally injective \u2014 each point z in Z corresponds to some sample x in X. However, they\u2019re rarely surjective \u2014 many samples in X do not have a corresponding point in Z. Indeed, mode collapse occurs when many points zi, zj, and zk map to a single sample xi, and the GAN is unable to generate points xj or xk. With this in mind, a more ideal GAN would have the following qualities:", "These three qualities suggest that we should aim for a one-to-one relationship (i.e. a bijective mapping) between the latent space and the sample space. To do this, we train a function G : Z \u27f6 X, which is our generator, and another function E : X \u27f6 Z, which we will call the encoder. The intents of these functions are:", "AEGAN is a four-network model comprising of two GANs and two autoencoders, illustrated in Figure 1, and is a generalization of the CycleGAN technique for unpaired image-to-image translation where one of the image domains is replaced with random noise. In short, we train two networks to translate between sample space X and latent space Z, and we train another two networks to discriminate between real and fake samples and latent vectors. Figure 1 is a complicated diagram, so let me break it down:", "The AEGAN is trained in the same way as a GAN, alternatingly updating the generators (G and E) and the discriminators (Dx and Dz). The AEGAN loss function is slightly more complex than the typical GAN loss, however. It consists of four adversarial components:", "and two reconstruction components (shown here summed together):", "which, all summed, form the AEGAN loss. E and G try to minimize this loss while Dx and Dz try to maximize it. If you don\u2019t care for the math, the intuition is simple:", "To start with, a disclaimer. Due to personal reasons, I\u2019ve only had the time and energy to test this on a single dataset. I\u2019m publishing my work as-is so that others can test out the technique themselves and validate my results or show that this is a dead-end. That said, here\u2019s a sample of the results after 300k training steps:", "By itself, figure 2 isn\u2019t all that exciting. If you\u2019re reading a Medium article about GANs, then you\u2019ve probably seen the StyleGAN trained on anime faces that produces way better results. What is exciting is comparing the above results to figure 3:", "The GAN used to generate the images in figure 3 and the AEGAN used to generate the images in figure 2 have the exact same architectures for G and for Dx; the only difference is that the AEGAN was made to learn the reverse function as well. This stabilized the training process. And before you ask, no, this wasn\u2019t a one-off fluke; I repeated the training for both the GAN and the AEGAN five times, and in each case, the AEGAN produced good results and the GAN produced garbage.", "An exciting side-effect of the AEGAN technique is that it allows for direct interpolation between real samples. GANs are known for their ability to interpolate between samples; draw two random vectors z1 and z2, interpolate between the vectors, then feed the interpolations to the generator and boom! With AEGAN, we can interpolate between real samples:", "Because the encoder E is able to map a sample x to its corresponding point z in the latent space, the AEGAN allows us to find points z1 and z2 for any samples x1 and x2 and interpolate between them as one would for a typical GAN. Figure 5 illustrates the reconstructions of 50 random samples from the dataset:", "First, I\u2019d like to address the shortcomings of this experiment. As I said, this was only tested on a single dataset. The structures of the individual networks G, E, Dx, and Dz also weren\u2019t extensively explored and no meaningful hypertuning was performed (on number or shape of layers, \u03bbs, etc.). The networks themselves were fairly simplistic; a more thorough and fair experiment would be to apply the AEGAN technique as a wrapper to a more powerful GAN on a more complex dataset such as CelebA.", "That said, the AEGAN has a number of desirable theoretical properties which make it ripe for further exploration.", "To that last point, the generators of regular GANs are never directly exposed to the training data, and only learn what the data looks like indirectly through the discriminator\u2019s feedback (hence the nickname \u201cblind forger\u201d). By including a reconstruction loss, the generator can beeline towards the low-dimensional manifold in high-dimensional pixel space. Consider figure 6, which shows the AEGAN\u2019s output after only 200 training steps:", "Compare this to figure 7, which shows a regular GAN with the same architecture as the AEGAN at the same point in its training:", "As you can see, the AEGAN is particularly effective at finding the low-dimensional manifold, although measuring its ability to fit that manifold will require further experimentation.", "I\u2019d be remiss if I didn\u2019t mention Variational Autoencoder / GANs somewhere, which is an interesting, related technique, so here it is. The data used to train these models is available on Kaggle. You can check out the original paper here. My tf.keras implementation of this network is available at the following github repo:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data science and ML consultant, generative artist, writer. flatland.ai"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F16082512b583&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----16082512b583--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----16082512b583--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://conor-lazarou.medium.com/?source=post_page-----16082512b583--------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=post_page-----16082512b583--------------------------------", "anchor_text": "Conor Lazarou"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdeb461dc9d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&user=Conor+Lazarou&userId=deb461dc9d26&source=post_page-deb461dc9d26----16082512b583---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16082512b583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16082512b583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/photos/sign-one-way-two-way-direction-3219707/", "anchor_text": "Pixabay"}, {"url": "https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/", "anchor_text": "they work wonders"}, {"url": "https://arxiv.org/abs/2004.05472", "anchor_text": "a recent paper"}, {"url": "https://en.wikipedia.org/wiki/Injective_function", "anchor_text": "injective"}, {"url": "https://en.wikipedia.org/wiki/Surjective_function", "anchor_text": "surjective"}, {"url": "https://arxiv.org/abs/1703.10593", "anchor_text": "CycleGAN"}, {"url": "https://www.gwern.net/Faces", "anchor_text": "way better results"}, {"url": "https://www.youtube.com/watch?v=djsEKYuiRFE", "anchor_text": "boom"}, {"url": "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html", "anchor_text": "CelebA"}, {"url": "https://arxiv.org/abs/1511.05644", "anchor_text": "Adversarial Autoencoders"}, {"url": "https://www.forbes.com/sites/bernardmarr/2019/06/12/artificial-intelligence-explained-what-are-generative-adversarial-networks-gans/#b915f137e007", "anchor_text": "blind forger"}, {"url": "https://arxiv.org/abs/1411.1784", "anchor_text": "conditionality"}, {"url": "https://arxiv.org/abs/1511.05644", "anchor_text": "Adversarial Autoencoders"}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "Variational Autoencoder / GANs"}, {"url": "https://www.kaggle.com/soumikrakshit/anime-faces", "anchor_text": "Kaggle"}, {"url": "https://arxiv.org/abs/2004.05472", "anchor_text": "here"}, {"url": "https://github.com/ConorLazarou/AEGAN-keras", "anchor_text": "ConorLazarou/AEGAN-kerasA Keras implementation of the Autoencoding Generative Adversarial Network (AEGAN) technique.github.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----16082512b583---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----16082512b583---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----16082512b583---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----16082512b583---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----16082512b583---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16082512b583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&user=Conor+Lazarou&userId=deb461dc9d26&source=-----16082512b583---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16082512b583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&user=Conor+Lazarou&userId=deb461dc9d26&source=-----16082512b583---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16082512b583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----16082512b583--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F16082512b583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----16082512b583---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----16082512b583--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----16082512b583--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----16082512b583--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----16082512b583--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----16082512b583--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----16082512b583--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----16082512b583--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----16082512b583--------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Conor Lazarou"}, {"url": "https://conor-lazarou.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "http://flatland.ai", "anchor_text": "flatland.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdeb461dc9d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&user=Conor+Lazarou&userId=deb461dc9d26&source=post_page-deb461dc9d26--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F51220adfabae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fautoencoding-generative-adversarial-networks-16082512b583&newsletterV3=deb461dc9d26&newsletterV3Id=51220adfabae&user=Conor+Lazarou&userId=deb461dc9d26&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}