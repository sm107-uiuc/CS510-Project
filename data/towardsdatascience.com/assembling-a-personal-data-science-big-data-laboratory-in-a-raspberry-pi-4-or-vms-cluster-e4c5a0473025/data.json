{"url": "https://towardsdatascience.com/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025", "time": 1683009212.3041332, "path": "towardsdatascience.com/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025/", "webpage": {"metadata": {"title": "A Data Science/Big Data Laboratory \u2014 part 2 of 4: Hadoop 3.2.1 and Spark 3.0.0 over Ubuntu 20.04 in a 3-node cluster | by Pier Taranti | Towards Data Science", "h1": "A Data Science/Big Data Laboratory \u2014 part 2 of 4: Hadoop 3.2.1 and Spark 3.0.0 over Ubuntu 20.04 in a 3-node cluster", "description": "This text can be used to support the installation in any Ubuntu 20.04 server clusters, and this is the beauty of well-designed layered software. Furthermore, if you have more nodes, you can\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/ptaranti/RaspberryPiCluster", "anchor_text": "My repository in GitHub", "paragraph_index": 9}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/capacity-scheduler.xml", "anchor_text": "/opt/hadoop/etc/hadoop/capacity-scheduler.xml", "paragraph_index": 16}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/core-site.xml", "anchor_text": "core-site.xml", "paragraph_index": 41}], "all_paragraphs": ["This text can be used to support the installation in any Ubuntu 20.04 server clusters, and this is the beauty of well-designed layered software. Furthermore, if you have more nodes, you can distribute the software as you like. The text assumes you know Linux command line, including ssh, vim, and nano.", "I do not recommend starting with less than three Raspberries since you need to set the communication, and both Zookeeper and Kafka requires an odd number of nodes. If you are trying a single node this guide may be used. Still, the performance is likely to be disappointing in a Raspberry \u2014 for single node I suggest a virtual machine with a reasonable amount of RAM and processor.", "Due to size, I had to divide the tutorial into four parts", "All configuration files are available at [1]:", "Disclaimer: This text is offered to everyone for free to use at your own risk. I took care in citing all my sources, but if you feel that something is missed, please send me a note. Since different software versions may behaviour in a distinct way due to their dependencies, I suggest using the same versions I used in your first try.", "The Hadoop and Spark installation considered the instructions from [3, 4] together with other sources.", "I have used the updated versions from the Apache website:", "First: download, and extract the files to /opt. Give access to pi user.", "Now you need to configure the Hadoop and Spark", "To be clear \u2014 we first configure it as a single node and then modify for a cluster. My repository in GitHub contains only the final cluster config files.", "I had a lot of trouble at this point: I accidentally inserted one blanc line on top of the file header. This blanc line caused parse errors and Hadoop kept failing until I realised the issue.", "adding the following line at the end:", "Use jps to check if all services are on (numbers change..) :", "You need these five services on!", "For testing the single node, I refer to the tutorial [2]:", "At this point, I got stuck, with a repeating message similar to:", "I followed the suggestion from [4] and other sources and changed the following file /opt/hadoop/etc/hadoop/capacity-scheduler.xml.", "Parameter yarn.scheduler.capacity.maximum-am-resource-percent should be set if you are running a cluster on a single machine where you have got less resource. This setting indicates the fraction of the resources that are made available to be allocated to application masters, increasing the number of possible concurrent applications. Note that this is dependent on your resources. It worked in my Pi 4 4GB ram.", "Edit the file, adding the property:", "Note \u2014 the tutorials usually provide commands to suppress warnings. I do prefer to see these warnings when experimenting. If you would like to remove it refers to the first tutorial.", "Now you should have one fully operational installation in a single node. It is time to Hadoop goes to a cluster!", "I executed the tutorials but faced a number of problems. This is expected \u2014 different environment, software versions.", "After some experimenting, I succeed to have a stable environment. The next steps to configure Hadoop to operate with Yarn in cluster are a mix from both [2, 4].", "Note \u2014 all nodes have the same configuration (p2, p3, \u2026 -> workers), except the node pi1 (pi1 -> master), because of the Spark. Again, my GitHub repository has the configuration available. I have made available the configuration for all nodes.", "Creating the folders for all nodes:", "The next will remove all data from Hadoop. Do your backup first if there is something important.", "Note that Spark will exist only in the master.", "Do it for all your nodes.", "I prefer doing one by one and confirming no abnormal behaviour.", "Now, the following files need to be edited, changing the configuration:", "Note \u2014 The property dfs.replication, indicates how many times data is replicated in the cluster. You can set to have all the data duplicated on the two or more nodes. Don\u2019t enter a value higher than the actual number of worker nodes. I used 1 because one of my noted was using a 16GB micro SD. Some of my parts delayed in the post due to the COVID-19 outbreak. If you misconfigure it your spark applications will get stuck in \u201caccepted\u201d status, due to the lack of resources.", "Note \u2014 The last property, dfs.permissions.enabled, was set to false to disable permission checking. I use spark from a machine external from the cluster, and this facilitates my access. Obviously I advice do not use this setting in a production environment. I also disabled the safe mode. To do this, after finishing the installation run:", "how many times data is replicated in the cluster. You can set to have all the data duplicated on the two or more nodes. Don\u2019t enter a value higher than the actual number of worker nodes. I used 1 because one of my noted was using a 16GB micro SD. Some of my parts delayed in the post due to the COVID-19 outbreak. If you misconfigure it your spark applications will get stuck in \u201caccepted\u201d status, due to the lack of resources.", "After updating the configuration files at all nodes, it is necessary to format the data space and starting the cluster (you can start from any node):", "Basically, you need to create/edit the following configuration file:", "These values can be adjusted to your hardware \u2014 but they will work with Raspberry Pi 4 4GB.", "Install the following packages in all nodes in order to allow the nodes to process jobs prepared in python/pyspark:", "Reboot all nodes, and restart services:", "You can send one application example to test the spark:", "At the end of the processing, you should receive an approximated calculation for PI value:", "Initially, I was not able to handle(upload/delete) files online. A workaround is available in:", "This workaround is implemented adding the following properties to Hadoop core-site.xml:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist, PhD, experienced team leader and co-worker; result-oriented professional \u2014 always learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe4c5a0473025&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@piertaranti?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@piertaranti?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "Pier Taranti"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb885a0240a08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&user=Pier+Taranti&userId=b885a0240a08&source=post_page-b885a0240a08----e4c5a0473025---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4c5a0473025&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4c5a0473025&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-ff37759cb2ec?source=friends_link&sk=3a4b90e57dc0fc0ec44a39d1aee2145c", "anchor_text": "Part 1: Introduction, Operational System and Networking"}, {"url": "https://towardsdatascience.com/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-8a1da8d49b48?source=friends_link&sk=4a481ee4e3778d6c9d4e5a305a407bb6", "anchor_text": "Part 3: PostgreSQL and Hive"}, {"url": "https://towardsdatascience.com/kafka-and-zookeeper-over-ubuntu-in-a-3-node-cluster-a-data-science-big-data-laboratory-part-4-of-4-47631730d240?source=friends_link&sk=955731d942d6f83e7f00d731e830ba30", "anchor_text": "Part 4: Kafka and Conclusion"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster", "anchor_text": "ptaranti/RaspberryPiClusterConfig files for a Hadoop + Spark + Hive + Kafka + Postgresql cluster (ubuntu 20.04) The files in this\u2026github.com"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/home/pi/.bashrc", "anchor_text": "/home/pi/.bashrc"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster", "anchor_text": "My repository in GitHub"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/tree/master/pi1/opt/hadoop/etc/hadoop", "anchor_text": "/opt/hadoop/etc/hadoop"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/hadoop-env.sh", "anchor_text": "/opt/hadoop/etc/hadoop/hadoop-env.sh,"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/core-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/core-site.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/hdfs-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/hdfs-site.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/mapred-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/mapred-site.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/yarn-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/yarn-site.xml"}, {"url": "http://pi1:4040", "anchor_text": "http://pi1:4040"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/capacity-scheduler.xml", "anchor_text": "/opt/hadoop/etc/hadoop/capacity-scheduler.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/capacity-scheduler.xml", "anchor_text": "/opt/hadoop/etc/hadoop/capacity-scheduler.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/core-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/core-site.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/hdfs-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/hdfs-site.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/mapred-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/mapred-site.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/yarn-site.xml", "anchor_text": "/opt/hadoop/etc/hadoop/yarn-site.xml"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/master", "anchor_text": "/opt/hadoop/etc/hadoop/master"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/workers", "anchor_text": "/opt/hadoop/etc/hadoop/workers"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/spark/conf/spark-defaults.conf", "anchor_text": "/opt/spark/conf/spark-defaults.conf"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/spark/conf/spark-env.sh", "anchor_text": "/opt/spark/conf/spark-env.sh"}, {"url": "http://pi1:9870/", "anchor_text": "ttp://pi1:9870/"}, {"url": "https://community.cloudera.com/t5/Support-Questions/unable-to-upload-files-to-hdfs/td-p/33650", "anchor_text": "unable to upload files to hdfsWhen i try to upload files to HDFS it shows \"Error:undefined\". Howerver from terminal i can upload files successfully\u2026community.cloudera.com"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/core-site.xml", "anchor_text": "core-site.xml"}, {"url": "http://pi1:8088/", "anchor_text": "http://pi1:8088/"}, {"url": "https://towardsdatascience.com/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-8a1da8d49b48", "anchor_text": "A Data Science/Big Data Laboratory \u2014 part 3 of 4: Hive and Postgres over Ubuntu in a 3-node clusterAssembling a Data Science/Big Data Laboratory in a Raspberry Pi 4 or VMs cluster with Hadoop, Spark, Hive, Kafka\u2026towardsdatascience.com"}, {"url": "https://github.com/ptaranti/RaspberryPiCluster", "anchor_text": "https://github.com/ptaranti/RaspberryPiCluster"}, {"url": "https://dev.to/awwsmm/building-a-raspberry-pi-hadoop-spark-cluster-8b2", "anchor_text": "Building a Raspberry Pi Hadoop / Spark Cluster"}, {"url": "https://medium.com/analytics-vidhya/build-raspberry-pi-hadoop-spark-cluster-from-scratch-c2fa056138e0", "anchor_text": "Build Raspberry Pi Hadoop/Spark Cluster from scratch"}, {"url": "https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/", "anchor_text": "How to Install and Set Up a 3-Node Hadoop Cluster"}, {"url": "https://medium.com/tag/cluster?source=post_page-----e4c5a0473025---------------cluster-----------------", "anchor_text": "Cluster"}, {"url": "https://medium.com/tag/hadoop?source=post_page-----e4c5a0473025---------------hadoop-----------------", "anchor_text": "Hadoop"}, {"url": "https://medium.com/tag/spark?source=post_page-----e4c5a0473025---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/kafka?source=post_page-----e4c5a0473025---------------kafka-----------------", "anchor_text": "Kafka"}, {"url": "https://medium.com/tag/hive?source=post_page-----e4c5a0473025---------------hive-----------------", "anchor_text": "Hive"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe4c5a0473025&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&user=Pier+Taranti&userId=b885a0240a08&source=-----e4c5a0473025---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe4c5a0473025&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&user=Pier+Taranti&userId=b885a0240a08&source=-----e4c5a0473025---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4c5a0473025&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe4c5a0473025&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e4c5a0473025---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e4c5a0473025--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e4c5a0473025--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e4c5a0473025--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@piertaranti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@piertaranti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Pier Taranti"}, {"url": "https://medium.com/@piertaranti/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "26 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb885a0240a08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&user=Pier+Taranti&userId=b885a0240a08&source=post_page-b885a0240a08--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8b755e2373b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025&newsletterV3=b885a0240a08&newsletterV3Id=8b755e2373b9&user=Pier+Taranti&userId=b885a0240a08&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}