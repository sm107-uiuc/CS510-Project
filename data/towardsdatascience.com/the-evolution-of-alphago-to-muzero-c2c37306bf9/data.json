{"url": "https://towardsdatascience.com/the-evolution-of-alphago-to-muzero-c2c37306bf9", "time": 1683002988.6887171, "path": "towardsdatascience.com/the-evolution-of-alphago-to-muzero-c2c37306bf9/", "webpage": {"metadata": {"title": "The Evolution of AlphaGo to MuZero | by Connor Shorten | Towards Data Science", "h1": "The Evolution of AlphaGo to MuZero", "description": "DeepMind recently released their MuZero algorithm, headlined by superhuman ability in 57 different Atari games. Reinforcement Learning agents that can play Atari games are interesting because, in\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["DeepMind recently released their MuZero algorithm, headlined by superhuman ability in 57 different Atari games.", "Reinforcement Learning agents that can play Atari games are interesting because, in addition to a visually complex state space, agents playing Atari games don\u2019t have a perfect simulator they can use for planning as in Chess, Shogi, and Go.", "This idea of a \u201cperfect simulator\u201d is one of the key limitations that keep AlphaGo and subsequent improvements such as AlphaGo Zero and AlphaZero, limited to Chess, Shogi and Go and useless for certain real-world applications such as Robotic Control.", "Reinforcement Learning problems are framed within Markov Decision Processes (MDPs) depicted below:", "The family of algorithms from AlphaGo, AlphaGo Zero, AlphaZero, and MuZero extend this framework by using planning, depicted below:", "DeepMind\u2019s AlphaGo, AlphaGo Zero, and AlphaZero exploit having a perfect model of (action, state) \u2192 next state to do lookahead planning in the form of Monte Carlo Tree Search (MCTS). MCTS is a perfect complement to using Deep Neural Networks for policy mappings and value estimation because it averages out the errors from these function approximations. MCTS provides a huge boost for AlphaZero in Chess, Shogi, and Go where you can do perfect planning because you have a perfect model of the environment.", "MuZero comes with a way of salvaging MCTS planning by learning a dynamics model depicted below:", "MuZero\u2019s approach to Model-Based Reinforcement Learning, having a parametric model map from (s,a) \u2192 (s\u2019, r), is that it does not exactly reconstruct the pixel-space at s\u2019. Contrast that with the image below from \u201cWorld Models\u201d by Ha and Schmidhuber:", "This planning algorithm from MuZero is very successful in the Atari domain and could have enormous application potential for Reinforcement Learning problems. This article will explain the evolution from AlphaGo, AlphaGoZero, AlphaZero, and MuZero to get a better understanding for how MuZero works. I have also made a video explaining this if you are interested:", "AlphaGo is the first paper in the series, showing that Deep Neural Networks could play the game of Go by predicting a policy (mapping from state to action) and value estimate (probability of winning from a given state). These policy and value networks are used to enhance tree-based lookahead search by selecting which actions to take from given states and which states are worth exploring further.", "AlphaGo uses 4 Deep Convolutional Neural Networks, 3 policy networks and a value network. 2 of the policy networks are trained with supervised learning on expert moves.", "Supervised learning describes loss functions consisting of some kind of L(y\u2019, y). In this case, the y\u2019 is the action the policy network predicted from a given state, and the y is the action the expert human player had taken in that state.", "The rollout policy is a smaller neural network that takes in a smaller input state representation as well. As a consequence of this, the rollout policy has a significantly lower modeling accuracy of expert moves than the higher capacity network. However the rollout policy network\u2019s inference time (time to make a prediction of action given state) is 2 microseconds compared to 3 milliseconds with the larger network, making it useful for Monte Carlo Tree Search simulations.", "The SL policy network is used to initialize the 3rd policy network which is trained with self-play and policy gradients. Policy gradients describe the idea of optimizing the policy directly with respect to the resulting rewards, compared to other RL algorithms that learn a value function and then make the policy greedy with respect to the value function. The policy gradient trained policy network plays against previous iterations of its own parameters, optimizing its parameters to select the moves that result in wins. The self-play dataset is then used to train a value network to predict the winner of a game from a given state.", "The final workhorse of AlphaGo is the combination of policy and value networks in MCTS, depicted below:", "The idea of MCTS is to perform lookahead search to get a better estimate of which immediate action to take. This is done by starting from a root node (the current state of the board), expanding that node by selecting an action and repeating this with subsequent states that result from the state, action transitions. MCTS chooses which edge of the tree to follow based on this Q + u(P) term which is a weighted combination of the value network\u2019s estimate of the state, the original probability density the policy network had given to this state, and a negative weighting of how many times the node has been visited, since this is repeated over and over again. Unique to AlphaGo is the use of a rollout policy simulation to average the contribution of the value network. The rollout policy simulates until the episode and wether that resulted in a win or a loss is blended with the value function estimate of that state with an extra parameter, lambda.", "AlphaGo Zero significantly improves the AlphaGo algorithm by making it more general and starting from \u201cZero\u201d human knowledge. AlphaGo Zero avoids the supervised learning of expert moves initialization and combines the value and policy network into a single neural network. This neural network is scaled up as well to utilize a ResNet compared to a simpler convolutional network in AlphaGo. The contribution of the ResNet performing both value and policy mappings is evident in the diagram below comparing the dual task ResNet to separate task CNNs:", "One of the most interesting characteristics of AlphaGo Zero is the way it trains its policy network using the action distribution found by MCTS, depicted below:", "The MCTS trains the policy network by using it as supervision to update the policy network. This is a clever idea since MCTS produces a better action distribution through lookahead search than the policy network\u2019s instant mapping from state to action.", "AlphaZero is the first step towards generalizing the AlphaGo family outside of Go, looking at changes needed to play Chess and Shogi as well. This requires formulating input state and output action representations for the residual neural network.", "In AlphaGo, the state representation uses a few handcrafted feature planes, depicted below:", "AlphaGo Zero uses a more general representation, simply passing in the previous 8 locations of stones for both players and a binary feature plane telling the agent which player it is controlling, depicted below:", "AlphaZero uses a similar idea to encode the input state representation for Chess and Shogi, depicted below:", "AlphaZero also makes some more subtle changes to the algorithm such as the way the self-play champion is crowned and the eliminations of data augmentation from Go board games such as reflections and rotations.", "This leads us to the current state-of-the-art in this series, MuZero. MuZero presents a very powerful generalization to the algorithm that allows it to learn without a perfect simulator. Chess, Shogi, and Go are all examples of games that come with a perfect simulator, if you move your pawn forward 2 positions, you know exactly what the resulting state of the board will be. You can\u2019t say the same thing about applying 30 N of force on a given joint in complex dexterous manipulation tasks like OpenAI\u2019s rubik\u2019s cube hand.", "The diagram below illustrates the key ideas of MuZero:", "Diagram A shows the pipeline of using a representation function h to map raw observations into a hidden state s0 that is used for tree-based planning. In MuZero, the combined value / policy network reasons in this hidden state space, so rather than mapping raw observations to actions or value estimates, it takes these hidden states as inputs. The dynamics function g learns to map from hidden state and action to a future hidden states.", "Diagram B shows how the policy network is similarly trained by mimicking the action distribution produced by MCTS as first introduced in AlphaGo Zero.", "Diagram C shows how this system is trained. Each of the three neural networks are trained in a joint optimization of the difference between the value network and the actual return, the difference between the intermediate reward experienced and predicted by the dynamics model and the difference between the MCTS action distribution and policy mapping.", "How does the representation function h get trained in this optimization loop?", "The representation function h comes into play in this joint optimization equation through back-propagation through time. Let\u2019s say you are taking the difference between the MCTS action distribution pi(s1) and the policy distribution p(s1). The output of p(s1) is a result of p(g(s0, a1)), which is a result of p(g(h(raw_input), a1)). This is how backprop through time sends update signals all the way back into the hidden representation function as well.", "I hope this article helped clarify how MuZero works within the context of the previous algorithms, AlphaGo, AlphaGo Zero, and AlphaZero! Thanks for reading!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc2c37306bf9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://connorshorten300.medium.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Connor Shorten"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59216259c525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&user=Connor+Shorten&userId=59216259c525&source=post_page-59216259c525----c2c37306bf9---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc2c37306bf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&user=Connor+Shorten&userId=59216259c525&source=-----c2c37306bf9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc2c37306bf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&source=-----c2c37306bf9---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://worldmodels.github.io/", "anchor_text": "https://worldmodels.github.io/"}, {"url": "https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.nature.com%2Farticles%2Fnature16961&v=A0HX8BgckFI&event=video_description&redir_token=xWFupkVllJha70MV9mB5IiYg3Gt8MTU3OTM3NDk0NEAxNTc5Mjg4NTQ0", "anchor_text": "https://www.nature.com/articles/natur..."}, {"url": "https://www.youtube.com/redirect?q=https%3A%2F%2Fwww.nature.com%2Farticles%2Fnature16961&v=A0HX8BgckFI&event=video_description&redir_token=xWFupkVllJha70MV9mB5IiYg3Gt8MTU3OTM3NDk0NEAxNTc5Mjg4NTQ0", "anchor_text": "https://www.nature.com/articles/natur..."}, {"url": "https://www.youtube.com/redirect?q=https%3A%2F%2Farxiv.org%2Fabs%2F1712.01815&v=A0HX8BgckFI&event=video_description&redir_token=xWFupkVllJha70MV9mB5IiYg3Gt8MTU3OTM3NDk0NEAxNTc5Mjg4NTQ0", "anchor_text": "https://arxiv.org/abs/1712.01815"}, {"url": "https://www.youtube.com/redirect?q=https%3A%2F%2Farxiv.org%2Fabs%2F1911.08265&v=A0HX8BgckFI&event=video_description&redir_token=xWFupkVllJha70MV9mB5IiYg3Gt8MTU3OTM3NDk0NEAxNTc5Mjg4NTQ0", "anchor_text": "https://arxiv.org/abs/1911.08265"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----c2c37306bf9---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----c2c37306bf9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----c2c37306bf9---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c2c37306bf9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c2c37306bf9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc2c37306bf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&user=Connor+Shorten&userId=59216259c525&source=-----c2c37306bf9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc2c37306bf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&user=Connor+Shorten&userId=59216259c525&source=-----c2c37306bf9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc2c37306bf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59216259c525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&user=Connor+Shorten&userId=59216259c525&source=post_page-59216259c525----c2c37306bf9---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F303e04c63860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&newsletterV3=59216259c525&newsletterV3Id=303e04c63860&user=Connor+Shorten&userId=59216259c525&source=-----c2c37306bf9---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Written by Connor Shorten"}, {"url": "https://connorshorten300.medium.com/followers?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "2K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw", "anchor_text": "https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59216259c525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&user=Connor+Shorten&userId=59216259c525&source=post_page-59216259c525----c2c37306bf9---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F303e04c63860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-evolution-of-alphago-to-muzero-c2c37306bf9&newsletterV3=59216259c525&newsletterV3Id=303e04c63860&user=Connor+Shorten&userId=59216259c525&source=-----c2c37306bf9---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=author_recirc-----c2c37306bf9----0---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=author_recirc-----c2c37306bf9----0---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=author_recirc-----c2c37306bf9----0---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Connor Shorten"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c2c37306bf9----0---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=author_recirc-----c2c37306bf9----0---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Introduction to ResNetsThis Article is Based on Deep Residual Learning for Image Recognition from He et al. [2] (Microsoft Research)\u2026"}, {"url": "https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=author_recirc-----c2c37306bf9----0---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "6 min read\u00b7Jan 24, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0a830a288a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-resnets-c0a830a288a4&user=Connor+Shorten&userId=59216259c525&source=-----c0a830a288a4----0-----------------clap_footer----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4?source=author_recirc-----c2c37306bf9----0---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0a830a288a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-resnets-c0a830a288a4&source=-----c2c37306bf9----0-----------------bookmark_preview----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c2c37306bf9----1---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c2c37306bf9----1---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c2c37306bf9----1---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c2c37306bf9----1---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c2c37306bf9----1---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c2c37306bf9----1---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c2c37306bf9----1---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----c2c37306bf9----1-----------------bookmark_preview----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c2c37306bf9----2---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----c2c37306bf9----2---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----c2c37306bf9----2---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c2c37306bf9----2---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c2c37306bf9----2---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c2c37306bf9----2---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c2c37306bf9----2---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----c2c37306bf9----2-----------------bookmark_preview----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/text-to-image-a3b201b003ae?source=author_recirc-----c2c37306bf9----3---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=author_recirc-----c2c37306bf9----3---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=author_recirc-----c2c37306bf9----3---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Connor Shorten"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c2c37306bf9----3---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/text-to-image-a3b201b003ae?source=author_recirc-----c2c37306bf9----3---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "Text to ImageThis article will explain an interesting paper which converts natural language text descriptions to 64x64 RGB images"}, {"url": "https://towardsdatascience.com/text-to-image-a3b201b003ae?source=author_recirc-----c2c37306bf9----3---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": "8 min read\u00b7Jan 25, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3b201b003ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-to-image-a3b201b003ae&user=Connor+Shorten&userId=59216259c525&source=-----a3b201b003ae----3-----------------clap_footer----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/text-to-image-a3b201b003ae?source=author_recirc-----c2c37306bf9----3---------------------0e1e5800_f765_49a3_b77e_a9ea04bfc242-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3b201b003ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-to-image-a3b201b003ae&source=-----c2c37306bf9----3-----------------bookmark_preview----0e1e5800_f765_49a3_b77e_a9ea04bfc242-------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "See all from Connor Shorten"}, {"url": "https://towardsdatascience.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----0-----------------clap_footer----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----c2c37306bf9----0-----------------bookmark_preview----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----c2c37306bf9----1-----------------bookmark_preview----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c2c37306bf9----0---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----c2c37306bf9----0-----------------bookmark_preview----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Trust Region Policy Optimization (TRPO) ExplainedThe Reinforcement Learning algorithm TRPO builds upon natural policy gradient algorithms, ensuring updates remain within \u2018trustworthy\u2019\u2026"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "\u00b712 min read\u00b7Oct 12, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----4b56bd206fc2----1-----------------clap_footer----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c2c37306bf9----1---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&source=-----c2c37306bf9----1-----------------bookmark_preview----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c2c37306bf9----2---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c2c37306bf9----2---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c2c37306bf9----2---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c2c37306bf9----2---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c2c37306bf9----2---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----2-----------------clap_footer----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c2c37306bf9----2---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----c2c37306bf9----2-----------------bookmark_preview----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/aiguys/reinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58?source=read_next_recirc-----c2c37306bf9----3---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://kargarisaac.medium.com/?source=read_next_recirc-----c2c37306bf9----3---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://kargarisaac.medium.com/?source=read_next_recirc-----c2c37306bf9----3---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Isaac Kargar"}, {"url": "https://medium.com/aiguys?source=read_next_recirc-----c2c37306bf9----3---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "AIGuys"}, {"url": "https://medium.com/aiguys/reinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58?source=read_next_recirc-----c2c37306bf9----3---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "Reinforcement Learning from Human Feedback, InstructGPT, and ChatGPTNote: some parts of this blog post are generated by ChatGPT! :)"}, {"url": "https://medium.com/aiguys/reinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58?source=read_next_recirc-----c2c37306bf9----3---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": "\u00b79 min read\u00b7Jan 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faiguys%2F693d00cb9c58&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faiguys%2Freinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58&user=Isaac+Kargar&userId=bf5ea8e11f80&source=-----693d00cb9c58----3-----------------clap_footer----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/aiguys/reinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58?source=read_next_recirc-----c2c37306bf9----3---------------------72523404_6493_4bcd_8e13_5d025430dbe6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F693d00cb9c58&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faiguys%2Freinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58&source=-----c2c37306bf9----3-----------------bookmark_preview----72523404_6493_4bcd_8e13_5d025430dbe6-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----c2c37306bf9--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}