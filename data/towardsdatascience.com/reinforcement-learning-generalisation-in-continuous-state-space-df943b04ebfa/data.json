{"url": "https://towardsdatascience.com/reinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa", "time": 1682997320.152574, "path": "towardsdatascience.com/reinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa/", "webpage": {"metadata": {"title": "Reinforcement Learning \u2014 Generalisation in Continuous State Space | by Jeremy Zhang | Towards Data Science", "h1": "Reinforcement Learning \u2014 Generalisation in Continuous State Space", "description": "Till now I have introduced most basic ideas and algorithms of reinforcement learning with discrete state, action settings. Recall the examples we have been implemented so far, Grid World\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/zero-equals-false/n-step-td-method-157d3875b9cb", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/RandomWalk/RandomWalk(n-step).py", "anchor_text": "here", "paragraph_index": 22}, {"url": "http://localhost:8888/edit/RandomWalk(General)/RandomWalk.py", "anchor_text": "full implementation", "paragraph_index": 29}, {"url": "https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b", "anchor_text": "next post", "paragraph_index": 34}], "all_paragraphs": ["Till now I have introduced most basic ideas and algorithms of reinforcement learning with discrete state, action settings. Recall the examples we have been implemented so far, Grid World, Tic-Tac-Toe, Multi-Arm Bandits, Cliff Walking, Blackjack \u2026 etc, most of which has a basic setting of a board or a grid in order to make the state space countable. However, the power of reinforcement learning does not stop there, and in a real world situation, the states space are mostly continuous, with uncountable states and actions combinations for an agent to explore. In this article, I will extend our previous learnt idea to continuous space and implement a more general Random Walk example by applying function approximation.", "From this article, I will introduce:", "For discrete state space, theoretically an agent is able to experience every state and explore rewards on each of them. When the case being extended to continuous state space, to generalise the value function, we will need a representation of state.", "Consider a supervised learning problem, no matter what algorithms one applies, the model being trained is able to do prediction on data it has never seen before, and the magic is that it learnt a representation of y = f(x) , where x is the input features and y is the target. This approximation or generalisation idea can be exactly copied to reinforcement learning problems, (in fact, most algorithms in machine learning can be applied on function approximation in reinforcement learning settings), where we try to approximate the value function v = v(s, w) (where s is state and w is model weights) and take the state, value as training examples. For example, in its simplest form, we could define value function v = w_0*s + w_1 , using a linear approximation with order 1.", "Now here comes the problem, we have a representation of value function, then how are we able to update the weights of parameters in order to make the value approximate the actual value? In fact, the weight update follows the rule in Stochastic Gradient Descent(SGD) :", "Where v(S_t) denotes the actual value at step t and v(S_t, w_t) denotes the approximate function with weight parameter w_t . Note that the square difference between actual value and estimated value measures the error of the approximate function, and by taking derivative with respect to w_t , the weight is tuning itself slightly towards the right direction.", "Stochastic gradient-descent (SGD) methods do this by adjusting the weight vector after each example by a small amount in the direction that would most reduce the error on that example.", "For approximate function with multiple weight parameters, one should update each weights by taking derivative respectively:", "Now let\u2019s get to the algorithm applied in continuous state space:", "It looks there\u2019s awful lot steps, but if you look closer, you will see it looks super similar with the n-step TD method we learnt here. Have a look at the n-step TD method in discrete space:", "The Q function here is substitutable by Value function. By comparing TD method for continuous space and discrete space, it is clear that the only difference lies in the value function update, whereas in discrete space, the value function(or Q function) is directly updated, in continuous space, the value function is implicitly updated through weights update, as the value function here is represented by weights w . Another thing you need to notice is that in continuous space, the target value is taken as G , which in 1 step TD method is the accumulated value of one step ahead and in Monte Carlo simulation(which essentially is infinite TD method as we talked before) is the accumulated value till the end of the episode.", "As we mentioned above, in continuous space setting, value function is a representation of states ( V = V(S, w) ) and most machine learning algorithms can be applied here. In this post, I will introduce some most basic approximation functions that can be easily implemented and help you get a sense on how to apply it in reinforcement learning problems.", "The simplest form of function approximation. For example, suppose that there are 10 states (1, 2, 3, \u2026, 10) in the space, we set 1 to 5 has the same value and 6 to 10 has another value, then this is called state aggregation. The mathematical representation could be:", "The function is simple but very important, as the idea is critical in Tile Coding, which is a technic of function generalisation that being used a lot in reinforcement learning problems. The advantage of state aggregation is that the derivative for state in each aggregated session is 1 and the value for that state is the corresponding weight.", "The polynomial function we will apply here can be written as:", "In this case the derivative of weight parameters is always the value of its corresponding power to the states.", "Similar to polynomial case, the Fourier function applied here is:", "The derivative of weight w_i is cos(i*\u03c0s).", "Notice that both polynomials and Fourier introduced here are linear in terms of weight parameter, as this guarantees convergence. And also here I only introduced case for one state, for more general form please refer to Sutton\u2019s book.", "Enough for theorems, let\u2019s apply what we\u2019ve learned and get our hands on a actual case.", "Consider a 1000-state version of the random walk task. The states are numbered from 1 to 1000, left to right, and all episodes begin near the center, in state 500. State transitions are from the current state to one of the 100 neighbouring states to its left, or to one of the 100 neighbouring states to its right, all with equal probability. Of course, if the current state is near an edge, then there may be fewer than 100 neighbours on that side of it. In this case, all the probability that would have gone into those missing neighbours goes into the probability of terminating on that side (thus, state 1 has a 0.5 chance of terminating on the left, and state 950 has a 0.25 chance of terminating on the right). As usual, termination on the left produces a reward of -1, and termination on the right produces a reward of +1. All other transitions have a reward of zero.", "Remember the 100-state random walk we talked in the other post, here the rules are mostly the same. Differences are", "I previously did the implementation of random walk on discrete state space, and you can check out here. The following implementation, I will be focusing on the difference.", "The soul of reinforcement learning in continuous state space. The value function should be able to do", "The 1000 states are divided into 10 groups, each with a value stored in self.values . The value function just returns the value stored in the corresponding group and update function update the value by adding delta*dev , where here derivative is 1 and delta is G-V(S, w) as introduced above.(Notice that here value is essentially the weight parameter)", "The LinearValueFunction includes both polynomial function and Fourier function. Inside the value function, features is a list of components of the value function representation, and inside the update function, derivative equals the components value as we described above.", "Difference from previous random walk, here the agent is able to walk faster(from 1 to 100 steps), and when its position reaches out of the boundary, the episode ends and reward will be received with either -1 or 1.", "With all the above prep work, the play function is a lot easier to implement. The structure is very alike with our previous implementation:", "If you have been following up my previous posts, you must have seen this structure many times. The only difference here is that the value function is replaced by valueFunction .", "Three different value functions are applied and let\u2019s compare the learning result. (full implementation)", "For aggregate state function with 1 step, 1000 states are aggregated into 10 groups, each with 100 states, and this is why you see a staircase-like graph.", "This is the learning graph with polynomial function of order 5 and 1 step, from which we see a divergence at the lower states and a convergence at higher states. This is because for polynomial function approximation, there is always an intercept, thus making the value for state 0 is non-zero(in general, polynomial functions are not recognised).", "This is for now the best approximation, and generally Fourier function has better performance than polynomial function.", "We here learned the basic theory of reinforcement learning in continuous space and implement some basic approximate functions. And for sure, the idea dose not limit only on these functions. In more advanced settings, neural network functions can be leveraged which makes a deep reinforcement learning problem.", "In the next post, I will introduce tile coding and apply it on Q function learning in continuous state space, which is more general than random walk example.", "Hmm\u2026I am a data scientist looking to catch up the tide\u2026"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdf943b04ebfa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://meatba11.medium.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----df943b04ebfa---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf943b04ebfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----df943b04ebfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf943b04ebfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&source=-----df943b04ebfa---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/zero-equals-false/n-step-td-method-157d3875b9cb", "anchor_text": "here"}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/RandomWalk/RandomWalk(n-step).py", "anchor_text": "here"}, {"url": "http://localhost:8888/edit/RandomWalk(General)/RandomWalk.py", "anchor_text": "full implementation"}, {"url": "https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b", "anchor_text": "next post"}, {"url": "http://incompleteideas.net/book/the-book-2nd.html?source=post_page---------------------------", "anchor_text": "http://incompleteideas.net/book/the-book-2nd.html"}, {"url": "https://github.com/JaeDukSeo/reinforcement-learning-an-introduction?source=post_page---------------------------", "anchor_text": "https://github.com/JaeDukSeo/reinforcement-learning-an-introduction"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----df943b04ebfa---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----df943b04ebfa---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/python3?source=post_page-----df943b04ebfa---------------python3-----------------", "anchor_text": "Python3"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----df943b04ebfa---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf943b04ebfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----df943b04ebfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf943b04ebfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----df943b04ebfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf943b04ebfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----df943b04ebfa---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcdbd8b83c584&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&newsletterV3=f37783fc8c26&newsletterV3Id=cdbd8b83c584&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----df943b04ebfa---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Written by Jeremy Zhang"}, {"url": "https://meatba11.medium.com/followers?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----df943b04ebfa---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcdbd8b83c584&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa&newsletterV3=f37783fc8c26&newsletterV3Id=cdbd8b83c584&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----df943b04ebfa---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----df943b04ebfa----0---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----df943b04ebfa----0---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----df943b04ebfa----0---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Jeremy Zhang"}, {"url": "https://medium.com/geekculture?source=author_recirc-----df943b04ebfa----0---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----df943b04ebfa----0---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Using ChatGPT in PythonPractical Examples of Using ChatGPT SDK"}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----df943b04ebfa----0---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "\u00b74 min read\u00b7Dec 20, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Feeaed9847e72&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fusing-chatgpt-in-python-eeaed9847e72&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----eeaed9847e72----0-----------------clap_footer----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----df943b04ebfa----0---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feeaed9847e72&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fusing-chatgpt-in-python-eeaed9847e72&source=-----df943b04ebfa----0-----------------bookmark_preview----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df943b04ebfa----1---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----df943b04ebfa----1---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----df943b04ebfa----1---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----df943b04ebfa----1---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df943b04ebfa----1---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df943b04ebfa----1---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df943b04ebfa----1---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----df943b04ebfa----1-----------------bookmark_preview----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df943b04ebfa----2---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----df943b04ebfa----2---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----df943b04ebfa----2---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----df943b04ebfa----2---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df943b04ebfa----2---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df943b04ebfa----2---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df943b04ebfa----2---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----df943b04ebfa----2-----------------bookmark_preview----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----df943b04ebfa----3---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----df943b04ebfa----3---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----df943b04ebfa----3---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Jeremy Zhang"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----df943b04ebfa----3---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----df943b04ebfa----3---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "UNet Line by Line ExplanationExample UNet Implementation"}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----df943b04ebfa----3---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": "\u00b74 min read\u00b7Oct 18, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9b191c76baf5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funet-line-by-line-explanation-9b191c76baf5&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----9b191c76baf5----3-----------------clap_footer----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----df943b04ebfa----3---------------------6eee0304_0b55_4d3e_8b50_49b61ebde384-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9b191c76baf5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funet-line-by-line-explanation-9b191c76baf5&source=-----df943b04ebfa----3-----------------bookmark_preview----6eee0304_0b55_4d3e_8b50_49b61ebde384-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "See all from Jeremy Zhang"}, {"url": "https://towardsdatascience.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----0-----------------clap_footer----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----df943b04ebfa----0-----------------bookmark_preview----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----1-----------------clap_footer----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----df943b04ebfa----1-----------------bookmark_preview----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df943b04ebfa----0---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----df943b04ebfa----0-----------------bookmark_preview----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----1-----------------clap_footer----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----df943b04ebfa----1---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----df943b04ebfa----1-----------------bookmark_preview----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df943b04ebfa----2---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----df943b04ebfa----2---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----df943b04ebfa----2---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----df943b04ebfa----2---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df943b04ebfa----2---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df943b04ebfa----2---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df943b04ebfa----2---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----df943b04ebfa----2-----------------bookmark_preview----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----df943b04ebfa----3---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/?source=read_next_recirc-----df943b04ebfa----3---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/?source=read_next_recirc-----df943b04ebfa----3---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Piotr Krosniak"}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----df943b04ebfa----3---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "Vaccine Supply Chain Optimization with AI-Powered Capacitated Vehicle Routing Problem(CVRP)- Part 1The world is facing a global health crisis, and one of the most important challenges is to ensure an efficient and timely distribution of\u2026"}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----df943b04ebfa----3---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": "6 min read\u00b7Jan 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fca79519e9ad7&operation=register&redirect=https%3A%2F%2Fpiotrkrosniak.medium.com%2Fvaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7&user=Piotr+Krosniak&userId=b791abcfafd5&source=-----ca79519e9ad7----3-----------------clap_footer----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----df943b04ebfa----3---------------------283b4956_a097_44fa_91fd_e49b7b9964ff-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca79519e9ad7&operation=register&redirect=https%3A%2F%2Fpiotrkrosniak.medium.com%2Fvaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7&source=-----df943b04ebfa----3-----------------bookmark_preview----283b4956_a097_44fa_91fd_e49b7b9964ff-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----df943b04ebfa--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}