{"url": "https://towardsdatascience.com/a-guide-to-ensemble-learning-d3686c9bed9a", "time": 1683000131.5448499, "path": "towardsdatascience.com/a-guide-to-ensemble-learning-d3686c9bed9a/", "webpage": {"metadata": {"title": "A guide to Ensemble Learning. Nobody can know everything but with\u2026 | by Gilbert Tanner | Towards Data Science", "h1": "A guide to Ensemble Learning", "description": "Nobody can know everything but with help, we can overcome every obstacle. That\u2019s exactly the idea behind ensemble learning. Eventhough, individual models might produce weak results combined they\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview", "anchor_text": "House Price Regression data-set", "paragraph_index": 3}, {"url": "https://github.com/TannerGilbert/Tutorials/tree/master/A%20guide%20to%20Ensemble%C2%A0Learning", "anchor_text": "my Github", "paragraph_index": 4}, {"url": "https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard", "anchor_text": "this excellent Kaggle kernel", "paragraph_index": 7}, {"url": "https://mlwave.com/kaggle-ensembling-guide/", "anchor_text": "Kaggle Ensembling Guide", "paragraph_index": 14}, {"url": "https://stats.stackexchange.com/questions/273749/majority-voting-in-ensemble-learning", "anchor_text": "majority vote", "paragraph_index": 16}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html", "anchor_text": "BaseEstimator", "paragraph_index": 21}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html", "anchor_text": "RegressorMixin", "paragraph_index": 21}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html", "anchor_text": "TransformerMixin", "paragraph_index": 21}, {"url": "https://www.quora.com/Why-does-random-forest-use-sampling-with-replacement-instead-of-without-replacement", "anchor_text": "sampling with replacement", "paragraph_index": 29}, {"url": "https://www.researchgate.net/publication/222467943_Stacked_Generalization", "anchor_text": "Stacked Generalization", "paragraph_index": 34}, {"url": "http://eepurl.com/gq-u4X", "anchor_text": "join my newsletter", "paragraph_index": 45}], "all_paragraphs": ["Nobody can know everything but with help, we can overcome every obstacle. That\u2019s exactly the idea behind ensemble learning. Eventhough, individual models might produce weak results combined they might be unbeatable.", "And ensemble models are exactly that \u2014 models consisting of a combination of base models. The only difference being the way they combine the models which can range from simple methods like averaging or max voting to more complex like Boosting or stacking.", "Ensemble learning techniques have seen a huge jump in popularity in the last years. This is because they can help you to build a really robust model from a few \u201cweak\u201d models, which eliminates a lot of the model tuning that would else be needed to achieve good results. They are especially popular in data science competitions because for these competitions the highest accuracy is more important than the runtime or interpretability of the model. This most often isn\u2019t the case in the industry but that doesn\u2019t mean that ensembling can\u2019t be of use for such applications. Rather it means that it isn\u2019t used at the same scale for industry problems as it is for data science competitions.", "In this article, we will go through the most common ensembling techniques out there. You will learn how they work and how you can use them with Python. We will work on the House Price Regression data-set which can be freely downloaded from Kaggle.", "Also, the full code for both regression and classification is available on my Github. If you have any questions or recommendations feel free to leave a comment down below or contact me on social media.", "After downloading the data-set we can import everything needed and load in the data-set with the following code.", "This data-set has quite a few interesting features and therefore we can get huge accuracy gains by creating the right features but because this isn\u2019t the topic of this article we won\u2019t go into further detail.", "If you are still interested in the feature engineering I would recommend you to check out this excellent Kaggle kernel, which not only includes excellent feature engineering but also shows how to do stacking.", "After executing all the feature engineering code from the kernel we have a data-set with 221 columns \u2014 a mixture of categorical and continues once.", "Before we can start working through the different ensembling techniques we need to define some base models which will be used for ensembling. For this data-set, we will use a Lasso regression, GradientBoosting, XGBoost, and lightGBM model.", "We will validate the results using the root mean squared error and cross-validation.", "Now we will quickly define and train each model so we can get an idea about their base performance.", "This will output the root mean squared error for each of our models:", "As mentioned at the start of the article there are multiple ways to ensemble models. There are simple once like max voting or averaging as well as more complex once like boosting, bagging or stacking.", "What is the same for each of them is that they hugely benefit from uncorrelated base models \u2014 models that make very different predictions. To explain why this is the case let us work through a little example from the Kaggle Ensembling Guide.", "Imagine we have a data-set with all 1s as the ground truth targets. We could have 3 highly correlated models which produce the following predictions:", "When we take a simple majority vote \u2014 choosing the value that appears most \u2014 we see no improvement:", "This is because these models all learned the same thing and therefore they are also making the same mistakes. But if we instead use 3 less-performing highly uncorrelated models we can see that accuracy increases significantly:", "This is a huge improvement from the 60\u201380% accuracy of the base models.", "Now that we have an understanding of what ensembling is and have our base models ready we can start working through the different ensembling techniques.", "Averaging is a simple method that is generally used for regression problems. Here the predictions are simply averaged to get a more robust result and even though this method is simple it almost always gives better results than a single model and therefore is always worth trying.", "For ease of usage, we will create a class that inherits from Scikit-Learns BaseEstimator, RegressorMixin, and TransformerMixin classes because that way we only need to overwrite the fit and predict methods to get a working model which can be used like any other Scikit-Learn model.", "The model can now be used like any other Scikit Learn model. The only difference is that when creating an object we need to pass the base models which will then be trained in the fit method and used for predictions in the prediction method.", "By averaging three of our base models \u2014 Lasso regression, GBM, and XGBoost \u2014 we get a significant accuracy increase.", "Averaging models is great and simple but it has one major flaw and that is that most of the time one model has more predictive power than another and therefore we want to give it more weight on the final predictions.", "We can achieve this by passing a weight for each of the models and then multiplying the predictions of each model with the corresponding weight. The only thing we need to look out for is that the weights need to add up to 1 in order not to change the scale of the predictions.", "To now create the model we not only need to pass the base models but also an array of weights.", "This even further reduces the error to an average of 0.118 with a standard deviation of 0.009 over the different folds.", "Bagging is a hugely popular ensembling method which is used in algorithms like Random Forest. It gains accuracy by not only averaging the models but also trying to create models that are as uncorrelated as possible by giving them different training sets.", "It creates the data-set using sampling with replacement a simple but sufficient data sampling technique. To implement this we will create a method called subsample and call it for every model to create its individual data-set.", "With this technique, we are able to create models which are highly uncorrelated and therefore perform really well when ensembled as can be seen when we compare a single decision tree and a random forest.", "Here we can clearly see the power of bagging:", "Boosting is a sequential process, where each subsequent model tries to correct the errors of the previous model. Therefore the succeeding models are dependent on the previous models and we need to train the models in sequence instead of parallel.", "One of the first popular boosting implementations is called AdaBoost. To create an AdaBoost model we can simply use the AdaBoostRegressor model from Scikit-Learn.", "Stacking was introduced by Wolpert in the paper Stacked Generalization in 1992. It is a method that uses k-fold for training base models which then make predictions on the left out fold. These so-called out of fold predictions are then used to train another model \u2014 the meta model \u2014 which can use the information produced by the base models to make final predictions.", "To implement this functionality we need to first train each base model k times (k\u2026Number of folds) and then use their predictions to train our meta model.", "To even get better results we can not only use the predictions of all the base models for training the meta model but also the initial features. Because of the added model complexity which is caused when adding the input features we should make a boolean parameter to determine whether we want to use input features.", "Now that our StackingAveragedModels is ready we can create and train a stacked average model with the following code:", "By using a Gradient Boosting Machine, LightGBM and XGBoost as the base models and lasso regression as a meta model we achieve a loss of 0.124. By including the input features we further reduced it to 0.120.", "For this problem, this doesn\u2019t seem like that big of a deal when knowing that we achieved better result using our simple weighted average model but for larger data-sets both stacking and blending can give you really good results. Furthermore, you could extend this implementation so you could use multiple layers which could even further reduce the error.", "Blending is a word introduced by the Netflix competition winners. It is very similar to stacking with to only difference being that instead of creating out-of-fold predictions using kfold you create a small holdout data-set which will then be used to train the meta-model.", "This model can be trained the same as our StackingAveragedModel. We only need to pass it some base models and a meta model.", "This gives us a root mean squared error of 0.120 which is almost the same accuracy we got using stacking. The big difference between Stacking and Blending can be seen when printing the training time. Whilst the Stacking model trained for about 42 seconds on my notebook the Blending model only trained for about 8 seconds.", "Ensembling Learning is a hugely effective way to improve the accuracy of your Machine Learning problem. It consists of a lot of different methods which range from the easy to implement and simple to use averaging approach to more advanced techniques like stacking and blending.", "In this article, we learned the basics workings of these different ensembling techniques and how to implement them in Python.", "That\u2019s all from this article. If you have any questions or just want to chat with me feel free to leave a comment below or contact me on social media. If you want to get continuous updates about my blog make sure to follow me on Medium and join my newsletter.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd3686c9bed9a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@gilberttanner?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gilberttanner?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "Gilbert Tanner"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb986eefd54ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&user=Gilbert+Tanner&userId=b986eefd54ba&source=post_page-b986eefd54ba----d3686c9bed9a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://unsplash.com/@pankajpatel?utm_source=medium&utm_medium=referral", "anchor_text": "Pankaj Patel"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview", "anchor_text": "House Price Regression data-set"}, {"url": "https://github.com/TannerGilbert/Tutorials/tree/master/A%20guide%20to%20Ensemble%C2%A0Learning", "anchor_text": "my Github"}, {"url": "https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard", "anchor_text": "this excellent Kaggle kernel"}, {"url": "https://mlwave.com/kaggle-ensembling-guide/", "anchor_text": "Kaggle Ensembling Guide"}, {"url": "https://stats.stackexchange.com/questions/273749/majority-voting-in-ensemble-learning", "anchor_text": "majority vote"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html", "anchor_text": "BaseEstimator"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html", "anchor_text": "RegressorMixin"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html", "anchor_text": "TransformerMixin"}, {"url": "https://www.quora.com/Why-does-random-forest-use-sampling-with-replacement-instead-of-without-replacement", "anchor_text": "sampling with replacement"}, {"url": "https://www.researchgate.net/publication/222467943_Stacked_Generalization", "anchor_text": "Stacked Generalization"}, {"url": "http://eepurl.com/gq-u4X", "anchor_text": "join my newsletter"}, {"url": "https://mlwave.com/kaggle-ensembling-guide/", "anchor_text": "Kaggle Ensembling GuideModel ensembling is a very powerful technique to increase accuracy on a variety of ML tasks. In this article I will\u2026mlwave.com"}, {"url": "https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/", "anchor_text": "A Comprehensive Guide to Ensemble Learning (with Python codes)Introduction When you want to purchase a new car, will you walk up to the first car shop and purchase one based on the\u2026www.analyticsvidhya.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d3686c9bed9a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d3686c9bed9a---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d3686c9bed9a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ensemble-learning?source=post_page-----d3686c9bed9a---------------ensemble_learning-----------------", "anchor_text": "Ensemble Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----d3686c9bed9a---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd3686c9bed9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&user=Gilbert+Tanner&userId=b986eefd54ba&source=-----d3686c9bed9a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd3686c9bed9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&user=Gilbert+Tanner&userId=b986eefd54ba&source=-----d3686c9bed9a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd3686c9bed9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d3686c9bed9a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d3686c9bed9a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gilberttanner?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gilberttanner?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Gilbert Tanner"}, {"url": "https://medium.com/@gilberttanner/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.6K Followers"}, {"url": "https://gilberttanner.com/", "anchor_text": "https://gilberttanner.com/"}, {"url": "https://www.youtube.com/c/GilbertTanner", "anchor_text": "https://www.youtube.com/c/GilbertTanner"}, {"url": "http://buymeacoff.ee/gilberttanner", "anchor_text": "buymeacoff.ee/gilberttanner"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb986eefd54ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&user=Gilbert+Tanner&userId=b986eefd54ba&source=post_page-b986eefd54ba--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa3ff29165918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-guide-to-ensemble-learning-d3686c9bed9a&newsletterV3=b986eefd54ba&newsletterV3Id=a3ff29165918&user=Gilbert+Tanner&userId=b986eefd54ba&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}