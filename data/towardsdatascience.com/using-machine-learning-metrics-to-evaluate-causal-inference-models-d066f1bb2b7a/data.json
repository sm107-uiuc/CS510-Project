{"url": "https://towardsdatascience.com/using-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a", "time": 1683018328.987108, "path": "towardsdatascience.com/using-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a/", "webpage": {"metadata": {"title": "Using machine learning metrics to evaluate causal inference models | by Ehud Karavani | Towards Data Science", "h1": "Using machine learning metrics to evaluate causal inference models", "description": "Reinterpreting machine learning metrics, like ROC curves, from a causal inference perspective of propensity-based models."}, "outgoing_paragraph_urls": [{"url": "http://www.cs.columbia.edu/~blei/fogm/2019F/readings/Holland1986.pdf", "anchor_text": "fundamental problem of causal inference", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/solving-simpsons-paradox-with-inverse-probability-weighting-79dbb1395597", "anchor_text": "inverse probability weighting", "paragraph_index": 3}, {"url": "https://arxiv.org/abs/1906.00442", "anchor_text": "a larger manuscript", "paragraph_index": 5}, {"url": "http://mlwiki.org/index.php/ROC_Analysis", "anchor_text": "A more in-depth overview", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/solving-simpsons-paradox-with-inverse-probability-weighting-79dbb1395597", "anchor_text": "IPW creates a pseudo-population in which the treated and control have similar characteristics", "paragraph_index": 20}, {"url": "https://academic.oup.com/ije/article/49/4/1397/5714095", "anchor_text": "Janssens and Martens", "paragraph_index": 25}, {"url": "https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation", "anchor_text": "Dariya Sydykova", "paragraph_index": 26}], "all_paragraphs": ["Evaluating causal inference models is literary impossible. Few scientific concepts are so pompously named \u2014 yet accurately describe the gravity of an issue \u2014 as the notorious \u201cfundamental problem of causal inference\u201d.", "Briefly, the prediction task in causal inference is different than that of supervised machine learning (ML). While in ML we interpolate the target to new unseen samples, in causal inference we extrapolate the target from units in one group to units in the other group. Because in any given time a unit can only be in one group and not the other (e.g., you either have received a drug or you haven\u2019t), we lack the ground-truth labels to compare against our predictions. Counterfactual outcome prediction cannot be derived like regular supervised prediction, nor can it be evaluated as one.", "Most causal inference algorithms usually have some machine learning core \u2014 a statistical model that predicts the outcome or treatment assignment. Once a mapping between features to targets is obtained, causal models can then have various ways to indirectly apply those statistical predictions to obtain a causal estimate.", "For example, inverse probability weighting (IPW) is a causal model that estimates the causal effect by first modelling the treatment assignment. It takes any machine learning classifier that can also output a continuous score between 0 and 1 and assume it to model the probability of being treated: p\u0302=Pr[T|X]. It regresses the features (X) against the binary treatment assignment (T), then takes the inverse of that predicted scores and use them to create a weighted average of the outcome.", "Having this machine-learning backbone allows us to interrogate it using commonly known metrics from machine learning; and just like IPW adjusts a binary classifier to obtain a causal estimate, we can adjust these ML metrics to obtain a causal-inference-relevant view.", "This post is a an effort to breakdown a larger manuscript into bite-size chunks, and will focus on what ROC curves can tell us about propensity models.", "Classifications models can be evaluated for their calibration \u2014 how well they behave as probability models \u2014 and for their discrimination \u2014 how well they separate positive from negative examples. AUC is a metric for discrimination. A more in-depth overview is slightly out of scope for this article, but I do want you to keep in mind two ways for generating ROC curves from a list of prediction scores and labels.", "First view is the na\u00efve one. For each possible threshold we will calculate the true-positive and false-positive rates, plotting that point in ROC space. Note that the TPR and FPR can be affected by the weight each unit contributes to the classification, which is not necessarily 1.", "Second view is more computationally efficient. It involves sorting the scores and traversing the list such that each positive unit moves you one step up and each negative unit moves you one step right. The size of the step is correspondingly determined by the fraction of positive and negative units, but we can weigh each unit so that the step size changes arbitrarily.", "In our case, the prediction scores are the propensity estimations (probability to be in the treatment group) and the labels are the actual treatment assignment. Moreover, controlling the ROC space through sample-weighting is the basis for the additional ROC curves to be presented.", "Coming from machine learning, this can be somewhat counterintuitive, so let\u2019s get done with it right out of the gate: good prediction performance usually suggests a bad propensity model and a bad causal model downstream. Propensity scores should not be able to discriminate well between the treatment and control units.", "If you\u2019re lucky, your good prediction performance is due to good-old overfit. You can use your ML knowledge to solve for that. Causal inference models are prone to all the same pitfalls in statistics, they are simply blessed with a few additional ones.", "If you\u2019re not lucky, your good discrimination ability may hint you have a positivity violation in your data. Positivity is an essential assumption if wanting to extrapolate outcomes across treatment groups, as in causal inference. It states that the treated should have some chance (i.e. positive probability) to be in the control group and vice versa. In other words, the groups should have some common support \u2014 in each subspace of features we should have both treated and control units, so both groups have their covariates overlap. Otherwise, how could you generalize the predicted outcome from the treated to the control if all treated units are males and all control units are females? Perfect discrimination between treated and controls suggests the groups occupy mutually exclusive regions in feature-space violating a necessary assumption for causal inference.", "Conversely, bad discrimination performance is not necessarily bad. It might simply suggest the treatment groups are well mixed \u2014 an encouraging step towards the validity of a causal analysis. However, it might also be due to underfit. The response surface of treatment assignment might be a complex one to model. Therefore, you should experiment in iteratively increase the expressiveness of your model to the point you overfit just to verify it is indeed the data that is balanced and not the model that is under-specified.", "Solving for lack of overlap is possible, but out of scope for this post. Just to namedrop a few strategies: you should revise the inclusion criteria of your data, rethink your confounder selection, stratify your analysis on highly predictive features, or use domain knowledge to thoughtfully help you extrapolate through mechanism rather than data.", "Focusing on propensity-based causal models, we have three relevant ROC curves: the regular one based on propensity scores and two novel curves created by reweighting the scores. They all work in tandem, and I\u2019ll present each one: how to obtain them and how to interpret them.", "How: This is the regular ROC curve simply obtained by taking the propensity scores against the binary treatment assignment.", "Interpretation: We already discussed the issue that the AUC should not be too high as it suggests good discrimination, which is bad for causal inference. The ROC curve allows us to detect such regions of perfect discrimination. Ideally, there should not be long vertical or horizontal segments in the curve. A sharp long vertical contour suggests there\u2019s a bunch of data points for which we only get true positives (upward movement) without paying any false negatives (rightward movement). That is, the treated units are very separable from the untreated \u2014 they are not well-mixed. Reiterating the above: this can hint that we have a positivity violation in the feature subspace that is mapped into this region of scores (thresholds) causing the vertical line.", "How: in this curve we weight the contribution of each unit\u2019s propensity score to the ROC curve by the corresponding inverse-probability weight of that unit.", "Interpretation: Ideally, like every post-weight discrimination metric, we should expect a random-like performance. Namely, a ROC curve that aligns with the diagonal and an AUC around 0.5.", "Intuition: This curve shows how well the weights balance the groups. IPW creates a pseudo-population in which the treated and control have similar characteristics \u2014 it weighs the sample so that in each region in the feature-space we should have similar amount of (weighted) units. If we were to apply a classifier in this weighted population, it would be difficult to discriminate the treated from the controls. For example, if we have the same amount of males and females we can\u2019t use sex as a predictive feature, and if we have the same amount of young and adults we can\u2019t use age, etc. Therefore, poor discrimination post-weighting is welcomed.", "How: We obtain this curve by weighing the scores such that each unit contributes its propensity score to the positive label (treatment group) and its complementary score (1 minus propensity) to the negative label (control group)", "Interpretation: Ideally, we would want the expected propensity to align with the vanilla (unweighted) propensity curve (and have same AUC).", "Intuition: The propensity-to-be-treated is never observed, we only see one instantiation of it in the form of treatment assignment. However, we can model the average propensity of units with similar features. If we assume the statistical model represents the true propensity, then we move from a binary classification task to a smoother calibration-like task where units with high confidence (extreme propensity) contribute almost like they would in the vanilla ROC curve, and low-confidence units (propensity around 0.5) contribute a segment parallel to the diagonal.", "Traditionally, practitioners will plot the propensity distribution, colored by the treatment and control groups, and look for overlap. ROC curves are another view of that propensity distribution.", "There is a direct transformation from scores distribution to ROC curves, as seen in the figure below taken from Janssens and Martens.", "And the gif below from Dariya Sydykova show how separability of scores affect how sharp the curves are.", "Following this perspective, the propensity histogram weighted by the inverse propensity serves the same purpose. The bar heights are no longer determined by the number of individuals in each bin, but by their accumulated weights. In the weighted scheme (right), the bars corresponding to the same propensity bucket (i.e. x-axis bin) have the same height in the treatment and control groups, relative to the unweighted version (left) in which the heights of the same bins differ.", "However, I would argue that viewing this in ROC space provides an easier interpretation, since we can convert the fuzzy notion of \u201cdistribution overlap\u201d to a concrete AUC score.", "We have seen how to interpret pre-weighting classification metrics (good performance is bad) and post-weighting classification metrics (bad performance is good).", "I focused on ROC curves for propensity models, presented two novel curves and discussed how to interpret them. Here are three take-aways for three curves:", "These presents an off-the-shelf intuitive measure to verify a causal model is not omitting complete nonsense. Using such simple AUC-based criteria can be implemented to automatically select causal inference models that perform better than others through cross-validation, similar to how we apply model selection in machine learning.", "I believe that deploying a propensity model and examining its behavior is beneficial in any causal inference analysis. Even if you end up modeling the response surface directly without using the propensity scores, it can still provide meaningful insights into the structure of the data and the assumption needed for a valid causal conclusion.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A research scientist working on machine learning for healthcare. Causal inference, data visualization and multi-modal prediction."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd066f1bb2b7a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ehudkr?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ehudkr?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "Ehud Karavani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2f86c3f9b1e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&user=Ehud+Karavani&userId=2f86c3f9b1e0&source=post_page-2f86c3f9b1e0----d066f1bb2b7a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd066f1bb2b7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd066f1bb2b7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "http://www.cs.columbia.edu/~blei/fogm/2019F/readings/Holland1986.pdf", "anchor_text": "fundamental problem of causal inference"}, {"url": "https://towardsdatascience.com/solving-simpsons-paradox-with-inverse-probability-weighting-79dbb1395597", "anchor_text": "inverse probability weighting"}, {"url": "https://arxiv.org/abs/1906.00442", "anchor_text": "a larger manuscript"}, {"url": "http://mlwiki.org/index.php/ROC_Analysis", "anchor_text": "A more in-depth overview"}, {"url": "https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation", "anchor_text": "taken from Dariya Sydykova"}, {"url": "http://mlwiki.org/index.php/ROC_Analysis", "anchor_text": "taken from ML wiki"}, {"url": "https://towardsdatascience.com/solving-simpsons-paradox-with-inverse-probability-weighting-79dbb1395597", "anchor_text": "IPW creates a pseudo-population in which the treated and control have similar characteristics"}, {"url": "https://twitter.com/ehudkar/status/1159817692158861313/photo/1", "anchor_text": "By the author"}, {"url": "https://academic.oup.com/ije/article/49/4/1397/5714095", "anchor_text": "Janssens and Martens"}, {"url": "https://academic.oup.com/ije/article/49/4/1397/5714095", "anchor_text": "Janssens and Martens"}, {"url": "https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation", "anchor_text": "Dariya Sydykova"}, {"url": "https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation", "anchor_text": "Dariya Sydykova"}, {"url": "https://github.com/IBM/causallib", "anchor_text": "Figure by the author, using causallib"}, {"url": "https://arxiv.org/abs/1906.00442", "anchor_text": "https://arxiv.org/abs/1906.00442"}, {"url": "https://medium.com/tag/causal-inference?source=post_page-----d066f1bb2b7a---------------causal_inference-----------------", "anchor_text": "Causal Inference"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d066f1bb2b7a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/model-selection?source=post_page-----d066f1bb2b7a---------------model_selection-----------------", "anchor_text": "Model Selection"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----d066f1bb2b7a---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/tag/explore?source=post_page-----d066f1bb2b7a---------------explore-----------------", "anchor_text": "Explore"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd066f1bb2b7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&user=Ehud+Karavani&userId=2f86c3f9b1e0&source=-----d066f1bb2b7a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd066f1bb2b7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&user=Ehud+Karavani&userId=2f86c3f9b1e0&source=-----d066f1bb2b7a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd066f1bb2b7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd066f1bb2b7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d066f1bb2b7a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d066f1bb2b7a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ehudkr?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ehudkr?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ehud Karavani"}, {"url": "https://medium.com/@ehudkr/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "73 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2f86c3f9b1e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&user=Ehud+Karavani&userId=2f86c3f9b1e0&source=post_page-2f86c3f9b1e0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fec66ea90b7fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-metrics-to-evaluate-causal-inference-models-d066f1bb2b7a&newsletterV3=2f86c3f9b1e0&newsletterV3Id=ec66ea90b7fc&user=Ehud+Karavani&userId=2f86c3f9b1e0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}