{"url": "https://towardsdatascience.com/how-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489", "time": 1682993137.860758, "path": "towardsdatascience.com/how-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489/", "webpage": {"metadata": {"title": "How to Get Beautiful Results with Neural Style Transfer | by Eugen Hotaj | Towards Data Science", "h1": "How to Get Beautiful Results with Neural Style Transfer", "description": "Generating high quality images with Neural Style Transfer is surprisingly difficult. In this article we explore what's necessary to make NST work."}, "outgoing_paragraph_urls": [{"url": "https://pytorch.org/tutorials/advanced/neural_style_tutorial.html", "anchor_text": "official PyTorch tutorial", "paragraph_index": 1}, {"url": "https://github.com/EugenHotaj/nn-hallucinations", "anchor_text": "my GitHub", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1508.06576", "anchor_text": "Gatys et al. paper", "paragraph_index": 3}, {"url": "https://ptrrupprecht.wordpress.com/2017/12/05/understanding-style-transfer/", "anchor_text": "this article", "paragraph_index": 5}, {"url": "https://distill.pub/2017/feature-visualization/", "anchor_text": "Feature Visualization", "paragraph_index": 13}, {"url": "https://github.com/EugenHotaj/nn-hallucinations", "anchor_text": "code", "paragraph_index": 17}, {"url": "https://distill.pub/2018/differentiable-parameterizations/#section-styletransfer", "anchor_text": "Differentiable Image Parameterization", "paragraph_index": 18}, {"url": "https://www.quora.com/Why-is-it-important-to-remove-correlated-features-in-machine-learning", "anchor_text": "removing correlated features", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Total_variation_denoising", "anchor_text": "total variation loss", "paragraph_index": 19}, {"url": "https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/", "anchor_text": "implicitly penalize", "paragraph_index": 19}, {"url": "https://github.com/EugenHotaj/nn-hallucinations", "anchor_text": "my GitHub", "paragraph_index": 21}], "all_paragraphs": ["I recently became interested in generating a Medium profile picture with Machine Learning. This pulled me deep into the land of Neural Style Transfer. While NST is conceptually simple to understand, generating high quality images is surprisingly difficult. There are a lot of intricate details and unmentioned tricks that one must implement correctly in order to get great results. In this article, we\u2019ll dive deep into Neural Style Transfer and examine what these tricks are in detail.", "There are a number of solid introductions to NST, both on Medium and other publications, so I won\u2019t waste any time going over the basics. If you have no idea what NST is (or you want to follow along with the article) a great way to get started is by looking at the official PyTorch tutorial. Unfortunately, like many other introductory articles, the final implementation generates mediocre results at best (Figure 1). We\u2019ll spend the next few sections updating the tutorial code to improve the transfer quality, but first we go on a tangent.", "All the accompanying code for this article can be found on my GitHub.", "Most of the Gatys et al. paper which introduced Neural Style Transfer is simple and straightforward to understand. However, one question that does not get addressed is why the Gram matrix is a natural way to represent style (i.e. texture)?", "At a high level, the Gram matrix measures the correlations between different feature maps in the same layer. A feature map is simply the post-activation output of a convolutional layer. For example, if a convolutional layer has 64 filters, it will output 64 feature maps. The Gram matrix then measures the correlation (similarity) between each feature map and every other feature map in the layer, without necessarily caring about exact pixel positions. To illustrate why this is a reasonable measure of texture, suppose we have two filters, one which detects blue things and one which detects spirals. We can apply these filters to an input image to produce 2 filter maps and measure their correlation. If the filter maps are highly correlated, then any spiral present in the image is almost certain to be blue. This means the texture of the image is composed of blue spirals, instead of red, green, or yellow spirals.", "Although this explanation still leaves me slightly uneasy, it seems to be a widely accepted fact in the texture synthesis community that the Gram matrix corresponds to style, as this article explains. Furthermore, we can\u2019t deny that the results we get by using the Gram matrix are impressive.", "The first step to improve transfer quality is to fix the PyTorch tutorial implementation. The tutorial tries to be faithful to the Gatys et al. paper but misses a few things along the way. For one thing, the paper\u2019s authors replace the MaxPool2d with an AvgPool2d as they found it produces higher quality results. Another detail is that the tutorial computes the ContentLoss and StyleLoss on the outputs of the convolutions instead of the the ReLU activations. This is more of a nitpick since I did not notice a big difference between using the convolutions vs. the ReLUs in my experiments.", "The most egregious difference between the tutorial and paper is that the \u201cwrong\u201d layers are used for the ContentLoss and StyleLoss respectively. I put wrong in quotes as the choice of layers is largely subjective and depends heavily on what produces the most pleasing style. That being said, there are some rules of thumb we can use to guide our decision. When measuring content similarity, the lower layers tend to activate most highly when there is a pixel perfect match between the content_img and the generated input_img. The deeper we go into the network, the less the layers care about an exact match, and instead activate highly when features are generally in the right place. To visualize what each layer is most concerned with, we can set style_weight=0 and run the training process on a random input_img using different layers as the content_layer.", "The tutorial uses the 4th convolution (conv2_2 in Figure 2) as the content layer. As we can see in Figure 3 above, this is likely too low of a layer to use for content as the network still cares about matching pixels exactly at this depth. Gatys et al. use conv4_2 instead, which is much more concerned with the overall feature arrangement instead of individual pixels.", "In the case of style, lower layers respond to small repetitive features while higher layers capture more abstract, global features. Therefore, in order to transfer the whole style of the style_img\u2014 from low level details to overarching motifs \u2014 we should include layers from all depths in the network. The tutorial uses the first 5 convolution layers, but these are all fairly low in the network and are unlikely to capture global features. Gatys et al. use conv1_1, conv2_1, conv3_1, conv4_1, and conv5_1, a nice distribution of layers across the entire network hierarchy. We can use the same method we used for content to visualize the style each choice of layers is optimizing for. To do this, we set content_weight=0, specify which style_layers we want to use, and run the training process on a random input_img.", "As expected, the style optimized by the tutorial layers captures low level, repetitive features but fails to capture high level, global features.", "The fixes we\u2019ve implemented so far should get us fairly close to the quality seen in the Gatys et al. paper. From here, we\u2019ll go even deeper and look at what next steps we can take to generate even better images.", "One of the first things I changed from the paper was to switch the optimizer from L-BFGS to Adam. In the paper, the authors claim that L-BFGS results in higher quality transfer but I did not notice a difference when using Adam in my experiments. Furthermore, Adam seemed to be more stable, especially when training for a large number of steps or with a large style_weight. In these cases, L-BFGS seemed to NaN out, probably due to exploding gradients (though I didn\u2019t look too deeply into it).", "Another minor tweak was to switch the mse_loss (i.e. L2 loss) to l1_loss. I can\u2019t think of a good reason to use L2 loss for style transfer (besides differentiability at 0) as the square term heavily penalizes outliers. As alluded to in the previous section, we don\u2019t really care about matching pixels exactly and can tolerate a few outliers in the generated image. Indeed, the outliers may even lead to more visually pleasing results as the style and content features are blended together. Finally, the authors of Feature Visualization \u2014 a must read article on a related topic \u2014 also use l1_loss for their task, likely for similar reasons.", "Actually, a lot of the tricks used to generate high quality Feature Visualizations elegantly transfer over to Neural Style Transfer. In fact, FV and NST are conceptually very similar and only differ in how they generate the input_img. In NST the input_img is optimized to activate different layers in a network in the same way as the content_img and style_img. FV on the other hand does not use a content_img and style_img but instead generates an input_img which maximally excites neurons in different layers.", "One trick I borrowed from FV is to use data augmentation on the input_img. This works exactly the same as with regular classification tasks: at each step, we apply some augmentations to the input_img (e.g rotation, cropping, resizing, etc.) before running it through the model and computing the loss. By augmenting the input_img at each step, we\u2019re forcing the input_img to generate features which are robust to minor perturbations. These robust features should contain less high frequency artifacts and generally look more visually appealing.\u00b9 However, I found the augmentations used in the Feature Visualization article to be very aggressive and had to scale them down appropriately. Even so, there are still some rotation artifacts that develop around the edges of the generated image (Figure 5). The simplest way to get rid of these artifacts is to just crop the image down by a few pixels \ud83d\ude43.", "Finally, the last modification I made was to switch the content_layer to conv3_2 instead of the conv4_2 Gatys et al. use. Most of the articles I read also recommend conv4_2, though I found that fine details get washed out at conv4_2 and the style overpowers the content in the generated image. On the other hand, conv3_2 still maintains these fine details without over-penalizing for pixel perfectness like lower layers do. Indeed, we can confirm that this is the case by looking at the Figure 3 again.", "We\u2019ve now discussed all the tricks I\u2019ve implemented in my Neural Style Transfer code. At this point, we\u2019ve substantially improved the transfer quality over the original PyTorch tutorial. Furthermore, the content_weight and style_weight are a lot more robust to the specific choice of images. For example, in the PyTorch tutorial, I found that a good style_weight on one set of images did not readily transfer to another set without proper tuning.", "That being said, it\u2019s possible to get even better results by trying to remove high frequency noise in the generated image. The most interesting approach to this that I came across was from the article Differentiable Image Parameterization \u2014 another must read which touches on similar topics. In the article, the authors generate the input_img by first parameterizing it in (decorrolated) Fourier space instead of (corrolated) pixel space. Since the input_img is generated via gradient descent, decorrelating the input acts as a preconditioner which makes optimization easier by allowing gradient descent to find minima more quickly (similar to removing correlated features in supervised learning tasks). Why that leads to higher quality transfer is not entirely clear to me, besides hand-wavy explanations like the minima found in decorrelated space are wider and more robust.", "A simpler approach is to dampen high frequency noise by penalizing it either directly or indirectly. The noise can be directly penalize by adding the total variation loss of the input_img to the optimization objective. Conversely, it\u2019s possible to implicitly penalize the noise by either blurring the input_img after each gradient descent step, or by blurring the gradients before applying them to the input_img. One issue with both approaches is that they also adversely penalize true high frequency features. This can be somewhat ameliorated by scaling down either the total variation loss or the amount of blur during training.", "If you made it this far, you should now know quite a lot about generating beautiful images with Neural Style Transfer. While conceptually simple, getting high quality results requires a lot of care. My original goal was to use Machine Learning to generate a Medium profile picture. After much trial and error, I think I\u2019ve stumbled on something that looks pretty striking. To me, the most exciting part of this whole process is the end-to-end differentiability of Neural Networks. With very little effort, we were able to \u201cinvert\u201d a model originally trained to discriminate between cats and dogs, and use it to generate countless images in a myriad different styles. Try doing that with a random forest.", "If you enjoyed this article, follow me to get notified when I post new stuff. All the code is available on my GitHub.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F75d0c05d6489&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://eugenhotaj.medium.com/?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": ""}, {"url": "https://eugenhotaj.medium.com/?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "Eugen Hotaj"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6454fd7d51dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&user=Eugen+Hotaj&userId=6454fd7d51dd&source=post_page-6454fd7d51dd----75d0c05d6489---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75d0c05d6489&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75d0c05d6489&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pytorch.org/tutorials/advanced/neural_style_tutorial.html", "anchor_text": "official PyTorch tutorial"}, {"url": "https://github.com/EugenHotaj/nn-hallucinations", "anchor_text": "my GitHub"}, {"url": "https://arxiv.org/abs/1508.06576", "anchor_text": "Gatys et al. paper"}, {"url": "https://ptrrupprecht.wordpress.com/2017/12/05/understanding-style-transfer/", "anchor_text": "this article"}, {"url": "https://www.researchgate.net/figure/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means_fig2_325137356", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/1508.06576.pdf", "anchor_text": "Gatys et al. paper"}, {"url": "https://distill.pub/2017/feature-visualization/", "anchor_text": "Feature Visualization"}, {"url": "https://github.com/EugenHotaj/nn-hallucinations", "anchor_text": "code"}, {"url": "https://distill.pub/2018/differentiable-parameterizations/#section-styletransfer", "anchor_text": "Differentiable Image Parameterization"}, {"url": "https://www.quora.com/Why-is-it-important-to-remove-correlated-features-in-machine-learning", "anchor_text": "removing correlated features"}, {"url": "https://en.wikipedia.org/wiki/Total_variation_denoising", "anchor_text": "total variation loss"}, {"url": "https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/", "anchor_text": "implicitly penalize"}, {"url": "https://github.com/EugenHotaj/nn-hallucinations", "anchor_text": "my GitHub"}, {"url": "https://reiinakano.com/2019/06/21/robust-neural-style-transfer.html", "anchor_text": "been shown"}, {"url": "https://www.reddit.com/r/MachineLearning/comments/7rrrk3/d_eat_your_vggtables_or_why_does_neural_style/", "anchor_text": "not yet understood"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----75d0c05d6489---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/neural-style-transfer?source=post_page-----75d0c05d6489---------------neural_style_transfer-----------------", "anchor_text": "Neural Style Transfer"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----75d0c05d6489---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----75d0c05d6489---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----75d0c05d6489---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F75d0c05d6489&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&user=Eugen+Hotaj&userId=6454fd7d51dd&source=-----75d0c05d6489---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F75d0c05d6489&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&user=Eugen+Hotaj&userId=6454fd7d51dd&source=-----75d0c05d6489---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75d0c05d6489&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F75d0c05d6489&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----75d0c05d6489---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----75d0c05d6489--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----75d0c05d6489--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----75d0c05d6489--------------------------------", "anchor_text": ""}, {"url": "https://eugenhotaj.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://eugenhotaj.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Eugen Hotaj"}, {"url": "https://eugenhotaj.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "235 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6454fd7d51dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&user=Eugen+Hotaj&userId=6454fd7d51dd&source=post_page-6454fd7d51dd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8c96cf49d3df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489&newsletterV3=6454fd7d51dd&newsletterV3Id=8c96cf49d3df&user=Eugen+Hotaj&userId=6454fd7d51dd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}