{"url": "https://towardsdatascience.com/optimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6", "time": 1683010994.0500648, "path": "towardsdatascience.com/optimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6/", "webpage": {"metadata": {"title": "Optimizing genomic data processing on Apache Spark | by Johan Nystr\u00f6m-Persson | Towards Data Science", "h1": "Optimizing genomic data processing on Apache Spark", "description": "A case study in optimizing a k-mer counting application on Apache Spark."}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/", "anchor_text": "Apache Spark", "paragraph_index": 2}, {"url": "https://www.scala-lang.org/", "anchor_text": "Scala programming language", "paragraph_index": 2}, {"url": "http://www.genome.umd.edu/jellyfish.html", "anchor_text": "Jellyfish", "paragraph_index": 4}, {"url": "https://homolog.us/blogs/bioinfo/2017/10/25/intro-minimizer/", "anchor_text": "minimizers", "paragraph_index": 7}, {"url": "https://www.ebi.ac.uk/ena/browser/view/PRJNA60251", "anchor_text": "PRJNA60251", "paragraph_index": 8}, {"url": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2694-8", "anchor_text": "BMC Bioinformatics 2019", "paragraph_index": 12}, {"url": "https://github.com/jtnystrom/discount", "anchor_text": "available on GitHub", "paragraph_index": 13}, {"url": "https://www.biorxiv.org/content/10.1101/2020.10.12.335364v5", "anchor_text": "available on BioRXiv", "paragraph_index": 13}, {"url": "https://www.jnpsolutions.io", "anchor_text": "https://www.jnpsolutions.io", "paragraph_index": 15}], "all_paragraphs": ["Bioinformatics generates a lot of data. \u201cOmics\u201d in particular (genomics, transcriptomics, proteomics\u2026) and its associated sequence data (such as NGS, next generation sequencing) can be computationally challenging. Processing it can consume a lot of CPU, memory and disk space. Many workloads that people may want to run can often not even be considered.", "One reason for this is that many important omics tools have been designed for operation on a single machine, and not for distributed (cluster) processing. Understandably so, since distributed processing adds new levels of difficulty to the already tricky craft of software development. However, this leads to a situation where sometimes we are expected to have access to machines with 100s of GB of RAM in order to perform, for example, taxonomic classification for metagenomics (where we identify all the different species present in a DNA sample). And even people who have such a beefy machine can\u2019t escape the fact that its memory puts a hard limit on the size of the analyses that can be run. In an age of affordable cloud computing services and commodity hardware, we should be able to do better. We would like to have the choice to run our computations on a cluster or in the cloud in an efficient way.", "Apache Spark is a powerful framework for big data analysis that has seen wide acceptance in recent years. It combines the strengths of functional programming, the MapReduce programming model, and, for those who want it, the modern Scala programming language (Python, Java and R may also be used). It manipulates large distributed collections of data and contains a query optimization engine that helps get the most out of the hardware. It is also supported by major cloud providers such as AWS and Google Cloud out of the box, but of course you could also run it on your own machines (or machine). Given all these benefits, it seems we should try to run some of our heavy omics analysis on Spark.", "However, we can\u2019t simply wrap an existing tool such as BLAST in Spark and expect it to work. In distributed computing we have to decompose the problem into relatively independent parts in order to get benefits. When we can express an algorithm in such a way, then Spark can do the heavy lifting for us and run the workload on clusters smoothly. Of course, whether this is even possible depends in each case on the algorithm or problem being considered.", "To understand the fundamentals of this space, we implemented a tool for k-mer counting. K-mers are short fragments of DNA sequences of length k. Thus, we may speak of 3-mers, 4-mers, 31-mers, and so on. k-mer analysis forms the backbone of many omics methods, including genome assembly, quality control of short reads, genome size estimation, and taxonomic classification. k-mer counting seemed to us to be the simplest problem in this space that is meaningful to solve, but still computationally challenging, and a good Spark-based solution should be a good foundation for solving other omics related problems. Essentially, in a given dataset of DNA sequences, we have to identify each distinct k-mer and count how many times each one occurs. On a single machine, traditionally you might use a tool such as Jellyfish to solve this problem. Below is an example of what the output may look like for k=28 (the full table would have billions of rows).", "How would you count k-mers in a distributed way? We can\u2019t simply use a big distributed array, since the number of potential 31-mers (for example) is huge: 4\u00b3\u00b9. We can\u2019t maintain that many counters in memory or on disk, and furthermore k might be much larger than 31. Only a tiny subset of these counters would be used in practice. With such sparse keys, binning will be essential. If you know your algorithms, you know that hash functions are generally used to distribute data into bins. This is how we create data structures such as maps and dictionaries. On Spark, this is the basis for partitioning. Good partitioning is one of the main keys to Spark performance, as it controls how the work is distributed to different worker machines. Bad partitioning leads to data skew, and under this situation you might have, for example, one worker node receiving a very large share of the data, overwhelming it. This would not only slow it down but also potentially force all the other nodes to wait for the slow node to finish. Furthermore, it might greatly increase the RAM requirement for that node (and thus all the nodes, since we can\u2019t control where the big chunk ends up). And thus we\u2019d be back where we started.", "As an analogy, imagine that a distributed pipeline is literally a system of pipes, and your workload consists of balls that you want to send through the pipes. If there are many golf balls and just one bowling ball, all the pipes have to be very wide. But if all the balls are golf balls, narrow pipes would suffice. Thus, evenly partitioning the data will be key to efficient resource usage.", "Without going into too much detail, the accepted way of hashing k-mers into bins has been a method called minimizers, and this is what tools like Jellyfish tend to use. (You might wonder why one couldn\u2019t simply use the standard string hash that comes with the programming language. The main reason is that hashing each k-mer separately causes the size of the input data to explode by 50x or more in the intermediate stages before counting. In Spark this would cause lots of slow shuffling over the network. Minimizers avoid this by hashing many adjacent k-mers together, a property that we seek to keep.)", "Minimizers work well for binning on a single machine, but can produce bins of wildly different sizes. For a distributed application, this is not ideal as we would have data skew. To counter this, we were able to develop a new hash function (a paper is in preparation), which replaces minimizers and produces a much more even partitioning. This can be measured by the size of the largest bin for a given total number of bins. Our test case is cow rumen metagenomics data, run SRR094926 from PRJNA60251. At around 1,000,000 bins, our \u201cworst\u201c bin was less than 1/100 of the minimizer case, as can be seen in the chart below (k = 28). This is very valuable, since the largest bin, by and large, dictates the memory requirement of this entire application.", "This allows us to smoothly divide the workload into a large number of small partitions, and then simply traverse each partition and count the k-mers there. When we had applied this hash and also optimized other bottlenecks, compared with a leading tool for distributed k-mer counting (which uses minimizers), our runtime was somewhat faster and memory usage was around 10% of the competing tool when applied to a cow rumen metagenomic dataset. Such low memory usage allowed us to use, for example, \u201chighcpu\u201d nodes on Google Cloud, which have less RAM and which are cheaper than normal nodes per hour. The innovation resulted in cost savings. Alternatively, we could have used the normal nodes but analysed 10x more data without running out of resources. Thus we arrive at an efficient, economical, and scalable way of counting k-mers in a distributed fashion, and hopefully a basis for other useful tools in this space.", "Many lessons were learned during this journey, but our main insight at this point has been that finding a way to eliminate data skew is very helpful for Spark performance. By doing this we were able to improve performance and reduce memory usage by 90%. Depending on the situation, going as far as to develop one\u2019s own hash function or custom partitioning scheme may be well worth the investment. For k-mers in omics data, it can change the tradeoffs completely.", "More generally, when we make the move from running an algorithm on a single machine to running on a cluster, completely new issues can arise. To get the best results from Spark, it is necessary to understand and address these issues as they come up. If these issues can be dealt with, Spark can be a very good choice for the distributed (cloud or cluster) processing of omics data.", "Finally, I would like to acknowledge FastKmer by U.F. Petrillo et al (BMC Bioinformatics 2019) which provided some important inspiration and ideas for our k-mer counting implementation.", "Update (November 2020): The code behind this work has, after further development, been released as part of the application Discount (available on GitHub). The hash function that I described above has now evolved into the \u201cuniversal frequency ordering\u201d for minimizers. A related paper, which describes our latest results and contains much more detail on this topic, is available on BioRXiv.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software and bioinformatics researcher and consultant based in Japan. Spark/Scala developer. https://www.jnpsolutions.io"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3333d6d41ed6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jtnystrom?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jtnystrom?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "Johan Nystr\u00f6m-Persson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe49554650ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&user=Johan+Nystr%C3%B6m-Persson&userId=e49554650ab4&source=post_page-e49554650ab4----3333d6d41ed6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3333d6d41ed6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3333d6d41ed6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@5tep5?utm_source=medium&utm_medium=referral", "anchor_text": "Alexander Popov"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://spark.apache.org/", "anchor_text": "Apache Spark"}, {"url": "https://www.scala-lang.org/", "anchor_text": "Scala programming language"}, {"url": "http://www.genome.umd.edu/jellyfish.html", "anchor_text": "Jellyfish"}, {"url": "https://homolog.us/blogs/bioinfo/2017/10/25/intro-minimizer/", "anchor_text": "minimizers"}, {"url": "https://www.ebi.ac.uk/ena/browser/view/PRJNA60251", "anchor_text": "PRJNA60251"}, {"url": "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2694-8", "anchor_text": "BMC Bioinformatics 2019"}, {"url": "https://github.com/jtnystrom/discount", "anchor_text": "available on GitHub"}, {"url": "https://www.biorxiv.org/content/10.1101/2020.10.12.335364v5", "anchor_text": "available on BioRXiv"}, {"url": "https://medium.com/tag/bioinformatics?source=post_page-----3333d6d41ed6---------------bioinformatics-----------------", "anchor_text": "Bioinformatics"}, {"url": "https://medium.com/tag/spark?source=post_page-----3333d6d41ed6---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/genomics?source=post_page-----3333d6d41ed6---------------genomics-----------------", "anchor_text": "Genomics"}, {"url": "https://medium.com/tag/big-data?source=post_page-----3333d6d41ed6---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/performance?source=post_page-----3333d6d41ed6---------------performance-----------------", "anchor_text": "Performance"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3333d6d41ed6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&user=Johan+Nystr%C3%B6m-Persson&userId=e49554650ab4&source=-----3333d6d41ed6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3333d6d41ed6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&user=Johan+Nystr%C3%B6m-Persson&userId=e49554650ab4&source=-----3333d6d41ed6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3333d6d41ed6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3333d6d41ed6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3333d6d41ed6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3333d6d41ed6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jtnystrom?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jtnystrom?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Johan Nystr\u00f6m-Persson"}, {"url": "https://medium.com/@jtnystrom/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "23 Followers"}, {"url": "https://www.jnpsolutions.io", "anchor_text": "https://www.jnpsolutions.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe49554650ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&user=Johan+Nystr%C3%B6m-Persson&userId=e49554650ab4&source=post_page-e49554650ab4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb260fba3db01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6&newsletterV3=e49554650ab4&newsletterV3Id=b260fba3db01&user=Johan+Nystr%C3%B6m-Persson&userId=e49554650ab4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}