{"url": "https://towardsdatascience.com/a-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42", "time": 1682996663.069959, "path": "towardsdatascience.com/a-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42/", "webpage": {"metadata": {"title": "A Game of Words: Vectorization, Tagging, and Sentiment Analysis | by Madeline McCombe | Towards Data Science", "h1": "A Game of Words: Vectorization, Tagging, and Sentiment Analysis", "description": "Full disclosure: I haven\u2019t watched or read Game of Thrones, but I am hoping to learn a lot about it by analyzing the text. If you would like more background about the basic text processing, you can\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@madelinemccombe/text-processing-is-coming-c13a0e2ee15c", "anchor_text": "other article", "paragraph_index": 0}, {"url": "https://www.kaggle.com/khulasasndh/game-of-thrones-books#005ssb.txt", "anchor_text": "on Kaggle", "paragraph_index": 0}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/TextAnalysis_GoT2.ipynb", "anchor_text": "my github", "paragraph_index": 3}, {"url": "https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/", "anchor_text": "found here", "paragraph_index": 4}, {"url": "https://monkeylearn.com/blog/beginners-guide-text-vectorization/", "anchor_text": "read more here", "paragraph_index": 6}, {"url": "https://medium.com/@paritosh_30025/natural-language-processing-text-data-vectorization-af2520529cf7", "anchor_text": "this method here", "paragraph_index": 7}, {"url": "https://medium.com/explore-artificial-intelligence/introduction-to-named-entity-recognition-eda8c97c2db1", "anchor_text": "this article", "paragraph_index": 12}, {"url": "https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da", "anchor_text": "found here", "paragraph_index": 13}, {"url": "https://pythonprogramming.net/chinking-nltk-tutorial/", "anchor_text": "found here", "paragraph_index": 15}, {"url": "https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b", "anchor_text": "found here", "paragraph_index": 16}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/TextAnalysis_GoT2.ipynb", "anchor_text": "github code", "paragraph_index": 17}, {"url": "https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis", "anchor_text": "explained here", "paragraph_index": 20}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "VADER Sentiment Analysis", "paragraph_index": 23}, {"url": "https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f", "anchor_text": "found here", "paragraph_index": 23}, {"url": "https://medium.com/@datamonsters/sentiment-analysis-tools-overview-part-2-7f3a75c262a3", "anchor_text": "explained here", "paragraph_index": 23}, {"url": "https://pypi.org/project/polyglot/", "anchor_text": "Polyglot", "paragraph_index": 24}, {"url": "https://pypi.org/project/gensim/", "anchor_text": "Genism", "paragraph_index": 24}, {"url": "https://medium.com/activewizards-machine-learning-company/comparison-of-top-6-python-nlp-libraries-c4ce160237eb", "anchor_text": "information here", "paragraph_index": 24}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/TextAnalysis_GoT2.ipynb", "anchor_text": "here on github", "paragraph_index": 26}, {"url": "https://towardsdatascience.com/text-processing-is-coming-c13a0e2ee15c", "anchor_text": "found here", "paragraph_index": 27}], "all_paragraphs": ["Full disclosure: I haven\u2019t watched or read Game of Thrones, but I am hoping to learn a lot about it by analyzing the text. If you would like more background about the basic text processing, you can read my other article. The text from all 5 books can be found on Kaggle. In this article I will be taking the cleaned text and using it to explain the following concepts:", "Currently, I have a list of lemmatized words, but how can I structure them in a way that a machine will be able to understand? I am going to explore a couple vectorization methods, which turn a list of words into an array of numbers that can be used for different machine learning methods. When doing this, it is important to make sure that stopwords and other non-essential words are removed from the text, so that the array/vector system created will have only important dimensions to model on.", "One method is called Bag-of-Words, which defines a dictionary of unique words contained in the text, and then finds the count of each word within the text. For example, if I were to collect a list of unique words from A Game of Thrones, and then split the full list into words by chapter, I would end up with an array that has one chapter per row and the counts of each word going across the columns. The drawbacks to this method are that it does not preserve the order of the words ([fall, death] and [fall, love] have very different meanings), and that it doesn\u2019t capture any actual meaning of the words. Also, if we were splitting the text by chapter, chapters with more words would be unintentionally weighted more heavily, as they would have high counts across the row. However, this is still a good way to see a distribution of terms and is useful if you are looking to see how many times a particular word shows up. Here is an implementation of this on the game of thrones text, split by chapter:", "In this example, page_lemm is a list of length 572 (number of pages), with each element being a string of words on that page. The CountVectorizer() function automatically tokenizes and counts the words in all of the strings. I did some behind the scenes removal of stopwords and lemmatization before using the code above, which you can see on my github. This code creates a dataframe, where each row corresponds to a chapter of the book, and each column corresponds to one unique word within the text. The body of the frame contains the count of each word per chapter.", "Another method that fixes some of the issues with Bag-of-Words is called TF-IDF, or term frequency-inverse document frequency. TF-IDF is similar to the previous method, except the value in each column for each row is scaled by the number of terms in the document and the relative rarity of the word. Term frequency equals the number of times a word appears in a document divided by the total number of words in the document. Inverse document frequency calculates the weight of rare words in all documents in the corpus, with rare words having a high IDF score, and words that are present in all documents in a corpus having IDF close to zero. This allows words that may have a lot of meaning to still be influential in the final analysis if they are rare. Think of it this way-would it be better to know that the word \u2018hand\u2019 is used in all chapters of a book, or would it be more influential to know that \u2018death\u2019 only occurs in 10 of them? The TF and IDF are multiplied together to reach the final TF-IDF score. A great step-by-step of this process can be found here. The scikit-learn package (sklearn) in Python has a function TfidfVectorizer() that will compute the TF-IDF values for you, shown here:", "As you can see, the code for these two methods is very similar and takes the same inputs, but gives different contents within the dataframe. Instead of the count of each word, the TF-IDF score is calculated. Here is a comparison of the top 10 words according to average Bag of Words count and the top 10 words according to average TF-IDF score. There is some overlap, but TF-IDF gives names of characters higher average scores than Bag of Words. I highlighted the words that do not overlap between the two approaches.", "Skip-Thought Vectors is another method of vectorization that predicts the surroundings of sentences using transfer learning in a neural network. Transfer learning is the concept that a machine can apply what it \u2018learns\u2019 from one task onto another task. This is the thought behind almost every machine learning technique, as we are trying to get machines to learn at a rate that is faster and more quantifiable than the way humans learn. For text processing especially, the idea is that an algorithm builds a neural network that learns from thousands of different books and figures out sentence structures, themes, and general patterns. This algorithm can then be applied to a book it hasn\u2019t read yet, and it can predict or model the sentiment or themes within the text. You can read more here about this method and how it compares to TF-IDF.", "Another method of vectorization that leans heavily on neural networks is word2vec, which calculates the cosine similarity between two words, and plots words in space so that similar words are grouped together. You can read about a neat implementation of this method here.", "Now that you have an array of numbers, what next? With Bag of Words, you can perform a logistic regression or other classification algorithm to show what documents (rows) within the array are most similar. This can be helpful when trying to see if two articles are related in topic. Skip Thought Vectors and Word2Vec both cluster words based on meaning within a text, which is a method called word embedding. This technique is important because it preserves relationships among words. Especially when dealing with review text data (anything with a numerical rating accompanying the text review), these techniques can yield valuable insights about what the consumers are feeling and thinking. Since A Game of Thrones does not have default values for classification, I have no way of validating a model, I am going to explain alternative methods of analyzing a text below.", "Part of Speech tagging (POS) is where a part of speech is assigned to each word in a list using context clues. This is useful because the same word with a different part of speech can have two completely different meanings. For example, if you have two sentences [\u2018A plane can fly\u2019 and \u2018There is a fly in the room\u2019], it would be important to define \u2018fly\u2019 and \u2018fly\u2019 correctly in order to determine how the two sentences are related (aka not at all). Tagging words by part of speech allows you to do chunking and chinking which is explained later. An important note is that POS tagging should be done straight after tokenization and before any words are removed so that sentence structure is preserved and it is more obvious what part of speech the word belongs to. One way to do this is by using nltk.pos_tag():", "[\u2018\u201cDead is dead,\u201d he said. \u201cWe have no business with the dead.\u201d \u2018, \u2018\u201cAre they dead?\u201d Royce asked softly. \u201cWhat proof have we?\u201d \u2018]", "Here is a snippet of what was created above, and you can see that adjectives are represented as \u2018JJ\u2019, nouns as \u2018NN\u2019, and so on. This information will be used when chunking later.", "Sometimes it is helpful to further define the parts of speech for special words, especially when trying to process articles about current events. Beyond being nouns, \u2018London\u2019, \u2018Paris\u2019, \u2018Moscow\u2019, and \u2018Sydney\u2019 are all locations that have specific meaning attached to them. The same goes for names of people, organizations, times, money, percents, and dates among other things. This process is important in text analysis because it can be a way to go about understanding chunks of text. Generally, to apply NER to a text, tokenization and POS tagging must have been performed previously. The nltk package has two methods to do NER built in, both of which are explained well in this article.", "Another useful way to perform NER and have the capability to visualize and sort the results is through the spaCy package. A good walkthrough of this can be found here. I explored the GOT text using this method, and had some interesting results:", "In the code above, document3 is the full text of A Game of Thrones in a single string. This package efficiently found and classified all types of entities. It was a bit confused on some instances of Gared (at one point it classified him as PERSON, another as ORG, and another later on as WORK_OF_ART). However, overall this gave more insight into the content of the text than just POS tagging did. A count of how many matches per type of entity and the top entities found is below. Unsurprisingly, there were a lot of names found in the text.", "Chunking and chinking are two methods used to extract meaningful phrases from a text. They combine POS tagging and Regex to produce text snippets that match the phrase structures requested. One implementation of chunking is to find phrases that provide descriptions of different nouns, called noun phrase chunking. The form of a noun phrase chunk is generally composed of a determinant/possessive, adjectives, a possible verb, and the noun. If you find that your chunks have part that you do not want, or that you\u2019d rather split the text on a specific POS, an easy way to achieve your goal is by chinking. This defines a small chunk (called a chink) that should be removed or split on when chunking. I am not going to explore chinking in this article, but a tutorial can be found here.", "The easiest way to do specific types of chunking with NLTK is using the nltk.RegexpParser(r\u2018<><><>\u2019). This allows you to specify your noun phrase formula, and is very easy to interpret. Each <> references the part of speech of one word to match, and normal regex syntax applies within each <>. This is very similar to the nltk.Text().findall(r\u2019<><><>\u2019) concept, but just with POS instead of actual words. A couple of things to note when creating the Regex string to parse is that the part of speech abbreviations (NN=noun, JJ=adjective, PRP=preposition, etc.) can vary between packages, and sometimes it is good to start more specific and then broaden your search. If you\u2019re super lost right now, a good intro to this concept can be found here. Also, it may be a good idea to brush up on sentence structures and parts of speech before so that you can fully interpret what the chunking returns. Here is an example of this applied to GOT:", "This is a very similar idea to NER, as you can group NN or NNP (nouns or proper nouns) together to find full names of objects. Also the pattern to match can be any combination of parts of speech, which is useful when looking for certain kinds of phrases. However, if the POS tagging is incorrect, you will not be able to find the types of phrases you are looking for. I only looked for noun phrases here, but there are more types of chunks included in my github code.", "Sentiment Analysis is how a computer combines everything covered so far and comes up with a way to communicate the overall gist of a passage. It compares the words in a sentence, paragraph, or another subset of text to a list of words in a dictionary and calculates a sentiment score based on how the individual words in a sentence are categorized. This is mostly used in analyzing reviews, articles, or other opinion pieces, but I am going to apply this to GOT today. I am mainly interested in seeing if the overall tone of the book is positive or negative, and it that tone varies between chapters. There are two ways of doing sentiment analysis: you can train and test a model on previously categorized text and then use that to predict whether new text of the same type will be positive or negative, or you can simply use an existing lexicon built into the function that will analyze and report a positive or negative score. Here is an example of the latter or some sentences from the first page of A Game of Thrones:", "Since this is analyzing text of a book and not text of reviews, a lot of the sentences are going to have a neutral compound score (0). This is totally fine for my purposes however, because I am just looking for general trends in the language of the book over time. But it is still nice to see that when dead is mentioned a negative score is applied.", "TextBlob is another useful package that can perform sentiment analysis. Once you turn your text into a TextBlob object (textblob.textBlob()), it has functions to tokenize, lemmatize, tag plain text, and make a WordNet, which quantifies the similarity between words. There are a lot of different text objects specific to this package that allow for really cool transformations, explained here. There is even a correct() function that will attempt to correct spelling mistakes. I am not going to go into most of these in this article, as I am trying to analyze a book which should generally have correct spelling and syntax, however many of these tools would be useful when dealing with particularly messy text data. Here is TextBlob\u2019s version of sentiment analysis on the first page of A Game of Thrones:", "\u201cDo the dead frighten you?\u201d Sentiment(polarity=-0.2, subjectivity=0.4) Ser Waymar Royce asked with just the hint of a smile. Sentiment(polarity=0.3, subjectivity=0.1) Gared did not rise to the bait. Sentiment(polarity=0.0, subjectivity=0.0)", "There is similarity between the sentiment scores of nltk and textblob, but the nltk version has more variability since it is a compound score. The textblob sentiments alternatively have a subjectivity score, which is good for telling how accurately a sentence may be classified. Below is a distribution of the sentiments by page per method. Textblob overall gave higher sentiment ratings, whereas nltk had more variance with the score.", "If you are trying to gather sentiment from social media text or emojis, the VADER Sentiment Analysis is a tool specifically curated for that task. It has built in slang (lol, omg, nah, meh, etc.) and can even understand emojis. A good walkthrough of how to use it can be found here. Also, if Python is not your go to language for text analysis, there are other methods in different languages/software to do sentiment analysis that are explained here.", "I only explained functions the nltk, textblob, vaderSentiment, spacy, and sklearn packages in this article, but there are many advantages and disadvantages to them depending on the task you\u2019re trying to accomplish. Some others that may be better suited to your task are Polyglot and Genism. Polyglot is known for having the ability to analyze a large number of languages (supports 16\u2013196 depending on the task). Genism is primarily used for unsupervised learning tasks on text, and will need any preprocessing to be done with a different package. You can find a handy chart with all this information here.", "One key thing that I\u2019ve learned from writing this article is that there are always at least three ways to accomplish a single task, and determining the best option just depends on what kind of data you are using. Sometimes you are going to prioritize computation time, and other times you will need a package that can do unsupervised learning well. Text processing is a fascinating science, and I cannot wait to see where it leads us in the next few years. In this article I covered vectorization and how that can determine similarity between text, tagging which allows meaning to be attached to words, and sentiment analysis which tells roughly how positive or negative a text is. I have gleaned many insights from Game of Thrones, like there is a lot of death, sir is a common title spelled Ser, and there are not as many instances of dragons as I was led to believe. However, I may be convinced to read the books now! I hope you enjoyed the article!", "A copy of my code, which has further examples and explanation, can be found here on github! Feel free to take and use the code as you please.", "My other article \u2018Text Preprocessing Is Coming\u2019 can be found here!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc78ff9a07e42&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@madelinemccombe?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@madelinemccombe?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "Madeline McCombe"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa4a48b9cfaca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&user=Madeline+McCombe&userId=a4a48b9cfaca&source=post_page-a4a48b9cfaca----c78ff9a07e42---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc78ff9a07e42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc78ff9a07e42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/simisi1-5920903/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4180794", "anchor_text": "simisi1"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4180794", "anchor_text": "Pixabay"}, {"url": "https://medium.com/@madelinemccombe/text-processing-is-coming-c13a0e2ee15c", "anchor_text": "other article"}, {"url": "https://www.kaggle.com/khulasasndh/game-of-thrones-books#005ssb.txt", "anchor_text": "on Kaggle"}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/TextAnalysis_GoT2.ipynb", "anchor_text": "my github"}, {"url": "https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/", "anchor_text": "found here"}, {"url": "https://monkeylearn.com/blog/beginners-guide-text-vectorization/", "anchor_text": "read more here"}, {"url": "https://medium.com/@paritosh_30025/natural-language-processing-text-data-vectorization-af2520529cf7", "anchor_text": "this method here"}, {"url": "https://medium.com/explore-artificial-intelligence/introduction-to-named-entity-recognition-eda8c97c2db1", "anchor_text": "this article"}, {"url": "https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da", "anchor_text": "found here"}, {"url": "https://pythonprogramming.net/chinking-nltk-tutorial/", "anchor_text": "found here"}, {"url": "https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b", "anchor_text": "found here"}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/TextAnalysis_GoT2.ipynb", "anchor_text": "github code"}, {"url": "https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis", "anchor_text": "explained here"}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "VADER Sentiment Analysis"}, {"url": "https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f", "anchor_text": "found here"}, {"url": "https://medium.com/@datamonsters/sentiment-analysis-tools-overview-part-2-7f3a75c262a3", "anchor_text": "explained here"}, {"url": "https://pypi.org/project/polyglot/", "anchor_text": "Polyglot"}, {"url": "https://pypi.org/project/gensim/", "anchor_text": "Genism"}, {"url": "https://medium.com/activewizards-machine-learning-company/comparison-of-top-6-python-nlp-libraries-c4ce160237eb", "anchor_text": "information here"}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/TextAnalysis_GoT2.ipynb", "anchor_text": "here on github"}, {"url": "https://towardsdatascience.com/text-processing-is-coming-c13a0e2ee15c", "anchor_text": "found here"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c78ff9a07e42---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/nlp?source=post_page-----c78ff9a07e42---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/text?source=post_page-----c78ff9a07e42---------------text-----------------", "anchor_text": "Text"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----c78ff9a07e42---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c78ff9a07e42---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc78ff9a07e42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&user=Madeline+McCombe&userId=a4a48b9cfaca&source=-----c78ff9a07e42---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc78ff9a07e42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&user=Madeline+McCombe&userId=a4a48b9cfaca&source=-----c78ff9a07e42---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc78ff9a07e42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc78ff9a07e42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c78ff9a07e42---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c78ff9a07e42--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@madelinemccombe?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@madelinemccombe?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Madeline McCombe"}, {"url": "https://medium.com/@madelinemccombe/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "189 Followers"}, {"url": "http://www.linkedin.com/in/madelinemccombe", "anchor_text": "www.linkedin.com/in/madelinemccombe"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa4a48b9cfaca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&user=Madeline+McCombe&userId=a4a48b9cfaca&source=post_page-a4a48b9cfaca--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc57fe1f09258&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42&newsletterV3=a4a48b9cfaca&newsletterV3Id=c57fe1f09258&user=Madeline+McCombe&userId=a4a48b9cfaca&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}