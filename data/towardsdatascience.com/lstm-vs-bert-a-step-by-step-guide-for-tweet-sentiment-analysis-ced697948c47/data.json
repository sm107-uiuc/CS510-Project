{"url": "https://towardsdatascience.com/lstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47", "time": 1683015983.6004858, "path": "towardsdatascience.com/lstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47/", "webpage": {"metadata": {"title": "LSTM vs BERT \u2014 a step-by-step guide for tweet sentiment analysis | by Yuki Takahashi | Towards Data Science", "h1": "LSTM vs BERT \u2014 a step-by-step guide for tweet sentiment analysis", "description": "Note from Towards Data Science\u2019s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author\u2019s contribution. You should\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/questions-96667b06af5", "anchor_text": "rules and guidelines", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/readers-terms-b5d780a700a4", "anchor_text": "Reader Terms", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/nlp-in-the-financial-market-sentiment-analysis-9de0dda95dc?source=friends_link&sk=9bb03bc7e108c125499bc9cf1996bd49", "anchor_text": "the sentiment analysis on financial text", "paragraph_index": 1}, {"url": "https://github.com/yuki678", "anchor_text": "https://github.com/yuki678", "paragraph_index": 32}], "all_paragraphs": ["Note from Towards Data Science\u2019s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author\u2019s contribution. You should not rely on an author\u2019s works without seeking professional advice. See our Reader Terms for details.", "After seeing the competitive result of BERT in the sentiment analysis on financial text, I performed another preliminary study on more informal text as the ultimate goal is to analyse traders\u2019 voice over the phones and chat in addition to the news sentiment. In this post, I let LSTM and BERT analyse a number of tweets from Stocktwit.", "Unlike formal financial text, traders voice and chat contains by far informal languages. Traditional rule based models or simple vectorisation techniques such as BoW, Tfidf, word2vec saw poor performance in my past research because of the fact that", "LSTM, which has been one of the most famous RNN based model in NLP, performed well. It is largely thanks to the fact that", "On the other hand, BERT I used here was pretrained on wikipedia, where the language is pretty different. Training BERT from scratch was not option due to the limitation of resources. In this situation, would it still be worth trying BERT for better performance than LSTM?", "The input text here is taken from Stocktwits as the similar language of traders\u2019 voice here. There are around one million tweets that have been hand-labelled with 0 (negative) to 4 (positive), which have been loaded as messages and sentiments list respectively. Note that actual environments usually need a lot more work to do on preparing the inputs such as the sound recognition, data clean-up, streaming infra. This post skip those steps and start from the point where the data have been loaded.", "Before the training, the input texts need preprocessing such as removing URL, ticker symbols, @mentions, symbols etc. Here I simply remove them as it will not be available in voices, but there\u2019re also interesting researches on how to utilise such information such as emoticons and hashtags rather than removing them if the final goal is to analyse the tweet text.", "Now the input has been cleaned up as follows.", "The next step is to tokenize the text. Here, I use python NLTK library but also give options to use different ways to see what works best for the input. After a few experiments, I decided to use nltk.word_tokenize() without the lemmatization and stopword removal.", "Once the input text is tokenized, we can create a corpus and vocab in the following manner. Word Cloud or bar chart is a good way to quickly view the frequent words in the input. The distribution shows the label is imbalanced having more neutral than other sentiments. It is possible to balance the data by resampling (under- or over-) but here take as they are because this ratio would represent actual occurrence of the sentiment in the tweet stream.", "Now that the input data are ready, create the neural network based model and tokenizer for the model.", "Use pytorch to create a LSTM based model. The class extends torch.nn.Module and define the layers as embedding \u2192 lstm \u2192 dropout \u2192 dense (fully-connected) \u2192 output (softmax). The tokenizer for LSTM is to pad the input to the right or to the left up to the specified maximum length and truncate if the input exceeds the maximum length, designed to be used during the training for each batch instead of preprocess all inputs.", "Here I use the Hugging Face implementation of BERT. Simply use their transformers and pre-trained model and tokenizer.", "Create a dataset class and data loader for batching. There are many different ways to define them and this is just a very simple solution to be used with the defined tokenizer which returns torch.tensor.", "The performance was measured in terms of accuracy, f1 and training time for different input sizes. Use Stratified Shuffle Split from scikit-learn that can perform under-sampling by preserving the label distrubtion, based on given train and test size. In each loop, measure the duration by perf_counter() for completing the training.", "Also, define a simple function to return Accuracy and F1 score.", "Note that model parameters are defined here when instantiating the model classes, which can be updated according to the input data.", "Define the training process as follows:", "AdamW Optimizer and Linear Schedule with Warmup for the learning rate are used but these can be swapped with other options as needed.", "In each training batch cycle, tokenize the input messages and move to torch.tensor, perform the feedforward prediction, calculate the loss and back propagate to update the weights. Clipping to avoid exploding gradient problem before the next batch step.", "At the end of each epoch shows Confusion Matrix and scores/loss for both training and validation data.", "After the first epoch of the smallest samples (n=1,000), the model simply classify all data as \u2018Neutral\u2019, which is reasonable as the \u2018Neutral\u2019 is the majority class.", "Completing the five epochs, it looks to have classified the data almost at random. It starts overfitting to the training data from the third epoch (= validation cycle = 10).", "The largest dataset (n=500,000) contains 500 times more data than the first cycle. It performed much better and now classify most of labels correctly. Overfitting from the fourth cycle, so three epochs will be the best.", "Three epochs of training the pretrained BERT took almost the same time as the five epochs of the above LSTM model.", "BERT shows the similar result but it starts overfitting in third epoch for the largest dataset (n = 500,000).", "As shown below, it naturally performed better as the number of input data increases and reach 75%+ score at around 100k data. BERT performed a little better than LSTM but no significant difference when the models are trained for the same amount of time.", "In this post, tweets from stockswits are cleaned, tokenized and analyzed to predict the sentiment by a LSTM model as well as a pretrained BERT model.", "Given the same resource and time, the pretrained BERT perfomed slightly better than LSTM but no significant difference.", "Potentially, training the BERT model from scratch on similar tweets could produce much better result, while the required resources and cost is beyond this study.", "Here is a piece of code which handles tweet stream as input and output the sentiment with confidence level, using the trained model above.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A product manager in London. Github \u2014 https://github.com/yuki678"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fced697948c47&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ced697948c47--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ced697948c47--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://yuki678.medium.com/?source=post_page-----ced697948c47--------------------------------", "anchor_text": ""}, {"url": "https://yuki678.medium.com/?source=post_page-----ced697948c47--------------------------------", "anchor_text": "Yuki Takahashi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3acb9d6e47b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&user=Yuki+Takahashi&userId=3acb9d6e47b8&source=post_page-3acb9d6e47b8----ced697948c47---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fced697948c47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fced697948c47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/questions-96667b06af5", "anchor_text": "rules and guidelines"}, {"url": "https://towardsdatascience.com/readers-terms-b5d780a700a4", "anchor_text": "Reader Terms"}, {"url": "https://towardsdatascience.com/nlp-in-the-financial-market-sentiment-analysis-9de0dda95dc?source=friends_link&sk=9bb03bc7e108c125499bc9cf1996bd49", "anchor_text": "the sentiment analysis on financial text"}, {"url": "https://medium.com/tag/nlp?source=post_page-----ced697948c47---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/ai?source=post_page-----ced697948c47---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ced697948c47---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/bert?source=post_page-----ced697948c47---------------bert-----------------", "anchor_text": "Bert"}, {"url": "https://medium.com/tag/finance?source=post_page-----ced697948c47---------------finance-----------------", "anchor_text": "Finance"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fced697948c47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&user=Yuki+Takahashi&userId=3acb9d6e47b8&source=-----ced697948c47---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fced697948c47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&user=Yuki+Takahashi&userId=3acb9d6e47b8&source=-----ced697948c47---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fced697948c47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ced697948c47--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fced697948c47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ced697948c47---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ced697948c47--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ced697948c47--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ced697948c47--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ced697948c47--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ced697948c47--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ced697948c47--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ced697948c47--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ced697948c47--------------------------------", "anchor_text": ""}, {"url": "https://yuki678.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://yuki678.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yuki Takahashi"}, {"url": "https://yuki678.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "385 Followers"}, {"url": "https://github.com/yuki678", "anchor_text": "https://github.com/yuki678"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3acb9d6e47b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&user=Yuki+Takahashi&userId=3acb9d6e47b8&source=post_page-3acb9d6e47b8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F23923a612f87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47&newsletterV3=3acb9d6e47b8&newsletterV3Id=23923a612f87&user=Yuki+Takahashi&userId=3acb9d6e47b8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}