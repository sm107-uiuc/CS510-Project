{"url": "https://towardsdatascience.com/data-mesh-applied-21bed87876f2", "time": 1683002134.9138591, "path": "towardsdatascience.com/data-mesh-applied-21bed87876f2/", "webpage": {"metadata": {"title": "Data Mesh Applied. Subtitle: Moving step-by-step from mono\u2026 | by Sven Balnojan | Towards Data Science", "h1": "Data Mesh Applied", "description": "How does a 21st-century data landscape look like? Zhamak Deghani from ThoughtWorks gave a beautiful and, for me, surprising answer: It\u2019s decentralized and very different from what we see in almost\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/theres-more-than-one-kind-of-data-mesh-three-types-of-data-meshes-7cb346dc2819", "anchor_text": "three kinds of data meshes", "paragraph_index": 0}, {"url": "https://martinfowler.com/articles/data-monolith-to-mesh.html", "anchor_text": "data mesh", "paragraph_index": 3}, {"url": "https://domainlanguage.com/ddd/", "anchor_text": "DDD", "paragraph_index": 6}, {"url": "http://thdpth.com/", "anchor_text": "free newsletter \u201cThree Data Point Thursday\u201d", "paragraph_index": 89}, {"url": "http://thdpth.com/", "anchor_text": "http://thdpth.com/", "paragraph_index": 92}], "all_paragraphs": ["(also check out the follow-up article: three kinds of data meshes)", "How does a 21st-century data landscape look like? Zhamak Deghani from ThoughtWorks gave a beautiful and, for me, surprising answer: It\u2019s decentralized and very different from what we see in almost any company currently. The answer is called a \u201cdata mesh\u201d.", "If you feel the pain of current data architecture in your company, as I do, then you want to move to a data mesh. But how? That is what I explore in this article.", "But first, a short recap on the data mesh.", "Twitter Summary of the data mesh", "Modern software development needs a decentralized approach to data. Data must be considered a product by its generating team; They need to serve it; Analytics teams and software teams need to change!", "DDD, microservices & DevOps changed the way we develop software in the last decade. Data in the analytics department, however, did not catch up to that. To speed up decision making based on data in a company with a modern development approach, analytics & software teams need to change.", "(1) software teams must consider data a product they serve to everybody else, including analytics teams", "(2) analytics teams must build on that, stop hoarding data and instead pull it in on-demand", "(3) analytics teams must start to consider their data lakes/ data warehouses as data products as well.", "If the short summary appeals to you, let me walk you through how to actually get to a data mesh from your current starting point. We will walk through an example, pass by legacy monoliths, data lakes and data warehouses on our way. We move step by step from our \u201cold\u201d system to this new one.", "SIDENOTE: Calling data lakes \u201cold\u201d might seem odd to you and it does to me as well. James Dixon, then CTO/ founder of Pentaho, imagined the concept of a data lake only 10 years ago. However, the central shifts in what surrounds data lakes, that is the software, DevOps, DDD, micro-services also only emerged in the last decade. So we do need to catch up, as the central all-mighty data lake is an answer to an old problem before those trends changed how we develop software at all. And besides, an all-mighty data lake is not what Dixon imagined in the first place.", "We start with an example of our typical micro-service architecture for an e-commerce business.", "That\u2019s a basic microservice architecture, with two domains, a \u201ccustomer domain\u201d with a customer API and a CRM system and an \u201corder domain\u201d, together with an order API. These services are operational services, they run the e-commerce website. These APIs let you create orders at the order API, customers at the customer API leads in the CRM system, check credit-lines and so on. They might be REST APIs, combined with some Event Stream, some Pub-Sub system, the specific implementation doesn\u2019t really matter.", "SIDENOTE: For us, orders and customers are different domains. That means the language in those domains might differ. A \u201ccustomer\u201d seen from team 2, the order team, has exactly one meaning, someone identified by a customer_id, that just bought something on the website. On team 1 the meaning might differ. They might consider a customer an entity from the CRM system, which can change the state from a mere \u201clead\u201d to a \u201cbuying\u201d customer, only the second one is known at the team 2 side.", "Team 1 owns the customer domain. They know this domain by heart. They know what a lead is, how the transition states from leads to actual customers are and so on. On the other hand team 2 knows everything about the order domain. They know whether a canceled order can be restored, how the order funnel on the website looks like and much more. The teams might know a little bit about the other domain, but not all the details. They don\u2019t own them.", "Both domains generate a lot of data as a byproduct. Lots of people in the organization need those data. Let\u2019s take a look at some of them:", "The data lake/ data warehouse solution to those requirements will emerge as something like this.", "A central team of data engineers would most likely be supplying all the data, via ETL tools or streaming solutions. They will have a central data lake or data warehouse, and a BI frontend up to use for marketing & management.", "Data scientists might take data straight from the data lake which is probably the simplest way for them to access the data.", "What possible problems do we see with this architecture?", "Here is the same e-commerce website with a data mesh architecture.", "What changed? For starters, data scientists & marketing people can access data from the source domain! But there\u2019s much more.", "SIDENOTE: The key to the data mesh architecture is to get the data DATSIS. Discoverable, addressable, trustworthy, self-describing, inter-operable & secure.", "Let\u2019s walk through the points step-by-step", "allCustomers/: Serving data one \u201ccustomer\u201d per line.", "allOrderItems/: Serving one order line item per line.", "allBuckets/: serving one bucket, which is a collection of order items, per line.", "- As CSV/parquet files located in a AWS S3 bucket (endpoints separated by subfolders, APIs separated by top-level folders) (addressable)", "- As REST APIs via JSON/ JSON lines", "- Through a central database and schemata.(Yes I get that \u201ccentral\u201d is not \u201cdecentralized\u201d)", "The data team is still there, but the possible load is appropriately distributed to decentralized actors, which are better suited for the job anyway. However, the data team also has its own service. How could that look like exactly? Let\u2019s see how a data lake still does fit into the data mesh & the possible pain points. There is an important transition state if you start with one.", "There are three situations a, now not necessarily central, data lake or warehouse still makes sense:", "When should you consider moving to a data mesh? First of all, if you\u2019re happy with your structure, if you\u2019re happy with the way your company uses data to make decisions, then don\u2019t. But if you feel any of the following pains, the solution is the data mesh.", "Let\u2019s get real. A data warehouse or a data lake, together with a central analytics team responsible for importing and modeling data. A legacy monolith from where the team imports data without APIs, possibly with direct database access and lots, lots of ETL jobs, tables, etc. Maybe we got some new microservices in new domains\u2026 Let\u2019s keep this simple but generic.", "SIDENOTE: I like Michael Feathers definition of legacy code: code without tests. And that\u2019s what I mean, big, ugly, unhappy code which no-one likes to work with.", "Remember, the goal is to get all the data DATSIS, step-by-step.", "Step 1: (Addressable data) Reroute Data Lake data & change BI Tool access.", "All the data is currently consumed & served through the data lake. If we want to change that, we first need to turn the big switch there, while fixing the standardization of addressability for future migration.", "For the purpose let\u2019s try to use S3 buckets. We thus fix standardisation as such:", "Example: A {name}-data-service is reachable via:", "In detail all services have at least one endpoint, the default data endpoint. Other endpoints are subfolders like:", "Where we use semantic version in the format \u201cvX.Y.Z\u201d, date to the second.", "Data files are denoted in the form \u201cvX.Y.Z.datapart01.???\u201d, limited to 1000 lines per file for easy consumption.", "We reroute the data-lake to it\u2019s new \u201caddress\u201d and change the BI tool access.", "This changes nothing yet for the rest of the organization, we need to give them access.", "Step 2: (Discoverability) Create a space to find our new data-* source.", "We can implement the simplest form of discoverability by creating a page in our knowledge management system (i.e. confluence/ your internal wiki,\u2026).", "Alright, so now new people, other than the ones currently using the data-lake can find the data. Now we can start adding nodes to our data mesh, we can go either way, by breaking out a shiny new microservice or by breaking one of those nasty old legacy pieces.", "Let\u2019s consider the microservice case first.", "Step 3: Break out a new microservice.", "The point of breaking out a service is to put the ownership into the domain team creating the data, so you could, for instance, get someone from the analytics team into the responsible domain team. For now, let\u2019s take the \u201corder team\u201d.", "We create the new order-data-API. Fix a basic set of SLAs, and make sure to adhere to the standard you set for the data-lake. We\u2019d now have two data-services:", "Put the new service into the discoverability tool.", "A second alternative is to let the central analytics team create this data-service, in that case, the ownership would still reside there. But at least we separated the services.", "Step 4: Break Out a Legacy piece.", "Legacy systems are usually not as nice to work with as shiny new microservices. Usually, you\u2019ll have some kind of database tables you\u2019re sourcing data from you don\u2019t even know, source some CSVs from some server or any other form of legacy, not well documented and standardized interface.", "And that\u2019s ok. You can keep it that way for now. You already have some kind of way of importing that data into your data warehouse or data-lake, so break it out of that and denote it as a data-service.", "For example, you could go from:", "Source DB \u2014 ETL Tool \u2192 raw data in data lake \u2192 transformed data in data lake", "to a wrap around the first two stages, and use the standardization:", "(Source DB \u2014 ETL Tool \u2192 raw data in data lake \u2192 S3 bucket) = new data service", "(S3 Bucket of new data service)\u2014 ETL Tool \u2192 import data into data lake \u2192 transformed data in data lake", "That way, when you transfer the service, the domain team only needs to switch the backbone, and dependent users can already switch to the new way of consuming data, even before the domain team takes ownership.", "Step 5: (Discoverability) Switch discoverability & BI tool source.", "Now start pushing your data-services to a general audience to get quick feedback, get the marketing team to source you\u2019ve broken out. Then switch the BI tool to now two data-services, not just one.", "You can then think about switching off support the support for the order data in your data-lake-service.", "If you\u2019re here, congrats, you\u2019ve broken out the first parts of your central data lake now you need to make sure, the ownership is transferred as well before new feature requests trickle in for those services. You can do so by:", "Wrap, wrap, wrap, break out more and more services. Gracefully roll out the old parts and replace them with new APIs. Start to gather new feature requests for the distributed services.", "Your central data-lake will have become quite small by now, containing only joined & modeled data, as will your data team if you started transferring people.", "Step 8: (TSIS) Make it Trustworthy, Self-describing, Inter-operable and Secure.", "Build a common data platform. That might mean libraries for everyone to place the files in the right location or any other more sophisticated toolset. Whatever there is of duplication in the teams, you will be able to take most of it into central hands. For instance, if you notice quickly, that AWS S3 files are not easily accessible by people in marketing & sales, you might decide to switch from S3 to a central database that is accessible via EXCEL, etc.", "In that case, you\u2019d want to have a library to make that switch with a simple upgrade, without much hassle for the teams. In an AWS setup you could, for instance, create a lambda function with a generic \u201cdata-service-shipper\u201d, that is responsible for:", "That way, the domain team has next to no effort other than upgrading their \u201clibrary\u201d. Other options could include creating a generic REST API which you can signal the data and its location and let the API handle the rest, like converting CSV, parquet, etc. to a single format.", "So as with microservices, the best way to start with a monolith is to break out parts, once you feel a certain \u201cpain\u201d. But which part do we break out first? It\u2019s a judgment call based on three considerations:", "The benefits signal indirectly, how many use cases for a true data-service you will be able to collect because changing data implies a change in the data-service and importance of data implies that many people will want to get the insights from that data service.", "If you weigh those things you can come to different conclusions. For instance, in our example, the customer domain could be a good place to start, because such data is quite likely to change often. However, it is sometimes less important than the order data which on the other hand might be hard to break out, depending on how many 1000s of ETL jobs you already put on top of that.", "If you have a place to start, there are still stepping stones in your way.", "The teams providing data currently as a byproduct have no incentive, currently, to properly care for that data, mostly because there is no direct feedback from the potential \u201cstakeholders/ consumers\u201d of that data.", "That\u2019s something that has to change and you have to take care of that as a central component. It\u2019s probably why Zhamak Deghani proposes you take specific use cases, identify the users and take a new team to care only for that specific user. I, on the other hand, don\u2019t see why the current e.g. order team can\u2019t take that role. True, the shift is a little bit harder, but it\u2019s much easier on the resources the company has to spend, and probably an easier sell.", "If you are not able to get the data generating teams to jump on that train, you have two options:", "Let\u2019s finish by exploring possible alternatives to this architecture.", "I tried to come up with an alternative but realized there is more like a matrix of different implementations.", "The key concept of a data mesh is decentralized ownership, where we might say since domain teams usually consider their data a byproduct that they don\u2019t really own it. As such, a data lake is centralized ownership of that raw data.", "If we now distinguish between raw & transformed data, we can see four different data architectures that are possible. We can also see 2\u20133 different ways of moving from a data lake to a data mesh.", "What we described above if the move from \u201cdata lake\u201d to \u201cpoint B\u201d and then to the full data mesh.", "However, a second option is to implement a decentralized \u201cownership of transformed data\u201d first, and then possibly think about the move to a full data mesh.", "How can decentralized transformed data ownership look like?", "Where is the difference? In this scenario, you could collect a lot of requirements, and sharpen the exact use cases that departments have on the data. Departments like marketing are often closer to the domain, then the in-between data team, so you would gain some edge in the \u201cdomain language\u201d problem, but not all of it. You would also still keep a central bottleneck on raw data consumption, and not push \u201cdata as a product\u201d into the domain teams. Both of which I see necessary somewhere in the future.", "Interested in how to build great data companies, great data-heavy products, becoming a great data team, or how to build anything great with open source? Then consider joining my free newsletter \u201cThree Data Point Thursday\u201d. It\u2019s become a trusted resource for data start-ups, VCs, and data leaders.", "I tried to write a shorter post than Zhamak Deghani, but that seemed to not work out. Here are the only four places I could find information on data mesh architectures:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "DataOps @ Meltano | Data PM | co-author of \u201cData Mesh in Action\u201d | Join my free data newsletter \u201cThree Data Point Thursday\u201d at http://thdpth.com/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F21bed87876f2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----21bed87876f2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----21bed87876f2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://svenbalnojan.medium.com/?source=post_page-----21bed87876f2--------------------------------", "anchor_text": ""}, {"url": "https://svenbalnojan.medium.com/?source=post_page-----21bed87876f2--------------------------------", "anchor_text": "Sven Balnojan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31ae15774b19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&user=Sven+Balnojan&userId=31ae15774b19&source=post_page-31ae15774b19----21bed87876f2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21bed87876f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21bed87876f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/theres-more-than-one-kind-of-data-mesh-three-types-of-data-meshes-7cb346dc2819", "anchor_text": "three kinds of data meshes"}, {"url": "https://martinfowler.com/articles/data-monolith-to-mesh.html", "anchor_text": "data mesh"}, {"url": "https://domainlanguage.com/ddd/", "anchor_text": "DDD"}, {"url": "https://www.thoughtworks.com/insights/articles/intelligent-enterprise-series-models-enterprise-intelligence", "anchor_text": "Continuous Intelligence Cycle"}, {"url": "http://thdpth.com/", "anchor_text": "free newsletter \u201cThree Data Point Thursday\u201d"}, {"url": "https://martinfowler.com/articles/data-monolith-to-mesh.html", "anchor_text": "Martin Fowlers website"}, {"url": "https://www.thoughtworks.com/podcasts/episodes", "anchor_text": "episode 30"}, {"url": "https://www.dataengineeringpodcast.com/zhamak-dehghani-data-mesh-episode-90/", "anchor_text": "Data Engineering Podcast"}, {"url": "https://softwareengineeringdaily.com/2019/07/29/data-mesh-with-zhamak-deghani/", "anchor_text": "Software Engineering Weekly Podcast"}, {"url": "https://medium.com/tag/data-science?source=post_page-----21bed87876f2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data?source=post_page-----21bed87876f2---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/data-lake?source=post_page-----21bed87876f2---------------data_lake-----------------", "anchor_text": "Data Lake"}, {"url": "https://medium.com/tag/programming?source=post_page-----21bed87876f2---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-warehouse?source=post_page-----21bed87876f2---------------data_warehouse-----------------", "anchor_text": "Data Warehouse"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F21bed87876f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&user=Sven+Balnojan&userId=31ae15774b19&source=-----21bed87876f2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F21bed87876f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&user=Sven+Balnojan&userId=31ae15774b19&source=-----21bed87876f2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21bed87876f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----21bed87876f2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F21bed87876f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----21bed87876f2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----21bed87876f2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----21bed87876f2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----21bed87876f2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----21bed87876f2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----21bed87876f2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----21bed87876f2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----21bed87876f2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----21bed87876f2--------------------------------", "anchor_text": ""}, {"url": "https://svenbalnojan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://svenbalnojan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sven Balnojan"}, {"url": "https://svenbalnojan.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.6K Followers"}, {"url": "http://thdpth.com/", "anchor_text": "http://thdpth.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31ae15774b19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&user=Sven+Balnojan&userId=31ae15774b19&source=post_page-31ae15774b19--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc7709b24b5cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-mesh-applied-21bed87876f2&newsletterV3=31ae15774b19&newsletterV3Id=c7709b24b5cf&user=Sven+Balnojan&userId=31ae15774b19&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.manning.com/books/data-mesh-in-action", "anchor_text": "Data Mesh in Action2022"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}