{"url": "https://towardsdatascience.com/how-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c", "time": 1683016657.808417, "path": "towardsdatascience.com/how-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c/", "webpage": {"metadata": {"title": "RecordLinkage: Perform Fuzzy Dataframe Row Matching | Towards Data Science", "h1": "How to Perform Fuzzy Dataframe Row Matching With RecordLinkage", "description": "Recordlinkage package provides all the tools to perform record linkage. You can also use it to deduplicate your data. In this article, you will see 2 case studies to learn how to implement it in your own projects."}, "outgoing_paragraph_urls": [{"url": "https://github.com/BexTuychiev/medium_stories/tree/master/november_2020/record_linkage", "anchor_text": "this", "paragraph_index": 10}, {"url": "https://sourceforge.net/projects/febrl/", "anchor_text": "Febrl", "paragraph_index": 12}, {"url": "https://www.linkedin.com/in/bextuychiev/", "anchor_text": "https://www.linkedin.com/in/bextuychiev/", "paragraph_index": 50}], "all_paragraphs": ["In one of my previous articles, I wrote about how to perform string similarity to clean text data using fuzzywuzzy package. Learning about the package and performing it in practice was really awesome. But wouldn't be even greater if we could perform the same process between rows of dataframes?", "Actually, the question should be why would we even need it? Today data is never collected in the same place but across several locations. A common challenge in this process is to convert all the little pieces of data into the same format so that when you merge them they work smoothly with data manipulation softwares such as SQL or pandas.", "But it is just not always possible. Consider these two fake tables:", "Assume they are schedules for NBA games and they were scraped from different sites. If we want to merge them together, the merge would result in duplicates because even though not exact, there are fuzzy duplicates:", "To merge them you would have to perform serious data cleaning operations to get the merge working. However, this dataset could have easily been thousands of rows and you would not be able to find all the edge cases.", "Real-world cases will be much more complex. Fuzzy row matching helps to remove duplicates and introduces consistency to your data.", "With that goal in mind, let me introduce you to recordlinkage package. It provides all the tools needed for record linkage and deduplication. In the next sections, we will see case studies to perform record linkage and will build a solid foundation for your future data cleaning projects.", "Get the best and latest ML and AI papers chosen and summarized by a powerful AI \u2014 Alpha Signal:", "recordlinkage can be installed using pip:", "For it to work, you need to import it with pandas:", "You can get the notebook and the data used in the article on this GitHub repo.", "For the next examples, we will load one of the built-in datasets of recordlinkage to showcase its powers:", "The above two datasets contain census data generated by the Febrl project. It was divided into two with 5k rows in each and each is suited to perform record linkage.", "For easy illustration, I will just take a random sample from both datasets:", "Assume we want to link the records of the two datasets without introducing duplication. To start the process, we would have to generate pairs for possible matches. Obviously, we cannot know which rows match so we would have to take all the possible pairs. Generating pairs to calculate similarity is done using the indexes of the two datasets. That\u2019s why it is also called indexing. recordlinkage package makes this process very easy:", "To start the process, we will create an indexing object. Next, we should specify the mode of generating the pairs. Since we need to generate all the possible combinations of indexes, we will use .full() method on the indexing object:", "Next, we will input the datasets to generate the pairs, also called candidates, and assign the result to a new variable:", "The result will be a pandas.MultiIndex object. The first level contains the indexes from the first dataset and similarly, the second level indexes contain the indexes for the second dataset.", "The length of the resulting series will always be the product of the lengths of datasets. Because for our 5-row datasets, each index from the first table will have 5 pairs of indexes from the second:", "However, if our datasets are large, generating all the possible pairs will be very computationally expensive. To avoid generating all the possible pairs, we should choose one column which has consistent values from both datasets. For our small datasets, there is a state column:", "If you pay attention, the unique values of state are consistent in both datasets. Meaning, one state name is not different from the other. This helps us because now we can exclude all the pairs that do not have a matching state value. To do this with recordlinkage, we have to change the mode from full to blocking:", "Remember, the logic behind blocking on a certain column is that we expect duplicate values to have the same or similar values across the columns of both datasets and if the rows do not match on some certain column, we can exclude that pair.", "As you see, the number of pairs (6) got reduced significantly. These index pairs are also the ones that have the same values for state. Let's check some of the pairs:", "If you use blocking on a consistent common column, the number of pairs will be much less. We can even use multiple columns to block as long as the unique values of those columns are inconsistent in both tables.", "Now that you have an understanding of indexing, we can start record linkage with the full datasets:", "For full datasets, almost 5.5 million pairs are returned. Remember, if we used full indexing, it would have been 25 million. Now, using these candidate pairs, we will perform a comparison of each column value. To start comparing, we should create a comparing object:", "This object has many useful functions to match the exact or fuzzy values of the columns. First, let\u2019s start by matching the exact matches:", "When we use exact for certain fields, we expect row pairs have exactly the same values for these fields. The parameters of exact:", "After we perform all the comparisons, the result will be a pandas dataframe and label controls the name of the appropriate column name in the resulting dataframe.", "Why did we choose exact matching? Because the postcode, social security ID, date of birth, and the state columns have to be an exact match to be a duplicate. This also depends on the values of those columns. If the unique values are consistent among the datasets, we should use exact.", "Now, for fuzzy matching. The given name, surname, address columns will probably have typos and inconsistencies, so we will use fuzzy string matching for them:", "For fuzzy string matching, we will use .string method. The parameters for column names are the same. Other parameters:", "There are other methods of matching values depending on the data type: compare.numeric and compare.date.", "Now, we have the methods in place, it is time to compute them and assign the result to a variable:", ".compute takes three arguments. The first one is the MultiIndex object of potential indexes. The next two are the two data frames we are using. Note that the order of their input should be the same as indexer.index().", "After the computation is done, we will have a dataset of this sort:", "The resulting data frame also has a multi-level index, the first one being census_a, the second one being census_b. The rest of the columns will have either 1 for a match or 0 for not a match. Let's interpret the first row of the above sample:", "The rows with indexes rec-3254-org and rec-1416-dup-0 only matched on the state column because there is 1 in that field. These rows failed to match in other fields.", "Now, let\u2019s set when we decide that two rows are duplicates. For our dataset, I think if the rows match on at least 4 columns, there is a pretty high chance that they are duplicates. We can easily subset for rows with an overall matching score of at least 4 with sum and boolean indexing:", "If you use .sum() with axis set to 1 or columns, it will take the sum of numeric values across columns.", "As you can see, almost 4676 rows matched out of 5.5 million possible pairs. Now before merging our original tables together, we have to make sure that we do not include these 4676 rows. To do this, we will do a little bit of manipulation:", "To get indexes of some level from multi-level indexes, we use .get_level_values on df.index.", "Since we chose the second level index, we should exclude them from census_b:", "Now, the unique_b is ready to be appended to the first dataset:", "There you go. From 10k rows full of duplicates, we got it to 5324 unique rows. Here is the full code:", "To solidify your knowledge, we will perform a record linkage with two other datasets:", "We have to merge these two datasets without duplication. Since they have long names and addresses, they will probably be full of typos and inconsistencies, so .merge won't work as expected:", "None matched! This definitely suggests we use record linkage. I will perform the process without too many details because the steps will be the same as before:", "Read more articles related to the topic:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "BEXGBoost | DataCamp Instructor |\ud83e\udd47Top 10 AI/ML Writer on Medium | Kaggle Master | https://www.linkedin.com/in/bextuychiev/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb53ca0cb944c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ibexorigin.medium.com/?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": ""}, {"url": "https://ibexorigin.medium.com/?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "Bex T."}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39db050c2ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&user=Bex+T.&userId=39db050c2ac2&source=post_page-39db050c2ac2----b53ca0cb944c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb53ca0cb944c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb53ca0cb944c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.pexels.com/@joey-kyber-31917?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Joey Kyber"}, {"url": "https://www.pexels.com/photo/sea-nature-sunset-water-119562/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@ibexorigin", "anchor_text": "author"}, {"url": "https://medium.com/@ibexorigin", "anchor_text": "author"}, {"url": "https://ibexorigin.medium.com/membership", "anchor_text": "Join Medium with my referral link - BEXGBoostGet exclusive access to all my \u26a1premium\u26a1 content and all over Medium without limits. Support my work by buying me a\u2026ibexorigin.medium.com"}, {"url": "https://alphasignal.ai/?referrer=Bex", "anchor_text": "Alpha Signal | The Best of Machine Learning. Summarized by AI.Stay in the loop without spending countless hours browsing for the next breakthrough; our algorithm identifies the\u2026alphasignal.ai"}, {"url": "https://github.com/BexTuychiev/medium_stories/tree/master/november_2020/record_linkage", "anchor_text": "this"}, {"url": "https://sourceforge.net/projects/febrl/", "anchor_text": "Febrl"}, {"url": "https://medium.com/@ibexorigin", "anchor_text": "author"}, {"url": "https://medium.com/@ibexorigin", "anchor_text": "author"}, {"url": "https://towardsdatascience.com/data-type-constraints-data-range-constraints-duplicate-data-with-pandas-44897a350b1e", "anchor_text": "Master the Most Time-consuming task in DS/ML, #1Dealing with common data problemstowardsdatascience.com"}, {"url": "https://towardsdatascience.com/how-to-identify-missingness-types-with-missingno-61cfe0449ad9", "anchor_text": "How to Identify Missingness Types With MissingnoMCAR, MAR, MNAR visualized with a new package in towntowardsdatascience.com"}, {"url": "https://towardsdatascience.com/cross-field-validation-using-pandas-f7a316fd37b7", "anchor_text": "Final Blows to the Dirty DataCross field validation with Pandastowardsdatascience.com"}, {"url": "https://towardsdatascience.com/fuzzywuzzy-fuzzy-string-matching-in-python-beginners-guide-9adc0edf4b35", "anchor_text": "FuzzyWuzzy: Fuzzy String Matching in Python, Beginner\u2019s Guide\u2026 and hands-on practice on a real-world datasettowardsdatascience.com"}, {"url": "https://towardsdatascience.com/meet-the-hardest-functions-of-pandas-part-i-7d1f74597e92", "anchor_text": "Meet the hardest functions of Pandas, Part IMaster the when and how of pivot_table(), stack(), unstack()towardsdatascience.com"}, {"url": "https://towardsdatascience.com/how-i-customarily-bin-data-with-pandas-9303c9e4d946", "anchor_text": "How I customarily bin data with PandasYou might have been using only the defaultstowardsdatascience.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b53ca0cb944c---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b53ca0cb944c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b53ca0cb944c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/software-development?source=post_page-----b53ca0cb944c---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/tag/programming?source=post_page-----b53ca0cb944c---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb53ca0cb944c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&user=Bex+T.&userId=39db050c2ac2&source=-----b53ca0cb944c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb53ca0cb944c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&user=Bex+T.&userId=39db050c2ac2&source=-----b53ca0cb944c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb53ca0cb944c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb53ca0cb944c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b53ca0cb944c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b53ca0cb944c--------------------------------", "anchor_text": ""}, {"url": "https://ibexorigin.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ibexorigin.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Bex T."}, {"url": "https://ibexorigin.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "16.4K Followers"}, {"url": "https://www.linkedin.com/in/bextuychiev/", "anchor_text": "https://www.linkedin.com/in/bextuychiev/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39db050c2ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&user=Bex+T.&userId=39db050c2ac2&source=post_page-39db050c2ac2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F22cea38b90f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-fuzzy-dataframe-row-matching-with-recordlinkage-b53ca0cb944c&newsletterV3=39db050c2ac2&newsletterV3Id=22cea38b90f3&user=Bex+T.&userId=39db050c2ac2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}