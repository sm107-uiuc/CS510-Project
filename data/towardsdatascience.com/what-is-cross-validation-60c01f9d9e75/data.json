{"url": "https://towardsdatascience.com/what-is-cross-validation-60c01f9d9e75", "time": 1683018187.8255749, "path": "towardsdatascience.com/what-is-cross-validation-60c01f9d9e75/", "webpage": {"metadata": {"title": "What is Cross-Validation?. Testing your machine learning models\u2026 | by Mohammed Alhamid | Towards Data Science", "h1": "What is Cross-Validation?", "description": "Cross-Validation (CV) is one of the key topics around testing your learning models. Although the subject is widely known, I still find some misconceptions cover some of its aspects. When we train a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation", "anchor_text": "situation", "paragraph_index": 21}, {"url": "https://github.com/malhamid/cross-validation/blob/master/Cross-Validation.ipynb", "anchor_text": "my Github", "paragraph_index": 24}], "all_paragraphs": ["Cross-Validation (CV) is one of the key topics around testing your learning models. Although the subject is widely known, I still find some misconceptions cover some of its aspects. When we train a model, we split the dataset into two main sets: training and testing. The training set represents all the examples that a model is learning from, while the testing set simulates the testing examples as in Figure 1.", "CV provides the ability to estimate model performance on unseen data not used while training.", "Data scientists rely on several reasons for using cross-validation during their building process of Machine Learning (ML) models. For instance, tuning the model hyperparameters, testing different properties of the overall datasets, and iterate the training process. Also, in cases where your training dataset is small, and the ability to split them into training, validation, and testing will significantly affect training accuracy. The following main points can summarize the reason we use a CV, but they overlap. Hence, the list is presented here in a simplified way:", "One of the critical pillars of validating a learning model before putting them in production is making accurate predictions on unseen data. The unseen data is all types of data that a model has never learned before. Ideally, the testing data is supposed to flow directly to the model in many testing iterations. However, in reality, access to such data is limited or not yet available in a new environment.", "The typical 80\u201320 rule of splitting data into training and testing can still be vulnerable to accidentally ending up in a perfect split that boosts the model accuracy while limiting it from performing the same in a real environment. Sometimes, the accuracy calculated this way is mostly a matter of luck! The 80\u201320 is not an actual rule per se, and you will find alternative ratios that range between 25~30% for testing and 70~75% for training.", "Finding the best combination of model parameters is a common step to tune an algorithm toward learning the dataset\u2019s hidden patterns. But, doing this step on a simple training-testing split is typically not recommended. The model performance is usually very sensitive to such parameters, and adjusting those based on a predefined dataset split should be avoided. It can cause the model to overfit and reduce its ability to generalize.", "For parameter tuning and avoid model overfitting, you might find some recommendations around splitting the dataset into three partitions: training, testing, and validation. For instance, 70% of the data is used for training, 20% for validation, and the remaining 10% is used for testing. In cases where the actual dataset is small, we might need to invest in using the maximum amount of data to train the model. In other instances, splitting into such three partitions could create bias in the training process where some significant examples are kept in training or validation splits. Hence, CV can become handy to resolve this issue.", "Sometimes the splits of training-testing data can be very tricky. The properties of the testing data are not similar to the properties of the training. Although randomness ensures that each sample can have the same chance to be selected in the testing set, the process of a single split can still bring instability when the experiment is repeated with a new division.", "Cross-Validation has two main steps: splitting the data into subsets (called folds) and rotating the training and validation among them. The splitting technique commonly has the following properties:", "K-fold and CV are two terms that are used interchangeably. K-fold is just describing how many folds you want to split your dataset into. Many libraries use k=10 as a default value representing 90% going to training and 10% going to the validation set. The next figure describes the process of iterating over the picked ten folds of the dataset.", "Figure 2 shows how one fold in each step iteratively is held out for testing while the remaining folds are used to build the model. Each step calculates the prediction error. Upon the completion of the final step, a list of computed error are produced of which we can take the mean.", "Figure 3 shows the change in the training and validation sets\u2019 size when using different values for k. The training set size increases whenever we increase the number of folds while the validation set decreases. Typically, the smaller the validation set, the likelihood that the randomness rises with a high noise variation. Increasing the training set size will increase such randomness and bring more reliable performance metrics.", "One of the advantages of CV is observing the model predictions against all the instances in the dataset. It ensures that the model has been tested on the full data without testing them simultaneously. Variations are expected in each step of the validation; therefore, computing the mean and standard deviation can reduce the information into a few comparing values.", "There are other techniques on how to implement cross-validation. Let\u2019s jump into some of those:", "LOOCV is the an exhaustive holdout splitting approach that k-fold enhances. It has one additional step of building k models tested with each example. This approach is quite expensive and requires each holdout example to be tested using a model. It also might increase the overall error rate and becomes computationally costly if the dataset size is large. Usually, it is recommended when the dataset size is small. Figure 4 demonstrates the overall process of a simple dataset containing ten examples.", "It is another exhaustive technique for performing CV. We can define in each iteration how many examples shall be used for testing the model and how many shall be left for training. The process is repeated for all possible combinations of pairs in the dataset. Note that LOOCV is a LOPCV technique where p =1.", "Let\u2019s refresh our minds on how to split the data using the Sklearn library. The following code divides the dataset into two splits: training and testing. We defined here that 1/3 of the dataset should be used for testing.", "We will then build a function to show how k-fold works compared to the single split in the previous code.", "The `k_fold_split` function shows the indexes and the size of each partition. It enables you to track how much data is dedicated for each fold and the chosen indexes.", "Using LOOCV as a splitting strategy is pretty straight forward. We will use again Sklearn library to perform the cross-validation.", "Cross-validation is a great way to ensure the training dataset does not have an implicit type of ordering. However, some cases require the order to be preserved, such as time-series use cases. We can still use cross-validation for time-series datasets using some other technique such as time-based folds.", "Dealing with cross-validation in an unbalanced dataset can be tricky as well. If oversampling is used, the leaking of the oversampled examples can mislead the CV results. One way to consider is the use of stratified sampling instead of splitting randomly. Here is a fantastic blog article discussing how to handle this situation.", "CV measures the generalization of the model, but it cannot avoid bias altogether. Nested cross-validation focuses on ensuring the model\u2019s hyperparameters are not overfitting the dataset. The nested keyword comes to hint at the use of double cross-validation on each fold. The hyperparameter tuning validation is achieved using another k-fold splits on the folds used to train the model.", "As mentioned earlier, CV is used to measure if a learning model can generalize on unseen data. We rely on using a validation dataset for early stopping and parameter tuning different from the testing set during the building of models. There are a couple of research papers recently suggesting the use of CV to measure overfitting as well. In this case, the direct application would be the use of CV as a validation set for a learning model.", "Cross-validation is a procedure to evaluate the performance of learning models. Datasets are typically split in a random or stratified strategy. The splitting technique can be varied and chosen based on the data\u2019s size and the ultimate objective. Also, the computational cost plays a role in implementing the CV technique. Regression and classification problems can use CV, but careful consideration must be paid for some types of datasets such as time-series. A complete example of the code can be found on my Github.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD, working on Machine Learning and AI"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F60c01f9d9e75&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@moh.alhamid?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@moh.alhamid?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "Mohammed Alhamid"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F330f41d600d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&user=Mohammed+Alhamid&userId=330f41d600d1&source=post_page-330f41d600d1----60c01f9d9e75---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F60c01f9d9e75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F60c01f9d9e75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@sortino?utm_source=medium&utm_medium=referral", "anchor_text": "Joshua Sortino"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation", "anchor_text": "situation"}, {"url": "https://github.com/malhamid/cross-validation/blob/master/Cross-Validation.ipynb", "anchor_text": "my Github"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----60c01f9d9e75---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/k-fold-cross-validation?source=post_page-----60c01f9d9e75---------------k_fold_cross_validation-----------------", "anchor_text": "K Fold Cross Validation"}, {"url": "https://medium.com/tag/crossvalidation?source=post_page-----60c01f9d9e75---------------crossvalidation-----------------", "anchor_text": "Crossvalidation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F60c01f9d9e75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&user=Mohammed+Alhamid&userId=330f41d600d1&source=-----60c01f9d9e75---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F60c01f9d9e75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&user=Mohammed+Alhamid&userId=330f41d600d1&source=-----60c01f9d9e75---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F60c01f9d9e75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F60c01f9d9e75&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----60c01f9d9e75---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----60c01f9d9e75--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@moh.alhamid?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@moh.alhamid?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mohammed Alhamid"}, {"url": "https://medium.com/@moh.alhamid/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "241 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F330f41d600d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&user=Mohammed+Alhamid&userId=330f41d600d1&source=post_page-330f41d600d1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Feb9178ad1719&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-cross-validation-60c01f9d9e75&newsletterV3=330f41d600d1&newsletterV3Id=eb9178ad1719&user=Mohammed+Alhamid&userId=330f41d600d1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}