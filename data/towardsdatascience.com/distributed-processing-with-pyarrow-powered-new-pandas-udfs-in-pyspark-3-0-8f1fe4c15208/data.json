{"url": "https://towardsdatascience.com/distributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208", "time": 1683012706.196061, "path": "towardsdatascience.com/distributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208/", "webpage": {"metadata": {"title": "Distributed Processing with PyArrow-Powered New Pandas UDFs in PySpark 3.0 | by P\u0131nar Ersoy | Towards Data Science", "h1": "Distributed Processing with PyArrow-Powered New Pandas UDFs in PySpark 3.0", "description": "Data processing time is so valuable as each minute spent costs back to users in financial terms. This article is mainly for data scientists and data engineers looking to use the newest enhancements\u2026"}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/docs/latest/api/python/index.html", "anchor_text": "API", "paragraph_index": 1}, {"url": "https://spark.apache.org/docs/latest/api/python/index.html", "anchor_text": "API", "paragraph_index": 2}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "Spark DataFrame", "paragraph_index": 3}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow", "paragraph_index": 5}, {"url": "https://spark.apache.org/", "anchor_text": "Apache Spark", "paragraph_index": 5}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow", "paragraph_index": 6}, {"url": "http://www.numpy.org/", "anchor_text": "NumPy", "paragraph_index": 7}, {"url": "https://pandas.pydata.org/docs/", "anchor_text": "Pandas", "paragraph_index": 7}, {"url": "http://arrow.apache.org/overview/", "anchor_text": "block by block", "paragraph_index": 8}, {"url": "https://pandas.pydata.org/docs/", "anchor_text": "Pandas", "paragraph_index": 9}, {"url": "http://scikit-learn.org/stable/", "anchor_text": "scikit-learn", "paragraph_index": 9}, {"url": "https://matplotlib.org/", "anchor_text": "matplotlib", "paragraph_index": 9}, {"url": "http://www.numpy.org/", "anchor_text": "NumPy", "paragraph_index": 9}, {"url": "https://spark.apache.org/docs/3.0.2/sql-pyspark-pandas-with-arrow.html", "anchor_text": "official site", "paragraph_index": 11}, {"url": "https://arrow.apache.org/docs/python/install.html", "anchor_text": "PyArrow", "paragraph_index": 20}, {"url": "https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html", "anchor_text": "Pandas User-Defined Functions", "paragraph_index": 29}, {"url": "https://docs.microsoft.com/en-us/azure/databricks/spark/latest/spark-sql/udf-python", "anchor_text": "Python UDFs", "paragraph_index": 29}, {"url": "https://spark.apache.org/", "anchor_text": "Apache Spark", "paragraph_index": 29}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/index.html", "anchor_text": "Pandas API", "paragraph_index": 29}, {"url": "https://www.slideshare.net/ueshin/apache-arrow-and-pandas-udf-on-apache-spark", "anchor_text": "Spark customized function structures", "paragraph_index": 30}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Row", "anchor_text": "Row", "paragraph_index": 31}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData", "anchor_text": "Group", "paragraph_index": 31}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Window", "anchor_text": "Window", "paragraph_index": 31}, {"url": "https://github.com/pinarersoy/PyArrow-Powered-New-Pandas-UDFs-in-Spark-3/blob/master/PySpark_PandasUDFs_in_one_file.ipynb?short_path=cba9063", "anchor_text": "GitHub", "paragraph_index": 36}, {"url": "https://www.linkedin.com/in/pinarersoy/", "anchor_text": "https://www.linkedin.com/in/pinarersoy/", "paragraph_index": 39}], "all_paragraphs": ["Data processing time is so valuable as each minute spent costs back to users in financial terms. This article is mainly for data scientists and data engineers looking to use the newest enhancements of Apache Spark since, in a noticeably short amount of time, Apache Spark has emerged as the next generation big data processing engine, and is highly being practiced throughout the industry faster than ever.", "Spark\u2019s consolidated structure supports both compatible and constructible APIs that are formed to empower high performance by optimizing across the various libraries and functions built together in programs enabling users to build applications beyond existing libraries. It gives the opportunity for users to write their own analytical libraries on top as well.", "Data is costly to migrate so Spark concentrates on performing computations over the data, regardless of where it locates. In user-interacting APIs, Spark strives to manage these storage systems that seem broadly related in case applications do not require concern about where their data is.", "When the data is too big to fit on a single machine with a long time to execute that computation on one machine drives it to place the data on more than one server or computer. This logic requires processing the data in a distributed manner. Spark DataFrame is the ultimate Structured API that serves a table of data with rows and columns. With its column-and-column-type schema, it can span large numbers of data sources.", "The purpose of this article is to introduce the benefits of one of the currently released features of Spark 3.0 that is related to Pandas with Apache Arrow usage with PySpark in order to be able to execute a pandas-like UDFs in a parallel manner. In the following headings, PyArrow\u2019s crucial usage with PySpark session configurations, PySpark enabled Pandas UDFs will be explained in a detailed way by providing code snippets for corresponding topics. At the end of the article, references and additional resources are added for further research.", "In the previous versions of Spark, there were inefficient steps for converting DataFrame to Pandas in PySpark as collecting all rows to the Spark driver, serializing each row into Python\u2019s pickle format (row by row), and sending them to a Python worker process. At the end of this converting procedure, it unpickles each row into a massive list of tuples. In order to be able to overcome these ineffective operations, Apache Arrow that is integrated with Apache Spark can be used to empower faster columnar data transfer and conversion.", "Apache Arrow helps to accelerate converting to pandas objects from traditional columnar memory providing the high-performance in-memory columnar data structures.", "Previously, Spark reveals a row-based interface for interpreting and running user-defined functions (UDFs). This introduces high overhead in serialization and deserialization and makes it difficult to work with Python libraries such as NumPy, Pandas which are coded in native Python that enables them to compile faster to machine code.", "With the newly proposed UDFs, it advocates introducing new APIs to support vectorized UDFs in Python, in which a block of data is transferred over to Python in some columnar format for execution by serializing block by block instead of row by row.", "Pandas package is recognized by machine learning and data science specialists since it has coherent integrations with plenty of Python libraries and packages including scikit-learn, matplotlib, and NumPy.", "Also, Pandas UDFs support users both to distribute their data loads and to use the Pandas APIs in Apache Spark.", "The user-defined functions can be executed by referring to the official site:", "For better performance, while executing jobs, the following configurations shall be set as follows.", "To be able to benefit from PyArrow optimizations, the following configuration can be enabled by setting this config to true which is disabled by default : spark.sql.execution.arrow.pyspark.enabled", "The upper enabled optimization may fall back to the non-Arrow optimization implementation situation in case of an error. To cope with this issue that occurs the actual computation within Spark,fallback.enabled shall be set to true : spark.sql.execution.arrow.pyspark.fallback.enabled", "Parquet-summary-metadata is not efficient to enable the following configurations for the below reasons:", "To sum up, the final recommended list of Arrow optimized configurations are as follows:", "Proper usage of PyArrow and PandasUDF requires some packages to be upgraded in the PySpark development platform.", "The following list of packages is needed to be updated in order to be able to use the latest version of PandasUDF with Spark 3.0 in a proper way.", "Also, you may need to assign a new environment variable in order not to face any issues with the PyArrow upgrade of 0.15.1 when running Pandas UDFs.", "PyArrow has a greater performance gap when it reads parquet files instead of other file formats. In this blog, you can find a benchmark study regarding different file format reads.", "It can be used with different kinds of packages with varying processing times with Python:", "As long as we are concerned with the performance and processing speed of written scripts, it is beneficial to be aware of how to measure their processing times.", "There exist two types of time-passed processing calculation when a Python script is executed.", "Processor Time: It measures how long a specific process actively being executed on the CPU. Sleep, waiting for a web request, or time are not included. time.process_time()", "Wall-Clock Time: It calculates how much time has passed \u201con a clock hanging on the wall\u201d, i.e. outside real time.time.perf_counter()", "There are additional ways to compute the amount of time spent on a running script.", "time.time() function is also quantifes time-passed as a wall-clock time; however it can be calibrated. For this reason, it is needed to go back in time to reset it.", "time.monotonic() function is monotonic that simply goes forward; however it has reduced precision performance than time.perf_counter()", "Pandas User-Defined Functions can be identified as vectorized UDF that is powered by Apache Arrow permits vectorized operations that serve much higher performance compared to row-at-a-time Python UDFs. They can be accepted as the most impactful improvements in Apache Spark by means of distributed processing of customized functions. They bring countless benefits, including empowering users to use Pandas APIs and improving performance.", "Ingesting Spark customized function structures in Python reveals its advanced functionality to SQL users by allowing them to call in the functions without generating the extra scripting effort to connect their functionalities.", "Functions can be executed by means of Row, Group, and Window while data formats can be used as Series for column and DataFrame for table structures.", "Scalar type of Pandas UDF can be described as the conversion of one or more Pandas Series into one Pandas Series. The final returning data series size is expected to be the same as the input data series.", "Grouped Agg of Pandas UDF can be defined as the conversion of one or more Pandas Series into one Scalar. The final returned data value type is required to be primitive (boolean, byte, char, short, int, long, float, and double) data type.", "Grouped Map of Pandas UDF can be identified as the conversion of one or more Pandas DataFrame into one Pandas DataFrame. The final returned data size can be arbitrary.", "According to the specifications of your input and output data, you can switch between these vectorized UDFs by adding more complex functions to them.", "The full implementation code and Jupyter Notebook are available on my GitHub.", "Questions and comments are highly appreciated!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Lead Data Scientist @Dataroid, BSc Software & Industrial Engineer, MSc Software Engineer https://www.linkedin.com/in/pinarersoy/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8f1fe4c15208&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@pinarersoy?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pinarersoy?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "P\u0131nar Ersoy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5411ba755d50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=post_page-5411ba755d50----8f1fe4c15208---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f1fe4c15208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f1fe4c15208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/illustrations/block-chain-data-records-concept-4115197/", "anchor_text": "Source"}, {"url": "https://spark.apache.org/docs/latest/api/python/index.html", "anchor_text": "API"}, {"url": "https://spark.apache.org/docs/latest/api/python/index.html", "anchor_text": "API"}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "Spark DataFrame"}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow"}, {"url": "https://spark.apache.org/", "anchor_text": "Apache Spark"}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow"}, {"url": "http://www.numpy.org/", "anchor_text": "NumPy"}, {"url": "https://pandas.pydata.org/docs/", "anchor_text": "Pandas"}, {"url": "http://arrow.apache.org/overview/", "anchor_text": "block by block"}, {"url": "https://pandas.pydata.org/docs/", "anchor_text": "Pandas"}, {"url": "http://scikit-learn.org/stable/", "anchor_text": "scikit-learn"}, {"url": "https://matplotlib.org/", "anchor_text": "matplotlib"}, {"url": "http://www.numpy.org/", "anchor_text": "NumPy"}, {"url": "https://spark.apache.org/docs/3.0.2/sql-pyspark-pandas-with-arrow.html", "anchor_text": "official site"}, {"url": "http://arrow.apache.org/", "anchor_text": "Apache Arrow"}, {"url": "https://en.wikipedia.org/wiki/Java_virtual_machine", "anchor_text": "Java Virtual Machine"}, {"url": "https://pandas.pydata.org/docs/", "anchor_text": "Pandas"}, {"url": "https://arrow.apache.org/docs/python/install.html", "anchor_text": "PyArrow"}, {"url": "https://www.kaggle.com/yassinealouini/m5-sales-hierarchy-dataset", "anchor_text": "dimension"}, {"url": "https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html", "anchor_text": "Pandas User-Defined Functions"}, {"url": "https://docs.microsoft.com/en-us/azure/databricks/spark/latest/spark-sql/udf-python", "anchor_text": "Python UDFs"}, {"url": "https://spark.apache.org/", "anchor_text": "Apache Spark"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/index.html", "anchor_text": "Pandas API"}, {"url": "https://www.slideshare.net/ueshin/apache-arrow-and-pandas-udf-on-apache-spark", "anchor_text": "Spark customized function structures"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Row", "anchor_text": "Row"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData", "anchor_text": "Group"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Window", "anchor_text": "Window"}, {"url": "https://github.com/pinarersoy/PyArrow-Powered-New-Pandas-UDFs-in-Spark-3/blob/master/PySpark_PandasUDFs_in_one_file.ipynb?short_path=808df3f", "anchor_text": "# Print the windowed results"}, {"url": "https://github.com/pinarersoy/PyArrow-Powered-New-Pandas-UDFs-in-Spark-3/blob/master/PySpark_PandasUDFs_in_one_file.ipynb?short_path=cba9063", "anchor_text": "GitHub"}, {"url": "https://docs.microsoft.com/en-us/azure/databricks/spark/latest/spark-sql/udf-python", "anchor_text": "Python User Defined Functions"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/index.html", "anchor_text": "Pandas API"}, {"url": "https://spark.apache.org/", "anchor_text": "Apache Spark"}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow"}, {"url": "https://databricks.com/session/vectorized-udf-scalable-analysis-with-python-and-pyspark", "anchor_text": "Vectorized UDF: Scalable Analysis with Python and PySpark"}, {"url": "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/142158605138935/3546232059139201/7497868276316206/latest.html", "anchor_text": "Demo for Apache Arrow Tokyo Meetup 2018"}, {"url": "https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/", "anchor_text": "Spark: The Definitive Guide"}, {"url": "https://medium.com/tag/spark?source=post_page-----8f1fe4c15208---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/python?source=post_page-----8f1fe4c15208---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8f1fe4c15208---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----8f1fe4c15208---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8f1fe4c15208---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8f1fe4c15208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=-----8f1fe4c15208---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8f1fe4c15208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=-----8f1fe4c15208---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f1fe4c15208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8f1fe4c15208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8f1fe4c15208---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8f1fe4c15208--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pinarersoy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pinarersoy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "P\u0131nar Ersoy"}, {"url": "https://medium.com/@pinarersoy/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "586 Followers"}, {"url": "https://www.linkedin.com/in/pinarersoy/", "anchor_text": "https://www.linkedin.com/in/pinarersoy/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5411ba755d50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=post_page-5411ba755d50--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd8be348d5069&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-processing-with-pyarrow-powered-new-pandas-udfs-in-pyspark-3-0-8f1fe4c15208&newsletterV3=5411ba755d50&newsletterV3Id=d8be348d5069&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}