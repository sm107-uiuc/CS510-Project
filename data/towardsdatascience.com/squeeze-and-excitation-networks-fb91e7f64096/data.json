{"url": "https://towardsdatascience.com/squeeze-and-excitation-networks-fb91e7f64096", "time": 1683005400.014961, "path": "towardsdatascience.com/squeeze-and-excitation-networks-fb91e7f64096/", "webpage": {"metadata": {"title": "Squeeze-and-Excitation Networks. Channel self-attention to improve CNN\u2026 | by Rachel Draelos, MD, PhD | Towards Data Science", "h1": "Squeeze-and-Excitation Networks", "description": "This post describes squeeze-and-excitation blocks, an architectural unit that can be plugged in to a convolutional neural network to improve performance with only a small increase in the total number\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1709.01507", "anchor_text": "Jie Hu, Li Shen, Samuel Albanie, Gang Sun, and Enhua Wu. \u201cSqueeze-and-Excitation Networks.\u201d CVPR 2018.", "paragraph_index": 2}, {"url": "https://glassboxmedicine.com/2019/05/05/how-computers-see-intro-to-convolutional-neural-networks/", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7", "anchor_text": "source", "paragraph_index": 35}, {"url": "https://glassboxmedicine.com/2020/04/04/squeeze-and-excitation-networks/", "anchor_text": "http://glassboxmedicine.com", "paragraph_index": 38}], "all_paragraphs": ["This post describes squeeze-and-excitation blocks, an architectural unit that can be plugged in to a convolutional neural network to improve performance with only a small increase in the total number of parameters. Squeeze-and-excitation blocks explicitly model channel relationships and channel interdependencies, and include a form of self-attention on channels.", "The main reference for this post is the original paper, which has been cited over 2,500 times:", "Jie Hu, Li Shen, Samuel Albanie, Gang Sun, and Enhua Wu. \u201cSqueeze-and-Excitation Networks.\u201d CVPR 2018.", "The Squeeze-and-Excitation (SE) block is intended to improve the quality of a convolutional neural network\u2019s representations. A review of convolutional neural networks (CNNs) is available here.", "For any layer of a convolutional neural network, we can build a corresponding SE block that recalibrates the feature maps:", "Figure 1 from the paper depicts an SE block:", "Our input is an image X that has s channels:", "We define a convolutional layer F_ tr which consists of filters V:", "We apply the convolutional layer F_ tr consisting of filters V to our input image X.", "To clarify the notation and the relationship between the input image X and the learned set of convolutional filters V, here is a quick review of 2D convolution for a multi-channel input image, in this case a 3-channel RGB input image.", "The transformation F_ tr includes multiple convolutional filters V=[ v_1, v_2,\u2026, v_C]. One filter for \u201c2D convolution\u201d of a 3-channel image is actually three-dimensional, as we can see from this animation where the sliding white outline represents a single filter, e.g. v_1:", "Consider the RGB image X, shown twice in the picture below \u2014 once at the top with a pale orange filter v_1 overlaid, and once at the bottom with a purple filter v_2 overlaid:", "We can see from the diagram above that a single filter is three-dimensional, measuring k x k x 3 for the 3 channels of X. In this example, V includes two filters, the pale orange filter v_1 and the purple filter v_2.", "In the paper\u2019s notation, superscript s is used to keep track of input X\u2019s channels (in this case s=1,2,3), while subscript c is used to keep track of the filters in V (in this case c=1,2):", "Here are the filters labeled in detail:", "By applying the filters V to input image X, we obtain output filter maps U:", "A single output filter map, e.g. u_1 (subscript c=1), is produced by a summation through all channels (i.e. through superscripts s=1, s=2, and s=3). Only implicit channel relationships can be captured in this manner. To quote the authors,", "Since the output is produced by a summation through all channels, channel dependencies are implicitly embedded in v_c, but are entangled with the local spatial correlation captured by the filters. The channel relationships modeled by convolution are inherently implicit and local (except the ones at top-most layers). We expect the learning of convolutional features to be enhanced by explicitly modeling channel interdependencies [i.e., with SE blocks].", "(Note: following the paper, bias terms have been omitted to simplify notation.)", "Now that we\u2019ve reviewed the paper\u2019s notation and 2D multi-channel convolution, here\u2019s an explanation of how squeeze-and-excitation blocks work. They are surprisingly simple, requiring only global average pooling and fully connected layers.", "The \u201csqueeze\u201d step in the SE block squeezes global spatial information into a channel descriptor. The squeeze step consists of global average pooling across the spatial dimensions H x W, to produce channel-wise statistics. Here\u2019s an excerpt from the paper with the description and equation for the squeeze step:", "The following sketch illustrates the squeeze operation which reduces each distinct H x W feature map u_c into a scalar channel descriptor z_c:", "The scalars [ z_1, z_2 ,\u2026, z_C] together form a vector z of length C which will be used in the excitation step. Note that that z captures global information in the sense that each element of z is produced by an aggregation across the full feature map height H and full feature map width W.", "The excitation operation is intended to fully capture channel-wise dependencies. The excitation operation processes the output of the squeeze step (the vector z) to produce a vector of activations s, which is then used to re-scale the feature maps. (This activations vector s is not to be confused with the s that was used earlier to keep track of the channels of input X).", "The vector s is calculated from the squeeze output z using two fully-connected layers with a bottleneck that takes the representation down to size C/r:", "The hyperparameter r is referred to as the \u201creduction ratio.\u201d If r is bigger, then the intermediate representation is smaller. The goal of reducing the size of the representation to C/r and then expanding it back up to C is to (a) limit model complexity and (b) aid generalization. As the authors put it, the reduction ratio r \u201callows us to vary the capacity and computational cost of the SE blocks in the network.\u201d", "Here is a sketch of the first part of the excitation step, in which the activations in s are calculated from the squeeze output z:", "Once s is calculated, the elements of s are used to rescale the feature maps of U to obtain the final output of the SE block, termed X-tilde:", "Here\u2019s a sketch of the final step:", "As you can see from the sketch, the activation s_1 has to be tiled across the H x W map u_1 so that s_1 element-wise multiplies all the values in u_1 to produce x-tilde_1.", "The stack of recalibrated feature maps [ x-tilde_1, x-tilde_2,\u2026, x-tilde_C] then continue through the rest of the CNN, as they are exactly the same dimension as the original feature maps [ u_1, u_2,\u2026, u_C].", "Thus, SE blocks add a form of self-attention to the CNN:", "SE blocks intrinsically introduce dynamics conditioned on the input, which can be regarded as a self-attention function on channels whose relationships are not confined to the local receptive field the convolutional filters are responsive to.", "A squeeze-and-excitation block can be plugged in to any CNN architecture. Figure 3 from the paper illustrates how to use an SE block in a ResNet:", "SE blocks do not increase the computational complexity of the model very much. In the following comparisons, \u201cSE-ResNet-50\u201d refers to a ResNet-50 model with SE blocks added, and \u201cvanilla ResNet-50\u201d refers to the baseline ResNet-50 without any SE blocks:", "Here\u2019s an example implementation of an SE block (source):", "The authors add SE blocks to ResNet architectures, ResNeXt architectures, VGG-16, and Inception architectures, and show that the addition of SE blocks improves performance on ImageNet classification. The performance improvement is shown in parentheses next to each entry in the SENet columns in Table 2:", "Additional takeaways from the results section:", "Originally published at http://glassboxmedicine.com on April 4, 2020.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a physician with a PhD in Computer Science. My research focuses on machine learning methods development for medical data. I am the CEO of Cydoc."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffb91e7f64096&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "Rachel Draelos, MD, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf----fb91e7f64096---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb91e7f64096&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb91e7f64096&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Fireworks#/media/File:OperaSydney-Fuegos2006-342289398.jpg", "anchor_text": "(Wikipedia, CC by 2.0)"}, {"url": "https://arxiv.org/abs/1709.01507", "anchor_text": "Jie Hu, Li Shen, Samuel Albanie, Gang Sun, and Enhua Wu. \u201cSqueeze-and-Excitation Networks.\u201d CVPR 2018."}, {"url": "https://glassboxmedicine.com/2019/05/05/how-computers-see-intro-to-convolutional-neural-networks/", "anchor_text": "here"}, {"url": "https://sites.google.com/site/nttrungmtwiki/home/it/data-science---python/tensorflow/tensorflow-and-deep-learning-part-3?tmpl=%2Fsystem%2Fapp%2Ftemplates%2Fprint%2F&showPrintDialog=1", "anchor_text": "Original Link"}, {"url": "https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7", "anchor_text": "source"}, {"url": "https://glassboxmedicine.com/2020/04/04/squeeze-and-excitation-networks/", "anchor_text": "http://glassboxmedicine.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----fb91e7f64096---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----fb91e7f64096---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----fb91e7f64096---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----fb91e7f64096---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----fb91e7f64096---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb91e7f64096&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----fb91e7f64096---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb91e7f64096&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----fb91e7f64096---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb91e7f64096&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffb91e7f64096&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fb91e7f64096---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fb91e7f64096--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fb91e7f64096--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fb91e7f64096--------------------------------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rachel Draelos, MD, PhD"}, {"url": "https://rachel-draelos.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "576 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa0377bd1bf3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsqueeze-and-excitation-networks-fb91e7f64096&newsletterV3=209c0f742bcf&newsletterV3Id=a0377bd1bf3d&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}