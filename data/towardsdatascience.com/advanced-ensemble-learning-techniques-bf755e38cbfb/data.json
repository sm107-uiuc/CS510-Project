{"url": "https://towardsdatascience.com/advanced-ensemble-learning-techniques-bf755e38cbfb", "time": 1683014729.211008, "path": "towardsdatascience.com/advanced-ensemble-learning-techniques-bf755e38cbfb/", "webpage": {"metadata": {"title": "Advanced Ensemble Learning Techniques | by Charu Makhijani | Towards Data Science", "h1": "Advanced Ensemble Learning Techniques", "description": "In my previous post about ensemble learning, I explained what is ensemble learning, how it relates to Bias and Variance in machine learning and what are the simple techniques of ensemble learning. If\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/ensemble-learning-techniques-6346db0c6ef8", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://github.com/charumakhijani/Ensemble-Learning/blob/master/EnsembleTechniques1.ipynb", "anchor_text": "link", "paragraph_index": 46}, {"url": "https://github.com/charumakhijani", "anchor_text": "https://github.com/charumakhijani", "paragraph_index": 49}], "all_paragraphs": ["In my previous post about ensemble learning, I explained what is ensemble learning, how it relates to Bias and Variance in machine learning and what are the simple techniques of ensemble learning. If you haven\u2019t read the post, please refer here.", "In this post, I will cover ensemble learning types, and advanced ensemble learning methods \u2014 Bagging, Boosting, Stacking, and Blending with code samples. In the end, I will explain some pros and cons of using ensemble learning.", "Ensemble learning methods can be categorized into two groups:", "In this method base learners are dependent on the results from previous base learners. Every subsequent base model corrects the prediction made by its predecessor fixing the errors in it. Hence the overall performance can be increased by improving the weight of previous labels.", "In this method there is no dependency between the base learners and all base learners execute in parallel and the results of all base models are combined in the end (using averaging for regression and voting for classification problems).", "Parallel Ensemble methods are divided into two categories-", "1. Homogeneous Parallel Ensemble Methods- In this method, a single machine learning algorithm is used as a base learner.", "2. Heterogeneous Parallel Ensemble Methods- In this method multiple machine learning algorithms are used as base learners.", "Bagging or Bootstrap Aggregation is a parallel ensemble learning technique to reduce the variance in the final prediction.", "The Bagging process is very similar to averaging, the only difference is that bagging uses random sub-samples of the original dataset to train the same/multiple models and then combines the prediction, whereas in averaging the same dataset is used to train models. Hence the technique is called Bootstrap Aggregation as it combines both Bootstrapping (or Sampling of data) and Aggregation to form an ensemble model.", "2. Model is built (either a classifier or a decision tree) with every sample.", "3. Predictions of all the base models are combined (using averaging or weighted averaging for regression problems or majority voting for classification problems) to get the final result.", "All three steps can be parallelized across different sub-samples, hence the training can be done faster when working on larger datasets.", "In bagging, every base model is trained on a different subset of data and all the results are combined, so the final model is less overfitted and variance is reduced.", "Bagging is more useful when the model is unstable, with stable models bagging is not useful in improving the performance. Model is called stable when it\u2019s less sensitive for small fluctuations in the training data.", "Some examples of Bagging are \u2014 Random Forest, Bagged Decision Trees, and Extra Trees. sklearn library also provides BaggingClassifier and BaggingRegressor classes to create your own bagging algorithms.", "Let's see this in the example below-", "As we see in the example, Bagging Classifiers are improving the variance of ML models and reduce the deviation. The same is the case when using VotingClassifier which improves the average variance of ML models.", "Boosting is a sequential ensemble learning technique to convert weak base learners to strong learner that performs better and is less biased. The intuition here is that individual models may not perform very well on the entire dataset, but they work well on some parts of the entire dataset. Hence each model in the ensemble actually boosts the overall performance.", "Boosting is an iterative method that adjusts the weight of an observation based on the previous classification. If an observation was classified incorrectly, then the weight of that observation is increased in the next iteration. In the same way, if an observation was classified correctly then the weight of that observation is reduced in the next iteration.", "Boosting is used to decrease the bias error, but it can also overfit the training data. That is why parameter tuning is an important part of boosting algorithms to make them avoid overfitting the data.", "Boosting was originally designed for classification problems but extended for regression problems as well.", "Some examples of Boosting algorithms are \u2014 AdaBoost, Gradient Boosting Machine (GBM), XGBoost, LightGBM, and CatBoost.", "Let's see Boosting with an example-", "Stacking, also known as stacked generalization, is an ensemble learning technique that combines multiple machine learning algorithms via meta learning (either a meta-classifier or a meta-regressor).", "The base-level algorithms are trained on the entire training dataset, and then the meta-model is trained on the predictions from all the base-level models as features. The base models are called level-0 models, and the meta-model which combines the base model's predictions is called a level-1 model.", "The level-1 model training data is prepared via k-fold cross-validation of the base models, and out-of-fold predictions (real numbers for regression and class labels for classification) are used as the training dataset.", "The level-0 models can be either a diverse range of algorithms or the same algorithm (most often they are diverse). The level-1 meta-model is most often a simple model, like Linear Regression for regression problems and Logistic Regression for Classification problems.", "The stacking method can reduce the bias or variance based on the algorithms used in level-0.", "There are many libraries for Stacking, like \u2014 StackingClassifier, StackingRegressor, make_classification, make_regression, ML Ensemble, and H20.", "Let's see Stacking with an example using StackingClassifier-", "As we see in this example, we have used different ML models in level 0 and stacked them with StackingClassifier using LogisticRegression in level 1, and it has improved the variance.", "Multi-levels Stacking is an extension of stacking where stacking is applied on multiple layers.", "For example in a 3-level stacking, Level-0 is the same where a diverse range of base learners are trained using k-fold cross-validation. In level-1, instead of a single meta-model, N such meta-models are used. In level-2, the final meta-model is used that takes the predictions from N meta-models of level-1.", "Adding multiple levels is both data expensive (as lots of data needed to be trained) and time expensive (as each layer adds multiple models).", "Blending is most often used interchangeably with Stacking. And it is almost similar to Stacking with only one difference, Stacking uses out-of-fold predictions for the training set whereas Blending uses a hold-out (validation) set (10\u201320% of the training set) to train the next layer.", "Although Blending is simpler than stacking and uses fewer data, the final model may overfit on the holdout set.", "1. Ensemble methods have higher predictive accuracy, compared to the individual models.", "2. Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset; different models can be combined to handle this type of data.", "3. With ensemble methods bias/variance can be reduced and most of the time, the model is not under fitted/overfitted.", "4. Ensemble of models is always less noisy and more stable.", "1. Ensembling is less interpretable, the output of the ensembled model is hard to predict and explain. Hence the idea with the ensemble is hard to sell and get useful business insights.", "2. The art of ensembling is hard to learn and any wrong selection can lead to lower predictive accuracy than an individual model.", "3. Ensembling is expensive in terms of both time and space. Hence ROI can increase with ensembling.", "After looking at the fundamentals of ensemble learning techniques above and the pros/cons of ensemble learning, it won\u2019t be wrong to say that if used correctly ensemble methods are great for improving the overall performance of ML models. When it's hard to rely on one model, an ensemble makes life easier and that\u2019s the reason why in most of the ML competitions ensemble methods are the choices for winners.", "Although selecting the right ensemble methods and using them is not an easy job but this art can be learned with experience. The techniques described in this post are most often a reliable source for ensembling, but other variants are also possible based on specific problems/needs.", "To access the complete code for the Advanced Ensemble Techniques, please check this GitHub link.", "Thanks for the read. If you like the story please like, share, and follow for more such content. As always, please reach out for any questions/comments/feedback.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML Engineering Leader | Writing about Data Science, Machine Learning, Product Engineering & Leadership | https://github.com/charumakhijani"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbf755e38cbfb&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://charumakhijani.medium.com/?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": ""}, {"url": "https://charumakhijani.medium.com/?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "Charu Makhijani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3b23858b69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&user=Charu+Makhijani&userId=a3b23858b69&source=post_page-a3b23858b69----bf755e38cbfb---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf755e38cbfb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf755e38cbfb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jeswinthomas?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Jeswin Thomas"}, {"url": "https://unsplash.com/s/photos/ensemble-learning?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/ensemble-learning-techniques-6346db0c6ef8", "anchor_text": "here"}, {"url": "https://github.com/charumakhijani/Ensemble-Learning/blob/master/EnsembleTechniques1.ipynb", "anchor_text": "link"}, {"url": "https://charumakhijani.medium.com/subscribe", "anchor_text": "Get an email whenever I publish and be the first one to read!Get an email whenever I publish and be the first one to read! By signing up, you will create a Medium account if you\u2026charumakhijani.medium.com"}, {"url": "https://github.com/charumakhijani", "anchor_text": "https://github.com/charumakhijani"}, {"url": "https://www.linkedin.com/in/charu-makhijani-23b18318/", "anchor_text": "https://www.linkedin.com/in/charu-makhijani-23b18318/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----bf755e38cbfb---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ensemble-learning?source=post_page-----bf755e38cbfb---------------ensemble_learning-----------------", "anchor_text": "Ensemble Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----bf755e38cbfb---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ensemble?source=post_page-----bf755e38cbfb---------------ensemble-----------------", "anchor_text": "Ensemble"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----bf755e38cbfb---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbf755e38cbfb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&user=Charu+Makhijani&userId=a3b23858b69&source=-----bf755e38cbfb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbf755e38cbfb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&user=Charu+Makhijani&userId=a3b23858b69&source=-----bf755e38cbfb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf755e38cbfb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbf755e38cbfb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bf755e38cbfb---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bf755e38cbfb--------------------------------", "anchor_text": ""}, {"url": "https://charumakhijani.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://charumakhijani.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Charu Makhijani"}, {"url": "https://charumakhijani.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "197 Followers"}, {"url": "https://github.com/charumakhijani", "anchor_text": "https://github.com/charumakhijani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3b23858b69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&user=Charu+Makhijani&userId=a3b23858b69&source=post_page-a3b23858b69--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6883cd406aeb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-ensemble-learning-techniques-bf755e38cbfb&newsletterV3=a3b23858b69&newsletterV3Id=6883cd406aeb&user=Charu+Makhijani&userId=a3b23858b69&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}