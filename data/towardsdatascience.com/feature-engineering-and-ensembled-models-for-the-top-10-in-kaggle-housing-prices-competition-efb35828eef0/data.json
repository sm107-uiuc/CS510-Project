{"url": "https://towardsdatascience.com/feature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0", "time": 1683001167.314682, "path": "towardsdatascience.com/feature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0/", "webpage": {"metadata": {"title": "Feature engineering and ensembled models for the top 10 in Kaggle \u201cHousing Prices Competition\u201d | by Gabriel Naya | Towards Data Science", "h1": "Feature engineering and ensembled models for the top 10 in Kaggle \u201cHousing Prices Competition\u201d", "description": "Kaggle\u00b9 is one of the most significant online communities of data scientists and machine learners. Within Kaggle, it is common to find competitions, where different users generate prediction models\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/", "anchor_text": "Kaggle", "paragraph_index": 0}, {"url": "https://www.kaggle.com/c/home-data-for-ml-course", "anchor_text": "Housing Prices Competition for Kaggle Learn Users", "paragraph_index": 1}, {"url": "https://www.kaggle.com/sandeepkumar121995", "anchor_text": "Sandeep Kumar", "paragraph_index": 3}, {"url": "https://www.kaggle.com/sandeepkumar121995/blending-of-6-models-top-10", "anchor_text": "code", "paragraph_index": 3}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5548942/", "anchor_text": "article", "paragraph_index": 23}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html#scipy.stats.skewtest", "anchor_text": "skewtest", "paragraph_index": 42}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.boxcox1p.html#scipy.special.boxcox1p", "anchor_text": "boxcox1p", "paragraph_index": 43}, {"url": "https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/", "anchor_text": "Ensemble models", "paragraph_index": 60}, {"url": "https://www.kaggle.com/adamsuwik", "anchor_text": "Adam Suwik", "paragraph_index": 67}, {"url": "https://www.kaggle.com/c/home-data-for-ml-course/discussion/100526#652503", "anchor_text": "post", "paragraph_index": 68}, {"url": "https://en.wikipedia.org/wiki/Kaggle", "anchor_text": "Kaggle", "paragraph_index": 85}, {"url": "https://en.wikipedia.org/wiki/Google_LLC", "anchor_text": "Google LLC", "paragraph_index": 85}, {"url": "https://medium.com/analytics-vidhya/incidence-of-correlation-and-time-features-in-a-regression-model-6fc1c4653e4f?source=your_stories_page---------------------------", "anchor_text": "Incidence of correlation and time features in a regression model", "paragraph_index": 86}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5548942/", "anchor_text": "Statistical data preparation: management of missing values and outliers", "paragraph_index": 87}, {"url": "https://cran.r-project.org/web/packages/jtrans/jtrans.pdf", "anchor_text": "Johnson Transformation", "paragraph_index": 92}, {"url": "https://gnaya73.glitch.me/", "anchor_text": "https://gnaya73.glitch.me/", "paragraph_index": 96}], "all_paragraphs": ["Kaggle\u00b9 is one of the most significant online communities of data scientists and machine learners. Within Kaggle, it is common to find competitions, where different users generate prediction models and submit their results to be position according to the score, in the leaderboard.", "The competition that supports the online courses that every beginner performs is \u201cHousing Prices Competition for Kaggle Learn Users\u201d .", "A global and learning-oriented competence, therefore, the material circulating on the web is profuse, even for those looking well can be found directly with complete codes of excellent models that come very close to 1% on the scoreboard.", "This article is base on the code exposed by Sandeep Kumar in Kaggle. This code was our most important starting point in the competition. While this code alone is not enough to reach the top 10, it uses many exciting techniques. To the methods used there, we have added others that have made the difference to position our model in the top 10.", "Because every detail counts when you start trying to improve within 1%, you need to be very methodical and thorough in handling data engineering as well as model parameters.", "The dataset has 1460 rows of houses with their corresponding 79 features and the target variable: the price of each house. There is also a test set with 1459 other houses.", "In this article, we are going to work them unified for the different techniques that we are going to apply and separating them before realizing the final prediction to raise the results.", "The workflow with the dataset will then be", "a) Import the train_features and test_features data.", "b) Save and remove the index (Id) and prepare train_features without the objective variable", "c) Create a data frame \u201cfeatures\u201d that joint them", "e) After finished in data engineering work, split again in X_train and X_test the datasets.", "f) Make the models, fit, and prediction", "g) If we apply any transformation to the target variable (Y), we must invert this transformation over the prediction.", "We are facing a regression exercise, and we must calculate the selling price of each house, of each row of the dataset.", "Our objective then is the column SalePrice, first, let\u2019s see its general behavior:", "Let\u2019s now see its practice in any model using it directly, or applying the logarithm to it.", "So we see the improvement is significant going down from 12934 to 8458 if we change the model training, taking as a result of the logarithm of the target variable instead of \u2018SalePrice\u2019 directly.", "\u201cThe purpose of the correlation is to examine the direction and strength of the association between two quantitative variables. Thus we will know the intensity of the relationship between them and whether, as the value of one variable increases, the value of the other variable increases or decreases.\u201d\u00b2", "If you want to know more about the incidence of the correlation of variables and the target variable, you can review this previous issue\u00b3 for a detailed analysis.", "We are going to create a data frame with the numeric columns and apply the Pandas \u201ccorr()\u201d method to them and evaluate the SalePrice target:", "Here we have an ordered list of variables related to the target variable, the increase in model precision may be thought to decrease as we use variables less and less correlated to the target variable.", "\u201c\u2026 Outliers significantly affect the process of estimating statistics (e.g., the average and standard deviation of a sample), resulting in overestimated or underestimated values. Therefore, the results of data analysis are considerably dependent on the ways in which the missing values and outliers are processed\u2026\u201d\u2074", "In the article from which this quotation is token, excellent concepts about the treatment of outliers\u2019 values can be found in-depth.", "Let\u2019s take as an example one of the variables that have the highest incidence in its correlation with a price: GrLivArea.", "To visualize outliers, we usually use boxplots.", "Here an excellent article about the use of boxplot and outliers detection\u2075 , and his main features:", "We perform a check on any model, using the entire training set, cutting the Outliers > 4500 and cutting the Outliers > 4000, obtaining the following values", "The difference in performance between cutting at 4000 or 4500 does not seem significant; however, the improvement in accuracy when slice GrLivArea registers greater than 4500 is considerable.", "In principle and on the training data, it would seem a suitable strategy. Still, it is necessary to look for a balance between what is slice in the entry of the model since it can generate overfitting or take away possibilities of generalization to our model.", "If we deploy null values in the data frame before and after these operations with this code, we are going to obtain graphs as in the following image.", "Remember that all null values must be clear before entering a model.", "Many of these data we can already know that we are not going to precise them or that the attempt to fill the null values is not viable for them; we apply the drop of the column directly.", "Everyday use for filling in missing data is to fill it in with \u201cNone\u201d or \u201czero,\u201d depending on the type of data.", "Let\u2019s see here two examples to assign the most frequent value (Pandas mode function) or how to apply the amount of the average of the whole column or a cluster of it.", "These examples are only for illustrative purposes; you can apply any Pandas function and make the grouping by any attribute that you want to make the cluster. It can also be used to create new features of the \u201ccluster\u201d type.", "Example a: Application of the most frequent MSZoning value, grouped for each MSSubClass", "Example b: Application of the mean value of LotFrontage, grouped for each Neighborhood", "Example c: Apply the most frequent amount to complete your features", "Finally, we must make sure that there is no value left with null so we can apply a fill to None or zero depending on the type of column:", "You can create new variables to add specific information that helps the model define the data sets, or to simplify the model by creating averages, sums, or Boolean variables.", "Each of these variables must be carefully selected, and the impact on the model must be measured to see whether or not it adds quality to the result, and in the case of being used to \u201csimplify\u201d if the loss of eliminated columns does not affect the accuracy of the model.", "For normally distributed data, the skewness should be about 0. For unimodal continuous distributions, a skewness value > 0 means that there is more weight in the right tail of the distribution. The function skewtest can be used to determine if the skewness value is close enough to 0, statistically speaking.\u2075", "We use the Scipy.boxcoxp1 \u2076 that compute the Box-Cox transformation of 1 + x. The Box-Cox transformation computed by boxcox1p is:", "For getting the lambda value to input in boxcoxp1, we use boxcox_normmax(features[ind)) from Scipy, that Compute optimal Box-Cox transform parameter for input data\u2077", "This transformation can be done only on features that have all their positive values; if you need to do a conversion on elements with negative values, see the reference note\u2078 .", "When creating variables related to the target variable, it is necessary to do them only on the train data set and then try to take them to the test dataset, since there we do not know the value of the target variable \u201cY\u201d.", "This type of variables with which we have added a significant improvement in the leaderboard of the competition", "For example, we can calculate the price per square meter, linked to each neighborhood or class of housing, then we first figure it in the train set:", "Then we make a dictionary with the prices for each neighborhood:", "And finally, we created the feature in the test dataset", "\u201cWhat one hot encoding does is, it takes a column which has categorical data, which has been label encoded and then splits the column into multiple columns. The numbers are replaced by \u201c1\u201d and \u201c0\u201d, depending on which column has what value\u2026 \u201d \u2079", "Categorizing object features can be very convenient, the discussion of which columns to use to apply OHE to them is broad and their limits diffuse, since each different value within the column will be transformed into a new dimension of the matrix input to the model. Sometimes it may be convenient to create a new feature that groups different values to reduce dimensionality, for example, a set of neighborhoods that have similar characteristics and prices.", "Some numeric columns, we may want to categorize them, for which it is convenient to change the type to string since finally, we will apply get_dummies to all the columns of type object.", "\u201cThe dummy variable trap manifests itself directly from one-hot-encoding applied on categorical variables \u2026 size of one-hot vectors is equal to the number of unique values that a categorical column takes up and each such vector contains exactly one \u20181\u2019 in it. This ingests multicollinearity into our dataset \u2026 \u201c\u00b9\u2070", "In other words, when performing the transformation, the set of features of the added OHE is aligned to the target variable, and therefore any column is usually removed. In our model, we have not applied this technique.", "Sandeep Kumar\u2019s original work includes at the end of feature engineering and applying get_dummies, a code that looks for those columns that have a lot of zero values (above 99.94%), which are drop.", "This technique indirectly mitigates in categorized variables the effect of the dummy variable trap and also avoids including in the model columns that by the impact of the content of the categorization are irrelevant for a model that seeks to extract the main characteristics and generalize them.", "The regression algorithms have had no problem supporting the columns after categorization, so except in strictly inconvenient cases, it does not seem necessary or even a good idea to remove them. However, this is only one approach; at the end of this article, we will see other approaches to the problem very different, and as much or even more useful.", "In this case, then, it is not necessary to reduce the dimensionality of the model since training time with different algorithms is not a problem, and brute force does not seem a bad strategy.", "\u201cEnsemble models give us excellent performance and work in a wide variety of problems. They\u2019re easier to train than other types of techniques, requiring less data with better results. In machine learning, ensemble models are the norm. Even if you aren\u2019t using them, your competitors are \u2026 Ensemble models are comprised of several weak models that aren\u2019t so great themselves, known as weak learners. When you combine them, they fill in each other\u2019s weaknesses and render better performance than they would when deployed alone.\u201d\u00b9\u00b9", "The competition metric is the Mean Absolute Error (MAE).", "For the initial measurement, RMSE and CV_RMSE used.", "Because the CV_RMSE is negative, to apply the square root, it is necessary to flip it.\u00b9\u00b2", "It is an example of one of the original models used by Sandeep Kumar, where we can see lots of hyperparameters uses:", "In the same operation that we carried out for the GBR model, we can carry it out with other different regression models. Then in a function, we assign them an incidence coefficient on the total value, in such a way that the ratios add up to 1.", "We were able to use other models, such as linear regressor, tree regressors, etc. The importance assigned to each model depends on the confidence we have in the algorithm on the test dataset, sometimes algorithms such as GBR, XGB, or LGB work very well in the fit but fall by overfitting to use them in the test set. On the other hand, models like SVR or RIDGE tend to have less precision but are more stable.", "When we managed to place our model in the top 10 of the world competition and to know that our knowledge was very scarce, with the desire to go for more but feeling on a plateau, I contacted Adam Suwik who was in the #3 at the time, and still remains there in the top positions:", "Very kindly Adam agreed to share the approach of his model in a very illustrative post.", "We transcribe here some of the most significant passages for this article:", "\u201c\u2026 This is no secret knowledge, only simple logical thinking (although specialist knowledge in the subject would be very helpful too).", "Adjusting the data to the model \u2014 most likely Linear Regression will be the # 1 choice. Unfortunately, most of the data does not make much sense and may adversely affect the result. For example, quality \u2014 it is not the case that excellent quality of a small house and a large villa has the same value \u2014 it should rather be replaced by \u201csize in square feet in exellent quality\u201d. And it seems to me that most of the data should be prepared in such a way \u2014 combined with the size of a plot, house area, basement area, pool size, etc.", "Combining data / simplifying the model \u2014 that\u2019s what I use a lot. The world is not that complicated. In this case, it seems to me that 3 features would be enough \u2014 how big the house is?, how nice it is? how comfortable is it?, maybe a few additional ones like a swimming pool, an additional garage space, etc. \u2026", "Dropping data \u2014 I use it a lot too. If I do not see value or think that the information is contained elsewhere, or if I have somehow engineered data, I drop whatever I can. Some expertise would be pretty useful here, but using just common sense, much of the data that seems to have an impact is really secondary. Nobody builds a luxury home on cheap foundations and viceversa \u2026", "Clusters \u2014 not always the same rules apply to entire populations, if I am able to isolate a large group of similar cases, I will build a separate model for them. From life experience \u2014 if you look at the price per square foot you will notice that for smaller apartments it is definitely bigger.", "And I probably could describe a few other things, but it all comes down to one thing \u2014 analyze all the data carefully and think about how to engineer them to fit the model you use. I believe in one principle: \u201cgarbage in, garbage out\u201d. What quality of data you provide, the quality of result you will get\u2026", "NaN\u2019s. Unfortunately, the answer is just as above \u2014 there are no secrets \u2014 do whatever seems to make sense. I like \u201c0\u201d, \u201cnone\u201d, I really like my own predictions, I hate the average, it\u2019s like admitting to the lack of any idea and just minimizing cost of assumed mistakes\u2026\u201d", "It is another approach, and there are many more approaches to the web. To be in 1% of any competition is in itself a good enough model and a sign that we are on the right way.", "We have seen how important it is to start a job supported in the preliminary work that others have shared, in this case, the transfer learning of the Sandeep Kumar model. Thanks him!", "This previous transfer learning gave us a floor and essential knowledge from which to start, much more elaborated and refined than the experience that a rookie takes from online courses.", "Then, after many hours of effort and systematic tests, we saw the impact of each technique on the different variables to make decisions about the engineering features and the ensemble of models.", "One day I got that idea that makes the difference, being distracted the head still thinking, the idea was to calculate the value of square feet based on a given concept, and the satisfaction of having reached that top ten was an incredible moment.", "The objective of this Kaggle competition is to learn", "This post aimed to transmit the techniques that you can use if you are stuck until the mud in the game as I was a few months ago hopefully, help you get on an exact path towards improving your model, or maybe help you light that little lamp that makes the difference.", "I will be grateful for comments and reports if something could be doing better.", "[1] Kaggle is an online community of data scientists and machine learners, owned by Google LLC . Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges. Kaggle got its start by offering machine learning competitions and now also offers a public data platform, a cloud-based workbench for data science, and short form AI education. On 8 March 2017, Google announced that they were acquiring Kaggle.", "[3] Incidence of correlation and time features in a regression model", "[4] Statistical data preparation: management of missing values and outliers", "\u201c\u2026 There are basically three methods for treating outliers in a data set. One method is to remove outliers as a means of trimming the data set. Another method involves replacing the values of outliers or reducing the influence of outliers through outlier weight adjustments. The third method is used to estimate the values of outliers using robust techniques.", "Trimming: Under this approach, a data set that excludes outliers is analyzed. The trimmed estimators such as mean decrease the variance in the data and cause a bias based on under- or overestimation. Given that the outliers are also observed values, excluding them from the analysis makes this approach inadequate for the treatment of outliers.", "Winsorization: This approach involves modifying the weights of outliers or replacing the values being tested for outliers with expected values. The weight modification method allows weight modification without discarding or replacing the values of outliers, limiting the influence of the outliers. The value modification method allows the replacement of the values of outliers with the largest or second smallest value in observations excluding outliers.", "Robust estimation method: When the nature of the population distributions is known, this approach is considered appropriate because it produces estimators robust to outliers, and estimators are consistent. In the recent years, many studies have proposed a variety of statistical models for robust estimation; however, their applications are sluggish due to complicated methodological aspects. \u201c", "\u201cOne thing you can do is add a fixed value that\u2019s just bigger than your smallest negative to make all your value normal. Another normalization method is the Johnson Transformation, which can handle negative values.", "The Mean Square Error returned by sklearn.cross_validation.cross_val_score is always a negative. While being a designed decision so that the output of this function can be used for maximization given some hyperparameters, it\u2019s extremely confusing when using cross_val_score directly. At least I asked myself how a the mean of a square can possibly be negative and thought that cross_val_score was not working correctly or did not use the supplied metric. Only after digging in the sklearn source code I realized that the sign was flipped.", "This behavior is mentioned in make_scorer in scorer.py, however it\u2019s not mentioned in cross_val_score and I think it should be, because otherwise it makes people think that cross_val_score is not working correctly", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine learning enthusiast and research at Kreilabs Uruguay. My profile: https://gnaya73.glitch.me/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fefb35828eef0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----efb35828eef0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----efb35828eef0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://gabriel-naya73.medium.com/?source=post_page-----efb35828eef0--------------------------------", "anchor_text": ""}, {"url": "https://gabriel-naya73.medium.com/?source=post_page-----efb35828eef0--------------------------------", "anchor_text": "Gabriel Naya"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4213edda07c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&user=Gabriel+Naya&userId=4213edda07c&source=post_page-4213edda07c----efb35828eef0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefb35828eef0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefb35828eef0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jesseroberts?utm_source=medium&utm_medium=referral", "anchor_text": "Jesse Roberts"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/c/home-data-for-ml-course", "anchor_text": "Housing Prices Competition for Kaggle Learn Users"}, {"url": "https://www.kaggle.com/sandeepkumar121995", "anchor_text": "Sandeep Kumar"}, {"url": "https://www.kaggle.com/sandeepkumar121995/blending-of-6-models-top-10", "anchor_text": "code"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5548942/", "anchor_text": "article"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html#scipy.stats.skewtest", "anchor_text": "skewtest"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.boxcox1p.html#scipy.special.boxcox1p", "anchor_text": "boxcox1p"}, {"url": "https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/", "anchor_text": "Ensemble models"}, {"url": "https://www.kaggle.com/adamsuwik", "anchor_text": "Adam Suwik"}, {"url": "https://www.kaggle.com/c/home-data-for-ml-course/discussion/100526#652503", "anchor_text": "post"}, {"url": "https://en.wikipedia.org/wiki/Kaggle", "anchor_text": "Kaggle"}, {"url": "https://en.wikipedia.org/wiki/Google_LLC", "anchor_text": "Google LLC"}, {"url": "https://www.google.com/url?sa=t&source=web&rct=j&url=https://personal.us.es/vararey/adatos2/correlacion.pdf&ved=2ahUKEwiaytLbhqnlAhUGLLkGHeL2B24QFjAMegQIBxAB&usg=AOvVaw1mijaxh5F0qXIXMpeadD5j", "anchor_text": "https://www.google.com/url?sa=t&source=web&rct=j&url=https://personal.us.es/vararey/adatos2/correlacion.pdf&ved=2ahUKEwiaytLbhqnlAhUGLLkGHeL2B24QFjAMegQIBxAB&usg=AOvVaw1mijaxh5F0qXIXMpeadD5j"}, {"url": "https://medium.com/analytics-vidhya/incidence-of-correlation-and-time-features-in-a-regression-model-6fc1c4653e4f?source=your_stories_page---------------------------", "anchor_text": "Incidence of correlation and time features in a regression model"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5548942/", "anchor_text": "Statistical data preparation: management of missing values and outliers"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html", "anchor_text": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.boxcox1p.html", "anchor_text": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.boxcox1p.html"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox_normmax.html?highlight=normmax#scipy.stats.boxcox_normmax", "anchor_text": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox_normmax.html?highlight=normmax#scipy.stats.boxcox_normmax"}, {"url": "https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data", "anchor_text": "https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data"}, {"url": "https://cran.r-project.org/web/packages/jtrans/jtrans.pdf", "anchor_text": "Johnson Transformation"}, {"url": "https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b", "anchor_text": "https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b"}, {"url": "https://towardsdatascience.com/one-hot-encoding-multicollinearity-and-the-dummy-variable-trap-b5840be3c41a", "anchor_text": "https://towardsdatascience.com/one-hot-encoding-multicollinearity-and-the-dummy-variable-trap-b5840be3c41a"}, {"url": "https://medium.com/@ODSC/ensemble-models-demystified-c871d5ee7793", "anchor_text": "https://medium.com/@ODSC/ensemble-models-demystified-c871d5ee7793"}, {"url": "https://github.com/scikit-learn/scikit-learn/issues/2439", "anchor_text": "https://github.com/scikit-learn/scikit-learn/issues/2439"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----efb35828eef0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----efb35828eef0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/kaggle-competition?source=post_page-----efb35828eef0---------------kaggle_competition-----------------", "anchor_text": "Kaggle Competition"}, {"url": "https://medium.com/tag/feature-engineering?source=post_page-----efb35828eef0---------------feature_engineering-----------------", "anchor_text": "Feature Engineering"}, {"url": "https://medium.com/tag/housing-prices?source=post_page-----efb35828eef0---------------housing_prices-----------------", "anchor_text": "Housing Prices"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fefb35828eef0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&user=Gabriel+Naya&userId=4213edda07c&source=-----efb35828eef0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fefb35828eef0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&user=Gabriel+Naya&userId=4213edda07c&source=-----efb35828eef0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefb35828eef0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----efb35828eef0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fefb35828eef0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----efb35828eef0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----efb35828eef0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----efb35828eef0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----efb35828eef0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----efb35828eef0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----efb35828eef0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----efb35828eef0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----efb35828eef0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----efb35828eef0--------------------------------", "anchor_text": ""}, {"url": "https://gabriel-naya73.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://gabriel-naya73.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Gabriel Naya"}, {"url": "https://gabriel-naya73.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "78 Followers"}, {"url": "https://gnaya73.glitch.me/", "anchor_text": "https://gnaya73.glitch.me/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4213edda07c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&user=Gabriel+Naya&userId=4213edda07c&source=post_page-4213edda07c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F4213edda07c%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-and-ensembled-models-for-the-top-10-in-kaggle-housing-prices-competition-efb35828eef0&user=Gabriel+Naya&userId=4213edda07c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}