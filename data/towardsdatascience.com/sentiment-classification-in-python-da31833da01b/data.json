{"url": "https://towardsdatascience.com/sentiment-classification-in-python-da31833da01b", "time": 1683013767.0176268, "path": "towardsdatascience.com/sentiment-classification-in-python-da31833da01b/", "webpage": {"metadata": {"title": "Sentiment classification in Python | by Zolzaya Luvsandorj | Towards Data Science", "h1": "Sentiment classification in Python", "description": "This post is the last of the three sequential posts on steps to build a sentiment classifier. Having done some exploratory text analysis and preprocessed the text, it\u2019s time to classify reviews to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/exploratory-text-analysis-in-python-8cf42b758d9e", "anchor_text": "exploratory text analysis", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/preprocessing-text-in-python-923828c4114f", "anchor_text": "preprocessed the text", "paragraph_index": 0}, {"url": "https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome", "anchor_text": "CRISP-DM", "paragraph_index": 1}, {"url": "https://www.python.org/about/gettingstarted/", "anchor_text": "this", "paragraph_index": 2}, {"url": "https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "\u2018VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\u2019", "paragraph_index": 14}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "neg, neu, pos: These three scores sum up to 1. These scores show the proportion of text falling in the category.compound: This score ranges from -1 (the most negative) to 1 (the most positive.", "paragraph_index": 16}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "VADER", "paragraph_index": 25}, {"url": "https://www.nltk.org/howto/sentiment.html", "anchor_text": "VADER in nltk", "paragraph_index": 25}, {"url": "https://towardsdatascience.com/preprocessing-text-in-python-923828c4114f", "anchor_text": "my previous post", "paragraph_index": 40}, {"url": "https://www.kaggle.com/pouryaayria/a-complete-ml-pipeline-tutorial-acu-86/comments", "anchor_text": "here", "paragraph_index": 40}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html", "anchor_text": "Logistic Regression Classifier", "paragraph_index": 41}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html?highlight=sgd#sklearn.linear_model.SGDClassifier", "anchor_text": "Stochastic Gradient Descent Classifier", "paragraph_index": 41}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB", "anchor_text": "Multinomial Naive Bayes Classifier", "paragraph_index": 41}, {"url": "https://zluvsand.medium.com/membership", "anchor_text": "my referral link", "paragraph_index": 66}, {"url": "https://towardsdatascience.com/exploratory-text-analysis-in-python-8cf42b758d9e", "anchor_text": "Exploratory text analysis in Python", "paragraph_index": 67}, {"url": "https://towardsdatascience.com/preprocessing-text-in-python-923828c4114f", "anchor_text": "Preprocessing text in Python", "paragraph_index": 67}, {"url": "https://towardsdatascience.com/simple-wordcloud-in-python-2ae54a9f58e5", "anchor_text": "Simple wordcloud in Python", "paragraph_index": 68}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96", "anchor_text": "Part 1: Preprocessing text in Python", "paragraph_index": 68}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc", "anchor_text": "Part 2: Difference between lemmatisation and stemming", "paragraph_index": 68}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc", "anchor_text": "Part 3: TF-IDF explained", "paragraph_index": 68}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267", "anchor_text": "Part 4: Supervised text classification model in Python", "paragraph_index": 68}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-5a-unsupervised-topic-model-in-python-733f76b3dc2d", "anchor_text": "Part 5A: Unsupervised topic model in Python (sklearn)", "paragraph_index": 68}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-5b-unsupervised-topic-model-in-python-ab04c186f295", "anchor_text": "Part 5B: Unsupervised topic model in Python (gensim)", "paragraph_index": 68}, {"url": "https://zluvsand.github.io/", "anchor_text": "https://zluvsand.github.io/", "paragraph_index": 70}], "all_paragraphs": ["This post is the last of the three sequential posts on steps to build a sentiment classifier. Having done some exploratory text analysis and preprocessed the text, it\u2019s time to classify reviews to sentiments. In this post, we will first look at 2 ways to get sentiments without building a model then build a custom model.", "Before we dive in, let\u2019s take a step back and look at the bigger picture really quickly. CRISP-DM methodology outlines the process flow for a successful data science project. In this post, we will do some of the tasks that a data scientist would go through during the modelling stage.", "This post assumes that the reader (\ud83d\udc40 yes, you!) has access to and is familiar with Python including installing packages, defining functions and other basic tasks. If you are new to Python, this is a good place to get started.", "I have tested the scripts in Python 3.7.1 in Jupyter Notebook.", "Let\u2019s make sure you have the following libraries installed before we start:\u25fc\ufe0f Data manipulation/analysis: numpy, pandas\u25fc\ufe0f Data partitioning: sklearn\u25fc\ufe0f Text preprocessing/analysis: nltk, textblob\u25fc\ufe0f Visualisation: matplotlib, seaborn", "Once you have nltk installed, please make sure you have downloaded \u2018stopwords\u2019 , \u2018wordnet\u2019 and \u2018vader_lexicon\u2019 from nltk with the script below:", "If you have already downloaded, running this will notify you so.", "Now, we are ready to import the packages:", "We will use IMDB movie reviews dataset. You can download the dataset here and save it in your working directory. Once saved, let\u2019s import it to Python:", "Let\u2019s look at the split between sentiments:", "Sentiment is evenly split in the sample data. Let\u2019s encode the target into numeric values where positive is 1 and negative is 0:", "Let\u2019s set aside 5000 cases for testing:", "We will quickly inspect the head of the training dataset:", "In this section, I want to show you two very simple methods to get sentiments without building a custom model. We will extract polarity intensity scores with VADER and TextBlob.", "\u2018VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\u2019", "Let\u2019s start with a simple example and see how we extract sentiment intensity scores using VADER sentiment analyser:", "neg, neu, pos: These three scores sum up to 1. These scores show the proportion of text falling in the category.compound: This score ranges from -1 (the most negative) to 1 (the most positive.", "Although not all reviews would be as simple as our example at hand, it\u2019s good to see that scores for the example review looks mostly positive. Now, let\u2019s add the intensity scores to the training data:", "All it takes to get sentiment scores is a single line of code once we initialise the analyser object. Shall we inspect the scores further? Let\u2019s start with peaking at 5 records with the highest pos scores:", "It\u2019s great to see that all of them are indeed positive reviews. Let\u2019s do the same for neg:", "This looks good too. But we could be looking at the extreme ends of the data where the sentiment is more obvious. Let\u2019s visualise the scores with histograms to understand better:", "From the histograms, it appears that pos, neg and potentially compound columns are useful in classifying positive and negative sentiments. We can quickly classify each review into either positive or negative classes using these scores. Let\u2019s see how well it will do:", "With very little effort, we can get about 69% accuracy using VADER. The performance on positive and negative reviews look different though. We have higher recall and lower precision of positive reviews \u2014 meaning that we have more false positives (See what I did there? Do you see why I encoded positive reviews as 1? \ud83d\ude4a). Let\u2019s see confusion matrix:", "As we can see, we have many true positives and false positives. In fact, about 67% of our predictions are positive. Let\u2019s see whether performance improves if we use the compound score.", "Performance looks pretty similar. I used training dataset to assess because we are not training a model here. However, if you do the same on the test data, the results should be very similar.", "\ud83d\udd17 More information on VADER and VADER in nltk.", "Another way to get sentiment score is to leverage TextBlob library. Using sentiment property from the TextBlob object, we can also extract similar scores. Here\u2019s how we can extract using our previous example:", "polarity: ranges from -1 (the most negative) to 1 (the most positive)subjectivity: ranges from 0 (very objective) to 1 (very subjective)", "Our example was analysed to be a very subjective positive statement. It\u2019s true, isn\u2019t it? Of these two scores, polarity is more relevant for us. Let\u2019s add the intensity scores to the training data and inspect 5 records with the highest polarity scores:", "As you saw, adding sentiment intensity score with TextBlob is also quite simple. Let\u2019s look at 5 records with the lowest polarity scores:", "Time to plot some histograms to understand the scores better:", "As expected, polarity score looks possibly useful in classifying positive and negative sentiments. Let\u2019s classify using the polarity score and see performance:", "With very little effort, we can get about 69% accuracy using TextBlob. Again, we have many false positives, in fact, even more than before. Let\u2019s look at confusion matrix:", "This time, the number of false positives are higher than the number of true negatives. Predictions are skewed to positive sentiment as 76% of predictions are positive.", "Let\u2019s compare how similar the scores from VADER and TextBlob are:", "There is about 79% overlap in their classifications with majority in positive sentiments. Let\u2019s visualise the polarity scores:", "This plot shows a little bit more information than the previous table. In the bottom left quadrant, we see mainly red circles since negative classifications in both methods were more precise. In the top right quadrant, there is a higher volume of circles that are mostly green but the color mix is not as pure as before. The remaining two quadrants show where the two scores disagree with each other. Overall, the colour is more mixed than the left half in the right half of the plot.", "We get very similar overall accuracy of 69% from both; however, when we look at the predictions closely, the performance differs between the approaches.", "Now you know how to get sentiment polarity scores with VADER or TextBlob. If you have unlabeled data, these two provide a great starting point to label your data automatically. It\u2019s time to build a model! \u2728", "The sentiment classification is one application of supervised classification model .Therefore, the approach we are taking here can be generalised to any supervised classification tasks.", "In my previous post, we have explored three different ways to preprocess text and shortlisted two of them: simpler approach and simple approach. Of these two, we will now test if there is any difference in model performance between the two options and choose one of them to use moving forward. To make things easier, we will create two functions (the idea of these functions is inspired from here):", "I have picked three algorithms to try: Logistic Regression Classifier, Stochastic Gradient Descent Classifier and Multinomial Naive Bayes Classifier. Let\u2019s initiate the models:", "Now, let\u2019s inspect model performance when using simpler approach:", "Great to see we get much better performance: 86\u201389% accuracy with baseline models compared to using only the sentiment scores. Since the classes are pretty balanced, we will mainly focus on accuracy. But we will ensure to inspect the predictions closer later to evaluate the model. Performance metrics look pretty close between Logistic Regression and Stochastic Gradient Descent with the latter being faster in training (see fit_time). Naive Bayes is the fastest of the three in training but performs slightly worse than the other two. Now let\u2019s assess simple approach:", "The performance looks similar to before. Therefore, we will favour the simpler approach and use it moving forward. Of the three algorithms, we will choose Stochastic Gradient Descent because it balances both speed and predictive power the most.", "In this section, we will explore whether adding VADER and TextBlob sentiment scores as features improves the predictive power of the model. Let\u2019s quickly check if there are any highly correlated features:", "The most correlated features are compound and neg. Let\u2019s run a quick model to see which scores are more useful to use:", "We get about 77% accuracy using the scores. Now let\u2019s inspect coefficients:", "Seems like we could only use neg, pos and polarity because they are the most dominant features among the scores. Let\u2019s see if model results can be improved by adding these selected scores to the previously preprocessed data.", "Since adding these scores didn\u2019t improve the model, it is unnecessary to add them as features. That will keep our pipeline simple too!", "It\u2019s time to build a small pipeline that puts together the preprocessor and the model. We will fine tune its hyperparameters to see if we can improve the model. Firstly, let\u2019s try to understand the impact of three hyperparameters: min_df, max_df for the vectoriser and loss for the model with random search:", "Here, we are trying 30 different random combinations of hyperparameter space specified. This will take a while to run. The output of the random search will be saved in a dataframe called r_search_results. Let\u2019s create another dataframe containing a few columns that are more interesting to us:", "Let\u2019s visualise the output to understand the impact of hyperparameters better:", "It looks loss='hinge' results in slightly better performance. Let\u2019s look at the numerical hyperparameters:", "As there seems to be a negative relationship between min_df and accuracy, we will keep min_df under 200. There isn\u2019t a clear trend in max_df probably because the performance was more impacted by min_df and loss. Although this is true for all three of them, it\u2019s more obvious for max_df. Now we have some idea on how these hyperparameters impact the model, let\u2019s define the pipeline more precisely (max_df=.6 and loss=\u2019hinge') and try to further tune it with grid search:", "Grid searching will also take a bit of time because we have 24 different combinations of hyperparameters to try. Like before, the output will be saved to a dataframe called g_search_results. Let\u2019s extract more relevant columns to another dataframe:", "With any of these combinations, we reach a cross validated accuracy of ~0.9. It\u2019s nice to see a marginal increase.", "We can see that by changing to ngram_range=(1,2), model performs better. The same is true for stop_words=None. On the other hand, whether we fit intercept or not doesn\u2019t have much impact, which means we can leave this hyperparameter to its default. I think this is good enough, we can now define the final pipeline.", "Using the top combination from grid search, this is how our final pipeline looks like:", "Our pipeline is very small and simple. Let\u2019s see its coefficients:", "Features with the highest or lowest coefficients look intuitive. But look at the number of features we have: 49,577! This is mainly due to having relaxed min_df, adding bigrams and not removing stop words. If we were keen to reduce the number of features, we could change these hyperparamaters in the pipeline. If we start cutting down features, we will notice a tradeoff between number of features and the model accuracy. What an optimal balance looks like depends on the context. Let\u2019s evaluate the pipeline:", "Accuracy on train and test set is about 0.94 and 0.92 respectively. Precision and recall by both sentiments look pretty similar. We have slightly more false negatives. Let\u2019s plot confusion matrix:", "Looks good. Yay \ud83c\udf8a, now we have a pipeline that classifies about 9 in 10 reviews into the correct sentiment. Let\u2019s see how long it takes to make a single prediction. We will use Jupyter Notebook\u2019s magic command %timeit:", "Although %timeit runs multiple loops and gives us mean and standard deviation of run time, I notice that I get slightly different output every time. Hence, we are looking at 10 loops of %timeit to observe the range.", "A single prediction takes about 1.5 to 4 milliseconds. This needs to be evaluated in the context of production environment for the use case.", "Alright, that was it for this post. \ud83d\udcab", "Would you like to access more content like this? Medium members get unlimited access to any articles on Medium. If you become a member using my referral link, a portion of your membership fee will directly go to support me.", "Thank you for reading my post. Hopefully, you have learned a few different practical ways to classify text into sentiments with or without building a custom model. Here are links to the other two posts of the series:\u25fc\ufe0f Exploratory text analysis in Python\u25fc\ufe0f Preprocessing text in Python", "Here are links to the my other NLP-related posts:\u25fc\ufe0f Simple wordcloud in Python(Below lists a series of posts on Introduction to NLP)\u25fc\ufe0f Part 1: Preprocessing text in Python\u25fc\ufe0f Part 2: Difference between lemmatisation and stemming\u25fc\ufe0f Part 3: TF-IDF explained\u25fc\ufe0f Part 4: Supervised text classification model in Python\u25fc\ufe0f Part 5A: Unsupervised topic model in Python (sklearn)\u25fc\ufe0f Part 5B: Unsupervised topic model in Python (gensim)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist \ud83d\udca1| Growth Mindset \ud83d\udd11 | Math Lover \ud83d\udd22 | Melbourne, AU \ud83d\udc28 | https://zluvsand.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fda31833da01b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----da31833da01b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----da31833da01b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://zluvsand.medium.com/?source=post_page-----da31833da01b--------------------------------", "anchor_text": ""}, {"url": "https://zluvsand.medium.com/?source=post_page-----da31833da01b--------------------------------", "anchor_text": "Zolzaya Luvsandorj"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bca2b935223&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=post_page-5bca2b935223----da31833da01b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda31833da01b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda31833da01b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/exploratory-text-analysis-in-python-8cf42b758d9e", "anchor_text": "exploratory text analysis"}, {"url": "https://towardsdatascience.com/preprocessing-text-in-python-923828c4114f", "anchor_text": "preprocessed the text"}, {"url": "https://unsplash.com/@artbyhybrid?utm_source=medium&utm_medium=referral", "anchor_text": "Hybrid"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome", "anchor_text": "CRISP-DM"}, {"url": "https://www.python.org/about/gettingstarted/", "anchor_text": "this"}, {"url": "https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews", "anchor_text": "here"}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "\u2018VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\u2019"}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "neg, neu, pos: These three scores sum up to 1. These scores show the proportion of text falling in the category.compound: This score ranges from -1 (the most negative) to 1 (the most positive."}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "VADER"}, {"url": "https://www.nltk.org/howto/sentiment.html", "anchor_text": "VADER in nltk"}, {"url": "https://textblob.readthedocs.io/en/dev/", "anchor_text": "TextBlob."}, {"url": "https://towardsdatascience.com/preprocessing-text-in-python-923828c4114f", "anchor_text": "my previous post"}, {"url": "https://www.kaggle.com/pouryaayria/a-complete-ml-pipeline-tutorial-acu-86/comments", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html", "anchor_text": "Logistic Regression Classifier"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html?highlight=sgd#sklearn.linear_model.SGDClassifier", "anchor_text": "Stochastic Gradient Descent Classifier"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB", "anchor_text": "Multinomial Naive Bayes Classifier"}, {"url": "https://unsplash.com/@countchris?utm_source=medium&utm_medium=referral", "anchor_text": "Count Chris"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://zluvsand.medium.com/membership", "anchor_text": "my referral link"}, {"url": "https://towardsdatascience.com/exploratory-text-analysis-in-python-8cf42b758d9e", "anchor_text": "Exploratory text analysis in Python"}, {"url": "https://towardsdatascience.com/preprocessing-text-in-python-923828c4114f", "anchor_text": "Preprocessing text in Python"}, {"url": "https://towardsdatascience.com/simple-wordcloud-in-python-2ae54a9f58e5", "anchor_text": "Simple wordcloud in Python"}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96", "anchor_text": "Part 1: Preprocessing text in Python"}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc", "anchor_text": "Part 2: Difference between lemmatisation and stemming"}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc", "anchor_text": "Part 3: TF-IDF explained"}, {"url": "https://medium.com/@zluvsand/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267", "anchor_text": "Part 4: Supervised text classification model in Python"}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-5a-unsupervised-topic-model-in-python-733f76b3dc2d", "anchor_text": "Part 5A: Unsupervised topic model in Python (sklearn)"}, {"url": "https://towardsdatascience.com/introduction-to-nlp-part-5b-unsupervised-topic-model-in-python-ab04c186f295", "anchor_text": "Part 5B: Unsupervised topic model in Python (gensim)"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----da31833da01b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----da31833da01b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----da31833da01b---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/classification?source=post_page-----da31833da01b---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/sentiment-analysis?source=post_page-----da31833da01b---------------sentiment_analysis-----------------", "anchor_text": "Sentiment Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fda31833da01b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=-----da31833da01b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fda31833da01b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=-----da31833da01b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda31833da01b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----da31833da01b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fda31833da01b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----da31833da01b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----da31833da01b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----da31833da01b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----da31833da01b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----da31833da01b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----da31833da01b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----da31833da01b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----da31833da01b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----da31833da01b--------------------------------", "anchor_text": ""}, {"url": "https://zluvsand.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://zluvsand.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Zolzaya Luvsandorj"}, {"url": "https://zluvsand.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.3K Followers"}, {"url": "https://zluvsand.github.io/", "anchor_text": "https://zluvsand.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bca2b935223&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=post_page-5bca2b935223--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea8899bb3fba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classification-in-python-da31833da01b&newsletterV3=5bca2b935223&newsletterV3Id=ea8899bb3fba&user=Zolzaya+Luvsandorj&userId=5bca2b935223&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}