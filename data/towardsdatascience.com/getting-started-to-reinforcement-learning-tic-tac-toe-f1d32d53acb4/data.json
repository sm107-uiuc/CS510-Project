{"url": "https://towardsdatascience.com/getting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4", "time": 1683007061.322401, "path": "towardsdatascience.com/getting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4/", "webpage": {"metadata": {"title": "Getting Started with Reinforcement Learning \u2014 Tic Tac Toe | by Juan Nathaniel | Towards Data Science", "h1": "Getting Started with Reinforcement Learning \u2014 Tic Tac Toe", "description": "Imagine yourself trying to maximize your daily productivity by choosing a set of activities (studying, binge-watching, day-dreaming). Here, you are the agent trying to maximize a reward (ie\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/juannat95/reinforcement_learning_projects/tree/master/tic-tac-toe", "anchor_text": "code", "paragraph_index": 19}, {"url": "https://tinyurl.com/2npw2fnz", "anchor_text": "https://tinyurl.com/2npw2fnz", "paragraph_index": 20}], "all_paragraphs": ["Imagine yourself trying to maximize your daily productivity by choosing a set of activities (studying, binge-watching, day-dreaming). Here, you are the agent trying to maximize a reward (ie. productivity) by selecting a subset of plausible actions. Each action that you choose will bring you to a new state (eg. choosing to binge-watch rather than to train your RL model would affect your mood, which will further deteriorate your will to be productive).", "Reinforcement learning (RL) captures this idea well. It concerns itself with how agents maximize their reward functions by taking a specific action. Each action and its corresponding reward will produce a new state which can influence the subsequent actions-reward interaction. These concepts will become clearer when we begin implementing our own RL model that can play a game of Tic-Tac-Toe with us. Let\u2019s begin!", "The objective of Tic-Tac-Toe is to be the first to place their marks (either cross or naughts) in a horizontal, vertical, or diagonal arrangement. Now, let us define the game in terms of RL keywords mentioned earlier:", "We will initialize the State class where it will monitor how each agent interacts, receives a reward, and plays the game.", "Here we initialize with zeros a 3x3 board, the 2 players, and the first player to start the game. isEnd is a flag to indicate whether the game can still proceed or a winner has been determined. Each player is assigned a particular playerSymbol where p1 is represented with 1 and p2 -1.", "getHash is a handy function that flattens the board configuration for easier analysis later. The output shape is transformed from (3,3) to (9,). getAvailablePosition will retrieve a collection of boxes on the board which is yet to be occupied and hence are available for the next move.", "After defining the available action spaces for the agent, we need to define how the winner would be determined (which will then break the playing while loop). Here, 4 possible break outcomes can be achieved after each playing turn: column win, row win, diagonal win, and draw.", "updateStates will update the board configuration with the current playerSymbol after each successful execution of an action. The next player will then be selected for the game to continue. If the game ends (either with a win or a draw), giveReward will feed an arbitrary value (ie. 1 point to the winning player, 0 to the losing player, and 0.1\u20130.5 to both in the case of a draw).", "Now let us initialize the Agent class to specify their behaviors (choosing an action that maximizes reward, calculating reward)", "The following hyperparameters warrant more explanations:", "states will store a list of board configurations from each player in a given game while states_val is a key-value dict that keeps the reward (\u2018value\u2019) associated with a certain board configuration/state (\u2018key).", "We then define chooseAction which allows an agent either to explore (picking random action) or exploit (choosing an action with the greatest reward given current board configuration/state).", "After an action has been taken by an agent, addStates will append the resulting board configuration into states. When the game ends, feedReward will assign a reward to each configuration in a (1) reversed manner: with the latest move/state valued first, and in a (2) discounted/decaying manner: penalizes more moves.", "The feedReward calculates the value associated with a particular state (ie. states_val) by accumulating the current value and the discounted/decaying difference between the next and the current state given a learning rate (Figure 2).", "For housekeeping, we will save the trained policies and load them later when we are playing with our trained RL bots! :)", "After defining the States and Player classes, we are going to implement the actual playing of the game!", "The playBot function is defined in the State class, and serves as the logic by which we play the game. The two players will each take a turn choosing an action (random or greedily) until a winner is chosen. The reward(s) will then be assigned to both agents depending on the value we defined earlier.", "After the policy has been saved, now it is time for us to play against our trained bot! We first need to slightly modify the playBot function defined earlier to load the learned policies (make the bot used its previously learned intelligence!)", "In addition, we also need to slightly modify how the HumanPlayer is defined: choosing the next set of action through user input!", "That\u2019s it, pretty cool right? Have fun training your own! You can check the full code and documentation here: code.", "Do subscribe to my Email newsletter: https://tinyurl.com/2npw2fnz where I regularly summarize AI research papers in plain English and beautiful visualization.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Engineering @ Columbia University | Documenting and sharing my learning journey through AI, programming, and research"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff1d32d53acb4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nathanieljuan?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nathanieljuan?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "Juan Nathaniel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7913527fa2dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&user=Juan+Nathaniel&userId=7913527fa2dc&source=post_page-7913527fa2dc----f1d32d53acb4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1d32d53acb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1d32d53acb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/juannat95/reinforcement_learning_projects/tree/master/tic-tac-toe", "anchor_text": "code"}, {"url": "https://tinyurl.com/2npw2fnz", "anchor_text": "https://tinyurl.com/2npw2fnz"}, {"url": "https://github.com/JaeDukSeo/reinforcement-learning-an-introduction", "anchor_text": "https://github.com/JaeDukSeo/reinforcement-learning-an-introduction"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----f1d32d53acb4---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/agent-based-modeling?source=post_page-----f1d32d53acb4---------------agent_based_modeling-----------------", "anchor_text": "Agent Based Modeling"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f1d32d53acb4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f1d32d53acb4---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----f1d32d53acb4---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff1d32d53acb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&user=Juan+Nathaniel&userId=7913527fa2dc&source=-----f1d32d53acb4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff1d32d53acb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&user=Juan+Nathaniel&userId=7913527fa2dc&source=-----f1d32d53acb4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1d32d53acb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff1d32d53acb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f1d32d53acb4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f1d32d53acb4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nathanieljuan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nathanieljuan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Juan Nathaniel"}, {"url": "https://medium.com/@nathanieljuan/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "658 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7913527fa2dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&user=Juan+Nathaniel&userId=7913527fa2dc&source=post_page-7913527fa2dc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7e37c55301c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-reinforcement-learning-tic-tac-toe-f1d32d53acb4&newsletterV3=7913527fa2dc&newsletterV3Id=7e37c55301c2&user=Juan+Nathaniel&userId=7913527fa2dc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}