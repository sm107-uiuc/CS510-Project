{"url": "https://towardsdatascience.com/spark-streaming-for-beginners-a0170113e479", "time": 1683011430.213245, "path": "towardsdatascience.com/spark-streaming-for-beginners-a0170113e479/", "webpage": {"metadata": {"title": "Spark Streaming for Beginners. Spark is deemed to be a highly fast\u2026 | by Priyanka Gupta | Towards Data Science", "h1": "Spark Streaming for Beginners", "description": "Spark is deemed to be a highly fast engine to process high volumes of data and is found to be 100 times faster than MapReduce. It is so as it uses distributed data processing through which it breaks\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Spark is deemed to be a highly fast engine to process high volumes of data and is found to be 100 times faster than MapReduce. It is so as it uses distributed data processing through which it breaks the data into smaller pieces so that the chunks of data can be computed in parallel across the machines which saves time. Also, it uses in-memory processing rather than disk based processing which allows the computation to be faster.", "Spark Streaming is one of the most important parts of Big Data ecosystem. It is a software framework from Apache Spark Foundation used to manage Big Data. Basically it ingests the data from sources like Twitter in real time, processes it using functions and algorithms and pushes it out to store it in databases and other places.", "First we configure spark and tell it from where it has to ingest the data, whether from local directory, spark cluster, mesos cluster or kubernetes cluster. If you are unfamiliar with these terms, don\u2019t worry. Basically these are cluster management systems which spark needs to handle tasks such as checking node health and scheduling jobs. If you choose your local directory as the master, you need to specify the number of cores from your local machine that you want spark to run on. The more cores you use to run, the faster would be the performance. If you specify *, it means use all the cores from your system. Then we specify app name which is the name we give to our spark application.", "Then we create an object of Java Streaming Context which kinda like opens the door for the streaming to start. It provides methods to create JavaDStream and JavaPairDStream from input sources which we\u2019ll discuss further. While creating Java Streaming Context object, we need to specify batch interval; basically spark streaming divides the incoming data into batches such that the final result is also generated in batches. A batch interval tells spark that for what duration you have to fetch the data, like if its 1 minute, it would fetch the data for the last 1 minute.", "So the data would start pouring in a stream in batches, this continuous stream of data is called DStream. Every batch of dsteam would contain collection of elements that can be processed in parallel, this collection is called RDD.", "To receive data, the streaming context provides method to stream data from a TCP socket connection or from files as input sources. The sources can be sources like HDFS, S3 etc. To read textfiles, there is textFileStream method of javastreamingcontext.", "But you won\u2019t be able to read the files already present in the directory before the streaming context starts, because it reads only the newly created files.", "So here I\u2019ll be streaming the data through socket connection through port 9999 and create a java receiver input DStream with it.", "So now if you establish a socket connection and write something in terminal, and run the dstream you\u2019ll see the text appearing in the console.", "Note: To start a java streaming context, we need to tell spark to start it, wait for computation to terminate and then stop it. And we need to print the DStream by method print().", "Notice when it prints the output at time t1, but no output is printed at time t2 and t3, as it fetches data for every minute. In the next batch intervals, it didn\u2019t receive any input, so it does not prints anything.", "Now I\u2019ll show you how we can use some transformations on these dstreams using lanbda functions.", "Map transformation applies the function we specify on the DStream and produces one output value for each input value. So it basically transform one stream to an other. Like here I want to count the length of the line of text, so I\u2019ll use map transformation for it.", "FlatMap transformation applies the function on DStream but can produce one or more output values for each input value. So if I want to transform the RDD such that it produces more than one values, I will use FlatMap transformation.", "So here I gave input a line of text \u2018hi how are you\u2019 and I want to split it into individual words. I used lambda function for the same. A FlatMap transformation returns arbitrary number of values that depends upon the rdd and the function applied, so the return type has to be a stream of values.", "A reduce transformation aggregates the elements in each RDD. It takes two arguments of single element RDDs and returns one.", "Here after we are apply flatMap function and return stream of words, I\u2019ll apply reduce transformation to get the word with highest length in each RDD.", "Try to understand this code, here it takes arguments of type String, wherein the words in each RDD are aggregated on basis of their length, and the word with maximum length is returned.", "Filter transformation filters the DStream according to the function given. Like after flatMap transformation, lets say I want to filter the word hello from the stream of words.", "Notice the word \u2018Hello\u2019 is not filtered as it includes upper case letter which we didn\u2019t specify in our code.", "mapToPair transformation transforms each input value to a pair of values.", "Notice here the object created is a JavaPairDStream rather than DStream as we are returning pairs in the stream.", "In a DStream, we can aggregate the elements of RDDs on the basis of key using reduceByKey. Unlike reduce transformation, it takes pairs of RDDs not single element RDDs. Like here it takes a tuple of String and Integer, and we are aggregating the count of the number of times a word appears in a RDD. It takes two arguments and returns one. But while specifying the call type, we aren\u2019t specifying tuple<String, Integer>, we are just specifying Integer as reduce by key will itself take note of the key and aggregate it on basis of the function specified.", "Count transformation counts the number of elements in each RDD and return a DStream with single element RDDs.", "Here after applying the flatMap transformation, we want to know the count of words in every RDD.", "So the number of words in the RDD were 13, so it returned 13 as output. This was after applying flatMap which split the line of words into individual words. If we apply without splitting the words lets see what we get.", "Since we haven\u2019t split the line of words into individual words, spark is treating the whole line as a single element. In the first batch, it receives 3 lines, so it returns count as 3, and next batches it receives 2 and 6 lines, so the count is 3 and 6 respectively.", "countByValue take a DStream of type k and counts the number of times the key appears in the RDD and returns a PairedDStream of (k, value) pairs.", "Here after I have split the line of words with flatMap, I applied countByValue transformation.", "Now I\u2019ll show you some actions we can perform on RDDs. So basically we are applying transformations on DStreams which contains RDDs, and we are applying functions on those RDDs when we specify a transformation. There are some actions spark provides that we can apply on these RDDs.", "So lets say I want to arrange the key value pairs I got after applying countByValue into descending order. What I can do is I can swap those key value pairs and then sort it which I\u2019ll show further. Using, mapToPair transformation, I am using swap action on RDDs to to change it to (Long, String) pairs.", "Now to sort the values in descending order, I can use sortByKey transformation of RDD. It will sort in ascending or descending order as per the boolean value specified. It we don\u2019t specify boolean value, it will sort in ascending as default.", "Now to use sortByKey, I will use transformToPair transformation. A transform function returns a new DStream by applying RDD to RDD transformation on every RDD. Here I want to return PairedDStream, so I\u2019ll use transformToPair.", "Now I can again swap the pairs using mapToPair to get words as Keys and counts as values.", "This was an outline of how spark streaming works and a few examples of how we apply transformations to DStreams. Thanks for reading!!! If you have doubts, you can ask me in the comment section.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science, Big Data, Machine Learning"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa0170113e479&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a0170113e479--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a0170113e479--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@priyanka1995?source=post_page-----a0170113e479--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@priyanka1995?source=post_page-----a0170113e479--------------------------------", "anchor_text": "Priyanka Gupta"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff31583f1af9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&user=Priyanka+Gupta&userId=f31583f1af9e&source=post_page-f31583f1af9e----a0170113e479---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa0170113e479&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa0170113e479&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@codestorm", "anchor_text": "Safar Safarov"}, {"url": "https://unsplash.com/photos/MSN8TFhJ0is", "anchor_text": "Unsplash.com"}, {"url": "https://spark.apache.org/docs/latest/streaming-programming-guide.html", "anchor_text": "spark.apache.org"}, {"url": "https://spark.apache.org/docs/latest/streaming-programming-guide.html", "anchor_text": "spark.apache.org"}, {"url": "https://spark.apache.org/docs/latest/streaming-programming-guide.html", "anchor_text": "spark.apache.org"}, {"url": "https://medium.com/tag/apache-spark?source=post_page-----a0170113e479---------------apache_spark-----------------", "anchor_text": "Apache Spark"}, {"url": "https://medium.com/tag/streaming?source=post_page-----a0170113e479---------------streaming-----------------", "anchor_text": "Streaming"}, {"url": "https://medium.com/tag/spark?source=post_page-----a0170113e479---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/java?source=post_page-----a0170113e479---------------java-----------------", "anchor_text": "Java"}, {"url": "https://medium.com/tag/kafka?source=post_page-----a0170113e479---------------kafka-----------------", "anchor_text": "Kafka"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa0170113e479&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&user=Priyanka+Gupta&userId=f31583f1af9e&source=-----a0170113e479---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa0170113e479&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&user=Priyanka+Gupta&userId=f31583f1af9e&source=-----a0170113e479---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa0170113e479&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a0170113e479--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa0170113e479&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a0170113e479---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a0170113e479--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a0170113e479--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a0170113e479--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a0170113e479--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a0170113e479--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a0170113e479--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a0170113e479--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a0170113e479--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@priyanka1995?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@priyanka1995?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Priyanka Gupta"}, {"url": "https://medium.com/@priyanka1995/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "19 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff31583f1af9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&user=Priyanka+Gupta&userId=f31583f1af9e&source=post_page-f31583f1af9e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1c5664c493a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-streaming-for-beginners-a0170113e479&newsletterV3=f31583f1af9e&newsletterV3Id=b1c5664c493a&user=Priyanka+Gupta&userId=f31583f1af9e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}