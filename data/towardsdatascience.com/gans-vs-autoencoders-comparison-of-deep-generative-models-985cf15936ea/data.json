{"url": "https://towardsdatascience.com/gans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea", "time": 1682996159.651582, "path": "towardsdatascience.com/gans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea/", "webpage": {"metadata": {"title": "GANs vs. Autoencoders: Comparison of Deep Generative Models | by Matthew Stewart, PhD | Towards Data Science", "h1": "GANs vs. Autoencoders: Comparison of Deep Generative Models", "description": "\u201cGenerative Adversarial Networks is the most interesting idea in the last 10 years in Machine Learning.\u201d \u2014 Yann LeCun, Director of AI Research at Facebook AI These articles are based on lectures\u2026"}, "outgoing_paragraph_urls": [{"url": "https://harvard-iacs.github.io/2019-CS109B/", "anchor_text": "AC209b", "paragraph_index": 3}, {"url": "https://iacs.seas.harvard.edu/people/pavlos-protopapas", "anchor_text": "Pavlos Protopapas", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/generating-images-with-autoencoders-77fd3a8dd368", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "\u201cAutoencoding beyond pixels using a learned similarity metric\u201d", "paragraph_index": 33}, {"url": "https://techblog.appnexus.com/a-keras-multithreaded-dataframe-generator-for-millions-of-image-files-84d3027f6f43", "anchor_text": "Keras Custom Data Generator", "paragraph_index": 34}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "\u201cAutoencoding beyond pixels using a learned similarity metric\u201d", "paragraph_index": 48}, {"url": "https://mpstewart.io", "anchor_text": "https://mpstewart.io", "paragraph_index": 61}], "all_paragraphs": ["\u201cGenerative Adversarial Networks is the most interesting idea in the last 10 years in Machine Learning.\u201d \u2014 Yann LeCun, Director of AI Research at Facebook AI", "Part 1 of this tutorial can be found here:", "Part 2of this tutorial can be found here:", "These articles are based on lectures taken at Harvard on AC209b, with major credit going to lecturer Pavlos Protopapas of the Harvard IACS department.", "This is the third part of a three-part tutorial on creating deep generative models specifically using generative adversarial networks. This is a natural extension to the previous topic on variational autoencoders (found here). We will see that GANs are typically superior as deep generative models as compared to variational autoencoders. However, they are notoriously difficult to work with and require a lot of data and tuning. We will also examine a hybrid model of GAN called a VAE-GAN.", "This part of the tutorial will mostly be a coding implementation of variational autoencoders (VAEs), GANs, and will also show the reader how to make a VAE-GAN.", "I strongly recommend the reader to review at least part 1 of the GAN tutorial, as well as my variational autoencoder walkthrough before going further, as otherwise, the implementation may not may much sense to the reader.", "All related code can now be found in my GitHub repository:", "The CelebFaces Attributes Dataset (CelebA) is a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations. The images in this dataset cover large pose variations and background clutter. CelebA has large diversities, large quantities, and rich annotations, including", "You can download the dataset from Kaggle here:", "The first step is to import all our necessary functions and extract the data.", "This step is likely something most readers have not used before. Due to the huge size of our data, it may not be possible to load the dataset into the memory of your Jupyter Notebook. This is a pretty normal problem to have when working on large datasets.", "A workaround for this is to use a stream generator, which streams batches of data (images in this case) into memory sequentially, thereby limiting the amount of memory that is required for the function. The caveat to this is that they are a bit complicated to understand and code, as they require a reasonable understanding of computer memory, GPU architecture, etc.", "For more information on writing custom generators in Keras, a good article to check out is the one I referenced in the above code:", "Not only do we have images for this dataset, but each image also has a list of attributes corresponding to aspects of the celebrity. For example, there are attributes describing whether the celebrity is wearing lipstick, or a hat, whether they are young or not, whether they have black hair, etc.", "Now we finish making the generator. We set the image name length to 6 since we have a 6 digit number of images in our dataset. This section of code should make sense after reading the custom Keras generator article.", "We can now pick three images and check that attributes make sense.", "First, we will create and compile a Convolutional VAE Model (including encoder and decoder) for the celebrity faces dataset.", "Now we can create and make a summary of the model.", "We randomly choose some images of the training set, run them through the encoder to parameterize the latent code, and then reconstruct the images with the decoder.", "Notice that the reconstructed images share similarities with the original versions. However, the new images are a bit blurry, which is a known phenomenon of VAEs. This has been hypothesized to be due to the fact that variational inference optimizes a lower bound to the likelihood, not the actual likelihood itself.", "We can choose two images with different attributes and plot their latent space representations. Notice that we can see some differences between the latent codes, which we might hypothesize as explaining the differences between the original images.", "We can randomly sample 15 latent codes and decode them to generate new celebrity faces. We can see from this representation that the images generated by our model is of great similar styles with those images in our training set and it is also of good reality and variations.", "So it seems that our VAE model is not particularly good. With more time and better selection of hyperparameters and so on, we would probably have achieved a better result than this.", "Now let us compare this result to a DC-GAN on the same dataset.", "Since we have already set up the stream generator, there is not too much work to do to get the DC-GAN model up and running.", "The above code is just for the architecture of the generator and discriminator network. Comparing this method of coding the GAN to that which I did in part 2 is a good idea, you can see this one is less clean and we did not define global parameters, so there are many places we could have potential errors.", "Now we define a bunch of functions to make our life easier, these are mostly just for the preprocessing and plotting of images to help us in analyzing the network output.", "We now define the training function. As we did before, notice that we switch between setting the discriminator to be trainable and untrainable (we did this implicitly in part 2).", "The output of this function will give us the following output for each epoch:", "It will also plot our validation losses for the discriminator and generator.", "The generated images look reasonable. Here we can see that our model performed adequately, though the quality of images is not so good as those in the training set (since we reshaped the images to become smaller and made them more blurry than the original ones). However, they are vivid enough to create valid faces, and these faces are close enough to reality. Also, compared with images produced by VAE, the images are more creative and real-looking.", "So it seems that the GAN performs superior in this circumstance. Now let us try a new dataset and see how well a GAN can perform compared to a hybrid variant, the VAE-GAN.", "In this section, we will aim to generate faces in the same style as the Anime dataset using a GAN, as well as another special form of GAN, a VAE-GAN. The term VAE-GAN was first used by Larsen et. al in their paper \u201cAutoencoding beyond pixels using a learned similarity metric\u201d. VAE-GAN models differentiate themselves from GANs in that their generators are variation autoencoders.", "First, we will focus on the DC-GAN. The Anime dataset consists of over 20K anime faces in the form of 64x64 images. We will also need to create another Keras Custom Data Generator. A link to the dataset can be found here:", "The first thing we need to do is create anime directory and download the data. This can be done from the link above. It is always good practice to check the data before moving ahead, so we do this now.", "We now create and compile our DC-GAN model.", "We can now train the model on the Anime dataset. We will do this in two different ways, the first will involve training the discriminator and generator with a 1:1 proportion of training times.", "The output will now start printing a series of anime characters. They are very grainy at first, and over time gradually become more and more pronounced.", "We will also get a plot of our generator and discriminator loss functions.", "Now we will do the same but with different training times for the discriminator and generator to see what the effect has been.", "Before moving forward, it is good to save the weights of the model somewhere so that you do not need to run the entire training again, and can instead just load the weights into the network.", "Now we move onto the second network implementation without worrying about saving over our previous network.", "Let us compare the output of these two networks. By running the line:", "the network will output some images from the generator (this is one of the functions we defined earlier).", "Now let\u2019s check the second model.", "We can see that the details of the generated images are improved and the texture of them are slightly more detailed. However, in comparison to the training images they are still sub-par.", "Perhaps the VAE-GAN will perform better?", "To reiterate what I said previously about the VAE-GAN, the term VAE-GAN was first used by Larsen et. al in their paper \u201cAutoencoding beyond pixels using a learned similarity metric\u201d. VAE-GAN models differentiate themselves from GANs in that their generators are variation autoencoders.", "First we need to create and compile the VAE-GAN and make a summary for each of the networks (this is a good way to simply check the architecture).", "We once again define some functions so that we can just print images from the generator.", "The parameters of the generator will be affected by both the GAN and VAE training.", "In the below cell we begin training our model. Note that we use the previous method to train the discriminator and GAN and VAE for different lengths of time. We emphasize the training of the discriminator in the first half of the training process and we train the generator more in the second half because we want to improve the quality of output images.", "If you are planning on running this network, beware that the training process takes a REALLY long time. I would not attempt this unless you have access to some powerful GPUs or are willing to run the model for an entire day.", "Now our VAE-GAN training is complete, we can check to see how our output images look and compare them to our previous GANs.", "We can see that in this implementation of VAE-GAN, we got a nice model which can generate images that are clear and of a similar style to the original images. Our VAE-GAN can create images more robustly and this can be done without extra noise of the anime faces. However, the competence of generalization of our model is not very good, it seldom changes the manner or sex of the character, so this is a point that we could try to improve.", "It is not necessarily clear that any one of the models is better than the others, and none of these methods have been optimized properly so it is difficult to make a comparison.", "This is still an active area of research, so if you are interested I recommend getting yourself stuck in and try and use GANs within your own work to see what you can come up with.", "I hope you have enjoyed this trilogy of articles on GANs and now have a much better idea of what they are, what they can do, and how to make your own.", "For updates on new blog posts and extra content, sign up for my newsletter.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML Postdoc @Harvard | Environmental + Data Science PhD @Harvard | ML consultant @Critical Future | Blogger @TDS | Content Creator @EdX. https://mpstewart.io"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F985cf15936ea&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----985cf15936ea--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----985cf15936ea--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@matthew_stewart?source=post_page-----985cf15936ea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@matthew_stewart?source=post_page-----985cf15936ea--------------------------------", "anchor_text": "Matthew Stewart, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb89dbc0712c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&user=Matthew+Stewart%2C+PhD&userId=b89dbc0712c4&source=post_page-b89dbc0712c4----985cf15936ea---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F985cf15936ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F985cf15936ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/comprehensive-introduction-to-turing-learning-and-gans-part-1-81f6d02e644d", "anchor_text": "Introduction to Turing Learning and GANsWant to turn horses into zebras? Make DIY anime characters or celebrities? Generative adversarial networks (GANs) are\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/comprehensive-introduction-to-turing-learning-and-gans-part-2-fd8e4a70775", "anchor_text": "Advanced Topics in GANsWant to turn horses into zebras? Make DIY anime characters or celebrities? Generative adversarial networks (GANs) are\u2026towardsdatascience.com"}, {"url": "https://harvard-iacs.github.io/2019-CS109B/", "anchor_text": "AC209b"}, {"url": "https://iacs.seas.harvard.edu/people/pavlos-protopapas", "anchor_text": "Pavlos Protopapas"}, {"url": "https://towardsdatascience.com/generating-images-with-autoencoders-77fd3a8dd368", "anchor_text": "here"}, {"url": "https://github.com/mrdragonbear/GAN-Tutorial", "anchor_text": "mrdragonbear/GAN-TutorialGitHub is home to over 50 million developers working together to host and review code, manage projects, and build\u2026github.com"}, {"url": "https://www.kaggle.com/jessicali9530/celeba-dataset", "anchor_text": "CelebFaces Attributes (CelebA) DatasetOver 200k images of celebrities with 40 binary attribute annotationswww.kaggle.com"}, {"url": "https://medium.com/@ensembledme/writing-custom-keras-generators-fe815d992c5a", "anchor_text": "Writing Custom Keras GeneratorsThe idea behind using a Keras generator is to get batches of input and corresponding output on the fly during training\u2026medium.com"}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "\u201cAutoencoding beyond pixels using a learned similarity metric\u201d"}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "https://arxiv.org/abs/1512.09300"}, {"url": "https://techblog.appnexus.com/a-keras-multithreaded-dataframe-generator-for-millions-of-image-files-84d3027f6f43", "anchor_text": "Keras Custom Data Generator"}, {"url": "https://github.com/Mckinsey666/Anime-Face-Dataset", "anchor_text": "Mckinsey666/Anime-Face-Dataset\ud83d\uddbc A collection of high-quality anime faces. Contribute to Mckinsey666/Anime-Face-Dataset development by creating an\u2026github.com"}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "\u201cAutoencoding beyond pixels using a learned similarity metric\u201d"}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "https://arxiv.org/abs/1512.09300"}, {"url": "https://mailchi.mp/6304809e49e7/matthew-stewart", "anchor_text": "Newsletter SubscriptionEnrich your academic journey by joining a community of scientists, researchers, and industry professionals to obtain\u2026mailchi.mp"}, {"url": "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb", "anchor_text": "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb"}, {"url": "https://www.jessicayung.com/explaining-tensorflow-code-for-a-convolutional-neural-network/", "anchor_text": "https://www.jessicayung.com/explaining-tensorflow-code-for-a-convolutional-neural-network/"}, {"url": "https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html", "anchor_text": "https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html"}, {"url": "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html", "anchor_text": "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"}, {"url": "https://github.com/tensorlayer/srgan", "anchor_text": "https://github.com/tensorlayer/srgan"}, {"url": "https://junyanz.github.io/CycleGAN/", "anchor_text": "https://junyanz.github.io/CycleGAN/"}, {"url": "https://affinelayer.com/pixsrv/", "anchor_text": "https://affinelayer.com/pixsrv/"}, {"url": "https://tcwang0509.github.io/pix2pixHD/", "anchor_text": "https://tcwang0509.github.io/pix2pixHD/"}, {"url": "https://arxiv.org/pdf/1511.06434v2.pdf", "anchor_text": "https://arxiv.org/pdf/1511.06434v2.pdf"}, {"url": "https://arxiv.org/pdf/1701.07875.pdf", "anchor_text": "https://arxiv.org/pdf/1701.07875.pdf"}, {"url": "https://arxiv.org/pdf/1411.1784v1.pdf", "anchor_text": "https://arxiv.org/pdf/1411.1784v1.pdf"}, {"url": "https://arxiv.org/pdf/1506.05751.pdf", "anchor_text": "https://arxiv.org/pdf/1506.05751.pdf"}, {"url": "https://arxiv.org/pdf/1609.04802.pdf", "anchor_text": "https://arxiv.org/pdf/1609.04802.pdf"}, {"url": "https://arxiv.org/pdf/1703.10593.pdf", "anchor_text": "https://arxiv.org/pdf/1703.10593.pdf"}, {"url": "https://arxiv.org/pdf/1606.03657", "anchor_text": "https://arxiv.org/pdf/1606.03657"}, {"url": "https://arxiv.org/pdf/1704.00028.pdf", "anchor_text": "https://arxiv.org/pdf/1704.00028.pdf"}, {"url": "https://arxiv.org/pdf/1701.07875.pdf", "anchor_text": "https://arxiv.org/pdf/1701.07875.pdf"}, {"url": "https://arxiv.org/pdf/1609.03126.pdf", "anchor_text": "https://arxiv.org/pdf/1609.03126.pdf"}, {"url": "https://arxiv.org/pdf/1512.09300.pdf", "anchor_text": "https://arxiv.org/pdf/1512.09300.pdf"}, {"url": "https://arxiv.org/pdf/1605.09782v6.pdf", "anchor_text": "https://arxiv.org/pdf/1605.09782v6.pdf"}, {"url": "https://arxiv.org/pdf/1612.04357.pdf", "anchor_text": "https://arxiv.org/pdf/1612.04357.pdf"}, {"url": "https://arxiv.org/pdf/1710.10916.pdf", "anchor_text": "https://arxiv.org/pdf/1710.10916.pdf"}, {"url": "https://arxiv.org/pdf/1612.07828v1.pdf", "anchor_text": "https://arxiv.org/pdf/1612.07828v1.pdf"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----985cf15936ea---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----985cf15936ea---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----985cf15936ea---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----985cf15936ea---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----985cf15936ea---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F985cf15936ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&user=Matthew+Stewart%2C+PhD&userId=b89dbc0712c4&source=-----985cf15936ea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F985cf15936ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&user=Matthew+Stewart%2C+PhD&userId=b89dbc0712c4&source=-----985cf15936ea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F985cf15936ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----985cf15936ea--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F985cf15936ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----985cf15936ea---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----985cf15936ea--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----985cf15936ea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----985cf15936ea--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----985cf15936ea--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----985cf15936ea--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----985cf15936ea--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----985cf15936ea--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----985cf15936ea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@matthew_stewart?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@matthew_stewart?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Matthew Stewart, PhD"}, {"url": "https://medium.com/@matthew_stewart/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "6.5K Followers"}, {"url": "https://mpstewart.io", "anchor_text": "https://mpstewart.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb89dbc0712c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&user=Matthew+Stewart%2C+PhD&userId=b89dbc0712c4&source=post_page-b89dbc0712c4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F20066c159638&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-vs-autoencoders-comparison-of-deep-generative-models-985cf15936ea&newsletterV3=b89dbc0712c4&newsletterV3Id=20066c159638&user=Matthew+Stewart%2C+PhD&userId=b89dbc0712c4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}