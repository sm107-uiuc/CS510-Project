{"url": "https://towardsdatascience.com/the-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f", "time": 1683015673.733571, "path": "towardsdatascience.com/the-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f/", "webpage": {"metadata": {"title": "The Upper Confidence Bound (UCB) Bandit Algorithm | by Steve Roberts | Towards Data Science", "h1": "The Upper Confidence Bound (UCB) Bandit Algorithm", "description": "In this, the fourth part of our series on Multi-Armed Bandits, we\u2019re going to take a look at the Upper Confidence Bound (UCB) algorithm that can be used to solve the bandit problem. If you\u2019re not\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/WhatIThinkAbout/BabyRobot/tree/master/Multi_Armed_Bandits", "anchor_text": "Multi_Armed_Bandits", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18#19ae", "anchor_text": "Epsilon-Greedy has linear regret", "paragraph_index": 10}, {"url": "https://towardsdatascience.com/multi-armed-bandits-part-2-5834cb7aba4b", "anchor_text": "Part 2", "paragraph_index": 15}, {"url": "https://github.com/WhatIThinkAbout/BabyRobot/tree/master/Multi_Armed_Bandits", "anchor_text": "github", "paragraph_index": 15}], "all_paragraphs": ["In this, the fourth part of our series on Multi-Armed Bandits, we\u2019re going to take a look at the Upper Confidence Bound (UCB) algorithm that can be used to solve the bandit problem.", "If you\u2019re not already familiar with the bandit problem and its terminology you may want to first take a look at the earlier parts of this series, which are as follows:", "All code for the bandit algorithms and testing framework can be found on github: Multi_Armed_Bandits", "Baby Robot is lost in the mall. Using Reinforcement Learning we want to help him find his way back to his mum. However, before he can even begin looking for her, he needs to recharge, from a set of power sockets that each give a slightly different amount of charge.", "Using the strategies from the multi-armed bandit problem we need to find the best socket, in the shortest amount of time, to allow Baby Robot to get charged up and on his way.", "Baby Robot has entered a charging room containing 5 different power sockets. Each of these sockets returns a slightly different amount of charge. We want to get Baby Robot charged up in the minimum amount of time, so we need to locate the best socket and then use it until charging is complete.", "This is identical to the Multi-Armed Bandit problem except that, instead of looking for a slot machine that gives the best payout, we\u2019re looking for a power socket that gives the most charge.", "In the Power Socket problem, where we\u2019re trying to get the most charge in the shortest amount of time, we\u2019ve seen that there\u2019s a trade-off between the amount of time we spend exploring, in search of the best socket, and the time spent exploiting the socket that currently gives the best return. If we take too long exploring then we\u2019re potentially missing out on using sockets that have already shown a high return. Alternatively, if we just exploit the sockets that have performed well then we might not find the best socket and potentially miss out on getting the maximum possible return.", "Obviously the best approach would be to choose the best socket every time and this is what\u2019s known as the optimal policy. It\u2019s also obvious that this approach isn\u2019t actually practical, since you initially don\u2019t know which socket is the best. Some time has to be spent investigating how the sockets perform if you\u2019re going to find the best one and therefore it\u2019s not always possible to choose the best action.", "The optimal policy, although only theoretical, can however be used to evaluate other policies, to see how close they come to being optimal. The difference between the return that would be achieved by the optimal policy and the amount of return actually achieved by the policy under test is known as the regret. In this case the return is the amount of charge from the sockets and the policy is the method or strategy used to select the sockets to try.", "As we\u2019ve seen, Epsilon-Greedy has linear regret. It continues to explore the set of all actions, long after it has gained sufficient knowledge to know which of these actions are bad actions to take.", "A better approach, in terms of maximising the total reward, would be to restrict the sampling over time to the actions showing the best performance. This is the exact approach taken by the Upper Confidence Bound (UCB) strategy.", "Rather than performing exploration by simply selecting an arbitrary action, chosen with a probability that remains constant, the UCB algorithm changes its exploration-exploitation balance as it gathers more knowledge of the environment. It moves from being primarily focused on exploration, when actions that have been tried the least are preferred, to instead concentrate on exploitation, selecting the action with the highest estimated reward.", "With UCB, \u2018A\u209c\u2019, the action chosen at time step \u2018t\u2019, is given by:", "The formula for UCB can be thought of as being formed from 2 distinct parts:", "To investigate the performance of the UCB algorithm we\u2019ll add another socket class to our test system. The full details of this test system are described in Part 2 of this series and all the code can be found in the github repository.", "The UCB socket needs to slightly modify the base power socket class, to add uncertainty to the metric it uses to evaluate a socket. So the \u2018sample\u2019 function now returns the sum of the estimated mean reward and the uncertainty value, which is calculated as a function of the number of times the socket has been tried and the current time step.", "The socket tester class reverts to the standard socket tester, with sockets being selected based only on the socket that returns the largest value from its sample function (i.e. the random sampling of the epsilon-greedy algorithm is no longer required).", "Using our test system we can analyse the performance of the UCB algorithm. To simplify the comparison, we\u2019ve taken only the first 2 sockets from our standard set. These 2 sockets have mean reward values of 6 and 4 seconds of charge respectively. The relative contributions of each of the exploration and exploitation terms can clearly be seen in the graph below.", "The main things to note here are:", "In-depth analysis of the UCB graph", "Some more, in depth observations, from the UCB graph are as follows:", "* The socket uncertainty value is set to infinity if a socket has not yet been tried, causing an initial priming round to be performed, in which each action is tried once to get its initial value. This then avoids divide-by-zero errors in the exploration term when actions have not yet been tried and N\u209c(a) is equal to zero. Obviously this is only applicable when there are fewer possible actions \u2018k\u2019 than there are time steps \u2018t\u2019, otherwise there wouldn\u2019t be enough time to try every action.", "* Due to the priming round the graph begins at time step 2. The number of times that each socket has been selected is shown by the number at the top of each bar. So, at time step 2, it can be seen that each socket has been selected once. Since each socket has been tried the same number of times the contribution of the uncertainty term is the same for each socket. However, due to its larger reward estimate \u2018Q\u2019, socket 1 has the largest total UCB value and is therefore selected by the argmax function.", "* At time step 3, socket 1 was the selected socket at the previous time step, so the count of the number of times it has been tried increases to 2. As a result the uncertainty term for this socket shrinks, so the solid blue bar can be seen to decrease in size. The hatched yellow bar also decreases due to this socket having been sampled and forming a better estimate for the true socket reward.On the other hand, socket 2 wasn\u2019t selected, so its reward estimate stays the same. The number of times it has been selected also stays the same, while the number of time steps increases, consequently the size of its uncertainty term increases, so the solid green bar can be seen to get bigger.However, the overall size of the UCB term for socket 1 is still greater than that of socket 2, so once again it is the socket that gets selected.", "* Eventually, at time step 5, socket 2\u2019s uncertainty term has increased sufficiently to make its total UCB value greater than that of socket 1 and so it is the socket that gets chosen. Once this happens its estimated reward value moves closer to the true mean reward, its uncertainty term shrinks and the whole process begins again.", "The behaviour of the UCB algorithm, over a range of confidence values, is shown below. The confidence parameter controls the level of exploration. In the case of our simple Power Socket experiment it can actually be seen that the greater the level of exploration the lower the mean total reward. This is due to each socket having a distinct value and a limited range of possible values, such that the other sockets are unlikely to generate values in the same range.", "As a result, in our simple experiment, it looks like exploration is actually unnecessary. After the initial priming step the UCB algorithm has already locked on to the optimal socket and produces the best results when it can just exploit this knowledge. Increasing the value of the confidence parameter sharply reduces the mean total reward and this decrease continues until the algorithm becomes no better than random search.", "A closer examination of the variation of the mean total reward as the confidence level is increased is shown below. Here it can be seen that the mean total reward does increase slightly, from having a confidence parameter of zero up to a value of about 0.6, after which it falls off rapidly. So a small degree of exploration is required to get the best results.", "Analysing how often each socket is selected, with the confidence parameter set to a value of 0.6 (the value that gave the maximum mean total reward, as shown above), gives the graph shown below. Here it can be seen that during the initial priming round, when a socket\u2019s uncertainty is set to infinity if it has not yet been tried, that each socket is selected exactly once during the first 5 time steps. After this point the optimal socket (socket 4) has already been identified as the best socket and so is selected for nearly all of the remaining trials.", "Due to the optimal action being identified quickly, and only trying the other actions when they have high uncertainty, the UCB method shows a much lower level of regret than seen in the Epsilon-Greedy method.", "As can be seen in the graphs below, the optimal and actual rewards are almost identical (so much so that the actual line is obscured by the optimal line) and regret is almost flat.", "The vast majority of the regret occurs during the initial priming round, where each socket is being tried once to get its first estimate. Indeed, it has been shown that the expected cumulative regret of UCB is logarithmic in \u2019T\u2019, the total number of time-steps.", "For an in-depth examination of UCB regret and UCB in general check out the following resources:", "In problems such as Socket Selection or the Multi-Armed Bandit, when faced with the dilemma of how to strike a balance between searching for the actions that give the best return and exploiting those that have already been found, it is important to use an approach that can modify the levels of exploration and exploitation.", "As we saw with the Epsilon-Greedy algorithm it simply maintains a constant level of exploration, continuing to explore the set of all actions as time progresses. As a result, it has linear regret. The difference between the reward it achieves and the maximum possible reward continues to increase with time.", "On the other hand, the Upper Confidence Bound (UCB) algorithm modifies its levels of exploration and exploitation. Initially, when it has little knowledge of the available actions, and a low confidence in the best actions to take, the exploration part of its equation causes it to search through the set of all possible actions.", "As exploration progresses better estimates are formed for the rewards given by each action. Therefore the level of exploration can be decreased and the use of the good actions that have been found can increase. Gradually the focus of the algorithm swings from exploration to favour exploitation. By shifting this balance as time progresses the UCB algorithm reduces its regret and, consequently, is able to achieve a much lower level of regret than that seen in Epsilon-Greedy.", "In the next part we\u2019ll take a look at Thompson Sampling, an even more sophisticated approach to balancing exploration and exploitation. Using this we\u2019ll get Baby Robot charged and ready to go in practically no time!", "Ph.D., \"The evolution of artificial neural networks\""], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc05c2bf4c13f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://towardsdatascience.com/tagged/baby-robot-guide", "anchor_text": "A Baby Robot\u2019s Guide To Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b6735266652&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&user=Steve+Roberts&userId=6b6735266652&source=post_page-6b6735266652----c05c2bf4c13f---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc05c2bf4c13f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&user=Steve+Roberts&userId=6b6735266652&source=-----c05c2bf4c13f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc05c2bf4c13f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&source=-----c05c2bf4c13f---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@artmatters?utm_source=medium&utm_medium=referral", "anchor_text": "Artur Matosyan"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/multi-armed-bandits-part-1-b8d33ab80697", "anchor_text": "Part 1: Mathematical Framework and Terminology"}, {"url": "https://towardsdatascience.com/multi-armed-bandits-part-2-5834cb7aba4b", "anchor_text": "Part 2: The Bandit Framework"}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18", "anchor_text": "Part 3: Bandit Algorithms"}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18#d7a7", "anchor_text": "The Greedy Algorithm"}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18#1519", "anchor_text": "The Optimistic-Greedy Algorithm"}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18#0145", "anchor_text": "The Epsilon-Greedy Algorithm (\u03b5-Greedy)"}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18#b390", "anchor_text": "Regret"}, {"url": "https://github.com/WhatIThinkAbout/BabyRobot/tree/master/Multi_Armed_Bandits", "anchor_text": "Multi_Armed_Bandits"}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18#19ae", "anchor_text": "Epsilon-Greedy has linear regret"}, {"url": "https://towardsdatascience.com/multi-armed-bandits-part-2-5834cb7aba4b", "anchor_text": "Part 2"}, {"url": "https://github.com/WhatIThinkAbout/BabyRobot/tree/master/Multi_Armed_Bandits", "anchor_text": "github"}, {"url": "https://banditalgs.com/2016/09/18/the-upper-confidence-bound-algorithm/", "anchor_text": "book and website on Bandit Algorithms"}, {"url": "http://dx.doi.org/10.1016/0196-8858(85)90002-8", "anchor_text": "Asymptotically efficient adaptive allocation rules"}, {"url": "https://towardsdatascience.com/bandit-algorithms-34fd7890cb18", "anchor_text": "Bandit Algorithms"}, {"url": "https://towardsdatascience.com/thompson-sampling-fc28817eacb8", "anchor_text": "Thompson Sampling"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----c05c2bf4c13f---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/multi-armed-bandit?source=post_page-----c05c2bf4c13f---------------multi_armed_bandit-----------------", "anchor_text": "Multi Armed Bandit"}, {"url": "https://medium.com/tag/baby-robot-guide?source=post_page-----c05c2bf4c13f---------------baby_robot_guide-----------------", "anchor_text": "Baby Robot Guide"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----c05c2bf4c13f---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc05c2bf4c13f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&user=Steve+Roberts&userId=6b6735266652&source=-----c05c2bf4c13f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc05c2bf4c13f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&user=Steve+Roberts&userId=6b6735266652&source=-----c05c2bf4c13f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc05c2bf4c13f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b6735266652&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&user=Steve+Roberts&userId=6b6735266652&source=post_page-6b6735266652----c05c2bf4c13f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1d5f26d16450&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&newsletterV3=6b6735266652&newsletterV3Id=1d5f26d16450&user=Steve+Roberts&userId=6b6735266652&source=-----c05c2bf4c13f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Written by Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/followers?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "593 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b6735266652&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&user=Steve+Roberts&userId=6b6735266652&source=post_page-6b6735266652----c05c2bf4c13f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1d5f26d16450&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f&newsletterV3=6b6735266652&newsletterV3Id=1d5f26d16450&user=Steve+Roberts&userId=6b6735266652&source=-----c05c2bf4c13f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/policy-and-value-iteration-78501afb41d2?source=author_recirc-----c05c2bf4c13f----0---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=author_recirc-----c05c2bf4c13f----0---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=author_recirc-----c05c2bf4c13f----0---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Steve Roberts"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c05c2bf4c13f----0---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/policy-and-value-iteration-78501afb41d2?source=author_recirc-----c05c2bf4c13f----0---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Policy and Value IterationAn Introduction to Reinforcement Learning: Part 3"}, {"url": "https://towardsdatascience.com/policy-and-value-iteration-78501afb41d2?source=author_recirc-----c05c2bf4c13f----0---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "\u00b716 min read\u00b7Jul 12, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F78501afb41d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-and-value-iteration-78501afb41d2&user=Steve+Roberts&userId=6b6735266652&source=-----78501afb41d2----0-----------------clap_footer----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/policy-and-value-iteration-78501afb41d2?source=author_recirc-----c05c2bf4c13f----0---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F78501afb41d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-and-value-iteration-78501afb41d2&source=-----c05c2bf4c13f----0-----------------bookmark_preview----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c05c2bf4c13f----1---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c05c2bf4c13f----1---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c05c2bf4c13f----1---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c05c2bf4c13f----1---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c05c2bf4c13f----1---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c05c2bf4c13f----1---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c05c2bf4c13f----1---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----c05c2bf4c13f----1-----------------bookmark_preview----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c05c2bf4c13f----2---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----c05c2bf4c13f----2---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----c05c2bf4c13f----2---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c05c2bf4c13f----2---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c05c2bf4c13f----2---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c05c2bf4c13f----2---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c05c2bf4c13f----2---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----c05c2bf4c13f----2-----------------bookmark_preview----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/thompson-sampling-fc28817eacb8?source=author_recirc-----c05c2bf4c13f----3---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=author_recirc-----c05c2bf4c13f----3---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=author_recirc-----c05c2bf4c13f----3---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Steve Roberts"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c05c2bf4c13f----3---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/thompson-sampling-fc28817eacb8?source=author_recirc-----c05c2bf4c13f----3---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "Thompson SamplingMulti-Armed Bandits: Part 5"}, {"url": "https://towardsdatascience.com/thompson-sampling-fc28817eacb8?source=author_recirc-----c05c2bf4c13f----3---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": "\u00b717 min read\u00b7Nov 2, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc28817eacb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthompson-sampling-fc28817eacb8&user=Steve+Roberts&userId=6b6735266652&source=-----fc28817eacb8----3-----------------clap_footer----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/thompson-sampling-fc28817eacb8?source=author_recirc-----c05c2bf4c13f----3---------------------568e681b_7fad_402e_ad41_de7b38e4198a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "8"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc28817eacb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthompson-sampling-fc28817eacb8&source=-----c05c2bf4c13f----3-----------------bookmark_preview----568e681b_7fad_402e_ad41_de7b38e4198a-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "See all from Steve Roberts"}, {"url": "https://towardsdatascience.com/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----c05c2bf4c13f----0-----------------bookmark_preview----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----c05c2bf4c13f----1-----------------bookmark_preview----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Trust Region Policy Optimization (TRPO) ExplainedThe Reinforcement Learning algorithm TRPO builds upon natural policy gradient algorithms, ensuring updates remain within \u2018trustworthy\u2019\u2026"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "\u00b712 min read\u00b7Oct 12, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----4b56bd206fc2----0-----------------clap_footer----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----c05c2bf4c13f----0---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&source=-----c05c2bf4c13f----0-----------------bookmark_preview----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Piotr Krosniak"}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Vaccine Supply Chain Optimization with AI-Powered Capacitated Vehicle Routing Problem(CVRP)- Part 1The world is facing a global health crisis, and one of the most important challenges is to ensure an efficient and timely distribution of\u2026"}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "6 min read\u00b7Jan 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fca79519e9ad7&operation=register&redirect=https%3A%2F%2Fpiotrkrosniak.medium.com%2Fvaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7&user=Piotr+Krosniak&userId=b791abcfafd5&source=-----ca79519e9ad7----1-----------------clap_footer----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----c05c2bf4c13f----1---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca79519e9ad7&operation=register&redirect=https%3A%2F%2Fpiotrkrosniak.medium.com%2Fvaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7&source=-----c05c2bf4c13f----1-----------------bookmark_preview----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c05c2bf4c13f----2---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----c05c2bf4c13f----2---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----c05c2bf4c13f----2---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c05c2bf4c13f----2---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c05c2bf4c13f----2---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c05c2bf4c13f----2---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c05c2bf4c13f----2---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----c05c2bf4c13f----2-----------------bookmark_preview----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c05c2bf4c13f----3---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c05c2bf4c13f----3---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----c05c2bf4c13f----3---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c05c2bf4c13f----3---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c05c2bf4c13f----3---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----3-----------------clap_footer----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----c05c2bf4c13f----3---------------------4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----c05c2bf4c13f----3-----------------bookmark_preview----4c3d8514_fbc4_477a_9c6d_edff6b9d9a05-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----c05c2bf4c13f--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}