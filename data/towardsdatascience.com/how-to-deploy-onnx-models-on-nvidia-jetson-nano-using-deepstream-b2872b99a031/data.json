{"url": "https://towardsdatascience.com/how-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031", "time": 1683001782.3720262, "path": "towardsdatascience.com/how-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031/", "webpage": {"metadata": {"title": "How to deploy ONNX models on NVIDIA Jetson Nano using DeepStream | by Bharath Raj | Towards Data Science", "h1": "How to deploy ONNX models on NVIDIA Jetson Nano using DeepStream", "description": "Deploying complex deep learning models onto small embedded devices is challenging. Even with hardware optimized for deep learning such as the Jetson Nano and inference optimization tools such as\u2026"}, "outgoing_paragraph_urls": [{"url": "https://developer.nvidia.com/embedded/jetson-nano-developer-kit", "anchor_text": "Jetson Nano", "paragraph_index": 0}, {"url": "https://developer.nvidia.com/tensorrt", "anchor_text": "TensorRT", "paragraph_index": 0}, {"url": "https://developer.nvidia.com/deepstream-sdk", "anchor_text": "DeepStream", "paragraph_index": 1}, {"url": "https://gstreamer.freedesktop.org/", "anchor_text": "GStreamer", "paragraph_index": 1}, {"url": "https://developer.nvidia.com/deepstream-sdk#plugins", "anchor_text": "GStreamer Plugins", "paragraph_index": 2}, {"url": "https://developer.nvidia.com/tensorrt", "anchor_text": "TensorRT", "paragraph_index": 2}, {"url": "https://docs.nvidia.com/metropolis/deepstream/plugin-manual/index.html", "anchor_text": "Plugin Manual", "paragraph_index": 2}, {"url": "https://developer.nvidia.com/embedded/jetson-nano-developer-kit", "anchor_text": "Jetson Nano", "paragraph_index": 6}, {"url": "https://github.com/onnx/models", "anchor_text": "model zoo", "paragraph_index": 7}, {"url": "https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/tiny_yolov2", "anchor_text": "model", "paragraph_index": 7}, {"url": "https://github.com/onnx/models", "anchor_text": "zoo", "paragraph_index": 8}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX/blob/master/FAQ.md", "anchor_text": "GitHub repository", "paragraph_index": 8}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository", "paragraph_index": 10}, {"url": "https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html", "anchor_text": "Getting Started With Jetson Nano Developer Kit", "paragraph_index": 12}, {"url": "https://www.hackster.io/news/getting-started-with-the-nvidia-jetson-nano-developer-kit-43aa7c298797", "anchor_text": "these", "paragraph_index": 12}, {"url": "https://medium.com/@ageitgey/build-a-hardware-based-face-recognition-system-for-150-with-the-nvidia-jetson-nano-and-python-a25cb8c891fd", "anchor_text": "resources", "paragraph_index": 12}, {"url": "https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html", "anchor_text": "DeepStream quick start guide", "paragraph_index": 14}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository", "paragraph_index": 19}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX/blob/master/README.md", "anchor_text": "readme", "paragraph_index": 19}, {"url": "https://gstreamer.freedesktop.org/documentation/application-development/introduction/basics.html?gi-language=c", "anchor_text": "foundations", "paragraph_index": 20}, {"url": "https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH", "anchor_text": "non-maximum suppression", "paragraph_index": 34}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository", "paragraph_index": 35}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX/blob/master/custom_bbox_parser/nvdsparsebbox_tiny_yolo.cpp", "anchor_text": "file", "paragraph_index": 35}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository", "paragraph_index": 36}, {"url": "https://specifications.freedesktop.org/desktop-entry-spec/latest/", "anchor_text": "key-file format", "paragraph_index": 37}, {"url": "https://docs.nvidia.com/metropolis/deepstream/plugin-manual/index.html#page/DeepStream_Plugin_Manual%2Fdeepstream_plugin_details.02.01.html%23wwpID0E0IZ0HA", "anchor_text": "link", "paragraph_index": 40}, {"url": "https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html#page/DeepStream_Development_Guide%2Fdeepstream_app_config.3.2.html%23", "anchor_text": "link", "paragraph_index": 43}, {"url": "https://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol", "anchor_text": "RTSP", "paragraph_index": 44}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "experiment", "paragraph_index": 53}, {"url": "https://thatbrguy.github.io", "anchor_text": "https://thatbrguy.github.io", "paragraph_index": 55}], "all_paragraphs": ["Deploying complex deep learning models onto small embedded devices is challenging. Even with hardware optimized for deep learning such as the Jetson Nano and inference optimization tools such as TensorRT, bottlenecks can still present itself in the I/O pipeline. These bottlenecks can potentially compound if the model has to deal with complex I/O pipelines with multiple input and output streams. Wouldn\u2019t it be great to have a tool that can take care of all bottlenecks in an end-to-end fashion?", "Turns out there is a SDK that attempts to mitigate this problem. DeepStream is an SDK that is optimized for NVIDIA Jetson and T4 platforms to provide a seamless end-to-end service to convert raw streaming data into actionable insights. It is built on top of the GStreamer framework. Here, \u201craw streaming data\u201d is typically continuous (and multiple) video streams and \u201cactionable insights\u201d are the final outputs of your deep learning or other analytics algorithms.", "DeepStream SDK uses its custom GStreamer Plugins to provide various functionalities. Notably, it has plugins for TensorRT based inference and object tracking. The below image lists out the capabilities of their plugins. For an exhaustive technical guide about their plugins, you can refer to their Plugin Manual.", "One feature I particularly liked about DeepStream is that it optimally takes care of the entire I/O processing in a pipelined fashion. We can also stack multiple deep learning algorithms to process information asynchronously. This allows you to increase throughput without the hassle of manually creating and managing a multiprocessing system design.", "The best part is, for some supported applications such as object detection, tracking, classification or semantic segmentation, DeepStream is easy to use! For such an application, as long you have a deep learning model in a compatible format, you can easily launch DeepStream by just setting a few parameters in some text files.", "In this blog, we will design and run an experiment on DeepStream to test out its features and to see if it is easy to use on the Jetson Nano.", "To test the features of DeepStream, let's deploy a pre-trained object detection algorithm on the Jetson Nano. This is an ideal experiment for a couple of reasons:", "The ONNX model zoo has a bunch of pre-trained object detection models. I chose the Tiny YOLO v2 model from the zoo as it was readily compatible with DeepStream and was also light enough to run fast on the Jetson Nano.", "Note: I did try using the SSD and YOLO v3 models from the zoo. But there were some compatibility issues. These issues are discussed in my GitHub repository, along with tips to verify and handle such cases. I ended up using Tiny YOLO v2 as it was readily compatible without any additional effort.", "Now, the features we want to investigate are as follows:", "The performance (Frames per Second, FPS) and ease-of-use will be evaluated for the experiment. The next few sections will guide you through how to set up DeepStream on Jetson Nano to run this experiment. All code used for this experiment is available on my GitHub repository. If you are just curious about how it turned out, feel free to skip to the results section.", "In this section, we will walk through some instructions to set things up for our experiment.", "Follow the instructions on the Getting Started With Jetson Nano Developer Kit to set up and boot your Jetson Nano. In case you face some issues with the setup, I would highly recommend following these resources.", "I would like to highlight some pointers that might save you some trouble:", "Now that you have your Jetson Nano up and running, we can install DeepStream. Nvidia has put together the DeepStream quick start guide where you can follow the instructions under the section Jetson Setup.", "Before you go ahead and install DeepStream using the above link, I would like to highlight a few points from my setup experience:", "After installing DeepStream and boosting the clocks (as mentioned in the guide), we can run one of their samples to verify that the installation is properly done. Move (cd) into your DeepStream installation folder and run the following command:", "On execution, you should see something like this:", "If you see something similar, congrats! You can play around with more samples if you would like. The guide has a section named \u201cReference Application Source Details\u201d which provides a description of the samples.", "Now that you have installed and tested DeepSteam, we can go ahead with our experiment. I have bundled up all the files required for the experiment in my GitHub repository. You can follow the step by step instruction in the repository\u2019s readme file about the setup instructions.", "Before moving on with the experiment, if you have not used GStreamer before, it would be worth your time to go through their foundations page. This helps with better understanding of some of the jargons used in DeepStream\u2019s documentation.", "In this section, we will explore how to interface the output of our ONNX model with DeepStream. More specifically, we will walk-through the process of creating a custom processing function in C++ to extract bounding box information from the output of the ONNX model and provide it to DeepStream.", "The ONNX model outputs a tensor of shape (125, 13, 13) in the channels-first format. However, when used with DeepStream, we obtain the flattened version of the tensor which has shape (21125). Our goal is to manually extract the bounding box information from this flattened tensor.", "Let us first try to visually understand the output tensor output by the ONNX model. Consider the output tensor to be a cuboid of dimensions (B, H, W), which in our case B=125,H=13,W=13. We can consider the axes X, Y and B along the width (W), height (H) and depth (B) respectively. Now, each location in the XY plane represents a single grid cell.", "Let us visualize a single grid cell (X=0, Y=0). There 125 values along the depth axis (B) for this given (X,Y) location. Let us rearrange the 125 values in groups of 25 as shown below:", "As we see here, each of the contiguous 25 values belong to a separate bounding box. Among each set of 25 values, the first 5 values are of the bounding box parameters and the last 20 values are class probabilities. Using this, we can extract the coordinates and confidence score for each of the 5 bounding boxes as shown here:", "Note that we have only performed this operation at one grid cell (X=0, Y=0). We must iterate over all combinations of X and Y to find the 5 bounding box predictions at each grid cell.", "Now that we have a visual idea of how the information is stored, let us try to extract it using indexing. After flattening the output tensor, we get a single array in which information is stored as shown in the image below:", "The flattened array has 125 * 13 * 13 = 21125 elements. As shown above, each location in the array corresponds to the indices (b, y, x). We can observe that for a given (y,x) value, the corresponding b values are separated by 13 * 13 = 169 .", "The following code snippet in Python shows how we can obtain the locations of b values corresponding to each of the 5 bounding boxes in a given (y, x) location. Do note that, as shown in Figure A, there are 25 b values for each bounding box for a given (y, x) location.", "All that is left to do is to write the C++ equivalent of the same.", "Now that we understand how the output is stored and can be extracted, we need to write a function in C++ to do the same. DeepStream expects a function with arguments as shown below:", "In the above function prototype, outputLayersInfo is a std::vector containing information and data about each output layer of our ONNX model. In our case, since we have just one output layer, we can access the data using outputLayersInfo[0].buffer. The variable networkInfo has information about the height and width expected by the model and detectionParams has information about some configurations such as numClassesConfigured.", "The variable objectList should be updated with a std::vector of bounding box information stored as objects of type NvDsInferParseObjectInfo at every call of the function. Since the variable was passed by reference, we don\u2019t need to return it as the changes will be reflected at the source. However, the function must return true at the end of its execution.", "For our use case, we create NvDsInferParseCustomYoloV2Tiny such that it will first decode the output of the ONNX model as described in Part-1 of this section. For each bounding box, we create an object of type NvDsInferParseObjectInfo to store its information. We then apply non-maximum suppression to remove duplicate bounding box detections of the same object. We then add the resulting bounding boxes to the objectList vector.", "My GitHub repository has nvdsparsebbox_tiny_yolo.cpp inside the directory custom_bbox_parser with the function already written for you. The below flowchart explains the flow of logic within the file. The code may seem large but that is only because it is heavily documented and commented for your understanding!", "All that\u2019s left now is to compile the function into a .so file so that DeepStream can load and use it. Before you compile it, you may need to set some variables inside the Makefile. You can refer to step 4 of the ReadMe in my GitHub repository for instructions. Once that is done, cd into the GitHub repository and run the following command:", "The good news is that most of the heavy lifting work is done. All that is left is to set up some configuration files which will tell DeepStream how to run the experiments. A configurations file has a set of \u201cgroups\u201d, each of which has a set of \u201cproperties\u201d that are written in the key-file format.", "For our experiment, we need to set up two configuration files. In this section we will explore some important properties within these configuration files.", "Our ONNX model is used by the Gst-Nvinfer plugin of DeepStream. We need to set-up some properties to tell the plugin information such as the location of our ONNX model, location of our compiled bounding box parser and so on.", "In the GitHub repository, the configuration file named config_infer_custom_yolo.txt is already setup for our experiment. Comments are given in the file with reasoning for each property setting. For a detailed list of all the supported properties, check out this link.", "Some interesting properties that we have not used are the \u201cnet-scale-factor\u201d and the \u201coffset\u201d properties. They essentially scale the input (x) using the formula: net_scale_factor * (x \u2014 mean). We did not use those properties as our network directly takes the unscaled image as the input.", "We also need to set a configuration file for DeepStream to enable and configure the various plugins that will be used by it. As mentioned before, the GitHub repository contains the configuration file deepstream_app_custom_yolo.txt which is already setup for our experiment.", "Unlike the previous part, this configuration has a lot of groups such as \u201cosd\u201d (On Screen Display), \u201cprimary-gie\u201d (Primary GPU Inference Engine) and so on. This link has information about all possible groups that can be configured and the properties supported for each group.", "For our experiment, we define a single source group (source0) and three sink groups (sink0, sink1 and sink2). The single source group is responsible for reading four input video streams parallely. The three sink groups are used for displaying output on screen, streaming output using RTSP and for saving output to disk respectively. We provide the path of the configuration file of Tiny YOLOv2 in the primary-gie group. Moreover, we also set the titled-display and osd groups to control how the output appears on screen.", "This is the easiest part. All you have to do is to run the following command:", "Launching DeepStream for the first time would take a while as the ONNX model would need to be converted to a TensorRT Engine. It is recommended to close memory hungry apps such as Chromium during this process. Once the engine file is created, subsequent launches will be fast provided the path of the engine file is defined in the Tiny YOLOv2 configuration file.", "On running DeepStream, once the engine file is created we are presented with a 2x2 tiled display as shown in the video below. Each unit in the tiled display corresponds to a different streaming input. As expected, all four different inputs are processed simultaneously.", "Since we also enabled RTSP, we can access the stream at rtsp://localhost:8554/ds-test. I used VLC and the RTSP address (after replacing localhost with the IP address of my Jetson Nano) to access the stream on my laptop which was connected to the same network. Note that, another sink is also used to save the output stream to disk. It is impressive to note that the console periodically logs an FPS of nearly 6.7 per video stream!", "If we had a single input stream, then our FPS should ideally be four times greater than this four video case. I test this out by changing the values in the configuration files and launching DeepStream once again. As expected, we get a whopping near 27 FPS for the single video stream! The performance is impressive considering it still is sending output to three different sinks.", "We do however note that the detection accuracy of Tiny YOLOv2 is not as phenomenal as the FPS. This is particularly because the model was optimized for speed at the cost of some accuracy. Moreover, the people in the video had blurred faces and the model might not have encountered this blurriness while training. Hence, the model might have faced additional difficulty for that class.", "DeepStream is blazingly fast. Even though Tiny YOLOv2 is optimized for speed rather than accuracy, a stable high FPS performance while providing amazing features such as seamless multi-stream processing and an RTSP stream is something to be appreciated.", "However, using DeepStream may not be straightforward, especially if your model is not completely compatible with TensorRT. In such cases, manually writing your own TensorRT layers might be a more viable (albeit tedious) option. Moreover, it may so happen that the readily available ONNX models may have an opset version greater than what is currently accepted by DeepStream.", "Nevertheless, I do feel that the functionality offered by DeepStream is worth the effort. I would recommend you to give it a shot by replicating my experiment!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Exploring Computer Vision and Machine Learning | https://thatbrguy.github.io"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb2872b99a031&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b2872b99a031--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b2872b99a031--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@thatbrguy?source=post_page-----b2872b99a031--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thatbrguy?source=post_page-----b2872b99a031--------------------------------", "anchor_text": "Bharath Raj"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d6e83a807b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&user=Bharath+Raj&userId=7d6e83a807b8&source=post_page-7d6e83a807b8----b2872b99a031---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2872b99a031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2872b99a031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://developer.nvidia.com/embedded/jetson-nano-developer-kit", "anchor_text": "Source"}, {"url": "https://developer.nvidia.com/embedded/jetson-nano-developer-kit", "anchor_text": "Jetson Nano"}, {"url": "https://developer.nvidia.com/tensorrt", "anchor_text": "TensorRT"}, {"url": "https://developer.nvidia.com/deepstream-sdk", "anchor_text": "DeepStream"}, {"url": "https://gstreamer.freedesktop.org/", "anchor_text": "GStreamer"}, {"url": "https://developer.nvidia.com/deepstream-sdk", "anchor_text": "Source"}, {"url": "https://developer.nvidia.com/deepstream-sdk#plugins", "anchor_text": "GStreamer Plugins"}, {"url": "https://developer.nvidia.com/tensorrt", "anchor_text": "TensorRT"}, {"url": "https://docs.nvidia.com/metropolis/deepstream/plugin-manual/index.html", "anchor_text": "Plugin Manual"}, {"url": "https://developer.nvidia.com/deepstream-sdk#plugins", "anchor_text": "Source"}, {"url": "https://developer.nvidia.com/embedded/jetson-nano-developer-kit", "anchor_text": "Jetson Nano"}, {"url": "https://github.com/onnx/models", "anchor_text": "model zoo"}, {"url": "https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/tiny_yolov2", "anchor_text": "model"}, {"url": "https://github.com/onnx/models", "anchor_text": "zoo"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX/blob/master/FAQ.md", "anchor_text": "GitHub repository"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository"}, {"url": "https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html", "anchor_text": "Getting Started With Jetson Nano Developer Kit"}, {"url": "https://www.hackster.io/news/getting-started-with-the-nvidia-jetson-nano-developer-kit-43aa7c298797", "anchor_text": "these"}, {"url": "https://medium.com/@ageitgey/build-a-hardware-based-face-recognition-system-for-150-with-the-nvidia-jetson-nano-and-python-a25cb8c891fd", "anchor_text": "resources"}, {"url": "https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html", "anchor_text": "DeepStream quick start guide"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX/blob/master/README.md", "anchor_text": "readme"}, {"url": "https://gstreamer.freedesktop.org/documentation/application-development/introduction/basics.html?gi-language=c", "anchor_text": "foundations"}, {"url": "https://pjreddie.com/media/files/papers/YOLO9000.pdf", "anchor_text": "Source"}, {"url": "https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH", "anchor_text": "non-maximum suppression"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX/blob/master/custom_bbox_parser/nvdsparsebbox_tiny_yolo.cpp", "anchor_text": "file"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "GitHub repository"}, {"url": "https://specifications.freedesktop.org/desktop-entry-spec/latest/", "anchor_text": "key-file format"}, {"url": "https://docs.nvidia.com/metropolis/deepstream/plugin-manual/index.html#page/DeepStream_Plugin_Manual%2Fdeepstream_plugin_details.02.01.html%23wwpID0E0IZ0HA", "anchor_text": "link"}, {"url": "https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html#page/DeepStream_Development_Guide%2Fdeepstream_app_config.3.2.html%23", "anchor_text": "link"}, {"url": "https://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol", "anchor_text": "RTSP"}, {"url": "https://github.com/thatbrguy/Deep-Stream-ONNX", "anchor_text": "experiment"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b2872b99a031---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----b2872b99a031---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/iot?source=post_page-----b2872b99a031---------------iot-----------------", "anchor_text": "IoT"}, {"url": "https://medium.com/tag/video-analytics?source=post_page-----b2872b99a031---------------video_analytics-----------------", "anchor_text": "Video Analytics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b2872b99a031---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2872b99a031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&user=Bharath+Raj&userId=7d6e83a807b8&source=-----b2872b99a031---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2872b99a031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&user=Bharath+Raj&userId=7d6e83a807b8&source=-----b2872b99a031---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2872b99a031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b2872b99a031--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb2872b99a031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b2872b99a031---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b2872b99a031--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b2872b99a031--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b2872b99a031--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b2872b99a031--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b2872b99a031--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b2872b99a031--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b2872b99a031--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b2872b99a031--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thatbrguy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thatbrguy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Bharath Raj"}, {"url": "https://medium.com/@thatbrguy/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.9K Followers"}, {"url": "https://thatbrguy.github.io", "anchor_text": "https://thatbrguy.github.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d6e83a807b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&user=Bharath+Raj&userId=7d6e83a807b8&source=post_page-7d6e83a807b8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffa56702c1a84&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-deploy-onnx-models-on-nvidia-jetson-nano-using-deepstream-b2872b99a031&newsletterV3=7d6e83a807b8&newsletterV3Id=fa56702c1a84&user=Bharath+Raj&userId=7d6e83a807b8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}