{"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-2-f7cfb6a5f1e3", "time": 1682995683.6133602, "path": "towardsdatascience.com/microsoft-introduction-to-ai-part-2-f7cfb6a5f1e3/", "webpage": {"metadata": {"title": "Microsoft Introduction to AI \u2014 Part 2 | by Christine Calo | Towards Data Science", "h1": "Microsoft Introduction to AI \u2014 Part 2", "description": "Have you ever been curious to know exactly how technology can read, decipher and understand our human natural language? How do AI assistants like Cortana, Siri, Alexa and Google help us with simple\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1", "paragraph_index": 2}, {"url": "https://www.classcentral.com/course/edx-introduction-to-artificial-intelligence-ai-9164", "anchor_text": "Microsoft Introduction to AI course", "paragraph_index": 2}, {"url": "https://medium.com/@christinecalo/a-little-about-christines-notes-8ea2205594a2", "anchor_text": "If you would like to know more info behind the course notes and other notes related to tech and product design you can find out more here.", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1", "paragraph_index": 4}, {"url": "https://www.classcentral.com/course/edx-introduction-to-artificial-intelligence-ai-9164", "anchor_text": "Microsoft Introduction to AI course", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1", "paragraph_index": 8}, {"url": "https://www.programiz.com/python-programming", "anchor_text": "link a good place to learn a bit about Python", "paragraph_index": 22}, {"url": "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview", "anchor_text": "Microsoft Text Analytics API", "paragraph_index": 46}, {"url": "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview", "anchor_text": "here.", "paragraph_index": 46}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/text-analytics/", "anchor_text": "give it a try", "paragraph_index": 46}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/speech-to-text/", "anchor_text": "Microsoft Speech-to-Text API", "paragraph_index": 60}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/speech-to-text/", "anchor_text": "Speech-to-Text API", "paragraph_index": 72}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/speech-to-text/", "anchor_text": "Text-to-Speech API", "paragraph_index": 72}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/translator-text-api/", "anchor_text": "Microsoft Translator API", "paragraph_index": 74}, {"url": "https://www.luis.ai/home", "anchor_text": "LUIS", "paragraph_index": 86}, {"url": "https://www.luis.ai/home", "anchor_text": "LUIS through here.", "paragraph_index": 86}, {"url": "https://www.luis.ai/home", "anchor_text": "LUIS portal", "paragraph_index": 87}, {"url": "https://medium.com/@christinecalo", "anchor_text": "my Medium account", "paragraph_index": 124}, {"url": "https://towardsdatascience.com/", "anchor_text": "Towards Data Science", "paragraph_index": 124}, {"url": "https://www.classcentral.com/course/edx-introduction-to-artificial-intelligence-ai-9164", "anchor_text": "Microsoft Introduction to AI course", "paragraph_index": 124}, {"url": "https://medium.com/@christinecalo/a-little-about-christines-notes-8ea2205594a2", "anchor_text": "If you would like to know a little background info behind the course notes and other notes related to tech and product design you can find out more here.", "paragraph_index": 125}], "all_paragraphs": ["Have you ever been curious to know exactly how technology can read, decipher and understand our human natural language? How do AI assistants like Cortana, Siri, Alexa and Google help us with simple questions and tasks? How do search engines like Google retrieve relevant information to our queries, especially when they have been phrased in natural language? This is Part 2 of the \u2018Microsoft Introduction to Artificial Intelligence\u2019 course notes. Delve into the exciting world of Natural Language Processing (NLP), learn how software can be used to process, analyse and extract meaning from our language.", "(skip the Background info if you have seen Part 1)", "For those who haven\u2019t seen Part 1 of this series, here is some background info. I\u2019ve always wanted to learn about Artificial Intelligence (AI) although felt a little intimidated by the maths involved and thought maybe some of the concepts would be out of my depth. Fortunately, my curiosity overcame my fear so I\u2019ve started to do a few courses related to AI. I recently completed the Microsoft Introduction to AI course and wrote course notes to help me retain the knowledge that I have learned. I have tried to write these notes in a basic way to make them easy to consume. I\u2019ve recently become an aunt and have bought a few children\u2019s books related to technology and space and really love how the authors and illustrators have managed to simplify complicated topics. So, I\u2019ve been inspired to treat these topics in a similar way by simplifying them to make them a lot more accessible, especially to those who share my initial AI jitters.", "*If you would like to know more info behind the course notes and other notes related to tech and product design you can find out more here.*", "(skip the Summary if you have seen Part 1)", "The Microsoft Introduction to AI course provides an overview of AI and explores machine learning principles that provide the foundation for AI. From the course you can discover the fundamental techniques that you can use to integrate AI capabilities into your apps. Learn how software can be used to process, analyse and extract meaning from natural language. Find out how software processes images and video to understand the world the way humans do. Learn about how to build intelligent bots that enable conversations between humans and AI systems.", "The course takes approximately 1 month to complete so 1 medium article I write contains 1 week's worth of content. This means that it would only take you approximately 29 minutes to read this article which is 1 week's worth of content. That is a fast way of learning. The course is free without a certificate however, if you\u2019d like a certificate as proof of completion there is a fee. There are labs associated with this course which I won\u2019t include in the notes as I believe the best way to learn is to actually do the labs. However, these notes are useful if you\u2019d like to know about the fundamental theory behind AI and would like to learn it in a way that might be a lot simpler than other resources. I\u2019ve tried to write it in layman terms and have included visuals to help illustrate the ideas. These notes are useful if you don\u2019t have time to do the course, it\u2019s a quick way to skim through the core concepts. Alternatively, if you have done the course like me you can use these notes to retain what you have learned.", "Graeme Malcolm \u2014 Senior Content Developer at Microsoft Learning Experiences.", "(skip the Syllabus if you have seen Part 1)", "The course is broken into the four parts which include:", "Learn about the fundamentals about AI and machine learning.", "Learn how software can be used to process, analyse and extract meaning from natural language.", "Learn how software can be used to process images and video to understand the world the way that we do.", "Find out how to build intelligent bots that enable conversational communication between humans and AI systems.", "The \u2018Language and Communication\u2019 part of the course will tackle the following topics:", "\u00b7 Term Frequency \u2014 Inverse Document Frequency", "As humans, we\u2019ve evolved to be the intelligent problem solvers that we are by communicating through written and spoken language. Communication is key to successful collaboration. So artificial intelligence needs to include the ability to communicate naturally with digital entities. Software needs to be able to understand text, extracting semantic meaning and even sentiment from the language that we use as humans. We also need to be able to speak to AI agents and have them respond appropriately even when engaging us in conversation. So in the next sections, we\u2019ll take a look at how we can process text and speech to enable AI for language and communication.", "Well, let\u2019s experiment with the idea that the more often a word or term appears in a body of text, the more semantically significant that word is. In other words, the frequency of a word might tell us something about the meaning of the text. So in our example below our friendly robot has been brushing up on his Shakespeare lately and he wants to understand this quote from Romeo and Juliet. Now we can start doing some frequency analysis by simply counting the occurrence of each word in the text. Notice in the image below that I\u2019ve ignored punctuation and casing. If there were any non-alphabetic characters such as numerals, I\u2019ve ignored them as well.", "We can visualise those word frequencies in a bar chart shown below. Actually, what we probably can do is shift the more frequent words to the beginning of the chart and show them in descending order of frequency as a Pareto chart.", "Now note that one of the most frequent words is \u2018a\u2019 and we\u2019ve also got words like \u2018that\u2019, \u2018as\u2019 and other common words that aren\u2019t really very useful for extracting semantic meaning from the text. Now we call these stop words. If we removed the stop words we get a cleaner picture of what the text is about as shown in the chart below.", "The most frequent word is \u2018name\u2019, which is really what Juliet is talking about in this part of the play.", "Let\u2019s try this out with some code in Python. First let us load a bit of text e.g. \u201cMoon.txt\u201d.", "Don\u2019t worry, you don\u2019t need to know about how to code in Python for this particular course. The example shown is just to get an idea how we can use technology to do a basic word frequency analysis. Although it is useful to have a basic understanding of it. I found this link a good place to learn a bit about Python. I\u2019m sure there are many more great resources out there.", "We can then normalise the text by removing numeric digits and punctuation, as well as, transform the text into lower case.", "We then get a frequency distribution of the words.", "You will get a frequency distribution that looks like this.", "We can then plot the distribution as a pareto chart and you will get a chart shown below.", "We can then remove stop words which will basically remove all the stop words from the pareto chart.", "Simple word frequency can be a reasonably effective way to look at a single document but when you have large amount of documents, common words can appear frequently in multiple documents. A simple count of how many times a word occurs in total might not reflect its importance within an individual document. So to deal with that, we use a more sophisticated measure of word importance that combines two metrics named term frequency and inverse document frequency.", "Let\u2019s start with term frequency. This is simply the relative frequency of a term within a document. Now in the case shown in the image below, our robot has been continuing his studies of Shakespeare. In this quotation, the word \u2018sweet\u2019 appears once out of a total of 14 words.", "Now, the word \u2018rose\u2019 appears with the same frequency within this document. So it would appear to be equally important.", "There\u2019s a similar story in the other two quotes. The word \u2018sweet\u2019 appears once in the second quote, as does the word \u2018prince\u2019. The word \u2018sweet\u2019 appears once again in the third quote, as does \u2018sorrow\u2019.", "Now let\u2019s look at the inverse document frequency. This is a measure of the relative number of documents within which the term appears. It\u2019s calculated as the log of total documents divided by the number of documents containing the term.", "Now the term \u2018rose\u2019 appears only in the first quote, so we can calculate its relative importance in that document like as shown below. However, \u2018sweet\u2019 appears in all three quotes, lowering its relative importance in individual documents to zero.", "It\u2019s a similar story for the other quotes. \u2018Prince\u2019 and \u2018sorrow\u2019 score higher IDFs because they don\u2019t appear in the other documents and are therefore relatively more important in the documents in which they do appear.", "Finally, we just multiply TF by IDF to work out the overall importance of each term to the documents in which they appear. As you can see below, the prevalence of the word \u2018sweet\u2019 across the collection of documents has effectively diluted its importance within the individual documents.", "Let\u2019s try this out through code. First we start off with normalising 3 blocks of text such as \u201cMoon.txt\u201d from our first example, \u201cGettysburg.txt\u201d and \u201cCognitive.txt\u201d and view the documents.", "Let\u2019s then get the TF-IDF values for the top three words in each document.", "You should get something like this:", "Now, sometimes there are words that are very similar. These words are from the same root and we use them across our documents. We want to make sure that those words are treated the same. Now, our literary robot continues to find interesting quotes from Shakespeare\u2019s plays. In the case illustrated below, there are three quotes that contain words with the same root which are \u2018sweet\u2019, \u2018sweetness\u2019 and the slight less commonly used \u2018sweeting\u2019.", "Stemming is a technique used to identify words with a common root and count them as the same.", "A common technique is to use something called the Porter algorithm. The Porter algorithm defines a sequence of rules for breaking words down into a common stem based on the pattern of consonants, vowels, common letter combinations and word endings and other syntactical elements.", "Let\u2019s now give this a go with code. First we view the frequency of unstemmed words from some text. The text in this example is the \u201cKennedyInaugural.txt\u201d.", "We then Stem the words using the Porter Stemmer algorithm. You should get a pareto chart showing stemmed words and their frequency.", "Sentiment analysis is a technique that we can use to analyse text and try to discern whether the text indicates that the writer is happy or unhappy or perhaps neutral about something. It\u2019s often used to analyse things like tweets, customer reviews on a website, emails, basically any message where it\u2019s important that we know how the person who wrote the text was feeling at the time. Sentiment analysis uses a machine learning classification algorithm to generate a sentiment score between 0 and 1. Scores closer to 1 indicate positive sentiment, while scores closer to 0 indicate negative sentiment. The model is pre-trained with an extensive body of text with sentiment associations.", "Natural language processing (NLP) enables AI systems to do much more than just use statistical analysis of word frequency. Using an NLP we can build applications that can extract key phrases to determine important points and topics. We can improve the accuracy of sentiment analysis by looking beyond the presence of positive words in the text and examining the semantics of what\u2019s being said.", "Let\u2019s take a look at the Microsoft Text Analytics API and see how that can be used to extract semantic meaning and sentiment from text. So the text analytics API is a cognitive service which you can learn about here. Why not give it a try.", "What we\u2019re going do is use this API to illustrate how to compare a couple of different documents and get some information from them. Below it shows some Python code that looks at phrases from 2 documents the \u2018Gettysburg Address\u2019 (doc2Txt) and the text from the \u2018Microsoft Cognitive Services website\u2019 (doc3Txt).", "Don\u2019t worry, you don\u2019t need to know about how to code in Python for this particular course. The example shown is just to get an idea how we can use technology to extract semantic meaning and sentiment from text.", "So we\u2019ve got some text and variables that we\u2019re going to pass up. We are then going to call the keyPhrases method of this API. We\u2019re passing up that body which contains the text that we want to analyse and we get back a response which is adjacent document with a collection of documents. So we\u2019ll go through each document and we\u2019ll just display the document ID and then all of the key phrases that have been found in that document.", "So when we go ahead and run that we get back, for document 1, these key phrases: new nation, great civil war, people, new birth of freedom, great battlefield..etc. So we\u2019re getting fairly informational key phrases out of that document.", "Then from document 2 we\u2019re getting: speech developers, Microsoft Cognitive Services, vision recognition, set of APIs. So we\u2019re getting a much more kind of comprehensive understanding of what these documents are about than what you would get from just analysing individual words.", "Now, the other thing that we can do with the text analytics API is we can do sentiment analysis. So I\u2019ve got a couple of simple examples of text here such as \u2018Wow! cognitive services are fantastic\u2019 and \u2018I hate it when computers don\u2019t understand me\u2019.", "This time we\u2019ll call the same API but we\u2019re calling the sentiment method. Again, we get back a list of documents. What we\u2019re going to do is assume that the sentiment is negative unless we look at the score that we get back and that score is greater than 0.5. It\u2019s a score between zero and one. So if the score is greater than 0.5 we\u2019ll consider the document to be positive. Otherwise we\u2019ll consider it to be negative.", "So when we go ahead and run that sure enough, Document 1 comes back as positive and Document 2 comes back as negative.", "Up until now, we focused on parsing text but of course, natural language includes speech. Now to work with speech we have to recognise that there are two models that need to work together. First of all there\u2019s an acoustic model that match audio to sound units or phonemes which define how specific word fragments are pronounced in a given language.", "Then there\u2019s a language model that provides a probability distribution across a sequence of words. So while in this case shown below, it may sound like we\u2019re trying to communicate something about fruit, boats, and furniture\u2026", "\u2026it\u2019s much more likely that the message is about satisfaction with the seat.", "Let\u2019s take a look at some real examples of using speech in an AI application.", "Again don\u2019t worry about not knowing much about how to code in Python. The example shown below is just to get an idea how we can use technology with speech.", "To work with speech, we are going to use the Bing speech API and again that\u2019s one of Microsoft\u2019s cognitive services. We\u2019re going to work with a speech API to convert some speech to text. Feel free to try out the Microsoft Speech-to-Text API. So what\u2019s going to happen is we\u2019re going to speak into the microphone of a computer and we\u2019re going to convert speech into text. So what we\u2019re doing below is using the speech recognition library. It has a thing called a Recognizer, which we\u2019ll initiate. We\u2019ll then use the microphone as the source and then they\u2019ll just listen to whatever is said into the microphone.", "Then we\u2019re going to send that to this recognize_bing method. So we\u2019ll go recognize_bing and that goes to the Bing speech API. We\u2019ll pass in the audio that we captured. We\u2019ll pass in the key for speech service so that it authenticates us and then we should get back a transcription of what was heard.", "If it isn\u2019t able to hear it very clearly because of the ambient noise, we\u2019ll get a message back that says the audio was unclear. If something else goes wrong, we\u2019ll get some other error message appearing.", "So we\u2019ll then go and run this code. We then speak into the microphone and say \u201cThe rain in Spain stays mainly in the plain\u201d. What comes back is a transcription of what was said.", "So we\u2019re able to send up our audio and we can send it either as directly from a microphone or as an audio file. So if you\u2019ve got files that you\u2019ve recorded and you want to transcribe them to text you can do that. Upload that audio file and then what comes back is the text from that audio.", "Now what about the other way around? What if I actually want to take some existing text and convert that to speech?", "Now one of the things we commonly do with AI applications is interact with them by speaking to them and then having them respond back using speech. So how would we do that? Well, again we could use the same API but a different method. First of all, we\u2019re just simply going to get the text that we want to convert into speech. So we\u2019ll type in some text and get that sent up.", "We\u2019re using some XML to set things up. So we\u2019re using this ElementTree element thing here to build up an XML structure. We\u2019re going to create an XML document that has all the information about the voice that we want to use. There are different voices available so we\u2019re going to specify this JessaRUS as the voice and specify various other bits of information in the headers about what we want to get back out. We\u2019ve got the output format and it\u2019s going to be a 16-bit mono audio stream that we get back. Now the important bit is we parse it in the axis token, so we get Bearer on the axis token.", "Then what we\u2019re going to get back is the audio stream that contains the text that has been synthesized. We\u2019re calling this synthesized method and we\u2019re going to get back this audio stream, which we can then do something with.", "So we\u2019ll get that data back and we\u2019ll just simply play it in the player, so you can hear it when it comes back.", "We then go ahead and run that. We then need to type in a phrase.", "We get back the audio and that is then played back.", "So you can see how this API works for submitting input to the AI service by speaking. You can speak to the API service and have it understand what\u2019s being said. You can then formulate a response as text and then play that response back as speech back. You can give the Speech-to-Text API and Text-to-Speech API a go and try it out for yourself by clicking on the hyperlinks.", "All of the examples of working with text and speech so far has assumed that we are working in English. But what if we need to collaborate with someone who speaks another language?", "Let\u2019s take a look at the Microsoft Translator API. Now for translation, there are actually two cognitive services APIs, there\u2019s one for text and one for speech. We\u2019ll focus on the text one but you could use either of them to do automatic translation through a number of different languages.", "So let\u2019s take a look, we\u2019re going to first of all ask for some text that we want to translate. We are going to type in some text. Then the fromLangCode, the input is the language that we want to translate from. TolanguageCode, the input is what\u2019s the language would we like to translate that code into?", "We defined some parameters, so this time we\u2019re not passing up the information on the body. We\u2019re actually passing up these parameters. The parameters are basically the text we want to translate, the language we want to translate it to and the language we want to translate it from.", "So we pass those up and we\u2019re then going to call this api.microsofttranslator.com. It\u2019s a GET request and we\u2019re going to pass it to that bit of the URL. We pass that all up.", "What we\u2019ll then get back is the translation, because this is the text translator, it\u2019ll come back in text. We go ahead and run that and type in some text.", "So that\u2019s the text that we want to translate. Now what language is that? Well that\u2019s English, so EN is the code for language.", "What language would we like to translate it to? Well FR for French.", "We get back the French translation.", "So we\u2019ve got this translation API. Very quickly we can submit some text and have it almost instantaneously translated to another language of our choice. That can be very useful for bringing people together from different languages, different countries and enabling them to communicate.", "The language understanding intelligence service (LUIS) is a cognitive service that you can use to implement natural language processing for applications that need to respond to human communications. Now we interact with LUIS through utterances which are fragments of language that need to be interpreted.", "From these utterances LUIS identifies the most likely intent which is a predefined goal or action for the input. In this case the utterance is mapped to a book flight intent.", "Now the intent is applied to the entities that are identified in the utterance. In this case the utterance include a location entity \u2018New York\u2019 and a date-time entity \u2018this weekend\u2019.", "To start using LUIS you need to provision it as an Azure service. Now Microsoft provision the language understanding intelligence service just like any other cognitive service in Azure, so we\u2019ll use the Azure portal to do that. You can learn more about LUIS through here.", "Here we are going to show a snap shot of using the LUIS portal to create an app that has intents and entities and all the things that we need in order to get that language understanding. First we create a LUIS resource in the Azure subscription. From there you can access the LUIS App portal where you can create a LUIS app.", "So the first thing to do is create a new app and that\u2019s going to ask for a name for this app. We\u2019ll call this \u2018Home Automation\u2019 and we\u2019ll have this in English as that\u2019s the language that this app is going to speak. You can add a bit of a description. Then click \u2018Done\u2019 and create the new app.", "So here\u2019s our app and it\u2019s called Home Automation.", "We can just go ahead and open that up. You can see that we get this UI within which we can work, create and test our app. Now the first thing we\u2019re going to want to do is to think about the intents in the app.", "So we\u2019re going to create an intent. So on the Intent tab in the UI we\u2019ll click \u2018Create New Intent\u2019. A popup should show up. We\u2019ll give the intent a name. The aim of the app we are building is effectively going to turn lights on and off so one of our intents is to turn the light on. So we\u2019ll just call it \u2018Light On\u2019.", "That then goes and creates an intent called Light On. We are ready to start adding utterances that are going to be the way that people will try and initiate this intent. We could put in multiple samples but for the sake of simplicity we are going to put in a one simple example here which is to \u2018switch the light on\u2019. So we\u2019ve got an utterance here of \u2018switch the light on\u2019 and that\u2019s going to signify the light on intent.", "What we\u2019re going to do is highlight the word \u2018light\u2019. You can see in the image below that it puts these little square brackets around it and we can use that to signify that this thing is an entity. You could also go and browse some pre-built entities or you could create a new entity. Here we\u2019re just going to create a new entity called \u2018light\u2019.", "That creates this new entity called light. It\u2019s a simple entity. There are more complex entities that we could create and as you explore LUIS in more depth you\u2019ll find uses for these more complex entities but in this case we have a simple entity called \u2018light\u2019.", "We can see that that\u2019s now highlighted as being an entity that we\u2019ve got in our utterance. So we\u2019ve created this intent of light and we\u2019ve created an utterance for that. We could create multiple utterances but in this case I\u2019ve just created one and specified that this light thing here is an entity.", "We\u2019re going to go back to intents and create a second intent here. On the basis that if we want to turn the light on, we would most likely want to turn it off as well.", "Again we\u2019ll just put in an utterance and specify that light in this case is an entity. It already knows about the entity called light, so that\u2019s listed. So we\u2019ll just go and select that and then that\u2019s another instance of that entity.", "So now we\u2019ve got a couple of very simple intents. Each intent has one utterance that tells us that the intent is what we\u2019re wanting to do. We specified that the word light in those utterances is the entity that this intent relates to. So what we\u2019re going to do is go ahead and train this app so that it knows about applying those utterances to those intents.", "Once it\u2019s trained we can actually test it.", "So it will bring up this little test window on the side, here we\u2019ll type one of our utterances \u2018switch the light on\u2019.", "It comes back from that with the suggestion that this is for the light on intent. So that\u2019s the intent that it thinks it means.", "We can actually even try text that we haven\u2019t typed in for the utterance. We could try something like \u2018turn the light on\u2019. Again it comes back with light on and it indicates it\u2019s 100% confident that that\u2019s what we meant. Even though it\u2019s not the exact utterance that we originally specified, it\u2019s smart enough to realise that it\u2019s close enough to what we presumably mean.", "So we\u2019ve now created our app and added two intents. We\u2019ve created the utterances for those intents and identified the entity, as well as, tested it out. We are now ready to go and publish this.", "So if we click on the publish tab here we\u2019ve got the option of publishing this to a production slot or to staging. In this case we\u2019re going to publish it to production and just going to look at what we want to do with that in terms of resources and keys.", "Now there\u2019s a key that\u2019s already there. When we created the app, this key was generated to test it with, so there\u2019s a test key that can be used. Now if we\u2019re actually going to publish into production then what we probably want to do is use a key from our Azure resource that we\u2019ve created for LUIS.", "So we can add a key and assign a key to our app.", "We\u2019ve now got this app associated with a key and that way we can put it into production and use the appropriate endpoint for the key that we want to bill the service against. This will allow us to put that into production using a production level key. So you can see here that what I\u2019ve got is this endpoint and that endpoint is what the client application will use to connect to our LUIS app in order to initiate these intents.", "So in the previous demonstration we created a LUIS app and published that as a service. Let\u2019s take a look now at how we can consume that app from a client. So previously we created our LUIS app and published it to a production slot using this option shown below. This is the endpoint that we\u2019ve got for our client apps to connect to our LUIS app.", "What we\u2019ve done is copied that endpoint over in our client code here. We\u2019ve got some Python code and have just pasted that endpoint in here. So that\u2019s the endpoint URL that\u2019s going to use to make an HTTP connection from our client app. In this case it\u2019s just this Python script and it\u2019s going to connect to our LUIS app.", "So what are we going to do? Well, we\u2019re going to connect and then we\u2019ll be entering a command. So we\u2019re going to get a prompt to enter a command where we\u2019ll have to type that in and then send that command to our LUIS app.", "There\u2019s a little bit of code in here where if the command has spaces in it that\u2019s going to mess up the URL, so we\u2019re just going to replace those with a little plus symbol, so that they get encoded in the URL properly. Then we\u2019ll put that together. That\u2019s going to be our request and then we will submit that to our endpoint and get back the response. The response will come back as a string which we\u2019ll just decode. It\u2019s actually a binary array, we\u2019ll decode that and it will load that as a JSON document.", "Then within that JSON document we\u2019re going to look for a top-scoring intent and get the intent. If it\u2019s Light On then we\u2019re going to display an appropriate image. If it\u2019s Light Off we\u2019ll display another appropriate image. If it\u2019s something else entirely, we\u2019ll display yet another image. So that\u2019s pretty much the logic, we send our command, we get back what the LUIS app says the intent is for that command and from that we\u2019ll then take an appropriate response.", "So we\u2019ll go ahead and run this code. It\u2019s going to ask us to enter in a command. So we\u2019ll just enter one of our utterances to switch on the light.", "We get back a response which is a picture of a lamp with the light switched on.", "We entered \u2018switch on the light\u2019 and yet our original utterance was \u2018switch the light on\u2019 but the word order made no difference. It still managed to figure out that\u2019s the right command.", "Let\u2019s run it again and try something else. Let\u2019s command it to turn the light off.", "As you can see it has displayed the appropriate response displaying an image showing the lamp without the light on.", "So with this very simple example, you\u2019ve seen where we can build a LUIS app, specify the intents, give some sample utterances for those intents and then train the app. The app is then able to respond to requests from the client and send back the appropriate information about the intent we believe that the user wants. The app can take the appropriate response based on that.", "So we\u2019ve seen how to build a LUIS app and how to train it with intents that relate to entities and to interpret utterances in order to decide which intent is intended. But what we really want to understand is how can that develop over time. How can we improve the performance of our LUIS app so that it understands different utterances and interprets them correctly going forward. Let\u2019s take a look at something called active learning, which is a way of improving our service over time. So we are going to use the same client app we created in the previous demonstration. We\u2019ve tried turn the light off and we got our appropriate response with the light off. Let\u2019s go and try something different and say something like \u2018turn out the light\u2019.", "Now in this case the LUIS app has not been able to identify the the right intent. It\u2019s basically sent back a response of none and we\u2019ve displayed a big question mark here because turn out the light is not something that any of the utterances we trained our LUIS app with. It would logically be interpreted as being either the light on or light off intent so the intent is unknown. Effectively it\u2019s none and we get back this response.", "If we go back and have a look at our LUIS app. On this Build tab we can review some endpoint utterances. We can see among those utterances we\u2019ve got \u2018turn out the light\u2019. That\u2019s the one we just tried and it\u2019s aligned to none. It\u2019s got a 0.29 score as it tries to identify that. It\u2019s just not able to figure out which of the intents that it relates to but what we could do is go and align that now to the light off intent like shown below.", "So it\u2019s now aligned to that intent. So we\u2019ll just go in and retrain that app and now if we go and test that, we\u2019ll try our intent that we\u2019ve just changed. So we\u2019ve got our \u2018put out the light\u2019 and that comes back as being light off. So it\u2019s now associating that with the the intent of turning it off. So we were able to retrain our model based on some input that we\u2019ve been getting from our client app.", "If we just go and publish that again, we\u2019ll just republish that to our production slot. Now that that\u2019s been republished we can go back and try out our app again. So we\u2019ll just run our code. This time when we run the command \u2018turn out the light\u2019, we get back the appropriate response. It\u2019s actually now able to identify that the intent is the light off intent as shown below.", "Thanks for reading this article, Part 2 of the Microsoft Introduction to Artificial Intelligence course. If you found this helpful then check out all 4 parts on my Medium account or in Towards Data Science. If you had some trouble with some of the concepts in this article (don\u2019t worry it took me awhile for the information to sink in) and you need a bit more info, then enrol for free in the Microsoft Introduction to AI course. It\u2019s helpful to watch the course videos alongside with these notes.", "*If you would like to know a little background info behind the course notes and other notes related to tech and product design you can find out more here.*", "Hi, I\u2019m Christine :) I\u2019m a product designer who\u2019s been in the digital field for quite some time and have worked at many different companies; from large companies (as large as 84,000 employees), to mid size and to very small startups still making a name for themselves. Despite having a lot of experience I\u2019m a product designer who has a fear of suffering from the dunning-kruger effect and so I\u2019m continuously trying to educate myself and I\u2019m always searching for more light. I believe to be a great designer you need to constantly hone your skills especially if you are working in the digital space which is constantly in motion.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Striving to Create Tech Products that People Love \u2014 Snr Product Designer | Digital Art Director | Writer of Tech"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff7cfb6a5f1e3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@christinecalo?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christinecalo?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "Christine Calo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F42f0d29b1852&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&user=Christine+Calo&userId=42f0d29b1852&source=post_page-42f0d29b1852----f7cfb6a5f1e3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7cfb6a5f1e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7cfb6a5f1e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1"}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1"}, {"url": "https://www.classcentral.com/course/edx-introduction-to-artificial-intelligence-ai-9164", "anchor_text": "Microsoft Introduction to AI course"}, {"url": "https://medium.com/@christinecalo/a-little-about-christines-notes-8ea2205594a2", "anchor_text": "If you would like to know more info behind the course notes and other notes related to tech and product design you can find out more here."}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1"}, {"url": "https://www.classcentral.com/course/edx-introduction-to-artificial-intelligence-ai-9164", "anchor_text": "Microsoft Introduction to AI course"}, {"url": "https://www.classcentral.com/course/edx-introduction-to-artificial-intelligence-ai-9164", "anchor_text": "Microsoft Introduction to Artificial Intelligence Course"}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Part 1"}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-1-879e31d6492a", "anchor_text": "Machine Learning"}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-3-cb21d7a5e119", "anchor_text": "Computer vision"}, {"url": "https://towardsdatascience.com/microsoft-introduction-to-ai-part-4-d310033bdb07", "anchor_text": "Conversation as a Platform"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.programiz.com/python-programming", "anchor_text": "link a good place to learn a bit about Python"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview", "anchor_text": "Microsoft Text Analytics API"}, {"url": "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview", "anchor_text": "here."}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/text-analytics/", "anchor_text": "give it a try"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/speech-to-text/", "anchor_text": "Microsoft Speech-to-Text API"}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/speech-to-text/", "anchor_text": "Speech-to-Text API"}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/speech-to-text/", "anchor_text": "Text-to-Speech API"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://azure.microsoft.com/en-au/services/cognitive-services/translator-text-api/", "anchor_text": "Microsoft Translator API"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.vecteezy.com/", "anchor_text": "Vecteezy"}, {"url": "https://www.luis.ai/home", "anchor_text": "LUIS"}, {"url": "https://www.luis.ai/home", "anchor_text": "LUIS through here."}, {"url": "https://www.luis.ai/home", "anchor_text": "LUIS portal"}, {"url": "https://medium.com/@christinecalo", "anchor_text": "my Medium account"}, {"url": "https://towardsdatascience.com/", "anchor_text": "Towards Data Science"}, {"url": "https://www.classcentral.com/course/edx-introduction-to-artificial-intelligence-ai-9164", "anchor_text": "Microsoft Introduction to AI course"}, {"url": "https://medium.com/@christinecalo/a-little-about-christines-notes-8ea2205594a2", "anchor_text": "If you would like to know a little background info behind the course notes and other notes related to tech and product design you can find out more here."}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f7cfb6a5f1e3---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/nlp?source=post_page-----f7cfb6a5f1e3---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/speech-recognition?source=post_page-----f7cfb6a5f1e3---------------speech_recognition-----------------", "anchor_text": "Speech Recognition"}, {"url": "https://medium.com/tag/text-analytics?source=post_page-----f7cfb6a5f1e3---------------text_analytics-----------------", "anchor_text": "Text Analytics"}, {"url": "https://medium.com/tag/microsoft?source=post_page-----f7cfb6a5f1e3---------------microsoft-----------------", "anchor_text": "Microsoft"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7cfb6a5f1e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&user=Christine+Calo&userId=42f0d29b1852&source=-----f7cfb6a5f1e3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7cfb6a5f1e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&user=Christine+Calo&userId=42f0d29b1852&source=-----f7cfb6a5f1e3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7cfb6a5f1e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff7cfb6a5f1e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f7cfb6a5f1e3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f7cfb6a5f1e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christinecalo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christinecalo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Christine Calo"}, {"url": "https://medium.com/@christinecalo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "268 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F42f0d29b1852&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&user=Christine+Calo&userId=42f0d29b1852&source=post_page-42f0d29b1852--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6d0254251a32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmicrosoft-introduction-to-ai-part-2-f7cfb6a5f1e3&newsletterV3=42f0d29b1852&newsletterV3Id=6d0254251a32&user=Christine+Calo&userId=42f0d29b1852&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}