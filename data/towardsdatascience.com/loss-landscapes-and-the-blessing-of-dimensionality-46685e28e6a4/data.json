{"url": "https://towardsdatascience.com/loss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4", "time": 1683009079.8276742, "path": "towardsdatascience.com/loss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4/", "webpage": {"metadata": {"title": "Loss landscapes and the blessing of dimensionality | by Javier Ideami | Towards Data Science", "h1": "Loss landscapes and the blessing of dimensionality", "description": "Explore visualizations of deep learning loss landscapes, the blessing of dimensionality and other visuals including GANs & Geometric DL"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "Visualizing the Loss Landscape of Neural Nets", "paragraph_index": 63}, {"url": "https://math.stackexchange.com/questions/995623/why-are-randomly-drawn-vectors-nearly-perpendicular-in-high-dimensions/995678", "anchor_text": "online", "paragraph_index": 68}, {"url": "http://twitter.com/Pavel_Izmailov", "anchor_text": "@Pavel_Izmailov", "paragraph_index": 89}, {"url": "http://twitter.com/tim_garipov", "anchor_text": "@tim_garipov", "paragraph_index": 89}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026", "paragraph_index": 89}, {"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "arXiv:1712.09913", "paragraph_index": 108}, {"url": "https://arxiv.org/abs/1703.04933", "anchor_text": "Sharp Minima Can Generalize For Deep Nets", "paragraph_index": 132}, {"url": "https://arxiv.org/abs/1906.03291", "anchor_text": "Understanding Generalization through Visualizations", "paragraph_index": 133}, {"url": "https://arxiv.org/abs/1902.02476", "anchor_text": "A simple baseline for Bayesian Uncertainty in Deep Learning", "paragraph_index": 144}, {"url": "https://arxiv.org/abs/1902.02366", "anchor_text": "\u201cNegative eigenvalues of the Hessian in deep neural networks\u201d", "paragraph_index": 171}], "all_paragraphs": ["\u201cLife requires Movement\u201d \u2014 (Aristotle, 4th century BC)", "\u201cLife is movement. The more life there is, the more flexibility there is. The more fluid you are, the more you are alive.\u201d \u2014 Arnaud Desjardins", "\u201cLife is movement, movement is change\u201d \u2014 beginning of a quote by Neale Donald Walsch", "\u201cIf life boils down to one thing, it\u2019s movement. To live is to keep moving\u201d \u2014 Jerry Seinfeld", "As many well known people have told us throughout history, life is movement. Life is changing your state in a proactive way, going from A to B. Life is also an expensive process and that makes the process of going from A to B a delicate, fascinating process that needs to be optimized. And that\u2019s where we begin this article. And although we will focus throughout the following sections on deep learning and A.I, we will be touching simultaneously on universal themes and principles that go to the core of what means being alive. Moving. Going from A to B. Doing so in an optimized way. In a process that depends on a very large number of parameters, which makes it multidimensional. Which makes it hard to visualize for beings that operate in only 3 dimensions (4 with time). Which is the whole point of this article. So let\u2019s begin this ride where it all begins, with movement.", "Say we want to go from A to B in regards to some objective.", "Some of these challenges will take minutes, other hours, others days and some of them years. Some of them depend on a moderate number of factors, others depend on a massive number of them.", "We want to optimize these and infinite other challenges and the objective is always going from A to B. You may also combine many challenges and see life itself as a massive fractal made of optimization processes at different scales.", "Going from A to B could be tackled in different ways. We could do it very systematically, trying lots of possibilities. Or we could try to find the most efficient way to get there as soon as possible. It turns out that life is all about optimization because, as mentioned earlier, life is expensive. Time is expensive, glucose is expensive, keeping us alive, and life in general, is expensive. So it\u2019s all about optimizing the process of going from A to B. Finding as fast as possible the most efficient way to get to the objective.", "Now, if we want to optimize any challenge, we first need to understand how many factors, how many parameters are involved in the process of solving that challenge. So, how many factors are involved in each specific challenge?", "Some challenges we face depend on 1 or 2 key factors. Others in 10 or 20. Some of them in 100 or more. And some, like our objective of becoming a successful medical doctor may depend on thousands of factors whose values have to combine in the right way over many years to take you to that objective.", "Deep learning and neural networks also deal with complex challenges. They also require an optimization process to find the optimum combination of factors that help the network go from A to B: from a series of images to predicting what those images represent. From a sequence of words in English to the same sequence in Spanish, etc.", "Now, in order to tackle complex challenges, neural networks use architectures composed of millions, sometimes billions of parameters. Their optimization processes depend on millions or billions of factors. Their parameter space, or weight space, is very high dimensional.", "To find out how we can combine the different values of those parameters to reach our objective, we cannot systematically try different combinations randomly. We would be trying forever. Instead, there are different optimization algorithms that are used to find the optimum combination of those parameters. One of them, very used in deep learning, is gradient descent.", "Furthermore, not only we want to find a combination of values of our parameters that takes us efficiently to the objective. But it would be great to find one that generalizes as well.", "This means to find a combination of values that could take the network not only from A to B, but also from A2, A3, and other variations of A (within the same statistical distribution space) to B.", "Taking the network from D, E, F, that is, data that is out of the distribution space of A, to B, is also an objective, one that we can do as humans, but that is very difficult for deep learning at the moment.", "In general, we want to avoid overfitting, that is, producing a combination of parameters that creates a mapping function from A to B that adapts too closely to the training data (A), but whose performance degrades when applied to other unseen input data points.", "We also want to avoid underfitting, producing a mapping function from A to B which is too simple and fails to capture the existing variation in our source data.", "Therefore, we want to optimize (avoid underfitting), but also generalize (avoid overfitting).", "But in this article we focus not on how we find the values of those 10, 100, 1000 or 1 billion parameters. Instead, we focus on how we may visualize that optimization process. The process of moving from A to B.", "Visualization has been a favourite tool of great creative geniuses throughout history. Visualizing allows us to study and access simultaneously a lot of information at low levels of abstraction (rather than accessing information sequentially at high levels of abstraction like when we, for example, use language). Visualization can help us gain insights that may take us much longer to access through other means (think of Albert Einstein visualizing that he was a photon travelling through space, as he, in combination with other strategies, visualized his way to his theory of relativity).", "So, let\u2019s say that we would like to create a visualization that showed us how we went from A to B, from being a student to becoming a medical doctor, from being an unhealthy eater to becoming a person that eats a balanced diet, from having a financial data series to being able to extract fraud signals from that data. We may then bump into trouble when one of these challenges depends on too many parameters:", "Our brain is not even designed to make sense of more than 3 dimensions (4 with time). If we could access somehow a massive number of dimensions, we may perceive nothing, or we may perceive a big mess. And the more we went within, the more nonsensical it may all feel.", "And yet, do we give up? No, of course not. What do we do instead in all the above cases?", "We perform a dimensionality reduction process. And this is something that we are doing constantly in our lives.", "If I ask you: how did you go from being a student to becoming a successful medical doctor? You don\u2019t stop and tell me: \u201cOh sorry, that process depended on so many parameters that I cannot really explain to you how I went from A to B\u201d.", "Instead, you reduce the high complexity/dimensionality to something more manageable. With your incredible brain, you identify the most essential vectors/directions/factors/parameters that have influenced that process of going from A to B. And you reduce that high dimensionality from maybe thousands of factors to just 2, 3, 4 or 7, for example. And then you proceed to explain that going from A to B was possible because of this, and this, and that. Voila.", "In the same way, if you want to do an infographic, or a chart or a drawing or whatever that displays that A to B journey, you will do a similar thing. You will reduce the dimensionality/complexity and then proceed to create that visualization using just the reduced number of dimensions.", "As we continue reflecting on these visualizations, we begin to realize that apart from creating visual representations of the different factors involved, it would be fantastic to be able to chart the actual progress towards the objective.", "That is, to visualize how far from the objective we were at different parts of the optimization process.", "And we realize that at every step of the process, we can combine the different parameters involved, after assigning a numerical value to them, and produce a result that expresses where we are at that point in time.", "And then we can compare that result with the objective and estimate how far we are from that objective.", "Reaching the objective will imply that there is no difference between the value produced by combining our different parameters and the intrinsic value of the objective. The difference will be 0. We will have reached B.", "Conversely, at the beginning of the process, the difference between the result of combining our parameters and our objective will be large.", "This difference, by the way, is what we call in deep learning, the loss value. The difference between what we should obtain (our target objective) and what we are obtaining at the moment (our current state).", "If we plot this process we find out that we are moving from a high area (a high loss value) to a low area (a low loss value). And so, our objective is, in fact, to go from a high position (when the way we combine the different factors involved produces a result that is far away from our final objective), to a low position, one that is as low as possible (when the way we combine the different factors involved produces a result that is very close to our final objective).", "If we plot only our state, we will follow a point that moves from a high position to a low position.", "But, if we plot not only our position, but also other nearby combinations, a range of other combinations in parameter space, we will then create a surface, a landscape.", "We can describe this loss landscape in many different ways.", "On the one hand, it is a visual representation of the performance (loss value) of different areas of our parameter or weight space, of how different combinations of our parameters perform.", "It can also be used, when following the state of our agent/minimizer through the optimization process, as a visual representation of the process of looking for different ways of combining the parameters involved in our challenge, to produce a result that is as close as possible to our final objective.", "A visual representation that shows not only where we are, but also other possibilities that exist around our state, within the parameter space that surrounds our state, allowing us to study the morphology and dynamics of a surface that expresses this fundamental and constant principle in life: movement. Going from A to B. And looking for the best possible way to do that.", "In a recent conversation with Tom Bilyeu, Donald Hoffman, professor of cognitive science at the University of California, Irvine, tells us, as mentioned previously, that one of the defining features of life is precisely that, movement, directed movement. As such, visualizing these processes goes way beyond neural networks and deep learning. We are touching an essential part of what defines life, intentional proactive movement from here to there, in search of the optimum way to get to those low valleys as soon as possible, because our survival is in the game, because computing is expensive, glucose is expensive, life in general, is expensive. And that\u2019s why we may view our entire existence as a massive fractal of optimization processes.", "And when we work with deep learning processes and neural networks, we are working with optimization processes that depend on millions of parameters.", "In such cases, plotting these surfaces and landscapes becomes a bigger challenge. And that\u2019s what we are going to tackle in the next sections. So let\u2019s now go to the specific case of plotting these intriguing landscapes within deep learning training processes.", "Most deep learning processes have the objective of learning a complex function (the mapping from A to B that I wrote about previously). And how can we evaluate the performance of those learning processes? We can do it with what we call a loss function. Such function will tell us how far apart are the current output of our network and what that output ideally should be. That difference is the loss. And as the training process advances, our objective is to minimize that loss, to make it as small as possible. A loss value of 0 means that the network performs perfectly.", "Note: What is described in this section applies mainly to supervised learning, the most used by far type of learning nowadays in these kinds of systems.", "Typically, at the beginning of the training process, the network won\u2019t perform very well and our loss value will be pretty high. As training progresses, loss values gradually become smaller.", "As mentioned previously, visualization has been a favourite tool of scientists, explorers and creators throughout history. As opposed to the abstract and sequential nature of language, visualization allows us to simultaneously access a lot of information at much lower and more detailed levels of abstraction.", "If we are able to visualize the dynamics and morphology of these loss landscapes as the training process progresses, and if we can do that in as much detail as possible, we increase our chances of generating valuable insights in connection with deep learning and its optimization processes.", "Maths and visualizations complement each other. They are both important in their own right. The value of visualizing is in accessing simultaneously a very rich and detailed amount of data at a low level of abstraction, which can potentially accelerate the discovery of insights that may take us longer to extract from numerical calculations.", "The loss of a network, let\u2019s recap, is related to the difference between the current output of the network and what that output should be. And the output of the network is calculated by performing operations with the weights of the network. Therefore, the loss value depends on those network weights.", "All right, so that\u2019s what the loss value is. But what about the entire loss landscape? The loss landscape represents the loss value calculated not only with the specific weight values that the network may have currently, but also in a certain range around the current position within the weight space of the optimizer.", "So the loss landscape helps us visualize the loss values within the weight space of a network (which includes the current weight values but also many other combinations of them), and is typically centered in the current state of our optimizer. Therefore, in the center of the landscape we can see what the loss value is for our current set of weights. And around that central point, we can see loss values calculated with other combinations of the weights of the network.", "Now, remember that we said that to compare the current output of the network with its ideal output we use a function to calculate the loss value. And that function is the loss function (or cost function). Because neural networks have lots of parameters, this function is a multidimensional and multivariable function. This will become important shortly, because it\u2019s easy for us humans to visualize a 1 dimensional function, or a 2D or 3D function. But what about a 1 million dimensional function? or a 1 billion dimensional function? Stand by, we are getting there.", "This is a typical question that often comes up. Wait, I see the landscape change in some videos. Shouldn\u2019t the landscape be fixed? Let\u2019s explain this in detail.", "The shape of the loss landscape is dependent on the weights (parameters) of the neural network and on the loss values generated by that network. In the full high dimensional weight space that covers all possible combinations of values of those weights, the landscape is fixed in relation to that specific network architecture, to the different variations of those weights (weight space) and to the calculated loss values derived from the previous two factors.", "However, things change when we create practical representations of these landscapes:", "Easy. We cannot. We, human beings, cannot visualize data in 100 million dimensions. But no worries, because math gives us tricks and ways to do what, in fact, we are doing constantly in our lives.", "Whenever we do any of the above: is the new lower dimensional representation still useful? Does the 2D picture still communicate valuable and useful information about the 3D world? Yes, of course. Let\u2019s now focus on how we go about this in relation to our loss landscapes.", "It\u2019s clear that we need to reduce the high dimensional data to a lower number of dimensions. There are many dimensionality reduction techniques used in machine learning, which include, for example, PCA (Principal component analysis), LDA (Linear discriminant analysis), MDS(Multidimensional scaling), Spectral Embedding, t-SNE, Isometric Feature Mapping, Factor Analysis, etc. We can even use autoencoders (AE neural nets).", "In our case, we are looking for a technique that gives us a way to reduce the number of dimensions while preserving enough information about our state and about a range of possibilities and values around where we are.", "There are different strategies to do this. One of these strategies was introduced by the excellent paper Visualizing the Loss Landscape of Neural Nets by Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, Tom Goldstein. With this strategy, what we are going to do, thinking of an analogy, is to create a plane and kind of slice the high dimensional space with that plane to transform it into a 2D surface on which we can build our 3D visualization.", "To do that, we are going to firstly find and select a couple of random directions in weight space. These are random vectors and they should have the same dimension of the weight vectors in our network. With those 2 random directions we can now form a plane (more about the orthogonality of those 2 random directions a bit later).", "Then, we can take that plane and slice the high dimensional space with it, revealing its structure projected in 2 dimensions. At that point, we can add a third dimension, which will be the loss value calculated at each point within that plane.", "Let\u2019s remember that we will position the current state of our minimizer at the center of that projection and then look around a certain range within that projected 2D plane. And with that, voila, we can represent the nearby region around our optimizer in 3D (as well as its current state).", "PCA (principal component analysis) is a dimensionality-reduction method that could in principle be applied here. However, PCA will help us in visualizing the landscape along the most optimized directions. And that is going to help us see those parts of the landscape that are more optimized. We, instead, want to see a more diverse range within weight space, other parts of the landscape further away that are not so optimized. Using other kinds of directions (like the method previously described) allows us to do that.", "Math to the rescue! Math experts have proven that within high dimensional spaces, if you choose random vectors, they tend to be orthogonal to each other (there are proofs of this online at various places).", "Let\u2019s make an analogy to explore this a bit. With more dimensions, we get more complexity, and also more possible directions that can be accessed.", "Let\u2019s consider a random vector in a 1 dimensional world. Nothing orthogonal to it can exist.", "Let\u2019s move to a 2 dimensional world. Orthogonal vectors to our random vector will form a 1 dimensional line. Therefore, the orthogonal vectors live in 2\u20131=n-1= 1 dimension.", "Now let\u2019s go to a 3 dimensional world. Orthogonal vectors in that world will compose a 2 dimensional plane. Therefore, the orthogonal vectors live in 3\u20131 = n-1 = 2 dimensions, producing 2 dimensional planes.", "As we keep increasing the number of dimensions, the orthogonal vectors that we may find are present in a subspace of that space which has n-1 dimensions. Now we can see that the larger n is, the larger is as well the size of that subspace, the share of the complete space that is taken by the possible orthogonal vectors.", "In summary, even though it cannot be guaranteed that two random vectors within a high dimensional space will be with all precision orthogonal to each other, we can however predict that they will be very possibly and very nearly so.", "Let\u2019s recap. We have created a plane from two random orthogonal vectors. And now we have to decide on the coordinates of our surface and on the range that we will explore around the central point of that plane (which, let\u2019s remember, will be the current state of our minimizer).", "So we create a 2D grid, which will include the x and y coordinates of our visualization. The center of that grid will be the 0,0 coordinate and in there we will position the loss value that corresponds with the current state of our minimizer (calculated with the current weight values of our network).", "We then explore around that central point within a range. We may pick for example a range that goes from -1 to 1. Picking that range means exploring a portion of the landscape that has a similar magnitude to that of our weights. Basically, we would explore the landscape within a range of variation in weight space similar to the magnitude of our weights, and that\u2019s pretty reasonable.", "Then, we decide the resolution of the landscape. We can break down that -1 to 1 range into as many points as we like. For example, a 50x50 visualization will use 50 points in the first axis, and another 50 in the other axis, for a total of 2500 points. For each of those 2500 points, we have to calculate the loss value, which gives us the third axis, the vertical z coordinate.", "Time to calculate the loss values. What we do is to take the current weight values of our minimizer, that correspond to the center of our grid (0,0) and change them along the random directions we previously selected. And we modify them by the amount that corresponds to the point on the grid whose loss value we want to know. Let\u2019s go into the details of the equation itself:", "Theta: It represents the current weights of our network, the parameters of our minimizer. The loss value calculated with these parameters will appear at the center of the grid (0,0)", "Delta and Eta: These 2 represent our two random vectors, our random directions in weight space.", "Alpha and Beta: They are the x and y coordinates of each of the points in the grid plane.", "To calculate the loss at one specific point of the grid plane, we will first calculate a new set of parameters(weights) which are the result of adding the original ones of our minimizer to the result of adding the product of the coordinate values of that point by each of our random directions. And then we will calculate the loss with that new set of parameters.", "Finally, the coordinates of each of the points of our loss landscape will be:", "We are looking at a certain range of the full landscape around our minimizer. So modifying that range, we can zoom more or less around our current position. If instead of projecting our weights through a -1,1 range, we use a -0.2, 0.2 range, we will be focusing our detail (whatever number of points we are calculating) on a much tighter range around our minimizer. Conversely, using a -3,3 range, we will zoom out to encompass a way larger area that shows areas of the landscape further away from our minimizer.", "As much as we like. Of course the further you go, the more you should increase the number of points calculated by axis in order to maintain a similar amount of detail.", "The issue, however, is that typically, as we go further and further away from the current position in the weight space of our minimizer, we find that loss values become really high and the landscape moves up and up so we stop seeing interesting features. When facing extreme contrasts in the visualization, we also tend to visualize the log of the loss values. This helps us in visualizing the extreme contrasts that appear on the edges of the visualization.", "Therefore, typically, the area we explore is more around the -1,1 range.", "As we move away from a local minima, we may wonder if we could find paths that connect that minima with other local minima around our position. In recent years researchers have uncovered ways to find shortcuts and connections between local minima, paths through which loss values remain very low. These paths are typically not straight lines but curved paths, polygonal paths, etc. Through a collaboration with Pavel Izmailov (@Pavel_Izmailov) and Timur Garipov (@tim_garipov), we created Icarus, a visualization based on the NeurIPS 2018 paper by Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry Vetrov, Andrew Gordon Wilson: https://arxiv.org/abs/1802.10026 where we visualize mode connectivity (paths connecting different local minima) using real data. Through these paths (a bezier curve in this specific case), training and test accuracy remain nearly constant.", "Later on in this article, I will write about the blessing of dimensionality, as more and more researchers are considering that the great results we get using deep learning may be related to how these high dimensional spaces allow gradient descent to easily find good minima in regions that are local, close to our starting position, regardless of where we initialize the optimizer within the loss landscape.", "Great questions! Let\u2019s go for it.", "First of all, applying dimensionality reduction techniques, transforming a very large number of dimensions into just 2, implies being realistic. In the same way that a 2D photograph cannot express the full richness of the 3D world, also our 3D loss landscape representations cannot communicate the full complexity of the high dimensional space.", "Also, in the same way that taking a photograph from different angles will provide us with different perspectives of the 3D world, using a different set of random directions may also generate different perspectives of the loss landscape.", "So, let\u2019s make one thing clear. If your objective is to get a fully precise idea of the shape of the loss function and landscape, you need to analyze these 3D representations carefully. In the same way that looking at 2D photographs requires some careful analysis if we are to interpret with precision some of the features of the 3D world.", "Going back to the photography analogy. When we take photos, not only we transform a 3 dimensional world into a 2 dimensional representation. But we often apply filters and other treatments that further distort the original 3D data source. As mentioned earlier, our position and the angle we use when taking the picture have a lot of influence as well on the final result. And we could continue reviewing other ways in which our interpretation keeps moving further and further away from the original data source.", "So, is the photograph a precise representation of that 3D world? No, surely not.", "And yet, is the photograph giving us useful data about that 3D world? information that could even potentially trigger interesting insights? Yes, of course. Definitely.", "That\u2019s why we take pictures. And combining pictures from different angles, we gain new insights that deepen our understanding of that 3D world.A similar thing happens when astronomers take pictures of galaxies, planets and stars. And a similar thing happens when we explore these loss landscapes, studying them from different perspectives and also in movement.", "In a certain sense, everything is relative and if we begin to scratch the surface of the different interpretations and dimensionality transformations that we apply in life, we could go on for a long time. Our perception of the \u201c3D world\u201d out there is of course yet another interpretation-distortion generated by our brain. But each of these transformations provides useful information, data that can inform, inspire and even potentially generate deep insights.", "Therefore, going back to these landscapes. Are they precise representations of the high dimensional \u201creality\u201d? Definitely not. But are they giving us useful data about that underlying high dimensional space, data that could potentially trigger new interesting insights? Definitely yes.", "And can we actually prove that? Yes, we can. For example, deep learning experts have demonstrated that the key convexities and non-convexities that appear in these kinds of reduced dimensionality representations match with those indicated by numerical analysis processes that are performed using the main related eigenvalues and eigenvectors.", "And the shape, the morphology of these surfaces, is just the beginning. We may also study the dynamics of these landscapes as our minimizer moves through them. For example, studying the way these representations change over time as we modify various hyperparameters of our network, can help us understand in new ways the dynamics of our training processes and the impact that these hyperparameters have in them.", "Therefore, even though we cannot visualize the entire high dimensional complexity, we can still gather many useful insights as we visualize these landscapes from different perspectives, just as we do when we take photographs.", "And just as capturing movies = pictures in movement, deepen our understanding of the 3D world (because static pictures can sometime produce confusion in our interpretation of that world), in the same way, loss landscapes in movement, representations in which we ride alongside our minimizer as the training process progresses, give us new ways to deepen our understanding of the dynamics of these processes and their behaviour and state at each of the steps of the process.", "And going back to what we mentioned earlier about eigenvalues. Math helps validate these representations by allowing us to verify if the convexity distribution we observe matches with what numerical analysis reports. And for that, as mentioned, we may use the Hessian and its related eigenvalues.", "Hessian matrices contain second order derivatives. Through them, we can understand the curvature of the loss landscape. To get that data, the simplest way is to study the essence of the Hessian, which can be expressed through its eigenvalues and eigenvectors.", "Fully convex functions have positive semi-definite Hessians with curvature values which are non-negative. Conversely, the opposite happens in non-convex functions.", "The academic paper arXiv:1712.09913 tells us that the key curvatures of these low dimensional representations we are creating, are in fact averages, weighted averages of those present at the high dimensional original space and function. And that\u2019s why by analyzing the eigenvalues of the hessian at each of the points of our landscape, we can estimate that on average, these visualizations are correct.", "Calculating the maximum and minimum eigenvalues of the hessian at each of the points in our visualization, we can then use their absolute ratio to study and map their distribution. In this way, we can see which areas have more or less convexity. With this data, we can verify that those areas that look very convex in our representation, match with areas that contain very small negative eigenvalues. And those areas in our visualization that are non-convex match with areas that have large negative eigenvalues.", "Hessian matrices are complex entities and computing them requires a lot of resources. Many complex entities and systems can be better understood by working with some of their properties which capture their essential qualities.", "That\u2019s why we use eigenvalues and eigenvectors. They help us capture the essential and key features of systems, in this specific case, of the hessian matrix.", "We are extracting the key data we need through a series of vectors and numbers, which is much simpler and faster than dealing with the full and often very large square hessian matrix.", "Furthermore, eigenvalues and eigenvectors give us insights about the properties of the hessian matrix that are not so easy to understand from the full matrix representation. That\u2019s why eigenvectors and eigenvalues are considered very useful in a variety of fields when we need to capture and extract the essence of a system. They are used, as an example, within image compression systems, through the process of discarding the small eigenvalues and preserving the ones that express the most important information of that entity.", "Let\u2019s go for it. When looking at the hessian at a specific point:", "By plotting the different combinations of eigenvalues, numerical analysis helps us understand and verify the convexity patterns of our landscape", "The hessian of a typical neural network is really large. Its size is proportional to the square of the number of weights of the network. And as we know, typical neural nets have a very large number of parameters.", "Therefore, computing with the complete hessian is not feasible in relation to any network of a significant size. It is not practical at all to try to gather all the eigenvalues.", "Instead, we use, for example, some algorithmic tricks and the Scipy library to extract the smallest and the largest eigenvectors and eigenvalues, and that is enough for us to get the data we need in order to study the convexity distribution of the landscape.", "There are so many possibilities. These visualizations help us deepen our understanding of the morphology and dynamics of the loss function as we move through the training process. The study of the dynamics of these optimization processes is one of the interesting areas. The study of the impact of changes in the values of different hyperparameters is another. But you could pick many others, for example: weight pruning and subnetworks. Research tells us that pruning weights, and finding good subnetworks can give us results that use less time and resources and yet are as good as those we obtain when using the full network. Visualizations can help us track and gain insights on the impact of these pruning processes on the loss landscape and function.", "Yes indeed. For example, the Taylor series (a way of expressing a function as an infinite sum of terms) shows us how we can prune some of the complexity of a function while still retaining its key features.", "It can be pretty strong across the training phase. As an example, in training mode, the use of batchnorm or dropout can have a significant impact on the morphology of the landscape.", "Analyzing changes in morphology related to the use of batchnorm, we find morphological variatons in the landscape when it is active (we keep other parameters like batch size, dropout, mode, etc stable to be able to establish comparisons). Batchnorm can have a regularizing effect, reducing generalization error.", "When the mean and the standar deviation are calculated in batch norm (calculations which are performed across batches), these values, these estimates, are noisy. The noise produced in the process of calculating the values is coming from other parts of the selected batch. That noise is then combined with the weights when the batchnorm operations are performed, and could potentially be helping the generalization capabilities of the network, producing a regularization effect.", "Therefore, currently under study, one of the hypotheses in connection with the morphology of the related landscape is that it may be related to a higher level of resilience, the previously described level of noise that in a certain sense helps the network generalize better. Just an example of how we can analyze changes in morphology to search for new insights.", "When we look at dropout, the impact on the training mode morphology is very clear, but the perturbations have a different character.", "Dropout introduces high frequency noise in the morphology of the landscape. These high frequency perturbations may be related to the way dropout helps the networks generalize better.", "Let\u2019s go into more examples about how we can analyze these visualizations. Due to the limited space available in this article, the explanations will be quite generic, but we will still cover different variations.", "Let\u2019s pick a specific moment of the process and show how we can use static high resolution captures to reflect about different aspects of the network (the same can be done with the dynamic moving visualizations which allow us in addition to study the dynamics of the process)", "As I explored more and more landscapes, I began to identify key features of these landscapes which I continue investigating in more depth. These are a few of them:", "More of these features and related analyses will be published and shared in more depth in the future.", "There is active research about this matter and this question has been answered in different ways, sometimes opposing ways, in recent years.", "The paper \u201cSharp Minima Can Generalize For Deep Nets\u201d by Laurent Dinh, Razvan Pascanu, Samy Bengio, Yoshua Bengio, tells us that sharp minima can generalize as well as flat ones. It also states that flat ones can generalize poorly as well on occasions. (note: the paper defines flatness as the size of a region that has roughly constant error).", "Other papers describe a different perspective on the matter. For example, the paper \u201cUnderstanding Generalization through Visualizations\u201d verifies that generalization error correlates well with the flatness of the minimizer. It also verifies that differences between flat and sharp minima are emphasized by the multidimensional nature of these loss landscapes. The paper also concludes that the high dimensionality nature of these landscapes keeps the minimizer away from bad minima (more about this a bit later in this article).", "In general, the trend is to state that flat minima generalize better than sharp ones. Intuitively this makes sense, given that flat minima should allow for more deviations from a certain point, while maintaining a similar loss value.", "Yes, it\u2019s possible to analyze the loss landscape with certain types of GANs. The issue with GANs, traditionally, has been that there is not a clear correlation between the loss value and how well the network is performing. In supervised learning, we know that if loss values are low, the network is performing well. But in GANs, we may be getting great results and yet have loss values all over the place. As the generator and discriminator compete with each other, loss values can have patterns of behaviour that are rather non-intuitive.", "To the rescue came a type of GAN called a Wasserstein GAN (with gradient penalty in this case).", "In most GANs, the loss value is telling us how well the generator is fooling the discriminator, rather than what the quality or performance of the output result is. So the quality of our output may be improving and yet the loss of the generator may not go down.So by analyzing the loss value in most GANs it is difficult to ascertain how well we are doing.", "On the other hand, with Wasserstein GANs, the loss value communicates the performance and quality of the output result, which therefore makes it possible to build visualizations in which we use the loss values to analyze the network\u2019s performance and other metrics around it.", "Below I show a visualization that uses the Celeb A dataset and a Wasserstein GP Gan. As seen in the video, we can track the performance of our generator\u2019s loss landscape, which starts as a flat surface that then begins to evolve as our minimizer converges towards different minima.", "We can also sense in the visualization the inestable nature of the training processes of GANs, that often behave like wild beasts that need to be tamed through very careful picking of the parameters and timings of their training processes.", "Yes, they can be applied to many other areas of deep learning and to other fields.", "For example, an area of deep learning where visualizations can help a lot is Geometric deep learning. Geometric deep learning intends to adapt neural networks to non-euclidean domains, which could be manifolds, graphs, etc.", "In collaboration with Neural Concept SA, the following video shows the activations of the convolutional layers inside a Geometric CNN, extracting features from the surface of a drone, while the network is being trained to predict aerodynamic properties of the aircraft. We visualize features near the beginning of the network and others near the end of the network.", "Another area is Bayesian deep learning. For example, in this collaboration with NYU researchers Pavel Izmailov and Andrew Gordon Wilson, we focus on their SWAG paper NeurIPS 2019:1902.02476: \u201cA simple baseline for Bayesian Uncertainty in Deep Learning\u201d by Wesley Maddox, Timur Garipov, Pavel Izmailov, Dmitry Vetrov, Andrew Gordon Wilson, a paper related to Bayesian deep learning, in which they take a pre-trained solution produced through SGD, Adam or any other optimizer, and then starting from it, they use a high learning rate and SGD to find a set of solutions.", "Then, they build a gaussian distribution that captures the different solutions traversed by the stochastic gradient descent training process. We can then use this distribution as an approximation to the posterior.", "This visualization uses real data to plot the optimized part of the loss landscape (using PCA) as well as the positions of the solutions and the related gaussian distribution produced.", "These visualizations allow us to study all kinds of surfaces from different perspectives as in the following study that looks at the convexity dynamics from below, as a minimizer progresses towards a minima.", "As mentioned earlier, the level of detail in these visualizations can be taken as far as we like. Of course the more data, the more compute time and resources we need. More data allows us to study the morphology of these surfaces in more detail.", "Many researchers are finding that as deep learning networks increase their dimensionality, finding good minima gets easier, not harder. This connects with what some call \u201cThe blessing of dimensionality\u201d.", "Recently, Babak Hassibi, who is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering and Computing and Mathematical Sciences at the California Institute of Technology, gave a talk titled \u201cDeep learning and the blessing of dimensionality\u201d (joint work with Navid Azizan Ruhi and Sahin Ali Lale).", "The opposite of the blessing of dimensionality is what is called \u201cThe curse of dimensionality\u201d, which refers to the fact that as dimensionality grows, the number of possible combinations and configurations grows as well, exponentially, whereas the number of those combinations that are covered by our data gets lower. This should theoretically cause different issues and yet, the opposite seems to be happening.", "As our networks grow larger in dimensionality, their number of parameters dwarf the number of data points in the system (overparameterized networks). As such, they should overfit the data, not generalize. However, what we find is that they definitely generalize, and the larger the network, the better!", "It is common to see cases where we have millions of parameters and thousands of data points, and yet the network won\u2019t overfit.", "Babak makes a great analogy in his talk in connection with finding needles in haystacks. In relation to under parameterized systems, we can imagine that we are trying to find a few needles (combinations of weight values that take us to good minima) in the haystack. Conversely, in relation to overparameterized networks, there are infinitely more needles available in the haystack, and that\u2019s why it may be much easier to find them.", "When we have 1 million parameters, for example, and 1000 data points, any point from which we begin our training process within the loss landscape, is going to be close to a combination that interpolates our data.", "And due to this blessing of dimensionality, convergence becomes an easier challenge to solve, it becomes easy to converge to a low minima within the landscape. On top of that, with a good regularizer we may also get the generalization capability that we want. Furthermore, Babak tells us that there is an implicit regularization capability embedded in our deep learning SGD algorithm.", "In summary, extra dimensions facilitate our optimization challenges. In high dimensional networks, the set of interpolating solutions is really large. Because of that, wherever your starting position is on the loss landscape, chances are very high that there is a local path somewhere close to your starting point that will take you to a good minima.", "In these visualizations, what we are doing could be described as \u201cfollowing the minimizer while examining its nearby surroundings\u201d. This is feasible because we know at all times the current weights of our network, so we can take those as the center / reference point of our low dimensional plane (the one we produced from the random orthogonal directions), and from that point we can explore its surroundings. Those nearby surroundings are constantly changing because the position of our minimizer (calculated from the changing weights of our network) varies as the training progresses (and as we move through weight space), all of this taking place within the non-changing, full high dimensional landscape, a region of which is expressed visually through our low dimensional interpretation.", "Let\u2019s now consider the alternative. If we want to fix in place the landscape while the training progresses, and at the same time we try to follow the path of the minimizer around that landscape, we face a challenge.", "The landscape we visualize in our representation is a low dimensional interpretation of a portion of the full high dimensional one. To create that representation, that lower dimensional version, we need to make use of a reference point, which happens to be, naturally, the current position of our minimizer, its current state and position in weight space.", "So, if we want to represent both the static landscape, and the path followed by the minimizer, we are missing something. What portion of the high dimensional landscape should we show at each step? We would naturally say that we want to show the area near to the current position of the minimizer. Sure, let\u2019s do that. But then, when the minimizer moves, what do we do? How does the trajectory relate to the area of the landscape that we are representing? The key thing to consider is that the minimizer is moving within the high dimensional space, not within the low dimensional interpretation. Therefore, the low dimensional interpretation of the \u201cnext\u201d position of the minimizer, may have little to do with the previous one (because the change happens in the high dimensional space). By fixing the landscape in place, we fix a low dimensional representation projected onto a plane that corresponds to a specific state and position in weight space of the minimizer.", "We can try to deal with this issue in various ways. The paper mentioned earlier, \u201cVisualizing the Loss Landscape of Neural Nets\u201d, makes use of PCA to analyze the trajectory of the minimizer, but as discussed earlier, PCA directions extract the optimized parts of the landscape. And by doing that, we won\u2019t have a way to match that data with the rest of the landscape with accuracy (in relation to the wider and more diverse areas that surround the minimizer).", "If the movement of our minimizer had a very low dimensional nature, we could take a single fixed landscape state and attempt to match a minimizer\u2019s trajectory to it (using PCA), by using projections. However, as Tom Goldstein once told me, the minimizer\u2019s trajectory will not be perfectly planar so we have to project it onto a plane, which means that the contours projected may not be the ones that exist off the plane. Beyond that, PCA limits us in other ways also in relation to the surrounding landscape.", "In summary, matching trajectory and landscape with accuracy remains a challenge. On top of that, to combine across the entire process an extensive and wide area of the surrounding landscape and the minimizer\u2019s trajectory is yet another obstacle on top of the previous one.", "A core issue here is that we are at all times visualizing and working with low dimensional interpretations of the higher dimensional structure. Let\u2019s consider a variation of our photography analogy.", "Say you take a series of pictures (2 dimensional interpretations of the 3d world) of any subject (existing in the higher 3 dimensional space), from various angles. And say that you then try to match them with each other. You could use photogrammetry (https://en.wikipedia.org/wiki/Photogrammetry). Photogrammetry can extract the underlying 3d structure from a combination of 2d sources of data. Could something similar be done with these loss landscapes? The challenge is that photogrammetry makes transformations from a mix of 2d sources to a 3d space. In our case, we are dealing with very high dimensional spaces, spaces with millions or billions of dimensions. There may be a way of doing such a thing in the future, but at the moment it remains an area of research.", "In summary, in these visualizations, we are joining the high dimensional ride by attaching ourselves to the minimizer itself. As we ride alongside the minimizer, we make use of a low dimensional 2d plane to analyze and study its surroundings from a certain perspective.", "If we didn\u2019t ride on the shoulders of the minimizer, and instead we stayed in place, analyzing a portion of the landscape through the lens of a fixed low dimensional interpretation, the minimizer would then move in the following steps to different parts of the higher dimensional structure, whose low dimensional representation is going to be different.", "Unfortunately for us, we cannot visualize those higher dimensional structures, and as we always need to slice them somehow with lower dimensional representations, fixing these low dimensional representations becomes possible if the movement of the minimizer took place in a very constrained number of dimensions. As such things cannot be guaranteed, finding an accurate way to put together those 2 representations (the minimizer\u2019s trajectory and the fixed landscape) becomes a challenge.", "The alternative is what we see here, riding safely on the shoulders of the minimizer, while analyzing and studying the changing surroundings as the training process progresses and we move around weight space. And this is enough to potentially give us useful information and insights about the morphology and dynamics of these processes.", "Ideally yes. But as usual, Pareto often beats perfection. It really depends on your objective. For some objectives, you may iterate on a subset of the entire set as long as you keep using the same subset. For example, the paper \u201cNegative eigenvalues of the Hessian in deep neural networks\u201d states that while studying the eigenvalues of the hessian, using 5% of the training set (and repeating always the use of the same 5%) generated results close enough to those produced by using the complete set.", "More related writings and more visualizations and audiovisual creations in the intersection of research and art, as well as collaborations with researchers around the world. These types of collaborations help us push forward the field of deep learning.", "Let\u2019s keep going further and deeper into the fascinating world of loss landscapes.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A multidisciplinary engineer, researcher, creative director, artist and entrepreneur, from augmented reality to deep learning, filmmaking, 3D and beyond."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F46685e28e6a4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ideami?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ideami?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "Javier Ideami"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7f7b5d730c84&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&user=Javier+Ideami&userId=7f7b5d730c84&source=post_page-7f7b5d730c84----46685e28e6a4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46685e28e6a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46685e28e6a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "Visualizing the Loss Landscape of Neural Nets"}, {"url": "https://math.stackexchange.com/questions/995623/why-are-randomly-drawn-vectors-nearly-perpendicular-in-high-dimensions/995678", "anchor_text": "online"}, {"url": "http://twitter.com/Pavel_Izmailov", "anchor_text": "@Pavel_Izmailov"}, {"url": "http://twitter.com/tim_garipov", "anchor_text": "@tim_garipov"}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026"}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026"}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026"}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026"}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026"}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026"}, {"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "arXiv:1712.09913"}, {"url": "https://arxiv.org/abs/1703.04933", "anchor_text": "Sharp Minima Can Generalize For Deep Nets"}, {"url": "https://arxiv.org/abs/1906.03291", "anchor_text": "Understanding Generalization through Visualizations"}, {"url": "https://arxiv.org/abs/1902.02476", "anchor_text": "A simple baseline for Bayesian Uncertainty in Deep Learning"}, {"url": "https://arxiv.org/abs/1802.10026", "anchor_text": "https://arxiv.org/abs/1802.10026"}, {"url": "https://arxiv.org/search/stat?searchtype=author&query=Garipov%2C+T", "anchor_text": "Timur Garipov"}, {"url": "https://arxiv.org/search/stat?searchtype=author&query=Izmailov%2C+P", "anchor_text": "Pavel Izmailov"}, {"url": "https://arxiv.org/search/stat?searchtype=author&query=Podoprikhin%2C+D", "anchor_text": "Dmitrii Podoprikhin"}, {"url": "https://arxiv.org/search/stat?searchtype=author&query=Vetrov%2C+D", "anchor_text": "Dmitry Vetrov"}, {"url": "https://arxiv.org/search/stat?searchtype=author&query=Wilson%2C+A+G", "anchor_text": "Andrew Gordon Wilson"}, {"url": "https://arxiv.org/abs/1902.02366", "anchor_text": "\u201cNegative eigenvalues of the Hessian in deep neural networks\u201d"}, {"url": "https://www.youtube.com/playlist?list=PLXRmG-SrXaHg4XsOAlZ3zbsYvwYhyXycJ", "anchor_text": "https://www.youtube.com/playlist?list=PLXRmG-SrXaHg4XsOAlZ3zbsYvwYhyXycJ"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----46685e28e6a4---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----46685e28e6a4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----46685e28e6a4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----46685e28e6a4---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----46685e28e6a4---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46685e28e6a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&user=Javier+Ideami&userId=7f7b5d730c84&source=-----46685e28e6a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46685e28e6a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&user=Javier+Ideami&userId=7f7b5d730c84&source=-----46685e28e6a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46685e28e6a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F46685e28e6a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----46685e28e6a4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----46685e28e6a4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----46685e28e6a4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----46685e28e6a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ideami?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ideami?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Javier Ideami"}, {"url": "https://medium.com/@ideami/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7f7b5d730c84&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&user=Javier+Ideami&userId=7f7b5d730c84&source=post_page-7f7b5d730c84--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4c3e5da2cfc1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Floss-landscapes-and-the-blessing-of-dimensionality-46685e28e6a4&newsletterV3=7f7b5d730c84&newsletterV3Id=4c3e5da2cfc1&user=Javier+Ideami&userId=7f7b5d730c84&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}