{"url": "https://towardsdatascience.com/5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2", "time": 1683017563.4451258, "path": "towardsdatascience.com/5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2/", "webpage": {"metadata": {"title": "5 Levels of Difficulty \u2014 Bayesian Gaussian Random Walk with PyMC3 and Theano | Towards Data Science", "h1": "5 Levels of Difficulty \u2014 Bayesian Gaussian Random Walk with PyMC3 and Theano", "description": "State-Space Models in Bayesian Time Series Analysis with PyMC3"}, "outgoing_paragraph_urls": [{"url": "https://github.com/luisroque/bayesian_time_series", "anchor_text": "GitHub", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Random_walk", "anchor_text": "[2]", "paragraph_index": 10}, {"url": "https://theano-pymc.readthedocs.io/en/latest/", "anchor_text": "[3]", "paragraph_index": 32}, {"url": "https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b", "anchor_text": "[4]", "paragraph_index": 32}, {"url": "http://www.mcmchandbook.net/HandbookChapter6.pdf", "anchor_text": "[5]", "paragraph_index": 34}, {"url": "https://docs.pymc.io/notebooks/GP-smoothing.html", "anchor_text": "[6]", "paragraph_index": 39}, {"url": "https://github.com/pymc-devs/pymc3/blob/4fd56fdeccf4550953b896f9af41c8b9b65b9ed8/pymc3/distributions/timeseries.py#L185", "anchor_text": "[7]", "paragraph_index": 42}, {"url": "https://theano-pymc.readthedocs.io/en/latest/library/scan.html?highlight=scan", "anchor_text": "[8]", "paragraph_index": 49}, {"url": "https://en.wikipedia.org/wiki/Exponential_smoothing", "anchor_text": "[9]", "paragraph_index": 52}, {"url": "https://docs.python.org/3/tutorial/floatingpoint.html", "anchor_text": "[10]", "paragraph_index": 54}, {"url": "https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval", "anchor_text": "[11]", "paragraph_index": 78}], "all_paragraphs": ["Today time series forecasting is ubiquitous, and decision-making processes in companies depend heavily on their ability to predict the future. Through a short series of articles, I will present you with a possible approach to this kind of problems, combining state-space models with Bayesian statistics.", "In the initial articles, I will take some of the examples from the book An Introduction to State Space Time Series Analysis by Jacques J.F. Commandeur and Siem Jan Koopman [1]. It comprises a well-known introduction to the subject of state-space modeling applied to the time series domain.", "This post belongs to a series. Feel free to check the previous post to acquire some more context:", "Also, you can always find all the data and code in my GitHub.", "The dataset that we are using comprises the monthly number (log transformed) of drivers killed or seriously injured (KSI) in the UK for the period January 1969 to December 1984.", "In the last article, we defined and implemented the deterministic level model. We built it from the ground up, which introduced us to important concepts. Nonetheless, we couldn\u2019t really capture the latent dynamic behavior in our data. This time and to change that, we will make use of stochastic parameters. The stochastic level model is a generalization of our first model, the deterministic level model. The model is straightforward, but it is an important piece that we add to our toolbox. When people refer to local level models, they refer to these models and not so much to the deterministic ones. The real change here is that we allow our level to vary; it is no longer deterministic, which means that the component is applied locally (hence the name).", "Now, we have a new equation to consider. The model can be written as", "for t=1,\u2026,n, where \u03bc_t is the unobserved level at time t, \u03b5_t is the observation disturbance (or sometimes referred to as irregular component) at time t, and \u03be_t is the level disturbance at time t.", "The first equation is called the measurement equation, and the second is our state equation. The second equation helps us model our dependencies in time, as the state at time t+1 is a function of the state at time t.", "Before moving on, we need a little more intuition. You\u2019ll see the concept of random walk thrown around in almost every financial time series paper or textbook. The simplest random walk that we can think of is a one-dimensional walk, using a straight line. The person has to decide one direction or the other, moving forward or backward. Let\u2019s imagine that the decision on its next step is taken by flipping a coin. If the coin falls heads up, the person takes a step forward; if the coin falls tails up, the person takes a step backward. This is a random walk. We can see the more formal definition:", "In mathematics, a random walk is a mathematical object, known as a stochastic or random process, that describes a path that consists of a succession of random steps on some mathematical space such as the integers. [2]", "In the same article, we can see that it is a ubiquitous behavior in nature as much as it is in human nature. The examples include the path traced by a molecule as it travels in a liquid or a gas, the search path of a foraging animal, the price of a fluctuating stock, and the gambler's financial status can all be approximated by random walk models.", "Now that we have defined it let\u2019s see how exactly it looks like. Let\u2019s draw a 1-D and 2-D random walks. We need to define an origin (e.g., y=0 for 1-D and (x=0, y=0) for 2-D) and then, as we said earlier, choose a step to move with equal probability.", "Let\u2019s investigate the distribution of our steps. We are randomly taken discrete steps, so we expect an equal number of -1 and 1 drawn for all the time steps.", "Just as an exercise, we can describe even better this distribution. It is a discrete distribution to start, and we are just randomly choosing from a list of two possible values. So we can model it with a binomial distribution with parameters n (equal to the number of steps) and p (probability of success \u2014 in our case, could be choosing 1).", "Let\u2019s plot it and understand some of its properties.", "We plot 1/100 of the number of steps that we used above to make sure that they follow a discrete distribution and not a continuous one. We should ensure that we get the expected 50% probability of getting 1 (considering 1 our success and p=0.5). Because it is a discrete distribution, we have to sum all the possible values up to the 50% point. This is called the cumulative distribution function.", "Both lines above are doing the same thing, but we are not getting exactly 50%, as you see. When n is small, the probability of a deviation from 50% is significant. If one increases the number of trials, for instance, to n = 100000, the result will move closer to 50%. As n approaches infinity, the outcome will approach 50%.", "Just our of curiosity, a random variable that follows a binomial distribution, for a sufficiently large n (more than sufficient in our case), can be approximated by a normal distribution with the parameters:", "That is why our plot for the binomial distribution above resembles so much a gaussian distribution.", "As we were expecting, the normal probability density function is basically superimposed.", "To make our case, let\u2019s draw our step directly from a Gaussian distribution. It is the usual way to define it and often yields the best results in real-world applications.", "The step is normally distributed with \u03bc=0 and \u03c3=1. In fact, you can use any distribution for the step, whichever fits your data best. As we saw in the code above, the Random Walk behavior is created by the cumulative sum of the steps. The way the steps are created is really up to you. The steps are usually referred to as innovations.", "An important distinction that I want you to always bear in mind is the difference between a random process and a random walk. A random process is stationary because it consists of random variables independently and identically distributed. More than that, it implies that the process has a constant mean and variance, which is the very own definition of a stationary process. This is not the case with a random walk.", "The random walk is a non-stationary process because the variance changes over time. Let\u2019s experiment with several draws.", "I hope it is clear that the variance grows with time. We can write it as", "Another aspect that shows the non-stationarity is the autocorrelations in the correlogram. It only starts to approach 0 for a large number of lags.", "Stationarity plays an important role in time series analysis, so we will often use this concept in future applications.", "As we usually do, let\u2019s start with the classical implementation before continuing to the Bayesian land. We\u2019ll be using the statsmodel library again.", "Here we can see the Maximum Likelihood Estimation (MLE) of the variance of the irregular component and the level disturbance variance (if you want to understand better how this estimation works, check my last article of the series).", "Now it is time to implement our local level model with our Bayesian hats. I promised five implementations with five increasing levels of complexity. We will start with the off-the-shelf solution that PyMC3 offers since it has a built-in Gaussian Random Walk (GRW) class. Next, we will learn about some tweaks that we can use when our parameters' posterior distributions are challenging to sample, namely when they are highly correlated. The third level is our first light attempt to manipulate PyMC3 objects. In the fourth level, we will build our own GRW custom class. Finally, on the last level, we will make use of Theano to implement all the steps from scratch.", "Although only the last level depends heavily on Theano, we will touch base on simple Theano functions or features across all implementations. So it makes sense to do a small introduction on the topic.", "PyMC3 is actually built on top of Theano. Theano, as per their own definition, is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently [3]. For those who follow the deep learning landscape, you are probably aware that in 2017 the Theano original development team announced that they were stopping further developments. Soon after, the PyMC3 dev team took over the maintenance of the library. More recently, the team announced that PyMC4, which was being developed using TensorFlow Probability instead, will be discontinued. Theano and JAX will be the computational backends for the future (read more here [4]).", "You can look at PyMC3 as a toolbox. We pick up tools to work on our data and, as a result, shape the posterior distributions of our parameters. For this solution, we are using the GaussianRandomWalk class that PyMC3 provides off-the-shelf. We are also following our equations, defined at the beginning of the article, line by line. We already know that we define priors for each of our parameters and a likelihood for the data in a Bayesian framework. In this case, we also define an adaptative prior, our Gaussian Random Walk latent process. It is called adaptative because we are not supplying parameters directly to it, but parameters distributions. This gives our model the ability to estimate its relevance based on the data.", "We are recovering our parameters well enough, but the sampling was not smooth, which could get us strange-looking results. The first thing to point out is the number of divergences; it immediately shows that something is off. Another important metric is the ess_mean: number of effective samples from sampling 2000 draws for each parameter. For instance, for \u03c3_\u03f5, we only got close to 100 valid samples, which shows that our posterior shape is quite hard to explore. The third thing to check is the r_hat. The metric shows the convergence between multiple chains of the same sampling process. Without defining it explicitly (you can do it in the pm.sample method), PyMC3 will always sample four chains by default. The idea is to compare the within-chain variances with the variance of all chains mixed together [5]. If you achieve convergence, the r_hat should be equal to 1. In real-world applications and with hard posterior shapes, this number should be very close to 1 (not necessarily exactly one). In our case, \u03c3_\u03f5 shows light signs of non-convergence. Finally, the trace plot is another source of information when talking about convergence. A well-mixed trace plot does not show any pattern; it should resemble white noise. Again, \u03c3_\u03f5 does show patterns in its trace plot; in fact, it seems to show some random walk behavior near-zero (we already know how to spot it). This is a typical indication of the posterior's hard shape on that area, making the sampler mix very slowly, i.e., it gets stuck on that area for several iterations. If we would plot an ACF, as we have been doing to analyze our time series, we would clearly see high correlations slowly decreasing across lags for that region.", "What could be producing such problems, you may ask?", "Let\u2019s plot the joint distribution of our parameters to get some more insights.", "They are highly negatively correlated; that is why we are suffering. Sampling high values for one parameter results necessarily in low values for the other and vice versa. Therefore, it is hard for the sampler to decide what will be the best combination.", "Another way of looking at our model is that it is unidentifiable. When we applied the Gaussian Random Walk prior, we defined a standard deviation for that adaptative prior, and, at the same time, we defined a standard deviation for the likelihood. This means that we have two sources of variance for each observation, and we are asking the sampler to decide which one matters more than the other. In a Bayesian framework, we can always supply more informative priors to try to make the life of the sampler easier, but in this case, it is probably not enough.", "To solve our problem, we can add a new parameter to our model while removing one of the highly correlated ones. This new parameter controls the contribution of the two variances that we are dealing with. We are hoping that this small trick reduces the correlation of our parameters. You can see a different application of this trick here [6].", "While the r_hat, mixing and ess_mean improved for \u03c3_\u03f5, we can see that we are still struggling with alpha. Let's check the joint posterior.", "It is much better than the one we saw previously, which indicates that the problem now is mainly our data. This is still not the best model to explain our data, and our sampler is telling us that.", "In the source code of the Gaussian Random Walk class [7] of PyMC3 you can find a comment stating:", "Note that this is mainly a user-friendly wrapper to enable an easier specification of GRW. You are not restricted to use only Normal innovations but can use any distribution: just use theano.tensor.cumsum() to create the random walk behavior", "The comment is reinforcing what we have learned above about what a Random Walk is. For our specific case, there is no clear benefit because we are using Normal innovations. Nonetheless, it opens the door for applications where this is not the case. You can plug in any distribution that explains better the behavior of your time series. Another very commonly used is the Student-t innovations.", "I would not advise this implementation for our problem at hand as it is not the most efficient, nevertheless could be useful in different settings.", "Now, it is time for us to get even more flexibility. As PyMC3 has its built-in class, we can build our own and modify it as we wish. I simplified the code for the GaussianRandomWalk class and defined a new class - the GRW. We can see that we could, for instance, easily swap our Normal.dist and replace it with whatever distribution we want.", "PyMC3 uses Theano to define functions involving array operations and linear algebra. In fact, when we define a PyMC3 model, we implicitly build up a Theano function. Why is this important? Well, sometimes, we need to take advantage of Theano features. This is the case with our current challenge.", "The first one is quite simple: it is Theano shared feature. This is the way to use variables the way we use them in Python. Symbolic variables are not given an explicit value until one is assigned to the execution of a compiled Theano function. Using Theano shared variables, on the other side, assigns explicit values to the variables, and these values are persisted in memory for the lifetime of the execution.", "The Theano function scan is a bit more challenging. In principle, it is nothing more than a loop in Theano. But its usage is not so trivial. See more in their API docs here [8].", "Let\u2019s see some examples to wrap our heads around it. Before that, we just need some insights on how it works:", "We are ready to try it out. Let\u2019s make something up that tests us. It must be something that requires the reuse of outputs from previous iterations. Consider this expression", "This is, in fact, an equation for a state-space model! It is the simplest form of exponential smoothing [9]. We will not cover it, at least for now, but it is not that different from the models that we\u2019ve been working with. It is another opportunity to touch base with important concepts that you will often see flying around in papers or textbooks. Exponential smoothing is a technique for smoothing time series data. Very briefly, it assigns exponentially decreasing weights to past observations. Our smoothing factor here is represented by alpha and is restricted by 0<\\alpha<1. We don\u2019t want to compute the model itself but just use scan to perform the calculations to fit it to toy data.", "We can immediately see that alpha is a non-sequence and a scalar parameter (does not depend on t), while s and y are sequence and vectors. We need to define an output_info, because our function depends on the output of a previous iteration. Finally, we need to define the initial value, which we will denote by variable i. Time to get our hands dirty.", "Just a curiosity about python or any other programming language. Floating-point numbers are represented in computer hardware as base 2 (binary) fractions. And most of the decimal fractions can\u2019t really be represented exactly as binary fractions. You can see the impact of the strange long numbers in our manual calculations (you can read more here [10])", "The best way to avoid this is to use the decimal library.", "Exactly what we got from our scan function. Nice!", "Feel free to play around with the parameters.", "Now that we know how to use scan, we just need to plug in our use case. It is easier than the function that we have set up above since we don't have a smoothing parameter. We are simply performing the cumulative sum of our level over time.", "While this was an interesting exercise and helpful to learn more about how PyMC3 and Theano interact, I would not advise this implementation for our particular problem. It is not scalable (try it yourself and see how much time it takes to sample).", "Comparing our values calculated using both classical and Bayesian approaches, we see that we get close values (not exactly the same). Bayesian computations are a bit slower than when we use statsmodels, but, as we saw, we get much more flexibility. For instance, if you do not have normally distributed innovations, we can change it very easily to any other distribution.", "Let\u2019s start by print the stochastic level and the observed time series.", "The plot looks good, meaning that when the level is allowed to vary over time, we can match the observed values pattern.", "It is time to look at the diagnostics. We will extend a bit the number of lags that the default correlogram uses.", "From the plots that we already know, the correlogram shows a significant correlation at lag 12 and 24 (see the bars outside of the blue shadowed region).", "We need to pay closer attention to the standardized residual plot. First, let\u2019s distinguish two concepts.", "The plot above with the difference between observations and the computed level appears to be composed of only independent random values (or white noise). This is, in fact, a plot of our irregular component, and it is a good thing that it does not show any specific patterns.", "A different thing is our prediction errors \u2014 i.e., our residuals. Remember that our next unobserved level \u03bc_{t+1} depends on our current unobserved level \u03bc_t. If we were plotting one-step-ahead predictions, which is basically computing the forecast of the next point in our series t+1 using the information we have until that moment, we would use the level at time t.", "We can see that our series of predictions are heavily influenced by the previous time step of the original series. Let\u2019s compute the residuals having this in mind. We can compute the residuals and normalize them.", "We can access the residuals from the model_fit. Another output that statsmodels give us is the plot on the upper right. We can easily plot it, and it helps us understand what kind of distribution our residuals follow. We can also plot the Gaussian distribution with parameters \u03bc = 0 and \u03c3= 1.", "The distribution doesn\u2019t exactly follow a normal distribution, but it is also not that far. There are some problems with the tails of the distribution. Let\u2019s analyze the last graph from statsmodel. It is the quantile-quantile plot. It generates an idealized distribution, in our case, the gaussian distribution. The idealized samples are divided into groups or quantiles. Each data point in the sample is paired with a similar member from the idealized distribution at the same cumulative distribution.", "A perfect match to a Gaussian distribution would be shown by the points being always on top of the red line. This is not quite the case, especially for the tails of the distribution. Since we focus much of the analysis of our residuals in terms of normality, we can also perform a statistical test and get a value if it is true or not (not very Bayesian, I know, but I want you to know different approaches).", "Let\u2019s do our hypothesis testing with the Jarque-Bera test for normality,", "The figure above shows the \u03c7\u00b2_(2) distribution and its critical value at 5% (black line). The red line is the value of our data. With our computed value being N > \u03c7\u00b2_(2;0.05), the null hypothesis is rejected, i.e., the residuals are not normally distributed.", "It all makes more sense now. With this small detour, we also understood better what the plot_components function of statsmodels is showing us.", "In our Bayesian setting, we already saw that there were problems with our model. We got that information from the sampling process directly through the convergences checks that we performed. We will skip the analysis that we did above for the sake of brevity, but we should also check some residuals properties in a Bayesian context.", "We will focus on the power available at our hands when we have access to posterior distributions. First, let\u2019s sample from our model.", "Our samples look good, following the data close because of our stochastic level component. We can see that we are not plotting a single line but several lines, which creates an area of fitting. This area is our expression of uncertainty from our estimated parameters. We can do even better, plotting the mean, median and credible intervals.", "Just a word on the difference between credible intervals and confidence intervals. The first is the Bayesian version, which results from estimating a probability distribution for our parameters instead of a single point (it comes from the fact that in a Bayesian framework, the parameters are treated as random variables). It summarizes the uncertainty, and we can interpret it as the interval that includes 95% of the probability distribution area (we will see more interesting things that we can do with it). The latter is the frequentist approach. It consists of the range of values that includes the true value of the parameter 95% of the times that we repeat the experiment. This means that 5% of the experiments could, in theory, yield complete nonsense values, for instance, negative values for our observations of UK drivers KSI (read more here [11]).", "Finally, just a recap of the idea of reparameterization that we did above. We had two variances contributing to a single observation, which created a highly negative correlation between them. To reduce this correlation, we replaced one of the parameters with a new one that controls the effect that each variance contributes to the observations. This resulted in much less correlation between our new parameters, even though it respects our first mathematical formulation of the problem (proven by the fact that we got identical results).", "This article was a long one. I feel that we are starting to know more about the tools at hand and use them to our advantage. The local level model is still not enough to explain our data, but it was another step closer. Like a sampler, we explore the space and learn how it is shaped in the process. Stay tuned for the next article; we will start adding more components to our state!", "[1] J. Commandeur, S. Koopman, An Introduction to State Space Time Series Analysis (2007), Oxford University Press", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Head of Data @ Marley Spoon | Ph.D. Researcher AI @ LIACC | Coordinator DS Masters @ NDS | CoFounder & ex-CEO @ HUUB"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F34343911c7d2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----34343911c7d2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34343911c7d2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@luisroque?source=post_page-----34343911c7d2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@luisroque?source=post_page-----34343911c7d2--------------------------------", "anchor_text": "Lu\u00eds Roque"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2195f049db86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=post_page-2195f049db86----34343911c7d2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34343911c7d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34343911c7d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://towardsdatascience.com/the-first-step-in-bayesian-time-series-linear-regression-89a64b826a7e", "anchor_text": "The First Step in Bayesian Time Series \u2014 Linear Regression"}, {"url": "https://towardsdatascience.com/first-bayesian-state-space-model-with-pymc3-51cbb06ef8bd", "anchor_text": "First Bayesian State-Space Model with PyMC3"}, {"url": "https://github.com/luisroque/bayesian_time_series", "anchor_text": "GitHub"}, {"url": "https://en.wikipedia.org/wiki/Random_walk", "anchor_text": "[2]"}, {"url": "https://theano-pymc.readthedocs.io/en/latest/", "anchor_text": "[3]"}, {"url": "https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b", "anchor_text": "[4]"}, {"url": "http://www.mcmchandbook.net/HandbookChapter6.pdf", "anchor_text": "[5]"}, {"url": "https://docs.pymc.io/notebooks/GP-smoothing.html", "anchor_text": "[6]"}, {"url": "https://github.com/pymc-devs/pymc3/blob/4fd56fdeccf4550953b896f9af41c8b9b65b9ed8/pymc3/distributions/timeseries.py#L185", "anchor_text": "[7]"}, {"url": "https://theano-pymc.readthedocs.io/en/latest/library/scan.html?highlight=scan", "anchor_text": "[8]"}, {"url": "https://en.wikipedia.org/wiki/Exponential_smoothing", "anchor_text": "[9]"}, {"url": "https://docs.python.org/3/tutorial/floatingpoint.html", "anchor_text": "[10]"}, {"url": "https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval", "anchor_text": "[11]"}, {"url": "https://www.linkedin.com/in/luisbrasroque/", "anchor_text": "LinkedIn"}, {"url": "https://en.wikipedia.org/wiki/Random_walk", "anchor_text": "https://en.wikipedia.org/wiki/Random_walk"}, {"url": "https://theano-pymc.readthedocs.io/en/latest/", "anchor_text": "https://theano-pymc.readthedocs.io/en/latest/"}, {"url": "https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b", "anchor_text": "https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b"}, {"url": "http://www.mcmchandbook.net/HandbookChapter6.pdf", "anchor_text": "http://www.mcmchandbook.net/HandbookChapter6.pdf"}, {"url": "https://docs.pymc.io/notebooks/GP-smoothing.html", "anchor_text": "https://docs.pymc.io/notebooks/GP-smoothing.html"}, {"url": "https://github.com/pymc-devs/pymc3/blob/4fd56fdeccf4550953b896f9af41c8b9b65b9ed8/pymc3/distributions/timeseries.py#L185", "anchor_text": "https://github.com/pymc-devs/pymc3/blob/4fd56fdeccf4550953b896f9af41c8b9b65b9ed8/pymc3/distributions/timeseries.py#L185"}, {"url": "https://theano-pymc.readthedocs.io/en/latest/library/scan.html?highlight=scan", "anchor_text": "https://theano-pymc.readthedocs.io/en/latest/library/scan.html?highlight=scan"}, {"url": "https://en.wikipedia.org/wiki/Exponential_smoothing", "anchor_text": "https://en.wikipedia.org/wiki/Exponential_smoothing"}, {"url": "https://docs.python.org/3/tutorial/floatingpoint.html", "anchor_text": "https://docs.python.org/3/tutorial/floatingpoint.html"}, {"url": "https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval)", "anchor_text": "https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval)"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----34343911c7d2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/bayesian-statistics?source=post_page-----34343911c7d2---------------bayesian_statistics-----------------", "anchor_text": "Bayesian Statistics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----34343911c7d2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----34343911c7d2---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----34343911c7d2---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34343911c7d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=-----34343911c7d2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34343911c7d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=-----34343911c7d2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34343911c7d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34343911c7d2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F34343911c7d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----34343911c7d2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----34343911c7d2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----34343911c7d2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----34343911c7d2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----34343911c7d2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----34343911c7d2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----34343911c7d2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----34343911c7d2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----34343911c7d2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@luisroque?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@luisroque?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Lu\u00eds Roque"}, {"url": "https://medium.com/@luisroque/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "902 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2195f049db86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=post_page-2195f049db86--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd8e0bc4b610d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-levels-of-difficulty-bayesian-gaussian-random-walk-with-pymc3-and-theano-34343911c7d2&newsletterV3=2195f049db86&newsletterV3Id=d8e0bc4b610d&user=Lu%C3%ADs+Roque&userId=2195f049db86&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}