{"url": "https://towardsdatascience.com/how-i-won-top-five-in-a-deep-learning-competition-753c788cade1", "time": 1683005878.586632, "path": "towardsdatascience.com/how-i-won-top-five-in-a-deep-learning-competition-753c788cade1/", "webpage": {"metadata": {"title": "How I Won Top Five in a Deep Learning Competition | by Damian Boh | Towards Data Science", "h1": "How I Won Top Five in a Deep Learning Competition", "description": "All code in this article is on my GitHub Repository. The datasets are already in the appropriate folders and the code is ready to run (after installing PyTorch). Last year, I participated in a deep\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub Repository", "paragraph_index": 0}, {"url": "https://www.crowdanalytix.com/community", "anchor_text": "CrowdANALYTIX", "paragraph_index": 1}, {"url": "https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/", "anchor_text": "transfer learning", "paragraph_index": 1}, {"url": "https://pytorch.org/get-started/locally/", "anchor_text": "PyTorch framework", "paragraph_index": 8}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub repository", "paragraph_index": 10}, {"url": "https://storage.googleapis.com/cax-contests/propensity-modeling/CAX_Characters_Train.zip", "anchor_text": "CrowdANALYTIX", "paragraph_index": 15}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub repo", "paragraph_index": 15}, {"url": "https://pytorch.org/docs/stable/torchvision/transforms.html", "anchor_text": "transforms package", "paragraph_index": 22}, {"url": "https://pytorch.org/docs/stable/torchvision/models.html", "anchor_text": "pre-trained models in PyTorch", "paragraph_index": 24}, {"url": "https://medium.com/udacity-pytorch-challengers/understanding-loss-function-and-error-in-neural-network-676a81cc776c", "anchor_text": "loss function", "paragraph_index": 30}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "back propagation", "paragraph_index": 30}, {"url": "https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/", "anchor_text": "convolutional neural networks (CNNs)", "paragraph_index": 31}, {"url": "http://www.image-net.org/", "anchor_text": "millions of images on ImageNet", "paragraph_index": 31}, {"url": "https://pytorch.org/docs/stable/torchvision/models.html", "anchor_text": "here.", "paragraph_index": 32}, {"url": "https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8", "anchor_text": "here", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac", "anchor_text": "here", "paragraph_index": 33}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images/blob/master/model_architecture.pdf", "anchor_text": "pdf file in my GitHub repository", "paragraph_index": 39}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images/blob/master/model_architecture.pdf", "anchor_text": "pdf file in my GitHub repository", "paragraph_index": 43}, {"url": "https://en.wikipedia.org/wiki/Dropout_(neural_networks)", "anchor_text": "dropout", "paragraph_index": 47}, {"url": "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/", "anchor_text": "ReLU", "paragraph_index": 47}, {"url": "https://colab.research.google.com/notebooks/welcome.ipynb", "anchor_text": "Google Colab", "paragraph_index": 49}, {"url": "https://colab.research.google.com/notebooks/welcome.ipynb", "anchor_text": "Google Colab Notebooks", "paragraph_index": 50}, {"url": "https://algorithmia.com/blog/introduction-to-optimizers", "anchor_text": "Optimizers", "paragraph_index": 51}, {"url": "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c", "anchor_text": "\u2018Adam\u2019 optimizer", "paragraph_index": 51}, {"url": "https://ruder.io/optimizing-gradient-descent/index.html", "anchor_text": "Stochastic Gradient Descent (SGD)", "paragraph_index": 51}, {"url": "https://en.wikipedia.org/wiki/Learning_rate", "anchor_text": "learning rate (LR)", "paragraph_index": 51}, {"url": "https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/", "anchor_text": "here", "paragraph_index": 51}, {"url": "https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html", "anchor_text": "cross entropy loss", "paragraph_index": 52}, {"url": "https://www.crowdanalytix.com/contests/identify-characters-from-product-images", "anchor_text": "rules", "paragraph_index": 63}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GiHub repository", "paragraph_index": 69}, {"url": "https://www.dataquest.io/blog/web-scraping-beautifulsoup/", "anchor_text": "this page", "paragraph_index": 69}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub Repository", "paragraph_index": 70}, {"url": "https://damianboh.github.io/", "anchor_text": "https://damianboh.github.io/", "paragraph_index": 72}], "all_paragraphs": ["All code in this article is on my GitHub Repository. The datasets are already in the appropriate folders and the code is ready to run (after installing PyTorch).", "Last year, I participated in a deep learning competition organized by CrowdANALYTIX and emerged in 4th place. I did this by using transfer learning in PyTorch. While many readers may already be familiar with this technique, I will share more of what I believe is crucial for the model\u2019s success. In all honesty, I\u2019m no expert in deep learning, I just depend on a lot of trial-and-error (and intuition).", "For exact details and rules of the challenge and CrowdANALYTIX, please visit the links below.", "The CrowdANALYTIX Community: where data experts collaborate & compete to build & optimize AI, ML, NLP and Deep Learning algorithms", "The dataset from CrowdANALYTIX consists of images of products such as T-shirts, bags, keychains, mobile covers etc. associated with 42 different characters. These characters are wide ranging \u2014 from cartoon characters like Angry Birds and Pikachu to anime characters like Naruto and Kakashi and even movie characters like Darth Vader and Harry Potter. And there\u2019s John Cena too (lol). The task is to classify the images according to these characters.", "The data distribution across training and test data sets are as follows:", "Some examples in the training set (Angry Birds, Charmander, Darth Vader and Minions) are given below.", "The task is not a very straightforward one, as shown by the many creative ways that designers have taken to infuse these characters onto the products. Can you, a human being, identify the character printed on the pants on the left?", "These are the libraries I used. The PyTorch framework was adopted as I am most familiar with it for deep learning, and I feel it allows for more flexibility compared to Keras, especially when I am adjusting a lot of parameters via trial-and-error.", "More on how to install PyTorch is given below.", "Feel free to navigate through my GitHub repository to take a look at the folder structure. You need the train, test and valid(ation) folder. In each of these folders, you have to further classify the images using their labels as folder names (shown in the earlier screenshot) and PyTorch will automatically assign their labels. I wrote a simple program to randomly pick about 20% of the images from each category and transfer them to the validation folder.", "Note: The images in the test folder are not labeled of course. However, PyTorch needs the images in test folder to be further placed into another folder. Failure to do so will result in PyTorch saying that it cannot find a folder within the test folder. I\u2019ve addressed this by creating a \u2018test2\u2019 folder inside the test folder and dumped all my test images there.", "Do not worry about the \u2018expanded\u2019 folder name. I will elaborate on that towards the end.", "Data augmentation is more of an art than a science. If you do it wrong, you hurt the accuracy. During training, we randomly crop, change the color, brightness, contrast, rotate, or flip the images so that for each pass through the dataset, the neural network sees different variations of the same image. These variations hence augment and \u2018add more\u2019 to the dataset. This helps in allowing the model to generalize to different variations of images. Importantly, there is no one-size-fit-all approach to data augmentation.", "Crucial Point: Some may believe that the more types of data augmentation we include, the better the model. This is not true and varies with context.", "It is hence crucial to identify which aspects to augment and which aspects not to augment, by carefully looking through the datasets (available on CrowdANALYTIX and my GitHub repo).", "Generating random images of different hue to augment the train data should negatively affect the accuracy in this case and this was confirmed. This is not surprising and confirms that colour is an important feature (e.g. there are no blue charmanders etc.) so this method of augmentation fails.", "Randomly flipping images horizontally to augment the train data also negatively affected the accuracy. This is probably because words like \u201cPokemon\u201d, \u201cHan Solo\u201d etc. in the train images themselves become flipped when they of course shouldn\u2019t be.", "This method of augmentation also negatively affected the accuracy no matter how many degrees of rotation was set. Looking at train and test set, we can see that almost all the images are upright. Rotating the train images was hence not necessary and even decreased the accuracy.", "This method of augmentation also was undesirable as the main feature in the image may not be cropped during preprocessing (for example in many images such as T-shirts, we may be cropping random parts like sleeves and collars, that do not include the character itself, making this training image useless).", "This was harder to tell intuitively by observing the images, but this method of augmentation did not increase the accuracy.", "As seen in the images, the products are taken under different lighting conditions and have different shades of brightness (although colour is the same, some images are clearly darker then others). Randomly generating images of different brightness (capped at a factor of 0.05) allowed the model to generalize to different lighting conditions and increased the accuracy of the best model to above 92%.", "The final part of code relevant in augmenting train data is shown below, it makes use of the transforms package in PyTorch. We realize that only augmentation of brightness was needed! I hope this serves as useful guidance in your future data augmentation approaches.", "If you are unsure of what to augment in the above, just go for trial-and-error!", "Apart from augmentation, a fixed (not random) transformation must be applied to all images as the pre-trained models in PyTorch expects images of dimensions 3 x 224 x 224 (3 is RGB pixel, 224 is width and height). We apply a resize and center crop to achieve this standard size.", "The full code for transformations is attached below. Note that we do not augment (apply random brightness transformations to) the validation dataset. This is to ensure fairness in using the exact same images when validating our model.", "The code (below) of loading the train and validation datasets from our folder is almost entirely lifted from documentation, do not worry too much about it. After loading the datasets, the program does some calculations to sample the train and validation datasets in batches. A common batch size of 50 is used.", "CNNs are deep-learning networks that are highly successful in image recognition tasks. An excellent introduction to CNN is given below if you are new to it.", "To summarize, a convolutional neural network consists of convolutional layers (refer to article above) through which the image is passed first. In trained CNN models, the first few layers will pick up the more low level features of images such as edges and strokes. The next few layers then pick up higher level features such as shapes like circles or combinations of strokes. As we progress further, the last few convolutional layers will pick up even higher level features such as the head of a dog. These features in the last few layers become more and more specific to what the network is trying to classify. In the middle of the convolutional layers are pooling layers to downsample the data or dropout layers that reduces over-fitting, as well as other layers you can read more about in the article above.", "The output of the convolutional layer will pass through a final network of fully connected layers (sometimes it is just one layer) which maps it to the exact number of outputs corresponding to the desired categories of images that we want to classify. For this reason, this network is also known as the classifier. For example, if the output of the last convolutional layer is 2048 and we want to train the network to differentiate between dogs, cats and hamsters, the input of the fully-connected layers from the convolutional layers will be 2048 and the output will be 3 (corresponding to the 3 animals mentioned).", "A trained CNN can pick up features and classify images by adjusting the weights in each of the layers. These weights are just numbers that are responsible for calculations performed in each layer. Each time a batch of images is passed through the model, the error between the model\u2019s prediction and the actual category of image is calculated by the loss function. The weights are then updated (by back propagation through the model) to minimize the loss function so the model becomes more accurate in classifying images \u2014 because it uses these new weights for calculations the next time images are passed through it.", "My transfer learning approach involves applying convolutional neural networks (CNNs) with weights that are already pre-trained on millions of images on ImageNet. The idea is that although I only have 6000+ images to train on, I can make use of a CNN model that has learned from millions of images before making some modifications to it to suit my data. You can read more about transfer learning below.", "The list of CNN models from the PyTorch website and their performance on the ImageNet dataset is available here.", "Do a preliminary run through each of the models first. After some trial-and-error, unsurprisingly \u2018resnext101_32x8d\u2019 performed the best and it has the lowest error on ImageNet (this may not always be the case when applying deep learning in other problems, hence the need for trial-and-error). ResNeXt is a model by UC San Diego and Facebook AI Research (FAIR), built on ResNet. I shall not dive into the architecture of this network in detail, you can read more on ResNet here and on ResNeXt here.", "By convention, the first few layers of the model through which the image is passed are also known as the bottom layers, while the last few layers are the top layers.", "Recall that the bottom layers of the model pick up more general and low level features that are not specific to our exact task, but general to all image recognition tasks. Hence, the trick is to freeze (not train the weights of) these bottom layers while training the network on our characters dataset. This is because the millions of images in ImageNet would have trained these bottom layers well enough to pick up things like strokes and edges already.", "At the same time, we want to unfreeze the top layers so their weights can be trained with our own dataset. As the top layers pick up high level features specific to the task, we want these layers to adapt to our specific task. For example, instead of having these features pick up tails of aeroplanes, we want it to pick up things like the head of Pikachu or the flaming \ud83d\udd25 tail of Charmander. These are more relevant to our current task.", "Many tutorials on transfer learning will tell you to unfreeze only the fully-connected layers. This is probably because it is a lot more computationally intensive to train (update the weights of) some convolutional layers as well. The accuracy, however, can be improved a lot more by training some convolutional layers so do take note!", "First, we select the model and set pretrained to True. If this is set to False the model will initialize with random (not trained) weights. If this is the first time you select the model, PyTorch will automatically download it.", "The \u2018model\u2019 command prints out the full architecture of the model, which is too long to show here. You can view it in this pdf file in my GitHub repository.", "There\u2019s no way to tell how many of the top layers should be frozen other than\u2026you guessed it\u2026trial and error.", "I have frozen the groups of layers (from conv1 to layer2) in the code below by setting the requires_grad parameter to False as we do not require the gradient during back propagation to update their weights while training.", "Within model.layer3, I have frozen the 1st to 18th layer as shown below. Just to clarify, model.layer3 is actually a group of layers named \u2018layer3\u2019. It is just the PyTorch way of representing these layers of ResNeXt. Freezing these layers gave the best model accuracy via trial-and-error.", "The remaining layers in model.layer3 as well as all other remaining layer (including the fully-connected layer) are not frozen and hence trained. If you are unsure of what I meant, take a look at the full architecture of ResNeXt 101 in PyTorch in this pdf file in my GitHub repository, the layers highlighted in layers are the ones trained.", "Scrolling through to the last few layers of the model we see the following:", "Pay attention to the last line, which shows the fully connected (fc) layer covered earlier. Recall that it maps the output of the convolutional layers to the number of image classes that the model is trying to classify. The input (in_features) is 2048, we can, therefore, interpret that the output of the convolutional/pooling layer above it is 2048. The output (out_features) of this fc layer is 1000, corresponding to the 1000 classes in the ImageNet dataset.", "The code below modifies the output of the layer to 42, corresponding to the 42 different characters that we have.", "Also, I have found that I only needed a single fully-connected layer for best results, after trying several fanciful layers with dropout and ReLU.", "This was undoubtedly the most time-consuming process. I trained each model with more and more layers unfrozen and see how the accuracy changes. Sometimes the accuracy drops after unfreezing some layers, but rise again when I unfreeze more, sometimes, the reverse happens. I admit that I am unable to build upon any intuition to explain why that is the case (enlighten me in the comments if you know please!). I spent weeks on this part.", "Run several Google Colab Sessions at once during trial-and error.", "However, the process was still sped up by running my code on several Google Colab Notebooks at once. Colab notebooks execute code on Google\u2019s cloud servers, meaning you can leverage the power of Google hardware, including GPUs and TPUs, regardless of the power of your machine. Even though I have a computer armed with a GPU, I need several sessions of Google Colab to test out multiple models simultaneously. Be careful not to exceed the RAM limit as each session takes up some RAM.", "Optimizers are algorithms used to update the weights of the neural network in order to minimize the loss function and increase the accuracy of a model. The \u2018Adam\u2019 optimizer was chosen over the other popular algorithm, \u2018Stochastic Gradient Descent (SGD)\u2019, as SGD was training way too slowly without any significant increase in accuracy. A good learning rate (LR), aka step size was chosen by trial and error. A step size too large may result in the algorithm missing the minimum point and \u2018crossing over\u2019 it, while a step size too small may result in the algorithm taking very long to train or getting stuck in the local minimum instead of reaching the true global minimum. Read more here. LR of 0.00005 proved to be a good starting rate for this.", "The most common loss function for such a task, the cross entropy loss, was used. Notice how, in the code below, I have initialized three separate optimizers for three different parts of the different neural network.", "Set higher weights for the fully connected (FC) layer for the first few epochs.", "By setting higher weights for the FC layer, we are training the FC layer much faster than the convolutional layers. The FC layer is initialized with totally random weights while the convolutional layers already have weights trained with the ImageNet dataset. You want to quickly and roughly compute the FC layer weights that map the convolutional layers\u2019 output to the image categories before the convolutional layers are fine-tuned. Some people may not train the convolutional layers altogether for the first couple of epochs because they argue that the training on convolutional layers is \u2018wasted\u2019 when the FC layers are still not doing their job to map the convolutional layers\u2019 output to the image categories. Note that you must still train the convolutional layers eventually after these couple of epochs as the accuracy drastically increases in doing so.", "I\u2019ve chosen the former approach as I found it to be more effective in this case. Notice I\u2019ve set a higher learning rate (LR parameter) for the FC layer in its optimizer as shown below.", "The code in the next section below trains 4 epochs of the model and output the results in each epoch, it is almost lifted entirely from the documentation. Note that you have to set model.train() for the training phase and model.eval() for the evaluation phase.", "The evaluation during each epoch is done on the validation dataset using the folders in the validation folder mentioned earlier. The validation set serves to evaluate the model on a dataset it is not trained on so that we know when the model overfits on the training set. Preventing overfitting is important as we want the model to generalize well to unseen data and not just on the training set. The accuracy of the model on the training set will always increase, but if the accuracy on the unseen validation set starts to decrease, we know the model is overfitting. Hence we should stop at the point where the validation accuracy starts to decrease.", "Also note that in the code, we have to manually set the gradients of the optimizers to zero using optimizer.zero_grad() when training on each fresh batch of data and to update the weights using optimizer.step(). The code for evaluation is similar except that there is no optimizer involved (we are not adjusting the weights of the model on validation images as no training is involved).", "Lower the learning rate after a few epochs.", "A good strategy would be to lower the learning rate after a few epochs (on epoch means one run of the model through all the images) as we are nearing the minimum. We do not want to \u2018cross over\u2019 and miss this minimum point. After the above 4 epochs, I set the learning rate to 0.00001 before training for another 4 epoch, then 0.000001 for the final 4 epoch before the validation accuracy starts to decrease. Refer to the \u2018final code.ipynb\u2019 notebook in my GitHub repository to see the flow.", "Note that a lot of time was spent fine-tuning the learning rates and number of epochs before changing them. You have to be patient (and open several Google Colab sessions each running on a different parameter)!", "Don\u2019t forget this! Transfer all the validation images back to the training folder before training the model for a final round before submission! I have to put a dummy image into the validation folder or I would encounter an error when training.", "The rules of the challenge state that: Being a real world application problem, we want the solvers to use image data/features like color, shape, SIFT etc. or deep learning approaches for image modeling. There is no limit on hardware or GPU usage, augmentation, adding additional train data etc.", "This is no surprise because when solving such a problem in the real world, we do always build on our own training dataset to make it even richer.", "Simply Google for more images to supplement your training data!", "After trying many alternatives, I have found that searching on Google using the categories of the image (i.e. the names Pikachu, Charmander etc.) followed by \u2018shirt doll\u2019 gave the best results! Trust me, I\u2019ve tried adding many words like \u2018product\u2019, \u2018mug\u2019, \u2018bag\u2019 etc. and some of them return nonsense.", "This was rather crucial to the success of the model. At some point of time when training my model, I realized I should have expanded my training data and had to restart the whole process again. This step should be done before the training of the model but I wanted to give an overall view of the whole model before elaborating on this separate part. In my GitHub repository, the \u2018expand_train_set_character\u2019 folder consists of the images I fetched from Google, while the \u2018train_expanded_character\u2019 folder consists of both the training data from CrowdANALYTIX as well as Google.", "A couple of difficulties were encountered during this process:", "The full code of the script to achieve this is given below, and also in the \u2018scrap image from google.ipynb\u2019 file in my GiHub repository. Basically it lists all the folder names in the train directory, which are the image categories, before Googling each term + \u2018shirt doll\u2019 and parsing the results, it then sorts the pictures into the \u2018expand_train_set_character\u2019 folder. Visit this page for a tutorial on how to use BeautifulSoup to scrape data from the web.", "This is one of my first few attempts at a deep learning competition. I am glad to have eventually emerged fourth place overall, with an accuracy of 92.294% as shown in the leaderboard at the start of the article. I hope that this article is useful for you and that you have picked up some tips and tricks to apply on future deep learning projects! Once again, all code in this article is on my GitHub Repository. The datasets are already in the appropriate folders and the code is ready to run (after installing PyTorch).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Developer and ML engineer with a theoretical physics background, keen interest in building web/mobile apps, ML and IoT. https://damianboh.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F753c788cade1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----753c788cade1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----753c788cade1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@bohmian?source=post_page-----753c788cade1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bohmian?source=post_page-----753c788cade1--------------------------------", "anchor_text": "Damian Boh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa12faceacf88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&user=Damian+Boh&userId=a12faceacf88&source=post_page-a12faceacf88----753c788cade1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F753c788cade1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F753c788cade1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub Repository"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "bck1990/Identify-Characters-from-Product-ImagesThis is a contest submission for CrowdANALYTIX (awarded 4th place overall)\u2026github.com"}, {"url": "https://www.crowdanalytix.com/community", "anchor_text": "CrowdANALYTIX"}, {"url": "https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/", "anchor_text": "transfer learning"}, {"url": "https://www.crowdanalytix.com/contests/identify-characters-from-product-images", "anchor_text": "competition page"}, {"url": "https://www.crowdanalytix.com/contests/identify-characters-from-product-images", "anchor_text": "Identify Characters from Product ImagesIdentify the characters from product image from a list of 42 possible valueswww.crowdanalytix.com"}, {"url": "https://storage.googleapis.com/cax-contests/propensity-modeling/CAX_Characters_Train.zip", "anchor_text": "here"}, {"url": "https://storage.googleapis.com/cax-contests/propensity-modeling/CAX_Characters_Test.zip", "anchor_text": "here"}, {"url": "https://pytorch.org/get-started/locally/", "anchor_text": "PyTorch framework"}, {"url": "https://pytorch.org/get-started/locally/", "anchor_text": "PyTorchSelect your preferences and run the install command. Stable represents the most currently tested and supported version\u2026pytorch.org"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub repository"}, {"url": "https://storage.googleapis.com/cax-contests/propensity-modeling/CAX_Characters_Train.zip", "anchor_text": "CrowdANALYTIX"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub repo"}, {"url": "https://pytorch.org/docs/stable/torchvision/transforms.html", "anchor_text": "transforms package"}, {"url": "https://pytorch.org/docs/stable/torchvision/models.html", "anchor_text": "pre-trained models in PyTorch"}, {"url": "https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/", "anchor_text": "A Beginner\u2019s Guide To Understanding Convolutional Neural NetworksConvolutional neural networks. Sounds like a weird combination of biology and math with a little CS sprinkled in, but\u2026adeshpande3.github.io"}, {"url": "https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/", "anchor_text": "above article"}, {"url": "https://medium.com/udacity-pytorch-challengers/understanding-loss-function-and-error-in-neural-network-676a81cc776c", "anchor_text": "loss function"}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "back propagation"}, {"url": "https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/", "anchor_text": "convolutional neural networks (CNNs)"}, {"url": "http://www.image-net.org/", "anchor_text": "millions of images on ImageNet"}, {"url": "https://ruder.io/transfer-learning/", "anchor_text": "Transfer Learning - Machine Learning's Next FrontierDeep learning models excel at learning from a large number of labeled examples, but typically do not generalize to\u2026ruder.io"}, {"url": "https://pytorch.org/docs/stable/torchvision/models.html", "anchor_text": "here."}, {"url": "https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac", "anchor_text": "here"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images/blob/master/model_architecture.pdf", "anchor_text": "pdf file in my GitHub repository"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images/blob/master/model_architecture.pdf", "anchor_text": "pdf file in my GitHub repository"}, {"url": "https://en.wikipedia.org/wiki/Dropout_(neural_networks)", "anchor_text": "dropout"}, {"url": "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/", "anchor_text": "ReLU"}, {"url": "https://colab.research.google.com/notebooks/welcome.ipynb", "anchor_text": "Google Colab"}, {"url": "https://colab.research.google.com/notebooks/welcome.ipynb", "anchor_text": "Google Colab Notebooks"}, {"url": "https://colab.research.google.com/notebooks/welcome.ipynb", "anchor_text": "Google ColaboratoryExample of Google Colab Notebookcolab.research.google.com"}, {"url": "https://algorithmia.com/blog/introduction-to-optimizers", "anchor_text": "Optimizers"}, {"url": "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c", "anchor_text": "\u2018Adam\u2019 optimizer"}, {"url": "https://ruder.io/optimizing-gradient-descent/index.html", "anchor_text": "Stochastic Gradient Descent (SGD)"}, {"url": "https://en.wikipedia.org/wiki/Learning_rate", "anchor_text": "learning rate (LR)"}, {"url": "https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/", "anchor_text": "here"}, {"url": "https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html", "anchor_text": "cross entropy loss"}, {"url": "https://www.crowdanalytix.com/contests/identify-characters-from-product-images", "anchor_text": "rules"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GiHub repository"}, {"url": "https://www.dataquest.io/blog/web-scraping-beautifulsoup/", "anchor_text": "this page"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "GitHub Repository"}, {"url": "https://github.com/bck1990/Identify-Characters-from-Product-Images", "anchor_text": "bck1990/Identify-Characters-from-Product-ImagesThis is a contest submission for CrowdANALYTIX (awarded 4th place overall)\u2026github.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----753c788cade1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----753c788cade1---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----753c788cade1---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----753c788cade1---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/image-classification?source=post_page-----753c788cade1---------------image_classification-----------------", "anchor_text": "Image Classification"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F753c788cade1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&user=Damian+Boh&userId=a12faceacf88&source=-----753c788cade1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F753c788cade1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&user=Damian+Boh&userId=a12faceacf88&source=-----753c788cade1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F753c788cade1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----753c788cade1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F753c788cade1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----753c788cade1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----753c788cade1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----753c788cade1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----753c788cade1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----753c788cade1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----753c788cade1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----753c788cade1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----753c788cade1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----753c788cade1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bohmian?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bohmian?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Damian Boh"}, {"url": "https://medium.com/@bohmian/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "https://damianboh.github.io/", "anchor_text": "https://damianboh.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa12faceacf88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&user=Damian+Boh&userId=a12faceacf88&source=post_page-a12faceacf88--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff2f8afd29374&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-won-top-five-in-a-deep-learning-competition-753c788cade1&newsletterV3=a12faceacf88&newsletterV3Id=f2f8afd29374&user=Damian+Boh&userId=a12faceacf88&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}