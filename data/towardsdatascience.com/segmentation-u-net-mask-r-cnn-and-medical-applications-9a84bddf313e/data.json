{"url": "https://towardsdatascience.com/segmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e", "time": 1683003161.638907, "path": "towardsdatascience.com/segmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e/", "webpage": {"metadata": {"title": "Intro to Segmentation. U-Net, Mask R-CNN, and Medical\u2026 | by Rachel Draelos, MD, PhD | Towards Data Science", "h1": "Intro to Segmentation", "description": "Segmentation has numerous applications in medical imaging (locating tumors, measuring tissue volumes, studying anatomy, planning surgery, etc.), self-driving cars (localizing pedestrians, other\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Image_segmentation#Applications", "anchor_text": "numerous applications", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1505.04597.pdf", "anchor_text": "Ronneberger et al. 2015", "paragraph_index": 6}, {"url": "https://github.com/ShawnBIT/UNet-family", "anchor_text": "in this repository", "paragraph_index": 6}, {"url": "https://glassboxmedicine.com/2019/05/26/classification-sigmoid-vs-softmax/", "anchor_text": "this post", "paragraph_index": 19}, {"url": "https://glassboxmedicine.com/2019/12/07/connections-log-likelihood-cross-entropy-kl-divergence-logistic-regression-and-neural-networks/", "anchor_text": "cross-entropy loss", "paragraph_index": 21}, {"url": "https://www.quantib.com/blog/image-augmentation-how-to-overcome-small-radiology-datasets", "anchor_text": "Quantib blog", "paragraph_index": 25}, {"url": "https://arxiv.org/abs/1703.06870", "anchor_text": "Mask R-CNN", "paragraph_index": 27}, {"url": "https://arxiv.org/abs/1506.01497", "anchor_text": "Faster R-CNN", "paragraph_index": 27}, {"url": "http://cocodataset.org/#download", "anchor_text": "here", "paragraph_index": 36}, {"url": "https://arxiv.org/pdf/1703.06870.pdf", "anchor_text": "He et al. 2018 Mask R-CNN", "paragraph_index": 39}], "all_paragraphs": ["Segmentation has numerous applications in medical imaging (locating tumors, measuring tissue volumes, studying anatomy, planning surgery, etc.), self-driving cars (localizing pedestrians, other vehicles, brake lights, etc.), satellite image interpretation (buildings, roads, forests, crops), and more.", "This post will introduce the segmentation task. In the first section, we will discuss the difference between semantic segmentation and instance segmentation. Next, we will delve into the U-Net architecture for semantic segmentation, and overview the Mask R-CNN architecture for instance segmentation. The final section includes many example medical image segmentation applications and video segmentation applications.", "The figure above illustrates four common image tasks:", "Here is another illustration of the difference between semantic segmentation and instance segmentation, showing how in semantic segmentation all \u201cchair\u201d pixels have the same label, while in instance segmentation the model has identified specific chairs:", "Here is an application of both semantic segmentation and instance segmentation to algae images:", "The following images show model predictions for instance segmentation:", "The U-Net paper (available here: Ronneberger et al. 2015) introduces a semantic segmentation model architecture that has become very popular, with over 10,000 citations (fifty different follow-up papers are listed in this repository). It was initially presented in the context of biomedical images but has since been applied to natural images as well.", "The basic idea of the U-Net is to perform the following task:", "Given an input image, in this case, a grayscale microscopy image of cells, the U-Net model produces a binary mask of 1s and 0s, where 1 indicates a cell and 0 indicates background (including borders between cells). Note that this is a semantic segmentation task because all cells receive the same label of \u201ccell\u201d (i.e. we don\u2019t have different labels to distinguish between different individual cells, as we would for instance segmentation.)", "This schematic shows the setup of training a U-Net model:", "Before the model is fully trained, for a given input image it will produce a binary segmentation mask that has problems, e.g. the \u201cpredicted binary segmentation mask\u201d shown in the figure above, where some cells are missing or have incorrect borders. The U-Net loss function compares the predicted mask with the ground-truth mask, to enable parameter updates that will allow the model to perform a better segmentation on the next training example.", "From this figure, the name \u201cU-Net\u201d is apparent, as the architecture diagram shows a U shape. The basic idea of the U-Net is to first obtain a lower-dimensional representation of the image through a traditional convolutional neural network, and then upsample that low-dimensional representation to produce the final output segmentation map.", "It\u2019s helpful to use the architecture diagram key provided in the lower right-hand corner, which explains what operations each arrow type corresponds to:", "The U-Net consists of a \u201ccontracting path\u201d and an \u201cexpansive path\u201d:", "The \u201ccontracting path\u201d is a traditional CNN, which produces the low-dimensional representation. The \u201cexpansive path\u201d up-samples the representation to produce the final output segmentation map. Gray arrows represent copying operations, in which high-resolution feature maps from the \u201ccontracting path\u201d are copied over and concatenated to feature maps in the \u201cexpansive path\u201d to make it easier for the network to learn a high-resolution segmentation.", "The U-Net does not have any fully connected layers, meaning the U-Net is a fully convolutional network.", "At the last layer of the U-Net a 1 x 1 convolution is applied to map each 64-channel feature vector to the desired number of classes, which in the paper is considered to be two classes (cell/background). If you want to use the U-Net for semantic segmentation with several classes, e.g. 6 classes (dog, cat, bird, turtle, cow, background) then the 64-channel feature vector can be mapped to 6 classes (6 channels) instead.", "Here is a close-up from Figure 1 showing the very last part of the \u201cexpansive path\u201d where a 64-channel feature vector is produced by a [conv 3\u00d73, ReLU] operation, and is finally mapped to a 2-channel feature vector (cell vs. background) using a teal-colored arrow representing a 1 x 1 convolution:", "A pixel-wise softmax is applied to the final [2-channel, 388 height, 388 width] representation to obtain the final output, a predicted segmentation map.", "For more details on the softmax function, see this post.", "The pixel-wise softmax can be conceptualized as follows. Think of the output map as a 388 x 388 image. Each pixel in that image is represented by K values, one value for each of the K channels, where K is the number of classes of interest. For each pixel we take a softmax over the K channels so that one channel will \u201cstick out\u201d as the highest value; this highest channel determines the class assigned to that pixel.", "The U-Net is trained using a cross-entropy loss:", "This is a typical cross-entropy loss, with the addition of the weighting w(x) which provides a weighting to tell the model that some pixels are more important than others.", "The weight map w is pre-computed based off of each ground truth segmentation using traditional computer vision techniques. Specifically, morphological image processing is applied to the ground truth segmentation to identify the thin borders that separate cells, and then the weight map is created so that these thin borders separating cells are given high weights. Incorporating this weight map into the cross-entropy loss means that the U-Net will be heavily penalized if it leaves out these thin borders between cells or if it draws them in the wrong place. The overall goal of using the weight map in the loss is to \u201cforce the network to learn the small separation borders [\u2026] between touching cells.\u201d", "Building a dataset to train a segmentation model is time-consuming due to the need to hand-draw correct ground-truth segmentations. Accordingly, the size of the final data set may be small. In the U-Net paper the authors employ data augmentation to increase the effective size of the training data. They apply random shifts, rotations, gray value variations, and random elastic deformations to the training samples. Elastic deformations can be especially useful in medical images because (to put it colloquially) biological samples are often \u201csquishy\u201d meaning that the outputs of the elastic deformations are still \u201crealistic.\u201d", "Here are some examples of data augmentation applied to a brain image, from the Quantib blog:", "Overall, at the time of publication the U-Net model achieved state-of-the-art results on cell semantic segmentation tasks, and has subsequently been used for a wide variety of natural image and medical image segmentation applications.", "What about instance segmentation? Recall that in instance segmentation, we don\u2019t just want to identify cell vs. background pixels \u2014 we want to separate individual cells. One model that can perform the instance segmentation task is Mask R-CNN. Mask R-CNN is an extension of the popular Faster R-CNN object detection model.", "The full details of Mask R-CNN would require an entire post. This is a quick summary of the idea behind Mask R-CNN, to provide a flavor for how instance segmentation can be accomplished.", "In the first part of Mask R-CNN, Regions of Interest (RoIs) are selected. An RoI is a patch of the input image that contains an object with high probability. Multiple RoIs are identified for each input image.", "In the second part of Mask R-CNN, shown in the figure below, each RoI is used to obtain three model outputs:", "An RoI is considered \u201cpositive\u201d if it overlaps enough with a ground-truth bounding box. The Mask R-CNN includes a mask loss, which quantifies how well the predicted segmentation masks match up with ground truth segmentation masks. The mask loss is only defined for positive RoIs \u2014 in other words, the mask loss is only defined when the relevant RoI overlaps enough with a true object in the image.", "After it is trained, the Mask R-CNN can produce class, bounding box, and segmentation mask annotations simultaneously for a single input image:", "Mask R-CNN can also be used for keypoint detection. In the example below, the keypoints are visualized as dots connected by lines:", "It\u2019s interesting to consider how much work goes in to creating data sets appropriate for training instance segmentation models. One popular instance segmentation data set is MS COCO, which includes 328,000 instance-segmented images. MS COCO was created in three stages:", "In total, that\u2019s 85,000 worker hours, which is equivalent to one person working 7 days a week, 12 hours a day, for over NINETEEN YEARS!", "If you are interested in exploring instance segmentation further, the COCO data set can be downloaded here.", "Here is a sampling of some cool applications of segmentation in medical imaging.", "It\u2019s also possible to apply segmentation algorithms to videos! Here are two neat examples:", "The featured image is from the Mask R-CNN paper: He et al. 2018 Mask R-CNN.", "I am a physician with a PhD in Computer Science. My research focuses on machine learning methods development for medical data. I am the CEO of Cydoc."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9a84bddf313e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Rachel Draelos, MD, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf----9a84bddf313e---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9a84bddf313e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----9a84bddf313e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9a84bddf313e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&source=-----9a84bddf313e---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://en.wikipedia.org/wiki/Image_segmentation#Applications", "anchor_text": "numerous applications"}, {"url": "https://arxiv.org/pdf/1405.0312.pdf", "anchor_text": "Lin et al. 2015 Microsoft COCO: Common Objects in Context"}, {"url": "https://datascience.stackexchange.com/questions/52015/what-is-the-difference-between-semantic-segmentation-object-detection-and-insta", "anchor_text": "StackExchange"}, {"url": "https://www.sciencedirect.com/science/article/pii/S0952197619302398?dgcid=rss_sd_all", "anchor_text": "Ruiz-Santaquiteria et al. 2020 Semantic vs. instance segmentation in microscopic algae detection."}, {"url": "https://www.arxiv-vanity.com/papers/1712.04837/", "anchor_text": "Chen et al. MaskLab: Instance Segmentation by Refining Object Detection with Semantic and Direction Features."}, {"url": "https://arxiv.org/pdf/1506.06204.pdf", "anchor_text": "Pinheiro et al. 2015 Learning to segment object candidates."}, {"url": "https://github.com/matterport/Mask_RCNN", "anchor_text": "matterport/Mask_RCNN"}, {"url": "https://arxiv.org/pdf/1505.04597.pdf", "anchor_text": "Ronneberger et al. 2015"}, {"url": "https://github.com/ShawnBIT/UNet-family", "anchor_text": "in this repository"}, {"url": "https://arxiv.org/pdf/1505.04597.pdf", "anchor_text": "Ronneberger et al. 2015"}, {"url": "https://arxiv.org/pdf/1505.04597.pdf", "anchor_text": "Ronneberger et al. 2015"}, {"url": "https://arxiv.org/pdf/1505.04597.pdf", "anchor_text": "Ronneberger et al. 2015"}, {"url": "https://arxiv.org/pdf/1505.04597.pdf", "anchor_text": "Ronneberger et al. 2015"}, {"url": "https://glassboxmedicine.com/2019/05/26/classification-sigmoid-vs-softmax/", "anchor_text": "this post"}, {"url": "https://glassboxmedicine.com/2019/12/07/connections-log-likelihood-cross-entropy-kl-divergence-logistic-regression-and-neural-networks/", "anchor_text": "cross-entropy loss"}, {"url": "https://www.quantib.com/blog/image-augmentation-how-to-overcome-small-radiology-datasets", "anchor_text": "Quantib blog"}, {"url": "https://www.quantib.com/blog/image-augmentation-how-to-overcome-small-radiology-datasets", "anchor_text": "Quantib blog"}, {"url": "https://arxiv.org/abs/1703.06870", "anchor_text": "Mask R-CNN"}, {"url": "https://arxiv.org/abs/1506.01497", "anchor_text": "Faster R-CNN"}, {"url": "https://arxiv.org/pdf/1703.06870.pdf", "anchor_text": "He et al. 2018 Mask R-CNN"}, {"url": "https://arxiv.org/pdf/1703.06870.pdf", "anchor_text": "He et al. 2018 Mask R-CNN"}, {"url": "https://arxiv.org/pdf/1703.06870.pdf", "anchor_text": "He et al. 2018 Mask R-CNN"}, {"url": "http://cocodataset.org/#download", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1405.0312.pdf", "anchor_text": "Lin et al. 2015 Microsoft COCO: Common Objects in Context."}, {"url": "https://github.com/matterport/Mask_RCNN", "anchor_text": "matterport/Mask_RCNN"}, {"url": "https://github.com/matterport/Mask_RCNN/blob/master/samples/nucleus", "anchor_text": "Segmenting Nuclei in Microscopy Images"}, {"url": "https://arxiv.org/pdf/1904.03355.pdf", "anchor_text": "Chen et al. 2019 3D Dilated Multi-Fiber Network for Real-time Brain Tumor Segmentation in MRI."}, {"url": "https://github.com/ShawnBIT/Paper-Reading/blob/master/AHCNet.pdf", "anchor_text": "Jiang et al. 2019 AHCNet: An Application of Attention Mechanism and Hybrid Connection for Liver Tumor Segmentation in CT Volumes"}, {"url": "https://arxiv.org/pdf/1904.09106.pdf", "anchor_text": "Automated segmentation of pulmonary lobes using coordination-guided deep neural networks."}, {"url": "http://xxx.itp.ac.cn/pdf/1909.10360v1", "anchor_text": "Ni et al. RAUNet: Residual Attention U-Net for Semantic Segmentation of Cataract Surgical Instruments."}, {"url": "https://hal.archives-ouvertes.fr/hal-01314970/document", "anchor_text": "Haouchine et al. 2016 Segmentation and Labelling of Intra-operative Laparoscopic Images using Structure from Point Cloud."}, {"url": "https://github.com/matterport/Mask_RCNN", "anchor_text": "matterport/Mask_RCNN"}, {"url": "https://www.youtube.com/watch?v=OOT3UIXZztE", "anchor_text": "Mask RCNN \u2014 COCO \u2014 instance segmentation by Karol Majek."}, {"url": "https://github.com/matterport/Mask_RCNN", "anchor_text": "matterport/Mask_RCNN"}, {"url": "https://arxiv.org/pdf/1703.06870.pdf", "anchor_text": "He et al. 2018 Mask R-CNN"}, {"url": "https://glassboxmedicine.com/2020/01/21/segmentation-u-net-mask-r-cnn-and-medical-applications/", "anchor_text": "http://glassboxmedicine.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9a84bddf313e---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----9a84bddf313e---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/segmentation?source=post_page-----9a84bddf313e---------------segmentation-----------------", "anchor_text": "Segmentation"}, {"url": "https://medium.com/tag/medicine?source=post_page-----9a84bddf313e---------------medicine-----------------", "anchor_text": "Medicine"}, {"url": "https://medium.com/tag/cnn?source=post_page-----9a84bddf313e---------------cnn-----------------", "anchor_text": "Cnn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9a84bddf313e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----9a84bddf313e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9a84bddf313e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----9a84bddf313e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9a84bddf313e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf----9a84bddf313e---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa0377bd1bf3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&newsletterV3=209c0f742bcf&newsletterV3Id=a0377bd1bf3d&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----9a84bddf313e---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Written by Rachel Draelos, MD, PhD"}, {"url": "https://rachel-draelos.medium.com/followers?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "576 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf----9a84bddf313e---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa0377bd1bf3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsegmentation-u-net-mask-r-cnn-and-medical-applications-9a84bddf313e&newsletterV3=209c0f742bcf&newsletterV3Id=a0377bd1bf3d&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----9a84bddf313e---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/learn-to-pay-attention-trainable-visual-attention-in-cnns-87e2869f89f1?source=author_recirc-----9a84bddf313e----0---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=author_recirc-----9a84bddf313e----0---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=author_recirc-----9a84bddf313e----0---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Rachel Draelos, MD, PhD"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9a84bddf313e----0---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/learn-to-pay-attention-trainable-visual-attention-in-cnns-87e2869f89f1?source=author_recirc-----9a84bddf313e----0---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Learn to Pay Attention! Trainable Visual Attention in CNNsWhen training an image model, we want the model to be able to focus on important parts of the image. One way of accomplishing this is\u2026"}, {"url": "https://towardsdatascience.com/learn-to-pay-attention-trainable-visual-attention-in-cnns-87e2869f89f1?source=author_recirc-----9a84bddf313e----0---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "\u00b711 min read\u00b7Aug 10, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F87e2869f89f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-to-pay-attention-trainable-visual-attention-in-cnns-87e2869f89f1&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----87e2869f89f1----0-----------------clap_footer----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/learn-to-pay-attention-trainable-visual-attention-in-cnns-87e2869f89f1?source=author_recirc-----9a84bddf313e----0---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F87e2869f89f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-to-pay-attention-trainable-visual-attention-in-cnns-87e2869f89f1&source=-----9a84bddf313e----0-----------------bookmark_preview----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9a84bddf313e----1---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9a84bddf313e----1---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9a84bddf313e----1---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9a84bddf313e----1---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9a84bddf313e----1---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9a84bddf313e----1---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9a84bddf313e----1---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----9a84bddf313e----1-----------------bookmark_preview----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9a84bddf313e----2---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9a84bddf313e----2---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9a84bddf313e----2---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9a84bddf313e----2---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9a84bddf313e----2---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9a84bddf313e----2---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9a84bddf313e----2---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----9a84bddf313e----2-----------------bookmark_preview----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/grad-cam-2f0c6f3807fe?source=author_recirc-----9a84bddf313e----3---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=author_recirc-----9a84bddf313e----3---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=author_recirc-----9a84bddf313e----3---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Rachel Draelos, MD, PhD"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9a84bddf313e----3---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/grad-cam-2f0c6f3807fe?source=author_recirc-----9a84bddf313e----3---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "Grad-CAMVisual Explanations from Deep Networks"}, {"url": "https://towardsdatascience.com/grad-cam-2f0c6f3807fe?source=author_recirc-----9a84bddf313e----3---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": "\u00b710 min read\u00b7May 29, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2f0c6f3807fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgrad-cam-2f0c6f3807fe&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----2f0c6f3807fe----3-----------------clap_footer----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/grad-cam-2f0c6f3807fe?source=author_recirc-----9a84bddf313e----3---------------------11f0f174_58d1_4595_ab31_1fbbe47b7144-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2f0c6f3807fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgrad-cam-2f0c6f3807fe&source=-----9a84bddf313e----3-----------------bookmark_preview----11f0f174_58d1_4595_ab31_1fbbe47b7144-------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "See all from Rachel Draelos, MD, PhD"}, {"url": "https://towardsdatascience.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----9a84bddf313e----0-----------------bookmark_preview----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Aaweg-I"}, {"url": "https://medium.com/aaweg-i-nterview?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Aaweg Interview"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Can you explain Jaccard\u2019s Index? How does it differ from Dice Coefficient?In object detection, there are two distinct tasks to measure:"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "\u00b76 min read\u00b7Nov 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faaweg-i-nterview%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&user=Aaweg-I&userId=5a024f90bf10&source=-----861c4a496b2b----1-----------------clap_footer----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&source=-----9a84bddf313e----1-----------------bookmark_preview----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----0-----------------clap_footer----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9a84bddf313e----0---------------------48b496e1_a649_4f05_854b_77179c8f6563-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----9a84bddf313e----0-----------------bookmark_preview----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----1-----------------clap_footer----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----9a84bddf313e----1---------------------48b496e1_a649_4f05_854b_77179c8f6563-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----9a84bddf313e----1-----------------bookmark_preview----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/computer-vision-u-net-6d21e08b09d7?source=read_next_recirc-----9a84bddf313e----2---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----9a84bddf313e----2---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----9a84bddf313e----2---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Aaweg-I"}, {"url": "https://aaweg-i.medium.com/computer-vision-u-net-6d21e08b09d7?source=read_next_recirc-----9a84bddf313e----2---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Computer Vision: U-NetConvolutional Networks for Biomedical Image Segmentation"}, {"url": "https://aaweg-i.medium.com/computer-vision-u-net-6d21e08b09d7?source=read_next_recirc-----9a84bddf313e----2---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "\u00b75 min read\u00b7Nov 25, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6d21e08b09d7&operation=register&redirect=https%3A%2F%2Faaweg-i.medium.com%2Fcomputer-vision-u-net-6d21e08b09d7&user=Aaweg-I&userId=5a024f90bf10&source=-----6d21e08b09d7----2-----------------clap_footer----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/computer-vision-u-net-6d21e08b09d7?source=read_next_recirc-----9a84bddf313e----2---------------------48b496e1_a649_4f05_854b_77179c8f6563-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d21e08b09d7&operation=register&redirect=https%3A%2F%2Faaweg-i.medium.com%2Fcomputer-vision-u-net-6d21e08b09d7&source=-----9a84bddf313e----2-----------------bookmark_preview----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9a84bddf313e----3---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----9a84bddf313e----3---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----9a84bddf313e----3---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----9a84bddf313e----3---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9a84bddf313e----3---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9a84bddf313e----3---------------------48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----3-----------------clap_footer----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9a84bddf313e----3---------------------48b496e1_a649_4f05_854b_77179c8f6563-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----9a84bddf313e----3-----------------bookmark_preview----48b496e1_a649_4f05_854b_77179c8f6563-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----9a84bddf313e--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}