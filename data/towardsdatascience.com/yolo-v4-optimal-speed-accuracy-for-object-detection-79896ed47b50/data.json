{"url": "https://towardsdatascience.com/yolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50", "time": 1683007524.7533, "path": "towardsdatascience.com/yolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50/", "webpage": {"metadata": {"title": "YOLO v4: Optimal Speed & Accuracy for object detection | by Andrej Anka | Towards Data Science", "h1": "YOLO v4: Optimal Speed & Accuracy for object detection", "description": "You only look once (YOLO) is a family of one-stage object detectors that are fast and accurate. Recently, YOLO v4 paper was released and showed very good results compared to other object detectors\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pjreddie.com/darknet/yolo/", "anchor_text": "YOLO", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/2004.10934", "anchor_text": "YOLO v4", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "ResNet", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1608.06993", "anchor_text": "DenseNet", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1409.1556", "anchor_text": "VGG", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1406.4729", "anchor_text": "SPP", "paragraph_index": 32}, {"url": "https://arxiv.org/abs/1606.00915", "anchor_text": "ASPP", "paragraph_index": 32}, {"url": "https://eccv2018.org/openaccess/content_ECCV_2018/papers/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper.pdf", "anchor_text": "RFB", "paragraph_index": 32}, {"url": "https://arxiv.org/abs/1807.06521", "anchor_text": "paper", "paragraph_index": 33}, {"url": "https://www.coral.ai/", "anchor_text": "Coral Edge TPU", "paragraph_index": 36}, {"url": "https://www.desmos.com/calculator/5bfjfhpqyw", "anchor_text": "look", "paragraph_index": 37}, {"url": "https://www.desmos.com/calculator/rhx5tl8ygi", "anchor_text": "desmos", "paragraph_index": 39}, {"url": "https://github.com/lutzroeder/netron", "anchor_text": "tool", "paragraph_index": 45}, {"url": "https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov4.cfg", "anchor_text": "yolov4.cfg", "paragraph_index": 45}, {"url": "https://colab.research.google.com/drive/1PuI9bYeM8O1OA82pI12oGopRJJrLWfs9?usp=sharing", "anchor_text": "here", "paragraph_index": 52}, {"url": "https://arxiv.org/abs/2004.10934", "anchor_text": "paper", "paragraph_index": 54}, {"url": "https://github.com/AlexeyAB/darknet", "anchor_text": "official repo", "paragraph_index": 54}, {"url": "https://github.com/AlexeyAB/darknet", "anchor_text": "official repo", "paragraph_index": 55}, {"url": "https://arxiv.org/abs/1612.03144", "anchor_text": "Feature Pyramid Networks for Object Detection", "paragraph_index": 56}, {"url": "https://arxiv.org/abs/1803.01534", "anchor_text": "Path Aggregation Network for Instance Segmentation", "paragraph_index": 57}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "EfficientDet: Scalable and Efficient Object Detection", "paragraph_index": 58}, {"url": "https://arxiv.org/abs/1708.02002", "anchor_text": "Focal Loss for Dense Object Detection", "paragraph_index": 59}, {"url": "https://arxiv.org/abs/2004.10934", "anchor_text": "YOLOv4: Optimal Speed and Accuracy of Object Detection", "paragraph_index": 60}, {"url": "https://arxiv.org/abs/1512.02325", "anchor_text": "Single Shot MultiBox Detector (SSD)", "paragraph_index": 61}, {"url": "https://arxiv.org/abs/1811.04533", "anchor_text": "A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network", "paragraph_index": 62}, {"url": "https://arxiv.org/abs/1708.04552", "anchor_text": "Improved Regularization of Convolutional Neural Networks with Cutout", "paragraph_index": 63}, {"url": "https://arxiv.org/abs/1911.09516", "anchor_text": "Learning Spatial Fusion for Single-Shot Object Detection", "paragraph_index": 64}, {"url": "https://arxiv.org/pdf/1902.09630v2.pdf", "anchor_text": "Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression", "paragraph_index": 65}, {"url": "https://arxiv.org/abs/1608.01471", "anchor_text": "UnitBox: An Advanced Object Detection Network", "paragraph_index": 66}, {"url": "https://arxiv.org/abs/1810.12890", "anchor_text": "DropBlock: A regularization method for convolutional networks", "paragraph_index": 67}, {"url": "https://arxiv.org/abs/1908.08681", "anchor_text": "Mish: A Self Regularized Non-Monotonic Neural Activation Function", "paragraph_index": 68}, {"url": "https://arxiv.org/abs/1807.06521", "anchor_text": "CBAM: Convolutional Block Attention Module", "paragraph_index": 69}, {"url": "https://ankandrew.github.io/aware-driving", "anchor_text": "https://ankandrew.github.io/aware-driving", "paragraph_index": 71}], "all_paragraphs": ["You only look once (YOLO) is a family of one-stage object detectors that are fast and accurate. Recently, YOLO v4 paper was released and showed very good results compared to other object detectors.", "Update 1: Added a colab demo", "Most of the modern accurate models require many GPUs for training with a large mini-batch size, and doing this with one GPU makes the training really slow and impractical. YOLO v4 addresses this issue by making an object detector which can be trained on a single GPU with a smaller mini-batch size. This makes it possible to train a super fast and accurate object detector with a single 1080 Ti or 2080 Ti GPU.", "YOLO v4 achieves state-of-the-art results at a real time speed on the MS COCO dataset with 43.5 % AP running at 65 FPS on a Tesla V100. Pretty interesting results! To achieve these results, they combine some features such as Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation, Mosaic data augmentation, DropBlock regularization, and CIoU loss. These are referred to as universal features because they should work well independently from the computer vision tasks, datasets and models. We will talk about these features later.", "Note: models that fall in the light-blue area are considered real-time object detectors (+30 FPS)", "We can see that EfficientDet D4-D3 achieves better AP than YOLO v4 models, but they run at speed of < 30 FPS on a V100 GPU. On the other hand, YOLO is able to run at a much higher speed (> 60 FPS) with very good accuracy.", "Although YOLO are one-stage detectors, there are also two-stage detectors like R-CNN, fast R-CNN and faster R-CNN which are accurate but slow. We will focus on the former ones. Let's take a look at the main components of a modern one-stage object detector.", "Models such as ResNet, DenseNet, VGG, etc, are used as feature extractors. They are pre-trained on image classification datasets, like ImageNet, and then fine-tuned on the detection dataset. Turns out that, these networks that produce different levels of features with higher semantics as the network gets deeper (more layers), are useful for latter parts of the object detection network.", "These are extra layers that go in between the backbone and head. They are used to extract different feature maps of different stages of the backbone. The neck part can be for example a FPN[1], PANet[2], Bi-FPN[3], among others. For example, YOLOv3 uses FPN to extract features of different scales from the backbone.", "What does a Feature Pyramid Network (FPN)?", "Augments a standard convolutional network with a top-down pathway and lateral connections so the network efficiently constructs a rich, multi-scale feature pyramid from a single resolution input image [4]", "Each lateral connection merges the feature maps from the bottom-up pathway to the top-down pathway, producing different pyramid levels. Before merging the feature maps, the previous pyramid level is up-sampled by a factor of 2x in FPN[1] so they have the same spatial size. The classification/regression network (the head) is then applied at each each level of the pyramid so that it helps to detect object of different sizes.", "This idea of Feature Pyramid Networks can be applied to different backbones models, and as an example, the original FPN[1] paper used ResNets. There are also many modules that integrate FPN in different ways, such as SFAM [7], ASFF [9], and Bi-FPN[3].", "Image (a) shows how features are extracted from the backbone in a Single Shot Detector architecture(SSD). The image above shows also three other different types of pyramid networks, but the idea behind them is the same as they help to:", "Alleviate the problem arising from scale variation across object instances [3].", "ASFF[9] and Bi-FPN[3] are also interesting types of FPNs and show interesting results, but we will skip them here.", "This is a network in charge of actually doing the detection part (classification and regression) of bounding boxes. A single output may look like (depending on the implementation): 4 values describing the predicted bounding box (x, y, h, w) and the probability of k classes + 1 (one extra for background). Objected detectors anchor-based, like YOLO, apply the head network to each anchor box. Other popular one-stage detectors, which are anchor-based, are: Single Shot Detector[6] and RetinaNet[4].", "Following illustration combines the three modules mentioned above.", "The authors of YOLO v4 paper[5] distinguish between two categories of methods that are used to improve the object detector\u2019s accuracy. They analyze different methods in both categories, to achieve a fast operating-speed neural network with good accuracy. These both categories are:", "Methods that can make the object detector receive better accuracy without increasing the inference cost. These methods only change the training strategy or only increase the training cost. [5]", "An example of BoF is data augmentation, which increases the generalization ability of the model. To do this we can do photo-metric distortions like: changing the brightness, saturation, contrast and noise or we can do geometric distortion of an image, like rotating it, cropping, etc. These techniques are a clear example of a BoF, and they help the detector accuracy!", "Note: for object detection tasks the bounding boxes should also have the same transformations applied", "There are other interesting techniques of augmenting the images like CutOut[8] which randomly masks out square regions of input during training. This showed to improve robustness and performance of CNNs. Similarly, Random Erasing[10] selects rectangle regions in an image and erases its pixels with random values.", "Other Back of Freebies are the regularization techniques used to avoid over-fitting, like: DropOut, DropConnect and DropBlock[13]. This last one actually shows very good results in CNNs and is used in YOLO v4 backbone.", "Dropping activations at random (b) is not good to remove semantic information, because nearby activations contain closely related information. Instead, by dropping continuous regions it can remove certain semantic information (e.g., head or feet) and enforce remaining units to learn other features for classifying input image.", "The cost function of the regression network also applies to the category. The traditional thing is to apply Mean Squared error to perform regression on the coordinates.", "As stated in the paper, this treats these points as independent variables but doesn\u2019t consider the integrity of the object itself. To improve this, IoU[12] loss has been proposed, which takes into consideration the area of the predicted Bounding Box(BBox) and the ground truth Bounding Box. This idea was improved furthermore by GIoU loss [11] by including the shape and orientation of an object in addition to the coverage area. On the other side, CIoU loss was also introduced and it takes into consideration the overlapping area, the distance between center points and aspect ratio. YOLO v4 uses CIoU loss as the loss for the Bounding Boxes, mainly because it leads to faster convergence and better performance compared to the others mentioned.", "Note: one thing that might cause confusion is that although many models use MSE for BBox regression loss, they use IoU as a metric and not as a loss function like mentioned above.", "Following illustration compares the same model with different IoU losses:", "We can notice CIoU performs better than GIoU. These detections come from Faster R-CNN (Ren et al. 2015) which was trained on the same MS COCO dataset, with GIoU and CIoU losses.", "Those plugin modules and post-processing methods that only increase the inference cost by a small amount but can significantly improve the accuracy of object detection [5]", "As stated in the paper, this kind of modules/methods usually involve: introducing attention mechanisms(Squeeze-and-Excitation and Spatial Attention Module), enlarging receptive field of model and strengthening feature integration capability, among others.", "Common modules that are used to improve the receptive field are SPP, ASPP and RFB (YOLO v4 uses SPP).", "Moreover, attention modules for CNNs are mainly divided in channel wise attention, like Squeeze-and-Excitation (SE)[15], and spatial-wise attention, like Spatial Attention Module (SAM)[16]. A reason why the latter is sometimes preferred, is because SE increases inference speed by a 10% on GPUs, which not desirable. Actually YOLO v4 considers SAM[16] module but not exactly as it was originally published in this paper. Note the following:", "Given a feature map F\u2019, the original implementation performed average-pooling and max-pooling operations along the channel axis and then concatenated them. Then a convolution layer is applied (with sigmoid as activation function) to generate an attention map (Ms), which is applied to the original F\u2019.", "YOLO v4 modified SAM, on the other hand, doesn\u2019t apply max-pooling and average-pooling, but instead F\u2019 goes through a conv. layer (with sigmoid activation) which then multiplies the original feature map (F\u2019).", "Feature Pyramids we discussed early like SFAM[7], ASFF[9] and Bi-FPN[3] also fall in this category of BoS, as do the activation functions. Since ReLU came out, there have been many variants of it, like LReLU, PReLU and ReLU6. Activations like ReLU6 and hard-Swish are specially designed for quantized networks used to make inference on embedded devices, like in the Google Coral Edge TPU.", "On the other hand, YOLO v4 uses a lot Mish[14] activation function in the backbone. Take a look at the graph:", "Turns out that this activation function shows very promising results. For example, using a Squeeze Excite Network[15] with Mish (on CIFAR-100 dataset) resulted in an increase in Top-1 test accuracy by 0.494% and 1.671% as compared to the same network with Swish and ReLU respectively. [14]", "You can check this desmos which contains some other activation functions graphed!", "Until now we have discussed methods used improve the model accuracy and different parts of an object detector(backbone, neck, head). Let us now talk about what is used in the new YOLO.", "The following table shows different considered backbones for GPU version", "Certain backbones are more suitable for classification than for detection. For example, CSPDarknet53 showed to be better than CSPResNext50 in terms of detecting objects, and CSPResNext50 better than CSPDarknet53 for image classification. As stated in the paper, a backbone model for object detection requires Higher input network size, for better detection in small objects, and more layers, for a higher receptive field.", "Originally in PAN paper, after reducing the size of N4 to have the same spatial size as P5, they add this new down-sized N4 with P5. This is repeated at all levels of \ud835\udc43\ud835\udc56+1 and \ud835\udc41\ud835\udc56 to produce \ud835\udc41\ud835\udc56+1. In YOLO v4 instead of adding \ud835\udc41\ud835\udc56 with each \ud835\udc43\ud835\udc56+1, they concatenate them (as shown in the image above).", "Looking at the SPP module, it basically performs max-pooling over the 19*19*512 feature map with different kernel sizes k = { 5, 9, 13} and \u2018same\u2019 padding ( to keep the same spatial size). The four corresponding feature maps get then concatenated to form a 19*19*2048 volume. This increases the neck receptive field, thus improving the model accuracy with negligible increase of inference time.", "If you want to visualize different layers used in yolo, like in the image above, I recommend using this tool (either web/desktop version works) and then opening yolov4.cfg with it.", "These are the heads applied at different scales of the network, for detecting different-size objects. The number of channels is 255 because of (80 classes + 1 for objectness + 4 coordinates) * 3 anchors.", "The different modules/methods of BoF and BoS used in the backbone and in the detector of YOLO v4 can be summarized as follows:", "The authors of the paper introduce a new method of data augmentation called \u2018Mosaic\u2019. Basically this combines 4 images of the training dataset in 1 image. By doing this now:", "Batch normalization calculates activation statistics from 4 different images on each layer [5]", "And so, it greatly reduces the need of selecting a large mini-batch size for training. Checkout following image, showing the new augmentation method.", "They also use Self-Adversarial Training (SAT), which operates in 2 forward backward stages. In the 1st stage the neural network alters the original image instead of the network weights. In this way the neural network executes an adversarial attack on itself, altering the original image to create the deception that there is no desired object on the image. In the 2nd stage, the neural network is trained to detect an object on this modified image in the normal way. [5]", "I made a Colab for testing YOLO v4 & tiny version on your own videos. This uses the model trained on MS COCO. You can take a look here", "There are many interesting ideas mentioned in this article which could be explained in much more detail, but I hope the main concepts are clear.", "Further details can be found in the paper. If you want to train it on your own dataset, check out the official repo.", "YOLO v4 achieves state-of-the-art results (43.5% AP) for real-time object detection and is able to run at a speed of 65 FPS on a V100 GPU. If you want less accuracy but much higher FPS, checkout the new Yolo v4 Tiny version at the official repo.", "[1] Feature Pyramid Networks for Object Detection", "[2] Path Aggregation Network for Instance Segmentation", "[3] EfficientDet: Scalable and Efficient Object Detection", "[4] Focal Loss for Dense Object Detection", "[5] YOLOv4: Optimal Speed and Accuracy of Object Detection", "[6] Single Shot MultiBox Detector (SSD)", "[7] A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network", "[8] Improved Regularization of Convolutional Neural Networks with Cutout", "[9] Learning Spatial Fusion for Single-Shot Object Detection", "[11] Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression", "[12] UnitBox: An Advanced Object Detection Network", "[13] DropBlock: A regularization method for convolutional networks", "[14] Mish: A Self Regularized Non-Monotonic Neural Activation Function", "[16] CBAM: Convolutional Block Attention Module", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Computer Science student. ML enthusiast. I try to explain things in simple terms with visual images. Checkout my app https://ankandrew.github.io/aware-driving"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F79896ed47b50&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----79896ed47b50--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----79896ed47b50--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ankas?source=post_page-----79896ed47b50--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ankas?source=post_page-----79896ed47b50--------------------------------", "anchor_text": "Andrej Anka"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28fa574bceab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&user=Andrej+Anka&userId=28fa574bceab&source=post_page-28fa574bceab----79896ed47b50---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79896ed47b50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79896ed47b50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.youtube.com/watch?v=MPU2HistivI", "anchor_text": "video"}, {"url": "https://pjreddie.com/darknet/yolo/", "anchor_text": "YOLO"}, {"url": "https://arxiv.org/abs/2004.10934", "anchor_text": "YOLO v4"}, {"url": "https://arxiv.org/abs/2004.10934", "anchor_text": "source"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "ResNet"}, {"url": "https://arxiv.org/abs/1608.06993", "anchor_text": "DenseNet"}, {"url": "https://arxiv.org/abs/1409.1556", "anchor_text": "VGG"}, {"url": "https://developers.google.com/machine-learning/practica/image-classification/preventing-overfitting", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/1708.04896.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/abs/1911.08287", "anchor_text": "source"}, {"url": "https://arxiv.org/abs/1406.4729", "anchor_text": "SPP"}, {"url": "https://arxiv.org/abs/1606.00915", "anchor_text": "ASPP"}, {"url": "https://eccv2018.org/openaccess/content_ECCV_2018/papers/Songtao_Liu_Receptive_Field_Block_ECCV_2018_paper.pdf", "anchor_text": "RFB"}, {"url": "https://arxiv.org/abs/1807.06521", "anchor_text": "paper"}, {"url": "https://www.coral.ai/", "anchor_text": "Coral Edge TPU"}, {"url": "https://www.desmos.com/calculator/5bfjfhpqyw", "anchor_text": "look"}, {"url": "https://www.desmos.com/calculator/rhx5tl8ygi", "anchor_text": "desmos"}, {"url": "https://github.com/lutzroeder/netron", "anchor_text": "tool"}, {"url": "https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov4.cfg", "anchor_text": "yolov4.cfg"}, {"url": "https://colab.research.google.com/drive/1PuI9bYeM8O1OA82pI12oGopRJJrLWfs9?usp=sharing", "anchor_text": "here"}, {"url": "https://arxiv.org/abs/2004.10934", "anchor_text": "paper"}, {"url": "https://github.com/AlexeyAB/darknet", "anchor_text": "official repo"}, {"url": "https://github.com/AlexeyAB/darknet", "anchor_text": "official repo"}, {"url": "https://arxiv.org/abs/1612.03144", "anchor_text": "Feature Pyramid Networks for Object Detection"}, {"url": "https://arxiv.org/abs/1803.01534", "anchor_text": "Path Aggregation Network for Instance Segmentation"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "EfficientDet: Scalable and Efficient Object Detection"}, {"url": "https://arxiv.org/abs/1708.02002", "anchor_text": "Focal Loss for Dense Object Detection"}, {"url": "https://arxiv.org/abs/2004.10934", "anchor_text": "YOLOv4: Optimal Speed and Accuracy of Object Detection"}, {"url": "https://arxiv.org/abs/1512.02325", "anchor_text": "Single Shot MultiBox Detector (SSD)"}, {"url": "https://arxiv.org/abs/1811.04533", "anchor_text": "A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network"}, {"url": "https://arxiv.org/abs/1708.04552", "anchor_text": "Improved Regularization of Convolutional Neural Networks with Cutout"}, {"url": "https://arxiv.org/abs/1911.09516", "anchor_text": "Learning Spatial Fusion for Single-Shot Object Detection"}, {"url": "https://arxiv.org/abs/1708.04896", "anchor_text": "Random Erasing Data Augmentation"}, {"url": "https://arxiv.org/pdf/1902.09630v2.pdf", "anchor_text": "Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression"}, {"url": "https://arxiv.org/abs/1608.01471", "anchor_text": "UnitBox: An Advanced Object Detection Network"}, {"url": "https://arxiv.org/abs/1810.12890", "anchor_text": "DropBlock: A regularization method for convolutional networks"}, {"url": "https://arxiv.org/abs/1908.08681", "anchor_text": "Mish: A Self Regularized Non-Monotonic Neural Activation Function"}, {"url": "https://arxiv.org/abs/1709.01507", "anchor_text": "Squeeze-and-Excitation Networks"}, {"url": "https://arxiv.org/abs/1807.06521", "anchor_text": "CBAM: Convolutional Block Attention Module"}, {"url": "https://medium.com/tag/object-detection?source=post_page-----79896ed47b50---------------object_detection-----------------", "anchor_text": "Object Detection"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----79896ed47b50---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----79896ed47b50---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/yolov4?source=post_page-----79896ed47b50---------------yolov4-----------------", "anchor_text": "Yolov4"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----79896ed47b50---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F79896ed47b50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&user=Andrej+Anka&userId=28fa574bceab&source=-----79896ed47b50---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F79896ed47b50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&user=Andrej+Anka&userId=28fa574bceab&source=-----79896ed47b50---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79896ed47b50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----79896ed47b50--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F79896ed47b50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----79896ed47b50---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----79896ed47b50--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----79896ed47b50--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----79896ed47b50--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----79896ed47b50--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----79896ed47b50--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----79896ed47b50--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----79896ed47b50--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----79896ed47b50--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ankas?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ankas?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andrej Anka"}, {"url": "https://medium.com/@ankas/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "80 Followers"}, {"url": "https://ankandrew.github.io/aware-driving", "anchor_text": "https://ankandrew.github.io/aware-driving"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28fa574bceab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&user=Andrej+Anka&userId=28fa574bceab&source=post_page-28fa574bceab--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F36732b57ec8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50&newsletterV3=28fa574bceab&newsletterV3Id=36732b57ec8&user=Andrej+Anka&userId=28fa574bceab&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}