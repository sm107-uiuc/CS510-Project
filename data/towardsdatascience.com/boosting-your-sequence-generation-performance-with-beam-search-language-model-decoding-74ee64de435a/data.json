{"url": "https://towardsdatascience.com/boosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a", "time": 1683004672.79332, "path": "towardsdatascience.com/boosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a/", "webpage": {"metadata": {"title": "Boosting your Sequence Generation Performance with \u2018Beam-search + Language model\u2019 decoding | by Kartik Chaudhary | Towards Data Science", "h1": "Boosting your Sequence Generation Performance with \u2018Beam-search + Language model\u2019 decoding", "description": "Whenever Image Processing, Audio data Analysis or Natural language processing (NLP) tasks are concerned, Deep learning has proved to be an ideal choice and has shown outstanding outcomes. Neural\u2026"}, "outgoing_paragraph_urls": [{"url": "https://ieeexplore.ieee.org/document/8583770", "anchor_text": "word-beam-search", "paragraph_index": 14}, {"url": "https://dropsofai.com", "anchor_text": "https://dropsofai.com", "paragraph_index": 35}], "all_paragraphs": ["Whenever Image Processing, Audio data Analysis or Natural language processing (NLP) tasks are concerned, Deep learning has proved to be an ideal choice and has shown outstanding outcomes. Neural Network-based model architectures are really good at understanding complex patterns as well as generating meaningful and realistic data. Although deep learning-based solutions are generally very efficient, it\u2019s never a bad idea to use better post-processing techniques to make predictions even more accurate.", "Complex problems such as Neural Machine Translation (NMT), Image caption generation (ICG) and speech recognition (ASR) are very much solvable today using deep learning. These problems are categorized as sequence generation problems where given an input, the model learns to generate some text sequence. If you take a look at the research papers showing state of the art (SOTA) results on these tasks, you will probably find their solution utilizing a beam search decoder fused with a Language model to boost the results. Let\u2019s learn more about these decoding techniques with examples \u2014", "Going further, we will define an example sequence generation problem and explore post-processing (decoding) techniques. We will start with a greedy-search-decoding technique and introduce beam-search-decoding fused with language model to further improve the overall results.", "Consider a problem of English language text generation and suppose we have already trained a model to do that. Depending upon the nature of the problem or solution strategy, our model might be a character-level model or a word-level model. A character-level text generator model generates text by predicting one character at a time. Similarly, a word-level text generator predicts one word at a time and multiple predicted such words make a sequence.", "Assume we have trained a character-level model that generates text by predicting one character at a time. This problem can be related to any of the following problems \u2014 Speech to Text, Optical Character Recognition, Image caption generation\u2026.etc. Such problems are usually solved using an encoder-decoder architecture as shown in the figure below. The encoder part is responsible for taking an input vector (audio, image or text\u2026.) and producing an encoded context vector. The decoder part then uses that context vector to generate the output sequence by predicting one token (char/ wordbbb) at a time.", "As our model is character-level, It will generate a probability distribution over all the possible characters for each token in the output sequence. In other words \u2014 For each token (char) our model is predicting, it will generate a probability array of length 26 (as per the English language \u2014 a to z) and the probabilities will show how likely a particular character is to be the output token.", "For a predicted sequence of length 10 (chars), our models' output would look something like this \u2014", "To convert this probabilistic output into a readable form (English text), we need a decoding algorithm. The simplest decoder would be a greedy-search-decoder. Let\u2019s write a greedy-search-decoder along with a complex one called beam-search-decoder \u2014", "The simplest way to decode the models\u2019 predictions is to consider the most likely sequence as output. A greedy decoder, also called as the best-path decoder considers the token (character or word) with the highest probability in each prediction and concatenates all the predicted tokens to get the final output sequence. This is a simple and fast way to get the output sequence. But it may not always give you the best output.", "Here is how you write a greedy decoder for your model in Python \u2014", "Here the shape of the model's prediction is 5*4 that means, the model is trying to generate a sequence of length five. As there are only four different tokens in the vocabulary, the model predicts the probability distribution of size four for each token in the sequence. As per the definition, the greedy decoder generates the sequence with the highest probability by choosing the most probable tokens at each time step.", "Beam search decoding is another popular way of decoding model predictions that leads to better results than the greedy search decoder in almost all cases. Unlike greedy decoder, it doesn\u2019t just consider the most probable token at each prediction, it considers top-k tokens having higher probabilities (where k is called the beam-width or beam-size). Although beam-search gives better results, it makes the overall pipeline slow as it is computationally complex.", "Thus it doesn\u2019t just give you one output sequence, it gives you k-different output sequences along with their likelihood (probabilities). Unlike greedy decoder where we had only a single output sequence, we have k different output sequences here and there is a very good chance that one of these k sequences is the correct output sequence.", "For the first time-step prediction, choose k tokens having higher probabilities instead of one (as in greedy we choose only one). Now going further, consider every token of the current prediction and append it to all the previously decoded k sequences and keep calculating corresponding probabilities of new sequences. Now choose top k sequences out of the new sequences based on the probability score and move to the next time-step. Repeat this process until the last token. Finally, return k sequences with their corresponding probability values.", "Tip: word-beam-search is another variant of beam-search decoding technique that restricts to or chooses output sequences having dictionary words only. It performs better than a vanilla beam search in most cases.", "Writing a beam search decoder in Python\u2014", "It\u2019s because a regular probability would cause problems when there are longer sequences. For example \u2014 Consider a sequence of length 100 is generated by the model. And the probability of each token in the sequence is 0.10 then the probability of the output sequence would be the multiplication of all these probabilities \u2014", "As we can see it\u2019s an extremely small number. Any programing language might fail to compare such small floating-point numbers as this could cause under-flow. This is why we calculate log-probabilities instead of regular probability. If you pay attention we are multiplying negative log-probability to calculate the score (line 16 in code), this is because the logarithm of a probability ( 0 < 1.0) is always a negative number. And thus we are choosing the top k sequences with minimum log-scores.", "Probability of sequence with N tokens would be \u2014", "If we take a log on both sides, this multiplication will convert to a summation. Hence calculation of the log-likelihood instead of real probability would be faster and efficient. As we know logarithm of a number < 1.0 would always be a negative number. So we will get a negative score for our sequence. We can convert this score(log-likelihood) to the original probability by taking the anti-logarithm of this score. For the purpose of finding k best sequences using the beam-search, we only need to compare the probabilities of certain sequences, so the log-likelihood would work just fine.", "Now we know that the beam search decoder gives you k different output sequences instead of one and there are good chances that one of these sequences is the correct output. But we don\u2019t have a way to identify which of the output sequence is the best. This is where a language model comes into the picture.", "A language model is a statistical representation of a given language. It is supposed to be able to guess the next word if a list of previously occurring words is given, from a given sentence. In other words, A language model is something that can determine the probability of a given text-sequence (sentence) where sequence tokens (chars/words) are pulled from a fixed vocabulary (language vocab). So, basically it can score your sentence. A good score means that the sentence is contextually correct and belongs to the given language.", "Language models are usually trained on a very large corpus of the text and are able to understand(learn) the context(co-occurrence) of words in the given sentences. A language model not necessarily has to be word-level, we can train the language model on characters as well. A character-level language model is supposed to guess the next character in a sequence, given the previous few characters. Again character-level models can also give you the probability (or likelihood) of a given sentence.", "Consider a scenario where a deep learning model is trying to generate some text (or consider a problem where the model is trying to convert voice to text) and the resulting probability distribution of characters is sent to the beam search decoder with a beam-width of 5. Assume that the following are the top 5 sequences generated using beam-search-decoding.", "A greedy-search-decoder will give you the first sequence as output because it is the sequence with the highest probability (0.41) as per our model. But clearly (3) is the correct output with slightly lesser probability.", "To find the best sequence out of these 5 sequences, we will use the language model to check the likelihood of each of these sequences as per the English language. If our language model is well trained, it is supposed to give a good probability(score) to the third sequence as it is 100% correct as per the English language.", "Assuming that the following are the likelihoods of these 5 sequences as per our language model.", "Now to choose the best output sequence, we will consider the weighted sum of both the probabilities \u2014", "Values of the constants Alpha and Beta is decided after tuning them on the validation dataset. We choose the values which give the best result on the validation set. We then use those values to evaluate our model on the test set.", "*Note: Sometimes the sequence length is also considered while calculating the final score of a sequence. If we don\u2019t penalize the scores with the sequence lengths, our model will give more preference to the smaller sequences. As the score would be lesser for the longer sequences (multiplication of more probability values (p < 1.0) will result in even smaller scores).", "Tip: It is observed that using a word-level language model gives better results in most cases. To be able to use a word-level language model for scoring, output sequences should be restricted to the dictionary words only. Thus a word-beam-search algorithm is used to come up with restricted beams and later those beams are re-scored with the language model to decide the final output.", "PS: Usually, as per research-papers, a very large number is used as beam-size (~1000\u20132000) is used while applying beam-search. It delivers better results but at the cost of speed as inference becomes quite slow.", "Few research papers utilizing beam-search decoding and a language model to improve the results \u2014", "Thanks for reading, Don\u2018t forget to share your thoughts with me.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI/ML @ Google | personal blog: https://dropsofai.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F74ee64de435a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----74ee64de435a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----74ee64de435a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kartikgill96?source=post_page-----74ee64de435a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=post_page-----74ee64de435a--------------------------------", "anchor_text": "Kartik Chaudhary"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3fd5a49d1e91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=post_page-3fd5a49d1e91----74ee64de435a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74ee64de435a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74ee64de435a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.shutterstock.com/image-vector/digital-binary-code-matrix-backgrounddata-flood-1341680024", "anchor_text": "https://www.shutterstock.com/image-vector/digital-binary-code-matrix-backgrounddata-flood-1341680024"}, {"url": "https://stackoverflow.com/questions/45977990/tensorflow-how-to-embed-float-sequences-to-fixed-size-vectors", "anchor_text": "https://stackoverflow.com/questions/45977990/tensorflow-how-to-embed-float-sequences-to-fixed-size-vectors"}, {"url": "https://ieeexplore.ieee.org/document/8583770", "anchor_text": "word-beam-search"}, {"url": "https://dropsofai.com/boosting-your-sequence-generation-performance-with-beam-search-language-model-decoding/", "anchor_text": "here"}, {"url": "https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf", "anchor_text": "https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf"}, {"url": "https://arxiv.org/pdf/1508.01211.pdf", "anchor_text": "https://arxiv.org/pdf/1508.01211.pdf"}, {"url": "https://arxiv.org/pdf/1411.4555.pdf", "anchor_text": "https://arxiv.org/pdf/1411.4555.pdf"}, {"url": "https://arxiv.org/pdf/1901.01808.pdf", "anchor_text": "https://arxiv.org/pdf/1901.01808.pdf"}, {"url": "https://www.shutterstock.com/image-vector/digital-binary-code-matrix-backgrounddata-flood-1341680024", "anchor_text": "https://www.shutterstock.com/image-vector/digital-binary-code-matrix-backgrounddata-flood-1341680024"}, {"url": "https://stackoverflow.com/questions/45977990/tensorflow-how-to-embed-float-sequences-to-fixed-size-vectors", "anchor_text": "https://stackoverflow.com/questions/45977990/tensorflow-how-to-embed-float-sequences-to-fixed-size-vectors"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----74ee64de435a---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/language-learning?source=post_page-----74ee64de435a---------------language_learning-----------------", "anchor_text": "Language Learning"}, {"url": "https://medium.com/tag/beam-search?source=post_page-----74ee64de435a---------------beam_search-----------------", "anchor_text": "Beam Search"}, {"url": "https://medium.com/tag/language-model?source=post_page-----74ee64de435a---------------language_model-----------------", "anchor_text": "Language Model"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----74ee64de435a---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74ee64de435a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=-----74ee64de435a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74ee64de435a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=-----74ee64de435a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74ee64de435a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----74ee64de435a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F74ee64de435a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----74ee64de435a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----74ee64de435a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----74ee64de435a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----74ee64de435a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----74ee64de435a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----74ee64de435a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----74ee64de435a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----74ee64de435a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----74ee64de435a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kartik Chaudhary"}, {"url": "https://medium.com/@kartikgill96/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "196 Followers"}, {"url": "https://dropsofai.com", "anchor_text": "https://dropsofai.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3fd5a49d1e91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=post_page-3fd5a49d1e91--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fca74cfd61cd8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a&newsletterV3=3fd5a49d1e91&newsletterV3Id=ca74cfd61cd8&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}