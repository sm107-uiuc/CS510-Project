{"url": "https://towardsdatascience.com/supercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1", "time": 1683010561.325176, "path": "towardsdatascience.com/supercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1/", "webpage": {"metadata": {"title": "Supercharging customer touchpoints with uplift modeling | by Steve Klosterman | Towards Data Science", "h1": "Supercharging customer touchpoints with uplift modeling", "description": "In this post, I will introduce the concept of uplift modeling and make a case for why it\u2019s an important part of the data scientist\u2019s toolbox of methods to increase business value. Then I\u2019ll show a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/klostest/uplift_modeling/blob/master/uplift-modeling.ipynb", "anchor_text": "here on Github", "paragraph_index": 1}, {"url": "https://blogs.oracle.com/datascience/data-driven-debt-collection-using-machine-learning-and-predictive-analytics", "anchor_text": "debt collection", "paragraph_index": 4}, {"url": "https://go.forrester.com/blogs/13-06-27-how_the_obama_campaign_used_predictive_analytics_to_influence_voters/", "anchor_text": "political campaigns", "paragraph_index": 4}, {"url": "https://zenodo.org/record/3653141#.XwEVz5NKjYU", "anchor_text": "here", "paragraph_index": 15}, {"url": "https://towardsdatascience.com/helping-late-borrowers-repay-with-uplift-modeling-at-tala-a1541aceffe4", "anchor_text": "Helping Late Borrowers Repay with Uplift Modeling at Tala", "paragraph_index": 79}, {"url": "https://causalml.readthedocs.io/en/latest/about.html", "anchor_text": "CausalML: a Python package that provides a suite of uplift modeling and causal inference methods using machine learning algorithms based on recent research. Accessed 7/5/2020.", "paragraph_index": 81}, {"url": "http://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf", "anchor_text": "Gutierrez, Pierre and Jean-Yves Gerardy, 2016. Causal Inference and Uplift Modeling: A review of the literature. JMLR: Workshop and Conference Proceedings 67:1\u201313.", "paragraph_index": 82}, {"url": "https://support.sas.com/resources/papers/proceedings13/096-2013.pdf", "anchor_text": "Lee, Taiyeong et al., 2013 Incremental Response Modeling Using SAS Enterprise Miner. SAS Global Forum 2013: Data Mining and Text Analytics.", "paragraph_index": 83}, {"url": "https://pylift.readthedocs.io/en/latest/", "anchor_text": "Pylift: an uplift library that provides, primarily, (1) fast uplift modeling implementations and (2) evaluation tools. Accessed 7/5/2020.", "paragraph_index": 84}, {"url": "https://arxiv.org/abs/2005.03447", "anchor_text": "Zhao, Zhenyu et al., 2020. Feature Selection Methods for Uplift Modeling.", "paragraph_index": 85}, {"url": "https://www.steveklosterman.com/", "anchor_text": "https://www.steveklosterman.com/", "paragraph_index": 87}], "all_paragraphs": ["In this post, I will introduce the concept of uplift modeling and make a case for why it\u2019s an important part of the data scientist\u2019s toolbox of methods to increase business value. Then I\u2019ll show a simple way to build an uplift model and demonstrate a few uplift model evaluation metrics, using synthetic data in Python.", "This post is available as a Jupyter notebook here on Github.", "Of the myriad ways that machine learning can create value for businesses, uplift modeling is one of the lesser known, compared to methods such as supervised classification or regression. But for many use cases, it may be the most effective modeling technique. In any situation where there is a costly action a business can selectively take for different customers, in hopes of influencing their behavior, uplift modeling should be a strong candidate for determining strategy. This is because uplift modeling aims to find the subset of customers that would be most influenced by the action. Identifying this segment is important for maximizing the return on investment in a business strategy.", "For example, in offering a coupon, a business is taking a potential revenue hit: if a customer buys and uses the coupon, revenue will be decreased by the value of the coupon. But, if the coupon persuades the customer to make a purchase, when they otherwise wouldn\u2019t have, then it may still be worth it. These kinds of customers are called \u201cpersuadables\u201d in the terminology of uplift modeling, which breaks things down into customer behavior with and without \u201ctreatment\u201d, where treatment in this example is receiving a coupon.", "The goal of uplift modeling, also known as net lift or incremental response modeling, is to identify the \u201cpersuadables\u201d, not waste efforts on \u201csure things\u201d and \u201clost causes\u201d, and avoid bothering \u201csleeping dogs\u201d, or those who would react negatively to the treatment, if they exist. Uplift modeling has found application in many domains including marketing, the classic use case illustrated here, as well as debt collection and political campaigns.", "Now that we know the goal of uplift modeling, how do we get there? A typical starting point for building an uplift model is a dataset from a randomized, controlled experiment: we need a representative sample of all different kinds of customers in both a treatment group, as well as a control group that didn\u2019t receive treatment. If the proportion of customers making a purchase is significantly higher in the treatment group than the control group, we know that the promotion is \u201cworking\u201d in the sense that it encourages a purchase on average across all customers. This is called the average treatment effect (ATE). Quantifying the ATE is the typical outcome of an A/B test.", "However, it may be that only a portion of customers within the treatment group are responsible for most of the ATE we observe. As an extreme example, maybe half of the customers in the treatment group were responsible for the entire ATE, whereas the promotion had no effect on the other half. If we had some way to identify the persuadable segment of customers ahead of time, who would more readily respond to treatment, then we would be able to concentrate our resources on them, and not waste time on those for whom the treatment would have little or no effect. We may need to find other promotions to engage the non-responders. In the process of determining variable treatment effects from person to person, conditional on the different traits these people have, we\u2019re looking for the individual treatment effect (ITE), also called the conditional average treatment effect (CATE). This is where machine learning and predictive modeling come into the picture.", "A classic technique for structuring an uplift model is to predict, for an individual customer, their likelihood of purchase if they are treated, and also the likelihood if they are not treated. These two probabilities are then subtracted to obtain the uplift: how much more likely is a purchase if treatment is given? This can be accomplished in two ways, where in both cases the binary response variable of the model is whether or not the customer made a purchase after the treatment:", "The two approaches are summarized in the following schematic:", "These approaches are widely documented in the literature on uplift modeling and causal inference (Lee et al. 2013, Gutierrez and Gerardy 2016). They have the advantage of being relatively simple and intuitive, and can be implemented using binary classification modeling techniques that many data scientists are familiar with, as well as specialized packages in enterprise software such as SAS (Lee et al. 2013). At the same time, causal inference is an active area of research within machine learning and other approaches may achieve better model performance. Different approaches include tree-based models designed to target uplift (reviewed in Gutierrez and Gerardy 2016), target variable transformation (Yi and Frost 2018), and other more recent innovations such as the X-Learner (Kunzel et al. 2019).", "In all varieties, uplift modeling faces a fundamental challenge. The goal is to predict, for an individual customer, their likelihood of purchase if treated, and also the likelihood if not treated, to calculate the uplift. But in reality, we never observe the outcome for someone who was both treated and not treated, because this is impossible! Someone is either treated, or not. In mathematical modeling, it\u2019s typically a problem if we can\u2019t observe all the outcomes we\u2019re interested in. This challenge illustrates the counterfactual nature of uplift modeling, and the importance of randomized experiments to understand the CATE across all types of customers.", "Gutierrez and Gerardy (2016) summarize this challenge and point the way forward:", "Estimating customer uplift is both a Causal Inference and a Machine Learning problem. It is a causal inference problem because one needs to estimate the difference between two outcomes that are mutually exclusive for an individual (either person i receives a promotional e-mail or does not receive it). To overcome this counter-factual nature, uplift modeling crucially relies on randomized experiments, i.e. the random assignment of customers to either receive the treatment (the treatment group) or not (the control group). Uplift modeling is also a machine learning problem as one needs to train different models and select the one that yields the most reliable uplift prediction according to some performance metrics. This requires sensible cross-validation strategies along with potential feature engineering.", "Let\u2019s explore these concepts using an example dataset, by building an S-Learner model and evaluating it.", "The most straightforward way to build an uplift model is to start with data from a randomized controlled experiment. This way, both the treatment and control groups should have a representative sample of the population of customers. Outside of designed experiments, quasi-experimental data may be available if a natural control group exists as part of a business\u2019s normal operations. Treatment and control groups can also be approximated by a technique known as propensity score matching, available in the CausalML package that also offers a suite of uplift modeling tools (CausalML).", "Here we use synthetic data from a recent publication (Zhao et al. 2020), which are publicly available here. These data simulate a designed experiment with an even split between treatment and control groups. We load only the first 10,000 rows from this dataset, which is the first of \u201c100 trials (replicates with different random seeds)\u201d. The dataset is constructed so that some features are predictive of the outcome, some are uninformative, and some are predictive of the treatment effect specifically.", "The columns we\u2019re interested in are treatment_group_key, which identifies whether or not the customer received treatment, conversion which is 1 if the customer made a purchase and 0 if not, and the 36 synthetic features which all start with x. In real data, the features may correspond to such things as customer purchase history, demographics, and other quantities a data scientist may engineer with the hypothesis that they would be useful in modeling uplift.", "Let\u2019s load the data and briefly explore it.", "Of these 10,000 records, how many are in the treatment group, and how many are in the control group?", "There is a 50/50 split. Let\u2019s encode the treatment variable as a binary 0/1:", "What was the overall conversion rate?", "What\u2019s the conversion rate in the treatment group versus the control group?", "There is a substantially higher conversion rate in the treatment group (37%) than the control group (27%), indicating the treatment is effective at encouraging conversion: the ATE is positive and is about 10%.", "Often in real data the difference is not so large and a significance test is usually conducted to determine the result of the A/B test.", "The p-value is the second quantity returned from the proportion test and is much smaller than 0.05, or pretty much any other threshold used to decide significance. So we know there\u2019s a significant ATE. This is the typical starting point for uplift modeling. If we were to have observed that the treatment did not increase conversion rate, while theoretically it may be possible to find a persuadable segment of customers using uplift modeling, in practice it may not be a worthwhile endeavor. This likely depends on the specific problem at hand.", "However in our case, having observed a substantial treatment effect, we proceed to use uplift modeling to find the CATE, and see if we can identify those persuadables.", "Here I\u2019ll use an XGBClassifier to train an S-Learner; that is, a single model including all the features, where the treatment indicator is also a feature. I'll split the data into training and validation sets (80/20 split), for early stopping. I'll also use the validation set to illustrate model evaluation metrics. In a real project, a held out test set should be reserved from this process, where the evaluation metrics on the test set would be used for final evaluation of the model.", "Specify the features as a list. This includes the treatment column and all features, which are the 8th column onward:", "Assemble the training and validation sets for training the XGBoost classifier:", "Now it\u2019s time to instantiate and train the model.", "The training process completes and we can see the model has a fairly high validation AUC. The training AUC is even higher than this, meaning technically the model is overfit. Normally I\u2019d do a hyperparameter search, but I found the values used here to provide sensible results for the purpose of illustrating uplift modeling with this dataset.", "As a practical side note, I\u2019ve found that in some cases, when using a T-Learner (not shown here), that overfitting to the training set can cause unexpected results when calculating uplift. In my experience, the issue could be remedied by decreasing max_depth or increasing min_child_weight in the XGBClassifier, in other words decreasing the amount of overfitting.", "Another point to consider in model building is feature selection, which I\u2019ve omitted here. In the context of uplift modeling, one could use the uplift model evaluation metrics introduced below on a validation set as a way to select features, for example by recursive feature elimination. Feature selection for uplift models is also the topic of recent research, including the paper that is the source of the dataset used here (Zhao et al. 2020).", "Now, we have our uplift model. The model building for an S-Learner is pretty simple, if you are already familiar with binary classification. To actually calculate the uplift for a given data set, with this approach we need to score the model twice, once with treatment = 1 and again with treatment = 0, then subtract these to get the uplift. Here we do this for the validation set, then plot a histogram of the uplift scores.", "The distribution of uplift is mostly positive, which makes sense since we know from our analysis of the experiment that the treatment encourages conversion on average. However, some instances have negative uplift, meaning treatment actually discourages conversion for some people. In other words, there appears to be a sleeping dog effect in these data.", "The main questions now are: should we trust these results? How do we know how good this model is? Metrics for uplift model evaluation are more complex than typical metrics used in supervised learning, such as the ROC AUC for classification tasks or RMSE for regression. Generally speaking, uplift evaluation metrics make a comparison of the conversion rate between the treatment and control groups, for different ranges of the predicted uplift score. For those with high uplift scores, we\u2019d expect to see a larger difference between treatment and control, while those with lower uplift scores should have a smaller difference, or even a larger conversion rate in the control group in the case of sleeping dogs (i.e. negative difference).", "A popular way to evaluate an uplift model is with a quantile chart. This will give a quick visual impression of whether the model is \u201cworking\u201d, in the sense of sloping true uplift. To create the quantile chart, we start with the uplift predictions for our validation set, and bin the instances into quantiles based on these scores. The number of quantiles depends on how much data we have, although 10 is a pretty typical number in practice (deciles). Then, within each bin, we\u2019ll find the difference in conversion rate for those who were in the treatment group and those who were in the control group. If the model is working well, we should see a larger positive difference in the highest decile, decreasing to a small or negative difference in the lowest decile (i.e. treatment rate similar to control rate, or lower than control rate). In other words, as predicted uplift increases, the true uplift from control to treatment group should increase as well.", "Create a new DataFrame from the validation data, to add the uplift scores and quantiles.", "Check that the treatment and control groups are approximately balanced, overall for the validation set (they should be since we used a random training/validation split but it\u2019s always good to check):", "Now, using the entire validation set (treatment and control groups together), make labels for the uplift score quantiles. We\u2019ll check that the treatment and control groups are balanced within the quantiles, since we\u2019ll be splitting the data by quantile and treatment to create the chart. Pandas has a convenient function to produce a series of labels according to which quantile an observation in the input series belongs to.", "From this function we get a column indicating which quantile each instance belongs to, represented by the bin edges:", "We also get a list of all bin edges in score_quantile_bins, but we don't need it here. Now let's add the score quantile to the dataframe so we can use it for analysis.", "Check that the number of treated and control observations within quantile bins are similar, using groupby/count and some multiindex magic:", "Without being too precise about it, it doesn\u2019t appear that the score quantiles are unbalanced in terms of the proportion of treatment and control; they are similar in each bin. This is expected, as we are working with data from a randomized experiment, however again it\u2019s good to check such assumptions.", "On to the uplift quantile chart. We\u2019ll start by creating a mask we can use for the treatment group:", "Then we get the conversion rates within uplift score quantiles, separately for treatment and control groups:", "Finally, we calculate their difference, which is the true uplift within each score quantile.", "Now we have all the information needed to plot an uplift quantile chart.", "The uplift quantile chart shows that, for the most part, true uplift increases from lower score bins to higher ones, which is what we\u2019d expect to see if the model is working. So it appears our model can effectively segment out customers who more readily respond to treatment. In a real project, it would be important to repeat this analysis on a held-out test set, to confirm the model works with data that was not used at all for model training, since technically this validation set was used for early stopping in the model fitting process. However good performance on the validation set is a good sign and as long as the test set has similar characteristics to the training and validation sets, we\u2019d expect to see similar performance there.", "What can we learn from the quantile chart? From analysis of the experiment we know the ATE is about 10%. The quantile chart we created with the validation set tells us that by targeting the top decile of uplift scores, we may achieve a treatment effect of over 35%, a noticeable increase. The next few deciles appear to have larger treatment effects than the ATE as well. Depending on how expensive the treatment is to apply, it may make sense to target a limited portion of the population using this information.", "We can also see that the sleeping dog effect has some support from observations of the true uplift. The bottom score decile, which consists entirely of negative scores, in fact has negative true uplift. So it appears that targeting the bottom 10% of the population, by uplift score, actually has a negative impact on the business.", "While the uplift quantile chart provides a qualitative snapshot telling us whether the model is effective at segmenting customers or not, we can go a step further in this direction and ask how accurate the model is at predicting uplift. This is the process of calibration, for which we\u2019ll need the average predicted uplift within the score quantiles:", "We\u2019ll put this together in a DataFrame with the true uplift that we calculated above, to create a scatter plot. If the uplift predictions are accurate, a scatter plot of predicted and true uplift should lie close to the one-one line.", "Qualitatively, we can see from the calibration plot that mean predicted uplift is close to true uplift, by quantile. This calibration could be made more precise by calculating some sort of metric, perhaps MAE (mean absolute error), as a measure of model goodness of fit.", "There are a few other ways these quantile-based analyses could be extended:", "When using uplift scores in practice, a common approach is to rank customers in descending order, according to their uplift score. We can extend the quantile chart idea to calculate how many additional customers (\u201cincremental customers\u201d) we can obtain by targeting a particular fraction of the population, in this way.", "This idea underlies the cumulative gain chart. The formula for cumulative gain is given by Gutierrez and Gerardy (2016) as:", "where Y\u1d40 is the cumulative sum of conversions in each bin of the treatment group, starting with the highest score bin and proceeding down, and N\u1d40 is the cumulative number of customers found in the same way; Y^C and N^C are similar cumulative sums for the control group. Cumulative gain effectively measures the cumulative uplift in probability of conversion, starting with the highest bin, and multiplies by the number of total customers in both treatment and control groups, to estimate the number of additional conversions that would occur if that number of customers were targeted.", "To get the data for the cumulative gain chart, we will need to calculate the amount of customers in each score quantile bin, both in the treatment and control groups (we visualized this above but will recalculate it here) and also the sum of converted customers. Here we\u2019ll flip the result upside down with .iloc[::-1] to simulate the strategy of targeting the customers with highest uplift scores first, and proceeding down from there.", "Here is how the treatment group looks, for example:", "And the cumulative sums of conversions and total customers:", "Putting all this together into the formula for cumulative gain shown above, we have:", "We can now examine and plot the cumulative gain.", "Cumulative gain gives another way to look at the potential impact of an uplift model-guided strategy. If we offer the treatment to every customer, we\u2019ll increase the number of converted customers by 248. However we can achieve a gain of 149 customers, about 60% of the maximum possible, by only offering treatment to the top 30% of customers (top 3 deciles), by uplift score. This is because as we move down the list, we\u2019re targeting customers with lower predicted individual treatment effect. The cumulative number of conversions may even go down from bin to bin, in the lower-valued bins of the chart, as we actually lose customers by targeting sleeping dogs.", "The various charts above are all informative and intuitive ways to understand the performance of an uplift model, however they don\u2019t immediately lead to model performance metrics, by which different modeling approaches might be compared. In order to make this leap, the idea of cumulative gain can be generalized to a curve, in a similar way to how the receiver operating characteristic (ROC) curve is used to evaluate binary classifiers. To get an ROC curve, true positive rates and false positive rates are calculated as the threshold for positive classification is successively raised to include more and more instances in a data set, until all are included. By comparison, a cumulative gain curve measures the cumulative gain in conversions, as defined above, in the targeted population as more and more people are targeted according to descending uplift score, until all are targeted.", "The gain curve is defined as", "where t is the index of the customer, starting from the highest uplift score and proceeding down, and the other variables are defined similarly to the previous equation.", "The gain curve calculation is available as part of the CausalML package, where it is called the uplift curve (CausalML). It can also be calculated fairly quickly in pandas. The first step is sorting on uplift score:", "On to this DataFrame, we add a few columns which will make the calculation of the curve easier, following the notation in the equations above.", "Now the calculation of the gain curve can be done as follows:", "The gain curve looks fairly similar to how the gain chart above would look (if it were turned on its side), just more continuous, and largely tells the same story. One advantage of the curve, however, is that similar to the ROC curve, we can calculate an area under the curve, with the interpretation that larger areas mean a more performant model: we would like to be able to gain as many customers as possible, by targeting a few as possible. If we had perfect knowledge of who would respond positively to treatment, we would treat only those who would, and the gain curve as plotted above would have a slope of one initially, before leveling off and potentially declining if there were sleeping dogs. This would lead to a gain curve with a steep initial slope, that stayed high as long as possible, resulting in a large area under the curve.", "Before calculating an AUC, it can be beneficial to normalize the data. As shown, the gain curve has units of customers on both the x- and y-axes. This can be good for visualizing things in terms of real-world quantities. However, if we wanted to assess performance on validation and test sets, for example, the areas under these curves may not be comparable as these datasets may have different numbers of observations. We can remedy this by scaling the curve so that both the x- and y-axes have a maximum of 1.", "The scaled x-axis represents the fraction of the population targeted:", "And the scaled y-axis is the fraction of gain from treating the entire population:", "Note the first entry in the normalized gain curve is NaN; there will always be at least one of these at the beginning because either N^T_t or N^C_t will be zero for at least the first observation, leading to a divide by zero error. So we'll drop entries from both the x and y vectors here to get rid of NaN s, which shouldn't be an issue if the data set is large enough.", "Now we can plot the normalized gain curve, along with a computed AUC. To this, we\u2019ll add a one-one line. Similar to the interpretation of a one-one line on an ROC curve, here this corresponds to the gain curve we\u2019d theoretically expect by treating customers at random: the fraction of the gain we would get by treating all customers increases according to the fraction treated and the ATE.", "Notice that, unlike an ROC curve, the gain curve can actually exceed 1.0 on the y-axis. This is because we may be able to gain more customers than the number we\u2019d get by treating everyone, if we can avoid some sleeping dogs.", "The AUC calculated here gives a general way to compare uplift model performance across different models and data sets, such as the training, validation, and testing sets for a given application. Normalized gain curves can be plotted together and have their AUCs compared in the same way ROC AUCs are compared for supervised classification problems. The interested reader may wish to develop a T-Learner model and compare with the S-Learner results shown here as an exercise.", "The goal of uplift modeling is to create predictive models of the individual treatment effect. Such models allow data scientists to segment populations into groups that are more likely to respond to treatment, and those that are less so. With this goal, a variety of modeling techniques have been developed; uplift modeling continues to receive active research interest. The evaluation of uplift models is not as straightforward as that of supervised classification or regression models because it requires separate consideration, and comparison, of treatment and control groups. However, open source Python packages (CausalML, Pylift) have been created to facilitate uplift model development and evaluation. Several useful uplift evaluation techniques, some of which are available in those packages, were demonstrated here using Python and pandas.", "Thanks for reading! If you\u2019re interested in using uplift modeling to address a business use case, including considerations of financial impact, model explainability, and monitoring in production, please see my follow up post Helping Late Borrowers Repay with Uplift Modeling at Tala.", "Thanks to Pierre Gutierrez and Robert Yi for your input and feedback", "CausalML: a Python package that provides a suite of uplift modeling and causal inference methods using machine learning algorithms based on recent research. Accessed 7/5/2020.", "Gutierrez, Pierre and Jean-Yves Gerardy, 2016. Causal Inference and Uplift Modeling: A review of the literature. JMLR: Workshop and Conference Proceedings 67:1\u201313.", "Lee, Taiyeong et al., 2013 Incremental Response Modeling Using SAS Enterprise Miner. SAS Global Forum 2013: Data Mining and Text Analytics.", "Pylift: an uplift library that provides, primarily, (1) fast uplift modeling implementations and (2) evaluation tools. Accessed 7/5/2020.", "Zhao, Zhenyu et al., 2020. Feature Selection Methods for Uplift Modeling.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist, PhD, and author of Data Science Projects with Python. https://www.steveklosterman.com/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9913ddf62c1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://steve-klosterman.medium.com/?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": ""}, {"url": "https://steve-klosterman.medium.com/?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "Steve Klosterman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F20266e1c64db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&user=Steve+Klosterman&userId=20266e1c64db&source=post_page-20266e1c64db----9913ddf62c1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9913ddf62c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9913ddf62c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/photos/space-shuttle-rocket-lift-off-774/", "anchor_text": "Pixabay"}, {"url": "https://github.com/klostest/uplift_modeling/blob/master/uplift-modeling.ipynb", "anchor_text": "here on Github"}, {"url": "https://blogs.oracle.com/datascience/data-driven-debt-collection-using-machine-learning-and-predictive-analytics", "anchor_text": "debt collection"}, {"url": "https://go.forrester.com/blogs/13-06-27-how_the_obama_campaign_used_predictive_analytics_to_influence_voters/", "anchor_text": "political campaigns"}, {"url": "https://pixabay.com/images/id-2115485/", "anchor_text": "Pixabay"}, {"url": "https://zenodo.org/record/3653141#.XwEVz5NKjYU", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/helping-late-borrowers-repay-with-uplift-modeling-at-tala-a1541aceffe4", "anchor_text": "Helping Late Borrowers Repay with Uplift Modeling at Tala"}, {"url": "https://causalml.readthedocs.io/en/latest/about.html", "anchor_text": "CausalML: a Python package that provides a suite of uplift modeling and causal inference methods using machine learning algorithms based on recent research. Accessed 7/5/2020."}, {"url": "http://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf", "anchor_text": "Gutierrez, Pierre and Jean-Yves Gerardy, 2016. Causal Inference and Uplift Modeling: A review of the literature. JMLR: Workshop and Conference Proceedings 67:1\u201313."}, {"url": "https://www.pnas.org/content/116/10/4156", "anchor_text": "Kunzel, Soren R. et al., 2019. Metalearners for estimating heterogeneous treatment effects using maching learning. PNAS March 5, 2019 115 (10) 4156\u20134165"}, {"url": "https://support.sas.com/resources/papers/proceedings13/096-2013.pdf", "anchor_text": "Lee, Taiyeong et al., 2013 Incremental Response Modeling Using SAS Enterprise Miner. SAS Global Forum 2013: Data Mining and Text Analytics."}, {"url": "https://pylift.readthedocs.io/en/latest/", "anchor_text": "Pylift: an uplift library that provides, primarily, (1) fast uplift modeling implementations and (2) evaluation tools. Accessed 7/5/2020."}, {"url": "https://tech.wayfair.com/data-science/2018/10/pylift-a-fast-python-package-for-uplift-modeling", "anchor_text": "Yi, Robert and Will Frost, 2018. Pylift: A Fast Python Package for Uplift Modeling. Accessed 7/5/2020."}, {"url": "https://arxiv.org/abs/2005.03447", "anchor_text": "Zhao, Zhenyu et al., 2020. Feature Selection Methods for Uplift Modeling."}, {"url": "https://www.steveklosterman.com/uplift-modeling/", "anchor_text": "https://www.steveklosterman.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9913ddf62c1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9913ddf62c1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/causal-inference?source=post_page-----9913ddf62c1---------------causal_inference-----------------", "anchor_text": "Causal Inference"}, {"url": "https://medium.com/tag/statistics?source=post_page-----9913ddf62c1---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/python?source=post_page-----9913ddf62c1---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9913ddf62c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&user=Steve+Klosterman&userId=20266e1c64db&source=-----9913ddf62c1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9913ddf62c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&user=Steve+Klosterman&userId=20266e1c64db&source=-----9913ddf62c1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9913ddf62c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9913ddf62c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9913ddf62c1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9913ddf62c1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9913ddf62c1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9913ddf62c1--------------------------------", "anchor_text": ""}, {"url": "https://steve-klosterman.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://steve-klosterman.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Steve Klosterman"}, {"url": "https://steve-klosterman.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "69 Followers"}, {"url": "https://www.steveklosterman.com/", "anchor_text": "https://www.steveklosterman.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F20266e1c64db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&user=Steve+Klosterman&userId=20266e1c64db&source=post_page-20266e1c64db--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F20266e1c64db%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupercharging-customer-touchpoints-with-uplift-modeling-9913ddf62c1&user=Steve+Klosterman&userId=20266e1c64db&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}