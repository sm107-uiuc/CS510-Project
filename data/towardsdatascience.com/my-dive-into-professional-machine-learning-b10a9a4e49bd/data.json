{"url": "https://towardsdatascience.com/my-dive-into-professional-machine-learning-b10a9a4e49bd", "time": 1683013656.029305, "path": "towardsdatascience.com/my-dive-into-professional-machine-learning-b10a9a4e49bd/", "webpage": {"metadata": {"title": "My Dive into Professional Machine Learning | by Jack McCumber | Towards Data Science", "h1": "My Dive into Professional Machine Learning", "description": "I finished up my internship about a month back. The experience itself was hugely rewarding and the people on my team that I had the pleasure of working with will be lifelong mentors. Now that the\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["I finished up my internship about a month back. The experience itself was hugely rewarding and the people on my team that I had the pleasure of working with will be lifelong mentors. Now that the project is finished, I wanted to reflect on the experience candidly and shed some light on what it was like going from hobbyist tinkerer to developing machine learning models in a professional environment.", "My role was an Artificial Intelligence Intern for SPIE, a not-for-profit company in Bellingham, Washington where I was completing my undergraduate degree in MIS/Analytics. SPIE publishes research journals and other literature related to the study of photonics, along with hosting academic conferences throughout the year where researchers present new findings. When I joined, SPIE was just beginning to dip their toes into using machine learning to improve their business and needed to see what was possible using new technologies. Besides myself, the only other active member in developing the pipeline was a professor I had for a text mining class in the previous quarter. From my understanding, SPIE reached out to them to see if they knew of any students who would be interested in being part of a unique project that would eventually become the internship. I had written to my professor at the end of the quarter to see if he knew of opportunities for jobs to pursue after graduation, and this happened to fall into his lap at the right time.", "SPIE\u2019s goal for this project was to predict the success of a paper that a researcher submitted to a digital library. Using this prediction, they were hoping to be more efficient in using their resources on services related to these presentations, like translating the paper and getting a video of the presentation transcribed. These tasks have to be completed manually by people with domain experience due to the complex nature of the content (dense research papers).", "There were two datasets that I was working with during the project:", "Presentation Data \u2014 Condensed database of ~2 million research papers from the SPIE library. This dataset contained 101 features ranging from simple date features detailing when the paper was submitted to hierarchal information about what conference/sub-conference/symposium the paper was presented at. Also included in the dataset was attendance data detailing the number of participants that came to a given presentation. The result-set in the data showed the downloads for a given year dating back to 2015. So for each paper, there were five columns of data from 2015 through 2019 and how many time the paper was downloads from SPIE\u2019s digital library that year.", "Taxon Data \u2014 SPIE invested in creating a taxonomy that tied each paper to certain topics. When a researcher published their paper to the digital library, an automated system recommended what tags should be associated with the paper to make it easier for people to search for it. If the system recommended the correct tags, it was included in the document. The process also allowed for researchers to enter-in their own tags, which are also represented in the data. This document only had 5 features of which only three were of use.", "The project was capped at 20 hours/week, but given that I was taking 19 credits and it was my last semester at college, most weeks I probably worked 12\u201317 hours on the project and billed the hours accordingly. As far as compensation, I was offered the choice of either working as an independent contractor for $23/hour or being an official SPIE employee for $21.05/hour; I chose the latter because I thought the title of \u201cArtificial Intelligence Intern\u201d would be an attention grabber when future potential employers looked at my resum\u00e9. The project lasted from February 2020 through August 2020 and was fully remote except for a preliminary onsite visit. I typically prefer working in an office environment, but the remote nature of the internship ended up being beneficial with COVID-19 going into full-swing a month after I started.", "I could go into a lot of the specific packages we used for every part of the project, but I think the tools people use aren\u2019t always as important as they\u2019re made out to be. As long as you know what you\u2019re doing and you can get where you want to go, I always favor the path of least resistance.", "During the first month of the project, I acquired the data and had to clean it. My first roadblock was actually looking at it. I was still new to Pandas at the time and the file sizes I was working with were massive. I spent an entire day trying to figure out what parameters would allow me to use their custom encoding and delimiters, but I eventually had to ask for help from one of my previous professors. Once I got past this, I began to explore the data. I reached out to another member of the team with more domain knowledge and really had to put in the work to be able to understand how the underlying organization of the data would contribute to the goal. During this stage, I also developed a pipeline for how I saw the project progressing and why each step would be warranted in the chain. We also decided on how the data would be trimmed, split, and tested. There were some issues with data fidelity (downloads are only given for the year as opposed to monthly or daily) as well as an issue with corruption of attendance data, so we had to find some workaround. We settled on advancing with about 40 features from the original presentation dataset and decided to use the download data as the dependent variable for the predictions.", "During the second stage, the primary activity was engineering new features. One of our first ideas was to use a version of forward-chaining to see how the performance of topics in previous years could be used to predict the popularity of other papers of that topic later on. This approach essentially tried to track the momentum of certain subjects. We also used an unsupervised approach to cluster the taxons into their natural domains which turned out to be one of the most significant predictors of success. Other than this, we used a random forest approach based on the mix of categorical and numerical variables.", "Because the initial dataset was so large, we always ran tests on randomly seeded subsets of data. We used standard parameters for training/testing/validation where, for instance, we used 20% for testing and 80% for training. This was one of the most frustrating parts of the test because the issues of bias and variance highlighted some earlier mistakes we had made. We had to tweak settings for about a week before we felt happy with the way the model was setup and confident that it would perform well in the worst-case scenarios. We used forward chaining in the project to train the data on earlier papers and used the later years as testing data. For example, if a paper was published in 2018, we used 2015\u20132017 to train the model and judged the accuracy based on 2018. This was a beneficial step, but not entirely in-line with the business question of predicting the performance of new papers. We ended up scrapping this approach for the decision tree portion and using it only in the LDA sub-model. During this stage, we also presented our findings to the executive committee where we answered some of the questions they had about the characteristics that make a research paper popular and showed them how we got there.", "Up until this point, we were developing the pipeline in sections. Because there were so many individual components that were being treated in specific ways, the model was somewhat siloed. Certain parts required more preprocessing while other just waited for them to finish. I think we could have saved some effort on this stage if we had spent more time planning in the beginning, but I was still very new to professional data science work and might not have had the wisdom to actually make that happen. The model was going to be deployed on Azure, but we later found out that the deprecation of Jupyter Notebooks on the platform conflicted with the process we intended to use. Unfortunately, this meant that I didn\u2019t get to see the model get deployed because my internship was wrapping up, but I believe we put in enough work to make the model fairly straightforward for the team to deploy it in the future. One of the more interesting parts of stitching my code together during this time was see my improvement over the course of this project. Reviewing everything I had written line-by-line (in all, about 2,000 lines) made me feel, for lack of a better word, nostalgic.", "I also just wanted to note new things I learned along the way and what changed over the course of the project.", "Overall, I would call the project successful based on the fact that the data was accurate at predicting the future popularity of papers with significant confidence.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb10a9a4e49bd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@thejackmccumber?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thejackmccumber?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "Jack McCumber"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbcbc0ea9ebcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&user=Jack+McCumber&userId=bcbc0ea9ebcf&source=post_page-bcbc0ea9ebcf----b10a9a4e49bd---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb10a9a4e49bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb10a9a4e49bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b10a9a4e49bd---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b10a9a4e49bd---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b10a9a4e49bd---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/ai?source=post_page-----b10a9a4e49bd---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/intern?source=post_page-----b10a9a4e49bd---------------intern-----------------", "anchor_text": "Intern"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb10a9a4e49bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&user=Jack+McCumber&userId=bcbc0ea9ebcf&source=-----b10a9a4e49bd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb10a9a4e49bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&user=Jack+McCumber&userId=bcbc0ea9ebcf&source=-----b10a9a4e49bd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb10a9a4e49bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb10a9a4e49bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b10a9a4e49bd---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b10a9a4e49bd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thejackmccumber?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thejackmccumber?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jack McCumber"}, {"url": "https://medium.com/@thejackmccumber/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "5 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbcbc0ea9ebcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&user=Jack+McCumber&userId=bcbc0ea9ebcf&source=post_page-bcbc0ea9ebcf--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fbcbc0ea9ebcf%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmy-dive-into-professional-machine-learning-b10a9a4e49bd&user=Jack+McCumber&userId=bcbc0ea9ebcf&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}