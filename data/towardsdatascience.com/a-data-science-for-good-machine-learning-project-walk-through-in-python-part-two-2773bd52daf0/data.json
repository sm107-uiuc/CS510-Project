{"url": "https://towardsdatascience.com/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0", "time": 1682993619.997407, "path": "towardsdatascience.com/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0/", "webpage": {"metadata": {"title": "A \u201cData Science for Good\u201d Machine Learning Project Walk-Through in Python: Part Two | by Will Koehrsen | Towards Data Science", "h1": "A \u201cData Science for Good\u201d Machine Learning Project Walk-Through in Python: Part Two", "description": "Machine learning is a powerful framework that from the outside may look complex and intimidating. However, once we break down a problem into its component steps, we see that machine learning is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@williamkoehrsen/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one-1977dd701dbc", "anchor_text": "first half of this series", "paragraph_index": 1}, {"url": "https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough", "anchor_text": "Jupyter Notebook both on Kaggle", "paragraph_index": 3}, {"url": "https://github.com/WillKoehrsen/data-science-for-good/blob/master/costa-rican-poverty/A%20Complete%20Walkthrough.ipynb", "anchor_text": "on GitHub", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74", "anchor_text": "as tuning", "paragraph_index": 4}, {"url": "https://github.com/hyperopt/hyperopt", "anchor_text": "Hyperopt library", "paragraph_index": 6}, {"url": "https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf", "anchor_text": "Tree Parzen Estimator", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f", "anchor_text": "conceptual explanation here", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a", "anchor_text": "article for using Hyperopt for model tuning here", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/shallow-understanding-on-bayesian-optimization-324b6c1f7083", "anchor_text": "Bayesian Optimization", "paragraph_index": 8}, {"url": "https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf", "anchor_text": "return to hyperparameter tuning is much less than the return to feature engineering", "paragraph_index": 13}, {"url": "https://www.kaggle.com/c/costa-rican-household-poverty-prediction/leaderboard", "anchor_text": "leaderboard", "paragraph_index": 13}, {"url": "https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa", "anchor_text": "slightly less performant model if it is simpler", "paragraph_index": 16}, {"url": "http://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/", "anchor_text": "overfitting to the testing data", "paragraph_index": 17}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "black box of machine learning", "paragraph_index": 25}, {"url": "http://danielhomola.com/wp-content/uploads/2018/03/DanielHomola_PhdThesis_final.pdf", "anchor_text": "sum total reduction in gini impurity for nodes split", "paragraph_index": 26}, {"url": "https://poverty.ucdavis.edu/faq/how-does-family-structure-relate-poverty", "anchor_text": "family size is correlated to more extreme poverty", "paragraph_index": 27}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.201.8131&rep=rep1&type=pdf#page=14", "anchor_text": "education level is inversely correlated with poverty", "paragraph_index": 27}, {"url": "https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/", "anchor_text": "confusion matrix", "paragraph_index": 29}, {"url": "https://weaponsofmathdestructionbook.com/", "anchor_text": "Weapons of Math Destruction", "paragraph_index": 31}, {"url": "https://research.google.com/pubs/archive/35179.pdf", "anchor_text": "greater quantities of high-quality labeled data", "paragraph_index": 33}, {"url": "https://homes.cs.washington.edu/~marcotcr/blog/lime/", "anchor_text": "Local Interpretable Model-agnostic Explainer (LIME)", "paragraph_index": 34}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html", "anchor_text": "Scikit-Learn\u2019s RFECV method", "paragraph_index": 39}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html", "anchor_text": "make a custom scoring metric", "paragraph_index": 39}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "fit into a", "paragraph_index": 41}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "Pipeline", "paragraph_index": 41}, {"url": "http://scikit-learn.org/stable/modules/unsupervised_reduction.html", "anchor_text": "number of unsupervised methods", "paragraph_index": 42}, {"url": "https://stats.stackexchange.com/questions/263539/clustering-on-the-output-of-t-sne", "anchor_text": "t-SNE (t-Distributed Stochastic Neighbors Embedding) are used only for visualization", "paragraph_index": 43}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "UMAP: Uniform Manifold Approximation and Projection", "paragraph_index": 44}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "used like an Scikit-Learn method with a", "paragraph_index": 44}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "fit", "paragraph_index": 44}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "and", "paragraph_index": 44}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "transform", "paragraph_index": 44}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "call", "paragraph_index": 44}, {"url": "https://www.kaggle.com/mlisovyi/cluster-analysis-tsne-mds-isomap", "anchor_text": "findings of other data scientists", "paragraph_index": 47}, {"url": "https://www.kaggle.com/c/costa-rican-household-poverty-prediction/kernels", "anchor_text": "other data scientists\u2019 notebooks", "paragraph_index": 54}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "ImageNet Large Scale Visual Recognition Challenge", "paragraph_index": 56}, {"url": "https://medium.com/@williamkoehrsen/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one-1977dd701dbc", "anchor_text": "part one", "paragraph_index": 59}, {"url": "http://twitter.com/koehrsen_will", "anchor_text": "@koehrsen_will", "paragraph_index": 62}], "all_paragraphs": ["Machine learning is a powerful framework that from the outside may look complex and intimidating. However, once we break down a problem into its component steps, we see that machine learning is really only a sequence of understandable processes, each one simple by itself.", "In the first half of this series, we saw how we could implement a solution to a \u201cdata science for good\u201d machine learning problem, leaving off after we had selected the Gradient Boosting Machine as our model of choice.", "In this article, we\u2019ll continue with our pipeline for predicting poverty in Costa Rica, performing model optimizing, interpreting the model, and trying out some experimental techniques.", "The full code is available as a Jupyter Notebook both on Kaggle (where it can be run in the browser with no downloads required) and on GitHub. This is an active Kaggle competition and a great project to get started with machine learning or to work on some new skills.", "Model optimization means searching for the model hyperparameters that yield the best performance \u2014 measured in cross-validation \u2014 for a given dataset. Because the optimal hyperparameters vary depending on the data, we have to optimize \u2014 also known as tuning \u2014 the model for our data. I like to think of tuning as finding the best settings for a machine learning model.", "There are 4 main methods for tuning, ranked from least efficient (manual) to most efficient (automated).", "Naturally, we\u2019ll skip the first three methods and move right to the most efficient: automated hyperparameter tuning. For this implementation, we can use the Hyperopt library, which does optimization using a version of Bayesian Optimization with the Tree Parzen Estimator. You don\u2019t need to understand these terms to use the model, although I did write a conceptual explanation here. (I also wrote an article for using Hyperopt for model tuning here.)", "The details are a little protracted (see the notebook), but we need 4 parts for implementing Bayesian Optimization in Hyperopt", "The basic idea of Bayesian Optimization (BO) is that the algorithm reasons from the past results \u2014 how well previous hyperparameters have scored \u2014 and then chooses the next combination of values it thinks will do best. Grid or random search are uninformed methods that don\u2019t use past results and the idea is that by reasoning, BO can find better values in fewer search iterations.", "See the notebook for the complete implementation, but below are the optimization scores plotted over 100 search iterations.", "Unlike in random search where the scores are, well random over time, in Bayesian Optimization, the scores tend to improve over time as the algorithm learns a probability model of the best hyperparameters. The idea of Bayesian Optimization is that we can optimize our model (or any function) quicker by focusing the search on promising settings. Once the optimization has finished running, we can use the best hyperparameters to cross validate the model.", "Optimizing the model will not always improve our test score because we are optimizing for the training data. However, sometimes it can deliver a large benefit compared to the default hyperparameters. In this case, the final cross validation results are shown below in dataframe form:", "The optimized model (denoted by OPT and using 10 cross validation folds with the features after selection) places right in the middle of the non-optimized variations of the Gradient Boosting Machine (which used hyperparameters I had found worked well for previous problems.) This indicates we haven\u2019t found the optimal hyperparameters yet, or there could be multiple sets of hyperparameters that performly roughly the same.", "We can continue optimization to try and find even better hyperparameters, but usually the return to hyperparameter tuning is much less than the return to feature engineering. At this point we have a relatively high-performing model and we can use this model to make predictions on the test data. Then, since this is a Kaggle competition, we can submit the predictions to the leaderboard. Doing this gets us into the top 50 (at the moment) which is a nice vindication of all our hard work!", "At this point, we have implemented a complete solution to this machine learning problem. Our model can make reasonably accurate predictions of poverty in Costa Rican households (the F1 score is relatively low, but this is a difficult problem). Now, we can move on to interpreting our predictions and see if our model can teach us anything about the problem. Even though we have a solution, we don\u2019t want to lose sight of why our solution matters.", "The very nature of machine learning competitions can encourage bad practices, such as the mistake of optimizing for the leaderboard score at the cost of all other considerations. Generally this leads to using ever more complex models to eke out a tiny performance gain.", "In the real-world, above a certain threshold \u2014 which depends on the application \u2014 accuracy becomes secondary to explainability, and you\u2019re better off with a slightly less performant model if it is simpler.", "A simple model that is put in use is better than a complex model which can never be deployed. Moreover, those at the top of the leaderboard are probably overfitting to the testing data and do not have a robust model.", "A good strategy for getting the most out of Kaggle is to work at a problem until you have a reasonably good solution \u2014 say 90% of the top leaderboard scores \u2014 and then not stress about getting to the very top. Competing is fun, but learning is the most valuable aspect of taking on these projects.", "In the midst of writing all the machine learning code, it can be easy to lose sight of the important questions: what are we making this model for? What will be the impact of our predictions? Thankfully, our answer this time isn\u2019t \u201cincreasing ad revenue\u201d but, instead, effectively predicting which households are most at risk for poverty in Costa Rica so they can receive needed help.", "To try and get a sense of our model\u2019s output, we can examine the prediction of poverty levels on a household basis for the test data. For the test data, we don\u2019t know the true answers, but we can compare the relative frequency of each predicted class with that in the training labels. The image below shows the training distribution of poverty on the left, and the predicted distribution for the testing data on the right:", "Intriguingly, even though the label \u201cnot vulnerable\u201d is most prevalent in the training data, it is represented less often on a relative basis for the predictions. Our model predicts a higher proportion of the other 3 classes, which means that it thinks there is more severe poverty in the testing data. If we convert these fractions to numbers, we have 3929 households in the \u201cnon vulnerable\u201d category and 771 households in the \u201cextreme\u201d category.", "Another way to look at the predictions is by the confidence of the model. For each prediction on the test data, we can see not only the label, but also the probability given to it by the model. Let\u2019s take a look at the confidence by the value of the label in a boxplot.", "These results are fairly intuitive \u2014 our model is most confident in the most extreme predictions \u2014 and less confident in the moderate ones. Theoretically, there should be more separation between the most extreme labels and the targets in the middle should be more difficult to tease apart.", "Another point to draw from this graph is that overall, our model is not very sure of the predictions. A guess with no data would place 0.25 probability on each class, and we can see that even for the least extreme poverty, our model rarely has more than 40% confidence. What this tells us is this is a tough problem \u2014 there is not much to separate the classes in the available data.", "Ideally, these predictions, or those from the winning model in the competition, will be used to determine which families are most likely to need assistance. However, just the predictions alone do not tell us what may lead to the poverty or how our model \u201cthinks\u201d. While we can\u2019t completely solve this problem yet, we can try to peer into the black box of machine learning.", "In a tree-based model \u2014 such as the Gradient Boosting Machine \u2014 the feature importances represent the sum total reduction in gini impurity for nodes split on a feature. I never find the absolute values very helpful, but instead normalize the numbers and look at them on a relative basis. For example, below are the 10 most important features from the optimized GBM model.", "Here we can see education and ages of family members making up the bulk of the most important features. Looking further into the importances, we also see the size of the family. This echoes findings by poverty researchers: family size is correlated to more extreme poverty, and education level is inversely correlated with poverty. In both cases, we don\u2019t necessarily know which causes which, but we can use this information to highlight which factors should be further studied. Hopefully, this data can then be used to further reduce poverty (which has been decreasing steadily for the last 25 years).", "In addition to potentially helping researchers, we can use the feature importances for further feature engineering by trying to build more features on top of these. An example using the above results would be taking the meaneduc and dividing by the dependency to create a new feature. While this may not be intuitive, it\u2019s hard to tell ahead of time what will work for a model.", "An alternative method to using the testing data to examine our model is to split the training data into a smaller training set and a validation set. Because we have the labels for all the training data, we can compare our predictions on the holdout validation data to the true values. For example, using 1000 observations for validation, we get the following confusion matrix:", "The values on the diagonal are those the model predicted correctly because the predicted label is the same as the true label. Anything off the diagonal the model predicted incorrectly. We can see that our model is the best at identifying the non-vulnerable households, but is not very good at discerning the other labels.", "As one example, our model incorrectly classifies 18 households as non-vulnerable which are in fact in extreme poverty. Predictions like these have real-world consequences because those might be families that as a result of this model, would not receive help. (For more on the consequences of incorrect algorithms, see Weapons of Math Destruction.)", "Overall, this mediocre performance \u2014 the model accuracy is about 60% which is much better than random guessing but not exceptional \u2014 suggests this problem may be difficult. It could be there is not enough information to separate the classes within the available data.", "One recommendation for the host organization \u2014 the Inter-American Development Bank \u2014 is that we need more data to better solve this problem. That could come either in the form of more features \u2014 so more questions on the survey \u2014 or more observations \u2014 a greater number of households surveyed. Either of these would require a significant effort, but the best return to time invested in a data science project is generally by gathering greater quantities of high-quality labeled data.", "There are other methods we can use for model understanding, such as Local Interpretable Model-agnostic Explainer (LIME), which uses a simpler linear model to approximate the model around a prediction. We can also look at individual decision trees in a forest which are typically straightforward to parse because they essentially mimic a human decision making process.", "Overall, machine learning still suffers from an explainability gap, which hinders its applicability: people want not only accurate predictions, but an understanding of how those predictions were generated.", "We\u2019ve already solved the machine learning problem with a standard toolbox, so why go further into exploratory techniques? Well, if you\u2019re like me, then you enjoy learning new things just for the sake of learning. What\u2019s more, the exploratory techniques of today will be the standard tools of tomorrow.", "For this project, I decided to try out two new (to me) techniques:", "Recursive feature elimination is a method for feature selection that uses a model\u2019s feature importances \u2014 a random forest for this application \u2014 to select features. The process is a repeated method: at each iteration, the least important features are removed. The optimal number of features to keep is determined by cross validation on the training data.", "Recursive feature elimination is simple to use with Scikit-Learn\u2019s RFECV method. This method builds on an estimator (a model) and then is fit like any other Scikit-Learn method. The scorer part is required in order to make a custom scoring metric using the Macro F1 score.", "While I\u2019ve used feature importances for selection before, I\u2019d never implemented the Recursive Feature Elimination method, and as usual, was pleasantly surprised at how easy this was to do in Python. The RFECV method selected 58 out of around 190 features based on the cross validation scores:", "The selected set of features were then tried out to compare the cross validation performance with the original set of features. (The final results are presented after the next section). Given the ease of using this method, I think it\u2019s a good tool to have in your skill set for modeling. Like any other Scikit-Learn operation, it can fit into a Pipeline, allowing you to quickly execute a complete series of preprocessing and modeling operations.", "There are a number of unsupervised methods in machine learning for dimension reduction. These fall into two general categories:", "Typically, PCA (Principal Components Analysis) and ICA (Independent Components Analysis) are used both for visualization and as a preprocessing step for machine learning, while manifold methods like t-SNE (t-Distributed Stochastic Neighbors Embedding) are used only for visualization because they are highly dependent on hyperparameters and do not preserve distances within the data. (In Scikit-Learn, the t-SNE implementation does not have a transform method which means we can\u2019t use it for modeling).", "A new entry on the dimension reduction scene is UMAP: Uniform Manifold Approximation and Projection. It aims to map the data to a low-dimensional manifold \u2014 so it\u2019s an embedding technique, while simultaneously preserving global structure in the data. Although the math behind it is rigorous, it can be used like an Scikit-Learn method with a fit and transform call.", "I wanted to try these methods for both dimension reduction for visualization, and to add the reduced components as additional features. While this use case might not be typical, there\u2019s no harm in experimenting! Below shows the code for using UMAP to create embeddings of both the train and testing data.", "The application of the other three methods is exactly the same (except TSNE which cannot be used to transform the testing data). After completing the transformations, we can visualize the reduced training features in 3 dimensions, with the points colored by the value of the target:", "None of the methods cleanly separates the data based on the label which follows the findings of other data scientists. As we discovered earlier, it may be that this problem is difficult considering the data to which we have access. Although these graphs cannot be used to say whether or not we can solve a problem, if there is a clean separation, then it indicates that there is something in the data that would allow a model to easily discern each class.", "As a final step, we can add the reduced features to the set of features after applying feature selection to see if they are useful for modeling. (Usually dimension reduction is applied and then the model is trained on just the reduced dimensions). The performance of every single model is shown below:", "The model using the dimension reduction features has the suffix DR while the number of folds following the GBM refers to the number of cross validation folds. Overall, we can see that the selected set of features (SEL) does slightly better, and adding in the dimension reduction features hurts the model performance! It\u2019s difficult to conclude too much from these results given the large standard deviations, but we can say that the Gradient Boosting Machine significantly outperforms all other models and the feature selection process improves the cross validation performance.", "The experimental part of this notebook was probably the most enjoyable for me. It\u2019s not only important to always be learning to stay ahead in the data science field, but it\u2019s also enjoyable for the sake of learning something new.", "The drive to constantly be improving and gaining new knowledge is a critical skill for a data scientist.", "Despite this exhaustive coverage of machine learning tools, we have not yet reached the end of methods to apply to this problem!", "Some additional steps we could take are:", "The great part about a Kaggle competition is you can read about many of these cutting-edge techniques in other data scientists\u2019 notebooks. Moreover, these contests give us realistic datasets in a non-mission-critical setting, which is a perfect environment for experimentation.", "The best contests can lead to new advances by encouraging friendly competition, open sharing of work, and rewarding innovative approaches.", "As one example of the ability of competitions to better machine learning methods, the ImageNet Large Scale Visual Recognition Challenge led to significant improvements in convolutional neural networks.", "Data science and machine learning are not incomprehensible methods: instead, they are sequences of straightforward steps that combine into a powerful solution. By walking through a problem one step at a time, we can learn how to build the entire framework. How we use this framework is ultimately up to us. We don\u2019t have to dedicate our lives to helping others, but it is rewarding to take on a challenge with a deeper meaning.", "In this article, we saw how we could apply a complete machine learning solution to a data science for good problem, building a machine learning model to predict poverty levels in Costa Rica.", "Our approach followed a sequence of processes (1\u20134 were in part one):", "Finally, if after all that you still haven\u2019t got your fill of data science, you can move on to exploratory techniques and learn something new!", "As with any process, you\u2019ll only improve as you practice. Competitions are valuable for the opportunities they provide us to employ and develop skills. Moveover, they encourage discussion, innovation, and collaboration, leading both to more capable individual data scientists and a better community. Through this data science project, we not only improve our skills, but also make an effort to improve outcomes for our fellow humans.", "As always, I welcome feedback, constructive criticism, and hearing about your data science projects. I can be reached on Twitter @koehrsen_will.", "Data Scientist at Cortex Intel, Data Science Communicator"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2773bd52daf0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://github.com/dconnolly/chromecast-backgrounds", "anchor_text": "Source"}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Will Koehrsen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9----2773bd52daf0---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2773bd52daf0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----2773bd52daf0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2773bd52daf0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&source=-----2773bd52daf0---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@williamkoehrsen/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one-1977dd701dbc", "anchor_text": "first half of this series"}, {"url": "https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough", "anchor_text": "Jupyter Notebook both on Kaggle"}, {"url": "https://github.com/WillKoehrsen/data-science-for-good/blob/master/costa-rican-poverty/A%20Complete%20Walkthrough.ipynb", "anchor_text": "on GitHub"}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74", "anchor_text": "as tuning"}, {"url": "https://github.com/hyperopt/hyperopt", "anchor_text": "Hyperopt library"}, {"url": "https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf", "anchor_text": "Tree Parzen Estimator"}, {"url": "https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f", "anchor_text": "conceptual explanation here"}, {"url": "https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a", "anchor_text": "article for using Hyperopt for model tuning here"}, {"url": "https://towardsdatascience.com/shallow-understanding-on-bayesian-optimization-324b6c1f7083", "anchor_text": "Bayesian Optimization"}, {"url": "https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf", "anchor_text": "return to hyperparameter tuning is much less than the return to feature engineering"}, {"url": "https://www.kaggle.com/c/costa-rican-household-poverty-prediction/leaderboard", "anchor_text": "leaderboard"}, {"url": "https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa", "anchor_text": "slightly less performant model if it is simpler"}, {"url": "http://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/", "anchor_text": "overfitting to the testing data"}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "black box of machine learning"}, {"url": "http://danielhomola.com/wp-content/uploads/2018/03/DanielHomola_PhdThesis_final.pdf", "anchor_text": "sum total reduction in gini impurity for nodes split"}, {"url": "https://poverty.ucdavis.edu/faq/how-does-family-structure-relate-poverty", "anchor_text": "family size is correlated to more extreme poverty"}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.201.8131&rep=rep1&type=pdf#page=14", "anchor_text": "education level is inversely correlated with poverty"}, {"url": "https://ourworldindata.org/extreme-poverty", "anchor_text": "source"}, {"url": "https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/", "anchor_text": "confusion matrix"}, {"url": "https://weaponsofmathdestructionbook.com/", "anchor_text": "Weapons of Math Destruction"}, {"url": "https://research.google.com/pubs/archive/35179.pdf", "anchor_text": "greater quantities of high-quality labeled data"}, {"url": "https://homes.cs.washington.edu/~marcotcr/blog/lime/", "anchor_text": "Local Interpretable Model-agnostic Explainer (LIME)"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV", "anchor_text": "Recursive Feature Elimination"}, {"url": "https://arxiv.org/pdf/1802.03426.pdf", "anchor_text": "Uniform Manifold Approximation and Projection"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html", "anchor_text": "Scikit-Learn\u2019s RFECV method"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html", "anchor_text": "make a custom scoring metric"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "fit into a"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "Pipeline"}, {"url": "http://scikit-learn.org/stable/modules/unsupervised_reduction.html", "anchor_text": "number of unsupervised methods"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA", "anchor_text": "PCA"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html", "anchor_text": "ICA"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html#sklearn.manifold.Isomap", "anchor_text": "IsoMap"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE", "anchor_text": "t-SNE"}, {"url": "https://stats.stackexchange.com/questions/263539/clustering-on-the-output-of-t-sne", "anchor_text": "t-SNE (t-Distributed Stochastic Neighbors Embedding) are used only for visualization"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "UMAP: Uniform Manifold Approximation and Projection"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "used like an Scikit-Learn method with a"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "fit"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "and"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "transform"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "call"}, {"url": "https://www.kaggle.com/mlisovyi/cluster-analysis-tsne-mds-isomap", "anchor_text": "findings of other data scientists"}, {"url": "https://www.kaggle.com/willkoehrsen/featuretools-for-good", "anchor_text": "this notebook"}, {"url": "http://contrib.scikit-learn.org/imbalanced-learn/stable/over_sampling.html", "anchor_text": "Oversampling the minority class"}, {"url": "http://scikit-learn.org/stable/modules/feature_selection.html", "anchor_text": "Further feature selection:"}, {"url": "http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/", "anchor_text": "Ensembling or stacking models"}, {"url": "https://www.kaggle.com/c/costa-rican-household-poverty-prediction/kernels", "anchor_text": "other data scientists\u2019 notebooks"}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "ImageNet Large Scale Visual Recognition Challenge"}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "Imagenet Competitions"}, {"url": "https://medium.com/@williamkoehrsen/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one-1977dd701dbc", "anchor_text": "part one"}, {"url": "http://twitter.com/koehrsen_will", "anchor_text": "@koehrsen_will"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2773bd52daf0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2773bd52daf0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/education?source=post_page-----2773bd52daf0---------------education-----------------", "anchor_text": "Education"}, {"url": "https://medium.com/tag/python?source=post_page-----2773bd52daf0---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----2773bd52daf0---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2773bd52daf0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----2773bd52daf0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2773bd52daf0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----2773bd52daf0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2773bd52daf0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9----2773bd52daf0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7d4a87a913e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&newsletterV3=e2f299e30cb9&newsletterV3Id=e7d4a87a913e&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----2773bd52daf0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Written by Will Koehrsen"}, {"url": "https://williamkoehrsen.medium.com/followers?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "38K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9----2773bd52daf0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7d4a87a913e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-data-science-for-good-machine-learning-project-walk-through-in-python-part-two-2773bd52daf0&newsletterV3=e2f299e30cb9&newsletterV3Id=e7d4a87a913e&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----2773bd52daf0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----2773bd52daf0----0---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----2773bd52daf0----0---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----2773bd52daf0----0---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Will Koehrsen"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2773bd52daf0----0---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----2773bd52daf0----0---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Hyperparameter Tuning the Random Forest in PythonImproving the Random Forest Part Two"}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----2773bd52daf0----0---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "12 min read\u00b7Jan 10, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F28d2aa77dd74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----28d2aa77dd74----0-----------------clap_footer----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----2773bd52daf0----0---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F28d2aa77dd74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&source=-----2773bd52daf0----0-----------------bookmark_preview----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2773bd52daf0----1---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2773bd52daf0----1---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2773bd52daf0----1---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2773bd52daf0----1---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2773bd52daf0----1---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2773bd52daf0----1---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2773bd52daf0----1---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----2773bd52daf0----1-----------------bookmark_preview----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2773bd52daf0----2---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----2773bd52daf0----2---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----2773bd52daf0----2---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2773bd52daf0----2---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2773bd52daf0----2---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2773bd52daf0----2---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2773bd52daf0----2---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----2773bd52daf0----2-----------------bookmark_preview----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----2773bd52daf0----3---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----2773bd52daf0----3---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----2773bd52daf0----3---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Will Koehrsen"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2773bd52daf0----3---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----2773bd52daf0----3---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "Random Forest in PythonA Practical End-to-End Machine Learning Example"}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----2773bd52daf0----3---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": "21 min read\u00b7Dec 27, 2017"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24d0893d51c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-in-python-24d0893d51c0&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----24d0893d51c0----3-----------------clap_footer----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----2773bd52daf0----3---------------------9b32c010_c0e4_4290_a333_1e95708c6f81-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "61"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24d0893d51c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-in-python-24d0893d51c0&source=-----2773bd52daf0----3-----------------bookmark_preview----9b32c010_c0e4_4290_a333_1e95708c6f81-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "See all from Will Koehrsen"}, {"url": "https://towardsdatascience.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----2773bd52daf0----0-----------------bookmark_preview----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----2773bd52daf0----1-----------------bookmark_preview----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Erdogan Taskesen"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "From Data to Clusters; When is Your Clustering Good Enough?Sensible clusters and hidden gems can be found using clustering approaches but you need the right cluster evaluation method!"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "\u00b717 min read\u00b75 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----5895440a978a----0-----------------clap_footer----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2773bd52daf0----0---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&source=-----2773bd52daf0----0-----------------bookmark_preview----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2773bd52daf0----1---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----2773bd52daf0----1-----------------bookmark_preview----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----2773bd52daf0----2---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----2773bd52daf0----2---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----2773bd52daf0----2---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----2773bd52daf0----2---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----2773bd52daf0----2---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----2773bd52daf0----2---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----2-----------------clap_footer----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----2773bd52daf0----2---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----2773bd52daf0----2-----------------bookmark_preview----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2773bd52daf0----3---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----2773bd52daf0----3---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----2773bd52daf0----3---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Albers Uzila"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----2773bd52daf0----3---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2773bd52daf0----3---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "Wanna Break into Data Science in 2023? Think Twice!It won\u2019t be smooth sailing for you"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2773bd52daf0----3---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": "\u00b711 min read\u00b7Dec 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&user=Albers+Uzila&userId=159e5ce51250&source=-----26842e9a87fe----3-----------------clap_footer----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2773bd52daf0----3---------------------4c5cde17_0d98_4738_be8f_6fcb866ff37e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&source=-----2773bd52daf0----3-----------------bookmark_preview----4c5cde17_0d98_4738_be8f_6fcb866ff37e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----2773bd52daf0--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}