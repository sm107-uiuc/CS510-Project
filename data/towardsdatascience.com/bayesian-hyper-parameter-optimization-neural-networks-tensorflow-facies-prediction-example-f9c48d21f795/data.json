{"url": "https://towardsdatascience.com/bayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795", "time": 1683012180.190717, "path": "towardsdatascience.com/bayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795/", "webpage": {"metadata": {"title": "Bayesian Hyper-Parameter Optimization: Neural Networks, TensorFlow, Facies Prediction Example | by Ryan A. Mardani | Towards Data Science", "h1": "Bayesian Hyper-Parameter Optimization: Neural Networks, TensorFlow, Facies Prediction Example", "description": "The purpose of this work is to optimize the neural network model hyper-parameters to estimate facies classes from well logs. I will include some codes in this paper but for a full jupyter notebook\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/mardani72/Hyper-Parameter_optimization", "anchor_text": "Github", "paragraph_index": 0}, {"url": "https://www.youtube.com/watch?v=RgO8BBNGB8w", "anchor_text": "Jeff Heaton", "paragraph_index": 1}, {"url": "https://scikit-optimize.github.io/stable/", "anchor_text": "Scikit-Optimize", "paragraph_index": 3}, {"url": "https://scikit-optimize.github.io/stable/user_guide.html", "anchor_text": "documentation", "paragraph_index": 4}, {"url": "https://github.com/mardani72/Facies-Classification-Machine-Learning/blob/master/Facies_Classification_Various_ML_Final.ipynb", "anchor_text": "here", "paragraph_index": 5}, {"url": "https://github.com/mardani72/Facies-Classification-Machine-Learning/blob/master/training_data.csv", "anchor_text": "here", "paragraph_index": 5}], "all_paragraphs": ["The purpose of this work is to optimize the neural network model hyper-parameters to estimate facies classes from well logs. I will include some codes in this paper but for a full jupyter notebook file, you can visit my Github.", "note: if you are new in TensorFlow, its installation elaborated by Jeff Heaton.", "In machine learning, model parameters can be divided into two main categories:1- Trainable parameters: such as weights in neural networks learned by training algorithms and the user does not interfere in the process,2- Hyper-parameters: users can set them before training operation such as learning rate or the number of dense layers in the model.Selecting the best hyper-parameters can be a tedious task if you try it by hand and it is almost impossible to find the best ones if you are dealing with more than two parameters.One way is to divide each parameter into a valid evenly range and then simply ask the computer to loop for the combination of parameters and calculate the results. The method is called Grid Search. Although it is done by machine, it will be a time-consuming process. Suppose you have 3 hyper-parameters with 10 possible values in each. In this approach, you will run 10\u00b3 neural network models (even with reasonable training datasets size, this task is huge).Another way is a random search approach. In fact, instead of using organized parameter searching, it will go through a random combination of parameters and look for the optimized ones. You may estimate that chance of success decreases to zero for larger hyper-parameter tunings.", "Scikit-Optimize, skopt, which we will use here to the facies estimation task, is a simple and efficient library to minimize expensive noisy black-box functions. Bayesian optimization constructs another model of search-space for parameters. Gaussian Process is one kind of these models. This generates an estimate of how model performance varies with hyper-parameter changes.", "As we see in the picture, the true objective function(red dash line) is surrounded by noise (red shade). The red line shows how scikit optimize sampled the search space for hyper-parameters(one dimension). Scikit-optimize fills the area between sample points with the Gaussian process (green line) and estimates true real fitness value. In the areas with low samples or lack(like the left side of the picture between two red samples), there is great uncertainty (big difference between red and green lines causing big uncertainty green shade area such as two standard deviations uncertainty).In this process, then we ask a new set of hyper-parameter to explore more search space. In the initial steps, it goes with sparse accuracy but in later iterations, it focuses on where sampling points are more with the good agreement of fitness function with true objective function(trough area in the graph).For more study, you may refer to Scikit Optimize documentation.", "Data ReviewThe Council Grove gas reservoir is located in Kansas. From this carbonate reservoir, nine wells are available. Facies are studied from core samples in every half foot and matched with logging data in well location. Feature variables include five from wireline log measurements and two geologic constraining variables that are derived from geologic knowledge. For more detail refer here. For the dataset, you may download it from here. The seven variables are:", "The nine discrete facies (classes of rocks) are:", "After reading the dataset into python, we can keep one well data as a blind set for future model performance examination. We also need to convert facies numbers into strings in the dataset. Refer to the full notebook.", "Feature EngineeringFacies classes should be converted to dummy variable in order to use in neural network:", "As we are dealing with various range of data, to make network efficient, let\u2019s normalize it.", "In this work, we will predict facies from well logs using deep learning in Tensorflow. There several hyper-parameters that we may adjust for deep learning. I will try to find out the optimized parameters for:", "To elaborate in this search dimension, we will use scikit-optimize(skopt) library. From skopt, real function will define our favorite range(lower bound = 1e-6, higher bound = 1e-1) for learning rate and will use logarithmic transformation. The search dimension for the number of layers (we look between 1 to 5) and each layer\u2019s node amounts(between 5 to 512) can be implemented with Integer function of skopt.", "For activation algorithms, we should use categorical function for optimization.", "Bring all search-dimensions into a single list:", "If you already worked with deep learning for a specific project and found your hyper-parameters by hand for that project, you know how hard it is to optimize. You may also use your own guess (like mine as default) to compare the results with the Bayesian tuning approach.", "Like some examples developed by Tneseflow, we also need to define a model function first. After defining the type of model(Sequential here), we need to introduce the data dimension (data shape) in the first line. The number of layers and activation types are those two hyper-parameters that we are looking for to optimize. Softmax activation should be used for classification problems. Then another hyper-parameter is the learning rate which should be defined in the Adam function. The model should be compiled considering that loss function should be \u2018categorical_crossentropy\u2019 as we are dealing with the classification problems (facies prediction).", "This function aims to create and train a network with given hyper-parameters and then evaluate model performance with the validation dataset. It returns fitness value, negative classification accuracy on the dataset. It is negative because skopt performs minimization rather than maximization.", "We already checked the default hyper-parameter performance. Now we can examine Bayesian optimization from scikit-optimize library. Here we use 40 runs for fitness function, though it is an expensive operation and needs to used carefully with datasets.", "just some last runs shows below:", "Using plot_convergence function of skopt, we may see the optimization progress and the best fitness value found on y-axis.", "Using the serach_result function, we can see the best hyper-parameter that Bayesian-optimizer generated.", "Optimized hyper-parameters are in order: Learning rate, number of dense layers, number of nodes in each layer, and the best activation function.", "We can see all results for 40 calls with corresponding hyper-parameters and fitness values.", "An interesting point is that the \u2018relu\u2019 activation function is almost dominant.", "First, let\u2019s look at 2D plot of two optimized parameters. Here we made landscape-plot of estimated fitness values for learning rate and number of nodes in each layer.The Bayesian optimizer builds a surrogate model of search space and searches inside this dimension rather than real search-space, that is why it is faster. In the plot, the yellow regions are better and blue regions are worse. Balck dots are the optimizer\u2019s sampling location and the red star is the best parameter found.", "In these plots, we can see how the optimization happened. The Bayesian approach tries to fit model parameters with prior info at the points with a higher density of sampling. Gathering all four parameters into a scikit-optimization approach will introduce the best results in this run if the learning rate is about 0.003, the number of dense layers 6, the number of nodes in each layer about 327, and activation function is \u2018relu\u2019.", "The same steps of data preparation are required here as well. We skip repeating here. Now we can make a model with optimized parameters to see the prediction.", "let\u2019s see the model accuracy development:", "Training and validation accuracy plot shows that almost after 80% accuracy (iteration 10), the model starts to overfit because we can not see improvement in test data prediction accuracy.", "Let\u2019s evaluate model performance with a dataset that has not seen yet (blind well). We always predict that Machine Learning models will predict with blind data by less accuracy than training process if dataset is small or features are not big enough to cover all complexity of data dimensions.", "In this work, we optimized hyper-parameters using a Bayesian approach with a scikit-learn library called skopt. This approach is superior to a random search and grid search, especially in complex datasets. Using this method, we can get rid of the hand-tuning of hyper-parameters for the neural networks, although in each run, you will face new parameters.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff9c48d21f795&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mardani.a?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mardani.a?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "Ryan A. Mardani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb36223c810e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&user=Ryan+A.+Mardani&userId=b36223c810e6&source=post_page-b36223c810e6----f9c48d21f795---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff9c48d21f795&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff9c48d21f795&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/mardani72/Hyper-Parameter_optimization", "anchor_text": "Github"}, {"url": "https://www.youtube.com/watch?v=RgO8BBNGB8w", "anchor_text": "Jeff Heaton"}, {"url": "https://scikit-optimize.github.io/stable/", "anchor_text": "Scikit-Optimize"}, {"url": "https://scikit-optimize.github.io/stable/user_guide.html", "anchor_text": "documentation"}, {"url": "https://github.com/mardani72/Facies-Classification-Machine-Learning/blob/master/Facies_Classification_Various_ML_Final.ipynb", "anchor_text": "here"}, {"url": "https://github.com/mardani72/Facies-Classification-Machine-Learning/blob/master/training_data.csv", "anchor_text": "here"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f9c48d21f795---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/hyperparameter-tuning?source=post_page-----f9c48d21f795---------------hyperparameter_tuning-----------------", "anchor_text": "Hyperparameter Tuning"}, {"url": "https://medium.com/tag/bayesian-optimization?source=post_page-----f9c48d21f795---------------bayesian_optimization-----------------", "anchor_text": "Bayesian Optimization"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----f9c48d21f795---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----f9c48d21f795---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff9c48d21f795&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&user=Ryan+A.+Mardani&userId=b36223c810e6&source=-----f9c48d21f795---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff9c48d21f795&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&user=Ryan+A.+Mardani&userId=b36223c810e6&source=-----f9c48d21f795---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff9c48d21f795&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff9c48d21f795&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f9c48d21f795---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f9c48d21f795--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f9c48d21f795--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f9c48d21f795--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mardani.a?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mardani.a?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ryan A. Mardani"}, {"url": "https://medium.com/@mardani.a/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "388 Followers"}, {"url": "http://www.dataenergy.ca", "anchor_text": "www.dataenergy.ca"}, {"url": "http://linkedin.com/in/amardani", "anchor_text": "linkedin.com/in/amardani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb36223c810e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&user=Ryan+A.+Mardani&userId=b36223c810e6&source=post_page-b36223c810e6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7a39952b3ca1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hyper-parameter-optimization-neural-networks-tensorflow-facies-prediction-example-f9c48d21f795&newsletterV3=b36223c810e6&newsletterV3Id=7a39952b3ca1&user=Ryan+A.+Mardani&userId=b36223c810e6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}