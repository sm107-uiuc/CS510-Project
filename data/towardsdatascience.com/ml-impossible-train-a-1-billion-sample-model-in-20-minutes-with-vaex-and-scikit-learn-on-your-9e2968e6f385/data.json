{"url": "https://towardsdatascience.com/ml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385", "time": 1683003180.726625, "path": "towardsdatascience.com/ml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385/", "webpage": {"metadata": {"title": "ML impossible: Train 1 billion samples in 5 minutes on your laptop using Vaex and Scikit-Learn | by Jovan Veljanoski | Towards Data Science", "h1": "ML impossible: Train 1 billion samples in 5 minutes on your laptop using Vaex and Scikit-Learn", "description": "\u201cData is the new oil.\u201d Regardless of whether or not you agree with this statement, the race for gathering and exploiting data has been going on for a while now. In fact, one thing the tech giants of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page", "anchor_text": "downloaded from their website", "paragraph_index": 4}, {"url": "https://nbviewer.jupyter.org/github/vaexio/vaex-examples/blob/master/medium-nyc-taxi-data-ml/vaex-taxi-ml-article.ipynb", "anchor_text": "click here", "paragraph_index": 4}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a", "anchor_text": "open-source DataFrame library", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Hierarchical_Data_Format#HDF5", "anchor_text": "HDF5", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94", "anchor_text": "This article", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94", "anchor_text": "this article", "paragraph_index": 13}, {"url": "http://numba.pydata.org/", "anchor_text": "Numba", "paragraph_index": 17}, {"url": "https://developer.nvidia.com/cuda-zone", "anchor_text": "CUDA", "paragraph_index": 17}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Principal_component_analysis", "anchor_text": "PCA", "paragraph_index": 19}, {"url": "http://blog.davidkaleko.com/feature-engineering-cyclical-features.html", "anchor_text": "this post", "paragraph_index": 21}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn", "paragraph_index": 26}, {"url": "https://xgboost.readthedocs.io/en/latest/", "anchor_text": "xgboost", "paragraph_index": 26}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html", "anchor_text": "SGDRegressor", "paragraph_index": 27}, {"url": "https://medium.com/u/b8a6decc0862?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Maarten Breddels", "paragraph_index": 30}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex", "paragraph_index": 47}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex", "paragraph_index": 47}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex", "paragraph_index": 48}, {"url": "https://github.com/scikit-learn/scikit-learn/pull/14963", "anchor_text": "bringing Vaex and scikit-learn closer together", "paragraph_index": 48}, {"url": "http://vaex.io", "anchor_text": "vaex.io", "paragraph_index": 49}, {"url": "https://www.linkedin.com/in/jovanvel/", "anchor_text": "https://www.linkedin.com/in/jovanvel/", "paragraph_index": 49}], "all_paragraphs": ["\u201cData is the new oil.\u201d Regardless of whether or not you agree with this statement, the race for gathering and exploiting data has been going on for a while now. In fact, one thing the tech giants of today have in common, is their capacity to fully exploit the enormous quantity of data they gather. They have the knowledge, manpower, and resources to analyse billions of data points, train and deploy a variety of machine learning models at scale, which then impacts countless people across our planet.", "Creating even a simple machine learning service is a non-trivial task. Even if we ignore the data gathering and augmentation steps, one still needs to understand the data, clean it appropriately, create meaningful features, and then train and tune a model. This is followed by a series of validation steps which hopefully lead to a better understanding of both the data and the model. The process is repeated until the model satisfies the business goals, after which it is put in production. In practice, however, the process may continue indefinitely.", "Imagine that we have a dataset containing over 1 billion samples, which we need to use for training of a machine learning model. Due to the sheer amount alone, exploring such dataset already becomes tricky, while iterating on the cleaning, pre-processing and training steps becomes a daunting task. Challenges such as these are commonly tackled with distributed or cloud computing. While this is the standard approach today, it can be quite costly, time-consuming, and simply less convenient compared to working on your local machine.", "In this article, I will demonstrate how anyone can train a machine learning model on a billion samples in a swift and efficient manner. Your laptop is all the infrastructure you need. Just make sure it is plugged in.", "As an example, assume we would like to help a taxi company predict how long a trip may take in New York City. We will use the New York City Taxi dataset, which contains information on over 1 billion taxi trips conducted between 2009 and 2015 by the recognizable Yellow Taxis. In its raw form, the data is provided by the New York City Taxi & Limousine Commission (TLC), and can be downloaded from their website. If you are simply interested in the Jupyter notebook used as the basis for this article, you can click here.", "In order to manipulate the large amount of data, we will use Vaex, a Python open-source DataFrame library. Leveraging concepts like memory mapping, lazy evaluations and efficient out-of-core algorithms, Vaex can easily handle datasets that would otherwise be too large to fit in RAM.", "Let\u2019s get started by opening the data. For convenience, I\u2019ve combined the 7 year of taxi data into a single HDF5 file. Even though the file is larger than 100GB on disk, opening it with Vaex is instantaneous:", "Inspecting the data is just as fast. Since the data is memory-mapped, Vaex knows immediately where to look, reading only the portions that are needed. For a simple preview as shown below, only the first and last 5 rows are read from disk.", "Working with the New York Taxi dataset is rather straightforward with Vaex, despite being over 100GB on disk and containing more than 1.1 billion records. This article goes over the Vaex fundamentals, and presents an exploratory data analysis of this very same dataset.", "Before we get started, let us split the data into a train and a test set. We will make the split by year, such that the trips conducted in 2015 will comprise the test set, and all prior to that will make up the training set. The dataset is ordered by year, so we can do the splitting by simply slicing the DataFrame.", "Note that no memory copies of the data are made by executing the above code cell. Slicing a Vaex DataFrame results in a shallow copy, which only references the appropriate portions of the original data.", "The goal of this exercise is to predict the likely duration of a taxi trip. The duration of a trip is not readily available in the dataset, but it is trivial to calculate from the pick-up and drop-off time-stamps.", "Calculating the trip distance in the code example above results in a virtual column. Creating such columns cost no memory, since they store just the expression that defines them, and are evaluated only when necessary.", "Now, let\u2019s filter out outliers and erroneous data samples from the training set. The exploratory data analysis presented in this article can serve as a guide on how to do this, so please check it out of if you would like to know the rationale behind these filtering choices.", "The main idea behind the filtering is to remove outliers and possible erroneous data inputs, so the model is not too \u201cdistracted\u201d by the few abnormal samples. After all the filters are applied, the training set comprises \u201conly\u201d 812,816,595 taxi trips.", "At this stage we can start to engineer some meaningful features. Since all of the features we will be virtual columns, we do not need to concern ourselves with memory usage, and thus have the freedom to experiment and get creative. Let\u2019s begin by extracting few features from the pick-up timestamps.", "Now, let us create a couple of more computationally demanding features. One of them is the distance between the pick-up and drop-off points, which we will call the \u201carc distance\u201d. The second feature is the direction angle of the taxi trip, i.e. an indication of whether the taxi is travelling for example due north or north-west from its origin towards its destination.", "Notice the .jit_numba method at the end of the function call. The evaluation of computationally expensive expressions like those defined above can be accelerated by Just-In-Time compilation via Numba. If your machine sports a more recent NVIDIA graphics card, you can use CUDA by invoking the .jit_cuda method for an extra boost. By using .jit_numba on some expressions and .jit_cuda on others, you can simultaneously leverage both your CPU and GPU for maximum performance.", "Before we pass the data to any model, we need to make sure it is suitably transformed in order to get the most out of it. Vaex contains the vaex.ml package which implements a variety of common data transformations, such as PCA, categorical encoders, and numerical scalers. All transformations are invoked with the familiar scikit-learn API, are parallelised and executed out-of-core.", "Let\u2019s focus on the pick-up and drop-off locations. In many cities in the United States the streets form a grid pattern. This is clearly visible in the Manhattan area. One idea to improve the performance of a model is to apply a set of PCA transformations on the pick-up and drop-off locations. This will cause the streets, traced by the many pick-up and drop-off points, to align with the natural geographical axes (longitude and latitude) instead of being at an angle to them.", "Notice that when using vaex.ml one passes the whole DataFrame to the .fit, .transform, or .fit_transform methods of a transformer, while the features on which the transformation is applied are specified while that transformer is instantiated. Most importantly, the .transform method returns a shallow copy of the DataFrame in which the result of the transformation is stored in the form of virtual columns. This makes it easy for us to visualise the results of the PCA transformations.", "Let us shift our focus on the \u201cpickup_time\u201d, \u201cpickup_day\u201d , and \u201cpickup_month\u201d features we defined earlier. The key property of these features is that they are cyclical in nature, i.e. January is as close to February as it is close to December. Thus we will use the CycleTransformer implemented in vaex.ml which essentially treats each feature as the angle \u03c6 in a unit circle in polar coordinates (\u03c1=1, \u03c6). The, transformer than computes the \ud835\udc65 and \ud835\udc66 projection of the radius \u03c1, thus getting two new components per feature. This trick perfectly preserves the relative distance between different values, since it is simply a coordinate transformation. You can read more about this approach in this post.", "We apply the same trick to the direction angle, since it is a cyclical feature as well. Let\u2019s plot the features derived from the \u201cpickup_time\u201d column, as to convince ourselves that the transformations make sense.", "We see that the transformed features create a perfect unit circle. Note that, unlike a regular wall clock, all 24 hours are represented on the circle. For example, \u201cmidnight\u201d has coordinates (x, y) = (1, 0), \u201c6 o\u2019clock\u201d is at (x, y) = (0, 1), while \u201cnoon\u201d is at (x, y) = (-1, 0).", "Lastly, we only have one continuous feature, \u201carc_distance\u201d , which we have not paid any attention to. We are simply going to apply standard scaling to it.", "Now that we are done with all of the pre-processing tasks, we can create a final list of features we are going to use for training the model.", "At this stage we are ready for the model training phase. While vaex.ml does not yet implement any predictive models, it does provide an interface to several of the popular machine learning libraries in the Python ecosystem such as scikit-learn and xgboost. The benefit of using these models via Vaex is that one does not waste any memory while doing the data cleaning, feature engineering and pre-preprocessing, and thus maximizes the available RAM for training the model.", "For the current problem, we are still in need of significantly more RAM than available on a typical laptop or desktop computer if we were to materialize all the features we intend to use for the training. To circumvent this issue, we will make use of the SGDRegressor available via scikit-learn. SGDRegressor belongs to a family of predictive models in scikit-learn that, besides the usual .fit, also implement a .partial_fit method. This allows the model to be trained on batches of data, essentially making it out-of-core.", "With the wrapper implemented in vaex.ml one can easily send batches of data from a Vaex DataFrame to the scikit-learn model. The use is straightforward. First instantiate the SGDRegressor from scikit-learn while setting its parameters in the standard way. Then instantiate the IncrementalPredictor implemented in vaex.ml while also providing the main model, a list of features names, the name of the target column, and the batch size. In principle any model can be used as long as it has a .partial_fit method and follows the scikit-learn API convention. Through the batch size one can control the RAM usage. Optionally one can also specify the number of epochs, i.e. how many times the data in each batch is seen by the model, and whether it should be shuffled or not. Finally we call the .fit method on the IncrementalPredictor instance, where we pass the training set DataFrame.", "It is quite remarkable that this Vaex + scikit-learn combo lead to a total training time of just 7 minutes on my laptop (MacBook Pro 15\", 2018, 2.6GHz Intel Core i7, 32GB RAM). This includes on-the-fly evaluation of the 14 features used, all of which are virtual columns, and training the scikit-learn model. In addition, with the set of parameters shown above, the RAM usage never surpassed 4 GB, which leaves me plenty of room to run Slack.", "The exact same setup as shown above was also run by Maarten Breddels on his Lenovo Thinkpad X1 Extreme laptop (Intel Core i7\u20138750H, 32GB RAM), and the training phase took less than 5 minutes!", "The IncrementalPredictor is not just a convenience class for passing Vaex DataFrames to scikit-learn models. It is also a vaex.ml transformer, meaning that the .transform method returns a shallow copy of a DataFrame containing the model predictions as a virtual column. This is the case for any model wrapper implemented in vaex.ml. Not only does this cost no extra memory, but it also makes it quite convenient to post-process the result and even make ensembles, as well as to calculate various performance metrics and diagnostic plots, as we shall see in a moment.", "Finally, let us constrain the predictions to be within the bounds of the data the model was trained on. This is done to prevent the estimation of unphysical or unrealistic durations for some exotic combinations of feature values. Thus, let us set any predictions smaller than 3 minutes to 3, and any predictions larger than 25 minutes to 25.", "Now that the model is trained, we would like to know how well it is doing by applying it on the test set. You may have noticed that, unlike other libraries, we did not explicitly create a pipeline to propagate all the data cleaning and transformation steps. In fact, with Vaex, a pipeline is automatically being created as one is doing exploration and transformation of the data. Each Vaex DataFrame contains a state, which is a serialisable object containing all of the transformations applied to it: filtering, creating new virtual columns, column transformation).", "Recall that all of the features we created, along with the output of the PCA transformations, scaling and the predictive model output, including the final tinkering with the predictions are virtual columns, and thus are stored in the state of the training DataFrame. Thus, to calculate the predictions on the test set, all we need to do is to apply this state to that test set DataFrame, and all of the transformations will be automatically propagated.", "The state can be also serialized and read from disk, which greatly simplifies the task of model deployment.", "Now that the trip duration predictions are available for both the training and the test set, let us calculate some performance metrics. Since this is a regression problem, we will calculate the mean absolute and the mean squared errors.", "Notice that calculation of the 4 statistics shown in the figure above took ~4.5 minutes. This is quite impressive considering that the computation requires evaluating all the features which were then passed on to the model to obtain the predictions, and this was done for over 1 billion samples between the train and the test sets, twice over.", "The mean absolute error evaluated on the test set is just over 3.5 minutes. Whether this is an acceptable error, one should probably consult with a frequent taxi passenger or a taxi driver in New York City. We should not accept such statistics at face value, and hence let us create a couple of diagnostic plots. Let us plot the distribution of the actual vs the estimated trip durations, as well as the absolute error of the predicted durations.", "While we see a strong correlation between the actual and the estimated trip durations, the left panel of the figure above also shows that the model estimates are systematically biased to higher values. One potential reason for this is the non-Gaussian distribution of the training features and the target variable. There could also be some outliers that negatively affect the model performance, despite or filtering efforts earlier. On the other hand, it is not that bad to be a bit pessimistic when it comes to estimating taxi trip durations, perhaps.", "The right panel shows the number of trips per absolute error bin. In fact, 77% of all trip durations in the test set were estimated with an absolute error of less than 5 minutes. While the current model may serve as a good starting baseline, there is plenty of room for improvement. The good news is that with Vaex, we have a tool that enables us to be creative and try out many features and pre-processing combinations in an incredibly efficient manner.", "Speaking of the model, the trained instance of the SGDRegressor is readily available as an attribute of the IncrementalPredictor. It can easily be accessed, and we can use it for example to inspect the relative importance of the features used to train the model.", "Imagine that we manage to iron all the quirks out of our model, and that after a thorough validation it is ready to be put in production. In principle, this is quite easily done with Vaex. All that is required is for one to store the state in the production environment. The state can than be easily applied on an incoming Vaex DataFrame, and the predictions will be readily available.", "Recall that the state not only memorizes all virtual columns that were created, but also which filters were applied. So, if one would query a prediction for a sample which would be filtered out if it was part of the training set, at prediction time it would also be filtered out, and thus that sample would \u201cdisappear\u201d. In reality, samples can not just go missing, and many production cases require that we always return at least some kind of a prediction, no matter the query.", "To overcome this hurdle, we can make use of the fact that in Vaex, a filtered DataFrame actually still contains all of the data, plus an expression that defines which rows are filtered out, and which are kept. While in other common libraries such as Numpy and Pandas one can only filter out more rows, in Vaex one can actually get rows back by using the \u201cor\u201d operator in a filter.", "Let\u2019s implement this idea for our problem. We add a variable called \u201cproduction\u201d to the training DataFrame and set its value to False. Then, we add an additional filter, which in this case is just the value of the variable. However, now we use the \u201cor\u201d instead of the default \u201cand\u201d operator which is used in cases like df3 = df2[df2.x < 5]. The idea is simple: if this last filter is set to False, it will have no effect on any other filters since its mode of operation is \u201dor\u201d. If it is set to True however, which can be done by modifying the value of the \u201cproduction\u201d variable, it will invalidate all other filters, and thus any data point can pass through.", "The code block above shows how we can include and modify the \u201cproduction\u201d variable such that the filters are disabled when needed. We can easily confirm that in this case, the test DataFrame contains as many samples as it did when we preformed the train/test split, with a prediction for each of them. Calculating the mean absolute error in this case gives us a higher result of 13 minutes, which is not surprising given that the model is ill trained to provide predictions for the many outliers or erroneous samples that are now part of the test set.", "I hope I managed to show you how easy and convenient it is to create a machine learning pipeline using Vaex, even when the training data numbers over a billion samples and takes over 100 GB of disk space. I am sure you will find much more creative ways of using Vaex to improve the model presented in this article, as well as create many new ones for various other problems and use cases.", "We, the Vaex team, believe in a future in which data science and machine learning can be down both conveniently and efficiently, even for \u201cbig\u201d data, with tools that are free and open-source. We aim to make Vaex better integrated with the pillars of the Python data science stack, and are putting considerable efforts in bringing Vaex and scikit-learn closer together. Stay tuned, there are definitely more exciting things coming this way!", "Just another data scientist | PhD Astrophysics | co-founder of vaex.io | https://www.linkedin.com/in/jovanvel/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9e2968e6f385&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@jovan.veljanoski?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Jovan Veljanoski"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3bd573100d67&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&user=Jovan+Veljanoski&userId=3bd573100d67&source=post_page-3bd573100d67----9e2968e6f385---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e2968e6f385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&user=Jovan+Veljanoski&userId=3bd573100d67&source=-----9e2968e6f385---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e2968e6f385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&source=-----9e2968e6f385---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page", "anchor_text": "downloaded from their website"}, {"url": "https://nbviewer.jupyter.org/github/vaexio/vaex-examples/blob/master/medium-nyc-taxi-data-ml/vaex-taxi-ml-article.ipynb", "anchor_text": "click here"}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex"}, {"url": "https://towardsdatascience.com/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a", "anchor_text": "open-source DataFrame library"}, {"url": "https://en.wikipedia.org/wiki/Hierarchical_Data_Format#HDF5", "anchor_text": "HDF5"}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex"}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94", "anchor_text": "This article"}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94", "anchor_text": "this article"}, {"url": "http://numba.pydata.org/", "anchor_text": "Numba"}, {"url": "https://developer.nvidia.com/cuda-zone", "anchor_text": "CUDA"}, {"url": "http://numba.pydata.org/", "anchor_text": "Numba"}, {"url": "https://developer.nvidia.com/cuda-zone", "anchor_text": "CUDA"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn"}, {"url": "https://en.wikipedia.org/wiki/Principal_component_analysis", "anchor_text": "PCA"}, {"url": "http://blog.davidkaleko.com/feature-engineering-cyclical-features.html", "anchor_text": "this post"}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn"}, {"url": "https://xgboost.readthedocs.io/en/latest/", "anchor_text": "xgboost"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html", "anchor_text": "SGDRegressor"}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn"}, {"url": "https://medium.com/u/b8a6decc0862?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Maarten Breddels"}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex"}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex"}, {"url": "https://github.com/vaexio/vaex", "anchor_text": "Vaex"}, {"url": "https://github.com/scikit-learn/scikit-learn/pull/14963", "anchor_text": "bringing Vaex and scikit-learn closer together"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9e2968e6f385---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9e2968e6f385---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/scikit-learn?source=post_page-----9e2968e6f385---------------scikit_learn-----------------", "anchor_text": "Scikit Learn"}, {"url": "https://medium.com/tag/vaex?source=post_page-----9e2968e6f385---------------vaex-----------------", "anchor_text": "Vaex"}, {"url": "https://medium.com/tag/big-data?source=post_page-----9e2968e6f385---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e2968e6f385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&user=Jovan+Veljanoski&userId=3bd573100d67&source=-----9e2968e6f385---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e2968e6f385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&user=Jovan+Veljanoski&userId=3bd573100d67&source=-----9e2968e6f385---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e2968e6f385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3bd573100d67&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&user=Jovan+Veljanoski&userId=3bd573100d67&source=post_page-3bd573100d67----9e2968e6f385---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9485ced537bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&newsletterV3=3bd573100d67&newsletterV3Id=9485ced537bb&user=Jovan+Veljanoski&userId=3bd573100d67&source=-----9e2968e6f385---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Written by Jovan Veljanoski"}, {"url": "https://medium.com/@jovan.veljanoski/followers?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "995 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "http://vaex.io", "anchor_text": "vaex.io"}, {"url": "https://www.linkedin.com/in/jovanvel/", "anchor_text": "https://www.linkedin.com/in/jovanvel/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3bd573100d67&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&user=Jovan+Veljanoski&userId=3bd573100d67&source=post_page-3bd573100d67----9e2968e6f385---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9485ced537bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385&newsletterV3=3bd573100d67&newsletterV3Id=9485ced537bb&user=Jovan+Veljanoski&userId=3bd573100d67&source=-----9e2968e6f385---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/plotly/interactive-and-scalable-dashboards-with-vaex-and-dash-9b104b2dc9f0?source=author_recirc-----9e2968e6f385----0---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=author_recirc-----9e2968e6f385----0---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=author_recirc-----9e2968e6f385----0---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Jovan Veljanoski"}, {"url": "https://medium.com/plotly?source=author_recirc-----9e2968e6f385----0---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Plotly"}, {"url": "https://medium.com/plotly/interactive-and-scalable-dashboards-with-vaex-and-dash-9b104b2dc9f0?source=author_recirc-----9e2968e6f385----0---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Interactive and scalable dashboards with Vaex and DashLearn how to build interactive, scalable dashboards with Dash and Vaex."}, {"url": "https://medium.com/plotly/interactive-and-scalable-dashboards-with-vaex-and-dash-9b104b2dc9f0?source=author_recirc-----9e2968e6f385----0---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "13 min read\u00b7Jun 23, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fplotly%2F9b104b2dc9f0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplotly%2Finteractive-and-scalable-dashboards-with-vaex-and-dash-9b104b2dc9f0&user=Jovan+Veljanoski&userId=3bd573100d67&source=-----9b104b2dc9f0----0-----------------clap_footer----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/plotly/interactive-and-scalable-dashboards-with-vaex-and-dash-9b104b2dc9f0?source=author_recirc-----9e2968e6f385----0---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "8"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9b104b2dc9f0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplotly%2Finteractive-and-scalable-dashboards-with-vaex-and-dash-9b104b2dc9f0&source=-----9e2968e6f385----0-----------------bookmark_preview----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9e2968e6f385----1---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9e2968e6f385----1---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9e2968e6f385----1---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9e2968e6f385----1---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9e2968e6f385----1---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9e2968e6f385----1---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9e2968e6f385----1---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----9e2968e6f385----1-----------------bookmark_preview----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9e2968e6f385----2---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9e2968e6f385----2---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9e2968e6f385----2---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9e2968e6f385----2---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9e2968e6f385----2---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9e2968e6f385----2---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9e2968e6f385----2---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----9e2968e6f385----2-----------------bookmark_preview----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94?source=author_recirc-----9e2968e6f385----3---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=author_recirc-----9e2968e6f385----3---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=author_recirc-----9e2968e6f385----3---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Jovan Veljanoski"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9e2968e6f385----3---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94?source=author_recirc-----9e2968e6f385----3---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "How to analyse 100s of GBs of data on your laptop with PythonYour laptop is way more powerful than you think. Unleash its full potential with the Vaex dataframe library."}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94?source=author_recirc-----9e2968e6f385----3---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": "15 min read\u00b7Dec 2, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff83363dda94&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94&user=Jovan+Veljanoski&userId=3bd573100d67&source=-----f83363dda94----3-----------------clap_footer----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94?source=author_recirc-----9e2968e6f385----3---------------------a08e635a_24b6_4fae_910d_8d393867dffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff83363dda94&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94&source=-----9e2968e6f385----3-----------------bookmark_preview----a08e635a_24b6_4fae_910d_8d393867dffe-------", "anchor_text": ""}, {"url": "https://medium.com/@jovan.veljanoski?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "See all from Jovan Veljanoski"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----9e2968e6f385----0-----------------bookmark_preview----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----1-----------------clap_footer----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----9e2968e6f385----1-----------------bookmark_preview----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9e2968e6f385----0---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----9e2968e6f385----0-----------------bookmark_preview----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Erdogan Taskesen"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "From Data to Clusters; When is Your Clustering Good Enough?Sensible clusters and hidden gems can be found using clustering approaches but you need the right cluster evaluation method!"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "\u00b717 min read\u00b75 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----5895440a978a----1-----------------clap_footer----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----9e2968e6f385----1---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&source=-----9e2968e6f385----1-----------------bookmark_preview----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/can-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2?source=read_next_recirc-----9e2968e6f385----2---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://medium.com/@marietruong?source=read_next_recirc-----9e2968e6f385----2---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://medium.com/@marietruong?source=read_next_recirc-----9e2968e6f385----2---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Marie Truong"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9e2968e6f385----2---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/can-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2?source=read_next_recirc-----9e2968e6f385----2---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Can ChatGPT Write Better SQL than a Data Analyst?A LeetCode SQL Competition Between ChatGPT and Me"}, {"url": "https://towardsdatascience.com/can-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2?source=read_next_recirc-----9e2968e6f385----2---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "\u00b76 min read\u00b7Jan 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff079518efab2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2&user=Marie+Truong&userId=4cfa1d0b321f&source=-----f079518efab2----2-----------------clap_footer----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/can-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2?source=read_next_recirc-----9e2968e6f385----2---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff079518efab2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2&source=-----9e2968e6f385----2-----------------bookmark_preview----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-for-climate-change-forecasting-large-ocean-waves-78484536be36?source=read_next_recirc-----9e2968e6f385----3---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://vcerq.medium.com/?source=read_next_recirc-----9e2968e6f385----3---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://vcerq.medium.com/?source=read_next_recirc-----9e2968e6f385----3---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Vitor Cerqueira"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9e2968e6f385----3---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/time-series-for-climate-change-forecasting-large-ocean-waves-78484536be36?source=read_next_recirc-----9e2968e6f385----3---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "Time Series for Climate Change: Forecasting Large Ocean WavesHow to use time series analysis and forecasting to tackle climate change"}, {"url": "https://towardsdatascience.com/time-series-for-climate-change-forecasting-large-ocean-waves-78484536be36?source=read_next_recirc-----9e2968e6f385----3---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": "\u00b77 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F78484536be36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-for-climate-change-forecasting-large-ocean-waves-78484536be36&user=Vitor+Cerqueira&userId=efb5f27c836d&source=-----78484536be36----3-----------------clap_footer----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-for-climate-change-forecasting-large-ocean-waves-78484536be36?source=read_next_recirc-----9e2968e6f385----3---------------------2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F78484536be36&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-for-climate-change-forecasting-large-ocean-waves-78484536be36&source=-----9e2968e6f385----3-----------------bookmark_preview----2ab2d0f5_a084_45c4_a7cb_0604672cdf4e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----9e2968e6f385--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}