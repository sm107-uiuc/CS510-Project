{"url": "https://towardsdatascience.com/hyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e", "time": 1683014516.5846741, "path": "towardsdatascience.com/hyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e/", "webpage": {"metadata": {"title": "Hyperparameter Tuning to Reduce Overfitting \u2014 LightGBM | by Soner Y\u0131ld\u0131r\u0131m | Towards Data Science", "h1": "Hyperparameter Tuning to Reduce Overfitting \u2014 LightGBM", "description": "Easy access to an enormous amount of data and high computing power has made it possible to design complex machine learning algorithms. As the model complexity increases, the amount of data required\u2026"}, "outgoing_paragraph_urls": [{"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/", "paragraph_index": 30}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14", "paragraph_index": 30}], "all_paragraphs": ["Easy access to an enormous amount of data and high computing power has made it possible to design complex machine learning algorithms. As the model complexity increases, the amount of data required to train it also increases.", "Data is not the only factor in the performance of a model. Complex models have many hyperparameters that need to be correctly adjusted or tuned in order to make the most out of them.", "For instance, the performance of XGBoost and LightGBM highly depend on the hyperparameter tuning. It would be like driving a Ferrari at a speed of 50 mph to implement these algorithms without carefully adjusting the hyperparameters.", "In this post, we will experiment with how the performance of LightGBM changes based on hyperparameter values. The focus is on the parameters that help to generalize the models and thus reduce the risk of overfitting.", "Let\u2019s start with importing the libraries.", "The dataset contains 60 k observations, 99 numerical features, and a target variable.", "The target variable contains 9 values which makes it a multi-class classification task.", "Our focus is hyperparameter tuning so we will skip the data wrangling part. The following code block splits the dataset into train and test subsets and converts them to a format suitable for LightGBM.", "We will start with a basic set of new hyperparameters and introduce new ones step-by-step.", "We can now train the model and see the results based on the specified evaluation metric.", "The evaluation metric is multi-class log loss. Here is the result of both training and validation sets.", "The number of boosting rounds is set as 500 but early stopping occurred. The early_stopping_rounds stops the training if the performance does not improve in the specified number of rounds.", "It seems like the model is highly overfitting to the training set because there is a significant difference between losses on training and validation sets.", "The min_data_in_leaf parameter is a way to reduce overfitting. It requires each leaf to have the specified number of observations so that the model does not become too specific.", "The validation loss is almost the same but the difference got smaller which means the degree of overfitting reduced.", "Another parameter to prevent the model from being too specific is feature_fraction which indicates the ratio of features to be randomly selected at each iteration.", "Now the model uses 80% of the features at each iteration. Here is the result.", "Bagging_fraction allows using a randomly selected sample of rows to be used at each iteration. It is similar to feature_fraction but for rows. The bagging_freq specifies the iteration frequency to update selected rows.", "The difference between train and validation losses is decreasing which indicates we are on the right track.", "LightGBM is an ensemble method using boosting technique to combine decision trees. The complexity of an individual tree is also a determining factor in overfitting. It can be controlled with the max_depth and num_leaves parameters. The max_depth determines the maximum depth of a tree while num_leaves limits the maximum number of leafs a tree can have. Since LightGBM adapts leaf-wise tree growth, it is important to adjust these two parameters together.", "Another important parameter is the learning_rate. The smaller learning rates are usually better but it causes the model to learn slower.", "We can also add a regularization term as a hyperparameter. LightGBM supports both L1 and L2 regularizations.", "We\u2019ve further decreased the difference between the train and validation loss which means less overfitting.", "The number of iterations is also an important factor in model training. The more iterations cause the model to learn more and thus the model starts overfitting after a certain amount of iterations.", "You may need to spend a good amount of time tuning the hyperparameters. Eventually, you will create your own way or strategy that will expedite the process of tuning.", "There are lots of hyperparameters. Some are more important in terms of accuracy and speed. Some of them are mainly used to prevent overfitting.", "Cross-validation can be used to reduce overfitting as well. It allows using each data point in both training and validation sets.", "We have focused only on reducing the overfitting. However, eliminating the overfitting does not matter much if the accuracy or loss is not satisfying. You can also tune hyperparameters to increase the accuracy to some extent. Some ways to work on to increase the performance of a model are:", "Thank you for reading. Please let me know if you have any feedback.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Top 10 Writer in AI and Data Science | linkedin.com/in/soneryildirim/ | twitter.com/snr14"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5eb81a0b464e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sonery.medium.com/?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----5eb81a0b464e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5eb81a0b464e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5eb81a0b464e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@dallimonti?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Andr\u00e9s Dallimonti"}, {"url": "https://unsplash.com/s/photos/cockpit?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5eb81a0b464e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5eb81a0b464e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----5eb81a0b464e---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/programming?source=post_page-----5eb81a0b464e---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----5eb81a0b464e---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5eb81a0b464e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----5eb81a0b464e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5eb81a0b464e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----5eb81a0b464e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5eb81a0b464e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5eb81a0b464e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5eb81a0b464e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5eb81a0b464e--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://sonery.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21K Followers"}, {"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/"}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7cdf5377373a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-to-reduce-overfitting-lightgbm-5eb81a0b464e&newsletterV3=2cf6b549448&newsletterV3Id=7cdf5377373a&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}