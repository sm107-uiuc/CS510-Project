{"url": "https://towardsdatascience.com/complete-introduction-to-pyspark-part-3-9c06e2c5e13d", "time": 1683016531.026953, "path": "towardsdatascience.com/complete-introduction-to-pyspark-part-3-9c06e2c5e13d/", "webpage": {"metadata": {"title": "Complete Introduction to PySpark- Part 3 | by Himanshu Sharma | Towards Data Science", "h1": "Complete Introduction to PySpark- Part 3", "description": "SQL is a language that is used to perform different operations on data like storing, manipulating, and retrieving. It works on relational databases in which data is stored in the form of rows and\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.linkedin.com/in/himanshusharmads", "anchor_text": "LinkedIn Profile", "paragraph_index": 21}, {"url": "https://github.com/hmix13", "anchor_text": "Github", "paragraph_index": 21}, {"url": "https://medium.com/@hmix13", "anchor_text": "my profile", "paragraph_index": 21}, {"url": "https://www.linkedin.com/in/himanshusharmads/", "anchor_text": "https://www.linkedin.com/in/himanshusharmads/", "paragraph_index": 23}], "all_paragraphs": ["SQL is a language that is used to perform different operations on data like storing, manipulating, and retrieving. It works on relational databases in which data is stored in the form of rows and columns.", "SQL commands can be classified into three types according to their properties:", "As the name suggests DDL commands are used to define the data. The commands which are included in DDL are CREATE, INSERT, TRUNCATE, DROP, etc.", "Data Manipulation commands are used to alter and update the data according to user requirements. Some of the commands defined under DDL are ALTER, UPDATE, DELETE, etc.", "In this, the commands defined are used for controlling the access of the database defined. Some of the commands defined under this are GRANT, REVOKE, etc.", "In order to perform SQL operations using PySpark, we need to have PySpark installed on our local machine. If you have already installed it we can get started else go through the below links to install PySpark and perform some basic operations on DataFrame using PySpark.", "After we have installed pyspark on our machine and configure it, we will open a jupyter notebook to start SQL operations. We will start by importing the required libraries and creating a PySpark session.", "For performing SQL operations we will need a dataset. In this article, we will use Boston Dataset which can be easily downloaded using Kaggle, and will load it using PySpark.", "Now let us start SQL operations on our dataset, we will start by creating a table and an Object of SQLContext which will be used to run queries on that table.", "For creating a table we will need to use the register function of PySpark. Similarly, we will also create an object of SQLContext use to run queries on the table.", "Select Query is used for selecting the data according to user requirements. We can use select the whole table using \u201c*\u201d or we can pass the name of the columns separated by \u201d,\u201d that we want to see.", "There are some predefined aggregate functions defined in SQL which can be used to select data according to user requirements. These functions are:", "The syntax for the following functions is given below.", "Similarly, we can use other functions to display output according to user requirements.", "By using conditional queries we can generate outputs that follow a certain condition passed by the user. The most used condition expression is \u201cwhere\u201d.", "We can use different supporting functions in conditional queries which helps in being more specific about the output and can help in running multiple conditions in a single query. These functions are:", "a. havingb. andc. ord. thene. between(used for range)etc.", "Similarly, we can use different functions using the same syntax as given above.", "We can have multiple queries running in the same line of code which is generally called a nested query. It is a complex form of query where we pass different conditions to generate the output according to user demand. Below given is an example of a nested query.", "Similarly, you can try different nested queries according to the output you want.", "This article provides you with the basic information about the SQL Queries using the PySpark. Go ahead try these and if you face any difficulty please let me know in the response section.", "Thanks for reading! If you want to get in touch with me, feel free to reach me on hmix13@gmail.com or my LinkedIn Profile. You can view my Github profile for different data science projects and packages tutorial. Also, feel free to explore my profile and read different articles I have written related to Data Science.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I write about my learnings in the field of Data Science, Visualization, Artificial Intelligence, etc.| Linkedin: https://www.linkedin.com/in/himanshusharmads/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9c06e2c5e13d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://hmix13.medium.com/?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": ""}, {"url": "https://hmix13.medium.com/?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "Himanshu Sharma"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdf1ad2ced320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&user=Himanshu+Sharma&userId=df1ad2ced320&source=post_page-df1ad2ced320----9c06e2c5e13d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c06e2c5e13d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c06e2c5e13d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@franki?utm_source=medium&utm_medium=referral", "anchor_text": "Franki Chamaki"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/python-in-plain-english/complete-introduction-to-pyspark-part-1-7d16d7c62cc9", "anchor_text": "Complete Introduction to PySparkPart 1: PySpark Installation on Windows from scratchmedium.com"}, {"url": "https://towardsdatascience.com/complete-introduction-to-pyspark-part-2-135d2f2c13e2", "anchor_text": "Complete Introduction to PySpark-Part 2Exploratory Data Analysis using PySparktowardsdatascience.com"}, {"url": "http://www.linkedin.com/in/himanshusharmads", "anchor_text": "LinkedIn Profile"}, {"url": "https://github.com/hmix13", "anchor_text": "Github"}, {"url": "https://medium.com/@hmix13", "anchor_text": "my profile"}, {"url": "https://medium.com/tag/sql?source=post_page-----9c06e2c5e13d---------------sql-----------------", "anchor_text": "Sql"}, {"url": "https://medium.com/tag/python?source=post_page-----9c06e2c5e13d---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----9c06e2c5e13d---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9c06e2c5e13d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/big-data?source=post_page-----9c06e2c5e13d---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c06e2c5e13d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&user=Himanshu+Sharma&userId=df1ad2ced320&source=-----9c06e2c5e13d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c06e2c5e13d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&user=Himanshu+Sharma&userId=df1ad2ced320&source=-----9c06e2c5e13d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c06e2c5e13d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9c06e2c5e13d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9c06e2c5e13d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9c06e2c5e13d--------------------------------", "anchor_text": ""}, {"url": "https://hmix13.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://hmix13.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Himanshu Sharma"}, {"url": "https://hmix13.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.8K Followers"}, {"url": "https://www.linkedin.com/in/himanshusharmads/", "anchor_text": "https://www.linkedin.com/in/himanshusharmads/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdf1ad2ced320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&user=Himanshu+Sharma&userId=df1ad2ced320&source=post_page-df1ad2ced320--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F79b4547b4bbf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomplete-introduction-to-pyspark-part-3-9c06e2c5e13d&newsletterV3=df1ad2ced320&newsletterV3Id=79b4547b4bbf&user=Himanshu+Sharma&userId=df1ad2ced320&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}