{"url": "https://towardsdatascience.com/pyspark-and-sparksql-basics-6cb4bf967e53", "time": 1683002752.266853, "path": "towardsdatascience.com/pyspark-and-sparksql-basics-6cb4bf967e53/", "webpage": {"metadata": {"title": "PySpark and SparkSQL Basics. How to implement Spark with Python\u2026 | by P\u0131nar Ersoy | Towards Data Science", "h1": "PySpark and SparkSQL Basics", "description": "Python is revealed the Spark programming model to work with structured data by the Spark Python API which is called as PySpark. Python programming language requires an installed IDE. The easiest way\u2026"}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/docs/0.9.1/api/pyspark/index.html", "anchor_text": "PySpark", "paragraph_index": 0}, {"url": "https://www.anaconda.com/distribution/", "anchor_text": "link", "paragraph_index": 3}, {"url": "https://docs.anaconda.com/anaconda/install/", "anchor_text": "Anaconda Documentation", "paragraph_index": 3}, {"url": "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html?highlight=sparksession#pyspark.sql.SparkSession", "anchor_text": "pyspark.sql.SparkSession", "paragraph_index": 8}, {"url": "https://www.kaggle.com/cmenca/new-york-times-hardcover-fiction-best-sellers", "anchor_text": "this link", "paragraph_index": 10}, {"url": "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html", "anchor_text": "Apache Spark doc", "paragraph_index": 14}, {"url": "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame", "anchor_text": "Apache Spark doc", "paragraph_index": 24}, {"url": "http://pyspark.sql.DataFrameNaFunction", "anchor_text": "pyspark.sql.DataFrameNaFunction", "paragraph_index": 27}, {"url": "https://spark.apache.org/docs/1.1.1/api/python/pyspark.rdd.RDD-class.html", "anchor_text": "Apache Spark docs", "paragraph_index": 28}, {"url": "https://spark.apache.org/docs/2.2.0/sql-programming-guide.html", "anchor_text": "Apache Spark docs", "paragraph_index": 29}, {"url": "https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html", "anchor_text": "Apache Spark doc", "paragraph_index": 31}, {"url": "https://github.com/pinarersoy/PySpark_SparkSQL_MLib", "anchor_text": "GitHub.", "paragraph_index": 33}, {"url": "https://www.linkedin.com/in/pinarersoy/", "anchor_text": "https://www.linkedin.com/in/pinarersoy/", "paragraph_index": 36}], "all_paragraphs": ["Python is revealed the Spark programming model to work with structured data by the Spark Python API which is called as PySpark.", "This post\u2019s objective is to demonstrate how to run Spark with PySpark and execute common functions.", "Python programming language requires an installed IDE. The easiest way to use Python with Anaconda since it installs sufficient IDE\u2019s and crucial packages along with itself.", "With the help of this link, you can download Anaconda. After the suitable Anaconda version is downloaded, click on it to proceed with the installation procedure which is explained step by step in the Anaconda Documentation.", "When the installation is completed, the Anaconda Navigator Homepage will be opened. In order to use Python, simply click on the \u201cLaunch\u201d button of the \u201cNotebook\u201d module.", "To be able to use Spark through Anaconda, the following package installation steps shall be followed.", "After PySpark and PyArrow package installations are completed, simply close the terminal and go back to Jupyter Notebook and import the required packages at the top of your code.", "First of all, a Spark session needs to be initialized. With the help of SparkSession, DataFrame can be created and registered as tables. Moreover, SQL tables are executed, tables can be cached, and parquet/JSON/CSV/Avro data formatted files can be read.", "For detailed explanations for each parameter of SparkSession, kindly visit pyspark.sql.SparkSession.", "A DataFrame can be accepted as a distributed and tabulated collection of titled columns which is similar to a table in a relational database. In this post, we will be using DataFrame operations on PySpark API while working with datasets.", "You can download the Kaggle dataset from this link.", "DataFrames can be created by reading text, CSV, JSON, and Parquet file formats. In our example, we will be using a .json formatted file. You can also find and read text, CSV, and Parquet file formats by using the related read functions as shown below.", "Duplicate values in a table can be eliminated by using dropDuplicates() function.", "After dropDuplicates() function is applied, we can observe that duplicates are removed from the dataset.", "Querying operations can be used for various purposes such as subsetting columns with \u201cselect\u201d, adding conditions with \u201cwhen\u201d and filtering column contents with \u201clike\u201d. Below, some of the most commonly used operations are exemplified. For the complete list of query operations, see the Apache Spark doc.", "It is possible to obtain columns by attribute (\u201cauthor\u201d) or by indexing (dataframe[\u2018author\u2019]).", "In the first example, the \u201ctitle\u201d column is selected and a condition is added with a \u201cwhen\u201d condition.", "In the second example, the \u201cisin\u201d operation is applied instead of \u201cwhen\u201d which can be also used to define some conditions to rows.", "In the brackets of the \u201cLike\u201d function, the % character is used to filter out all titles having the \u201c THE \u201d word. If the condition we are looking for is the exact match, then no % character shall be used.", "StartsWith scans from the beginning of word/content with specified criteria in the brackets. In parallel, EndsWith processes the word/content starting from the end. Both of the functions are case-sensitive.", "Substring functions to extract the text between specified indexes. In the following examples, texts are extracted from the index numbers (1, 3), (3, 6), and (1, 6).", "Data manipulation functions are also available in the DataFrame API. Below, you can find examples to add/update/remove column operations.", "For updated operations of DataFrame API, withColumnRenamed() function is used with two parameters.", "Removal of a column can be achieved in two ways: adding the list of column names in the drop() function or specifying columns by pointing in the drop function. Both examples are shown below.", "There exist several types of functions to inspect data. Below, you can find some of the commonly used ones. For a deeper look, visit the Apache Spark doc.", "The grouping process is applied with GroupBy() function by adding column name in function.", "Filtering is applied by using the filter() function with a condition parameter added inside of it. This function is case-sensitive.", "For every dataset, there is always a need for replacing, existing values, dropping unnecessary columns, and filling missing values in data preprocessing stages. pyspark.sql.DataFrameNaFunction library helps us to manipulate data in this respect. Some examples are added below.", "It is possible to increase or decrease the existing level of partitioning in RDD Increasing can be actualized by using the repartition(self, numPartitions) function which results in a new RDD that obtains the higher number of partitions. Decreasing can be processed with coalesce(self, numPartitions, shuffle=False) function that results in a new RDD with a reduced number of partitions to a specified number. For more info, please visit the Apache Spark docs.", "Raw SQL queries can also be used by enabling the \u201csql\u201d operation on our SparkSession to run SQL queries programmatically and return the result sets as DataFrame structures. For more detailed information, kindly visit Apache Spark docs.", "DataFrame API uses RDD as a base and it converts SQL queries into low-level RDD functions. By using the .rdd operation, a dataframe can be converted into RDD. It is also possible to convert Spark Dataframe into a string of RDD and Pandas formats.", "Any data source type that is loaded to our code as data frames can easily be converted and saved into other types including .parquet and .json. For more save, load, write function details, please visit Apache Spark doc.", "Spark Session can be stopped by running the stop() function as follows.", "The code and Jupyter Notebook are available on my GitHub.", "Questions and comments are highly appreciated!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Lead Data Scientist @Dataroid, BSc Software & Industrial Engineer, MSc Software Engineer https://www.linkedin.com/in/pinarersoy/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6cb4bf967e53&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@pinarersoy?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pinarersoy?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "P\u0131nar Ersoy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5411ba755d50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=post_page-5411ba755d50----6cb4bf967e53---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cb4bf967e53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cb4bf967e53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/illustrations/analytics-information-innovation-3088958/", "anchor_text": "(Source)"}, {"url": "https://spark.apache.org/docs/0.9.1/api/pyspark/index.html", "anchor_text": "PySpark"}, {"url": "https://www.anaconda.com/distribution/", "anchor_text": "link"}, {"url": "https://docs.anaconda.com/anaconda/install/", "anchor_text": "Anaconda Documentation"}, {"url": "https://pypi.org/project/pyarrow/", "anchor_text": "pyarrow"}, {"url": "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html?highlight=sparksession#pyspark.sql.SparkSession", "anchor_text": "pyspark.sql.SparkSession"}, {"url": "https://www.kaggle.com/cmenca/new-york-times-hardcover-fiction-best-sellers", "anchor_text": "this link"}, {"url": "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html", "anchor_text": "Apache Spark doc"}, {"url": "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame", "anchor_text": "Apache Spark doc"}, {"url": "http://pyspark.sql.DataFrameNaFunction", "anchor_text": "pyspark.sql.DataFrameNaFunction"}, {"url": "https://spark.apache.org/docs/1.1.1/api/python/pyspark.rdd.RDD-class.html", "anchor_text": "Apache Spark docs"}, {"url": "https://spark.apache.org/docs/2.2.0/sql-programming-guide.html", "anchor_text": "Apache Spark docs"}, {"url": "https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html", "anchor_text": "Apache Spark doc"}, {"url": "https://github.com/pinarersoy/PySpark_SparkSQL_MLib", "anchor_text": "GitHub."}, {"url": "http://spark.apache.org/docs/latest/", "anchor_text": "http://spark.apache.org/docs/latest/"}, {"url": "https://docs.anaconda.com/anaconda/", "anchor_text": "https://docs.anaconda.com/anaconda/"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6cb4bf967e53---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6cb4bf967e53---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/spark?source=post_page-----6cb4bf967e53---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/python?source=post_page-----6cb4bf967e53---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/ai?source=post_page-----6cb4bf967e53---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cb4bf967e53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=-----6cb4bf967e53---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cb4bf967e53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=-----6cb4bf967e53---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cb4bf967e53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6cb4bf967e53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6cb4bf967e53---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6cb4bf967e53--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pinarersoy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pinarersoy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "P\u0131nar Ersoy"}, {"url": "https://medium.com/@pinarersoy/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "586 Followers"}, {"url": "https://www.linkedin.com/in/pinarersoy/", "anchor_text": "https://www.linkedin.com/in/pinarersoy/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5411ba755d50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=post_page-5411ba755d50--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd8be348d5069&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-and-sparksql-basics-6cb4bf967e53&newsletterV3=5411ba755d50&newsletterV3Id=d8be348d5069&user=P%C4%B1nar+Ersoy&userId=5411ba755d50&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}