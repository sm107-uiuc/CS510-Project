{"url": "https://towardsdatascience.com/introduction-to-deep-similarity-learning-for-sequences-89d9c26f8392", "time": 1683008398.740119, "path": "towardsdatascience.com/introduction-to-deep-similarity-learning-for-sequences-89d9c26f8392/", "webpage": {"metadata": {"title": "An introduction to Deep Similarity Learning for sequences | by Thomas Di Martino | Towards Data Science", "h1": "An introduction to Deep Similarity Learning for sequences", "description": "In this article, I will go through my take on the general concept of Similarity Learning, which processes it involves and how it can be summarized. I will then apply these outlined concepts to the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/dimartinot/Text-Semantic-Similarity/", "anchor_text": "https://github.com/dimartinot/Text-Semantic-Similarity/", "paragraph_index": 24}], "all_paragraphs": ["In this article, I will go through my take on the general concept of Similarity Learning, which processes it involves and how it can be summarized. I will then apply these outlined concepts to the context of sequence similarity detection with question similarities.", "When one is doing similarity learning, the same process is always performed:", "As explained in this infographic, any process involving Similarity Learning revolves around 3 main concepts:", "In most Deep Learning tasks, the first layers of a model represent what is sometimes referred to as \u201can encoding phase\u201d: it has the role of extracting relevant features from the input data.", "For the rest of the article, we will write the encoding function as follows:", "This encoder can take, depending on the input, different forms, amongst which we find:", "Usually, after the input data has been reduced to a vector by these encoders, we stack layers of Fully-Connected Neurons to classify these extracted features. In our case, we use this vector as a dimensionally reduced version of our data to compute distance with other pieces of data. It becomes way easier to numerically say how different two vectors are rather than two sentences for example.", "To sum up, an encoder will use a combination of any kind of layers that will, adequately to its input data, generate the data\u2019s latent representation, a compressed, non-human interpretable, vector of information.", "Throughout Deep Learning history, multiple types of architectures have been created to generate latent vectors. Some of them were:", "We will explore Siamese Neural Networks further away in this article.", "Once we have our vectorized input data, we can compare the two vectors using a distance function. The most popular distances are:", "Once the distance is calculated, we could set a threshold above which we consider two pieces of data to be dissimilar and vice versa to consider them similar.", "However, depending on the input data, setting this threshold might be complex or time consuming. For simplicity, we can use another classifier that will, given an input distance, classify if this distance is the one of similar or dissimilar objects. My choice was to use a logistic regression classifier: finding a linear seperation in our data correspond to learn the threshold classifying our distances.", "Text is an extremely hard-to-process data structure: while it is often said that images are universal, text is cultural. Whether it is by the language used or by the vocabulary proper to its writer, text is difficult to interpret, even for us.", "Nevertheless, in some situations, we would like to be able to measure the similarity between texts. For example, we could want to know:", "This last problem is the context I will use in this article to talk about the text similarity problem: it originates from Kaggle (Quora Question pairs) and was published by the Quora team as a list of questions marked as being duplicate or not.", "As explained in 1.a, multiple architectures have been created for the task of similarity learning. For the context of this task, we will focus on the Siamese Recurrent Neural Network (Thyagarajan, 2015).", "A Siamese Recurrent Neural Network is a neural network using stacks of RNN to compute a fix-sized vector representation of the input data.", "A global view of my siamese network is as follows:", "The code for my architecture used on the Quora dataset as a stack of BiLSTMs (Bidirectional LSTM) is the following:", "This stack of BiLSTM is then used by the following Encoder class:", "Two main components are to be noticed in this model:", "Described in (Hadsell, Chopra and LeCun, 2006), the goal of the contrastive loss is to train the model to put similar data closer together (i.e. minimising their distance) and dissimilar data further away from each other (i.e. maximising their distance). Its formula is the following:", "This formula is pretty straightforward to understand:", "Source code for the project can be found in Github at the following link: https://github.com/dimartinot/Text-Semantic-Similarity/", "I achieved performances of 76% to 79% accuracy over all 3 sets of data (train, val & test) as well as 0.83 AUC Score.", "Koch, G., Zemel, R. and Salakhutdinov, R., 2015. Siamese neural networks for one-shot image recognition. ICML Deep Learning Workshop.", "Silberer, C. and Lapata, M., 2015. Learning Grounded Meaning Representations with Autoencoders. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pp.721\u2013732.", "Thyagarajan, A. 2015. Siamese Recurrent Architectures for Learning Sentence Similarity.", "Hadsell, Raia & Chopra, Sumit & Lecun, Yann. 2006. Dimensionality Reduction by Learning an Invariant Mapping.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "As a French PhD student, I am passionate to whatever comes close to Artificial Intelligence and Earth Observation."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F89d9c26f8392&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://dimartinot.medium.com/?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": ""}, {"url": "https://dimartinot.medium.com/?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "Thomas Di Martino"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd9193bbca1e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&user=Thomas+Di+Martino&userId=d9193bbca1e2&source=post_page-d9193bbca1e2----89d9c26f8392---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F89d9c26f8392&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F89d9c26f8392&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@rvignes?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Romain Vignes"}, {"url": "https://unsplash.com/s/photos/text?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://github.com/dimartinot/Text-Semantic-Similarity/", "anchor_text": "https://github.com/dimartinot/Text-Semantic-Similarity/"}, {"url": "https://github.com/dimartinot/Text-Semantic-Similarity/blob/master/notebook/EDA.ipynb", "anchor_text": "https://github.com/dimartinot/Text-Semantic-Similarity/blob/master/notebook/EDA.ipynb"}, {"url": "https://github.com/dimartinot/Text-Semantic-Similarity/blob/master/notebook/Training.ipynb", "anchor_text": "https://github.com/dimartinot/Text-Semantic-Similarity/blob/master/notebook/Training.ipynb"}, {"url": "https://github.com/dimartinot/Text-Semantic-Similarity/tree/master/src/model", "anchor_text": "https://github.com/dimartinot/Text-Semantic-Similarity/tree/master/src/model"}, {"url": "https://www.kaggle.com/c/quora-question-pairs/overview", "anchor_text": "Kaggle"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----89d9c26f8392---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----89d9c26f8392---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/siamese-networks?source=post_page-----89d9c26f8392---------------siamese_networks-----------------", "anchor_text": "Siamese Networks"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----89d9c26f8392---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----89d9c26f8392---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F89d9c26f8392&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&user=Thomas+Di+Martino&userId=d9193bbca1e2&source=-----89d9c26f8392---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F89d9c26f8392&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&user=Thomas+Di+Martino&userId=d9193bbca1e2&source=-----89d9c26f8392---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F89d9c26f8392&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F89d9c26f8392&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----89d9c26f8392---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----89d9c26f8392--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----89d9c26f8392--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----89d9c26f8392--------------------------------", "anchor_text": ""}, {"url": "https://dimartinot.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://dimartinot.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Thomas Di Martino"}, {"url": "https://dimartinot.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "78 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd9193bbca1e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&user=Thomas+Di+Martino&userId=d9193bbca1e2&source=post_page-d9193bbca1e2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbef9317e5499&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-deep-similarity-learning-for-sequences-89d9c26f8392&newsletterV3=d9193bbca1e2&newsletterV3Id=bef9317e5499&user=Thomas+Di+Martino&userId=d9193bbca1e2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}