{"url": "https://towardsdatascience.com/confidence-intervals-for-permutation-importance-2d025bc740c5", "time": 1683000784.154956, "path": "towardsdatascience.com/confidence-intervals-for-permutation-importance-2d025bc740c5/", "webpage": {"metadata": {"title": "Confidence intervals for permutation importance | by Luke Merrick | Towards Data Science", "h1": "Confidence intervals for permutation importance", "description": "In this post, we explain how a new theoretical perspective on the popular permutation feature importance technique allows us to quantify its uncertainty with confidence intervals and avoid potential\u2026"}, "outgoing_paragraph_urls": [{"url": "https://blog.fiddler.ai/2019/09/regulations-to-trust-ai-are-here-and-its-a-good-thing/", "anchor_text": "AI continues to grow more regulated", "paragraph_index": 3}, {"url": "https://fiddler.ai/", "anchor_text": "Fiddler Labs", "paragraph_index": 9}, {"url": "https://arxiv.org/abs/1910.00174", "anchor_text": "recent preprint released on arXiv", "paragraph_index": 10}, {"url": "https://gist.github.com/lukemerrick/e31d9a8ec1b42767ad09155eb2f9b231", "anchor_text": "Jupyter notebook here", "paragraph_index": 14}, {"url": "https://blog.fiddler.ai/", "anchor_text": "Fiddler\u2019s blog", "paragraph_index": 20}, {"url": "https://arxiv.org/abs/1910.00174", "anchor_text": "full paper", "paragraph_index": 20}, {"url": "http://jse.amstat.org/v19n3/decock.pdf", "anchor_text": "http://jse.amstat.org/v19n3/decock.pdf", "paragraph_index": 21}], "all_paragraphs": ["In this post, we explain how a new theoretical perspective on the popular permutation feature importance technique allows us to quantify its uncertainty with confidence intervals and avoid potential pitfalls in its use.", "First, let\u2019s motivate the \u201cwhy\u201d of using this technique in the first place. Let\u2019s imagine you just got hired onto the data science team at a major international retailer. Prior to your arrival, this team built a complex model to forecast weekly sales at each of your dozens of locations around the globe. The model takes into account a multitude of factors: geographic data (like local population density and demographics), seasonality data, weather forecast data, information about individual stores (like total square footage), and even the number of likes your company\u2019s tweets have been getting recently. Let\u2019s assume, too, that this model works wonders, giving the business team advance insight into future sales patterns weeks in advance. There is just one problem. Can you guess what it is?", "Nobody knows why the sales forecast model works so well.", "Why is this a problem? A number of reasons. The business folks relying on the model\u2019s predictions have no idea how reliable they would be if, say, Twitter experienced an outage and tweet likes decreased one week. On the data science team, you have little sense of what factors are most useful to the model, so you\u2019re flying blind when it comes to identifying new signals with which to bolster your model\u2019s performance. And let\u2019s not forget other stakeholders. If a decision based on this model\u2019s forecast were to lead to bad results for the company, the board will want to know a lot more about this model than \u201cit just works,\u201d especially as AI continues to grow more regulated.", "So what can we do? A great first step is to get some measure of feature importance. This means assigning a numerical score of importance to each of the factors that your model uses. These numerical scores represent how important these features are to your model\u2019s ability to make quality predictions.", "Many modeling techniques come with built-in feature importance measurements. Perhaps you can use the information-gain-based importance measure that comes by default with your xgboost model? Not so fast! As your teammates will point out, there is no guarantee that these feature importances will describe your complex ensemble, and besides, gain-based importance measures are biased [1].", "So what can we do instead? We can use \u201crandomized ablation\u201d (aka \u201cpermutation\u201d) feature importance measurements. Christoph Molnar offers a clear and concise description of this technique in his Interpretable ML Book [2]:", "The concept is really straightforward: We measure the importance of a feature by calculating the increase in the model\u2019s prediction error after permuting the feature. A feature is \u201cimportant\u201d if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction. A feature is \u201cunimportant\u201d if shuffling its values leaves the model error unchanged, because in this case the model ignored the feature for the prediction.", "Where did this technique come from? Randomized ablation feature importance is certainly not new. Indeed, its inception dates back to at least 2001, when a variant of this technique was introduced as the \u201cnoising\u201d of variables to better understand how random forest models use them [3]. Recently, however, this technique has seen a resurgence in use and variation. For example, an implementation of this technique will be included in the upcoming version 0.22 of the popular Scikit-learn library [4]. For a more theoretical example, consider the recently-introduced framework of \u201cmodel class reliance,\u201d which has termed a variant of the randomized ablation feature importance \u201cmodel reliance\u201d and used it as a core building block [5].", "While working with this technique at Fiddler Labs, we have sought to develop a clear sense of what it means, theoretically, to permute a column of your features, run that through your model, and see how much the model\u2019s error increases. This has led us to use the theoretical lens of randomized ablation, hence our new name for what is commonly called permutation feature importance.", "In a recent preprint released on arXiv, we develop a clear theoretical formulation of this technique as it relates to the classic statistical learning problem statement. We find that the notion of measuring error after permuting features (or, more formally, ablating them through randomization) actually fits in quite nicely with the mathematics of risk minimization in supervised learning [6]. If you are familiar with this body of theory, we hope this connection will be as helpful to your intuition as it has been to ours.", "Additionally, our reformulation provides two ways of constructing confidence intervals around the randomization ablation feature importance scores, a technique that practitioners can use to avoid potential pitfalls in the application of randomized ablation feature importance. To the best of our knowledge, current formulations and implementations of this technique do not include these confidence measurements.", "Consider what might happen if we were to re-run randomized ablation feature importance with a different randomized ablation (e.g. by using a different random seed), or if we run it on two different random subsets of a very large dataset (e.g. to avoid using a full dataset that would exceed our machine\u2019s memory capacity). Our feature importances might change! Ideally, we would want to use a large dataset and average over many ablations to mitigate the randomness inherent in the algorithm, but in practice, we may not have enough data or compute power to do so.", "There are two sources of uncertainty in the randomized ablation feature importance scores: the data points we use, and the random ablation values (i.e. permutation) we use. By running the algorithm multiple times and examining the run-to-run variance, we can construct a confidence interval (CI) that measures the uncertainty stemming from the ablation used. Similarly, by looking point-by-point at the loss increases caused by ablation (instead of just averaging loss over our dataset), we can construct a CI that measures the uncertainty stemming from our finite dataset.", "To demonstrate the use of randomized ablation feature importance values with CIs, let\u2019s apply the technique to a real model. To this end, I used the Ames Housing Dataset [7] to build a complex model that estimates the sale price of houses. The full code for this example is available in a Jupyter notebook here.", "To show the importance of confidence intervals, we run randomized ablation feature importance using just 100 points, with just K=3 repetitions. This gives us the following top-10 features by score, with a 95% confidence interval indicated by the black error bars:", "As we can see from our error bars, it is uncertain which feature is actually the third most important over these 100 points. Re-running randomized ablation feature importance with K=30 iterations, we arrive at much tighter error bounds, and we find with confidence that a house\u2019s neighborhood actually edges out its total basement square footage in importance to our model:", "However, it turns out that a larger source of uncertainty in these feature importance scores actually stems from the small size of the dataset used, rather than the small number of ablation repetitions. This fact is uncovered by using the other CI methodology presented in our paper, which captures uncertainty resulting from both ablation and the size of the dataset. Running this other CI technique on another 100 points of our dataset (with just one repetition) we observe the following wide CIs:", "By increasing the number of points to 500 instead of 100, our confidence improves significantly, and we become fairly confident that neighborhood is the third most important feature to our model overall (not just in our limited dataset).", "Feature importance techniques are a powerful and easy way to gain valuable insight about your machine learning models. The randomized ablation feature importance technique, often referred to as \u201cpermutation\u201d importance, offers a straightforward and broadly-applicable technique for computing feature importances. We also showed here how, through a new way of theorizing and formulating the \u201ctrue\u201d value of randomized ablation feature importance, we are able to construct confidence intervals around our feature importance measurements. These confidence intervals are a useful tool for avoiding pitfalls in practice, especially when datasets are not large.", "If you liked this post, you can find more like it on Fiddler\u2019s blog, and if you want a deeper dive into CIs for randomized ablation feature importance, be sure to check out the full paper. Don\u2019t worry, it\u2019s only four pages long!", "[7] De Cock, Dean. Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project (2011). http://jse.amstat.org/v19n3/decock.pdf", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2d025bc740c5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@lukemerrick_?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lukemerrick_?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "Luke Merrick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F54932a03b331&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&user=Luke+Merrick&userId=54932a03b331&source=post_page-54932a03b331----2d025bc740c5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d025bc740c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d025bc740c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://blog.fiddler.ai/2019/09/regulations-to-trust-ai-are-here-and-its-a-good-thing/", "anchor_text": "AI continues to grow more regulated"}, {"url": "https://fiddler.ai/", "anchor_text": "Fiddler Labs"}, {"url": "https://arxiv.org/abs/1910.00174", "anchor_text": "recent preprint released on arXiv"}, {"url": "https://gist.github.com/lukemerrick/e31d9a8ec1b42767ad09155eb2f9b231", "anchor_text": "Jupyter notebook here"}, {"url": "https://blog.fiddler.ai/", "anchor_text": "Fiddler\u2019s blog"}, {"url": "https://arxiv.org/abs/1910.00174", "anchor_text": "full paper"}, {"url": "https://explained.ai/rf-importance/", "anchor_text": "https://explained.ai/rf-importance/"}, {"url": "https://christophm.github.io/interpretable-ml-book/feature-importance.html", "anchor_text": "https://christophm.github.io/interpretable-ml-book/feature-importance.html"}, {"url": "https://www.stat.berkeley.edu/%7Ebreiman/randomforest2001.pdf", "anchor_text": "https://www.stat.berkeley.edu/%7Ebreiman/randomforest2001.pdf"}, {"url": "https://scikit-learn.org/dev/modules/permutation_importance.html", "anchor_text": "https://scikit-learn.org/dev/modules/permutation_importance.html"}, {"url": "https://arxiv.org/abs/1801.01489", "anchor_text": "https://arxiv.org/abs/1801.01489"}, {"url": "https://arxiv.org/abs/1910.00174", "anchor_text": "https://arxiv.org/abs/1910.00174"}, {"url": "http://jse.amstat.org/v19n3/decock.pdf", "anchor_text": "http://jse.amstat.org/v19n3/decock.pdf"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2d025bc740c5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----2d025bc740c5---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/feature-importance?source=post_page-----2d025bc740c5---------------feature_importance-----------------", "anchor_text": "Feature Importance"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2d025bc740c5---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/ai?source=post_page-----2d025bc740c5---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d025bc740c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&user=Luke+Merrick&userId=54932a03b331&source=-----2d025bc740c5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d025bc740c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&user=Luke+Merrick&userId=54932a03b331&source=-----2d025bc740c5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d025bc740c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2d025bc740c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2d025bc740c5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2d025bc740c5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2d025bc740c5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2d025bc740c5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lukemerrick_?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lukemerrick_?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Luke Merrick"}, {"url": "https://medium.com/@lukemerrick_/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "26 Followers"}, {"url": "http://lukemerrick.com", "anchor_text": "lukemerrick.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F54932a03b331&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&user=Luke+Merrick&userId=54932a03b331&source=post_page-54932a03b331--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F338ddfed5f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconfidence-intervals-for-permutation-importance-2d025bc740c5&newsletterV3=54932a03b331&newsletterV3Id=338ddfed5f21&user=Luke+Merrick&userId=54932a03b331&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}