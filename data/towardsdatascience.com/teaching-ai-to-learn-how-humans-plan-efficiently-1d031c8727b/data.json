{"url": "https://towardsdatascience.com/teaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b", "time": 1683012969.489964, "path": "towardsdatascience.com/teaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b/", "webpage": {"metadata": {"title": "Teaching AI to Learn How Humans Plan Efficiently | by Agni Kumar | Towards Data Science", "h1": "Teaching AI to Learn How Humans Plan Efficiently", "description": "Human planning is hierarchical. Whether planning something simple like cooking dinner or something complex like a trip abroad, we usually begin with a rough mental sketch of the goals we want to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/agnikumar/chunking", "anchor_text": "here", "paragraph_index": 53}, {"url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007594&rev=2", "anchor_text": "recent paper", "paragraph_index": 53}, {"url": "http://www.mit.edu/afs/athena.mit.edu/user/a/g/agnik/www/assets/files/hierarchical_rl.pdf", "anchor_text": "Reward Generalization and Reward-Based Hierarchy Discovery for Planning", "paragraph_index": 54}, {"url": "https://psycnet.apa.org/record/1957-02914-001", "anchor_text": "The magic number seven plus or minus two: Some limits on our capacity for processing information", "paragraph_index": 55}, {"url": "https://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.06134", "anchor_text": "Examples of Adaptive MCMC", "paragraph_index": 56}, {"url": "https://www.researchgate.net/publication/303357683_Neural_Mechanisms_of_Hierarchical_Planning_in_a_Virtual_Subway_Network", "anchor_text": "Neural mechanisms of hierarchical planning in a virtual subway network", "paragraph_index": 57}, {"url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007594&rev=2", "anchor_text": "Discovery of hierarchical representations for efficient planning", "paragraph_index": 58}, {"url": "https://amstat.tandfonline.com/doi/abs/10.1080/10618600.2000.10474879", "anchor_text": "Markov Chain Sampling Methods for Dirichlet Process Mixture Models", "paragraph_index": 59}, {"url": "https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf", "anchor_text": "Reinforcement Learning: An Introduction", "paragraph_index": 60}], "all_paragraphs": ["Human planning is hierarchical. Whether planning something simple like cooking dinner or something complex like a trip abroad, we usually begin with a rough mental sketch of the goals we want to achieve (\u201cgo to India, then return back home\u201d). This sketch is then progressively refined into a detailed sequence of sub-goals (\u201cbook flight ticket\u201d, \u201cpack luggage\u201d), sub-sub-goals, and so on, down to the actual sequence of bodily movements that is much more complicated than the original plan.", "Efficient planning requires knowledge of the abstract high-level concepts that constitute the essence of hierarchical plans. Yet how humans learn such abstractions remains a mystery.", "Here, we show that humans spontaneously form such high-level concepts in a way that allows them to plan efficiently given the tasks, rewards, and structure of their environment. We also show that this behavior is consistent with a formal model of the underlying computations, thus grounding these findings in established computational principles and relating them to previous studies of hierarchical planning.", "The figure above depicts an example of hierarchical planning, namely how someone might plan to get from their office in Cambridge to purchase a dream wedding dress in Patna, India. Circles represent states and arrows represent actions that transition between states. Each state represents a cluster of states in the lower level. Thicker arrows indicate transitions between higher-level states, which often come to mind first.", "When applied to computationally intelligent agents, hierarchical planning could enable models with advanced planning abilities. Hierarchical representations can be modeled from a Bayesian viewpoint by assuming a generative process for the structure of a particular environment. Existing work on this problem includes the development of a computational framework for acquiring hierarchical representations under a set of simplified assumptions on the hierarchy, i.e. modeling how people create clusters of states in their mental representations of reward-free environments in order to facilitate planning.", "In this work, we contribute a Bayesian cognitive model of hierarchical discovery that combines knowledge of clustering and rewards to predict cluster formation, and compare the model to data obtained from humans.", "We analyze situations with both static and dynamic reward mechanisms, finding that humans generalize information about rewards to high-level clusters and use information about rewards to create clusters, and that reward generalization and reward-based cluster formation can be predicted by our proposed model.", "A key area where psychology and neuroscience combine is the formal understanding of human behavior in relation to assigned actions. We ask:", "What is the planning and methodology employed by human agents when faced with accomplishing some task? How do humans discover useful abstractions?", "This is especially interesting in light of the unique ability of humans and animals to adapt to new environments. Previous literature on animal learning suggests that this flexibility stems from a hierarchical representation of goals that allows for complex tasks to be broken up into low-level subroutines that can be extended across a variety of contexts.", "The process of chunking occurs when actions are stitched together into temporally extended action sequences that achieve distant goals. Chunking is often the result of the transfer of learning from a goal-directed system to a habitual system, which executes actions in a stereotyped way.", "From a computational standpoint, such a hierarchical representation allows for agents to quickly execute actions in an open loop, reuse familiar action sequences whenever a known problem is encountered, learn faster by tweaking established action sequences to solve problems reminiscent of those seen previously, and plan over extended time horizons. Agents do not need to be concerned with the minuscule tasks associated with goal achievement, e.g., the goal of going to the store being broken down into leaving the house, walking, and entering the store as opposed to getting up out of bed, moving the left foot forward, then the right one, etc.", "The question of how agents should make rewarding decisions is the subject of reinforcement learning. Hierarchical reinforcement learning (HRL) has become the prevailing framework for representing hierarchical learning and planning. Within research on modeling of HRL, several ideas have been presented around potential methods of model construction.", "We focus on the idea that people spontaneously organize their environment into clusters of states that constrain planning. Such hierarchical planning is more efficient in time and memory than naive or flat planning, which include low-level actions and is consistent with people\u2019s limited working memory capacity [3].", "In the diagram below, thick nodes and edges indicate that they must all be considered and maintained in short-term memory in order to compute the plan, and gray arrows indicate cluster membership. We observe that planning how to get from state s to state g in the low-level graph G takes at least as many steps as actually executing the plan (top), introducing high-level graph H alleviates this problem reduces computational costs (middle), and extending the hierarchy recursive further reduces the time and memory involved in planning (bottom).", "Solway et al. provide a formal definition of an optimal hierarchy, but they do not specify how the brain might discover it [2]. We hypothesize that an optimal hierarchy depends on the structure of environment, including both graph structure and the distribution of observable features of the environment, specifically rewards.", "We assume that agents represent their environment as a graph, where nodes are states in the environment and edges are transitions between states. The states and transitions may be abstract or as concrete as subway stations and the train lines traveling between them.", "We represent the observable environment as graph G = (V, E) and the latent hierarchy as H. Both G and H are unweighted, undirected graphs. H consists of clusters, where each low-level node in G belongs to exactly one cluster, and bridges, or high-level edges, that connect these clusters. Bridges can exist between clusters k and k\u2019 only if there is an edge between some v, v\u2019 \u2208 V such that v \u2208 k and v\u2019\u2208 k\u2019, i.e., each high-level edge in H has a corresponding low-level edge in G.", "In the illustration below, colors denote cluster assignments. Black edges are considered during planning, while gray edges are ignored by the planner. Thick edges correspond to transitions across clusters. The transition between clusters w and z is accomplished via a bridge.", "Prior to the addition of rewards, the learning algorithm discovers optimal hierarchies given the following constraints:", "However, we do not want clusters to be too small \u2014 in the extreme, each node is its own cluster, which renders the hierarchy useless. Additionally, while we want sparse connectivity across clusters, we want to maintain bridges across clusters in order to preserve properties of the underlying graphs.", "We use the discrete-time stochastic Chinese Restaurant Process (CRP) as a prior for clusters. The discovery of hierarchies can be accomplished by inverting the generative model to obtain the posterior probability of hierarchy H. The generative model formally presented in [6] generates such hierarchies.", "In the context of the graph G, rewards can be interpreted as observable features of vertices. Because people often cluster based on observable features, it is reasonable to model clusters induced by rewards [5]. Furthermore, we assume that each state delivers a randomly determined reward and that the agent\u2019s goal is to maximize the total reward [8].", "Since we hypothesize that clusters induce rewards, we model each cluster as having an average reward. Each node in that cluster has an average reward drawn from a distribution centered around the average cluster reward. Finally, each observed reward is drawn from a distribution centered around the average reward of that node. A formal discussion is provided in [1].", "To simplify inference, we first assume that rewards are constant, static. We label rewards that can change between observations with some fixed probability as dynamic.", "We conducted two experiments to test our hypothesis about human behavior and understand how well it could be predicted by our model. In particular, we studied to what degree clusters drive inferences about rewards, and to what degree rewards drive the formation of clusters. For each experiment, we collected human data and compared it to the predictions of the model.", "The goal of the first experiment was to understand how rewards generalize within state clusters. We tested whether graph structure drives cluster formations and whether people generalize a reward observed at one node to the cluster that the node belongs to.", "The experiment was conducted by asking 32 human subjects to choose a node to visit next as specified in the following scenario. Participants were randomly presented with either the graph below or a flipped version of it, to ensure that bias of handedness or graph structure was not introduced. We predicted that participants would choose the node adjacent to the labeled one that was located in the larger cluster, i.e. the gray node to the left of the blue one in the first case, and the gray node to the right of the blue one in the second case.", "Participants were presented with the following task and associated graph:", "You work in a large gold mine that is composed of multiple individual mines and tunnels. The layout of the mines is shown in the diagram below (each circle represents a mine, and each line represents a tunnel). You are paid daily, and are paid $10 per gram of gold you found that day. You dig in exactly one mine per day, and record the amount of gold (in grams) that mine yielded that day. Over the last few months, you have discovered that, on average, each mine yields about 15 grams of gold per day. Yesterday, you dug in the blue mine in the diagram below, and got 30 grams of gold. Which of the two shaded mines will you dig in today? Please circle the mine you choose.", "We expected most participants to automatically identify the following clusters, with nodes colored in peach and lavender to denote the different clusters, and make a decision about which mine to select with these clusters in mind. It was hypothesized that participants would select a peach-colored node as opposed to a lavender one, since the node with label 30, a fairly larger than average reward, is in the peach-colored cluster.", "We approximated Bayesian inference over H using Metropolis-within-Gibbs sampling [4], which updates each component of H by sampling from its posterior, conditioning on all other components in a single Metropolis-Hastings step. We employed a Gaussian random walk as the proposal distribution for continuous components, and the conditional CRP prior as the proposal distribution for cluster assignments [7]. The approach can be interpreted as stochastic hill climbing with respect to a utility function defined by the posterior.", "There were 32 participants in each of the human and simulated groups. The top three clusterings outputted by the model are shown below (left panel). All top three results were the same, indicating that the model identified the colored groupings with high confidence. The results for participants, as well as those for the static rewards model, are visualized in the bar chart below (right panel), depicting the proportion of human and simulated subjects who chose to visit node 2 next. The solid black line indicates the mean and the dotted black lines indicate the 2.5th and 97.5th percentiles.", "The listed p-values in the table below were calculated via a right-tailed binomial test, where the null was assumed to be a binomial distribution over choosing left or right gray node. The significance level was taken to be 0.05, and both the human experimental results and modeling results were statistically significant.", "In the second experiment, the goal was to determine whether rewards induce clusters. We predicted that nodes with the same reward positioned adjacent to each other would be clustered together, even if the structure of the graph alone would not induce clusters.", "Recall that Solway et. al showed that people prefer paths that cross the fewest hierarchy boundaries [2]. Therefore, between two otherwise identical paths, the only reason to prefer one over the other would be because it crosses fewer hierarchy boundaries. One possible counterargument to this is that people pick the path with higher rewards. However, in our setup detailed below, rewards are given only in the goal state, not cumulatively over the path taken. Additionally, the magnitude of rewards was varied between trials. Therefore, it is unlikely that people would favor a path because nodes along that path had higher rewards.", "This experiment was conducted on the web using Amazon Mechanical Turk (MTurk). Participants were given the following context about the task:", "Imagine you are a miner working in a network of gold mines connected by tunnels. Every mine yields a certain amount of gold (points) each day. On each day, your job is to navigate from a starting mine to a target mine and collect the points from the target mine. On some days, you will be free to choose any mine you like. On those days, you should try to pick the mine that yields the most points. On other days, only one mine will be available. The points of that mine will be written in green and the other mines will be grayed out. On those days, you should navigate to the available mine. The points of each mine will be written on it. The current mine will be highlighted with a thick border. You can navigate between mines using the arrow keys (up, down, left, right). Once you reach the target mine, press the space key to collect the points and start the next day. There will be 100 days (trials) in the experiment.", "The graph below (left panel) was presented to participants. As in the previous experiment, participants were randomly given either the configuration shown in or the horizontally-flipped version of the same graph in order to control for potential left-right asymmetry. Expected induced clusters are depicted as well, with nodes numbered for reference (right panel).", "We will refer to the first case, where participants are free to navigate to any mine, as free-choice and the second case, where participants navigate to a specified mine, as fixed-choice. Participants received a monetary reward for each trial to discourage random responses.", "At each trial, reward values were changed with probability 0.2. New rewards were drawn uniformly at random from the interval [0, 300]. However, the grouping of rewards remained the same across trials: nodes 1, 2, and 3 always had one reward value, nodes 4, 5, and 6 had a different reward value, and nodes 7, 8, 9, and 10 had a third reward value.", "The first 99 trials allowed the participant to develop a hierarchy of clusters. The final trial, which acted as the test trial, asked participants to navigate from node 6 to node 1. Assuming that rewards induced the clusters shown in above, we predicted that more participants would take the path through node 5, which crosses only one cluster boundary, over the one through node 7, which crosses two cluster boundaries.", "We modeled the fixed-choice case, with the assumption that the tasks in all 100 trials were all the same as the 100th trial presented to participants, the test trial. First, we assumed static rewards, where the rewards remained constant across all trials. Next, we assumed dynamic rewards, where rewards changed for each trial.", "In contrast to the previous experiment, where the participant picks a single node the model predicts that node, this experiment is concerned with the second node of the full path the participant chose to take from the start node to the goal node. Therefore, in order to compare the model to human data, we used a variant of breadth-first search, hereafter referred to as hierarchical BFS, to predict a path from the start node (node 6) to the goal (node 1).", "Static rewards. For each subject, we sampled from the posterior using Metropolis-within-Gibbs sampling and chose the most probable hierarchy, i.e., the hierarchy with the highest posterior probability. Then, we used hierarchical BFS to first find a path between clusters and then between the nodes within the clusters.", "Dynamic rewards. For dynamic rewards, we used online inference. For each simulated participant, we allowed the sampling for each trial to progress only 10 steps. Then, we saved the hierarchy, and added information about the modified rewards. Next, we allowed sampling to progress again, starting from the saved hierarchy. As in the human experiment, at the beginning of each trial, there was a 0.2 probability that the rewards would be re-randomized to new values, although the rewards were always equal within clusters. This inference method simulated how human participants might learn cumulatively over the course of many trials. We assumed, for the purpose of this experiment, that people keep only one hierarchy in mind at a time, rather than updating multiple hierarchies in parallel. We also modified the log posterior to penalize disconnected clusters, because such clusters became much more common under this type of inference.", "There were 95 participants in each of the human and two simulated groups. The null hypothesis is represented by an equal number of participants choosing a path through node 5 and through node 7, since in the absence of any other information and given that both paths are of equal length, a participant is equally likely to choose either.", "As given in the table above, the results of the human experiment and static rewards modeling were statistically significant at \u03b1 = 0.05. Furthermore, as shown below, the results of the human experiment are in the 90th percentile of a normal distribution centered around 0.5, the expected proportion given the null hypothesis. In the figure, we include clusterings identified by the static rewards model (first row), the static rewards model with cluster formation between disconnected components penalized second row), and the dynamic rewards model (third row).", "Static rewards. We used 1000 iterations of Metropolis-within-Gibbs sampling to generate each sample, with a burnin and lag of 1 each. The simulation under static rewards certainly favors paths through node 5, to a level that is statistically significant. Moreover, since its purpose is to model human behavior, this result is meaningful in light of the human data being statistically significant as well (0.0321 < \u03b1 = 0.05).", "Dynamic rewards. In order to mimic the human trials, we ran 100 trials, each with 10 iterations of Metropolis-within-Gibbs to sample from the posterior. The burnin and lag were again set to 1. The online inference method appears to have modeled human data better than modeling for static rewards, even though the group of simulated participants under dynamic rewards modeling is farther from the hypothesis than the group simulated under static rewards modeling. 56 human participants and 54 simulated participants under dynamic rewards modeling chose to go through node 5 (a 3.4% difference), compared to 64 simulated participants under static rewards modeling (an 18.5% difference).", "The bar chart above visualizes the proportion of human and simulated subjects whose chosen path\u2019s second node was node 5. The solid black line indicates the expected proportion given the null hypothesis and the dotted black lines indicate the 10th and 90th percentiles.", "Humans seem to spontaneously organize environments into clusters of states that support hierarchical planning, enabling them to tackle challenging problems by breaking them down into sub-problems at various levels of abstraction. People constantly rely on such hierarchical presentations to accomplish tasks big and small \u2014 from planning one\u2019s day, to organizing a wedding, to getting a PhD \u2014 often succeeding on the very first attempt.", "We have shown that an optimal hierarchy depends not only on graph structure, but also on observable characteristics of the environment, i.e., the distribution of rewards.", "We built hierarchical Bayesian models to understand how clusters induce static rewards and how both static and dynamic rewards induce clusters, and found that most results were statistically significant in terms of how closely our models captured human actions. All data and code files for all the simulations and experiments presented are available in the GitHub repository linked here. We hope that the model presented, as well as related results in a recent paper, pave the way for future studies to investigate the neural algorithms that support the essential cognitive ability of hierarchical planning.", "[1] A. Kumar and S. Yagati, Reward Generalization and Reward-Based Hierarchy Discovery for Planning (2018), MIT", "[3] G. Miller, The magic number seven plus or minus two: Some limits on our capacity for processing information (1956), The Psychological Review", "[4] G. Roberts and J. Rosenthal, Examples of Adaptive MCMC (2009), Journal of Computational and Graphical Statistics", "[5] J. Balaguer, H. Spiers, D. Hassabis, and C. Summerfield, Neural mechanisms of hierarchical planning in a virtual subway network (2016), Neuron", "[6] M. Tomov, S. Yagati, A. Kumar, W. Yang, and S. Gershman, Discovery of hierarchical representations for efficient planning (2020), PLOS Computational Biology", "[7] R. Neal, Markov Chain Sampling Methods for Dirichlet Process Mixture Models (2000), Journal of Computational and Graphical Statistics", "[8] R. Sutton and A. Barto, Reinforcement Learning: An Introduction (2018), The MIT Press", "Machine Learning Engineer at Apple | MIT Alum"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1d031c8727b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@agnikumar?source=post_page-----1d031c8727b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Agni Kumar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F465ede362700&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&user=Agni+Kumar&userId=465ede362700&source=post_page-465ede362700----1d031c8727b---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d031c8727b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&user=Agni+Kumar&userId=465ede362700&source=-----1d031c8727b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d031c8727b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&source=-----1d031c8727b---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@isaacmsmith", "anchor_text": "Isaac"}, {"url": "https://unsplash.com/photos/6EnTPvPPL6I", "anchor_text": "Unsplash"}, {"url": "https://github.com/agnikumar/chunking", "anchor_text": "here"}, {"url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007594&rev=2", "anchor_text": "recent paper"}, {"url": "http://www.mit.edu/afs/athena.mit.edu/user/a/g/agnik/www/assets/files/hierarchical_rl.pdf", "anchor_text": "Reward Generalization and Reward-Based Hierarchy Discovery for Planning"}, {"url": "http://alm.plos.org/works/doi.org/10.1371/journal.pcbi.1003779?source_id=twitter", "anchor_text": "Optimal behavioral hierarchy"}, {"url": "https://psycnet.apa.org/record/1957-02914-001", "anchor_text": "The magic number seven plus or minus two: Some limits on our capacity for processing information"}, {"url": "https://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.06134", "anchor_text": "Examples of Adaptive MCMC"}, {"url": "https://www.researchgate.net/publication/303357683_Neural_Mechanisms_of_Hierarchical_Planning_in_a_Virtual_Subway_Network", "anchor_text": "Neural mechanisms of hierarchical planning in a virtual subway network"}, {"url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007594&rev=2", "anchor_text": "Discovery of hierarchical representations for efficient planning"}, {"url": "https://amstat.tandfonline.com/doi/abs/10.1080/10618600.2000.10474879", "anchor_text": "Markov Chain Sampling Methods for Dirichlet Process Mixture Models"}, {"url": "https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf", "anchor_text": "Reinforcement Learning: An Introduction"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----1d031c8727b---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1d031c8727b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1d031c8727b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----1d031c8727b---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----1d031c8727b---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d031c8727b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&user=Agni+Kumar&userId=465ede362700&source=-----1d031c8727b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d031c8727b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&user=Agni+Kumar&userId=465ede362700&source=-----1d031c8727b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d031c8727b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=post_page-----1d031c8727b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F465ede362700&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&user=Agni+Kumar&userId=465ede362700&source=post_page-465ede362700----1d031c8727b---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F325aa6b3e06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&newsletterV3=465ede362700&newsletterV3Id=325aa6b3e06c&user=Agni+Kumar&userId=465ede362700&source=-----1d031c8727b---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Written by Agni Kumar"}, {"url": "https://medium.com/@agnikumar/followers?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "128 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F465ede362700&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&user=Agni+Kumar&userId=465ede362700&source=post_page-465ede362700----1d031c8727b---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F325aa6b3e06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-ai-to-learn-how-humans-plan-efficiently-1d031c8727b&newsletterV3=465ede362700&newsletterV3Id=325aa6b3e06c&user=Agni+Kumar&userId=465ede362700&source=-----1d031c8727b---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/age-of-awareness/how-i-graduated-from-mit-with-4-degrees-in-4-years-bc78e0875355?source=author_recirc-----1d031c8727b----0---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=author_recirc-----1d031c8727b----0---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=author_recirc-----1d031c8727b----0---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Agni Kumar"}, {"url": "https://medium.com/age-of-awareness?source=author_recirc-----1d031c8727b----0---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Age of Awareness"}, {"url": "https://medium.com/age-of-awareness/how-i-graduated-from-mit-with-4-degrees-in-4-years-bc78e0875355?source=author_recirc-----1d031c8727b----0---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "How I Graduated From MIT With 4 Degrees in 4 YearsIt\u2019s all about optimization and balance. And no, I didn\u2019t go insane."}, {"url": "https://medium.com/age-of-awareness/how-i-graduated-from-mit-with-4-degrees-in-4-years-bc78e0875355?source=author_recirc-----1d031c8727b----0---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "\u00b77 min read\u00b7Jun 26, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fage-of-awareness%2Fbc78e0875355&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fage-of-awareness%2Fhow-i-graduated-from-mit-with-4-degrees-in-4-years-bc78e0875355&user=Agni+Kumar&userId=465ede362700&source=-----bc78e0875355----0-----------------clap_footer----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/age-of-awareness/how-i-graduated-from-mit-with-4-degrees-in-4-years-bc78e0875355?source=author_recirc-----1d031c8727b----0---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc78e0875355&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fage-of-awareness%2Fhow-i-graduated-from-mit-with-4-degrees-in-4-years-bc78e0875355&source=-----1d031c8727b----0-----------------bookmark_preview----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d031c8727b----1---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----1d031c8727b----1---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----1d031c8727b----1---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----1d031c8727b----1---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d031c8727b----1---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d031c8727b----1---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d031c8727b----1---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----1d031c8727b----1-----------------bookmark_preview----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----1d031c8727b----2---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----1d031c8727b----2---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----1d031c8727b----2---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----1d031c8727b----2---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----1d031c8727b----2---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----1d031c8727b----2---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----1d031c8727b----2---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----1d031c8727b----2-----------------bookmark_preview----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar/the-right-way-to-introduce-yourself-at-work-3a7cb1a1f93d?source=author_recirc-----1d031c8727b----3---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=author_recirc-----1d031c8727b----3---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=author_recirc-----1d031c8727b----3---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "Agni Kumar"}, {"url": "https://medium.com/@agnikumar/the-right-way-to-introduce-yourself-at-work-3a7cb1a1f93d?source=author_recirc-----1d031c8727b----3---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "The Right Way to Introduce Yourself at WorkA powerful three-slide deck that will make people remember you"}, {"url": "https://medium.com/@agnikumar/the-right-way-to-introduce-yourself-at-work-3a7cb1a1f93d?source=author_recirc-----1d031c8727b----3---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": "\u00b73 min read\u00b7Oct 17, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F3a7cb1a1f93d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40agnikumar%2Fthe-right-way-to-introduce-yourself-at-work-3a7cb1a1f93d&user=Agni+Kumar&userId=465ede362700&source=-----3a7cb1a1f93d----3-----------------clap_footer----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar/the-right-way-to-introduce-yourself-at-work-3a7cb1a1f93d?source=author_recirc-----1d031c8727b----3---------------------0b1bab86_d06e_4345_b9e2_d8f47fc13530-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a7cb1a1f93d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40agnikumar%2Fthe-right-way-to-introduce-yourself-at-work-3a7cb1a1f93d&source=-----1d031c8727b----3-----------------bookmark_preview----0b1bab86_d06e_4345_b9e2_d8f47fc13530-------", "anchor_text": ""}, {"url": "https://medium.com/@agnikumar?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "See all from Agni Kumar"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----1d031c8727b----0-----------------bookmark_preview----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----1d031c8727b----1-----------------bookmark_preview----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----1d031c8727b----0---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----1d031c8727b----0-----------------bookmark_preview----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----1d031c8727b----1---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----1d031c8727b----1-----------------bookmark_preview----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----1d031c8727b----2---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----1d031c8727b----2---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----1d031c8727b----2---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Josep Ferrer"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----1d031c8727b----2---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----1d031c8727b----2---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Stop doing this on ChatGPT and get ahead of the 99% of its usersUnleash the Power of AI Writing with Effective Prompts"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----1d031c8727b----2---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "\u00b78 min read\u00b7Mar 31"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&user=Josep+Ferrer&userId=8213af8f3ccf&source=-----f3441bf7a25a----2-----------------clap_footer----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----1d031c8727b----2---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "71"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&source=-----1d031c8727b----2-----------------bookmark_preview----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----1d031c8727b----3---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----1d031c8727b----3---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----1d031c8727b----3---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Aleid ter Weel"}, {"url": "https://medium.com/better-advice?source=read_next_recirc-----1d031c8727b----3---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "Better Advice"}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----1d031c8727b----3---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "10 Things To Do In The Evening Instead Of Watching NetflixDevice-free habits to increase your productivity and happiness."}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----1d031c8727b----3---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": "\u00b75 min read\u00b7Feb 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-advice%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&user=Aleid+ter+Weel&userId=6ffe087f07e5&source=-----4e270e9dd6b9----3-----------------clap_footer----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----1d031c8727b----3---------------------8689b9b1_6745_445c_80d2_6ac43996ff5d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "204"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&source=-----1d031c8727b----3-----------------bookmark_preview----8689b9b1_6745_445c_80d2_6ac43996ff5d-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1d031c8727b--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----1d031c8727b--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}