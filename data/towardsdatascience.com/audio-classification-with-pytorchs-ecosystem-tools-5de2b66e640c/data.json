{"url": "https://towardsdatascience.com/audio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c", "time": 1683015336.857162, "path": "towardsdatascience.com/audio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c/", "webpage": {"metadata": {"title": "Audio Classification with PyTorch\u2019s Ecosystem Tools | by Dan Malowany | Towards Data Science", "h1": "Audio Classification with PyTorch\u2019s Ecosystem Tools", "description": "Audio signals are all around us. As such, there is an increasing interest in audio classification for various scenarios, from fire alarm detection for hearing impaired people, through engine sound\u2026"}, "outgoing_paragraph_urls": [{"url": "https://allegro.ai/blog/ml-dl-engineering-made-easy-with-pytorch-and-allegro-trains/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "image classification", "paragraph_index": 1}, {"url": "https://allegro.ai/blog/accelerate-hyperparameter-optimization-with-pytorchs-ecosystem-tools/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "hyperparameters optimization", "paragraph_index": 1}, {"url": "https://pytorch.org/audio/", "anchor_text": "Torchaudio", "paragraph_index": 1}, {"url": "https://allegro.ai/trains-open-source/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "Allegro Trains", "paragraph_index": 1}, {"url": "http://t.allegro.ai/code_pytorch_audioclassification", "anchor_text": "this script", "paragraph_index": 3}, {"url": "https://pytorch.org/audio/datasets.html#yesno", "anchor_text": "YesNo", "paragraph_index": 3}, {"url": "https://pytorch.org/audio/datasets.html", "anchor_text": "torchaudio built-in datasets", "paragraph_index": 3}, {"url": "http://t.allegro.ai/git_trains_server_p1", "anchor_text": "Trains-server", "paragraph_index": 12}, {"url": "http://t.allegro.ai/demo_pytorch_audioclassification", "anchor_text": "demo server", "paragraph_index": 12}, {"url": "https://allegro.ai/docs/deploying_trains/trains_deploy_overview/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "documentation", "paragraph_index": 12}, {"url": "https://urbansounddataset.weebly.com/urbansound8k.html", "anchor_text": "UrbanSound8K", "paragraph_index": 13}, {"url": "http://t.allegro.ai/UrbanSound8", "anchor_text": "full notebook", "paragraph_index": 21}, {"url": "http://t.allegro.ai/git_trains_agent_p1", "anchor_text": "Trains Agent", "paragraph_index": 22}, {"url": "http://t.allegro.ai/demo_pytorch_audioclassification", "anchor_text": "Allegro Trains\u2019 web app", "paragraph_index": 22}, {"url": "https://allegro.ai/docs/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "Allegro Trains\u2019 documentation", "paragraph_index": 25}, {"url": "https://pytorch.org/audio", "anchor_text": "torchaudio documentation", "paragraph_index": 25}, {"url": "https://pytorch.org/docs/stable/torchvision/index.html", "anchor_text": "torchvision documentation", "paragraph_index": 25}], "all_paragraphs": ["Audio signals are all around us. As such, there is an increasing interest in audio classification for various scenarios, from fire alarm detection for hearing impaired people, through engine sound analysis for maintenance purposes, to baby monitoring. Though audio signals are temporal in nature, in many cases it is possible to leverage recent advancements in the field of image classification and use popular high performing convolutional neural networks for audio classification. In this blog post we will demonstrate such an example by using the popular method of converting the audio signal into the frequency domain.", "This blog post is a third of a series on how to leverage PyTorch\u2019s ecosystem tools to easily jumpstart your ML/DL project. The previous blog posts focused on image classification and hyperparameters optimization. In this blog post, we will show how using Torchaudio and Allegro Trains enables simple and efficient audio classification.", "In recent years, Convolutional Neural Networks (CNNs) have proven very effective in image classification tasks, which gave rise to the design of various architectures, such as Inception, ResNet, ResNext, Mobilenet and more. These CNNs achieve state-of-the-art results on image classification tasks and offer a variety of ready to use pre-trained backbones. As such, if we will be able to transfer audio classification tasks into the image domain, we will be able to leverage this rich variety of backbones for our needs.", "As mentioned before, instead of directly using the sound file as an amplitude vs time signal we wish to convert the audio signal into an image. The following preprocessing was done using this script on the YesNo dataset that is included in torchaudio built-in datasets.", "As a first stage of preprocessing we will:", "The code for such preprocessing, looks like this:", "The resulted matplotlib plot looks like this:", "Now it is time to transform this time-series signal into the image domain. We will do that by converting it into a spectogram, which is a visual representation of the spectrum of frequencies of a signal as it varies with time. For that purpose we will use a log-scaled mel-spectrogram. A mel spectrogram is a spectrogram where the frequencies are converted to the mel scale, which takes into account the fact that humans are better at detecting differences in lower frequencies than higher frequencies. The mel scale converts the frequencies so that equal distances in pitch sounded equally distant to a human listener.", "So let\u2019s use torchaudio transforms and add the following lines to our snippet:", "Now the audio file is represented as a two dimensional spectrogram image:", "That\u2019s exactly what we wanted to achieve. The Audio-classification problem is now transformed into an image classification problem.", "Pytorch\u2019s ecosystem includes a variety of open source tools that can jump start our audio classification project and help us manage and support it. In this blog we will use three of these tools:", "For simplification, we will not explain in this blog how to install a Trains-server. Therefore, the experiment will be logged on the Allegro Trains demo server. For further information on how to deploy a self-hosted Trains server, see the Allegro Trains documentation.", "For the purpose of this blog we will use the UrbanSound8K dataset that contains 8732 labeled sound excerpts (<=4s) of urban sounds from 10 classes, including dog barks, siren and street music. We will use a pretrained ResNet model to classify these audio files.", "We will start by initializing Allegro Trains to track everything we do:", "Next we will make sure there are no \u201cmagic numbers\u201d hidden in the code and that all the script parameters are reflected in the experiment manager web app. When writing a python script, you can use the popular argparse package and Allegro Trains will automatically pick it up. As we are writing a Jupyter notebook example we will define a configuration dictionary and connect it to the Allegro Trains task object:", "Now it is time to define our PyTorch Dataset object. This object should include data loading as well as data preprocessing. The loading of the dataset\u2019s metadata is done in the constructor of the class and is configured based on the UrbanSound8K dataset structure. Therefore, it will look as follows:", "The next thing we will do is define the __ getitem__ method of the Dataset class. As explained before we want this part to perform several preprocessing steps:", "In addition to the above, we want all transformed signals to have the same shape. Therefore, we will clip all Mel spectrograms to a preconfigured length and zero pad spectrograms shorter than this length. The result should look like this:", "Now comes the best part. As we have converted the problem from the audio domain to the image domain, we don\u2019t need to worry about defining a model. We can use one of the built-in models that come with Torchvision. We decided to choose the effective and robust ResNet model. As the dataset is small and we want to mitigate the risk for overfitting, we will use the small but effective ResNet18 model. In addition to this great shortcut we just took, Torchvision enables us to load a model pretrained on Imagenet, so the training will be shorter and more effective.", "All we need to do is adapt the input layer and output layer of the model to our data. This can be done easily as follows:", "That\u2019s it! We can start training our model. In this blog, we will not go over the structure of the training and evaluation loops. They are pretty simple and straightforward \u2014 you can look them up in the full notebook. We will just note that during training and evaluation we make sure to report the audio signals, the scalars (loss, accuracy) and the spectrograms to the PyTorch\u2019s built-in TensorBoard class, for debugging purposes. Allegro Trains will automatically pick up all the reports sent to TensorBoard and will log them under your experiment in the web app.", "All we have got left to do is to execute our Jupyter notebook, either locally or on a remote machine using Trains Agent and watch the progress of our training on Allegro Trains\u2019 web app.", "As we made sure we report debug data every few iterations, we can check out the debug samples section in the Allegro Trains webapp and make sure that the data being fed into the model makes sense. We can either listen to the original audio signals or examine the spectrograms:", "Automatic audio classification is a growing area of research that includes fields such as speech, music and environmental sounds. This rising field can benefit greatly from the rich experience and various tools developed for computer vision tasks. As such, leveraging the PyTorch ecosystem open source tools can boost your audio classification machine learning project. Not only can you enjoy a set of free open source productivity tools, but you can also use the robust and proven set of pretrained computer vision models, by transforming your signals from the time domain to the frequency domain.", "In this tutorial, we demonstrated the use of Tochaudio, Torchvision and Allegro Trains for a simple and effective audio classification task. With zero integration efforts and no cost, you get a versatile training and evaluation script. To learn more, reference the Allegro Trains\u2019 documentation, torchaudio documentation and torchvision documentation.", "In the next blog post of this series, we will demonstrate how to easily create a machine learning pipeline, using the PyTorch ecosystem. This is highly effective for cases where we have a repeating sequence of tasks. For example, preprocessing and training, as we mentioned at the beginning of this blog post.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5de2b66e640c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dan_41998?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dan_41998?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "Dan Malowany"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F679430f47f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&user=Dan+Malowany&userId=679430f47f06&source=post_page-679430f47f06----5de2b66e640c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5de2b66e640c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5de2b66e640c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://allegro.ai/blog/ml-dl-engineering-made-easy-with-pytorch-and-allegro-trains/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "image classification"}, {"url": "https://allegro.ai/blog/accelerate-hyperparameter-optimization-with-pytorchs-ecosystem-tools/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "hyperparameters optimization"}, {"url": "https://pytorch.org/audio/", "anchor_text": "Torchaudio"}, {"url": "https://allegro.ai/trains-open-source/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "Allegro Trains"}, {"url": "http://t.allegro.ai/code_pytorch_audioclassification", "anchor_text": "this script"}, {"url": "https://pytorch.org/audio/datasets.html#yesno", "anchor_text": "YesNo"}, {"url": "https://pytorch.org/audio/datasets.html", "anchor_text": "torchaudio built-in datasets"}, {"url": "https://en.wikipedia.org/wiki/Nyquist_frequency", "anchor_text": "Nyquist frequency"}, {"url": "https://allegro.ai/trains-open-source/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "Allegro Trains"}, {"url": "https://pytorch.org/audio/", "anchor_text": "Torchaudio"}, {"url": "https://pytorch.org/docs/stable/torchvision/index.html", "anchor_text": "Torchvision"}, {"url": "http://t.allegro.ai/git_trains_server_p1", "anchor_text": "Trains-server"}, {"url": "http://t.allegro.ai/demo_pytorch_audioclassification", "anchor_text": "demo server"}, {"url": "https://allegro.ai/docs/deploying_trains/trains_deploy_overview/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "documentation"}, {"url": "https://urbansounddataset.weebly.com/urbansound8k.html", "anchor_text": "UrbanSound8K"}, {"url": "http://t.allegro.ai/UrbanSound8", "anchor_text": "full notebook"}, {"url": "http://t.allegro.ai/git_trains_agent_p1", "anchor_text": "Trains Agent"}, {"url": "http://t.allegro.ai/demo_pytorch_audioclassification", "anchor_text": "Allegro Trains\u2019 web app"}, {"url": "https://allegro.ai/docs/?utm_source=pytorch_blog&utm_medium=referral&utm_campaign=trains_c&utm_content=audioclass", "anchor_text": "Allegro Trains\u2019 documentation"}, {"url": "https://pytorch.org/audio", "anchor_text": "torchaudio documentation"}, {"url": "https://pytorch.org/docs/stable/torchvision/index.html", "anchor_text": "torchvision documentation"}, {"url": "https://allegro.ai/blog/audio-classification-with-pytorchs-ecosystem-tools/", "anchor_text": "https://allegro.ai"}, {"url": "https://medium.com/tag/audio-classification?source=post_page-----5de2b66e640c---------------audio_classification-----------------", "anchor_text": "Audio Classification"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----5de2b66e640c---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5de2b66e640c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5de2b66e640c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning-codebase?source=post_page-----5de2b66e640c---------------deep_learning_codebase-----------------", "anchor_text": "Deep Learning Codebase"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5de2b66e640c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&user=Dan+Malowany&userId=679430f47f06&source=-----5de2b66e640c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5de2b66e640c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&user=Dan+Malowany&userId=679430f47f06&source=-----5de2b66e640c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5de2b66e640c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5de2b66e640c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5de2b66e640c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5de2b66e640c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5de2b66e640c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5de2b66e640c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dan_41998?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dan_41998?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dan Malowany"}, {"url": "https://medium.com/@dan_41998/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "54 Followers"}, {"url": "https://il.linkedin.com/in/dan-malowany-78b2b21", "anchor_text": "https://il.linkedin.com/in/dan-malowany-78b2b21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F679430f47f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&user=Dan+Malowany&userId=679430f47f06&source=post_page-679430f47f06--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fee078f7a2215&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-with-pytorchs-ecosystem-tools-5de2b66e640c&newsletterV3=679430f47f06&newsletterV3Id=ee078f7a2215&user=Dan+Malowany&userId=679430f47f06&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}