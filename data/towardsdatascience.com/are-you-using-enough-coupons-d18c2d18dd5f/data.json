{"url": "https://towardsdatascience.com/are-you-using-enough-coupons-d18c2d18dd5f", "time": 1683003875.485579, "path": "towardsdatascience.com/are-you-using-enough-coupons-d18c2d18dd5f/", "webpage": {"metadata": {"title": "Are you using enough coupons?. Building models to predict a coupon\u2026 | by Yeonjoo Yoo | Towards Data Science", "h1": "Are you using enough coupons?", "description": "I love a good sale. It is so satisfying to see a discount applied to the total price right before clicking the purchase button at the checkout for an online store. Also, I subscribe to periodical\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.inc.com/jason-aten/amazon-just-announced-prime-day-data-staggering-numbers-beat-black-friday-cyber-monday-combined.html", "anchor_text": "For example, Amazon\u2019s Prime Day 2019 was greater in sales total than Black Friday and Cyber Monday of 2018 combined.", "paragraph_index": 1}, {"url": "https://www.kaggle.com/vasudeva009/predicting-coupon-redemption", "anchor_text": "Kaggle", "paragraph_index": 9}, {"url": "https://github.com/YeonjooSmith/CouponRedemption", "anchor_text": "my GitHub repository", "paragraph_index": 10}, {"url": "https://www.kaggle.com/vasudeva009/predicting-coupon-redemption", "anchor_text": "the Kaggle site", "paragraph_index": 10}], "all_paragraphs": ["I love a good sale. It is so satisfying to see a discount applied to the total price right before clicking the purchase button at the checkout for an online store. Also, I subscribe to periodical purchases of household items or my dog\u2019s and cats\u2019 medications and supplements that I need regularly to get more discounts. We receive notifications and emails about special offers and coupons and we sometimes wait for deals to make big purchases and buy gifts such as Black Friday.", "The coupon marketing strategy has many benefits. Coupons attract new customers and reactivate old customers. Promotional campaigns using coupons can make very effective advertisement opportunities by engaging customers to try new or related products and buy more. For example, Amazon\u2019s Prime Day 2019 was greater in sales total than Black Friday and Cyber Monday of 2018 combined.", "Investigating how well coupons are redeemed and what affects the coupon redemption behavior is very important to know in order to measure if a promotional campaign is successful and how it can be improved. In this article, I would like to introduce my project on predicting the coupon redemption using machine learning techniques. By building models, we can also see what kind of factors influence customers to redeem coupons and if we can have a couple of suggestions to design a better promotional campaign.", "This post would focus mainly on summarizing the process \u2014 how and why I chose particular methods and techniques used in each step and how I interpret the modeling results.", "The following is a part of the description from the site:", "ABC promotions are shared across various channels including email, notifications, etc. A number of these campaigns include coupon discounts that are offered for a specific product/range of products. The retailer would like the ability to predict whether customers redeem the coupons received across channels, which will enable the retailer\u2019s marketing team to accurately design coupon construct, and develop more precise and targeted marketing strategies.", "The data available in this problem contains the following information, including the details of a sample of campaigns and coupons used in previous campaigns -", "Based on previous transaction & performance data from the last 18 campaigns, predict the probability for the next 10 campaigns in the test set for each coupon and customer combination, whether the customer will redeem the coupon or not?", "Note that I only used the train data set which contains the information about 18 campaigns by dividing the set into two groups \u2014 Train set and Test set \u2014 as it has the known target variable values.", "The data was obtained from Kaggle and it consists of 6 tables.", "The target variable is redemption_status in Train and the predictor variables are created from the rest of the features. The original task described from the site was to train a model using Train data set which is the result of Most of the features are self-explanatory so I just want to explain a couple of them are not so obvious. But you can visit my GitHub repository or the Kaggle site for the definitions for each feature. The feature campaign_type in Campaign Data is anonymized campaign type (X or Y); for example, regular sales like semi-annual or annual sale and irregular sale like seasonal campaigns may be categorized as the X type and other inconsistent campaigns as the Y type. The income_bracket in the Customer Demographics table represents a label encoded income bracket that a higher income corresponds to a higher number.", "There are three big characteristics that I found in this data.", "First, the target variable, redemption_statuse, is a categorical variable, 0 (no) or 1(yes) for the coupon redemption so it is a classification problem.", "Second, the target variable is imbalanced. With the raw data before the data preparation step, the redemption rate is 0.93%! It is hard to train a model properly for the small portioned class because predicting as 100% \u2018not redeemed\u2019 would yield over 99% accuracy.", "Third, tables need to be merged carefully and more features need to be created. The schema above shows that it is a relational database and all tables but one, the Customer Transaction Data, has a primary key which is a unique value for each data point in a table. The first feature in the list in the schema that contains \u201cid\u201d in the tables is the primary key but Customer Transaction Data does not have a unique transaction id. Therefore, in order to use the data in this table, the data needs to be aggregated by a keyword such as the number of coupon discounts used by each customer using customer_id from Customer Demographics and Customer Transaction Data.", "I will not go over every data preparation process that I have gone through but I will highlight major steps. You can visit my GitHub repository to check out the entire process and codes.", "In order to deal with the imbalanced class problem, the SMOTE ( Synthetic Minority Oversampling Technique) resampling method was implemented. It generated more data points of the positive class (1, \u201credeemed\u201d) in the train data that have \u201csimilar\u201d properties as the original data points. Since we are interfering with how a model would be trained, the oversampling data size should be as small as possible. In Figure 1, The area under the ROC curve (AUC) values are similar to one another when the ratio of minority class to the majority class is greater than 0.33 which was chosen for this resampling process.", "Notice that the SMOTE method is easy to implement in python using imblearn package.", "Moreover, one of the biggest parts of the data preparation was the feature engineering to combine information from multiple tables. For example, if we were to get information from Customer Transaction Data about items, we need to aggregate the transaction table by item_id. We can use pandas.pivot_table function to create new features as the list described.", "For instance, I couldn\u2019t have combined the list of features related to items in the table above as they do not include item_id in the train and test data. So transaction1 was created with the new features by the data aggregation from Customer Transaction Data (transaction in the codes). Then it was merged to the item Data table and the Coupon Item Mapping table. Finally, the features in the merged table aggregate by coupon_id which is one of the columns in the train and the test data set. The data aggregations and the merges of two tables were repeated to extract information as much as possible to combine them with the train and test data sets as new features.", "Before we get into the data analysis and modeling, we need to have clear expectations from modeling on this project. I found asking and answering these questions very helpful to choose types of models and metrics to measure the performance of models.", "\u2014 What do (or did) I want from modeling?", "I wanted to know what influences customers not to or to use coupons so that I could design effective promotions that more customers would participate in. That meant that I wanted models that have the feature importance that explains which predicting variables influence more to predict the target variable value. I chose to use the logistic regression, the random forest, and the gradient boosting methods as they all can provide the feature importance and all three have very different approaches from each other in finding the relationship between predictor variables and the target variable.", "\u2014 What is (or was) more important to predict between two classes in the target variable (the coupon redemption status)?", "As most of the transactions in the given dataset did not use a coupon to get a discount (thus the imbalanced dataset), I wanted the models to learn what conditions do the coupon redeemed transactions have. Therefore, I wanted to focus on predicting the positive class right and detect most of them by focusing on the recall score; the rate of the number of the positive class predicted out of the total known number of the positive class. The accuracy score is still important. However, as mentioned earlier, getting most of the positive class wrong would still yield a high accuracy model which is not the most useful metric to judge a model. As long as the accuracy is \u201csomewhat\u201d high, we will tune models to have a high recall score.", "\u2014 What is the consequence (cost) for getting predictions wrong? How about the precision score?", "The consequence of having a relatively high number of false-positives, thus having a low precision score, is not very serious in this case. Unlike problems like credit card fraud detection or disease detection problems, including many false-positives just means that the next promotion based on the model would target a wider range of conditions. Also, note that the recall score and the precision score are in the inverse relationship. In order to increase the recall score, the rules to pick the positive class would be lenient and would accept more false positives thus the precision score goes down.", "By answering the questions above, my plan became:", "For all three, the accuracy scores show that the model is not overfitted \u2014 the differences in accuracy scores between the train data and the test data are not too big. However, the differences in recall scores between the train and the test data sets are larger especially the Gradient Boost model. As we discussed earlier when a model has a higher recall score (especially with the minor positive class), it has a relatively lower F-1 score and accuracy score because of a low precision score. Which model should we conclude as the optimal model for our needs? Well, detecting more positive classes is more important than the accuracy of the prediction. So I would choose the logistic regression model and the random forest model over the gradient boosting model. Between these two models, although the accuracy score of the logistic model is about 16% less than the random forest model\u2019s score, its recall score is about 14% higher than the random forest model\u2019s. Therefore, the logistic model would be the one whose feature influences that I would depend on when the previous promotions are analyzed. On the other hand, I would use the random forest model for estimating how the coupon redemption would turn out when a promotion is being designed as its accuracy and F1 scores are higher than the previous model with a relatively high recall score. But for now, let\u2019s analyze and compare the feature importances of all three models with our ranking of the models in our minds. A good thing to notice in the plots below is that there are many features that coincide from one plot to the other. In fact, every feature in the top 10 important features in the random forest model is on the list in the gradient boosting model with some difference in ranks.", "First, note that the coefficients and scores from the models to rank features are different scales because the formulations to calculate these numbers differ by models. Moreover, the scores from the last two models do now indicate if each feature has a negative or positive impact on the target variable not like the coefficients of the logistic regression model which assumes the linear relation between predictor variables. I listed the interpretations and suggestions using the feature importances from the above plots", "While I was able to come up with insightful conclusions and suggestions to improve the coupon redemption rate, there are some limitations to this modeling work.", "Models navigate and predict the results by minimizing or maximizing mathematical formulas such as a loss function or an information gain formula. They do not have a business understanding or background information about this data set. So when we get the results from a model that does not make sense to us, we have to analyze them in the right way. For example, the average coupon discount has a negative impact on coupon redemption according to the logistic regression model; the more discounting coupon a customer has, the less likely he/she uses the coupon. Well, it does not make sense to me. But we can see that it is the AVERAGE coupon discount. If coupon discount values per coupon were not distributed around the middle like a bell curve shape, their mean value would not be the best way to represent the data set. The median or the mode of the values may have been better.", "Moreover, although three methods were implemented to create the models, there may be a better method that could reproduce the behavior of the data. I would like to try the XGBoost library later if it could build a model that provides a better result.", "I hope you found this article useful. I tried to tell you the whole story rather than to focus on a specific topic or a technique. I would sincerely appreciate your comments and questions.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd18c2d18dd5f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@yeonjooyoo?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yeonjooyoo?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "Yeonjoo Yoo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2121380de821&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&user=Yeonjoo+Yoo&userId=2121380de821&source=post_page-2121380de821----d18c2d18dd5f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd18c2d18dd5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd18c2d18dd5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://giphy.com/gifs/memecandy-Lqs62MVUrUWAC3R9TL", "anchor_text": "giphy.com"}, {"url": "https://www.inc.com/jason-aten/amazon-just-announced-prime-day-data-staggering-numbers-beat-black-friday-cyber-monday-combined.html", "anchor_text": "For example, Amazon\u2019s Prime Day 2019 was greater in sales total than Black Friday and Cyber Monday of 2018 combined."}, {"url": "https://www.kaggle.com/vasudeva009/predicting-coupon-redemption", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/vasudeva009/predicting-coupon-redemption", "anchor_text": "Kaggle"}, {"url": "https://github.com/YeonjooSmith/CouponRedemption", "anchor_text": "my GitHub repository"}, {"url": "https://www.kaggle.com/vasudeva009/predicting-coupon-redemption", "anchor_text": "the Kaggle site"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d18c2d18dd5f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd18c2d18dd5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&user=Yeonjoo+Yoo&userId=2121380de821&source=-----d18c2d18dd5f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd18c2d18dd5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&user=Yeonjoo+Yoo&userId=2121380de821&source=-----d18c2d18dd5f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd18c2d18dd5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd18c2d18dd5f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d18c2d18dd5f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d18c2d18dd5f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yeonjooyoo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yeonjooyoo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yeonjoo Yoo"}, {"url": "https://medium.com/@yeonjooyoo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "231 Followers"}, {"url": "https://www.linkedin.com/in/yeonjoosmith/", "anchor_text": "https://www.linkedin.com/in/yeonjoosmith/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2121380de821&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&user=Yeonjoo+Yoo&userId=2121380de821&source=post_page-2121380de821--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F46ce918069c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-you-using-enough-coupons-d18c2d18dd5f&newsletterV3=2121380de821&newsletterV3Id=46ce918069c6&user=Yeonjoo+Yoo&userId=2121380de821&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}