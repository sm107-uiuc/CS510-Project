{"url": "https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159", "time": 1682993693.746586, "path": "towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159/", "webpage": {"metadata": {"title": "Smarter Ways to Encode Categorical Data for Machine Learning | by Jeff Hale | Towards Data Science", "h1": "Smarter Ways to Encode Categorical Data for Machine Learning", "description": "Better encoding of categorical data can mean better model performance. In this article I\u2019ll introduce you to a wide range of encoding options from the Category Encoders package for use with\u2026"}, "outgoing_paragraph_urls": [{"url": "http://contrib.scikit-learn.org/categorical-encoding/index.html", "anchor_text": "Category Encoders package", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/7-data-types-a-better-way-to-think-about-data-types-for-machine-learning-939fae99a689", "anchor_text": "an earlier article", "paragraph_index": 6}, {"url": "http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/", "anchor_text": "Will McGinnis", "paragraph_index": 11}, {"url": "https://patsy.readthedocs.io/en/latest/API-reference.html", "anchor_text": "Patsy package", "paragraph_index": 11}, {"url": "https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/", "anchor_text": "UCLA statistics reference", "paragraph_index": 11}, {"url": "http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/", "anchor_text": "stated intents", "paragraph_index": 16}, {"url": "http://contrib.scikit-learn.org/categorical-encoding/", "anchor_text": "docs", "paragraph_index": 19}, {"url": "https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html", "anchor_text": "this post", "paragraph_index": 19}, {"url": "https://github.com/scikit-learn-contrib/categorical-encoding/blob/master/category_encoders/james_stein.py", "anchor_text": "here", "paragraph_index": 19}, {"url": "https://github.com/scikit-learn-contrib/categorical-encoding/blob/master/category_encoders/m_estimate.py", "anchor_text": "here", "paragraph_index": 19}, {"url": "https://medium.com/@jeffhale", "anchor_text": "me", "paragraph_index": 22}, {"url": "http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/", "anchor_text": "here", "paragraph_index": 25}, {"url": "https://www.kaggle.com/discdiver/category-encoders-examples", "anchor_text": "this Kaggle Kernel", "paragraph_index": 31}, {"url": "https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding", "anchor_text": "Machine Learning tutorial series", "paragraph_index": 36}, {"url": "https://stats.stackexchange.com/questions/308916/what-is-one-hot-encoding-called-in-scientific-literature", "anchor_text": "names", "paragraph_index": 36}, {"url": "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/", "anchor_text": "here", "paragraph_index": 39}, {"url": "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html", "anchor_text": "GetDummies", "paragraph_index": 40}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html", "anchor_text": "OneHotEncoder", "paragraph_index": 40}, {"url": "http://www.willmcginnis.com/2016/12/18/basen-encoding-grid-search-category_encoders/", "anchor_text": "said", "paragraph_index": 48}, {"url": "https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f", "anchor_text": "hashing trick", "paragraph_index": 51}, {"url": "https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087", "anchor_text": "here", "paragraph_index": 51}, {"url": "https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512", "anchor_text": "competitions", "paragraph_index": 56}, {"url": "https://www.slideshare.net/OwenZhang2/tips-for-data-science-competitions", "anchor_text": "Kaggle classification challenge", "paragraph_index": 60}, {"url": "https://memorablepython.com", "anchor_text": "Python", "paragraph_index": 62}, {"url": "https://memorablesql.com", "anchor_text": "SQL", "paragraph_index": 62}, {"url": "https://medium.com/@jeffhale", "anchor_text": "here", "paragraph_index": 62}, {"url": "https://dataawesome.com", "anchor_text": "https://dataawesome.com", "paragraph_index": 64}], "all_paragraphs": ["Better encoding of categorical data can mean better model performance. In this article I\u2019ll introduce you to a wide range of encoding options from the Category Encoders package for use with scikit-learn machine learning in Python.", "Use Category Encoders to improve model performance when you have nominal or ordinal data that may provide value.", "For nominal columns try OneHot, Hashing, LeaveOneOut, and Target encoding. Avoid OneHot for high cardinality columns and decision tree-based algorithms.", "For ordinal columns try Ordinal (Integer), Binary, OneHot, LeaveOneOut, and Target. Helmert, Sum, BackwardDifference and Polynomial are less likely to be helpful, but if you have time or theoretic reason you might want to try them.", "For regression tasks, Target and LeaveOneOut probably won\u2019t work well.", "In this article I\u2019ll discuss terms, general usage and five classic encoding options: Ordinal, One Hot, Binary, BaseN, and Hashing. In the future I may evaluate Bayesian encoders and contrast encoders with roots in statistical hypothesis testing. \ud83d\ude80", "In an earlier article I argued we should classify data as one of seven types to make better models faster. Here are the seven data types:", "Useless \u2014 useless for machine learning algorithms, that is \u2014 discreteNominal \u2014 groups without order \u2014 discreteBinary \u2014 either/or \u2014 discreteOrdinal \u2014 groups with order \u2014 discreteCount \u2014 the number of occurrences \u2014 discreteTime \u2014 cyclical numbers with a temporal component \u2014 continuousInterval \u2014 positive and/or negative numbers without a temporal component \u2014 continuous", "Here we\u2019re concerned with encoding nominal and ordinal data. A column with nominal data has values that cannot be ordered in any meaningful way. Nominal data is most often one-hot (aka dummy) encoded, but there are many options that might perform better for machine learning.", "In contrast, ordinal data can be rank ordered. Ordinal data can be encoded in one of three ways, broadly speaking, but I think it\u2019s safe to say that its encoding is often not carefully considered.", "Many of these encoding methods go by more than one name in the statistics world and sometimes one name can mean different things. We\u2019ll follow the Category Encoders usage.", "Big thanks to Will McGinnis for creating and maintaining this package. It is largely derived from StatsModel\u2019s Patsy package, which in turn is based on this UCLA statistics reference.", "There are an infinite number of ways to encode categorical information. The ones in Category Encoders should be sufficient for most uses. \ud83d\udc4d", "Here\u2019s the list of Category Encoders functions with their descriptions and the type of data they would be most appropriate to encode.", "The first group of five classic encoders can be seen on a continuum of embedding information in one column (Ordinal) up to k columns (OneHot). These are very useful encodings for machine learning practitioners to understand.", "Ordinal \u2014 convert string labels to integer values 1 through k. Ordinal.OneHot \u2014 one column for each value to compare vs. all other values. Nominal, ordinal.Binary \u2014 convert each integer to binary digits. Each binary digit gets one column. Some info loss but fewer dimensions. Ordinal.BaseN \u2014 Ordinal, Binary, or higher encoding. Nominal, ordinal. Doesn\u2019t add much functionality. Probably avoid.Hashing \u2014 Like OneHot but fewer dimensions, some info loss due to collisions. Nominal, ordinal.Sum \u2014 Just like OneHot except one value is held constant and encoded as -1 across all columns.", "The five contrast encoders all have multiple issues that I argue make them unlikely to be useful for machine learning. They all output one column for each value found in a column. Their stated intents are below.", "Helmert (reverse) \u2014 The mean of the dependent variable for a level is compared to the mean of the dependent variable over all previous levels.Backward Difference \u2014 the mean of the dependent variable for a level is compared with the mean of the dependent variable for the prior level. Polynomial \u2014 orthogonal polynomial contrasts. The coefficients taken on by polynomial coding for k=4 levels are the linear, quadratic, and cubic trends in the categorical variable.", "The Bayesian encoders use information from the dependent variable in their encodings. They output one column and can work well with high cardinality data.", "Target \u2014 use the mean of the DV, must take steps to avoid overfitting/ response leakage. Nominal, ordinal. For classification tasks.LeaveOneOut \u2014 similar to target but avoids contamination. Nominal, ordinal. For classification tasks.WeightOfEvidence \u2014 added in v1.3. Not documented in the docs as of April 11, 2019. The method is explained in this post.James-Stein \u2014 forthcoming in v1.4. Described in the code here.M-estimator \u2014 forthcoming in v1.4. Described in the code here. Simplified target encoder.", "Category Encoders follow the same API as scikit-learn\u2019s preprocessors. They have some added conveniences, such as the ability to easily add an encoder to a pipeline. Additionally, the encoder returns a pandas DataFrame if a DataFrame is passed to it. Here\u2019s an example of the code with the BinaryEncoder:", "We\u2019ll tackle a few gotchas with implementation in the future. But you should be able to jump right into the first five if you are familiar with scikit-learn\u2019s API.", "Note that all Category Encoders impute missing values automatically by default. However, I recommend filling missing data data yourself prior to encoding so you can test the results of several methods. I plan to discuss imputing options in a forthcoming article, so follow me on Medium if you want to make sure you don\u2019t miss it.", "You might see commentators use the following terms interchangeably: dimension, feature, vector, series, independent variable, and column. I will too :) Similarly, you might see row and observation used interchangeably.", "k is the original number of unique values in your data column. High cardinality means a lot of unique values (a large k). A column with hundreds of zip codes is an example of a high cardinality feature.", "High dimensionality means a matrix with many dimensions. High dimensionality comes with the Curse of Dimensionality \u2014 a thorough treatment of this topic can be found here. The take away is that high dimensionality requires many observations and often results in overfitting.", "Sparse data is a matrix with lots of zeroes relative to other values. If your encoders transform your data so that it becomes sparse, some algorithms may not work well. Sparsity can often be managed by flagging it, but many algorithms don\u2019t work well unless the data is dense.", "OrdinalEncoder converts each string value to a whole number. The first unique value in your column becomes 1, the second becomes 2, the third becomes 3, and so on.", "What the actual value was prior to encoding does not affect what it becomes when you fit_transform with OrdinalEncoder. The first value could have been 10 and the second value could have been 3. Now they will be 1 and 2, respectively.", "If the column contains nominal data, stopping after you use OrdinalEncoder is a bad idea. Your machine learning algorithm will treat the variable as continuous and assume the values are on a meaningful scale. Instead, if you have a column with values car, bus, and truck you should first encode this nominal data using OrdinalEncoder. Then encode it again using one of the methods appropriate to nominal data that we\u2019ll explore below.", "In contrast, if your column values are truly ordinal, that means that the integer assigned to each value is meaningful. Assignment should be done with intention. Say your column had the string values \u201cFirst\u201d, \u201cThird\u201d, and \u201cSecond\u201d in it. Those values should be mapped to the corresponding integers by passing OrdinalEncoder a list of dicts like so:", "Here\u2019s the basic setup for all the code samples to follow. You can get the full notebook at this Kaggle Kernel.", "And here\u2019s the OrdinalEncoder code to transform the color column values from letters to integers.", "All the string values are now integers.", "Scikit-learn\u2019s OrdinalEncoder does pretty much the same thing as Category Encoder\u2019s OrdinalEncoder, but is not quite as user friendly. Scikit-learn\u2019s encoder won\u2019t return a pandas DataFrame. Instead it returns a NumPy array if you pass a DataFrame. It also outputs values starting with 0, compared to OrdinalEncoder\u2019s default of outputting values starting with 1.", "You could accomplish ordinal encoding by mapping string values to integers in pandas. But that\u2019s extra work once you know how to use Category Encoders.", "One-hot encoding is the classic approach to dealing with nominal, and maybe ordinal, data. It\u2019s referred to as the \u201cThe Standard Approach for Categorical Data\u201d in Kaggle\u2019s Machine Learning tutorial series. It also goes by the names dummy encoding, indicator encoding, and occasionally binary encoding. Yes, this is confusing. \ud83d\ude09", "The one-hot encoder creates one column for each value to compare against all other values. For each new column, a row gets a 1 if the row contained that column\u2019s value and a 0 if it did not. Here\u2019s how it looks:", "color_-1 is actually an extraneous column, because it\u2019s all 0s \u2014 with no variation, it\u2019s not helping your model learn anything. It may have been intended for missing values, but in version 1.2.8 of Category Encoders it doesn\u2019t serve a purpose.", "One-hot encoding can perform very well, but the number of new features is equal to k, the number of unique values. This feature expansion can create serious memory problems if your dataset has high cardinality features. One-hot-encoded data can also be difficult for decision-tree-based algorithms \u2014 see discussion here.", "The pandas GetDummies and scikit-learn\u2019s OneHotEncoder functions perform the same role as the Category Encoders OneHotEncoder. I find Category Encoders OneHotEncoder a bit nicer to use.", "Binary encoding can be thought of as a hybrid of one-hot and hashing encoders. Binary creates fewer features than one-hot, while preserving some uniqueness of values in the column. It can work well with higher dimensionality ordinal data.", "The first column has no variance, so it isn\u2019t doing anything to help the model.", "With only three levels, the information embedded becomes muddled. There are many collisions and the model can\u2019t glean much information from the features. Just one-hot encode a column if it only has a few values.", "In contrast, binary really shines when the cardinality of the column is higher \u2014 with the 50 US states, for example.", "Binary encoding creates fewer columns than one-hot encoding. It is more memory efficient. It also reduces the chances of dimensionality problems with higher cardinality.", "For ordinal data, most values that were close to each other when in ordinal form will share many of the same values in the new columns. Many machine learning algorithms can learn that the features are similar. Binary encoding is a decent compromise for ordinal data with high cardinality.", "If you\u2019ve used binary encoding successfully, please share in the comment. For nominal data a hashing algorithm with more fine-grained control usually makes more sense.", "When the BaseN base = 1 it is basically the same as one hot encoding. When base = 2 it is basically the same as binary encoding. McGinnis said of this encoder, \u201cPractically, this adds very little new functionality, rarely do people use base-3 or base-8 or any base other than ordinal or binary in real problems.\u201d", "The main reason for BaseN\u2019s existence is to possibly make grid searching easier. You could use BaseN with scikit-learn\u2019s GridSearchCV. However, if you\u2019re going to grid search with these encoding options, you can make the encoder part of your scikit-learn pipeline and put the options in your parameter grid. I don\u2019t see a compelling reason to use BaseN. If you do, please share in the comments.", "The default base for BaseNEncoder is 2, which is the equivalent of BinaryEncoder.", "HashingEncoder implements the hashing trick. It is similar to one-hot encoding but with fewer new dimensions and some info loss due to collisions. The collisions do not significantly affect performance unless there is a great deal of overlap. An excellent discussion of the hashing trick and guidelines for selecting the number of output features can be found here.", "Here\u2019s the ordinal column again for a refresher.", "And here\u2019s the HashingEncoder with output.", "The n_components parameter controls the number of expanded columns. The default is eight columns. In our example column with three values the default results in five columns full of 0s.", "If you set n_components less than k you\u2019ll have a small reduction in the value provided by the encoded data. You\u2019ll also have fewer dimensions.", "You can pass a hashing algorithm of your choice to HashingEncoder; the default is md5. Hashing algorithms have been very successful in some Kaggle competitions. It\u2019s worth trying HashingEncoder for nominal and ordinal data if you have high cardinality features. \ud83d\udc4d", "That\u2019s all for now. Here\u2019s a recap and suggestions for when to use the encoders.", "For nominal columns try OneHot, Hashing, LeaveOneOut, and Target encoding. Avoid OneHot for high cardinality columns.", "For ordinal columns try Ordinal (Integer), Binary, OneHot, LeaveOneOut, and Target. Helmert, Sum, BackwardDifference and Polynomial are less likely to be helpful, but if you have time or theoretic reason you might want to try them.", "The Bayesian encoders can work well for some machine learning tasks. For example, Owen Zhang used the leave one out encoding method to perform well in a Kaggle classification challenge.", "*Update April 2019: I updated this article to include information about forthcoming encoders and reworked the conclusion.**", "I write about data science, Python, SQL, and DevOps. Check out my other articles and follow me here if you\u2019re into that stuff. \ud83d\ude00", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I write about data science. Join my Data Awesome mailing list to stay on top of the latest data tools and tips: https://dataawesome.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6dca2f71b159&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jeffhale.medium.com/?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": ""}, {"url": "https://jeffhale.medium.com/?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "Jeff Hale"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F451599b1142a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&user=Jeff+Hale&userId=451599b1142a&source=post_page-451599b1142a----6dca2f71b159---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6dca2f71b159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6dca2f71b159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "http://contrib.scikit-learn.org/categorical-encoding/index.html", "anchor_text": "Category Encoders package"}, {"url": "https://towardsdatascience.com/7-data-types-a-better-way-to-think-about-data-types-for-machine-learning-939fae99a689", "anchor_text": "an earlier article"}, {"url": "http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/", "anchor_text": "Will McGinnis"}, {"url": "https://patsy.readthedocs.io/en/latest/API-reference.html", "anchor_text": "Patsy package"}, {"url": "https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/", "anchor_text": "UCLA statistics reference"}, {"url": "http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/", "anchor_text": "stated intents"}, {"url": "http://contrib.scikit-learn.org/categorical-encoding/", "anchor_text": "docs"}, {"url": "https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html", "anchor_text": "this post"}, {"url": "https://github.com/scikit-learn-contrib/categorical-encoding/blob/master/category_encoders/james_stein.py", "anchor_text": "here"}, {"url": "https://github.com/scikit-learn-contrib/categorical-encoding/blob/master/category_encoders/m_estimate.py", "anchor_text": "here"}, {"url": "https://medium.com/@jeffhale", "anchor_text": "me"}, {"url": "http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/", "anchor_text": "here"}, {"url": "https://www.kaggle.com/discdiver/category-encoders-examples", "anchor_text": "this Kaggle Kernel"}, {"url": "https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding", "anchor_text": "Machine Learning tutorial series"}, {"url": "https://stats.stackexchange.com/questions/308916/what-is-one-hot-encoding-called-in-scientific-literature", "anchor_text": "names"}, {"url": "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/", "anchor_text": "here"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html", "anchor_text": "GetDummies"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html", "anchor_text": "OneHotEncoder"}, {"url": "http://www.willmcginnis.com/2016/12/18/basen-encoding-grid-search-category_encoders/", "anchor_text": "said"}, {"url": "https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f", "anchor_text": "hashing trick"}, {"url": "https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087", "anchor_text": "here"}, {"url": "https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512", "anchor_text": "competitions"}, {"url": "https://www.slideshare.net/OwenZhang2/tips-for-data-science-competitions", "anchor_text": "Kaggle classification challenge"}, {"url": "https://memorablepython.com", "anchor_text": "Python"}, {"url": "https://memorablesql.com", "anchor_text": "SQL"}, {"url": "https://medium.com/@jeffhale", "anchor_text": "here"}, {"url": "https://dataawesome.com", "anchor_text": ""}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6dca2f71b159---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6dca2f71b159---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data?source=post_page-----6dca2f71b159---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6dca2f71b159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&user=Jeff+Hale&userId=451599b1142a&source=-----6dca2f71b159---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6dca2f71b159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&user=Jeff+Hale&userId=451599b1142a&source=-----6dca2f71b159---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6dca2f71b159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6dca2f71b159&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6dca2f71b159---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6dca2f71b159--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6dca2f71b159--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6dca2f71b159--------------------------------", "anchor_text": ""}, {"url": "https://jeffhale.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jeffhale.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jeff Hale"}, {"url": "https://jeffhale.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "18K Followers"}, {"url": "https://dataawesome.com", "anchor_text": "https://dataawesome.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F451599b1142a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&user=Jeff+Hale&userId=451599b1142a&source=post_page-451599b1142a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7ae6804f27a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsmarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159&newsletterV3=451599b1142a&newsletterV3Id=e7ae6804f27a&user=Jeff+Hale&userId=451599b1142a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}