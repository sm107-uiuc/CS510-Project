{"url": "https://towardsdatascience.com/testing-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd", "time": 1683006514.837642, "path": "towardsdatascience.com/testing-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd/", "webpage": {"metadata": {"title": "Testing Airflow jobs on Google Cloud Composer using pytest | by Massimo Belloni | Towards Data Science", "h1": "Testing Airflow jobs on Google Cloud Composer using pytest", "description": "Airflow is an open-source workflow management platform developed by Airbnb and now maintained by Apache. It is basically cron on steroids [1], with the theoretical ability of scaling without limits\u2026"}, "outgoing_paragraph_urls": [{"url": "https://airflow.apache.org/", "anchor_text": "Airflow", "paragraph_index": 0}, {"url": "https://www.astronomer.io/", "anchor_text": "astronomer.io", "paragraph_index": 0}, {"url": "https://cloud.google.com/composer", "anchor_text": "Google Cloud Composer", "paragraph_index": 0}, {"url": "http://housinganywhere.com/", "anchor_text": "HousingAnywhere", "paragraph_index": 1}, {"url": "https://github.com/apache/airflow", "anchor_text": "Airflow is completely written in Python", "paragraph_index": 2}, {"url": "https://docs.pytest.org/en/latest/", "anchor_text": "pytest", "paragraph_index": 7}, {"url": "https://pypi.org/project/testing.postgresql/", "anchor_text": "mock up a Postgres instance using pytest", "paragraph_index": 10}, {"url": "https://docs.snowflake.com/en/user-guide/python-connector.html", "anchor_text": "Snowflake Connector for Python", "paragraph_index": 12}, {"url": "https://airflow.apache.org/docs/stable/_modules/airflow/contrib/hooks/snowflake_hook.html", "anchor_text": "SnowflakeHook", "paragraph_index": 13}, {"url": "https://towardsdatascience.com/getting-started-with-airflow-using-docker-cd8b44dbff98", "anchor_text": "Mark Nagelberg", "paragraph_index": 17}], "all_paragraphs": ["Airflow is an open-source workflow management platform developed by Airbnb and now maintained by Apache. It is basically cron on steroids [1], with the theoretical ability of scaling without limits, completely abstracting the complexity of this feature to the final users. You just write the code, decide when it has to run, and Airflow takes care of the rest. Deploying Airflow isn\u2019t easy and requires deep knowledge in Ops and tools like Kubernetes and Celery. For this reason, a lot of cloud providers offer managed deployments of Airflow like astronomer.io or Google Cloud Composer, just to cite the most famous. Setting up a cluster running Airflow is just a matter of clicks, and from that point onwards almost everything can be configured using the Airflow Web UI.", "At HousingAnywhere we use the Google Cloud Platform for basically everything, and deciding to deploy Airflow on Cloud Composer has been a natural consequence. The resulting environment comes out of the box with a CeleryExecutor and the dags folder is stored on Google Cloud Storage. Whatever you need to run on Airflow has to be pushed to that bucket first, and whatever the jobs produce will be stored in specific folders on the same bucket.", "Airflow is completely written in Python and all the workflows are created via Python scripts. This isn\u2019t a limit, actually, because tasks themselves (the atomic work units composing a DAG, a set of tasks depending one on the other) can be ideally written in any language and run via bash or Docker. At HousingAnywhere we use Airflow for plenty of different use cases, from moving data around to web-scraping and, of course, we version everything on Github. During the first days of experimentation we were manually pushing to the bucket all the new jobs just merged on the master branch: this works, but it is not sustainable at scale, with the huge risk of having different sources of truth, one on Github and one on GCS.", "Using Google Cloud Build, we designed an automated process triggered by any relevant change on the master branch of our Airflow repository. Whatever happens on master is automatically synced with the GCS bucket and no one has to manually take care of this process anymore. Basically a CD for Airflow.", "The CloudBuild syntax and the integration with the Google Cloud Composer API allowed us to do even more, serializing the vast majority of our Airflow environment on Github: not just the dags folder, but also other important parameters on which the tasks depend, like Variables. The main idea here is that if something bad happens, we can recreate our environment almost completely just running the same CloudBuild job on a new Airflow cluster without any effort or re-work.", "Such an automated flow, though, requires scrupulous checks on what is merged on the master branch, preventing developers from triggering automated tasks possibly breaking the environment. While working on the CD then, we started to design an automated CI able to reliably test our branches and possibly give red light if there is something wrong.", "While it is true that a meaningful deployment of Airflow is complex, setting up a quick environment able to sequentially run tasks is not. It is really a matter of three commands to create a local Airflow deployment, and the underlying Python codebase makes it very lightweight and flexible.", "Using pytest (the library that at HousingAnywhere we were already using for testing Python on all our CIs) it is quite easy to mock up all the objects needed to run a task, and, luckily, this effort can be shared among all the Airflow instances one wishes to test out. Each developer just has to take care of importing those resources and taking care of its own tests. The complexity of being on Airflow is almost completely removed, and writing meaningful tests over the code\u2019s features is really a matter of best practices decades old.", "We have written tests for all our Operators and a consistency check over the DAGs in the dags folder, in order not to merge something broken (or cyclic) there as well.", "Wrapping this up, it is now just a matter of defining the testing pipeline for your favorite CI tool (at HousingAnywhere we use Jenkins, but whatever works) and fancily ending up running a pytest command. If the branch is green, it is safe to merge. The folder containing the tests doesn\u2019t need to be pushed to the bucket on GCS, and can be kept out from the designed CD.", "It might be interesting to show here an example of how we are dealing with testing Airflow tasks running against Snowflake, our cloud data warehouse. If it is quite easy to mock up a Postgres instance using pytest, the only solution for Snowflake is to actually create a testing environment on the cloud as similar as possible as the producing one, and to run all the tests against it, taking care of populating it with meaningful data and resources.", "For such a purpose it is very useful the GET_DDL function available through the Snowflake Query Engine, that outputs the SQL DDL query needed to recreate the table passed as argument. Creating a testing environment at testing time is really a matter of executing a couple of sql queries. From a monitoring perspective, it is smart to connect the testing database to a separate warehouse, to control the costs and to avoid conflicts with the prediction resources.", "A subset of the production data has to be dumped and copied to the testing environment, possibly wiping them at the end of the testing session. But this is mainly based on specific needs and on the functionalities of the task to be tested. The Snowflake Connector for Python gives a lot of freedom in this direction, but for some very specific use cases we also use SQLAlchemy in combination with Pandas.", "On Airflow\u2019s side, all the connections to databases or external sources should be handled via hooks. The SnowflakeHook is available out of the box with the default Airflow installation, and the effort needed to use it is very limited, it is just a matter of importing the correct resources via pip.", "Testing credentials can be exposed to the tasks using the pytest mocker library. Everytime a function will call get_connection, the interpreter will return these credentials, without actually asking anything to Airflow.", "The actual content of the tests is task specific, in this example we wish to write tests for a job pushing new advertisers in a Snowflake table. We want to enforce that we didn\u2019t use any advertiser that is not contained in the task\u2019s result (possibly generated by another one, executed before).", "The pre and post sets are populated running queries directly against the Snowflake table.", "[1] This amazing definition is not mine. Credits to Mark Nagelberg", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9e0a1198b4cd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://massibelloni.medium.com/?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": ""}, {"url": "https://massibelloni.medium.com/?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "Massimo Belloni"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4e623cf1c796&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&user=Massimo+Belloni&userId=4e623cf1c796&source=post_page-4e623cf1c796----9e0a1198b4cd---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e0a1198b4cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e0a1198b4cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@marckleen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Marc Kleen"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://airflow.apache.org/", "anchor_text": "Airflow"}, {"url": "https://www.astronomer.io/", "anchor_text": "astronomer.io"}, {"url": "https://cloud.google.com/composer", "anchor_text": "Google Cloud Composer"}, {"url": "http://housinganywhere.com/", "anchor_text": "HousingAnywhere"}, {"url": "https://github.com/apache/airflow", "anchor_text": "Airflow is completely written in Python"}, {"url": "https://docs.pytest.org/en/latest/", "anchor_text": "pytest"}, {"url": "https://godatadriven.com/blog/testing-and-debugging-apache-airflow/", "anchor_text": "Bas Harenslak"}, {"url": "https://pypi.org/project/testing.postgresql/", "anchor_text": "mock up a Postgres instance using pytest"}, {"url": "https://docs.snowflake.com/en/user-guide/python-connector.html", "anchor_text": "Snowflake Connector for Python"}, {"url": "https://airflow.apache.org/docs/stable/_modules/airflow/contrib/hooks/snowflake_hook.html", "anchor_text": "SnowflakeHook"}, {"url": "https://towardsdatascience.com/getting-started-with-airflow-using-docker-cd8b44dbff98", "anchor_text": "Mark Nagelberg"}, {"url": "https://medium.com/tag/airflow?source=post_page-----9e0a1198b4cd---------------airflow-----------------", "anchor_text": "Airflow"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----9e0a1198b4cd---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/testing?source=post_page-----9e0a1198b4cd---------------testing-----------------", "anchor_text": "Testing"}, {"url": "https://medium.com/tag/google-cloud-composer?source=post_page-----9e0a1198b4cd---------------google_cloud_composer-----------------", "anchor_text": "Google Cloud Composer"}, {"url": "https://medium.com/tag/google-cloud-platform?source=post_page-----9e0a1198b4cd---------------google_cloud_platform-----------------", "anchor_text": "Google Cloud Platform"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e0a1198b4cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&user=Massimo+Belloni&userId=4e623cf1c796&source=-----9e0a1198b4cd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e0a1198b4cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&user=Massimo+Belloni&userId=4e623cf1c796&source=-----9e0a1198b4cd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e0a1198b4cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9e0a1198b4cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9e0a1198b4cd---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9e0a1198b4cd--------------------------------", "anchor_text": ""}, {"url": "https://massibelloni.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://massibelloni.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Massimo Belloni"}, {"url": "https://massibelloni.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "443 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4e623cf1c796&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&user=Massimo+Belloni&userId=4e623cf1c796&source=post_page-4e623cf1c796--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd607a9e5bd7d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftesting-airflow-jobs-on-google-cloud-composer-using-pytest-9e0a1198b4cd&newsletterV3=4e623cf1c796&newsletterV3Id=d607a9e5bd7d&user=Massimo+Belloni&userId=4e623cf1c796&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}