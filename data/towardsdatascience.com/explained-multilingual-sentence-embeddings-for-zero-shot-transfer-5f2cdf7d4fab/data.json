{"url": "https://towardsdatascience.com/explained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab", "time": 1682994533.843665, "path": "towardsdatascience.com/explained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab/", "webpage": {"metadata": {"title": "Explained: Multilingual Sentence Embeddings for Zero-Shot Transfer | by Rani Horev | Towards Data Science", "h1": "Explained: Multilingual Sentence Embeddings for Zero-Shot Transfer", "description": "Language models and transfer learning have become one of the cornerstones of NLP in recent years. Phenomenal results were achieved by first building a model of words or even characters, and then\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1812.10464", "anchor_text": "paper", "paragraph_index": 1}, {"url": "http://www.nyu.edu/projects/bowman/xnli/", "anchor_text": "XNLI", "paragraph_index": 13}, {"url": "https://fairseq.readthedocs.io/en/latest/tutorial_simple_lstm.html", "anchor_text": "fairseq", "paragraph_index": 18}, {"url": "https://www.lyrn.ai", "anchor_text": "LyrnAI", "paragraph_index": 21}, {"url": "https://gist.github.com/ranihorev/6ba9a88c9e7401b603cd483dd767e783", "anchor_text": "here", "paragraph_index": 22}], "all_paragraphs": ["Language models and transfer learning have become one of the cornerstones of NLP in recent years. Phenomenal results were achieved by first building a model of words or even characters, and then using that model to solve other tasks such as sentiment analysis, question answering and others.", "While most of the models were built for a single language or several languages separately, a new paper \u2014 Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond \u2014 presents a different approach. The paper uses a single sentence encoder that supports over 90 languages. Its language model is trained on a dataset that contains sentences from all these languages. However, it can be utilized for a given task by only training the target model (e.g. classifier) on a single language, a technique named Zero-Shot.", "This Universal language model achieves strong results across most languages in tasks such as Natural Language Inference (classifying relationship between two sentences), that are state-of-the-art for Zero-Shot models. This technique is faster to train and has the potential to support hundreds of languages with limited training resources.", "Most of the predictive algorithms in Natural Language Processing (NLP) aren\u2019t capable of processing raw text directly, as it\u2019s non-numeric and unstructured. A popular way to overcome this is by creating a language model in which characters, words or sentences are translated into a meaningful vector, i.e. embedding vector. The embeddings can be fed to a prediction model, as a constant input or by combining the two models (language and prediction) and fine-tuning them for the task.", "In most models, every supported language requires an additional language model as well as additional training for every task. The models tend to be data hungry and require huge datasets, sometimes with billions of words. A different approach is to first train a single language model for all languages together. Later on, for any given task, it would be sufficient to train on a dataset of a single language to receive good results for all languages, as the model is able to generalize many languages and apply the learned knowledge on them as well. The advantages of this technique, named Zero-Shot, are simplicity (one model for all) and efficiency especially due to faster training.", "To train the language model, the authors created a comprehensive dataset that consists of sentences and their translation in additional languages. The dataset is based on multiple sources:", "The final dataset includes 223 million parallel sentences in 93 languages from 34 families (e.g. Germanic and Semitic) and 28 scripts (Latin to Hebrew).", "The model includes two parts \u2014 the language model training and its Zero-Shot utilization for several NLP tasks.", "The language model uses a standard architecture for machine translation with an encoder, which generates a vector representation for a sentence in one language, and a decoder that tries to translate the sentence vector to the target language. A key feature of the model is its use of a single network for all languages.", "The decoder then tries to predict iteratively the next word based on the sentence embedding, the previous output of the LSTM module (embedded with BPE) and the target language ID. The decoder has only one LSTM layer (of size 2048) and a softmax layer to predict the most probable word. The sole purpose of the decoder is to train the encoder and it isn\u2019t used afterward.", "To avoid quadratic cost as the number of learned languages increases, the model is trained only with two target languages (English and Spanish) and not all-vs-all.", "The trained encoder can be used for solving other NLP tasks:", "The model is trained only on sentences in English and then tested on all languages (Zero-Shot). In addition, the encoder is constant and not fine-tuned for every task.", "The paper presents the model results on the XNLI dataset that includes sentences in 14 languages for the NLI task. The model achieves state-of-the-art results when compared to other models that were trained as Zero-Shot as well. For example, compared to Zero-Shot BERT, the proposed model reaches better results in most languages.", "On the other end, when training BERT for each language separately (by translating the training data to the target language), its results are superior to the proposed model with Zero-Shot configuration.", "In addition, the model also presents state-of-the-art results in classification task on the MLDoc dataset (Reuters news articles) and in similar text identification on the BUCC dataset. The model results across many languages show the consistency of its language model and the benefit of low-resource languages from using a single multilingual model.", "[Optional: Some tasks (BUCC, MLDoc) tend to perform better when the encoder is trained on long and formal sentences, whereas other tasks (XNLI, Tatoeba) benefit from training on shorter and more informal sentences?]", "[Optional: Ablation study: Reducing the number of layers in the encoder reduces accuracy]", "The model was implemented in Pytorch using fairseq for the encoder and the decoder. The language model was trained with 16 NVIDIA V100 GPUs for about 5 days.It will be open-source.", "The Multilingual Sentence Embeddings presents a novel technique for creating language models, which is faster, simpler and scalable. It can easily be fitted to new languages and new tasks while achieving strong results across many languages. It can even work with \u201cunknown\u201d languages that aren\u2019t part of the language model.", "However, when efficiency and scalability are less important than accuracy, it seems that this model, and Zero-Shot models in general, are inferior to fine-tuned models such as BERT. Interestingly, the authors plan to borrow concepts from the BERT architecture, e.g. using its Transformer instead of the BiLSTM module, to improve their model. A different approach would be to fine-tune the model for specific languages and compare the results.", "To stay updated with the latest Deep Learning research, subscribe to my newsletter on LyrnAI", "Byte Pair Encoding (BPE) is a data compression technique that iteratively replaces the most frequent pair of symbols (originally bytes) in a given dataset with a single unused symbol. In each iteration, the algorithm finds the most frequent (adjacent) pair of symbols, each can be constructed of a single character or a sequence of characters, and merged them to create a new symbol. All occurences of the selected pair are then replaced with the new symbol before the next iteration. Eventually, frequent sequence of characters, up to a whole word, are replaced with a single symbol, until the algorithm reaches the defined number of iterations (50k in this paper). During inference, if a word isn\u2019t part of the BPE\u2019s pre-built dictionary, it will be split into subwords that are.An example code of BPE can be found here.", "Learn something new every day. Currently Deep Learning :)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5f2cdf7d4fab&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@ranihorev?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Rani Horev"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8----5f2cdf7d4fab---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f2cdf7d4fab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----5f2cdf7d4fab---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f2cdf7d4fab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&source=-----5f2cdf7d4fab---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arxiv.org/abs/1812.10464", "anchor_text": "paper"}, {"url": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "LSTM"}, {"url": "https://arxiv.org/abs/1812.10464", "anchor_text": "Artetxe et al."}, {"url": "http://www.nyu.edu/projects/bowman/xnli/", "anchor_text": "XNLI"}, {"url": "https://github.com/google-research/bert/blob/master/multilingual.md", "anchor_text": "BERT"}, {"url": "https://arxiv.org/abs/1812.10464", "anchor_text": "Artetxe et al."}, {"url": "https://fairseq.readthedocs.io/en/latest/tutorial_simple_lstm.html", "anchor_text": "fairseq"}, {"url": "https://www.lyrn.ai", "anchor_text": "LyrnAI"}, {"url": "https://gist.github.com/ranihorev/6ba9a88c9e7401b603cd483dd767e783", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5f2cdf7d4fab---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----5f2cdf7d4fab---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----5f2cdf7d4fab---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/lyrnai?source=post_page-----5f2cdf7d4fab---------------lyrnai-----------------", "anchor_text": "Lyrnai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f2cdf7d4fab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----5f2cdf7d4fab---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f2cdf7d4fab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----5f2cdf7d4fab---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f2cdf7d4fab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8----5f2cdf7d4fab---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9bc3579798b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&newsletterV3=53f9e9fdd8d8&newsletterV3Id=9bc3579798b7&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----5f2cdf7d4fab---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Written by Rani Horev"}, {"url": "https://medium.com/@ranihorev/followers?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "1.7K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8----5f2cdf7d4fab---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9bc3579798b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-multilingual-sentence-embeddings-for-zero-shot-transfer-5f2cdf7d4fab&newsletterV3=53f9e9fdd8d8&newsletterV3Id=9bc3579798b7&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----5f2cdf7d4fab---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----5f2cdf7d4fab----0---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----5f2cdf7d4fab----0---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----5f2cdf7d4fab----0---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Rani Horev"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5f2cdf7d4fab----0---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----5f2cdf7d4fab----0---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "BERT Explained: State of the art language model for NLPAn approachable and understandable explanation of BERT, a recent paper by Google that achieved SOTA results in wide variety of NLP tasks."}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----5f2cdf7d4fab----0---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "7 min read\u00b7Nov 10, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff8b21a9b6270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----f8b21a9b6270----0-----------------clap_footer----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----5f2cdf7d4fab----0---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "29"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8b21a9b6270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270&source=-----5f2cdf7d4fab----0-----------------bookmark_preview----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5f2cdf7d4fab----1---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----5f2cdf7d4fab----1---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----5f2cdf7d4fab----1---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5f2cdf7d4fab----1---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5f2cdf7d4fab----1---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5f2cdf7d4fab----1---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5f2cdf7d4fab----1---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----5f2cdf7d4fab----1-----------------bookmark_preview----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5f2cdf7d4fab----2---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----5f2cdf7d4fab----2---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----5f2cdf7d4fab----2---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5f2cdf7d4fab----2---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5f2cdf7d4fab----2---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5f2cdf7d4fab----2---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5f2cdf7d4fab----2---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----5f2cdf7d4fab----2-----------------bookmark_preview----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----5f2cdf7d4fab----3---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----5f2cdf7d4fab----3---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----5f2cdf7d4fab----3---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Rani Horev"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5f2cdf7d4fab----3---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----5f2cdf7d4fab----3---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "Explained: A Style-Based Generator Architecture for GANs - Generating and Tuning Realistic\u2026NVIDIA\u2019s novel architecture for Generative Adversarial Networks"}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----5f2cdf7d4fab----3---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": "9 min read\u00b7Dec 30, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cb2be0f431&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----6cb2be0f431----3-----------------clap_footer----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----5f2cdf7d4fab----3---------------------abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cb2be0f431&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431&source=-----5f2cdf7d4fab----3-----------------bookmark_preview----abfc884a_d67c_468f_a7c1_2cd3d6ec89a1-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "See all from Rani Horev"}, {"url": "https://towardsdatascience.com/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----0-----------------clap_footer----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----5f2cdf7d4fab----0-----------------bookmark_preview----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----5f2cdf7d4fab----1-----------------bookmark_preview----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----0-----------------clap_footer----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----5f2cdf7d4fab----0---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----5f2cdf7d4fab----0-----------------bookmark_preview----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://tmmtt.medium.com/?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://tmmtt.medium.com/?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Teemu Maatta"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "OpenAI\u2019s Embedding Model With Vector DatabaseThe updated Embedding model offers State-of-the-Art performance with 4x longer context window. Thew new model is 90% cheaper. The smaller\u2026"}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "\u00b712 min read\u00b7Jan 10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2Fb69014f04433&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fopenais-embedding-model-with-vector-database-b69014f04433&user=Teemu+Maatta&userId=a536c637e472&source=-----b69014f04433----1-----------------clap_footer----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----5f2cdf7d4fab----1---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb69014f04433&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fopenais-embedding-model-with-vector-database-b69014f04433&source=-----5f2cdf7d4fab----1-----------------bookmark_preview----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----5f2cdf7d4fab----2---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=read_next_recirc-----5f2cdf7d4fab----2---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=read_next_recirc-----5f2cdf7d4fab----2---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Eric Kleppen"}, {"url": "https://python.plainenglish.io/?source=read_next_recirc-----5f2cdf7d4fab----2---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Python in Plain English"}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----5f2cdf7d4fab----2---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Topic Modeling For Beginners Using BERTopic and PythonHow to make sense of your text data by reducing it to topics"}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----5f2cdf7d4fab----2---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "\u00b711 min read\u00b7Feb 12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2Faaf1b421afeb&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Ftopic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb&user=Eric+Kleppen&userId=1e2ea32699c9&source=-----aaf1b421afeb----2-----------------clap_footer----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----5f2cdf7d4fab----2---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faaf1b421afeb&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Ftopic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb&source=-----5f2cdf7d4fab----2-----------------bookmark_preview----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----5f2cdf7d4fab----3---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----5f2cdf7d4fab----3---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----5f2cdf7d4fab----3---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Andrea D'Agostino"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----5f2cdf7d4fab----3---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----5f2cdf7d4fab----3---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "How to Train a Word2Vec Model from Scratch with GensimIn this article we will explore Gensim, a very popular Python library for training text-based machine learning models, to train a Word2Vec\u2026"}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----5f2cdf7d4fab----3---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": "\u00b79 min read\u00b7Feb 6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc457d587e031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031&user=Andrea+D%27Agostino&userId=4e8f67b0b09b&source=-----c457d587e031----3-----------------clap_footer----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----5f2cdf7d4fab----3---------------------4baa3f47_4d45_4591_8d06_882cec6b3e86-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc457d587e031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031&source=-----5f2cdf7d4fab----3-----------------bookmark_preview----4baa3f47_4d45_4591_8d06_882cec6b3e86-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----5f2cdf7d4fab--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}