{"url": "https://towardsdatascience.com/an-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee", "time": 1682994663.061322, "path": "towardsdatascience.com/an-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee/", "webpage": {"metadata": {"title": "An Overview of Categorical Input Handling for Neural Networks | by pascalwhoop | Towards Data Science", "h1": "An Overview of Categorical Input Handling for Neural Networks", "description": "In the context of a coding exercise in 2018, I was asked to write a sklearn pipeline and a tensorflow estimator for a dataset that describes employees and their wages. The goal: Create a predictor to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/uciml/adult-census-income", "anchor_text": "dataset", "paragraph_index": 0}, {"url": "https://github.com/pascalwhoop/categorical-demo", "anchor_text": "benchmark predictor network", "paragraph_index": 10}, {"url": "https://arxiv.org/pdf/1604.06737v1.pdf", "anchor_text": "This paper", "paragraph_index": 14}, {"url": "https://www.fast.ai/2018/04/29/categorical-embeddings/", "anchor_text": "this post about it", "paragraph_index": 14}, {"url": "https://keras.io/layers/embeddings/", "anchor_text": "embedding layer", "paragraph_index": 15}, {"url": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py", "anchor_text": "natural language processing approaches", "paragraph_index": 15}, {"url": "https://www.tensorflow.org/guide/embedding", "anchor_text": "adopt such a pretrained embedding", "paragraph_index": 16}, {"url": "http://ruder.io/word-embeddings-2017/index.html#taskanddomainspecificembeddings", "anchor_text": "domain-specific embedding", "paragraph_index": 16}, {"url": "https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/", "anchor_text": "Difference Coding", "paragraph_index": 17}, {"url": "https://lineardigressions.com/", "anchor_text": "linear digressions", "paragraph_index": 19}, {"url": "http://www.bullshitjob.com/title/", "anchor_text": "This page takes it to the extreme", "paragraph_index": 19}, {"url": "https://en.wikipedia.org/wiki/Top-level_domain", "anchor_text": "TLD", "paragraph_index": 20}, {"url": "https://stats.stackexchange.com/questions/36303/regression-model-with-categorical-values", "anchor_text": "This,", "paragraph_index": 23}, {"url": "https://stats.stackexchange.com/questions/298479/how-to-handle-large-categorical-values-in-data-frame", "anchor_text": "this,", "paragraph_index": 23}, {"url": "https://stats.stackexchange.com/questions/313715/one-hot-encoding-alternatives-for-large-categorical-values", "anchor_text": "this", "paragraph_index": 23}], "all_paragraphs": ["In the context of a coding exercise in 2018, I was asked to write a sklearn pipeline and a tensorflow estimator for a dataset that describes employees and their wages. The goal: Create a predictor to predict if someone earns more or less than 50k a year.", "One of the issues I had was the handling of categorical values. While a decision tree or forest has no issues with such data (they actually work really well with it), it\u2019s a bit more tricky to handle with a NN. Of course, we all learned One-Hot-Encoding is a way to map this kind of data into a NN passable format. But I was asked to develop an exhaustive list of many ways of handling a categorical column. The column with the highest number of categories is the native-country with 41 unique occurring values.", "Let\u2019s assume for a minute the dataset had an additional column called \u201cemail domain\u201d which holds domains such as \u201c@gmail.com\u201d \u201c@hotmail.com\u201d and private domains such as \u201c@pascalbrokmeier.de\u201d. This list may hold thousands of unique values and these values are very difficult to handle by a neural network. A good tool would encode the meaning of the categories in some meaningful way while keeping the number of dimensions relatively low.", "It turns out there are a number of ways to approach this problem. In the following article I will therefore create an overview of many ways to handle categorical data with neural networks. I will split the list into two categories: Generic approaches that can map any column of arbitrary symbols into appropriate representations and domain specific ones. For the domain specific example I will describe ways of representing the country column in some meaningful way.", "Before diving into ways of handling categorical data and passing it to a neural network, I want to loose a few words to describe what it is. In my own words, categorical data is a set of symbols that describe a certain higher level attribute of some object, system or entity of interest. As an example, the concepts \u201cred\u201d, \u201cblue\u201d and \u201cgreen\u201d describe the fact that some physical objects radiate a specific distribution of the electromagnetic spectrum which turns into an observation of a conscious human being that can still observe the world through the visual sense. This is a whole lot more to handle than a simple \u201c1, 2, 3\u201d. How would you order the colors? How would you put them into relation with each other? What is belongs to what? Which of the following four words would you assign a lower distance between each other? \u201cGreen, blue, sky, leaf\u201d.", "Categorical data can, but doesn\u2019t have to, follow some sort of ordering. Often however, categorical data may be distinct or even overlapping. Sometimes possible values of a category set can have relations between each other, sometimes they have nothing to do with each other whatsoever. All of these concepts need to be kept in mind when transferring categorical input into a numeric vector space.", "a categorical variable is a variable that can take on one of a limited, and usually fixed number of possible values, assigning each individual or other unit of observation to a particular group or nominal category on the basis of some qualitative property.", "Okay enough taking credit for other peoples work. Let\u2019s get into it:", "The following ways of encoding categorical data are agnostic to the type of categories we\u2019re interacting with.", "Let\u2019s start with the simplest form: Assigning each possible category an integer and pass it along. This is an enormously naive way of handling the data and it usually serves no good other than to make it work, meaning the program won\u2019t crash anymore. When looking at the country column, one may then expect something like this:", "There are several downsides to this approach: Canada != 1/2 * China and Vietnam != 40/39*United-States . Any higher-level information about these countries is lost in translation. The results show less performance when using my benchmark predictor network:", "The one that I found most often to be the \u201crecommended approach\u201d is OHE, also called \u201cDummy Encoding\u201d. It\u2019s explained on nearly every page that pops up when searching for \u201ccategorical data neural networks\u201d. It\u2019s also part of sklearn and therefore very quick to apply to a dataset. The principle is simple and best shown with a bit of code:", "Excuse me for not having it shared as a gist. For some reason, medium turns my pasted gist links into screenshots of the gist. Very useless", "The results are an improvement over the previous variant:", "This paper and this post about it both describe how to turn tabular data into something a neural network can manage.", "What this does is allow you to pre-train train an embedding layer for each category that you intend to convert into something a NN can consume. In the graphic above, the instacart team used an embedding layer to convert any of their 10 million products into a 10 dimensional embedding. The following hidden layers then only need to handle a much smaller input size. Also, these lower dimensions are then of fixed size which is important for building models, as the input size of the first layer needs to be set during training time and the later prediction values must also adhere to this size. The concept is very similar to natural language processing approaches and we may even make use of the pre-trained embeddings. More on that later", "What does this mean for our categorical values? Well, for each categorical column in the dataset, we\u2019d have to create an embedding network that learns embeddings for that category. If the categorical column contains words from a pre-trained embedding vocabulary (such as a colors embedding or another subdomain), it may be beneficial to adopt such a pretrained embedding. If the vocabulary in the category is out of the ordinary, it may be better to train (or adapt) a domain-specific embedding. This has the added benefit of much lower dimensionality. A vector space that only needs to describe colors in relation to each other may be much smaller than one that tries to embed all words in the English language.", "Difference Coding may be helpful for a categorical value that describes ordinal properties. Let\u2019s assume there are just three forms of education: None, School, University. In this example, the result would be three new variables with the following values:", "Basically, the higher in the order, the more expressive are the values as more of the columns move away from a 0 value.", "How many words are in the category string, how long is the string, which letters occur how often? While this may be extremely noisy information, a NN with a sufficiently large dataset may be able to extract some small predictive power from such information. I remember Katie from linear digressions mentioning an intuition of hers once that went something along the lines of \u201cif you can imagine a human deriving some value out of the data, a machine learning algorithm may very well do too\u201d. What does that mean for our dataset? Well, a long job title may be indicative of a higher rank in a (arguably too deep) hierarchy chain, thus increasing the probability of earning a higher salary. Quick detour: This page takes it to the extreme (and distracts from my bad example).", "Let\u2019s jump back to the hypothetical email column. A domain has a TLD which may hold information about the origin of the individual. It may also give us an indicator about their affiliations with non-profit organizations (.org) or if they work in an educational institution (.edu). This information may be valuable for the training of a NN. Splitting the category into sub-columns may therefore be valuable.", "Edit: Probably the most powerful technique of all though is the usage of n-grams, specifically character level n-grams. The above paragraph already eludes to this but a the n-grams are definitely the more generic approach. Let\u2019s say you take each email and create a set of 2 \u2014 10-grams. Now, these n-grams can be encoded and passed to a ML algorithm. They will contain several grams such as \u201cweb.de\u201d, \u201cgmail.c\u201d or \u201c@apple.com\u201d. Surely, one can get a good amount of information from such substrings. Also, you now have a way of passing information to ML algorithms that contains all those cases where people don\u2019t have a gmail or hotmail account. People with personal domains certainly fall into a different category as jonny95@gmail.com (sorry Jonny).", "As noted, while many email domains such as those from Google Mail or Hotmail are very widespread over the population (and thus don\u2019t contain a lot of information), custom domains may be a strong indicator for a persons salary, especially if those custom domains are not personal domains but belong to some organization. There is also a plethora of data extractable from the web based on the domain name. A crawler may be added to the pipeline that, for each encountered domain name, performs a HTTP call to the domain, extracts some keywords and uses them during training.", "Converting categories to something a neural network can process is a common problem but finding more than a few ways to approach the problem seems to be hard. This, this, this question suggest that there really aren\u2019t many alternatives. Ultimately, any method that requires a NN or a regression to convert the categories into some vector representation requires itself a numeric input to begin with. There simply aren\u2019t many other ways to map a set of alternative values other than simply numbering ( OrdinalEncoder ) or turning each possible value into its own binary dimension ( OneHotEncoder ). Even the embeddings take the detour of a OneHotEncoder before passing a fixed-size vector into the prediction layers.", "If you know of any other ways of encoding such values, please share it with me! I\u2019ll update the article accordingly and credit any author of course.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Developer, Tech enthusiast, student, board sports and food lover"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc172ba552dee&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c172ba552dee--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c172ba552dee--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@pascalwhoop?source=post_page-----c172ba552dee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pascalwhoop?source=post_page-----c172ba552dee--------------------------------", "anchor_text": "pascalwhoop"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb86dbeb85bc5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&user=pascalwhoop&userId=b86dbeb85bc5&source=post_page-b86dbeb85bc5----c172ba552dee---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc172ba552dee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc172ba552dee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@sanwaldeen", "anchor_text": "sanwaldeen"}, {"url": "https://www.kaggle.com/uciml/adult-census-income", "anchor_text": "dataset"}, {"url": "https://github.com/pascalwhoop/categorical-demo", "anchor_text": "benchmark predictor network"}, {"url": "https://arxiv.org/pdf/1604.06737v1.pdf", "anchor_text": "This paper"}, {"url": "https://www.fast.ai/2018/04/29/categorical-embeddings/", "anchor_text": "this post about it"}, {"url": "https://tech.instacart.com/deep-learning-with-emojis-not-math-660ba1ad6cdc", "anchor_text": "https://tech.instacart.com/deep-learning-with-emojis-not-math-660ba1ad6cdc"}, {"url": "https://keras.io/layers/embeddings/", "anchor_text": "embedding layer"}, {"url": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py", "anchor_text": "natural language processing approaches"}, {"url": "https://www.tensorflow.org/guide/embedding", "anchor_text": "adopt such a pretrained embedding"}, {"url": "http://ruder.io/word-embeddings-2017/index.html#taskanddomainspecificembeddings", "anchor_text": "domain-specific embedding"}, {"url": "https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/", "anchor_text": "Difference Coding"}, {"url": "https://lineardigressions.com/", "anchor_text": "linear digressions"}, {"url": "http://www.bullshitjob.com/title/", "anchor_text": "This page takes it to the extreme"}, {"url": "https://en.wikipedia.org/wiki/Top-level_domain", "anchor_text": "TLD"}, {"url": "https://stats.stackexchange.com/questions/36303/regression-model-with-categorical-values", "anchor_text": "This,"}, {"url": "https://stats.stackexchange.com/questions/298479/how-to-handle-large-categorical-values-in-data-frame", "anchor_text": "this,"}, {"url": "https://stats.stackexchange.com/questions/313715/one-hot-encoding-alternatives-for-large-categorical-values", "anchor_text": "this"}, {"url": "https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/", "anchor_text": "https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis-2/"}, {"url": "https://en.wikipedia.org/wiki/Autoencoder", "anchor_text": "https://en.wikipedia.org/wiki/Autoencoder"}, {"url": "https://en.wikipedia.org/wiki/Categorical_variable#Categorical_variables_and_regression", "anchor_text": "https://en.wikipedia.org/wiki/Categorical_variable#Categorical_variables_and_regression"}, {"url": "https://en.wikipedia.org/wiki/List_of_analyses_of_categorical_data", "anchor_text": "List of analyses of categorical data - WikipediaThis a list of statistical procedures which can be used for the analysis of categorical data, also known as data on the\u2026en.wikipedia.org"}, {"url": "https://jaan.io/what-is-variational-autoencoder-vae-tutorial/", "anchor_text": "Tutorial - What is a variational autoencoder? - Jaan AltosaarUnderstanding Variational Autoencoders (VAEs) from two perspectives: deep learning and graphical models.jaan.io"}, {"url": "https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9", "anchor_text": "On learning embeddings for categorical data using Keras(This is a breakdown and understanding of the implementation of Joe Eddy solution to Kaggle\u2019s Safe Driver Prediction\u2026medium.com"}, {"url": "https://datascience.stackexchange.com/questions/43397/how-to-handle-different-input-sizes-of-an-nn-when-one-hot-encoding-a-categorical/43399#43399", "anchor_text": "How to handle different input sizes of an NN when One-Hot-Encoding a categorical input?Thanks for contributing an answer to Data Science Stack Exchange! Some of your past answers have not been\u2026datascience.stackexchange.com"}, {"url": "https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/", "anchor_text": "Why One-Hot Encode Data in Machine Learning?Getting started in applied machine learning can be difficult, especially when working with real-world data. Often\u2026machinelearningmastery.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c172ba552dee---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c172ba552dee---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----c172ba552dee---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----c172ba552dee---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc172ba552dee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&user=pascalwhoop&userId=b86dbeb85bc5&source=-----c172ba552dee---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc172ba552dee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&user=pascalwhoop&userId=b86dbeb85bc5&source=-----c172ba552dee---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc172ba552dee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c172ba552dee--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc172ba552dee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c172ba552dee---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c172ba552dee--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c172ba552dee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c172ba552dee--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c172ba552dee--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c172ba552dee--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c172ba552dee--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c172ba552dee--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c172ba552dee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pascalwhoop?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pascalwhoop?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "pascalwhoop"}, {"url": "https://medium.com/@pascalwhoop/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "210 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb86dbeb85bc5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&user=pascalwhoop&userId=b86dbeb85bc5&source=post_page-b86dbeb85bc5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fedc4d1722acb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee&newsletterV3=b86dbeb85bc5&newsletterV3Id=edc4d1722acb&user=pascalwhoop&userId=b86dbeb85bc5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}