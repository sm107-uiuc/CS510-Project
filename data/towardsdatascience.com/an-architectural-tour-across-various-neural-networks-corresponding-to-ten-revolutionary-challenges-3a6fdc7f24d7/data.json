{"url": "https://towardsdatascience.com/an-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7", "time": 1683016026.168442, "path": "towardsdatascience.com/an-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7/", "webpage": {"metadata": {"title": "An Architectural Tour Across Various Neural Networks Corresponding to Ten Revolutionary Challenges in Molecular Biology Modeling | by Miri Trope | Towards Data Science", "h1": "An Architectural Tour Across Various Neural Networks Corresponding to Ten Revolutionary Challenges in Molecular Biology Modeling", "description": "As a data scientist, have you ever been asked: \u201cdoes deep learning mimic the brain?\u201d At this point, you are probably going red, as you wonder what and how to respond. Well, there are no wrong\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/not-just-performance-insights-about-the-validation-process-of-sequences-of-life-models-eddd2c365343", "anchor_text": "link", "paragraph_index": 7}], "all_paragraphs": ["As a data scientist, have you ever been asked: \u201cdoes deep learning mimic the brain?\u201d At this point, you are probably going red, as you wonder what and how to respond. Well, there are no wrong questions, but there are definitely bad answers \u2026 This blog tries to elucidate an answer by granting an intuition to the question of why use various neural-networks (NN) models in light of the amazing field known as molecular biology. These miniature molecules are rarely seen (perhaps they live on the edge in their mysterious world :-); however, they entirely compose our being, in every cell of any creatures on the planet. As has been hinted in the title,", "in this talk, I will cover ten life-sciences problems solved by utilizing the power of approximately ten neural network architectures, along with pointing out the downsides of other machine learning (ML) traditional algorithms.", "Like being in a time-machine, we will jump from past to present through the evolution of organisms to the function of RNA, DNA, protein, and cell (ordered as nature dictated). Through the exploration of primary literature from the elites in the field (about 30 articles), we will learn about genetic diseases, viruses, and even understand what the 2020 Nobel Prize in Chemistry is all about (CRISPR).", "Drawing sketches to describe various neural networks associated with each corresponding challenge is the theme of this discussion. Beginning with the simplest possible neural networks: the multilayer-perceptron, convolution (CNN) and long short-term memory (LSTM), we will bridge the gap to understanding advanced models inspired by image processing, such as residual, generative adversarial networks (GAN), and contrastive nets. Sliding on to natural language processing (NLP) by translating the language of life (proteins) with the rise of Transformers (through attention mechanism), as well as classical models such as sequence models, and autoencoder-decoder. Inspired by molecule message passing, we will employ graph neural networks (GNN) by representing a molecule where the atoms are nodes and bonds are edges. No less importantly, we will crack the optimal activation functions with maxout layers. Last but not least, switching from Atari games to cells, we will close this talk with deep reinforcement learning (as most talks do). Fundamentals of machine learning will be addressed here-and-there in data augmentation, transfer learning, and t-SNE.", "I hope that after reading this blog, you will be familiar with NNs (and molecular biology, of course) like the back of your hands.", "I have included below a list of phrases worth knowing (not exclusively for reading this blog) from my data science experience in bioinformatics.", "Phylogenetic, motifs, exome, in-silico, glycans, oligo-to-polygenic, omics, metagenomics, biopolymer, heterogeneities, pathogen, neural crest, exon, splicing- DNA, exome, bacterial clade, chromatin, texa-tree, k-mer encoder, cellular, gene ontology", "For simplicity, I inferred the next headlines as best representing the underlying idea of each challenge: (1) The motivation of the challenge, (2) what we are trying to predict, (3) what is the rationale for using this particular architecture, (4) the input (most importantly, the representation) and output of the net for training, and lastly, (5) alternative methods (if any). The internal and external order of the challenges is organized according to model complexity, and the most influential paper of each challenge is highlighted to differentiate it amongst others (though all the papers were strictly selected- guaranteed!). Having said that, it is important to mention that some articles discussed here are still in arxiv status (pending acceptance). However, I still see beneficial value in knowing them for understanding the overall architectural-choice, while considering the validation process (which is lacking in this blog, maybe next time \u2014 update: here is a link to my blog about the validation, consider it as an appendix). For now, please enjoy your introduction to molecular-biology related advanced ML methods.", "With no further ado, let\u2019s shift to the revolutionary challenges we currently face in this exciting research era.", "Through the lens of genes, every aspect of life is addressed through sequencing coding. However, only partial information about particular diseases has been studied by way of clinical cases. How can a disease (phenotype) diagnosis be learned from analyzing sites of genes (genotype)? This is a serious question since the value of being alive during this age has increased dramatically relative to past generations \u2026 Yet, both biologists and bio-informatics still have a long way to go in investigating which genes are responsible for particular diseases, as in the following cases. In this section, I will describe how ML can potentially be applied as a diagnostic tool, paving the way for future clinical applications and advancing personalized medicine, and in general, hopefully improving our quality of life.", "Predicting the disease group from the control group for exome-based in-silico diagnosis of Crohn\u2019s disease CD [2] and bipolar disorder BD [1] patients, as well as predicting lung cancer survival features on gene-expression data [3] are our topic. The input is a tensor of Fg \u00d7 Ng (Ng stands for a list of genes involved in this specific disease and Fg is a list of features), and the output is probability scores. For instance, in the CD case, two sets of genes {222,691} (number of genes in each group) were found in the literature resulting in the disease and 11 features describing the genes (represent each gene\u2019s mutational burden as exonic, intronic, splicing, and so forth) [2]. In the third case, which classifies tumor type, input images (175x175 pixels) were generated by directly mapping gene-expression values to a fixed set of colors, using domain-specific information to determine every gene\u2019s position inside the image [3].", "The architectures are quite simple, leveraging basic principles in NN, involving fully connected layers (multi-layer perceptron nets [2]) and convolutional layers (for chromosomal representation [1]) and transfer-learning (for images [3]). The question arises whether NNs are qualified in classifying genes, even at the basic level of encoding? It is probably fair to say that a (shared) neuron will contain some \u201chidden\u201d compressed representation of the input features. This representation is optimized to allow the following layer to discriminate between cases and controls. In this sense, the encoding nets probably contain some significantly simplified representation of the genes, and NN models utilize the sliding window techniques (in the convolutional case), for instance, to understand the interactions between their representation (features).", "The underlying patterns of RNA sequences consist of short contiguous amino-acids called motifs, to which the proteins bind (RNA-binding proteins RBP). Variations of the motif in the sequences alter the affinity of binding. Another pattern that affects binding is the RNA secondary structure, increasing or decreasing the binding affinity depending on the RBP\u2019s preference.", "The challenge of predicting protein binding is not that easy, considering the following data constraints of various biological factors that affect binding. (1) The availability of high-quality data (genetic sequences are often quite noisy and biased) and metadata (empirically identified secondary structures) is an issue that still slips between the cracks. (2) This experiment includes short sequences that do not represent the diversity of secondary structures that RNAs can form. (3) RNA competition is in vitro, and so it does not faithfully recapitulate conditions in vivo, where other proteins are present and potentially competing for binding sites.", "Those were the downsides, now let\u2019s shift our attitude towards ML (the positive side). Many amino acids may be interchangeable in the biological context, but a glycine to alanine (G->A) substitution may be neutral, while a tryptophan to alanine (T->A) substitution would probably not. Therefore, it makes sense and even pragmatically possible to reduce dimensions by researching suitable encoders to represent amino acids. Embedding, as used in the language models, reduces the dimensionality of the input as there are many letters in human alphabets, and they can form many words of different lengths. However, for DNA/RNA sequences, there are only 4 annotating letters {T/U, A, C, G}, with one-hot encoding, all nucleotides are equally similar and dissimilar, leaving the classifier to figure out how they relate to individual items and in combination in a sequence.", "After describing the representation, comes the architectural part; the CNN filters can be viewed as motifs, a gold mine for biologists as it allows them to interpret the protein\u2019s binding preference and compare it with existing knowledge on binding preferences. The LSTM layers, on the other hand, offer more long-range context-dependency than the CNN filters, and when used in a binary classification setting, their output is interpreted directly as a binding profile. Because the LSTM nodes have a memory and can remember and detect contextual clues that are important for the classification task, they are especially useful when analyzing long sequences like RNA-sequences. They do not model anything specifically about secondary structure but instead \u201csimply\u201d learn the binding motifs\u2019 contexts. LSTM nodes are inherently unidirectional because they are time-dependent; they have memory of the past but no future knowledge. Each time-step is a nucleotide, so in order for the model to be aware of both upstream and downstream elements, we use an LSTM layer to analyze the forward sequence and another layer to analyze the reverse sequence. This is a generally useful approach as even language processing requires both past and present knowledge to understand a sentence\u2019s meaning entirely. Combining these is called a bidirectional LSTM (biLSTM) architecture but is approximately two regular LSTM layers.", "Thus, we use bidirectional layers because protein binding is not inherently a directional process but can be affected by sequences, both upstream and downstream. The LSTM layers of DeepCLIP [5] are fed based on the different distributions of convolutional-layer-detected motifs. In a way, the CNN layers can also be thought of as magnifying glasses or binoculars that guide the LSTM layers\u2019 attention by enhancing those regions of the input sequence. The latest model in this area is called ResidualBind [6], showing that using convolutional layers alone is inefficient in capturing all of the sequence variations, because RBPs have different degrees of complexity in their binding modes (some binding modes may be simple, while others may be complex). Thus, the residual module allows the network to build upon the first convolutional layer\u2019s patterns while considering the dilated long-range context of the convolutional layer.", "The central role of phylogenies in evolutionary biology is inferred in Charles Darwin\u2019s Origin of Species, where the sole figure included in the book is a sketch of the hypothetical phylogeny of some species (Darwin 1859). The genius of phylogenetic representation is reflected by its simple yet elegant manner of organization, defined as a tree. Here, several prediction tasks are explored to analyze the phylogenetic evolutionary tree\u2019s construction; from the evaluation of IBD disease severity using metagenomics data [7], predicting the taxonomic origin of glycans [8], to predicting the topology of trees with four taxa (i.e., quartet trees)[9].", "In CNN models, metagenomics data can be loosely interpreted as an image, followed by the concept of proximity (distance) between features. As in pictures (pixels), the same holds with respect to bacterial clades in their phylogenetic tree. The metagenomics data were converted into a set of images [7], one for each sample, where pixels corresponding to the same bacterial species have the same position (coordinates) across all samples, and the intensity of the pixel corresponds to a pixel\u2019s data abundance.", "In that case, the convolutional layer plays a role in functioning under the policy of phylogenetic relation between bacterial clades, later used by the classifier when discriminating patients. Before diving too deeply into architectural aspects, let\u2019s talk about the limitations of other machine learning methods such as SVM, RF, etc. when the input is multi-modal and consists of sequences and a phylogenetic tree (as in our case). Unlike the convolution layer, which takes care of the distances of the tree nodes, no alternative method would handle both modalities simultaneously, in such an appropriate way. What\u2019s more, the nature of heterogeneities in substitution processes across sites and lineages requires explicitly taking into account substitution models of sequence evolution. In that case, other methods could fail due to model misspecification and insufficiency.", "Now that we are on the same page about the effectiveness of NNs to our problem, let\u2019s understand in detail the input and output. Abstractively, the original quartet phylogenetic assumption [9] task is simply predicting a discrete state (out of three) from the input data of four sequences. Therefore, four aligned amino acid sequences of dimension 4\u00d720\u00d7L are fed into a residual network, where 20 stands for possible amino acid states at any site of a protein sequence, 4 denoted as four taxons, and L for sequences lengths. The network output includes three numbers representing the likelihood that a given taxon is a sister of the other taxons. In theory, residual layers remember the input information as an additive part of the output, allowing deeper network structures without suffering from the vanishing gradients effect, hence can potentially achieve better learning of complex evolutionary processes [9].", "Clustered regularly interspaced short palindromic repeats (CRISPR)- associated (Cas9) system is now a famous technique in gene-editing (particularly after the granting of the Nobel Prize to Emmanuelle Charpentier and Jennifer Doudna this year). CRISPR/Cas9 was primarily found in Streptococcus pyogenes, which uses this mechanism to defend against invading viruses. Since then, CRISPR DNA-engineering has advanced quickly and has already been applied in treating diverse diseases. Briefly, CRISPR employs a guide RNA (gRNA) which binds to the DNA target site. Afterwards, a nuclease, such as the CRISPR associated protein 9 (Cas9), causes conformational changes before cleaving the DNA. However, it has an off-target risk. Cutting the off-target sites will harm the cells severely [12]. Thus, the research goal is accurately predicting the single gRNA on-target knockout efficacy [10]. For supervised learning, the input is a matrix L\u00d74 of gRNA sequence (4 nucleotides and L sequence length), and output is the known on-target knockout efficacies.", "The impressive skill of the NNs ability to understand the inner structure of data, which comes from the flexible combination of layer types and topologies, stands out relatively to shallow models (decision trees, for instance). Convolutional layers, for example, have a unique trait of processing data information through a shared local connection. Considering that DNA and RNA bases influence each other locally, convolutional layers could be a rational choice to handle those sequences-related issues. RNN is also a suitable way to model the sgRNA-related problems since sequential data naturally match the topology of RNN. However, RNN networks are usually challenging to train and require more data to achieve acceptable performance than CNN networks. Thus, adding studying cases by data augmentation helps alleviate generalization ability [12].", "Please sit while you read this because you are about to hear news about your own body. Let\u2019s be straight about one of the fundamental facts of genetics. Scientists admit (it\u2019s written black in white): \u201cit is known that over 98% of the human genome is non-coding, and 93% of disease-associated variants are located in these regions\u201d [14]. If you are already overwhelmed given that theory, let me comfort you that you are not alone; we are sailing in the same boat to the unknown, hoping to understand the function of these regions. However, this task is challenging as most of these regions are not well understood in their functions. Predicting the functional effects of non-coding variants from only a DNA sequence, using appropriate feature extraction and selection approaches for specific functional effects, is practically solving a multi-label classification problem. For those familiar with biology, the big picture for this task would be represented as predicting transcription factor binding (binding to proteins), handling the datasets prepared by DeepSEA and DanQ of classifying 919 binary targets (chromatin features) for 1000 input sequences in-length.", "DeepSEA proposed a model that utilizes CNNs to capture motifs from the raw DNA sequences, simple as it sounds: this model contains three consecutive convolution layers followed by fully connected layers that perform pattern recognition and pooling layers for spatial scaling [13]. The convolution layer is actually quite similar to scanning motifs in the DNA sequence, which may resemble how proteins like transcription factor recognize DNA sequence. The higher up layers then recognize sequence patterns over the longer sequence and capture motifs interactions and meta-patterns. DANQ, on the other hand, optimizes the model by adding on top of that CNN, a biLSTM network. The rationale is to interpret motifs as following a regulatory grammar governed by physical constraints that dictate the in vivo spatial arrangements and frequencies of motifs combinations, a feature associated with tissue-specific functional elements such as enhancers [14]. So far so good, but what about a little spicier approach? Maybe to strengthen the grammar association a little bit, is the time ripe for attention mechanism? An ensemble of various architectures is represented in this work [15], starts from the convolution layer, which captures regulatory motifs, then the recurrent layer captures regulatory grammar, and lastly, the category attention layer for the selection of corresponding valid features of different functions followed by the dense layer that classifies predictive labels [15].", "Different heads can pay attention to different kinds of information from various latent spaces. The attention score (achieved by summing-up the multi-heads) can approximately find the functional sites in DNA sequences, which is very useful in interpretability. Moreover, using the weight-sharing strategy of attention mechanisms reduces the number of locally connected parameters, from 10 million to million. The way to achieve this is by determining relevant characteristics for each binary target, and then the locally connected layer eliminates all unnecessary connections for each specific target [15]. To give you a glance at how the recognition of motifs serves medicine, catch a glimpse at the following \u201cwet experiment\u201d: from thousand of learned motifs, hundreds were matched to known motifs as having a significant potential developing vital functional effects such as NRSF, EZH2, and P300 [15].", "Natural language processing NLP has been generalized towards understanding the language of life (proteins). NLP methods are often independent in expensive labeled data, thanks to unsupervised learning, which eases the realization of the language of life (grammarly) in protein sequences (including one of the most abundant protein modifications, glycans). The main concept behind this approach is representing protein sequences as sentences and their constituent, amino acids, as single words (in glycans, each token (3-mers) represents a glycoword that can be found at a given position in the glycan [17]). The principal challenge discussed in this section is the interpretation of amino acids as a spoken language, which means uncovering the grammar (and its derivatives such as style, figure of speech, expression, etc.). Pessimists regarding the availability of biological/ medical data (like me) will be enlightened while hearing about the protein dataset scale. Apparently, UniRef and BFD datasets contain up to 393 billion amino acids (words) from 2.1 billion protein sequences, making it the largest collection of protein sequences available at the time of writing (22- and 112-times the entire English Wikipedia)[18].", "One of the architectures proven to learn useful representations of proteins is Transformers, which outperform LSTM-based approaches, as well as uncontextualized methods using word2vec [18], despite its lack of transparency. Yet, through the lens of the Transformer\u2019s inner workings, the attention mechanism, various protein properties can be examined, both at the token level (protein properties) and the token-pair level (contact maps)[1]. More about the interpretability techniques of those \u2018misty\u2019 models will be discussed later, while the focus here is on explaining instance-level predictions (post hoc interpretation). The Transformers models are related to two main approaches: auto-regression or auto-encoding. Auto-regressive predicts the next token in a sequence, given all previous tokens, while auto-encoding reconstructs corrupted input training. In translation tasks, usually, uni-directional models (auto-regressive) perform with bi-directional models (auto-encoding).", "The following is a summation/comparison of four well-known Transformers trained on proteins sequences datasets: Bert, Albert, Transformer-XL, and XLNet. 1st, Bert is a bidirectional model that originally tried to reconstruct corrupted tokens and nowadays is considered the de-facto standard for transfer learning in NLP. Second, Albert reduced Bert\u2019s complexity by hard parameter sharing between its attention layers, increasing the number of attention heads (improving traffic jams). Third, Transformer-XL overcomes the obstacle of having a maximum sequence length (around 20% of the sequences in those datasets are longer than 510 amino acids), which common to all previous Transformers by cutting sequences into fragments (chips) but allows the flow of information between them for longer proteins reusing its hidden states of fragments that have already been processed. Lastly, XLNet uses a similar uni-directional memory mechanism introduced by Transformer-XL, enabling the processing of arbitrary length sequences by gathering bidirectional context within one memory fragment [18].", "Back to interpretability, to probe the information captured in the token-level for tasks like binding sites and secondary structure, we freeze the weights of the original model and build upon a classifier with a single linear layer followed by softmax. For token-pair probing tasks (contact map), the concatenation of a pairwise feature vector is processed by the element-wise differences and products of the two tokens\u2019 output vectors [16].", "After reading all this dry and massive information, lo and behold by enjoying visualizing the beautiful visual embedding space, created by projecting the high-dimensional representations down to two dimensions using t-SNE [18], fig. 6.", "Of all the challenges discussed in this blog, I am most excited especially discussing the following two challenges! The reason I am so excited is the complexity of the model built as a system of neural nets, while each architecture benefit is fully exploited, and even managing another net in the model to give the best results (think of it as the best work team ever, while optimized, the nets are working on your behalf\u2026).", "Proteins make contact with other proteins in cellular pathways, hence understanding the functionality of these pathways through protein-protein interaction (PPI) networks is essential. Gene ontology term annotations (GO) classify proteins into about 200 different functionality classes, gathered into sections of molecular function, biological process, and cellular component. The challenge is predicting GO terms probabilities given an input data of protein sequence and structure (represented as graphs derived from molecule interactions in the 3D shape). Two types of sequence diversity are selected for the experiments: using sequences from the same organism or across species, while the last take advantage of large scale training sets and overcome the issue of limited feature space common only to proteins of the same organism [21].", "In DeepFRI, graph convolutional network GCN gets as input: a one-hot encoded protein sequence -> two stacked forward LSTM layers with 512 units each -> trained embeddings + an adjacency matrix (the protein graph), and returns the output: a single feature matrix that subsequently fed into two fully connected layers to produce the final predictions [19]. The adjacency matrix, also termed a contact map, is a 2D binary matrix representing the distance between all possible protein connections pairs. The convolution layers are suitable for this sort of structural problem as they convolve protein features over discrete paths (through contact maps) that are distinct in the primary sequence but close to each other in the 3D space. The formulation of Kipf & Welling [30] defines the equation of representation added to the first GCN layer, which indicates the multiplication of the contact map matrices and the final LSTM layer\u2019s hidden states.", "Do the activation functions commonly used in NN such as ReLU, Sigmoid, Tanh, etc. appropriately encode regular or common patterns within biological sequences? Another architectural approach is a network whose layers have the maxout activation function. The maxout activation of a layer is the element-wise maximum of a set of input affine transformations. Those activation functions approximate any arbitrary continuous function and outperform other conventional activation functions parameterized by specific hypotheses (e.g., rectified or sigmoid functions).", "Due to the highly sparse and unbalanced space occupied in this prediction task, a support vector machine (SVM) comes to the rescue using the maxout net features and providing an independent margin calibration, a binary classification for each class (with its specific decision boundaries)[20]. In this context, a point to mention is the networks\u2019 structure pattern (in terms of the number of units). While it is common to reduce the number of units in each layer for dimensionality reduction tasks, it\u2019s not always the case. In particular here, because the network was trained initially as a large multi-label classifier, leaving you ending up with a large number of classes, i.e., several hundred output units. Therefore, the later layers often provide more depth to allow the internal feature representations to be interpreted variously. Thus a large space to encode that type of highly informative presentation is needed [20].", "The immune system neutralizes an antigen, a viral invader, by recruiting antibodies to stop the invasion. However, an adequate response can last from days to weeks. Can the prediction of new viral mutations lead to predefined neutralizing antibodies? This process of highly selective interactions between the antigen and antibody determines the basis of antibody-mediated virus neutralization. A prediction of the corresponding antigen-epitope sequences synthesized by viral genomes is actually a broader problem than intuitively thought, considering the mutations of evolving populations in different viral species, learning a generalized time-reversible evolutionary model [24].", "For the sake of the training process, the evaluation was conducted by a collection of antibody-antigen sequences of various viruses, including HIV, Influenza, Dengue, SARS, Ebola, Hepatitis, etc. to find the most stable antibodies using features simulations in bioinformatics, structural biology, and molecular dynamics [22]; and two representations have been developed. The first representation is named graphical protein featurization GPF [22,23], and the second is a binary phylogenetic tree (partially structured)[23]. To give you a feeling regarding the representation of GPF, let\u2019s assume you have a sequence of length N. First, a construction of an adjacency matrix Nx20 (20 stands for the total number of amino acids representing a protein, and N the sequence length) is produced. Then, because we have 38 features F for each amino acid, the feature matrix shape is 20x38. Now, we multiply the adjacency with the feature matrix to construct the graph embedding. We call this product the graph embedding, and it has the shape of NxF. Finally, we mean pool over the graph embedding to convert it into Fx1 vector. This vector is multiplied by its transpose, giving us the final matrix of FxF. Finally, the FxF matrix is flattened to create a 1444 size vector (38x38 = 1444).", "Another architecture is based upon seq2seq generators within an adversarial network framework GAN, which generates complete protein sequences augmented with random noise (thus avoiding hand-tailored work done by experts) [24]. Those possible mutations of future virus populations are full-length proteins above 300 amino acids in length, imitating the underlying normal distribution N(0,1) that the original antigen sequence might come from by utilizing uni and bi-directional LSTM (analog to sentences translation)[22,23]. Those new sequences should not be significantly different from the original antigen (it does not make a lot of biological sense to have extremely varied sequences). Therefore, an auto-encoder is used as a discriminator that takes in two sequences and determines whether the input sequences are a real parent-child pair or if it is not. Bear in mind that the rationale for using biLSTM in the encoder layer and LSTM in the decoder (and not any other variation of the two) is the overall high performing architecture that solves particularly translation tasks using seq2seq models in combination with LSTMs. For biLSTM, the sequence is input both forwards and backwards, requiring the entirety of the sequence (this is not a problem for the encoder because we already have the entire input (parent) sequence). However, this does not make sense with the decoder because the output (child) sequence is generated in each step until we reach a stopping point; thus, it\u2019s a uni-directional LSTM.", "I chose to present this topic right after all the proteins sections, as a trope to the \u201cthat\u2019s life\u201d theme, meaning the optimized representation of a protein, which we massively discussed over the last three challenges, is concluded in this section.", "Pretrained embedding representations of biological sequences that capture meaningful properties can lighten many supervised learning problems in biology. The learning protein sequence embeddings routine, maps any protein sequence to a sequence of vector embeddings, one per amino acid position, encoding structural information. An ideal embedding cleanly separates the latent space\u2019s dataset domains, requiring no parameter tuning or additional evaluation labels.", "The beauty of representation learning is that all the biological properties are automatically learned in a purely data-driven manner, in which models infer hidden features that are essential to ensure the semantic and grammatical meaning of naturally occurring protein sequences. While other methods don\u2019t encode structural information, the Bepler et al. framework maps any protein sequence to a vector embedding by encoding both sequence and structure. Their model was trained using three biLSTM layers with 512 hidden units each and final output embedding dimension of 100 on protein sequences with a two-part feedback mechanism that incorporates information from (i) global structural similarity between proteins and (ii) pairwise residue contact maps for individual proteins [25].", "The inspiration of contrastive learning has been pointed out by Oord saying: \u201cone of the most common strategies for unsupervised learning has been to predict the future, missing or contextual information\u2026In neuroscience, predictive coding theories suggest that the brain predicts observations at various levels of abstraction\u201d. The desired embedding is captured in the latent representation of the protein during self-supervised pre-training of the model that presents patches as capturing motifs, unusual structural elements, regions of unusual amino acid composition, parts of catalytic sites, etc. The general formulation is: given input X, define {x1 , x2} as two different \u201cviews\u201d of X (e.g. patches of an image, or representations of different sequence timesteps), and encoders {g1 , g2} which encode {x1 , x2} respectively. The goal is to find encoder mappings that maximize the mutual information MI between the outputs. The model\u2019s intuition is that the global protein context determines its function, which influences each local patch of sequence/structure. By maximizing the mutual information between the global context and the local, the model is \u201cforced\u201d to learn the aspects of the protein\u2019s overall function that are connected to the local sequence/structure. This method outperforms in terms of accuracy, and the number of parameters, showing it is the most \u201cskilled\u201d protein representation [26]. Orange stars denote the contrastive model, and blue crosses denote other previously discussed methods ([26], fig. 1).", "Trained agents can beat human-level scores in several Atari games. If that is the case, why not train a model to predict a cell\u2019s movement? The cellular movements are treated as a result of derived and controlled behaviors regulated by inter or intracellular signals. Modeling cell interactions such as co-attraction and contact-inhibition of locomotion are essential for understanding collective cell migration. Collective cell migration is the coordinated motion of a group of cells commonly observed during embryonic development and wound healing, for instance. Predicting those biophysical behaviors through the means of artificial intelligence models is closer than ever. However, while the regulatory networks can be defined at a cellular, group, tissue, or even embryonic levels, only the individual cell movement (the leader agent) and its cell neighbors (the follower\u2019s agent) movement are modeled at that time. It feels like I\u2019m describing a game out here \u2026 :-)", "The main question in this game is, what would be the next agents move? In which trajectories and patterns can one model their movement towards a collective cell migration? The answer varies from learning their movement through computer vision tracking (however, there are vast problems here from costly experiments to discrete space) to applying dynamic equations like the old fashion one (but a good one, or at least most likely to imitate the biological behavior well) \u2014 diffusion [29]. To understand the policy learning entirely, stay tuned.", "Deep reinforcement learning is skillful at dealing with high-dimensional inputs since it optimizes the cell migration path over considerable temporal and spatial spans from a global perspective. What\u2019s more, it overcomes the local optimization problem encountered by traditional rule-based, agent-based modeling that uses greedy algorithms. The main concern over here is how to collect the observations. I mean, what is the best way to build an agent-based modeling framework to establish a simulation platform for collective cell migration using 3D time-lapse microscopy images [28]? Don\u2019t think too much about it because most of the nets are image-based, usually time-consuming, and computationally expensive. Also, the finite number of outputs cannot generate an infinite continuous representation for the migration direction.", "Deep deterministic policy gradient DDPG can learn versatile policies for both leader and follower cells using low-dimensional observations with biologically parameters and applying reinforcement learning [29]. Thus, two networks were trained, the critic and actor. The actor-network has three hidden layers with 64, 128, and 64 neurons and an output layer with one neuron. The critical network imports as input the position, concentration gradient direction, and action value from the actor network\u2019s output layer and finds the Q-value (optimal action-value) through another similar architecture network. The diffusion model then describes the concentration field in the simulation environment gathered with the particle dynamics motion. As the agents move, they act as multiple moving sources of chemo-attractants affecting the distribution of the concentration field, which determines the agents\u2019 action. Next, the interaction between particle motion and concentration space requires the simulation environment to solve the diffusion equation iteratively due to the agent\u2019s new locations [29].", "The advance in research methods relating to molecular biology is incredibly impressive, even taking into account the fact that during 2020 we have been shut in at home for an extended period of time (escaping the coronavirus). However, utilizing neural networks\u2019 potential to solve those vital challenges has encouraged the data-science community to \u201creturn fire\u201d\u2019 by seriously working 24/7 on these breath-taking innovative fields that directly affect our lives. Perhaps the panic caused by the national emergency over the epidemic was a refreshing wake up call, leading us to explore seriously innovative options for incorporating biology and machine learning methods into one approach?", "Another thought worth mentioning is the source of successful NN models. So far, the vision and NLP communities have developed much of the architecture discussed here. Thus most of my workaround was investigating patterns inspired by those applications (vision and NLP are apps, not pure mathematics). However, this raises the question of whether a new architectural model will pop up from the bioinformatics/ biotechnology/ biomedical/ biological/ genetics communities (that probably finds themselves swimming in a molecule pool)? While impressive works have come from mimicking nature behavior, will similar inspiration bring about innovation for the next generation of ML architecture?"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3a6fdc7f24d7&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@miritrope?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Miri Trope"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcd3969155b54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&user=Miri+Trope&userId=cd3969155b54&source=post_page-cd3969155b54----3a6fdc7f24d7---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3a6fdc7f24d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&user=Miri+Trope&userId=cd3969155b54&source=-----3a6fdc7f24d7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a6fdc7f24d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&source=-----3a6fdc7f24d7---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/not-just-performance-insights-about-the-validation-process-of-sequences-of-life-models-eddd2c365343", "anchor_text": "link"}, {"url": "https://medium.com/tag/data-science?source=post_page-----3a6fdc7f24d7---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----3a6fdc7f24d7---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3a6fdc7f24d7---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/genetics?source=post_page-----3a6fdc7f24d7---------------genetics-----------------", "anchor_text": "Genetics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----3a6fdc7f24d7---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3a6fdc7f24d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&user=Miri+Trope&userId=cd3969155b54&source=-----3a6fdc7f24d7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3a6fdc7f24d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&user=Miri+Trope&userId=cd3969155b54&source=-----3a6fdc7f24d7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a6fdc7f24d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcd3969155b54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&user=Miri+Trope&userId=cd3969155b54&source=post_page-cd3969155b54----3a6fdc7f24d7---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F15d2b34a4f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&newsletterV3=cd3969155b54&newsletterV3Id=15d2b34a4f18&user=Miri+Trope&userId=cd3969155b54&source=-----3a6fdc7f24d7---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Written by Miri Trope"}, {"url": "https://medium.com/@miritrope/followers?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "53 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcd3969155b54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&user=Miri+Trope&userId=cd3969155b54&source=post_page-cd3969155b54----3a6fdc7f24d7---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F15d2b34a4f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-architectural-tour-across-various-neural-networks-corresponding-to-ten-revolutionary-challenges-3a6fdc7f24d7&newsletterV3=cd3969155b54&newsletterV3Id=15d2b34a4f18&user=Miri+Trope&userId=cd3969155b54&source=-----3a6fdc7f24d7---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/questions-you-should-ask-ai-based-drug-discovery-companies-78c5a011c915?source=author_recirc-----3a6fdc7f24d7----0---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=author_recirc-----3a6fdc7f24d7----0---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=author_recirc-----3a6fdc7f24d7----0---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Miri Trope"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3a6fdc7f24d7----0---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/questions-you-should-ask-ai-based-drug-discovery-companies-78c5a011c915?source=author_recirc-----3a6fdc7f24d7----0---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Questions you should ask AI-based drug discovery companiesIssues AI-based drug discovery companies are dealing with"}, {"url": "https://towardsdatascience.com/questions-you-should-ask-ai-based-drug-discovery-companies-78c5a011c915?source=author_recirc-----3a6fdc7f24d7----0---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "7 min read\u00b7Feb 7, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F78c5a011c915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquestions-you-should-ask-ai-based-drug-discovery-companies-78c5a011c915&user=Miri+Trope&userId=cd3969155b54&source=-----78c5a011c915----0-----------------clap_footer----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/questions-you-should-ask-ai-based-drug-discovery-companies-78c5a011c915?source=author_recirc-----3a6fdc7f24d7----0---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F78c5a011c915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquestions-you-should-ask-ai-based-drug-discovery-companies-78c5a011c915&source=-----3a6fdc7f24d7----0-----------------bookmark_preview----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3a6fdc7f24d7----1---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3a6fdc7f24d7----1---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3a6fdc7f24d7----1---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3a6fdc7f24d7----1---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3a6fdc7f24d7----1---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3a6fdc7f24d7----1---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3a6fdc7f24d7----1---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----3a6fdc7f24d7----1-----------------bookmark_preview----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3a6fdc7f24d7----2---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----3a6fdc7f24d7----2---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----3a6fdc7f24d7----2---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3a6fdc7f24d7----2---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3a6fdc7f24d7----2---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3a6fdc7f24d7----2---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3a6fdc7f24d7----2---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----3a6fdc7f24d7----2-----------------bookmark_preview----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bridging-the-gap-between-genetics-and-neural-networks-4fdb91032f4b?source=author_recirc-----3a6fdc7f24d7----3---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=author_recirc-----3a6fdc7f24d7----3---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=author_recirc-----3a6fdc7f24d7----3---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Miri Trope"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3a6fdc7f24d7----3---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/bridging-the-gap-between-genetics-and-neural-networks-4fdb91032f4b?source=author_recirc-----3a6fdc7f24d7----3---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "Bridging the Gap Between Genetics and Neural NetworksBuilding and Analysing Neural Networks on Genetic Data"}, {"url": "https://towardsdatascience.com/bridging-the-gap-between-genetics-and-neural-networks-4fdb91032f4b?source=author_recirc-----3a6fdc7f24d7----3---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": "\u00b713 min read\u00b7Apr 28, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4fdb91032f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbridging-the-gap-between-genetics-and-neural-networks-4fdb91032f4b&user=Miri+Trope&userId=cd3969155b54&source=-----4fdb91032f4b----3-----------------clap_footer----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bridging-the-gap-between-genetics-and-neural-networks-4fdb91032f4b?source=author_recirc-----3a6fdc7f24d7----3---------------------a5d42224_74aa_4426_8a55_4ebfc502bec3-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fdb91032f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbridging-the-gap-between-genetics-and-neural-networks-4fdb91032f4b&source=-----3a6fdc7f24d7----3-----------------bookmark_preview----a5d42224_74aa_4426_8a55_4ebfc502bec3-------", "anchor_text": ""}, {"url": "https://medium.com/@miritrope?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "See all from Miri Trope"}, {"url": "https://towardsdatascience.com/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----3a6fdc7f24d7----0-----------------bookmark_preview----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----3a6fdc7f24d7----1-----------------bookmark_preview----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3a6fdc7f24d7----0---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----3a6fdc7f24d7----0-----------------bookmark_preview----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----3a6fdc7f24d7----1---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----3a6fdc7f24d7----1-----------------bookmark_preview----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----3a6fdc7f24d7----2---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----3a6fdc7f24d7----2---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----3a6fdc7f24d7----2---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Josep Ferrer"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----3a6fdc7f24d7----2---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----3a6fdc7f24d7----2---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Stop doing this on ChatGPT and get ahead of the 99% of its usersUnleash the Power of AI Writing with Effective Prompts"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----3a6fdc7f24d7----2---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "\u00b78 min read\u00b7Mar 31"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&user=Josep+Ferrer&userId=8213af8f3ccf&source=-----f3441bf7a25a----2-----------------clap_footer----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----3a6fdc7f24d7----2---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "71"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&source=-----3a6fdc7f24d7----2-----------------bookmark_preview----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----3a6fdc7f24d7----3---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----3a6fdc7f24d7----3---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----3a6fdc7f24d7----3---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Aleid ter Weel"}, {"url": "https://medium.com/better-advice?source=read_next_recirc-----3a6fdc7f24d7----3---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "Better Advice"}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----3a6fdc7f24d7----3---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "10 Things To Do In The Evening Instead Of Watching NetflixDevice-free habits to increase your productivity and happiness."}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----3a6fdc7f24d7----3---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": "\u00b75 min read\u00b7Feb 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-advice%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&user=Aleid+ter+Weel&userId=6ffe087f07e5&source=-----4e270e9dd6b9----3-----------------clap_footer----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----3a6fdc7f24d7----3---------------------7f41de13_ae2a_42da_9e69_c2756b50a82f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "204"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&source=-----3a6fdc7f24d7----3-----------------bookmark_preview----7f41de13_ae2a_42da_9e69_c2756b50a82f-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----3a6fdc7f24d7--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}