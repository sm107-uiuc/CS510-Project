{"url": "https://towardsdatascience.com/context-theory-i-introduction-9d121194bd48", "time": 1682995574.8832269, "path": "towardsdatascience.com/context-theory-i-introduction-9d121194bd48/", "webpage": {"metadata": {"title": "Conversation Structure Chatbot context Pragmatics context aware chatbot Context Theory computational pragmatics statistical pragmatics | Towards Data Science", "h1": "Context Theory I: Introduction", "description": "Conversation Structure Chatbot context Pragmatics context aware chatbot Context Theory computational pragmatics statistical pragmatics"}, "outgoing_paragraph_urls": [{"url": "http://nlp.stanford.edu:8080/parser/", "anchor_text": "Stanford NLP", "paragraph_index": 4}, {"url": "https://explosion.ai/demos/displacy", "anchor_text": "SpaCy", "paragraph_index": 4}, {"url": "https://chris.com/", "anchor_text": "https://chris.com", "paragraph_index": 36}, {"url": "https://duygua.github.io", "anchor_text": "https://duygua.github.io", "paragraph_index": 36}, {"url": "https://www.youtube.com/c/NLPwithDuygu", "anchor_text": "https://www.youtube.com/c/NLPwithDuygu", "paragraph_index": 38}], "all_paragraphs": ["Conversational AI has come a long way since the early days of state machines and intent classification combinations. End-to-end training strategies and reinforcement learning research accelerated to replace unscalable predefined intents and hard-coded states. However, things are far from perfect and complete to chatbot end-users. In this aspect, Dialogue Management components show great potential for improvement, and the key for conversing like a real human-being lies in keeping up with the conversation.", "Almost everyone can classify some predefined intents. The bigger question is: can you classify context-dependent intents? What do you do to short answers, for instance, when so many of them exist in almost all spoken languages, carry not much information, and whose meaning is generally heavily context-dependent, but can still dramatically change the way dialogue goes and drastically contribute to the whole context?", "While generating an answer, one maybe can catch grammatical cohesion and lexical cohesion\u2026 but are grammatical and lexical choices the only things that make a text coherent?", "In this series of posts, I will explain the basics of the Context Theory and Computational Pragmatics for mainly practical purposes; to be used in Dialogue Management components of chatbots and other forms of intelligent assistants. This way, we can conduct better NLU, model the dialogue state better and generate coherent answers\u2026 thus almost imitating a human being.", "Dear readers, no such thing as computational Context Theory exists, and I doubt that one will ever exist. Contrary to the well-studied parts of linguistics, such as Syntax Theory, context lacks a well-defined unit. Syntax theory enjoys constituents such as the unit. Consequently grammatical tagging, dependency grammars and phrase structure grammars have attracted considerable research. The overall result is satisfactory, with several statistical and rule-based parser implementations in popular NLP libraries, including Stanford NLP and SpaCy. Let\u2019s see an example of dependency relations generated by the SpaCy parser:", "What about if we want to do the same for the context?", "If one has enough GPU power and a statistical framework, modeling dependencies in a statistical manner is not difficult at all (OK, it\u2019s not trivial either). However, if you want to model context, what is it that you will model? What are the components that make up a conversations\u2019 context-so-far? Entities, relations, coreferences, conversation memory, social norms, ground of the conversation, place and time of the conversation, state of mind and moods of the participants\u2013how do we model those?", "Maybe we could ascribe one memory unit for the conversation history\u2013but what about the memory of the participants? Maybe Participant I slept badly the previous night, feels tired and does not feel like conversing at all on that day, thus giving short answers only. Maybe Participant II got dumped by a girlfriend recently and doesn\u2019t wanna talk about women at all. How do you model someone else\u2019s life experience and state of mind?", "What about cultural norms or the general facts of everyday life? Time and spatial dependencies? Obviously whether the conversation takes place at a workplace or at a cafe matters a lot. In the same way, you don\u2019t talk to your boss in the way that you talk to your mama, I assume.", "Only one continuous dense representation or several vectors? Graph embeddings for the factoids maybe?", "Different linguists seek to define what context is, in order to develop their own theories. For instance, H.G. Widdowson defined context as:", "\u201cthose aspects of the circumstance of actual language use which are taken as relevant to meaning\u201d.", "G. Yule gave rather a risk-free definition:", "\u201cContext is the physical environment in which a word is used\u201d during his research of reference.", "Purposes are different, research focuses are different, but a very important aspect is shared: the environment. One cannot isolate what has been said from the circumstances in which it has been said. Whoever claims that \u201clanguage is a self-contained system\u201d may not really be correct. Language includes linguistics, culture, time, space, surroundings and common sense. That\u2019s what we\u2019re going to explore thoroughly in this series.", "After all these computational and linguistic concerns only one question is left: What is it that we want to model as context exactly anyway?", "What is that thing so called a \u201ccontext\u201d exactly?", "In order to find a reasonable \u201cunit\u201d for the context concept, let\u2019s go through some basic concepts first:", "Coherence is the term you are looking for if one is curious about what makes a text semantically meaningful. Coherence includes both the syntactical features , the \u201ccommon-sense\u201d, the general world knowledge and logical connections. See the examples:", "Here, obviously the second speaker is aware of the general world knowledge that Sandro Paris is a French clothing retailer. Then (s)he was able to make a comment on the issue in turn.", "This dialogue segment looks perfectly simple and ordinary, though it contains a significant catch. In the second line, the second speaker draws the logical conclusion that", "via their common-sense. The second conclusion is based on a cultural reference that married people wear wedding rings. Despite looking insignificant, given that an average human being draws many logical conclusions per day, it is computationally not-so-straightforward how we represent common-sense. We\u2019ll come to this issue later in the series.", "Coherence is a big playground, a combination of logic, knowledge representation, grammar and semantics; combining different parts of the brain, despite being listed under linguistics. However cohesion is really a pure linguistic concept. Cohesion is the grammatical and lexical linkage that semantically glues a text together. Cohesion possesses well-defined instruments, and in this article I\u2019ll discuss referencing and ellipsis.", "What is referencing? We can roughly say that it\u2019s a pointer that a speaker holds to something in the current discourse context, in the world of the two participants. Don\u2019t raise your eyebrow, we are still discovering what the \u201cworld\u201d is \ud83d\ude0a. More technically, a referring expression is a linguistic expression that a speaker uses for referring to something. The thing referred to is called the referent.", "Referencing can be anaphoric or cataphoric. Anaphora denotes the act of referring backwards in the context, while cataphora is literally pointing downwards, coming from \u03ba\u03b1\u03c4\u03b1\u03c6\u03bf\u03c1\u03ac (\u201ca downward motion\u201d). Compare the examples:", "The referring term here is the pronoun he and is an anaphor with the antecedent Jim. Since we are interested in context theory for conversational interfaces, we see the anaphoric type more. In the second sentence the pronoun his is a cataphor with postcedent Picasso. Maybe inspiration of the ancient Greeks was \u201cup context\u201d and \u201cdown context\u201d of dialogue\u2013who knows? \ud83d\ude09", "Another Greek-derived term Ellipsis (literally omission) occurs in colloquial language a lot: when a phrase is \u201cobvious\u201d from the context, we simply omit it.", "A frequent and well-studied form of ellipsis is verb phrase ellipsis, or VP-ellipsis for short. In this sort of construction, a non-finite verb phrase is omitted. See the examples:", "How do we charge meaning to these sort of sentences? One possibility is that our brains make a strict syntactical replacement, for instance in the third sentence to charge meaning to did, we look for previous VPs and find fell asleep. Another possibility is that instead of a syntactical reconstruction, we instead make a retrieval of the current semantic context. In the second case, instead of POS-tagging, we perform a retrieval of the continuous context vector. Though we can perfectly understand the grammar of our own languages, we can employ some retrieval tasks, can\u2019t we? \ud83d\ude09 At the end, the human brain can process semantics in different ways. Let\u2019s hope we can manage the same throughout our series.", "Another concept of discourse, Definiteness/Indefiniteness is actually primary school level grammatical information\u2013however, it is very useful in terms of what is inferable information, and what is not. We all know the English definite article (the) and indefinite articles (a, an). Definite and indefinite terms then are applied to noun phrases: the girl, an apple\u2026 When we want to introduce a new entity to the context, we use the indefinite article. Later if we want to refer to this entity we either use it together with the definite article, or we use a pronoun, or we use a demonstrative. For instance:", "Here, the customer answer is completely coherent and understandable because the black pair of shoes is already introduced to the context one line ago. Hence at that point, both the customer and the bot are familiar what object has been talked about.", "Indeed, the opposite also applies: definite usage makes sense only when the existence of the referred entity has been given by the current context. Can you imagine this sentence being spoken \ud83d\ude0a:", "My mother tongue is a language without any articles, neither definite nor indefinite. During English translation, only the context tells you where to insert an article. If you want to say the above sentence correctly, this is how you say:", "In the second sentence, though there is no definite articles, one still understands the meaning. Occasionally, we use one-anaphora in definite situations:", "In any case, familiarity does not depend only on usage of articles, it depends on the context as a whole. As in the case of Turkish-English translation, context give clues to the definiteness/indefiniteness. The context as a \u201cwhole\u201d is stronger than the summation of its components; if some components are missing, still we can fill-the-gaps from the discourse context.", "Dear readers, here we reach the end of the article, yet still we are not quite convinced of how to represent a context object or better what a context object indeed is. We\u2019ll keep looking in the next articles of this series for more sequentiality, for more semantics and more important for more pragmatics. Maybe Humpty is right after all, we have to put some extra effort to resolve the words that do a lot of work, who knows?", "For all and more, join us at https://chris.com for finest Chris engineering. We build the next generation driver assistant and bring a revolution to Conversational AI. You can also visit me on https://duygua.github.io. Until then stay happy and tuned.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior NLP Engineer from Berlin. Deepgram member, spaCy contributor. Enjoys quality code, in love with grep. Youtube: https://www.youtube.com/c/NLPwithDuygu"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9d121194bd48&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9d121194bd48--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9d121194bd48--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@duygu.altinok12?source=post_page-----9d121194bd48--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@duygu.altinok12?source=post_page-----9d121194bd48--------------------------------", "anchor_text": "Duygu ALTINOK"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d36e9642444&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&user=Duygu+ALTINOK&userId=5d36e9642444&source=post_page-5d36e9642444----9d121194bd48---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d121194bd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d121194bd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://nlp.stanford.edu:8080/parser/", "anchor_text": "Stanford NLP"}, {"url": "https://explosion.ai/demos/displacy", "anchor_text": "SpaCy"}, {"url": "https://chris.com/", "anchor_text": "https://chris.com"}, {"url": "https://duygua.github.io", "anchor_text": "https://duygua.github.io"}, {"url": "https://spacy.io", "anchor_text": "https://spacy.io"}, {"url": "http://nlp.stanford.edu/pubs/StanfordCoreNlp2014.pdf", "anchor_text": "The Stanford CoreNLP Natural Language Processing Toolkit"}, {"url": "https://medium.com/tag/nlp?source=post_page-----9d121194bd48---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/conversational-ai?source=post_page-----9d121194bd48---------------conversational_ai-----------------", "anchor_text": "Conversational AI"}, {"url": "https://medium.com/tag/chatbot-development?source=post_page-----9d121194bd48---------------chatbot_development-----------------", "anchor_text": "Chatbot Development"}, {"url": "https://medium.com/tag/context-theory?source=post_page-----9d121194bd48---------------context_theory-----------------", "anchor_text": "Context Theory"}, {"url": "https://medium.com/tag/pragmatics?source=post_page-----9d121194bd48---------------pragmatics-----------------", "anchor_text": "Pragmatics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9d121194bd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&user=Duygu+ALTINOK&userId=5d36e9642444&source=-----9d121194bd48---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9d121194bd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&user=Duygu+ALTINOK&userId=5d36e9642444&source=-----9d121194bd48---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d121194bd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9d121194bd48--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9d121194bd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9d121194bd48---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9d121194bd48--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9d121194bd48--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9d121194bd48--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9d121194bd48--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9d121194bd48--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9d121194bd48--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9d121194bd48--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9d121194bd48--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@duygu.altinok12?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@duygu.altinok12?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Duygu ALTINOK"}, {"url": "https://medium.com/@duygu.altinok12/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "517 Followers"}, {"url": "https://www.youtube.com/c/NLPwithDuygu", "anchor_text": "https://www.youtube.com/c/NLPwithDuygu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d36e9642444&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&user=Duygu+ALTINOK&userId=5d36e9642444&source=post_page-5d36e9642444--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe03b6df6be6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontext-theory-i-introduction-9d121194bd48&newsletterV3=5d36e9642444&newsletterV3Id=e03b6df6be6a&user=Duygu+ALTINOK&userId=5d36e9642444&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}