{"url": "https://towardsdatascience.com/bayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d", "time": 1683004412.75166, "path": "towardsdatascience.com/bayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d/", "webpage": {"metadata": {"title": "Bayesian Hierarchical Modeling (or \u201cmore reasons why autoML cannot replace Data Scientists yet\u201d) | by Alain Tanguy | Towards Data Science", "h1": "Bayesian Hierarchical Modeling (or \u201cmore reasons why autoML cannot replace Data Scientists yet\u201d)", "description": "In this article, we will use a Probabilistic Programming library developed for python, pymc3. A first introduction to the efficiency of Bayesian approaches in basic statistics and to pymc3 can be\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/from-frequentism-to-bayesianism-hypothesis-testing-a-simple-illustration-11213232e551", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/from-frequentism-to-bayesianism-going-deeper-part-2-offline-a-b-test-d3324f7a39bb", "anchor_text": "there", "paragraph_index": 0}, {"url": "https://docs.pymc.io/notebooks/GLM-hierarchical.html", "anchor_text": "https://docs.pymc.io/notebooks/GLM-hierarchical.html,", "paragraph_index": 37}, {"url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "anchor_text": "Area Under the ROC Curve", "paragraph_index": 39}], "all_paragraphs": ["In this article, we will use a Probabilistic Programming library developed for python, pymc3. A first introduction to the efficiency of Bayesian approaches in basic statistics and to pymc3 can be found here and there.", "Since early 2018, Automated Machine Learning has become one of the trendiest topic in data science. Amazon\u2019s Sagemaker or Google AutoML to mention just a few are now accessible to most Data Scientists, to such an extent that some tend to think exploring and understanding data is not necessary anymore in order to build machine learning models.", "The promise of AutoML can be summed up this way:", "the high degree of automation allows non-experts to make use of machine learning models and techniques without requiring to become an expert in a particular field first.\u00b9", "The reasoning is straightforward ; expertise is no longer required, just give data to the AutoML algorithm, and after testing a fixed number of predefined models, it will return the best one.", "But here\u2019s the catch\u2026 AutoML algorithms ignore what best means to us, and will merely try to minimize an empirical error. Knowledge and expertise are still required to understand what this error really means, and to what extent it differs from the one we are actually hoping to minimize.", "Given n data points, the empirical error is given by", "for a particular function fn over all observable values of features xi and target yi where V denotes a loss function.\u00b2", "It is usually computed through a cross-validation or train/test process. Missing some links between covariates and target will generate a bias often leading to under/over-fitting and eventually to a higher test/cross-validated error.", "It is too often, and wrongly, the only one taken into account by data scientists (and always by autoML engines).", "generalization error(also known as the out-of-sample error) is a measure of how accurately an algorithm is able to predict outcome values for previously unseen data. It is defined by:", "for a particular function fn over all possible values of features x and target y where V denotes a loss function and \u03c1(x, y) is the unknown joint probability distribution for x and y.\u00b3", "Obviously, it is usually the one we would prefer to minimize when training our model. Unfortunately, it cannot be computed directly from data, unlike the empirical one which is merely an estimate of the former.", "With enough good quality data, we interchange those. Now imagine only part of the information is available at training time, or that there just isn\u2019t enough data at all, as it is often the case in Machine Learning. Our model will then be trained on a different distribution \u03c1(x, y) from the one it will be running on later, and as a consequence, the empirical error will diverge from the generalized one.", "Biased data leads to biased empirical error.", "We can already see how much of a problem this is: the empirical error does not estimate the desired quantity anymore, but is the only we can compute from data. We need to make sure it can still be relied on to some extent. This is where human expertise comes into plays and shows its full potential.", "The same way parametric approaches are preferred over non-parametric ones when the relation between variables is clear, knowledge from the field of study compensate the lack of information from the data by explicitly modeling some dependences.", "The better our model can extrapolate from partial or truncated distribution, the closer empirical and generalization error will be.", "All data scientists have heard this sentence at least once, but it turns out only a few truly realize the implication when it comes to actual modeling. The topic of causality is actually just left out most of the time, sometimes wrongly, sometimes justifiably, but rarely knowingly.", "The error yielded by confounders cannot be fully measured by traditional statistical methods since it is not a statistical error per se.", "One could argue that when the empirical error is low, or even the generalization error; then we shouldn\u2019t care if our model exploits true causality or spurious correlations. It might be true in some cases, but unless we explicitly know why, this situation shouldn\u2019t be overlooked.", "Simpson\u2019s paradox, described by Edward Simpson in 1951 and George Udny Yule in 1903, is a paradox in which a statistical trend appears when data are segmented into separate groups but reverses when the groups are combined.", "It is usually observed in the presence of a confounding variable (represented here by the different colour groups) when causal relations are ignored.", "The impact Simpson\u2019s paradox will have in machine learning is when it comes to decision making, where we are given the choice of which data we should consider to pick an action, the aggregated or the partitioned?", "Unfortunately the answer usually cannot be inferred from the data itself. Indeed with exact similar values we can have different answers, depending on the causal relationships among the variables. The real source of error lies outside of the data itself and eventually it doesn\u2019t matter how low the test or cross-validation error is. We are not safe from getting making completely wrong decisions unless we are able to correctly model the environment first.", "We will now through a concrete example show how to handle this situation in the concrete case of hierarchical dependences.", "Often data scientists have to deal with geographic data, which have the disadvantage of not being easily exploitable by classic machine learning models. The location feature usually has a really high cardinality and is often unbalanced. However it is intuitive that parameters from models will vary from region to region, depending on local variables, but will still be closely related since they model the same phenomenon across different places.", "We are going to see a way to handle this spatial dependence and thus to minimize all types of error listed above through the following example.", "We consider the problem of estimating the use of contraceptive in Bangladesh, and to this end we use data come from the 1988 Bangladesh Fertility Survey. It consists of a subsample of 1934 women grouped in 60 districts, with variables are defined as follows:", "and we\u2019ll consider 3 logistic Bayesian regressions with different characteristics to model different possible approaches.", "Here we simply obliviate the role of the DISTRICT variable by not using it. The result is a simple logistic regression with only 4 parameters, including the intercept. The location is not seen as a confounder and each region is assumed to behave similarly.", "For each district we fit a different logistic regression, leading to a total of 60 models with 4 parameters each. Even if we assume behaviour to vary from district to district, we don\u2019t take any advantage of the similarities they could share.", "Bayesian hierarchical modelling is a statistical model written in multiple levels that estimates the parameters of the posterior distribution using the Bayesian method. The sub-models combine to form the hierarchical model, and Bayes\u2019 theorem is used to integrate them with the observed data and account for all the uncertainty that is present.\u2074", "We assume that while \ud835\udefds are different for each district as in the unpooled case, now the coefficients all share similarity. We can model this by assuming that each individual coefficient comes from a common group distribution:", "Though analytically intractable, probabilistic programming allows us to compute the posterior of all our parameters using Markov chain Monte Carlo (MCMC) to sample from the posteriors distributions. Again pymc3 offers an extremely intuitive way to model our network and to compute posteriors!", "We can also easily compute a graphical representation of our Bayesian network:", "First of all, let\u2019s try to understand the differences between our models.", "Inspired by https://docs.pymc.io/notebooks/GLM-hierarchical.html, we can visualize the evolution of our regression parameters over the different regressions.", "We display the coefficients of each district\u2019s non-hierarchical posterior mean, hierarchical posterior mean, and pooled posterior mean. The small amount of data available at district level led unpooled posteriors to be spread far out and thus the shrinkage effect is really important, yet differences among mean in the hierarchical model are still significant, as betas vary in order of magnitude between districts.", "We use the Area Under the ROC Curve (AUC) as our error measure for comparing the models. It can be seen as the probability that our models will score a randomly chosen positive class higher than a randomly chosen negative class. It is particularly interesting to us since it has the advantage of not requiring to set a threshold to assign labels.", "We considered 2 test sets in order to measure performances, a stratified by district one and a non-stratified one. The use of a non-stratified test set is more representative of a case where the generalization error will differ significantly from the empirical model error, since features distributions among districts will vary significantly between train and test sets!", "The measures have been averaged over multiple seeds for the test set sampling in order to be more representative of the real performance.", "The shrinkage effect provided us with an improved statistical power and can also be seen as a smart way to regularize.", "Some districts have extremely few individuals from which to train, and thus the unstratified test error on those gets bigger with the unpooled model. The partial pooling takes into account the similarity between parameters, and provides low density districts with information from others, while keeping their specificities.", "As a result the difference between models is even more significant regarding the unstratified test set, showing us its generalization capacity is greater as performances are almost not affected by the stratification strategy.", "=> Multi-level hierarchical Bayesian models outperform basic approaches when we have multiple sets of measurements we expect to have similarity.", "It would be interesting to compare this Bayesian approach to other classic data preprocessing approaches (different encodings of the district variable) or algorithms (gradient boosting, random forest, etc.).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist working in numerous fields, ranging from marketing to insurance pricing, as well as logistics among other things, for 5 years."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd01e7d571d3d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@alain.tanguy?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alain.tanguy?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "Alain Tanguy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F95f2427cc046&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&user=Alain+Tanguy&userId=95f2427cc046&source=post_page-95f2427cc046----d01e7d571d3d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd01e7d571d3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd01e7d571d3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/frequentist-to-bayesian", "anchor_text": "From Frequentism to Bayesianism"}, {"url": "https://unsplash.com/@alinnnaaaa?utm_source=medium&utm_medium=referral", "anchor_text": "Alina Grubnyak"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/from-frequentism-to-bayesianism-hypothesis-testing-a-simple-illustration-11213232e551", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/from-frequentism-to-bayesianism-going-deeper-part-2-offline-a-b-test-d3324f7a39bb", "anchor_text": "there"}, {"url": "https://commons.wikimedia.org/w/index.php?curid=62007681", "anchor_text": "https://commons.wikimedia.org/w/index.php?curid=62007681"}, {"url": "https://docs.pymc.io/notebooks/GLM-hierarchical.html", "anchor_text": "https://docs.pymc.io/notebooks/GLM-hierarchical.html,"}, {"url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "anchor_text": "Area Under the ROC Curve"}, {"url": "https://en.wikipedia.org/w/index.php?title=Generalization_error&oldid=942140633", "anchor_text": "https://en.wikipedia.org/w/index.php?title=Generalization_error&oldid=942140633"}, {"url": "https://en.wikipedia.org/wiki/International_Standard_Book_Number", "anchor_text": "ISBN"}, {"url": "https://en.wikipedia.org/wiki/Special:BookSources/0-521-77362-8", "anchor_text": "0\u2013521\u201377362\u20138"}, {"url": "https://docs.pymc.io/notebooks/GLM-hierarchical.html", "anchor_text": "https://docs.pymc.io/notebooks/GLM-hierarchical.html"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d01e7d571d3d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/frequentist-to-bayesian?source=post_page-----d01e7d571d3d---------------frequentist_to_bayesian-----------------", "anchor_text": "Frequentist To Bayesian"}, {"url": "https://medium.com/tag/programming?source=post_page-----d01e7d571d3d---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/pymc3?source=post_page-----d01e7d571d3d---------------pymc3-----------------", "anchor_text": "Pymc3"}, {"url": "https://medium.com/tag/bayesian-machine-learning?source=post_page-----d01e7d571d3d---------------bayesian_machine_learning-----------------", "anchor_text": "Bayesian Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd01e7d571d3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&user=Alain+Tanguy&userId=95f2427cc046&source=-----d01e7d571d3d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd01e7d571d3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&user=Alain+Tanguy&userId=95f2427cc046&source=-----d01e7d571d3d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd01e7d571d3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd01e7d571d3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d01e7d571d3d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d01e7d571d3d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alain.tanguy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alain.tanguy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alain Tanguy"}, {"url": "https://medium.com/@alain.tanguy/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "73 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F95f2427cc046&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&user=Alain+Tanguy&userId=95f2427cc046&source=post_page-95f2427cc046--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa8381887a56c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-hierarchical-modeling-or-more-reasons-why-automl-cannot-replace-data-scientists-yet-d01e7d571d3d&newsletterV3=95f2427cc046&newsletterV3Id=a8381887a56c&user=Alain+Tanguy&userId=95f2427cc046&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}