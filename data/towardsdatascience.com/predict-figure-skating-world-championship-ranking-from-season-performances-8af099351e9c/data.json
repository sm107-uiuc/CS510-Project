{"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c", "time": 1683001361.142019, "path": "towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c/", "webpage": {"metadata": {"title": "Predict figure skating world championship ranking from season performances | by Khanh Nguyen | Towards Data Science", "h1": "Predict figure skating world championship ranking from season performances", "description": "Multi-factor models"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient", "anchor_text": "Kendall ranking correlation coefficient", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&sk=7e6b2992c6dd5e6e7e1803c574b4236d", "anchor_text": "first part", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Root-mean-square_deviation", "anchor_text": "root-mean-squared error", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Tikhonov_regularization", "anchor_text": "ridge regression", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Early_stopping", "anchor_text": "early stopping", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Gradient_descent", "anchor_text": "gradient descent", "paragraph_index": 13}, {"url": "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.random_sample.html#numpy.random.RandomState.random_sample", "anchor_text": "random_sample", "paragraph_index": 26}, {"url": "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.html", "anchor_text": "RandomState", "paragraph_index": 26}, {"url": "https://docs.scipy.org/doc/numpy/reference/generated/numpy.nansum.html", "anchor_text": "np.nansum", "paragraph_index": 34}, {"url": "https://docs.scipy.org/doc/numpy/reference/constants.html?highlight=newaxis#numpy.newaxis", "anchor_text": "np.newaxis", "paragraph_index": 51}, {"url": "https://docs.scipy.org/doc/numpy/reference/generated/numpy.nan_to_num.html", "anchor_text": "np.nan_to_num", "paragraph_index": 59}, {"url": "https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit", "anchor_text": "%timeit", "paragraph_index": 62}, {"url": "https://pypi.org/project/memory-profiler/", "anchor_text": "memory_profiler", "paragraph_index": 65}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2?source=friends_link&sk=61ecc86c4340e2e3095720cae80c0e70", "anchor_text": "next part", "paragraph_index": 70}, {"url": "https://sifter.org/~simon/journal/20061211.html", "anchor_text": "FunkSVD", "paragraph_index": 72}], "all_paragraphs": ["In the previous parts of the project, I tried to predict the ranking in the annual world championship of figure skating based on the scores that skaters earned from previous competition events in the season. The main strategy is to separate the skater effect, the intrinsic ability of each skater, from the event effect, the influence of an event on a skater\u2019s performance, so that a more accurate ranking could be built.", "Several models were proposed for this ranking problem, in which the season score of an event-skater pair can be approximated by:", "These latent scores can either be added together (additive model), or multiplied together (multiplicative model), or a combination of the two (hybrid model):", "The predicted rankings from all 3 previous models were compared with the baseline model of simply ranking skaters based on their season averages. The metric used to evaluate these models is the Kendall ranking correlation coefficient \u2014 also called Kendall\u2019s tau \u2014 with respect to the actual world championship ranking: a model is better if its predicted ranking have a Kendall\u2019s tau closer to 1, which means the predicted ranking is more correlated with the actual ranking in the world championship of that year. You can check out the first part of the project for an explanation of how Kendall\u2019s tau works, including how to calculate it for a toy example.", "From the above report on these three models over the 10 years (out of 14) chosen in the training set, all models approximate the season\u2019s scores better than the baseline model of season averages, as evidenced by their lower root-mean-squared error (RMSE) on average compared to the baseline model.", "Yet, in the much more important metric of Kendall\u2019s tau, these models sadly do not provide any significant increase in this metric compared to the baseline model, since the 95%-confidence intervals of difference in Kendall\u2019s tau between them and the baseline encompass zero for both male and female skaters.", "To improve on these models, I tried several strategies to prevent the model from overfitting to the season scores, which can be noisy and might not reflect the true ability of the skater (perhaps they had food poisoning earlier the day of the competition). As a result, this might better capture the true ability of skaters and rank them more accurately for the world championship.", "These strategies include ridge regression and early stopping, two of the most popular strategies to reduce model overfit in machine learning. However, neither strategy managed to improve the Kendall\u2019s tau of the models in any significant amount. Therefore, a new kind of model is needed if we want to better predict how skaters would rank in the world championship.", "To develop this new model, let\u2019s revisit the hybrid model that was developed in the previous part of the project:", "In the above formula, we can see that each event is represented by a single latent score (\u03b8_event), and each skater is also represented by a single latent score (\u03b8_skater).", "However, instead of a single latent score, what if each skater is represented by multiple latent factors? For example, how much he likes skating in the morning, or how conditioned she is for competing in high altitudes. Similarly, each event can be represented the same factors: how early in the morning the event takes place, or at what altitude.", "As a result, each corresponding factor between a skater and an event can multiply together, and the sum of these products are then added to a baseline score to predict the true score of that skater-event pair in the season:", "Similar to the previous models, the latent factors in the multi-factor model can be be found by minimizing the sum of squared difference between the true scores and the predicted scores during the season (which will be called residuals from here on):", "Despite the explosion of latent scores in the multi-factor model \u2014 that double summation at the end looks pretty scary indeed \u2014 let\u2019s keep calm and gradient descent on. First, let\u2019s differentiate the objective function with respect to the latent scores to obtain their gradients.", "Similar to the hybrid model, the gradient of the baseline score is just the sum of residuals for all event-skater pairs in the season:", "Next, let\u2019s figure out the gradient of some factor k of a given event i (\u03b8_ei,k):", "Similarly, the gradient of random factor k of a given skater j is just the skater analogue of the event gradient above:", "The main differences in this formula compared to the previous one are:", "However, note that residual in the outer derivative is still independent of k, and can be reused to find the gradient of all other factors of that skater (aside from k).", "Once the gradients for all factors in each event and each skater have been calculated, we can update the latent scores of those factors as such:", "Given the gradient formulas and the update rules outlined above, gradient descent for the multi-factor model can be summarized as:", "With the above summary, it can be seen that:", "In other words, the gradient descent algorithm for the multi-factor model is virtually the same as that of the single-factor hybrid model, except that once residuals for every event-skater pair are calculated, we need to calculate gradients and update the scores for each latent factor one by one (by reusing the residuals).", "Let\u2019s use the same toy example that we had used for the hybrid model, a season_scores pandas DataFrame with 7 season scores across 4 skaters (MAJOROV, FERNANDEZ, GE, MURA) and 3 events at different countries (CA, FR, RU):", "Similar to the hybrid model, we first convert this data frame from long format to pivot table format, with the skaters as rows, and events as columns and entries are the scores for each event-skater pair. Note that not all skaters participate in all events, so there are missing values in the pivot table, which are represented as NaN (Not a Number).", "Then, we convert the pandas pivot table into a 4\u00d73 numpy matrix true_scores so we can manipulate it more easily. This will in effect remove all row and column names, so let\u2019s store the skater names (rows) and event names (columns) so we can still identify them after running gradient descent.", "For the baseline score, similar to the hybrid model, we can just use the random_sample method of a RandomState object (with a specific seed) to return a random number between 0 and 1.", "For this toy example, let\u2019s assume for each event and each skater, we have 2 latent factors. Therefore, we can initialize all the latent scores for the 4 skaters as a 4\u00d72 matrix. Similarly, we can initialize all the latent scores for the 3 events as a 2\u00d73 matrix.", "The reason for initializing these latent scores in matrix forms is that the predicted score for every event-skater pair can be calculated all at once by multiplying these vectors together (using the matrix multiplication operator @) and add the baseline on top of that:", "To illustrate it more clearly, the diagram below shows the two latent matrices (of sizes 4\u00d72 and 2\u00d73 respectively) multiplied together with the baseline added on top to form a 4\u00d73 matrix of predicted scores for every event-skater pair.", "Highlighted in red is how the predicted score of an event-skater pair (CA-MAJOROV) was computed via this operation. Notice how the multiplication of the two latent score matrices automatically perform the summation over all factors of an event-skater pair, by taking the dot product of the corresponding row of that skater and corresponding column of that event in the respective latent score matrices.", "Once the predicted score for every event-skater pair is calculated, finding the residuals are as simple as subtracting the numpy pivot table of true score from the predicted score matrix:", "Recall that our true_scores numpy matrix contain NaN values for event-skater pairs that do not exist during the season. Therefore, when residuals are calculated, the corresponding residual for those pairs are also NaN.", "In terms of baseline score, nothing has changed from the hybrid model in its gradient, which is just the sum of all residuals, and update the score using this gradient.", "Therefore, to calculate the baseline gradient (baseline_gradient), we use the same np.nansum function to sum over the residuals of existing event-skater pairs in the reason, while ignoring non-existant pairs, which are the NaN\u2019s in the residuals matrix. Finally, the baseline score is updated by subtracting its gradient multiplied with the learning rate alpha.", "Below is the code for the entire step:", "As mentioned earlier in the derivation of gradient descent, once the residuals have been calculated (step 2a), we treat each factor as completely separate from all other factors. Therefore, we can calculate the gradients and update the scores for each latent factor one by one via the loop for k in range(2) (with 2 as the number of factors in our toy example): the first factor will have k=0, while the second k=1.", "Let\u2019s first go through the steps for the first factor (k=0):", "I won\u2019t go into much detail about this step, since it was explained in full in part 2 of the project, including the arguments of np.nansum: axis, which controls the summation direction for the gradient (across skaters or across events), and keepdims, which prevents numpy from collapsing the gradients to 1-D and maintain their row/column vector forms for the later update step. In short, I will just summarize these operations in the diagrams below, first for calculating the gradients (for the first latent factor) in all events:", "Then, for calculating gradients (for the first latent factor) in all skaters:", "Once the latent scores for the first factor are updated, the loop then moves on to the second factor (k=1) and repeats the same thing: calculate the gradients for this factor in all events and skaters (using the same residuals matrix from step 2a), and update the latent scores using these gradients. Below are the extracted single-factor vectors that will be worked on when k=1:", "Finally, the entire step 2 is repeated many times, moving between calculating residuals, finding gradients, and updating latent scores, until the RMSE after each loop \u2014 np.sqrt(np.nanmean(residuals**2))\u2014 has stabilized. After 1000 iterations, the RMSE of the multi-factor model for this toy example is an astonishing 0.004 (compared to 4.30 of the single-factor hybrid model in part 2), with an iteration-to-iteration difference of 1e-5.", "In fact, when multiplying the latent skater and event matrices to get back the final predicted scores during the season, it is not at all a surprise that the RMSE of the model is so low, as the predicted scores (left) are virtually identical to the true scores (right):", "Finally, the latent scores for the 2 factors across all skaters can be retrieved at the end in a pandas DataFrame, with the previously-stored skater names added back in as row index, and the factors (0 and 1) as columns:", "The algorithm works! However, when I applied it to the real data, it took quite a while for it to run, especially when there are many factors involved. Granted, I was also logging a bunch of intermediate values along the way, but let\u2019s see how we can make gradient descent faster so iterating on the model becomes less painful.", "As derived earlier, gradient descent for the multi-factor model is the same as that of the single-factor model but applied to each factor one by one. This is the \u201cnaive\u201d implementation of the algorithm, as we just code the same way the math tells us to do.", "However, instead of processing the factors one by one \u2014 via the costly for loop in step 2c \u2014 we can calculate gradients and update the scores of all latent factors at the same time. This is possible by exploiting yet again numpy\u2019s broadcasting, this time with an extra dimension of factors (instead of just skaters and events). The code for the modified version of step 2c is below:", "What are the weird indexing of the matrices with np.newaxis? Why keepdims=False instead of True in the naive implementation? Read on below to see how they work.", "Recall that we have the initialized latent score matrix for all events and skaters, which are the numpy arrays event_scores of size (2, 3) and skater_scores of size (4, 3) respectively. From step 2a, we also have the residuals matrix (residuals) of size (4, 3), in which each row represents a skater and each column an event. All the matrices are outlined in the diagram below:", "In the latent matrices above, the two factors are stuck together. However, the gradient descent algorithm dictates that they should be treated separately. Therefore, we need to find a way to separate the two factors in each of the latent matrices. Specifically, for events, we need 2 row vectors of size 1\u00d73, and for skaters, we need 2 column vectors of size 4\u00d71, with each vector representing one factor.", "Here are how these latent matrices are reshaped:", "Recall the latent matrix for events (event_scores) is a 2-D numpy array of size (2, 3). Therefore, event_scores[:, np.newaxis, :] will still reserve the original dimensions \u2014 via : \u2014 while adding a new axis in between the original axes \u2014 via np.newaxis. This results in a 3-D array of size (2, 1, 3). You can think of this as 2 different layers of (1, 3) array, each layer representing a single factor across all events (highlighted in red below):", "We can do the same for the latent matrix of skater, which is originally a 2-D numpy array of size (4, 2). However, we want to make this into 2 different layers of (4, 1) array, each layer representing a single factor across all skaters. To do this, we use skater_scores.T[:, :, np.newaxis]: since skater_scores.T is of size (2, 4), the 3-D array after the new axis is added at the end will have size (2, 4, 1). The two layers of latent skater scores are represented below (in red):", "Finally, the residuals matrix, originally a 2-D array of size (4, 3), are reshaped as residuals[np.newaxis, :, :], which is a 3-D array of size (1, 4, 3) due to the new axis added in front. You can think of the residuals matrix as essentially the same as before, but now existing in one flat layer in 3-D.", "Once we know how to reshape the various matrices, we can start calculating gradients not only across all events and skaters, but also for all factors at once.", "Once the gradients across are calculated at once for all factors, these 2-D gradient arrays are subtracted from the event and skater latent score matrices of the same shape with a learning rate alpha.", "The optimized gradient descent algorithm \u2014 using numpy\u2019s broadcasting to calculate gradient and update latent scores for all factors at once \u2014 is presented in its entirety below (for 4 skaters, 3 events, and 2 latent factors):", "The above implementation using numpy broadcasting works. However, it looks quite clunky, especially with keeping up with all the 3-D matrices when calculating the gradients.", "Here\u2019s a much simpler way to calculate the same gradients for both factors at the same time, but only by multiplying 2-D matrices:", "However, note that for this to work, numpy\u2019s matrix multiplication operation needs to ignore the NaN values in the residual matrix. This is sadly not the case \u2014 there\u2019s no such thing as np.nanmatmul. Nevertheless, we can always replace the NaN values with zeros using np.nan_to_num, then continue with the matrix multiplication as usual:", "Once the gradients are calculated, they are used to update the respective latent score matrices respectively.", "Let\u2019s see if these optimized versions of the gradient descent algorithm beats the factor-by-factor naive implementation using for loop.", "Using the %timeit magic function of Jupyter notebooks, I measure the time it takes for each implementation to run one iteration of gradient descent on this toy example (4 skaters, 3 events). I also vary the number of factors and measure the corresponding time for both implementations to see how time-efficient they are when the number of factors increases.", "The result can be seen in the accompanying graph:", "However, one potential disadvantage of these optimized methods is the increased space complexity: for example, from broadcasting to larger 3-D matrices. We can verify this by plotting the amount of memory consumed when running each implementation one after another. We still use the toy example of 4 skaters and 3 events, but the number of factors are bumped up to a worse-case scenario of 100,000 factors.", "From the above graph of memory used over time (using the memory_profiler package) \u2014 we can see that:", "In short, the implementation of gradient descent using matrix multiplication offers significant improvement in readability, speed and/or memory usage compared to the other two methods. As a result, it is ultimately chosen to find the latent scores for the multi-factor model.", "When we apply the gradient descent algorithm chosen above to the familiar example of male skaters in the 2017 season, we can again track the residuals and RMSE of the model across iterations of the algorithm. They are displayed in the animated dashboard below for the first 150 iterations of gradient descent:", "Despite the multi-factor models approximating the season scores very well, it has a major weakness: instead of a single score that can be used to rank the skaters (from highest to lowest), each skater now has multiple latent scores, one for each factor. This begs the question: by which score are we supposed to rank the skaters?", "With 5 latent factors, when we rank the skaters using the scores of each factor separately, we see that:", "Therefore, none of the factors \u2014 used separately \u2014 can decently rank the skaters the world championship! Instead, we must find a way to combine the latent scores across different factors to rank skaters more accurately. In the next part of the project, I will discuss how we can do so.", "In the multi-factor model, the latent scores of skater are stored in the matrix skater_scores of size number of skaters \u00d7 number of factors, while the latent scores of events are stored in the matrix event_skaters of size number of factors \u00d7 number of events. As a result, the multi-factor model can be seen as factorizing the season score matrix of size number of skaters \u00d7 number of events into these 2 latent matrices, such that their product on top of the baseline score \u2014 skater_scores @ event_scores + baseline\u2014 approximates well the original matrix of season scores.", "In fact, the gradient descent algorithm used in this part of the project is almost identical to that of the famous FunkSVD matrix factorization used in the Netflix challenge to recommend movies to users: by factorizing the rating matrix into user-specific and movie-specific latent matrices, we can use the product of these latent scores to predict the ranking on movies a user has not seen yet. The multi-factor model, then, is essentially FunkSVD with user=skater, movie=event, and rating=season score.", "However, the main differences between the two cases are:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8af099351e9c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8af099351e9c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8af099351e9c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://seismatica.medium.com/?source=post_page-----8af099351e9c--------------------------------", "anchor_text": ""}, {"url": "https://seismatica.medium.com/?source=post_page-----8af099351e9c--------------------------------", "anchor_text": "Khanh Nguyen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb9e5af5001b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&user=Khanh+Nguyen&userId=bb9e5af5001b&source=post_page-bb9e5af5001b----8af099351e9c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8af099351e9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8af099351e9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/dknguyengit/skate_predict", "anchor_text": "repo"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&sk=7e6b2992c6dd5e6e7e1803c574b4236d", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-world-championship-ranking-from-season-performances-part-2-hybrid-7d296747b15?source=friends_link&sk=86881d127654ece260be2e3029dfbad2", "anchor_text": "part 2"}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2?source=friends_link&sk=61ecc86c4340e2e3095720cae80c0e70", "anchor_text": "part 4"}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-7461dc5c0722?source=friends_link&sk=fcf7e410d33925363d0bbbcf59130ade", "anchor_text": "part 5"}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-d97bfbd37807", "anchor_text": "part 6"}, {"url": "https://en.wikipedia.org/wiki/Linear_least_squares#Derivation_of_the_normal_equations", "anchor_text": "normal equation"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-world-championship-ranking-from-season-performances-part-2-hybrid-7d296747b15?source=friends_link&sk=86881d127654ece260be2e3029dfbad2", "anchor_text": "second part"}, {"url": "https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient", "anchor_text": "Kendall ranking correlation coefficient"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&sk=7e6b2992c6dd5e6e7e1803c574b4236d", "anchor_text": "first part"}, {"url": "https://en.wikipedia.org/wiki/Root-mean-square_deviation", "anchor_text": "root-mean-squared error"}, {"url": "https://en.wikipedia.org/wiki/Tikhonov_regularization", "anchor_text": "ridge regression"}, {"url": "https://en.wikipedia.org/wiki/Early_stopping", "anchor_text": "early stopping"}, {"url": "https://en.wikipedia.org/wiki/Gradient_descent", "anchor_text": "gradient descent"}, {"url": "https://en.wikipedia.org/wiki/Chain_rule", "anchor_text": "chain rule"}, {"url": "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.random_sample.html#numpy.random.RandomState.random_sample", "anchor_text": "random_sample"}, {"url": "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.html", "anchor_text": "RandomState"}, {"url": "https://docs.scipy.org/doc/numpy/reference/generated/numpy.nansum.html", "anchor_text": "np.nansum"}, {"url": "https://docs.scipy.org/doc/numpy/reference/constants.html?highlight=newaxis#numpy.newaxis", "anchor_text": "np.newaxis"}, {"url": "https://docs.scipy.org/doc/numpy/reference/generated/numpy.nan_to_num.html", "anchor_text": "np.nan_to_num"}, {"url": "https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit", "anchor_text": "%timeit"}, {"url": "https://pypi.org/project/memory-profiler/", "anchor_text": "memory_profiler"}, {"url": "https://en.wikipedia.org/wiki/Mebibyte", "anchor_text": "MiB"}, {"url": "https://raw.githubusercontent.com/dknguyengit/skate_predict/master/viz/batch_anim_cropped.gif", "anchor_text": "that"}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2?source=friends_link&sk=61ecc86c4340e2e3095720cae80c0e70", "anchor_text": "next part"}, {"url": "https://sifter.org/~simon/journal/20061211.html", "anchor_text": "FunkSVD"}, {"url": "https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf", "anchor_text": "article"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8af099351e9c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/sports-analytics?source=post_page-----8af099351e9c---------------sports_analytics-----------------", "anchor_text": "Sports Analytics"}, {"url": "https://medium.com/tag/figure-skating?source=post_page-----8af099351e9c---------------figure_skating-----------------", "anchor_text": "Figure Skating"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----8af099351e9c---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8af099351e9c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8af099351e9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&user=Khanh+Nguyen&userId=bb9e5af5001b&source=-----8af099351e9c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8af099351e9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&user=Khanh+Nguyen&userId=bb9e5af5001b&source=-----8af099351e9c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8af099351e9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8af099351e9c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8af099351e9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8af099351e9c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8af099351e9c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8af099351e9c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8af099351e9c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8af099351e9c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8af099351e9c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8af099351e9c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8af099351e9c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8af099351e9c--------------------------------", "anchor_text": ""}, {"url": "https://seismatica.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://seismatica.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Khanh Nguyen"}, {"url": "https://seismatica.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "231 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb9e5af5001b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&user=Khanh+Nguyen&userId=bb9e5af5001b&source=post_page-bb9e5af5001b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F23c332b6074c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c&newsletterV3=bb9e5af5001b&newsletterV3Id=23c332b6074c&user=Khanh+Nguyen&userId=bb9e5af5001b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}