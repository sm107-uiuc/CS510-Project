{"url": "https://towardsdatascience.com/decision-trees-ac091793070", "time": 1683017949.965539, "path": "towardsdatascience.com/decision-trees-ac091793070/", "webpage": {"metadata": {"title": "The Non-Technical Guide to Decision Trees | by Adam Shafi | Towards Data Science", "h1": "The Non-Technical Guide to Decision Trees", "description": "Simple explanation of the Decision Tree Machine Learning algorithm, aimed at a non-technical audience."}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/adamshafi", "anchor_text": "https://www.linkedin.com/in/adamshafi", "paragraph_index": 43}], "all_paragraphs": ["Tree-based models are some of the most widely used models today; they are very powerful, easy to implement and provide feature importances to help with interpretability. One of the most widely used tree-based models is the Random Forest, which is based on Decision Trees.", "In order to understand Random Forest, it is essential to know what the underlying model, the Decision Tree is doing.", "Despite its ease of use, it can be a tricky algorithm to explain to a non-technical audience. This guide explains the Decision Tree using a simple example. Some maths is included here, but you might want to omit this depending on your audience.", "Decision Trees can be used for both Classification and Regression. We\u2019ll focus on Classification here.", "For explaining everything here on out, we are going to use a hypothetical dataset about apples, pears and grapes. I like using this example in explanations because it\u2019s very visual, but the features you can pull from these are very variable.", "Here\u2019s what data we might find in our example dataset\u2026", "The decision tree is a concept most people should be aware of, as it crops up in many other fields. Let\u2019s dig in.", "Imagine you are trying to separate the above data. You don\u2019t know what fruit it is but you have the rest of the attributes. What feature would you use first to create the most separation?", "I\u2019m going to start with size. The blue box in the diagram below represents our Root Node this is the first decision we make. The yellow circles are the options and the green boxes are leaves.", "Here, we\u2019ve arbitrarily chosen size and 4cm. There is actually some simple maths we can use to decide both of these, which we\u2019ll get onto later.", "As expected, choosing a size threshold of 4cm fully separates the grapes from the apples and pears. The grapes leaf can be described as pure because it only contains grapes.", "In our dataset, only apples have the colour red. Let\u2019s use this as our next decision boundary.", "This creates another pure leaf on the yes side, but on the other side, there is still a mix of apples and pears that we need to classify.", "Finally, let\u2019s use the shape. In our dataset, this is binary; round or tapered.", "And that\u2019s it! We have 2 pure leaves and fully separated apples and pears.", "We now have a full tree that could be used on unseen data to classify the fruit.", "The full tree is below, grab a piece of fruit and a ruler and give it a try!", "We can also visualise the decision boundaries. The below chart shows a theoretical sphericity measure where the boundary between round and round taper is around 0.7. Colour would be the third dimension in this chart.", "We can easily visualise 2D decision boundaries, as you can see with the vertical diameter and horizontal sphericity boundaries. These plots are a very useful way to visualise how the data is being split.", "There are a few questions still outstanding here that we\u2019ll tackle in the next few chapters. These are:", "If a leaf is not pure (it contains a mixture of classes), we can measure its impurity by looking at the proportions of each class inside the leaf. The two most common ways to calculate purity are using either the Gini or Entropy score.", "Our algorithm aims to minimise impurity at each decision boundary using these scores, which means at each decision boundary, it calculates the Gini scores and selects the feature that will produce the best scores.", "The Gini formula is as follows:", "This is simply 1 minus the sum of probabilities for each class, squared.", "The sum of probabilities is just the occurrence of each class divided by the total. I have calculated the Gini impurity for each leaf below, if we\u2019d used our original decisions as the root node.", "To get the Gini score at each root, we just take the weighted average of the leaves. This prevents the difference in sample sizes from causing an issue.", "In the example above, for size, we would do the following:", "Summing these gives a Gini score of 0.33", "We can repeat this for every node, with the minimum Gini score being the node we use. Please note Shape and Size do give the same result here.", "Entopy is used less often than Gini. It uses a log formula which can give different results in some cases.", "The impurity score is calculated only at the current node (ie for just one feature). It is not calculated for what the full tree will be if each feature is used first. This is known as a greedy algorithm.", "Now we know how the decision is made for which feature to use at each node, but how do we decide what to use for continuous variables, or those with multiple categories?", "These are actually very simple. With continuous variables, the list is sorted and the Gini score is calculated at the midpoint of each value. Here\u2019s an example for each value, we would test 1.1, 1.5 and so on and take the boundary that produces the best Gini score.", "Multi-Category variables (eg Red, Purple, Green) are also straightforward. We just test each category and pick the one the produces the best Gini score!", "By default, decision trees will continue to split data until all leaves are pure. This means trees can get very deep if our data is difficult to separate for example, if we had a particularly round pear, or a very small apple.", "There is a ways to prevent this, in Scikit Learn we can limit the depth or number of leaves in the tree to prevent it getting too deep. If this happens, we might end up with leaves that aren\u2019t 100% pure.", "In the case of impure leaves, the model will predict the majority class, but the probability will not be 100%.", "For example, if we had a leaf with 3 apples and 1 pear and we tested on a new observation, if the criteria for that leaf was met, the model would predict an apple with 75% probability.", "Nowadays, models are becoming more advanced and complex so it\u2019s more likely that you will want to use one of many powerful tree based models such as Random Forest, XGBoost or LightGBM. However, these models rely on concepts such as bagging or boosting applied to many Decision Trees. Understanding the Decision Tree provides a framework for understanding these powerful, widely used models and will enhance your ability to explain and interpret them.", "The biggest issue with the decision tree is tree depth. As mentioned above, the tree will continue to grow until it achieves purity. Having very specific decision boundaries leads to overfitting. This is when our model has learnt the train data almost perfectly and doesn\u2019t perform well on data it hasn\u2019t seen before.", "\u2018Pruning\u2019 the tree by reducing the leaves does reduce overfitting, but can also limit our model\u2019s predictive power. So how can we improve on Decision Trees?", "This is where the Random Forest model comes in. Read about it here:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Get in touch: https://www.linkedin.com/in/adamshafi"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fac091793070&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac091793070--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac091793070--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://adam-shafi.medium.com/?source=post_page-----ac091793070--------------------------------", "anchor_text": ""}, {"url": "https://adam-shafi.medium.com/?source=post_page-----ac091793070--------------------------------", "anchor_text": "Adam Shafi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F159c0484eaef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&user=Adam+Shafi&userId=159c0484eaef&source=post_page-159c0484eaef----ac091793070---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac091793070&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac091793070&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@michaelbenz?utm_source=medium&utm_medium=referral", "anchor_text": "Michael Benz"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@nordwood?utm_source=medium&utm_medium=referral", "anchor_text": "NordWood Themes"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@gillystewart?utm_source=medium&utm_medium=referral", "anchor_text": "Gilly Stewart"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@toddquackenbush?utm_source=medium&utm_medium=referral", "anchor_text": "Todd Quackenbush"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/random-forest-29cf337c68d4", "anchor_text": "Random Forest for a non-Technical AudienceOne of the most widely used algorithms today is actually quite tricky to explain\u2026towardsdatascience.com"}, {"url": "https://www.linkedin.com/in/adamshafi/", "anchor_text": "Adam Shafi - Data Science Immersive - General Assembly | LinkedInData Scientist with over 4 years experience in Analytics including managing teams, delivering projects, and turning\u2026www.linkedin.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ac091793070---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/random-forest?source=post_page-----ac091793070---------------random_forest-----------------", "anchor_text": "Random Forest"}, {"url": "https://medium.com/tag/decision-tree?source=post_page-----ac091793070---------------decision_tree-----------------", "anchor_text": "Decision Tree"}, {"url": "https://medium.com/tag/algorithm?source=post_page-----ac091793070---------------algorithm-----------------", "anchor_text": "Algorithm"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ac091793070---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac091793070&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&user=Adam+Shafi&userId=159c0484eaef&source=-----ac091793070---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac091793070&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&user=Adam+Shafi&userId=159c0484eaef&source=-----ac091793070---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac091793070&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac091793070--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fac091793070&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ac091793070---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac091793070--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ac091793070--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ac091793070--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ac091793070--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ac091793070--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ac091793070--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ac091793070--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ac091793070--------------------------------", "anchor_text": ""}, {"url": "https://adam-shafi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://adam-shafi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Adam Shafi"}, {"url": "https://adam-shafi.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "482 Followers"}, {"url": "https://www.linkedin.com/in/adamshafi", "anchor_text": "https://www.linkedin.com/in/adamshafi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F159c0484eaef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&user=Adam+Shafi&userId=159c0484eaef&source=post_page-159c0484eaef--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F34fb74c5b03b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-trees-ac091793070&newsletterV3=159c0484eaef&newsletterV3Id=34fb74c5b03b&user=Adam+Shafi&userId=159c0484eaef&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}