{"url": "https://towardsdatascience.com/machine-learning-foundations-features-and-similarity-a6ef2901f09f", "time": 1683004620.408986, "path": "towardsdatascience.com/machine-learning-foundations-features-and-similarity-a6ef2901f09f/", "webpage": {"metadata": {"title": "Machine Learning Foundations: Features and Similarity | by Jamie Bullock | Towards Data Science", "h1": "Machine Learning Foundations: Features and Similarity", "description": "The world of machine learning is full of references to \u201cfeature vectors\u201d, \u201cdimensionality\u201d, \u201cspace\u201d and \u201cdistance\u201d. All of this can be overwhelming unless you already have a strong maths background\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/RGB_color_model", "anchor_text": "RGB", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Pulse-code_modulation", "anchor_text": "PCM", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Feature_extraction", "anchor_text": "feature extraction", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)", "anchor_text": "standardisation", "paragraph_index": 28}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html", "anchor_text": "built-in function", "paragraph_index": 28}, {"url": "https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)", "anchor_text": "min-max scaling", "paragraph_index": 32}, {"url": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm", "anchor_text": "k-NN classification", "paragraph_index": 43}, {"url": "https://www.kaggle.com/datasets", "anchor_text": "real-world datasets", "paragraph_index": 48}], "all_paragraphs": ["The world of machine learning is full of references to \u201cfeature vectors\u201d, \u201cdimensionality\u201d, \u201cspace\u201d and \u201cdistance\u201d. All of this can be overwhelming unless you already have a strong maths background. In this post, I\u2019m going to explain some of these basics.", "In order for a program to perform machine learning tasks, we need a way to represent objects numerically. For example, if we want our software to recognise sounds, we need a way to represent sounds using numbers. The same is true for recognising images or text.", "The numbers we use to represent aspects of objects in machine learning are called features.", "In computing, we already have standard numerical representations of objects. For example, images consist of RGB values that describe the colour of each pixel to be drawn on the screen. Sounds consist of PCM audio samples that describe the loudness of the audio signal over time.", "Whilst we could use these numeric representations for training machine learning systems, it is usually not desirable to do this. The reasons are:", "To deal with this we employ a process of transforming these fine-grained values into a smaller number of more descriptive features. This process is known as feature extraction. Features can be thought of as existing in a hierarchy from low-level features that are closer to a machine representation (less abstract) to high-level features that are closer to human perception (more abstract).", "Common features used to represent a sound might be: pitch, loudness, brightness and noisiness. Higher level features might be tempo, key, and mood. Features used to represent text might be \u201cword presence\u201d, \u201cword count\u201d, and \u201cword frequency\u201d.", "In traditional machine learning the features used to describe an object are usually arrived at through a combination of prior knowledge, intuition, testing and automated feature selection. This process is called feature engineering. In more recent deep learning techniques, feature extraction itself can be an automatic part of the machine learning process.", "The process of determining which features best describe an object with least overlap between features is called feature selection", "We now know that a feature is a value that represents some aspect of an object. In order to make comparisons between the features of different objects it is convenient to think about them spatially. We can think of each feature label as a dimension and each feature value as a position within that dimension. The combination of all the dimensions we use to describe an object is called a feature space.", "This can all seem confusing at first! This is because we tend to think of a \u201cspace\u201d as a physical thing with 3 dimensions measured in metres or feet. However, all the same geometry that can be applied to a 3D physical space can also be applied to a mathematical space with any number of dimensions, and where each dimension represents any numeric range.", "Let\u2019s think about a practical example\u2026", "Say we have one feature describing a sound\u2026 \u201caverage loudness\u201d, and its value is -6 decibels. This gives us one dimension, and one feature value (-6). We can represent this feature spatially on a line:", "Now, let\u2019s add two more features, \u201caverage frequency\u201d (in Hertz) and duration (in seconds). This gives our feature space three dimensions in total. We can now represent our sound as point in that 3D space:", "But it doesn\u2019t stop there! Unlike a physical space, a feature space can have any number of dimensions. So if we added \u201caverage brightness\u201d, \u201caverage noisiness\u201d and \u201cattack time\u201d, this would give six dimensions in total.", "A group of features that describe an object is referred to as a feature vector. This can seem a confusing concept at first. We know from school maths that a vector is something with direction and magnitude. Typical examples of vectors are \u201cdisplacement\u201d, and \u201cvelocity\u201d. We may be familiar with diagrams like this:", "This shows the vector a (red line) as a displacement from point A to point B in two dimensions. The magnitude or norm of the vector can be computed using the following equation:", "\u2016a\u2016 is the mathematical symbol for the magnitude of a, and the formula above is called the Euclidean Norm or L2-Norm. Plugging in the values for our points we get:", "So the magnitude of our vector a, is 9.2, but how does this relate to our feature vectors for machine learning? Our sound (A) in figure 3 is just a \u201cpoint\u201d in 3D space, right, not a \u201cvector\u201d?", "Well, we can actually treat our sound from figure 3 as a vector by relating its position to the origin (co-ordinate x=0, y=0, z= 0). A vector extending from the origin to a given point is called a position vector. When people talk about \u201cvectors\u201d in machine learning, they usually mean position vectors.", "Redrawing figure 3 to show our position vector for sound A, we get the following, where the red arrow is the vector:", "In order to compute the length of our feature vector, we can again use the L2-norm. So:", "You can see that with a position vector the origin is always zero, so the terms for the origin can be omitted. So our generalised formula for the L2-norm for feature \u201cpoint\u201d vectors becomes:", "Where x\u2081 is the first element in our feature vector and x\u1d62 is the ith element. Plugging in our values for Sound A, this becomes", "So the length of our three dimensional feature vector for Sound A is 440.05.", "You will notice that the feature space for Sound A shown so far has not been drawn to scale. If it had, it would look more like this:", "As a consequence, the magnitude or length of our feature vector is dominated by a single feature: frequency (Hz). Hence our magnitude is 440.05, very close to our frequency value. We could actually double the duration of the sound to 6.8 seconds, and it would only increase the length of our feature vector by 0.04. This is a Bad Thing!", "This kind of variability in data ranges will cause a problem for many machine learning algorithms because some features will be treated as more significant than others. It is therefore usual to apply feature scaling prior to submitting feature vectors to a machine learning system. This ensures that the structure of the input data is not \u201cbiased\u201d towards certain features with large ranges.", "A widely used method for scaling is standardisation (or Z-score normalisation). Most machine learning libraries have a built-in function for standardisation, but in pure python, for example, it may look as follows:", "So, say we have 5 sounds with the following feature vectors for each sound:", "If we standardise these values, this gives the following:", "Notice that the ranges for each feature are now greatly reduced and roughly comparable to each other. This makes the data far more suitable for machine learning applications and in our case, removes the bias towards the \u201caverage frequency\u201d feature.", "Note that if data is required to be a specific range (e.g. 0..1) then min-max scaling should instead be used.", "One of the most pervasive tools in machine learning is the ability to measure the \u201cdistance\u201d between two objects. This enables us to gauge how similar the objects are. Distance could be thought of as the inverse of similarity, as the distance between objects increases, similarity decreases.", "Similarity is used in recommender systems, classifiers, clustering algorithms, and other machine learning techniques. A solid understanding of similarity and distance measures is fundamental to properly understanding machine learning.", "We now know that we can treat a collection of features as a vector in n-dimensional space. We also know that we can normalise our features to facilitate meaningful comparisons between feature values within that space. Measuring the distance between different feature vectors takes this a step further.", "Let\u2019s add the normalised feature vectors for two of the sounds (A and D) to our 3D graph.", "We can see that each sound\u2019s normalised features are plotted as a point within the 3D space.", "In order to measure how similar the sounds are, we need to calculate the length of the vector that connects the two points (Sound A, Sound B). This is shown below.", "We know from earlier that to calculate the length of a vector we can use the L2-norm. So in order to compute the distance between Sound A and Sound D, we need to calculate the L2-norm of the vector AD. Revisiting our L2-norm formula from above, this gives us:", "Where x, y, and z are the dimensions of the graph and x\u2082 and x\u2081 are the x co-ordinates of Sound D and Sound A respectively.", "Plugging in our normalised coordinates for the two sounds gives:", "Now we have a set of normalised feature vectors representing 5 objects (in our case sounds) and a method for calculating the distance between two objects. This enables us to group our objects by similarity to a source object! So, given the table above, we can calculate the similarity of every other sound, to sound A and then sort by similarity. This gives:", "This gives the foundation for a range of techniques such as clustering and k-NN classification, which the reader is encouraged to explore further.", "In this example, we\u2019ve used only three features for ease of visualisation. However, a typical application will involve many more features, typically between 20 and several hundred. In this case, our l2-norm between two (non-origin) points (or Euclidean distance) can be generalised to:", "Where q\u1d62 is the value for ith dimension of point q and p\u1d62 is the value for the ith dimension of point p.", "There are a number of other ways to calculate the similarity between two feature vectors, such as cosine similarity, which measures the difference in orientation rather than distance. These will be covered in a future post.", "In this article, I have introduced the concepts of features, feature vectors, feature normalisation and measuring the distance between feature vectors. This has been done through a worked example using the nominal features of a sound (loudness, frequency, duration). An important point to bear in mind is that these \u201csound features\u201d were for illustration purposes only. In a real-world scenario, these may not be useful features, depending on what exactly is being compared or measured.", "Feature selection is part of the \u201cart\u201d of machine learning and data science. As a next step, the reader is encouraged to explore a range of real-world datasets and experiment with applying the concepts from this post to explore the data.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa6ef2901f09f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jamiebullock.medium.com/?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": ""}, {"url": "https://jamiebullock.medium.com/?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "Jamie Bullock"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa87a918b1d95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&user=Jamie+Bullock&userId=a87a918b1d95&source=post_page-a87a918b1d95----a6ef2901f09f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa6ef2901f09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa6ef2901f09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@wimvanteinde?utm_source=medium&utm_medium=referral", "anchor_text": "Wim van 't Einde"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/RGB_color_model", "anchor_text": "RGB"}, {"url": "https://en.wikipedia.org/wiki/Pulse-code_modulation", "anchor_text": "PCM"}, {"url": "https://en.wikipedia.org/wiki/Feature_extraction", "anchor_text": "feature extraction"}, {"url": "https://developers.google.com/machine-learning/crash-course/representation/feature-engineering", "anchor_text": "Google Developers"}, {"url": "https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)", "anchor_text": "standardisation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html", "anchor_text": "built-in function"}, {"url": "https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)", "anchor_text": "min-max scaling"}, {"url": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm", "anchor_text": "k-NN classification"}, {"url": "https://www.kaggle.com/datasets", "anchor_text": "real-world datasets"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a6ef2901f09f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a6ef2901f09f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/feature-engineering?source=post_page-----a6ef2901f09f---------------feature_engineering-----------------", "anchor_text": "Feature Engineering"}, {"url": "https://medium.com/tag/tutorial?source=post_page-----a6ef2901f09f---------------tutorial-----------------", "anchor_text": "Tutorial"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----a6ef2901f09f---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa6ef2901f09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&user=Jamie+Bullock&userId=a87a918b1d95&source=-----a6ef2901f09f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa6ef2901f09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&user=Jamie+Bullock&userId=a87a918b1d95&source=-----a6ef2901f09f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa6ef2901f09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa6ef2901f09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a6ef2901f09f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a6ef2901f09f--------------------------------", "anchor_text": ""}, {"url": "https://jamiebullock.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jamiebullock.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jamie Bullock"}, {"url": "https://jamiebullock.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "5.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa87a918b1d95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&user=Jamie+Bullock&userId=a87a918b1d95&source=post_page-a87a918b1d95--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F43a533362e33&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-foundations-features-and-similarity-a6ef2901f09f&newsletterV3=a87a918b1d95&newsletterV3Id=43a533362e33&user=Jamie+Bullock&userId=a87a918b1d95&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}