{"url": "https://towardsdatascience.com/optimizing-neural-networks-where-to-start-5a2ed38c8345", "time": 1682994598.2138612, "path": "towardsdatascience.com/optimizing-neural-networks-where-to-start-5a2ed38c8345/", "webpage": {"metadata": {"title": "Optimizing Neural Networks \u2014 Where to Start? | by George Liu | Towards Data Science", "h1": "Optimizing Neural Networks \u2014 Where to Start?", "description": "In this project, I use Keras to build a generic neural network class which can be used to test model performance. Various parameters\u2019 importance is tested, visualized and analyzed."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/getting-started-with-tensorflow-in-google-colaboratory-9a97458e1014", "anchor_text": "Google Colab", "paragraph_index": 3}, {"url": "https://github.com/georgeliu1998/keras_model_tuning", "anchor_text": "my project repo", "paragraph_index": 35}, {"url": "http://linkedin.com/in/georgeliu2", "anchor_text": "linkedin.com/in/georgeliu2", "paragraph_index": 38}], "all_paragraphs": ["There are so many parameters and hyperparameters (all referred to as parameters hereon) to tune with a neural network, so where to start?", "In Professor Andrew Ng\u2019s Deep Learning Specialization courses, he gives the following guideline:", "These are great tips. But, to make them part of our skills, we need intuition :) To achieve that, I built a customizable neural network class in Python and conducted a series of experiments to verify the ideas. Let\u2019s see!", "We\u2019ll use Google Colab for this project, so most of the libraries are already installed. Since we\u2019ll train neural networks, it\u2019s important to use GPU to speed up training.", "To enable GPU, just go to \u201cRuntime\u201d in the dropdown menu and select \u201cChange runtime type\u201d. You can then verify by hovering mouse over \u201cCONNECTED\u201d in the top right corner:", "In this project, we\u2019ll use the Pima Indians Diabetes Dataset, for these reasons:", "Although we can download the dataset manually, for reproducibility, let\u2019s download it from Kaggle. Since we need to do it using Kaggle\u2019s API, we\u2019ll first create the API token by visiting the \u201cMy Account\u201d page on Kaggle. This will download a kaggle.json file to your computer.", "Next, we need to upload this credential file to Colab:", "Then we can install Kaggle API and save the credential file in the \u201c.kaggle\u201d directory.", "Now we can download the dataset:", "This dataset will be downloaded to your current working directory which is the \u201ccontent\u201d folder in Colab. As files get deleted every time you restart your Colab session, it\u2019s a good idea to save files in your Google Drive. You just need to mount the drive using below code and save there:", "Once it\u2019s mounted, you\u2019ll be able to load data directly from Google Drive with the \u201c/content/gdrive\u201d path. Mounting your Google Drive will also come in handy later when you need to save plot files.", "XGBoost is known as the go-to algorithm thanks to its high accuracy and efficiency. Let\u2019s give it a try!", "Then we got 74.88% accuracy and it took only 0.35 seconds! If we standardize the features and test again, we\u2019ll get a result of 76.31%! This result is already very close to the state-of-the-art accuracy on this dataset.", "To be able to test different models, we need the capability of creating models on the fly. Meanwhile, we also need to test the model and provide results. Both needs point me to object-oriented programming. I then create the following class for testing. I\u2019ll explain the technical details of this and the following section in a separate post.", "Since we need to test many different combinations of parameters and need to save the results, it\u2019s important to automate the test process. Again, let me show and not tell since details will be explained in a later post:", "Let\u2019s start with a baseline model with the following default parameters:", "It\u2019s not bad, but definitely far from the top result of 77.7%.", "To understand different parameters\u2019 impacts on model tuning, let\u2019s adjust one parameter at a time while keeping other parameters constant (thus different from an exhaustive search such as GridSearchCV in sklearn). Running the tests will provide us with the following results:", "First, it\u2019s interesting to note that some parameters not mentioned in the above parameter tuning guideline, can be important factors, e.g. optimizer and epochs.", "Second, learning rate is indeed among the most impactful parameters.", "Third, for this specific experiment (including parameter choices), it seems that number of layers is more important than number of hidden units. This is contrary to the above guideline.", "Below is the tuning trend which can be used to find the ranges to tune in.", "It\u2019s important to note that the test here is only meant to provide some intuition and shouldn't be taken as formal rules. This is due to at least two reasons \u2014 one, the various parameters and their candidate values are not necessarily comparable; two, there\u2019s innate randomness in neural networks, as such, results such as the above plots could change.", "Although it\u2019s highly likely that the interaction between parameter values does matter, i.e. 40 epochs may yield a worse accuracy when paired with a learning rate other than 0.001 (e.g. 0.1), we\u2019ll nevertheless try out a naive approach here \u2014 combine the independently tuned best parameter values and train a model, which gives us:", "Wow, that\u2019s a brutal 50 minutes! Although we cannot complain about the result since it\u2019s state of the art! It seems the naive approach does work.", "Now that we see the relative importance of the parameters, it\u2019s time to tune the model. As learning rate is the most important one, let\u2019s tackle it first. We\u2019ll use the following code to generate 6 random learning rate values between 0.0001 and 0.01 since this is the most promising area based on the above tuning trend visualization.", "After running the test, we got:", "which points us to 0.0006716184352348816 as the best learning rate. Let\u2019s use this and continue tuning batch size also with 6 options, since, we definitely want to trust Prof. Ng\u2019s guideline that batch size is a second most important parameter :)", "Although batch size 2 has a higher accuracy result, the time cost significantly outweighs the benefit, so we\u2019ll go with batch size of 16.", "After updating the batch size value in our parameters dictionary, we can now proceed to tune number of epochs. Since the time taken to train and test increases with the number of epochs, it\u2019s better to tune this parameter at a later stage to avoid long running time.", "which gives us the best number of epochs as 200. Next, let\u2019s build the final model, with standardized features:", "Absolutely great result! The time taken is not too bad, although it\u2019s 1422 times more than XGBoost \ud83d\ude02", "Now, what if we don\u2019t tune the parameters and just standardize the features?", "So it seems that parameter tuning\u2019s effect is a bit marginal, but standardization, i.e. to make features have zero mean and unit variance is huge for neural networking model tuning.", "You can find the complete code in my project repo on GitHub. Do give it a try and see what results you can get!", "Thank you for reading! Is there anything that I can improve on? Kindly let me know below. We all get better by learning from each other!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Business Savvy Data Scientist Specializing in Analytics & Machine Learning \ud83d\udc68\u200d\ud83c\udf93 Lifelong Learner Fascinated by Tech \ud83d\udc49 linkedin.com/in/georgeliu2"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5a2ed38c8345&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://georgeliu1998.medium.com/?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": ""}, {"url": "https://georgeliu1998.medium.com/?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "George Liu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F55d85d947493&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&user=George+Liu&userId=55d85d947493&source=post_page-55d85d947493----5a2ed38c8345---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5a2ed38c8345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5a2ed38c8345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/f_0t4fYEauU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Adi Goldstein"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/getting-started-with-tensorflow-in-google-colaboratory-9a97458e1014", "anchor_text": "Google Colab"}, {"url": "https://github.com/georgeliu1998/keras_model_tuning", "anchor_text": "my project repo"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5a2ed38c8345---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----5a2ed38c8345---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----5a2ed38c8345---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----5a2ed38c8345---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5a2ed38c8345---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5a2ed38c8345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&user=George+Liu&userId=55d85d947493&source=-----5a2ed38c8345---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5a2ed38c8345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&user=George+Liu&userId=55d85d947493&source=-----5a2ed38c8345---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5a2ed38c8345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5a2ed38c8345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5a2ed38c8345---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5a2ed38c8345--------------------------------", "anchor_text": ""}, {"url": "https://georgeliu1998.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://georgeliu1998.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "George Liu"}, {"url": "https://georgeliu1998.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "958 Followers"}, {"url": "http://linkedin.com/in/georgeliu2", "anchor_text": "linkedin.com/in/georgeliu2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F55d85d947493&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&user=George+Liu&userId=55d85d947493&source=post_page-55d85d947493--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F55d85d947493%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-neural-networks-where-to-start-5a2ed38c8345&user=George+Liu&userId=55d85d947493&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}