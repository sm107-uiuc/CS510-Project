{"url": "https://towardsdatascience.com/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a", "time": 1683013768.8341088, "path": "towardsdatascience.com/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a/", "webpage": {"metadata": {"title": "Beyond CUDA: GPU Accelerated C++ for Machine Learning on Cross-Vendor Graphics Cards Made Simple with Kompute | by Alejandro Saucedo | Towards Data Science", "h1": "Beyond CUDA: GPU Accelerated C++ for Machine Learning on Cross-Vendor Graphics Cards Made Simple with Kompute", "description": "Machine learning, together with many other advanced data processing paradigms, fits incredibly well to the parallel-processing architecture that GPU computing offers. In this article you\u2019ll learn how\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute framework", "paragraph_index": 1}, {"url": "https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm.html", "anchor_text": "model parallelism", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Data_parallelism", "anchor_text": "data parallelism", "paragraph_index": 3}, {"url": "https://www.khronos.org/", "anchor_text": "Khronos Group", "paragraph_index": 6}, {"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute", "paragraph_index": 10}, {"url": "https://github.com/axsaucedo/vulkan-kompute/issues", "anchor_text": "open an issue", "paragraph_index": 12}, {"url": "https://docs.microsoft.com/en-us/cpp/cpp/smart-pointers-modern-cpp?view=vs-2019", "anchor_text": "smart pointers", "paragraph_index": 20}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#optensorcreate", "anchor_text": "kp::OpTensorCreate", "paragraph_index": 21}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/2e8a5aa3a6d6172abb51ac038e1b75c5c2d58af9/test/TestMultipleAlgoExecutions.cpp#L274", "anchor_text": "this variation here", "paragraph_index": 22}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#opalgobase", "anchor_text": "kp::OpAlgoBase", "paragraph_index": 27}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#optensorsynclocal", "anchor_text": "kp::OpTensorSyncLocal", "paragraph_index": 29}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/4e3802cb9dbf8742f9caf0374ef1612466c5ab1a/examples/array_multiplication#kompute-array-multiplication-example", "anchor_text": "this repository", "paragraph_index": 32}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/4e3802cb9dbf8742f9caf0374ef1612466c5ab1a/examples/array_multiplication/src/Main.cpp#L15", "anchor_text": "Kompute C++ code", "paragraph_index": 32}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/shaders/glsl/logistic_regression.comp#L7", "anchor_text": "full code for the shader", "paragraph_index": 69}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression#kompute-logistic-regression-example", "anchor_text": "example repository", "paragraph_index": 69}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression#kompute-logistic-regression-example", "anchor_text": "example repo", "paragraph_index": 83}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/src/Main.cpp#L15", "anchor_text": "Kompute C++ Code", "paragraph_index": 83}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/shaders/glsl/logistic_regression.comp#L7", "anchor_text": "Shader File", "paragraph_index": 83}], "all_paragraphs": ["Machine learning, together with many other advanced data processing paradigms, fits incredibly well to the parallel-processing architecture that GPU computing offers.", "In this article you\u2019ll learn how to write your own ML algorithm from scratch in GPU optimized code, which will be able to run in virtually any hardware \u2014 including your mobile phone. We\u2019ll introduce core GPU & ML concepts and show how you can use the Kompute framework to implement it in only a handful lines of code.", "We will be building first a simple algorithm that will multiply two arrays in parallel, which will introduce the fundamentals of GPU processing. We will then write a Logistic Regression algorithm from scratch in the GPU. You can find the repo with the full code in the following links:", "The potential and adoption of GPU computing has been exploding in recent years \u2014 you can get a glimpse of the increasing speed in adoption from the charts in the image below. In deep learning there has been a massive increase in adoption of GPUs for processing, together with paradigms that have enabled massively parallelizable distribution of compute tasks across increasing number of GPU nodes. There is a lot of exciting research around techniques that propose new approaches towards model parallelism and data parallelism\u2014 both which allow algorithms and data respectively to be sub-divided in a broad range of approaches to maximize processing efficiency.", "In this article we outline the theory, and hands on tools that will enable both, beginners and seasoned GPU compute practitioners, to make use of and contribute to the current development and discussions across these fascinating high-performance computing areas.", "Before diving right in, it is worth introducing the core framework that is making it possible to build hyper-optimized, cross platform and scalable GPU algorithms \u2014 and that is the Vulkan Framework.", "Vulkan is an Open Source project led by the Khronos Group, a consortium of a very large number of tech companies who have come together to work towards defining and advancing the open standards for mobile and desktop media (and compute) technologies. On the left you can see the broad range of Khronos Members.", "You may be wondering, why do we need yet another new GPU framework where there are already many options available for writing parallelizable GPU code? The main reason is that unlike some of its closed source counterparts (e.g. NVIDIA\u2019s CUDA, or Apple\u2019s Metal) Vulkan is fully Open Source, and unlike some of the older options (e.g. OpenGL), Vulkan is built with the modern GPU architecture in mind, providing very granular access to GPU optimizations. Finally, whilst some alternatives provide vendor-specific support for GPUs, Vulkan provides cross-platform, and cross-vendor support, which means that it opens the doors to opportunities in mobile processing, edge computing, and more.", "The Vulkan SDK provides very low-level access to GPUs, which allows for very specialized optimizations. This is a great asset for GPU developers \u2014 the main disadvantage is the verbosity involved, requiring 500\u20132000+ lines of code to only get the base boilerplate required to even start writing the application logic. This can result not only in expensive developer cycles but also prone to small errors that can lead to larger problems.", "This can actually be seen across many new and renowned machine learning & deep learning projects like Pytorch, Tensorflow, and Alibaba DNN \u2014 between others \u2014 which have either integrated or are looking to integrate the Vulkan GPU SDK to add mobile GPU (and cross-vendor GPU) support. All of these frameworks end up with very similar and extremely verbose boilerplate code, which means they would have benefited (and could still benefit) from using a unified baseline. This was one of the main motivations for us to start the Kompute project.", "Kompute is a framework built on top of the Vulkan SDK, specifically designed to extend its compute capabilities as a simple to use, highly optimized, and mobile friendly General Purpose GPU computing framework.", "Kompute was not built to hide any of the core Vulkan concepts \u2014 the Vulkan API is very well designed \u2014instead it augments Vulkan\u2019s Computing capabilities with a BYOV (bring your own Vulkan) design, enabling developers by reducing boilerplate code required and automating some of the more common workflows involved in writing Vulkan applications.", "For new developers curious to learn more, it provides a solid base to get started into GPU computing. For more advanced Vulkan developers, Kompute allows them to integrate it into their existing Vulkan applications, and perform very granular optimizations by getting access to all of the Vulkan internals when required. The project is fully open source, and we welcome bug reports, documentation extensions, new examples or suggestions \u2014 please feel free to open an issue in the repo.", "To build our first simple array-multiplication GPU computing application using Kompute, we will create the following:", "At the core of Kompute are \u201cKompute Operations\u201d, which are used for GPU actions, as well as \u201cKompute Tensor\u201d operations to handle the GPU data and memory. More specifically, this diagram shows the relationship between Kompute components (including explicit memory ownership).", "When interacting with the GPU, you have to send the instructions to the GPU to execute, and you need to make sure that the GPU has all of the relevant data available in GPU memory to begin processing. With Vulkan you send these instructions to the GPU via a queue, so to simplify things intuitively you can think of your GPU as a remote server, where data serialization, resource creation and memory allocation is expensive, and instructions are submitted via a queue \u2014 there is still GPU-CPU shared memory but you tend to only use this for data transfer to the GPU.", "Let\u2019s jump into the code. Typically, in a Kompute application we\u2019ll follow the following steps:", "First, we\u2019ll create our Kompute Manager, which is in charge of creating and managing all the underlying Vulkan resources.", "As you can see, here we are initializing our Kompute Manager, expecting it to create all the base Vulkan resources on Device 0 (in my case Device 0 is my NVIDIA card, and Device 1 is my integrated graphics card). For more advanced use-cases it\u2019s also possible to initialize the Kompute Manager with your own Vulkan resources (Device, Queue, etc) but this is out of scope of this article.", "We will now create the Kompute Tensors that will be used for input and output. These will hold the data required which will be mapped into the GPU to perform this simple multiplication.", "The reason why Kompute uses std::shared_ptr by design to avoid passing the objects by value, and instead passing them using smart pointers.", "Now that we have our Tensors created with local data, we will map the data into the GPU. For this we will use the kp::OpTensorCreate Kompute Operation, which will initialize the underlying Vulkan buffer and GPU memory, and perform the respective mapping into the GPU.", "It\u2019s also worth mentioning that it\u2019s possible to shorten the tensor creation steps by leveraging the Kompute Manager buildTensor helper function. This would allow you to skip the need to create the shared_ptr explicitly as well as the kp::OpTensorCreate Operation as outlined below (you can also find the full code implementation of this variation here).", "Now that we\u2019ve initialized the necessary Kompute Tensor components and they are mapped in GPU memory, we can add the Kompute Algorithm that will be executed in the GPU. This is referred to as the \u201cshader\u201d code, which follows a C-like syntax. You can see the full shader code below, and we\u2019ll break down each of the sections below.", "The #version 450 and layout(local_size_x = 1) in; sections specify the version and parallel thread execution structure (which we\u2019ll look at further down the article). We then can see the GPU data inputs and outputs defined in the format:", "These are the parameters that can be used throughout the shader code for processing. Namely in this case, the processing is done inside the main function. The first variable uint index = gl_GlobalInvocationID.x; is the currently parallel execution index which will allow us to process each data input.", "We then come into the core of this algorithm which is the multiplication o[index] = a[index] * b[index]. This part is quite self-explanatory \u2014 we multiply the elements of the GPU arrays a[] and b[] , then store the output on the array o[].", "In order to run the shader above we will create the Kompute Operation kp::OpAlgoBase. The parameters required for this Kompute Operation includes the Tensors to bind into the GPU instructions, as well as the shader code itself.", "It\u2019s worth mentioning that Kompute allows the user to also pass the shader through a file path, or alternatively there are also Kompute tools that will allow you to convert the shader binaries into C++ header files.", "Once the algorithm gets triggered, the result data will now be we held in the GPU memory of our output tensor. We can now use the kp::OpTensorSyncLocal Kompute Operation to sync the Tensor GPU memory as per the code block below.", "Finally, we can print the output data of our tensor.", "When you run this, you will see the values of your output tensor printed. That\u2019s it, you\u2019ve written your first Kompute!", "You can also find the full example in the repo so you can run it and extend it as desired. You can find the full standalone example in this repository which includes the instructions on how to build it as well as the Kompute C++ code.", "Although it may not seem obvious, the above introduced some intuition around core concepts and design thinking in GPU computing, whilst still abstracting a couple of the more in-depth concepts. In the following sections we will be providing more concrete terminology and we\u2019ll be scratching the surface of some of the more advanced concepts such as threads, blocks, memory strides and shared memory (although a lot will be provided as further reading).", "Let\u2019s look at a more advanced GPU compute use-case, specifically implementing the hello world of machine learning, logistic regression. Before we cover the implementation we will provide some intuition on the theory, and the terminology that we\u2019ll be using throughout.", "In machine learning we always have two stages, training and inference. In the diagram below you can see the two simplified flows. At the top is the training flow, where you identify some training data, extract some features, and train a model until you are happy with the accuracy. Once you have a trained model, you persist the model \u201cweights\u201d and deploy the model into the second workflow, where the model would perform inference on unseen data.", "In this case we will have an input dataset X , where each element is a pair xi and xj . Our input data will be the following:", "With this input data, the expected target value Y to be predicted will be the following:", "Our primary objective in machine learning is to learn using this data to find the function (and parameters) that will allow us to predict values Y from just using X as input.", "It\u2019s worth noting that the predicted values are defined as \u0177 , which are specifically the values computed with our inference function, distinct to the \u201ctrue\u201d or \u201cactual\u201d values of Y that we defined above.", "The functions that we will be using for logistic regression will be the following:", "And the parameters that we\u2019ll be looking to learn with our machine learning algorithm are:", "There is also the surrounding function \u03c3 which is the sigmoid function. This function forces our input to be closer to 0 or 1, which could be intuitively seen as the probability of our prediction to be \u201ctrue\u201d, and is defined as following:", "This is now the inference function that will allow us to process predictions from new data points. If we say for example that we have a new unseen set of inputs X = { (0, 1) }, and we assume that the learned parameters were W = (1, 1), b = 0 after running our machine learning algorithm through our training data (which we\u2019ll do later on), then we\u2019ll be able to run this through our prediction function by substituting the values as follows:", "In this case the prediction is 0.73..., which would be a positive prediction. This of course is just to demonstrate what our inference function will look like once we learn the parameters W and b.", "The way that we will be learning the parameters is by performing a prediction, calculating the error, and then re-adjusting the weights accordingly. The method used to \u201cre-adjust\u201d the weights based on the \u201cprediction error\u201d will be done by leveraging gradient descent. This will be repeated multiple times to find more accurate parameters.", "For this we will need to use the derivatives of each of the formulas. The first one, which is the derivative of our linear mapping function z is:", "Where the variables are defined as follows:", "Similarly the derivatives for w and b respectively are the following:", "In this case m is the total number of input elements.", "We will now be able to re-adjust the parameters using the above as follows:", "In this case \u03b8 is the learning rate, which as the name suggests controls the ratio by which the parameters will be modified on each iteration. Intuitively, the smaller, the more iterations it will be required for the algorithm to converge, however if the learning is too big, it will overshoot, leading to never being able to converge (from the image above you can imagine it will keep bouncing from side to side never reaching the bottom).", "In order for us to calculate loss, we will be using the log loss function, known also as cross-entropy loss function. This function is defined as follows:", "The function itself is set up such that the larger the difference between the predicted class and the expected class, the larger the error (you can see how much it punishes if the predicted class is on the complete different label).", "The loss function will provide us an idea of the improvement of our algorithm across iterations.", "Finally, one of the most important points here will be the intuition behind how we can leverage the parallel architecture of the GPU to optimize computation. In this case, we\u2019ll be able to do it by processing multiple input parameters at the same time, referred to as a micro-batch, and then re-adjusting the parameters in batch. This is known as data-parallelization, and is one of many techniques available. In the next section we will see how this is implemented, namely passing a mini-batch of inputs, storing the weights, and then re-adjusting them before the next iteration.", "Note: In this post we won\u2019t delve into much detail, nor best practices on machine learning, however at the end of the article we will be listing a broad range of sources for people interested to take their machine learning (or GPU compute) knowledge to the next level.", "Now that we have covered some of the core concepts, we will be able to learn about the implementation of the shader, which is the code that will be executed in the GPU.", "First we need to define all the input and output buffers as follows:", "If you remember, at the end of the last section we mentioned how we will be leveraging the concept of micro-batches in order to use the parallel architecture of GPU processing. What this means in practice, is that we will be passing multiple instances of X to the GPU to process at a time, instead of expecting the GPU to process it one by one. This is why we see that above we have an array for xi, xj, y, wOuti, wOutj, andbOut respectively.", "We also receive the constant M, which will be the total number of elements \u2014 if you remember this parameter will be used for the calculation of the derivatives. We will also see how these parameters are actually passed into the shader from the C++ Kompute side.", "Now that we have all the input and output parameters defined, we can start the main function, which will contain the implementation of our machine learning training algorithm.", "We will first start by keeping track of the current index of the global invocation. Since the GPU executes in parallel, each of these runs will be running directly in parallel, so this allows the current execution to consistently keep track of what iteration index is currently being executed.", "We now can start preparing all the variables that we\u2019ll be using throughout the algorithms. All our inputs are buffer arrays, so we\u2019ll want to store them in vec2 and float variables.", "In this case we\u2019re basically making explicit the variables that are being used for the current \u201cthread run\u201d. The GPU architecture consists of slightly more nuanced execution structures that involve thread blocks, memory access limitations, etc \u2014 however we won\u2019t be covering these in this example.", "Now we get into the more fun part \u2014implementing the inference function. Below we will implement the inference function to calculate \u0177, which involves both the linear mapping function, as well as the sigmoid function.", "Now that we have yHat, we can now use it to calculate the derivatives (\u2202z, \u2202w and \u2202b), which in this case are the derivative of the currently-executed index input element.", "We can now pass the derivatives as outputs, so the parameters can be re-adjusted for the next iteration.", "Finally we\u2019re able to calculate the loss and add it to the output lout array.", "That\u2019s it, we\u2019ve now finished the shader that will enable us to train a Logistic Regression algorithm in the GPU \u2014 you can find the full code for the shader in the GPU logistic regression example repository.", "Now we\u2019ll cover the Kompute code required to run this code against a dataset to train our first model and find the parameters.", "In order to run the shader we created above in the GPU using Kompute, we will follow the following steps:", "As you can see this is more involved than the simpler example we used above. In this case we will use the Kompute Sequence instead of the Kompute Manager directly, as we want to have deeper control on the commands that can be recorded to send in batch to the GPU. We will discuss this in more detail as we cover each of the steps. Let\u2019s get started.", "We will be importing the single header of Kompute \u2014 it\u2019s also possible to use the more granular class-based headers if required. We will also create some of the base configuration variables; namely ITERATIONS and learningRate which will be used in latter code blocks.", "Now we\u2019ll be creating all the tensors required. In this sub-section you will notice that we will be referencing all the buffers/arrays that are being used in the shader. We\u2019ll also cover how the order in the parameters passed relates to the way data is bound into the shaders so it\u2019s accessible.", "We also store them in a parameter vector for easier access:", "If you remember from the previous example, we were able to execute commands directly using the Kompute Manager. However we are able to use the Kompute Sequence resource if we want further granularity to record command batches that can be submitted and loaded into the GPU before processing. For this, we will create a Kompute Manager, then create a Kompute Sequence through it.", "We can now start by running instructions on GPU resources \u2014 namely we will start by initialising and map the Tensors with their respective GPU memory. Here you will see how Kompute Sequences provide you with further granularity on the command execution, but it won\u2019t be until the ML inference section that you will see the flexibility of Kompute Sequence.", "Let\u2019s get started by recording commands, namely the OpTensorCreate command, and then evaluating the operation across all the tensors above. This operation will create the respective Vulkan memory/buffer resources.", "In this section we will want to clear the previous recordings of the Kompute Sequence and begin recording a set of sequences. You will notice that unlike the previous section, in this case we won\u2019t be running the eval() straight away as we\u2019ll have to run it multiple times, together with extra commands to re-adjust the parameters.", "You will also notice that we will be recording three types of Kompute Operations, namely:", "Now that we have the command recorded, we can start running executions of these pre-loaded commands. In this case, we will be running the execution of a micro-batch iteration, followed by updating the parameters locally, so they are used in the following iteration.", "We now have a trained logistic regression model, or at least we\u2019ve been able to optimize its respective function to identify suitable parameters. We are now able to print these parameters and use the parameters for inference in unseen datasets.", "You are able to find this entire example in the example repository, which you\u2019ll be able to run and extend. You will find all the complete files in the GPU Logistic Regression example repo, including the Kompute C++ Code, and the Shader File.", "Congratulations, you\u2019ve made it all the way to the end! Although there was a broad range of topics covered in this post, there is a massive amount of concepts that were skimmed through. These include the underlying Vulkan concepts, GPU computing fundamentals, machine learning best practices, and more advanced Kompute concepts. Luckily, there are a broad range of resources online to expand your knowledge on each of these. Some links I recommend as further reading include the following:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Chief Scientist @ The Institute for Ethical AI & Machine learning | Engineering Director @ Seldon | Member at Large @ ACM | Building the future of production ML"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc9350e5e5d3a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278----c9350e5e5d3a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9350e5e5d3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9350e5e5d3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://docs.google.com/presentation/d/1WBLcBmk7J04Zu8cD3ugagPkEpKkDuJpNr-HfroNe4X8/edit#slide=id.p", "anchor_text": "Author"}, {"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute framework"}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "Kompute Repository"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/4e3802cb9dbf8742f9caf0374ef1612466c5ab1a/examples/array_multiplication#kompute-array-multiplication-example", "anchor_text": "Repository"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/4e3802cb9dbf8742f9caf0374ef1612466c5ab1a/examples/array_multiplication/src/Main.cpp#L15", "anchor_text": "Kompute Code"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression#kompute-logistic-regression-example", "anchor_text": "Repository"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/src/Main.cpp#L15", "anchor_text": "Kompute Code"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/shaders/glsl/logistic_regression.comp#L7", "anchor_text": "Shader Code"}, {"url": "https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm.html", "anchor_text": "model parallelism"}, {"url": "https://en.wikipedia.org/wiki/Data_parallelism", "anchor_text": "data parallelism"}, {"url": "https://streamhpc.com/blog/2017-05-04/what-is-khronos-as-of-today/", "anchor_text": "StreamHPC"}, {"url": "https://www.khronos.org/", "anchor_text": "Khronos Group"}, {"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute"}, {"url": "https://ethicalml.github.io/vulkan-kompute/", "anchor_text": "Documentation"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/issues", "anchor_text": "open an issue"}, {"url": "https://ethicalml.github.io/vulkan-kompute/overview/reference.html", "anchor_text": "Architecture Design"}, {"url": "https://docs.microsoft.com/en-us/cpp/cpp/smart-pointers-modern-cpp?view=vs-2019", "anchor_text": "smart pointers"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#optensorcreate", "anchor_text": "kp::OpTensorCreate"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/2e8a5aa3a6d6172abb51ac038e1b75c5c2d58af9/test/TestMultipleAlgoExecutions.cpp#L274", "anchor_text": "this variation here"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#opalgobase", "anchor_text": "kp::OpAlgoBase"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#optensorsynclocal", "anchor_text": "kp::OpTensorSyncLocal"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/4e3802cb9dbf8742f9caf0374ef1612466c5ab1a/examples/array_multiplication#kompute-array-multiplication-example", "anchor_text": "this repository"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/4e3802cb9dbf8742f9caf0374ef1612466c5ab1a/examples/array_multiplication/src/Main.cpp#L15", "anchor_text": "Kompute C++ code"}, {"url": "https://www.datasciencecentral.com/profiles/blogs/why-logistic-regression-should-be-the-last-thing-you-learn-when-b", "anchor_text": "DS Central"}, {"url": "https://mi-academy.com/2018/10/04/the-history-of-gradient-descent/", "anchor_text": "ML Academy"}, {"url": "https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/", "anchor_text": "from ML Mastery"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/shaders/glsl/logistic_regression.comp#L7", "anchor_text": "full code for the shader"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression#kompute-logistic-regression-example", "anchor_text": "example repository"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#optensorsyncdevice", "anchor_text": "kp::OpTensorSyncDevice"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#opalgobase", "anchor_text": "kp::OpAlgoBase"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/overview/reference.html#optensorsynclocal", "anchor_text": "kp::OpTensorSyncLocal"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/tree/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression#kompute-logistic-regression-example", "anchor_text": "example repo"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/src/Main.cpp#L15", "anchor_text": "Kompute C++ Code"}, {"url": "https://github.com/axsaucedo/vulkan-kompute/blob/7906406dd1e8bbfb01c1c5d68be44f63587440aa/examples/logistic_regression/shaders/glsl/logistic_regression.comp#L7", "anchor_text": "Shader File"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/", "anchor_text": "Kompute Documentation"}, {"url": "https://ethical.institute/mle.html", "anchor_text": "The Machine Learning Engineer Newsletter"}, {"url": "https://github.com/EthicalML/awesome-production-machine-learning/", "anchor_text": "Awesome Production Machine Learning"}, {"url": "https://www.fast.ai/2018/09/26/ml-launch/", "anchor_text": "Introduction to ML for Coders course"}, {"url": "https://vulkan-tutorial.com/", "anchor_text": "Vulkan SDK Tutorial"}, {"url": "https://medium.com/tag/gpu-computing?source=post_page-----c9350e5e5d3a---------------gpu_computing-----------------", "anchor_text": "Gpu Computing"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c9350e5e5d3a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/gpu-machine-learning?source=post_page-----c9350e5e5d3a---------------gpu_machine_learning-----------------", "anchor_text": "Gpu Machine Learning"}, {"url": "https://medium.com/tag/gpu-deep-learning?source=post_page-----c9350e5e5d3a---------------gpu_deep_learning-----------------", "anchor_text": "Gpu Deep Learning"}, {"url": "https://medium.com/tag/vulkan?source=post_page-----c9350e5e5d3a---------------vulkan-----------------", "anchor_text": "Vulkan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc9350e5e5d3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&user=Alejandro+Saucedo&userId=32de426f7278&source=-----c9350e5e5d3a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc9350e5e5d3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&user=Alejandro+Saucedo&userId=32de426f7278&source=-----c9350e5e5d3a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9350e5e5d3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc9350e5e5d3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c9350e5e5d3a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c9350e5e5d3a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/@AxSaucedo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "616 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1b4684c4c42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a&newsletterV3=32de426f7278&newsletterV3Id=b1b4684c4c42&user=Alejandro+Saucedo&userId=32de426f7278&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}