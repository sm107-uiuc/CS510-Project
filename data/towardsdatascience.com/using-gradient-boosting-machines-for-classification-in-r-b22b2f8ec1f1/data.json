{"url": "https://towardsdatascience.com/using-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1", "time": 1683012202.77968, "path": "towardsdatascience.com/using-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1/", "webpage": {"metadata": {"title": "Using gradient boosting machines for classification in R | by Sheenal Srivastava | Towards Data Science", "h1": "Using gradient boosting machines for classification in R", "description": "Understand the factors driving student success so that Open University can allocate resources to improve student success The Open University Learning Analytics Dataset is a publicly available dataset\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/shedoesdatascience/openlearning", "anchor_text": "https://github.com/shedoesdatascience/openlearning", "paragraph_index": 43}], "all_paragraphs": ["Understand the factors driving student success so that Open University can allocate resources to improve student success", "The Open University Learning Analytics Dataset is a publicly available dataset containing data about courses, students and their interactions with VLE for seven selected courses (modules).", "As the unique identifiers across all the data tables were student ID, module and course description, data was aggregated at this level. The following variables were used in the analysis:", "Variable NameVariable TypeVariable NameVariable Typeid_student unique identifier/primary keyimd band categorical code_modulecategoricalage band categorical code_presentation categorical num of previous attemptsnumericalgender categorical studied credits categorical region categorical disability categorical highest education categorical final result numerical sum weighted score numerical average module length numerical average submission duration numerical average proportion content accessed numerical average date registration numerical trimmed assessment type categorical", "Excluded variables: Student ID and sum weighted score", "Reason for exclusion: Student ID\u2013 identifying information, sum weighted score \u2014 correlated to final result", "Reason for not using \u201cfinal result\u201d as success factor: There is a disproportionate of \u201cPass\u201d records within the dataset thus reducing the model accuracy at predicting \u201cFail\u201d, \u201cWithdrawn\u201d and \u201cDistinction\u201d. As such, the response variable was binarised.", "Why do we check for missing data? \u2014 If a large proportion of data is missing/null, sample is not representative enough to provide accurate results. This is not the case when the missing/null data is missing for a valid reason.", "\u2022 Split data into training & test sets for nominal and binary predictors to test for model accuracy", "Why do we split the data into training and test sets \u2014 The model is trained on the training set. Model accuracy is tested on the test set to determine how well the model is good at prediction success against non-success on data it has not \u201cseen\u201d.", "All data exploration, transformation, and loading of final dataset was done in Alteryx to avoid writing code and test its functionality for basic data transformation steps that would typically be carried out in R such as joins, mutate and group by.", "First, I joined three datasets \u2014 assessments.csv, studentAssessments.csv and courses.csv by ID assessments (primary key).", "Next, I engineered two features: weighted_score and submission_duration. Dates are usually meaningless unless they are transformed into useful features. Course description only had two categories, which I converted to 1 and 2 for ease of reference.", "The next step was to add in data on student interactions with the virtual learning platform (VLE). Some feature engineering was done for ease of analysis such as creating a new variable called activity_type_sum that reduces the number of categories in activity type into two broad categories \u2014 content access and browsing. The reason for doing this is that granular categories only result in more features and reduce the number of observations per category. The number of clicks were summed by the activity type feature. Proportion of activity out of total activity that is browsing related and content access related was also calculated. This is a good way to create a feature that is relative to another feature and scaled by total activity thus ensuring that all students are represented on a similar scale by their activity type.", "Block 1 was joined to Block 2 using student_id, code_module and code_presentation as the primary key. The resulting output is shown below.", "The above output \u2014 Block 3 \u2014 was joined with student registration data using student_id, code_module, and code_presentation to bring across the data_registered field.", "The date_unregistered field was ignored as it had a lot of missing values. Moreover, students with empty unregistered field cells have withdrawal as the value for their final_result. This variable is our target/response variable. So, the date_unregistered field appears to be a proxy measure for final_result and as such it makes sense to exclude this variable from our analysis.", "As shown above, for a given id_student, code_module, and code_presentation, the module_presentation length, proportion_content and date_registration is repeated. As we want to have unique records, we can aggregate the data as follows:", "Data is now at student_id, code_module, code_presentation and assessment_type level; however, the target variable \u2014 final_result \u2014 is at student_id, code_module and code_presentation level. Hence, this data will need to be further aggregated.", "Let\u2019s look at student info first. A unique record here is id_student, code_module, code_presentation.  So, we will need to go back a step and summarise a student_id, code_module and code_presentation to represent all assessments taken by an individual. We will still use the previous summary formulas.", "By doing this we have 8 unique assessment types that a student can take for a given code module and code presentation. Assessment types are not repeated (trimmed only) so if at student took 3 TMAs this is not reflected as shown below.", "A variable could be created to count the number of assessments per assessment type but it would contain lots of missing values as not all assessments have all three types of assessments. Now, we are ready to join to the student info data with output shown below.", "Now, we have 18 columns. We have been told that a presentation may differ if presented in February vs. October. We will assume that it does not differ year on year (i.e. 2013B is same as 2014B). As such, we will recode code_presentation into 1 for B and 2 for J as a binary variable.", "The final output is shown below.", "It is finally time for some data exploration.", "Categorical variables can be represented with bar charts where the y-axis is the frequency of the occurence of a given category. For example, in the chart below we can see that the most frequently taken code module is FFF followed by BBB. There are seven unique code modules with no missing values.", "Data can also be summarised numerically using a five-point summary for continuous variables and using mode for categorical variables as shown below.", "Insights we can make from the summary below is that the more common student is a Scottish male student presenting without a disability with an Imd_band between 20 to 40% with a typical Pass as their final result.", "Now we can move towards modelling the dataset.", "We have been asked to assist Open University in better understanding student success. \u2022 We will assume that student success is measured via the final result where pass and distinction are indicators of \u201csuccess\u201d and withdrawn and fail are indicators of \u201cnon-success\u201d. \u2022 For the independent variables, we will use all variables from the previoustable except for weighted_score. The reason for this is because weighted score determines the final result for a given student. As such, it is highly correlated (multicollinear) to final result and as such will be excluded. \u2022 Student ID is identifying information and as such will not be used as a predictor.", "GBM (Gradient Boosted Model) was used as a model of choice. This type of model creates a series of weak learners (shallow trees) where each new tree tries to improve on the error rate of the previous tree. The final tree is one with the lowest error rate. It is an ensemble machine learning method as several trees are created to provide the final results. However, unlike in randomForest, these trees are created in a series rather than in parallel. Furthermore, these trees are not independent and are depenent on the previous tree\u2019s error rate where the following three will try harder to improve prediction for the more difficult cases. This is controlled by a parameter called hte learning rate.", "The model was run with 500 rounds (500 trees) with minimum and maximum depths of 4 for the tree. Typically, it is not good to have very deep trees as this can lead to overfitting where the algorithm tries to explain every observation in the dataset as it increases the depth of the tree leading to leaves containing a very small number of observations that fit the given rule.", "We can see from the above output that the model has a RMSE (root-mean-squared error) value of 0.55 which is quite high. It is particularly bad at predicting Distinction and Fail, which may be due to the imbalance in the dataset where we know from our exploratory data analysis that Pass is the most common final result.", "To counteract this imbalance issue, the target variable was redefined as \u201csuccess\u201d (distinction and pass) and \u201cfailure\u201d (fail and withdrawn). It is common to combine categories to deal with imbalanced datasets. Other ways are to undersample (i.e. reduce the number of instances for the most frequent class) or oversample (i.e. create artificial observations for the non-frequent classes).", "The model was re-run with the following output. Here we can see that the mean per-class error has dropped significantly. The Area Under the Curve (AUC) is another accuracy metric that tells you how well the model is at classifying cases correctly (i.e. maximising the true positive rate (TPR)). The higher the AUC, the more accurate the model. As the AUC is measured between 0 and 1, an AUC of 0.87 is pretty good.", "Another metric that is commonly used in classification problems is the F1 score which is the harmonic mean of precision and recall. Both metrics aim to maximise the TPR while minimising either the false negative rate (recall) or false positive rate (precision). A true positive is when a success or failure is classified correctly. A false negative is when a success is labelled as a failure. A false positive is when a failure is labelled as a success. For the F1 score to be high, both precision and recall need to be high.", "Confusion matrix indicates an overall error rate of 17.11% which is mainly driven by how good the model is at classifying successes. The model is not so good at classifying failures with an error rate of 39.07%. Again this may be due to the data being overrepresented by \u201cPasses\u201d. Thus, the results should be treated with caution and model re-run with a more balanced dataset.", "Now, let\u2019s look at the top predictors of success or failure by looking at the variable importance list.", "Now, let\u2019s visualise information on the top predictors to better understand the model. The stacked bar plot below shows the proportion of records by course module and final_result. We can deduce that students are more likely to be successful in completing AAA, EEE and GGG courses over other courses.", "The histograms above show the average submission duration by success and failure.", "It appears that when students are successful, they are more likely to submit their assignment within 10 days (+/-) of the assessment submission date.", "Machine learning was used to quickly identify top contributors to student success.", "Hopefully, you now have a better understanding of utilising GBM for a classification problem, the pitfalls of a classification problem (i.e. imbalanced dataset) and the use of various accuracy metrics.", "The reference to all R code is provided in my git repository: https://github.com/shedoesdatascience/openlearning", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb22b2f8ec1f1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sheenalsrivastava?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sheenalsrivastava?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "Sheenal Srivastava"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F42bf180d6f14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&user=Sheenal+Srivastava&userId=42bf180d6f14&source=post_page-42bf180d6f14----b22b2f8ec1f1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb22b2f8ec1f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb22b2f8ec1f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/shedoesdatascience/openlearning", "anchor_text": "https://github.com/shedoesdatascience/openlearning"}, {"url": "https://medium.com/tag/gbm?source=post_page-----b22b2f8ec1f1---------------gbm-----------------", "anchor_text": "Gbm"}, {"url": "https://medium.com/tag/gradient-boosting?source=post_page-----b22b2f8ec1f1---------------gradient_boosting-----------------", "anchor_text": "Gradient Boosting"}, {"url": "https://medium.com/tag/r-programming?source=post_page-----b22b2f8ec1f1---------------r_programming-----------------", "anchor_text": "R Programming"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b22b2f8ec1f1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/classification?source=post_page-----b22b2f8ec1f1---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb22b2f8ec1f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&user=Sheenal+Srivastava&userId=42bf180d6f14&source=-----b22b2f8ec1f1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb22b2f8ec1f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&user=Sheenal+Srivastava&userId=42bf180d6f14&source=-----b22b2f8ec1f1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb22b2f8ec1f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb22b2f8ec1f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b22b2f8ec1f1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b22b2f8ec1f1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sheenalsrivastava?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sheenalsrivastava?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sheenal Srivastava"}, {"url": "https://medium.com/@sheenalsrivastava/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "67 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F42bf180d6f14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&user=Sheenal+Srivastava&userId=42bf180d6f14&source=post_page-42bf180d6f14--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1966e1e5a2c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1&newsletterV3=42bf180d6f14&newsletterV3Id=1966e1e5a2c8&user=Sheenal+Srivastava&userId=42bf180d6f14&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}