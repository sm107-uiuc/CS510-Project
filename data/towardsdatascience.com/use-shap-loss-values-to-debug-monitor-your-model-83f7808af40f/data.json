{"url": "https://towardsdatascience.com/use-shap-loss-values-to-debug-monitor-your-model-83f7808af40f", "time": 1683009750.43381, "path": "towardsdatascience.com/use-shap-loss-values-to-debug-monitor-your-model-83f7808af40f/", "webpage": {"metadata": {"title": "Use SHAP loss values to debug/monitor your model | by Chuangxin Lin | Towards Data Science", "h1": "Use SHAP loss values to debug/monitor your model", "description": "Responsible AI has been a very hot topic in recent years. Accountability and explainability now become the necessary components of your machine learning models, particularly when the models make\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP", "paragraph_index": 0}, {"url": "https://github.com/slundberg/shap/blob/master/notebooks/tree_explainer/Explaining%20the%20Loss%20of%20a%20Model.ipynb", "anchor_text": "example", "paragraph_index": 1}, {"url": "https://github.com/slundberg/shap/blob/fc30c661339e89e0132f5f89e5385e3681090e1f/shap/explainers/tree.py#L39", "anchor_text": "docstring", "paragraph_index": 3}, {"url": "https://github.com/slundberg/shap/blob/master/notebooks/tree_explainer/Census%20income%20classification%20with%20XGBoost.ipynb", "anchor_text": "the tutorial example", "paragraph_index": 4}, {"url": "https://github.com/Chancylin/shap_loss", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://archive.ics.uci.edu/ml/datasets/adult", "anchor_text": "dataset", "paragraph_index": 4}, {"url": "https://github.com/slundberg/shap/blob/master/shap/plots/monitoring.py", "anchor_text": "API", "paragraph_index": 10}, {"url": "https://jphall663.github.io/GWU_rml/", "anchor_text": "Introduction to Responsible Machine Learning", "paragraph_index": 24}], "all_paragraphs": ["Responsible AI has been a very hot topic in recent years. Accountability and explainability now become the necessary components of your machine learning models, particularly when the models make decisions that will impact people\u2019s life, such as medical diagnostic, financial service. This is a very large topic for machine learning and a lot of ongoing work has been dedicated to various aspects. You can check more resources on this topic[1]. In this post, I will focus on SHAP (SHapley Additive exPlanations), which is one of the most popular explainability packages, due to its versatile (local/global explainability; model-specific/agnostic) and the solid theoretical foundation from game theory. You can find many posts and tutorials to understand how SHAP can help you understand how your ML model works, i.e., how each of your features contributes to the model prediction. However, in this post, I will talk about SHAP loss values that many people may be less familiar with. I will walk through some key concepts by presenting an example. I will also share some of my thoughts.", "To begin with, you may want to check the example provided by SHAP package. And there are two important notes:", "Essentially, this means when integrating out the absent features, you should use the marginal distribution instead of the conditional distribution. And the way to achieve the marginal distribution is to assign the absent features with the values from the background dataset.", "The use of \u201cinterventional\u201d (i.e., marginal distribution) or \u201ctree_path_dependent\u201d (i.e., conditional distribution) is an important nuance (see docstring in SHAP package) and it\u2019s worth further discussion. But I don\u2019t want to confuse you in the very beginning. You just need to know that in the common practice, TreeShap calculates shap values very fast because it takes advantage of the conditional distribution from the tree structure of the model, but the use of conditional distribution can introduce the problem of causality[2].", "The example in this post is modified from the tutorial example in SHAP package and you can find the full code and notebook here. I first trained an XGBoost classifier. The dataset uses 12 features to predict if a person makes over 50K a year.", "You can use the SHAP package to calculate the shap values. The force plot will give you the local explainability to understand how the features contribute to the model prediction for an instance of interest (Fig. 1). The summary plot will give the global explainability (Fig. 2). You can check Part 1 in the Jupyter Notebook. There is nothing new but just the common use of SHAP, so I will leave the details to you and jump to Part 2, shap values for the model loss.", "Now the contribution to the model loss is more of interest, so we need to calculate shap loss values. In some sense, this is similar to residual analysis. The code snippet is as follows. Note that you need to", "Now the fore plot for a data instance has a similar interpretation as that in Fig. 2, but in terms of log loss instead of prediction. A successful prediction (ground truth as True and prediction as True) is given in Fig. 3, while a wrong prediction (ground truth as True and prediction as False) in Fig. 4. You can see how the features with blue color try to reduce the logloss from the base value, and the reds increase the logloss. It\u2019s noteworthy that the base values (expected values) of the model loss depend on the label (True/False) so it is a function instead of a single number. The calculation of expected values is by first setting all the data labels to True (or False), and then calculate the average log loss, for which you can check more details on the notebook. I am not sure if there is a particular reason for such a calculation of base values, but after all, the base values just serve as a reference value so I think it should not matter very much.", "Similarly, we have the summary plot for the model logloss (Fig. 5). This will tell you how the features contribute to the model logloss (the calculation is based on absolute mean). A feature with a large contribution means it contributes a lot to the model loss, could be increasing the logloss for some data instance or reducing the logloss for other data instances. Therefore, the summary plot here should show the consistency with the top features by shap values in Fig. 2. But we can see the ranking orders are a bit different. While \u201cRelationship\u201d remains the top one, the order of \u201cAge\u201d, \u201cEducation-Num\u201d, \u201cCapital Gain\u201d, \u201cHours per week\u201d, \u201cOccupation\u201d is different. And \u201cCapital Gain\u201d in Fig. 5 has a relatively large contribution than it does in Fig. 2. This suggests that \u201cCapital Gain\u201d plays an important role in reducing the log loss while relatively speaking it may not be that important for the model to make the prediction compared to \u201cRelationship\u201d. It\u2019s noteworthy that the summary plot in Fig. 5 should be interpreted with cautions, since the bar plot in Fig. 5 is calculated based on absolute mean, which means both the effect of reducing logloss and increasing logloss are taken into account to rank the importance of a feature. In plain language, a large magnitude of (absolute) contribution may not necessarily mean a feature is a \u201cgood\u201d feature.", "Of course, you can use the scatter summary plot instead of the bar summary plot to see the detailed distribution to dive deeper for your model debugging (i.e., improve your model performance). The other way I investigate it is to decompose the shap loss values into negative component (Fig. 6) and positive component (Fig. 7). And in terms of the model debugging, you want to achieve a more negative value and reduce the positive value for all the features since you wish all the features reduce the final model logloss.", "Now we come to the most interesting part: use the shap loss value to monitor your model. Model drift and data drift are real-world problems that your model deteriorates and leads to unreliable/inaccurate predictions. But these usually happen silently, and it is very hard to identify the root cause. In a recent paper[3] by the SHAP author, they use the shap loss values to monitor the model health. The idea is very appealing and I wish to explore more on that. Note that the API is available but seems under ongoing development.", "First we need to calculate the shap loss values for the training data and test data. In the context of monitoring, you need to calculate the shap loss values for dataset from different time-snapshot. You may recall that we have done this in the beginning of this section. But note that we use the background data sampled from the entire dataset. For the rationale of monitoring, it makes more sense to calculate the shap loss values for the training dataset and the test dataset separately, by using the background data from the training dataset and the test dataset. The code snippets are as follows:", "The monitoring plots for the top features are shown in Fig. 8. First all the data instances will be ordered by the index. And here we assume the index indicates the evolution of time (from left to right along the axis). In this toy example, we don\u2019t have data from different time snapshot so we simply treat the training data as the current data and the test data as the future data we would like to monitor.", "There are some important points to understand these monitoring plots, based on the current implementation in the SHAP pakcage. In order to see if the shap loss values are time-consistent, t-test will be repeatedly conducted to compare two data samples. The current implementation uses an increment of 50 data points to split the data. That means, the first t-test will compare data[0: 50] to data[50:]; and the second will compare data[0: 100] to data[100:], and so on. The t-test will fail if the p value is smaller than 0.05/n_features. In other words, it uses the confidence level of 95% and Bonferroni correction has been applied. Where the t-test fails, a vertical dash line will be plotted to indicate the location. A bit surprising, we see the monitoring plots show the inconsistency of shap loss values for [\u201cRelationship\u201d, \u201cEducation-Num\u201d, \u201cCapital Gain\u201d], and that happens when we enter the time snapshot of test data (Fig. 8).", "The reason for the use of an increment of 50 data points is not very clear to me. And in this example, since we know [0:26048] is the training data, and [-6513:] is the test data. I modified the increment to 6500 and see if it will give a different result. But the monitoring plots still show the same inconsistency (i.e., the failure of t-test) when it comes to comparing the test data (Fig. 9).", "Finally, I think it\u2019s a good idea to check the t-test on the training data and test data directly. And this verifies the conclusion again, the shap loss values are inconsistent between the training dataset and the test dataset.", "The inconsistency of shap loss values between training data and test data is actually very unexpected, and can be troublesome. Remember that we simply use training/test split from the entire dataset, so there is a good reason to believe that training dataset and test dataset should be consistent, in terms of data distribution or shap loss values contribution. By any means, this is just a simple experiment and more investigations should be performed to draw any firm conclusion. But I think there may be some reasons why the SHAP package indicates the monitoring functionality is just preliminary, for example:", "Another interesting discussion point is the use of background data. Note that for the monitoring plots, the shap loss values on the training dataset and the test dataset are calculated using different background data (subsamples from training dataset/test dataset). Since the \u201cinterventional\u201d approach to calculate shap loss values is very expensive, I only tried the subsamples data of a size of 100 data instances. That could yield a high-variance result of the shap loss values. Perhaps a background data of a large size will reduce the variance and give the consistency of shap loss values in the monitoring plots. And when I used the same background data (subsamples from the entire dataset), there will not be inconsistency in the monitoring plot. So how you choose the background data matters a lot!", "I hope this post can give you a useful introduction to the shap loss values. You can better debug your ML models by investigating the shap loss values. It can also be a useful approach to monitoring your ML models for model drift and data drift, which is still a very big challenge in the community. But note the limitation: in order to use the shap loss values for monitoring, you need to have the ground truth for the new coming data, which is usually only available after a certain period. Also, unfortunately this functionality is still under development, and the appropriateness of the use of t-test needs to be further justified.", "Last but not least, calculating shap values (TreeShap) by marginal distribution or conditional distribution can give different results (see the equations). The use of conditional distribution will introduce the problem of causality, while marginal distribution will provide unlikely data points to the model[4]. There seems no consensus about which one to use, depending on what scenarios[2,5]. This paper[6] has some interesting comments on this topic which I would like to quote here:", "In general, whether or not users should present their models with inputs that don\u2019t belong to the original training distribution is a subject of ongoing debate.", "This problem fits into a larger discussion about whether or not your attribution method should be \u201ctrue to the model\u201d or \u201ctrue to the data\u201d which has been discussed in several recent articles.", "Thank you for your time. And don\u2019t hesitate to leave any comments and discussions!", "All the plots in this post are created by the author by using the SHAP package. Please kindly let me know if you think any of your work is not properly cited.", "[1] Introduction to Responsible Machine Learning", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F83f7808af40f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----83f7808af40f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----83f7808af40f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lcxustc.medium.com/?source=post_page-----83f7808af40f--------------------------------", "anchor_text": ""}, {"url": "https://lcxustc.medium.com/?source=post_page-----83f7808af40f--------------------------------", "anchor_text": "Chuangxin Lin"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F890a7b9564d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&user=Chuangxin+Lin&userId=890a7b9564d7&source=post_page-890a7b9564d7----83f7808af40f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83f7808af40f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83f7808af40f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "https://github.com/slundberg/shap/blob/master/notebooks/tree_explainer/Explaining%20the%20Loss%20of%20a%20Model.ipynb", "anchor_text": "example"}, {"url": "https://github.com/slundberg/shap/blob/fc30c661339e89e0132f5f89e5385e3681090e1f/shap/explainers/tree.py#L39", "anchor_text": "docstring"}, {"url": "https://github.com/slundberg/shap/blob/master/notebooks/tree_explainer/Census%20income%20classification%20with%20XGBoost.ipynb", "anchor_text": "the tutorial example"}, {"url": "https://github.com/Chancylin/shap_loss", "anchor_text": "here"}, {"url": "https://archive.ics.uci.edu/ml/datasets/adult", "anchor_text": "dataset"}, {"url": "https://github.com/slundberg/shap/blob/master/shap/plots/monitoring.py", "anchor_text": "API"}, {"url": "https://jphall663.github.io/GWU_rml/", "anchor_text": "Introduction to Responsible Machine Learning"}, {"url": "https://arxiv.org/abs/1910.13413", "anchor_text": "https://arxiv.org/abs/1910.13413"}, {"url": "https://christophm.github.io/interpretable-ml-book/shap.html", "anchor_text": "https://christophm.github.io/interpretable-ml-book/shap.html"}, {"url": "https://arxiv.org/abs/1908.08474", "anchor_text": "arXiv preprint arXiv:1908.08474"}, {"url": "https://distill.pub/2020/attribution-baselines/", "anchor_text": "Visualizing the impact of feature attribution baselines"}, {"url": "https://medium.com/tag/shap?source=post_page-----83f7808af40f---------------shap-----------------", "anchor_text": "Shap"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----83f7808af40f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----83f7808af40f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F83f7808af40f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&user=Chuangxin+Lin&userId=890a7b9564d7&source=-----83f7808af40f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F83f7808af40f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&user=Chuangxin+Lin&userId=890a7b9564d7&source=-----83f7808af40f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83f7808af40f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----83f7808af40f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F83f7808af40f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----83f7808af40f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----83f7808af40f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----83f7808af40f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----83f7808af40f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----83f7808af40f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----83f7808af40f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----83f7808af40f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----83f7808af40f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----83f7808af40f--------------------------------", "anchor_text": ""}, {"url": "https://lcxustc.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lcxustc.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Chuangxin Lin"}, {"url": "https://lcxustc.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "39 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F890a7b9564d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&user=Chuangxin+Lin&userId=890a7b9564d7&source=post_page-890a7b9564d7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F95ae0568d57e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fuse-shap-loss-values-to-debug-monitor-your-model-83f7808af40f&newsletterV3=890a7b9564d7&newsletterV3Id=95ae0568d57e&user=Chuangxin+Lin&userId=890a7b9564d7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}