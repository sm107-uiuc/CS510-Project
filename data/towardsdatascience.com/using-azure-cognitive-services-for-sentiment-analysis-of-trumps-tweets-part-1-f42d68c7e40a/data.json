{"url": "https://towardsdatascience.com/using-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a", "time": 1682997078.429441, "path": "towardsdatascience.com/using-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a/", "webpage": {"metadata": {"title": "Using Azure Cognitive Services for Sentiment Analysis of Trump\u2019s Tweets | by Irfan Elahi | Towards Data Science", "h1": "Using Azure Cognitive Services for Sentiment Analysis of Trump\u2019s Tweets", "description": "An extensive tutorial on how to use Azure Cognitive Services (Text analytics API) to perform sentiment analysis using Databricks (Python and Scala)"}, "outgoing_paragraph_urls": [{"url": "http://databricks.com", "anchor_text": "following link", "paragraph_index": 8}, {"url": "https://iag.me/socialmedia/how-to-create-a-twitter-app-in-8-easy-steps/", "anchor_text": "this link", "paragraph_index": 16}, {"url": "https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html", "anchor_text": "FUSE mount", "paragraph_index": 23}, {"url": "http://twitter.com/realDonaldTrump", "anchor_text": "@realDonaldTrump", "paragraph_index": 26}, {"url": "https://www.udemy.com/apache-spark-hands-on-course-big-data-analytics/", "anchor_text": "Spark", "paragraph_index": 26}, {"url": "https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/", "anchor_text": "Azure Text Analytics API", "paragraph_index": 26}, {"url": "https://mvnrepository.com/artifact/org.scalaj/scalaj-http", "anchor_text": "scalaj", "paragraph_index": 30}, {"url": "https://mvnrepository.com/artifact/io.spray/spray-json", "anchor_text": "spray json", "paragraph_index": 30}, {"url": "https://apress.com/gp/book/9781484248096", "anchor_text": "Scala Programming for Big Data Analytics book", "paragraph_index": 56}], "all_paragraphs": ["Sentiments can manifest anywhere from reviews, news, real-life conversations, journalism to name a few. The capability to identify the polarity of sentiments accurately by employing machine learning approaches unlocks series of business use-cases that can yield immense value for businesses. Instead of humans to parse through the content to infer sentiment, a process that bears a wide spectrum of inefficiency w.r.t. cost and time to value, if machines could be forged to determine the sentiments automatically; businesses can tap this insight to align their strategies (e.g. for a retail company, they can expedite on tailored marketing to reduce the risk of churn and limit the impact of negative word of mouth, it can be a feedback loop to revisit the product/service and enhance it as Bill Gates once famously stated that \u201cYour most unhappy customers are your greatest source of learning\u201d)", "With this context in mind, if one has to build the capability to perform sentiment learning at scale, one option is to use the traditional machine learning approaches to build a classifier which predicts that whether the input (which can be a text transformed from its raw form to the form (consisting of bag-of-words or TF/IDF or any other representation e.g. word2vec) that\u2019s understandable by machine learning algorithms) belongs to discrete binary categories (positive or negative). One can use the good-old supervised machine learning algorithms like Naive Bayes, Logistic Regression, SVM, Decision Trees or ensemble based like RandomForest to do the task and can achieve relatively good level of performance based on the chosen evaluation metric. Or one can explore Deep Learning approaches like Multi-Layer Perceptrons to achieve similar objective\u00a0with\u00a0caveats. But chances are that no matter how advanced or well-established your data science team is, unless you are Microsoft or Google or alike, it won\u2019t be easy to compete your approaches, in terms of performance and efficiency, against the ones used in big companies (e.g. Microsoft). One of the beauties of Cloud services is that they provide ready-to-consume analytics services like Azure Cognitive Services or AWS Comprehend based on their decades of investment in R&D. One can employ these services for sentiment analysis use-cases to enable rapid speed-to-value. In my previous article, we explored the usage of Azure Cognitive Services for content moderation whereas this post is about using yet another services in the suite of Azure Cognitive Services for sentiment analysis!", "To make matters interesting, I\u2019ll demonstrate how you can use Azure Cognitive Services to perform sentiment analysis on the the tweets published by Donald Trump. Not sure about you but many may have a preconceived and biased assumption that tweets from him do bear a \u201cspecific polarity\u201d. This exercise will endeavor to validate that assumption and will analyze recent tweets by him to see what sentiments do they bear.", "The post will consist of two parts. In the first part, I\u2019ll demonstrate how you can retrieve the data (Trump\u2019s tweet in this case) using Python and in the next I\u2019ll highlight how you can use Scala and Databricks (Spark) to analyze the tweets in scalable fashion. And again, the code implementation won\u2019t be production grade and is meant to prove the capability only.", "Let\u2019s start off with the first part i.e. Data extraction. For this, you will require the following:", "The workflow will look something like this:", "Extract Tweets -> Perform some processing -> Persist in file system -> Read Tweets in Spark -> Integrate with Azure Cognitive Services -> Generate Sentiment Predictions -> Perform Analysis", "The part in bold will be the scope of this post. The rest will be covered in part II. So let\u2019s start shall we?", "If you haven\u2019t signed up for the community version of Databricks, you can visit the following link. Once signed up, you will have to launch a cluster prior to using the notebooks. With community edition, the available cluster is pretty small but it will be more than enough for us. To create a cluster, click \u201cClusters\u201d on the left hand menu and then click \u201c+ Create Cluster\u201d button:", "it will present you with options to create cluster. Specify a name of your choice for the cluster. The parameters\u2019 default values should be fine. Once done, click \u201cCreate Cluster\u201d. It will take a few minutes for the cluster to be setup.", "The cluster will be installed with bare-minimum packages. To extract tweets, we\u2019ll be using tweepy. To use that, you will firstly have to install it in the cluster. To do that, click Workspace -> Users.", "Click your email id and then right click in the cascaded section -> Create -> Library", "and then in that section, select PyPI, write \u201ctweepy\u201d in the package area and click \u201cCreate\u201d", "Once done, click \u201cNew Notebook\u201d in the main page of Databricks:", "give a name to your notebook, select Python and click \u201cCreate\u201d", "Once that\u2019s done, a notebook will become available for your use. If you have used Jupyter notebooks before, the UX will appear to be somewhat similar.", "Now with the environment initialized and provisioned, another dependency needs to be catered: to enable integration with Twitter, you need to have a Twitter app created. I won\u2019t go into the specifics of this step however this link provides step by step procedure to do this. Once you\u2019ve registered a Twitter app, you need the following four credentials related to it:", "now we are in the position to actually do coding! I\u2019ll endeavor to explain the code as we proceed along.", "Let\u2019s start off by importing the required modules and initializing the required variables.", "Authentication mechanism while using twitter app is OAuth and tweepy\u2019s APIs make it convenient to perform that using OAuthHandler class in which you specify the Twitter app related credentials. And then use tweepy.API which is a wrapper API provided by Twitter for the rest of the steps:", "The object returned by tweepy.API class provides a number of methods that can be used to extract tweets. The one that we\u2019ll use in this post is user_timeline() function that allows us to specify Twitter handle, number of tweets:", "Many of the parameters are self explanatory. Specifically, setting include_rts to False exclude retweets from the account and tweet_mode as extended gives full text of tweets otherwise it will be truncated. trump_tweets is an object of type tweepy.models.ResultSet. It\u2019s like an iterable that can be traversed and each element in this contains attribute full_text that contains the required text of tweets. So let\u2019s just use Python\u2019s list comprehension to do this task as follows:", "Here\u2019s how the tweets look like when I tried to extract. Yours may vary.", "now let\u2019s save this list in the form of a text file so that we can use them in the second stage of our pipeline. As we\u2019ll be analyzing the tweets using Spark in Databricks in part 2 so using a distributed file system or object store makes sense in this context. That\u2019s where Databricks DBFS (Databricks File System) makes things easier. This topic itself demands great deal of comprehension but at this stage, it would be enough to know that DBFS is also a distributed file system, physicalized on object store depending on the cloud environment (Blob for Azure or S3 for AWS). You can also mount your object stores in DBFS and can access those under its namespace. And lastly, you can use local file system APIs (e.g. of Python) to do read/write on DBFS as well (courtesy of FUSE mount). Thus:", "You can verify that the data has been written successfully in a number of ways. One of the ways is to read the file again to ensure that it has been written correctly:", "This concludes the first part of this blog-post in which the process of extracting tweets from a specific user using Python (via tweepy module) is highlighted along with the configuration steps to use Databricks notebooks.", "After you have extracted the required set of tweets from your specified twitter handle (@realDonaldTrump in this example), the next section in this analytical pipeline is to integrate with Azure Cognitive Services to get sentiment predictions. We\u2019ll use Spark in Databricks to enable processing at scale (with some caveats). As mentioned before that Azure Cognitive Services is a suite of services and for sentiment analysis of the tweets, we will be using Azure Text Analytics API. Also, just to broaden the impact of this post and to add more breadth to your skill-set, I\u2019ll demonstrate how will you be able to do that while using Scala! So let\u2019s get started.", "Firstly, you\u2019ll need to take care of a few dependencies:1. Text analytics API in Azure Cognitive Service \u2014 If you have an Azure subscription (the free trial will work too for this example), you\u2019ll need to provision Text Analytics API in Azure Cognitive Services. The process should be similar to my previous post where I demonstrated how one can use Content Moderation service of Azure Cognitive Services. After the Text Analytics API has been provisioned, you need to grab the following details:", "> Text Analytics API end-point> API authentication key", "once done, your text analytics API will be ready to be consumed from a REST based client, written in a language of your choice (Scala in this case).", "2. Scala libraries \u2014 We will be relying on a couple of Scala libraries to get the job done. Specifically, we\u2019ll require the following ones:> scalaj (to send REST calls to Azure Text Analytics API)> spray json (to parse the Json responses of Azure Text Analytics API that we\u2019ll use for further processing subsequently)", "As we are using Databricks, thus the process of managing these dependencies for your environment will be similar. i.e. You will have to create a library and attach it to the cluster that you launched. For JVM languages, maven is usually the go-to repository where you can find many of your such dependencies. To manage these libraries in Databricks, you will have to provide maven repository coordinates for these (which is consists of (groudpID:artifactID:Version). When you specify these maven repository coordinates, dependency management (like the one being used in Databricks) become able to find these in maven repository, download and install/provision them in your environment. Here\u2019s an example of how you specify maven coordinates of Spray Json library in Databricks:", "You\u2019ll have to do the same for scalaj library. Now coming to the implementation part, it always helps to have an oversight of the workflow that you\u2019ll be implementing and thus our workflow will consist of the following steps:", "Read the tweets from DBFS -> Remove any lines in the tweets file which just have URL in them (as they won\u2019t have any signal of sentiment in them) -> Format each tweet line in the form of a REST call that\u2019s required for Azure Text Analytics API end-point -> send REST calls to Azure Text Analytics API end-point -> Process the results for analytical insights", "With this workflow in view, let\u2019s consider implementation of each step. As a good practice, we\u2019ll firstly create some helper functions that will help us to perform many of the above mentioned tasks.", "Create a Databricks notebook, choose Scala as the language, and in a cell, write this code:", "Let\u2019s understand what\u2019s happening in this code:1. We created a function of the name requestFormatter and it accepts one parameter (givenTweet) of type String.2. The function returns String3. The function creates a Json as per the requirements of Azure Text Analytics API which consists of a key-value pair with key as \u201cdocuments\u201d and value as a list of object consisting of language, id and text fields. These fields are self explanatory. id field in a list should be unique. text is the field where the actual data (tweet) in this case, will be embedded. Also, as documents is a list so you can have multiple objects of the language, id and text fields and you can send up to 5000 objects in one REST call. however for the sake of simplicity, I am just sending one object in one REST POST call.", "In another cell, type the following code:", "Here\u2019s what we are doing in this function:1. The function sendPostRequest accepts three parameters (textAnalyticsUrl represents Azure Text Analytics API end-point URI, subscriptionKey represents the key that you retrieved previously that\u2019ll be used for authentication of your REST calls and requestBody is the data that will be sent as a part of your REST calls2. We introduced a delay of 3 seconds just for this implementation so that Azure doesn\u2019t block our requests. There are better ways to address this limitation.3. Then we send a REST POST call and specify URI, headers (\u201cContent-Type\u201d, \u201capplication/json\u201d, \u201cOcp-Apim-Subscription-Key\u201d, subscriptionKey) and populate body of the request with the Json that we will get with our previous function. 4. Lastly, we return results of the REST response as String from this function which looks of the form:", "where documents object contains a list and specifically score corresponding to the id of the document. The returned score varies from 0 to 1 and it\u2019s the result of the prediction yield after invoking the Azure Text Analytics API. Values close to 0 represent negative sentiments and closer to 1 represent positive.", "This function is employed to remove HTTP lines that may be present in our file of tweets.", "1. The function expects a parameter (textLine of type String) and returns Boolean values (true or false). 2. It makes use of regular expression and looks for a specific pattern in text file where a line is starting with \u201chttp\u201d. It can be refined further indeed but for simplicity sake, let\u2019s use that.3. It then tries to find that pattern in text file. Here, Scala\u2019s pattern matching constructs are used to match against two possibilities: if a match is found i.e Some(x), then value returned will be false else it will return true. The reasoning behind why we are returning these values will become apparent shortly.", "Now with these functions in place, let\u2019s implement the rest of the logic, which interestingly and thanks to Scala being a functional programming language, can be represented in one line of code:", "let\u2019s decipher what\u2019s happening here:1. Firstly, we made use of SparkContext (sc) textFile function which is used to read data from text file (usually from HDFS and in this case DBFS which implements its interfaces). It accepts file path as string and that\u2019s where we specified where our tweets file is present. This function returns RDD of type String where each element corresponds to each line in the file(s)2. The next step is to filter out any line consisting just of http URLs. that\u2019s where we used Spark\u2019s filter transformation. In its parameter, we passed a function (thanks to functional programming again) specifically, removeHttpLines which will operate on each line of the data and will only return those lines which yield true from that function (i.e. which don\u2019t have http at the start of them).3. The next part transforms each line of the filtered text (i.e. http lines removed) and converts (using requestFormatter function ) each tweet into the required Json string of the form:", "3. The next portion then invokes Azure Text Analytics API end-point using the function sendPostRequest", "Upon executing this, no execution will happen thanks to Spark\u2019s lazy execution model. As the data is small and it\u2019s a PoC setting, thus it\u2019s safe to use \u201ccollect\u201d action (however try to avoid this in production settings as it returns data from all the distributed executor nodes of Spark to the driver program thus causing memory overflow challenges).", "Now we have the responses in Scala collection form. Each element of the list is a string (Json) consisting of the response from Azure Text Analytics API and we can\u2019t do much about it in the current state. If you want to answer a few questions like:> What\u2019s the maximum and minimum value of the score?> What\u2019s the average sentiment score in this tweets corpora?> What are the most positive tweets by Trump in this corpora?", "To answer these analytical questions (and many others), one treatment that could be done on the data in this form is to transform the existing Json string to Scala case classes which are optimized for such processing. There can be many ways to do this however I resorted to using spray json library to do this:", "To do this, firstly we will have to create a parser for Json. This involves creating case classes that represent structure of Json as follows:", "and then using spray json constructs to specify the Json\u2019s structure, including the values of key and how different sections are embedded within each other e.g.", "now with these functions and objects created, what\u2019s remaining is to use them in Scala collection to get the desired result:", "The upstated expression should be familiar to you by now but still here is a breakdown understanding of the steps:1. Firstly, we will perform filtering to only consider elements which have \u201cdocuments\u201d section in the Json2. We then parse each Json string and convert to AzureTextAnalyticsResponse case class3. We then just access score of each parsed Json object to get a list just consisting of sentiment scores", "Once we have this, then doing further analysis becomes convenient for example we can calculate average sentiment score as follows:", "The score turned out to be 0.629 which means that the analyzed tweets have slightly positive sentiment on average :-)", "and similarly, we can get the maximum sentiment score of Trump\u2019s tweets:", "which turns out to be 0.99 meaning quite some tweets had quite high degree of positivity :-)", "Thus, in conclusion, we can use this approach to do a number of analysis to address different set of questions. Also, this is a pretty basic implementation with a lot of opportunities of enhancements so would be keen to know what you do with this foundational knowledge. If you struggled to understand some of Scala and Spark concepts, do check out my recent Scala Programming for Big Data Analytics book published by Apress.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Enterprise Data Engineer @ Transurban | Author | Photographer"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff42d68c7e40a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@elahi_irfan?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@elahi_irfan?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "Irfan Elahi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d91dacdb2f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&user=Irfan+Elahi&userId=6d91dacdb2f0&source=post_page-6d91dacdb2f0----f42d68c7e40a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff42d68c7e40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff42d68c7e40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@conkarampelas?utm_source=medium&utm_medium=referral", "anchor_text": "Con Karampelas"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://databricks.com", "anchor_text": "following link"}, {"url": "https://iag.me/socialmedia/how-to-create-a-twitter-app-in-8-easy-steps/", "anchor_text": "this link"}, {"url": "https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html", "anchor_text": "FUSE mount"}, {"url": "http://twitter.com/realDonaldTrump", "anchor_text": "@realDonaldTrump"}, {"url": "https://www.udemy.com/apache-spark-hands-on-course-big-data-analytics/", "anchor_text": "Spark"}, {"url": "https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/", "anchor_text": "Azure Text Analytics API"}, {"url": "https://mvnrepository.com/artifact/org.scalaj/scalaj-http", "anchor_text": "scalaj"}, {"url": "https://mvnrepository.com/artifact/io.spray/spray-json", "anchor_text": "spray json"}, {"url": "https://apress.com/gp/book/9781484248096", "anchor_text": "Scala Programming for Big Data Analytics book"}, {"url": "https://medium.com/tag/scala?source=post_page-----f42d68c7e40a---------------scala-----------------", "anchor_text": "Scala"}, {"url": "https://medium.com/tag/python?source=post_page-----f42d68c7e40a---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/azure-cognitive-service?source=post_page-----f42d68c7e40a---------------azure_cognitive_service-----------------", "anchor_text": "Azure Cognitive Service"}, {"url": "https://medium.com/tag/spark?source=post_page-----f42d68c7e40a---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/databricks?source=post_page-----f42d68c7e40a---------------databricks-----------------", "anchor_text": "Databricks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff42d68c7e40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&user=Irfan+Elahi&userId=6d91dacdb2f0&source=-----f42d68c7e40a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff42d68c7e40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&user=Irfan+Elahi&userId=6d91dacdb2f0&source=-----f42d68c7e40a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff42d68c7e40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff42d68c7e40a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f42d68c7e40a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f42d68c7e40a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@elahi_irfan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@elahi_irfan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Irfan Elahi"}, {"url": "https://medium.com/@elahi_irfan/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "252 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d91dacdb2f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&user=Irfan+Elahi&userId=6d91dacdb2f0&source=post_page-6d91dacdb2f0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F16225527f69f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-cognitive-services-for-sentiment-analysis-of-trumps-tweets-part-1-f42d68c7e40a&newsletterV3=6d91dacdb2f0&newsletterV3Id=16225527f69f&user=Irfan+Elahi&userId=6d91dacdb2f0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}