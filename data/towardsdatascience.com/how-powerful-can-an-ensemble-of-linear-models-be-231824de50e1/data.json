{"url": "https://towardsdatascience.com/how-powerful-can-an-ensemble-of-linear-models-be-231824de50e1", "time": 1683008325.3336508, "path": "towardsdatascience.com/how-powerful-can-an-ensemble-of-linear-models-be-231824de50e1/", "webpage": {"metadata": {"title": "How powerful can an ensemble of linear models be? | by Sarthak Vajpayee | Towards Data Science", "h1": "How powerful can an ensemble of linear models be?", "description": "With the rapid growth of deep learning algorithms in recent years, today they have become a state of the art in AI. And this makes me wonder if the traditional and old school machine learning\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.mercari.com/", "anchor_text": "Mercari", "paragraph_index": 4}, {"url": "https://www.kaggle.com/wiki/RootMeanSquaredLogarithmicError", "anchor_text": "Root Mean Squared Logarithmic Error", "paragraph_index": 5}, {"url": "https://www.kaggle.com/c/mercari-price-suggestion-challenge/data", "anchor_text": "this", "paragraph_index": 8}, {"url": "https://www.pyimagesearch.com/2016/10/17/stochastic-gradient-descent-sgd-with-python/", "anchor_text": "this wonderful blog", "paragraph_index": 63}, {"url": "https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff", "anchor_text": "this", "paragraph_index": 67}, {"url": "https://en.wikipedia.org/wiki/Support_vector_machine", "anchor_text": "this blog", "paragraph_index": 67}, {"url": "https://towardsdatascience.com/entropy-how-decision-trees-make-decisions-2946b9c18c8", "anchor_text": "blog", "paragraph_index": 83}, {"url": "http://uc-r.github.io/gbm_regression", "anchor_text": "here", "paragraph_index": 98}], "all_paragraphs": ["With the rapid growth of deep learning algorithms in recent years, today they have become a state of the art in AI. And this makes me wonder if the traditional and old school machine learning techniques like Linear Regression, Support Vector Machines, etc are still decent enough that they can go head to head with deep learning techniques?To look over the capabilities of these often overlooked machine learning techniques I will be solving a Kaggle competition problem using only traditional machine learning techniques (no neural networks).", "Note: I\u2019ll be using python 3.7 for this project.", "The project is divided into 6 major steps-", "It can be hard to know how much something\u2019s really worth. Small details can mean big differences in pricing. For example, one of these sweaters cost $335 and the other cost $9.99. Can you guess which one\u2019s which?", "Product pricing gets even harder at scale, considering just how many products are sold online. Clothing has strong seasonal pricing trends and is heavily influenced by brand names, while electronics have fluctuating prices based on product specifications.Mercari, Japan\u2019s biggest community-powered shopping app, knows this problem deeply. They\u2019d like to offer pricing suggestions to sellers, but this is tough because their sellers are enabled to put just about anything, or any bundle of things, on Mercari\u2019s marketplace.In this competition, we need to build an algorithm that automatically suggests the right product prices. We\u2019ll be provided with text descriptions of products, and features including details like product category name, brand name, and item condition.", "The evaluation metric for this competition is Root Mean Squared Logarithmic Error. The RMSLE is calculated as:", "Where:\u03f5 is the RMSLE value (score)n is the total number of observations in the (public/private) data set,pi is the prediction of price,ai is the actual sale price for i.log(x) is the natural logarithm of x", "Note that, because of the public nature of this data, this competition is a \u201cKernels Only\u201d competition. So, we need to build a code that executes within an hour on a machine with 16 GB RAM and 4 CPUs.", "The data we\u2019ll be using is provided by Mercari and can be found on Kaggle using this link. The data lists details about products from the Mercari website. Let\u2019s check out one of the products from the website and how it is described in the dataset.", "Let\u2019s import the data using pandas and check the first 5 entries.", "In this section, we\u2019ll be exploring and analyzing the data in depth. We\u2019ll be covering the data feature by feature.", "This is the target feature that we need to predict using the information about the product in the form of other features.Let\u2019s check out the statistical summary of this feature using describe()", "Now we\u2019ll take a look at the histogram of the prices. Here, I\u2019ve used the number of bins as 200.", "We are converting the prices to Normal distribution as it is one of the most well-known distributions in statistics because it fits many natural phenomena and this makes it one of the most easily interpretable distributions that we can do analysis on. Another reason for transforming the data into a normal distribution is that the variance in price is reduced and most of the points are centered around the mean which makes the price prediction much easier for the model.", "I\u2019ve already converted the data into a log form. Here is the histogram of the log(price+1).", "This is a categorical feature that denotes the condition of the item. Let\u2019s check out more about it using value_counts()", "Let\u2019s look at the bar-graph of this feature", "Now let\u2019s compare the price distribution of products with different item_condition_id", "Let\u2019s check out the boxplot and violin plot of the price distribution of products with different item_condition_id.", "The boxplot and violin plots also tell us that the price distributions of items with different item_condition_id are not so different, also the distributions are a bit right-skewed. Products with item_condition_id = 5 have the highest median price whereas products with item_condition_id = 4 have the lowest median price. Most of the products have a price in the range of 1.5 and 5.2", "This is a text type data that tells us about the category of the product.Let\u2019s check out the statistical summary of the feature category name-", "These are string type features that are actually 3 sub-categories joined into 1.Let\u2019s consider the most frequently occurring category name feature \u2018Women/Athletic Apparel/Pants, Tights, Leggings\u2019 as mentioned in the above description. It can be broken down into 3 sub-categories: - sub-category_1: \u2018Women\u2019- sub-category_2: \u2018Athletic Apparel\u2019- sub-category_3: \u2018Pants, Tights, Leggings\u2019To make the visualization for this feature easy, I\u2019ll consider this feature sub-category wise. Let\u2019s divided the data sub-category wise.", "Let\u2019s plot the bar graph of sub-category 1", "Let\u2019s check the distribution of sub_category_1 and log of price", "Now let\u2019s take a look at the violin plots of sub_category_1", "Let\u2019s check the statistical description of sub_category_2:", "Bar graph of the top 20 categories in sub_category_2", "Let\u2019s check the statistical description of sub_category_3:", "This is another text type feature that denotes the brand the product belongs to. Let\u2019s check out the statistical summary of the feature brand_name.", "Let\u2019s check the histogram of the top 20 brands", "Let\u2019s see the bar-plot of the top 20 brands with their mean product price.", "Let\u2019s see the bar-plot of the top 20 brands with maximum product price", "This is a numerical categorical data type that can take 2 values, 0s or 1sLet\u2019s check out its statistical description.", "Let\u2019s compare the log of price distribution of products with different shipping.", "This is a text type feature that describes the product. Let\u2019s take a look at some of these.", "We\u2019ll be using this feature as is after performing some NLP techniques which will be discussed later in this blog.Another thing that we can do with this feature is, calculate it\u2019s word-length i.e. the number of words this feature contains for each product and do some analysis on that.Let\u2019s check the statistical summary of the word_length of the item description.", "Let\u2019s plot the histogram of item_description_word_length,", "Let\u2019s try to convert this into a Normal distribution by taking the log of the word length. Here is what the distribution looks like.", "Now let\u2019s see how the log(item_word_length) affects the price of the item", "Finally, let\u2019s check out the last feature that is the name of the product. This is also a text type feature and we\u2019ll be performing NLP on it later but first, let\u2019s do some analysis on it by plotting the histogram of the number of words in the \u2018name\u2019 feature.", "Let\u2019s see how the prices vary with the number of words in the product\u2019s name.", "In this step, we\u2019ll be cleaning the data and make it ready for modeling.Remember that we have 6 features out of which, we have:- 4 text features: Name, description, brand name, and category- 2 categorical features: shipping and the item_condition_id", "Let\u2019s start by cleaning the text features and for that, we\u2019ll define some functions-", "The function works by decontracting words like \u201cwe\u2019ll\u201d to \u201cwe will\u201d, \u201ccan\u2019t\u201d to \u201ccannot\u201d, \u201cwe\u2019re\u201d to \u201cwe are\u201d etc. This step is necessary because we do not want our model to treat phrases like \u201cwe\u2019re\u201d and \u201cwe are\u201d differently.", "In the above code block, I\u2019ve defined a list containing the stop words. Stop words are words that do not add much semantic or literal meaning to sentences. Most of these are contracted representations of words or not so important words like \u2018a\u2019, \u2018at\u2019, \u2018for\u2019 etc, and symbols.", "Now we\u2019ll define a function that takes the sentences, and uses the deconcatenated function and stopwords list to clean and return processed text.", "Time to clean our text data using preprocess_text() function.", "Note that the df[\u2018name\u2019] column contains both \u2018name\u2019 and \u2018brand_name\u2019 features concatenated and preprocessed, similarly df[\u2018text\u2019] feature contains \u2018item_description\u2019 and \u2018category_name\u2019 features concatenated and preprocessed.", "Let\u2019s proceed to the further processes but before that, we need to split the data into train and cross-validation sets. Also, we\u2019ll be converting the target values i.e. the prices into log form so that they are normally distributed and the RMSLE(root mean squared log error) is easy to compute.", "Now it\u2019s time to convert these preprocessed text features into a numerical representation. I\u2019ll be using TF-IDF vectorizer for this process. We\u2019ll start with the feature \u2018name\u2019", "Let\u2019s also process the remaining categorical features starting with \u2018shipping\u2019since this feature takes only 2 values 0 and 1, we do not need to perform some special kind of encoding for these, let\u2019s keep them as they are.", "The second categorical feature that also happens to be an ordinal feature is \u2018item_condition_id\u2019. Remember these can take 5 integer values (1\u20135) so we\u2019ll also keep these as they are.", "Notice that I\u2019ve used -1 because this feature contains 5 types of values between (1\u20135) so -1 converts them to a range of (0\u20134). This will give us an advantage while converting to sparse data.", "Now as the final step, we\u2019ll be stacking these features column-wise.", "I will now convert this preprocessed data into a binary form in which the values will only be either 1s or 0s.", "The advantage of this step is that now we\u2019ll be having 2 datasets with a good variance to work on.", "It\u2019s time for testing some models on our data. The models that we\u2019ll be trying are-- Ridge regressor- Linear SVR- SGD Regressor- Random Forest Regressor- Decision Tree Regressor- XGBoost Regressor", "We use linear regression to find the optimal hyperplane (the red line in the above gif) such that the loss or square of the sum of distances of each point from the plane/line is minimum. We can notice that the loss will be minimum if we consider the line obtained at iterations=28.Ridge regression is also known as Linear Regression with L2 Regularization which means it uses the sum of the square of weights as a penalty. The penalty term is added to restrict the model from overfitting (capturing noise).The Ridge regression has just 1 hyperparameter \u03bb that is multiplied with the penalty/regularization term and it decides the degree of underfitting the model undergoes. The greater the value of \u03bb, the more we under-fit.alpha is simply the regularization strength and it must be a positive float. So as alpha increases, the underfitting also increases.", "Okay, so our Ridge returned a loss of 0.4232 on cv data.", "Now we\u2019ll be using the Ridge regressor on the binary data", "Our Ridge regressor returned a loss of 0.4335 on cv data.", "Let\u2019s Try SGD-Regressor (as SVR) on Binary data", "Let\u2019s quickly refresh what SGD is and how it works. Remember the loss that I mentioned in Ridge regression? Well, there are different types of losses, let\u2019s understand this geometrically. If a regression problem is all about finding the optimal hyperplane that best fits our data, a loss simply means how much our data differs from the hyperplane. So, a low loss means that the points don\u2019t differ much from our hyperplane and the model performs well and vice-versa.In the case of linear regression, the loss is a squared loss and it is obtained by taking the sum of squared distances of data points from the hyperplane divided by the number of terms.", "Loss functions are important because they define what the hyperplane will be like. There are other algorithms called the Gradient Descent that make use of these loss-functions and update the parameters of the hyperplane such that it perfectly fits the data. The goal here is to minimize the loss. SGD is one optimized algorithm that updates the parameters of the hyperplane by reducing the loss step by step. It is done by calculating the gradient of the loss function with respect to the features and then using those gradients to descent towards the minima. In the above diagram (left part), we can see how the algorithm is reaching the minima of loss function by taking the right step downhill, and with each step in the correct direction, the parameters are getting updated which leads to a better fitting hyperplane (right part). To know more about the Stochastic Gradient Descent (SGD) algorithm you can check this wonderful blog.", "Here are some other common losses but we\u2019ll be using \u2018Huber\u2019, \u2018epsilon_insensitive\u2019, and \u2018squared_epsilon_insensitive\u2019 for the hyperparameter tuning of this model.", "The random search cross-validation tells us that \u2018squared_epsilon_insensitive\u2019 loss with L2 regularization works best for this data. By the way, \u2018squared_epsilon_insensitive\u2019 loss is one of the losses used by another well-known machine learning algorithm Support Vector Machine which uses margin maximization technique by making the use of support vectors to generate a better fitting hyperplane.", "But why is margin maximization so important that it makes SVM one of the top ML algorithms? Let\u2019s quickly understand this using a simple classification problem where we need to find an optimal hyperplane that separates the blue and red points.", "One fun fact is that the flat bottom part in the \u2018squared_epsilon_insensitive\u2019 loss is because of this margin maximization trick. You can refer to this and this blog to learn more about SVR.", "SGD Regressor (as SVR) returned a loss of 0.4325\u2026 on cv data.", "Let\u2019s try SGD regressor (as linear regressor) on binary data", "Here we\u2019ll be performing all the previous step procedures but on binary data.", "The random search cross-validation tells us that \u2018squared_loss\u2019 loss with L2 regularization works best for this data. By the way, this setup of squared_loss with L2 regularization sounds familiar right? This is exactly what we used in the Ridge regression model. Here we are approaching this from an optimization problem\u2019s perspective because SGDRegressor gives us much more hyperparameters to play around with and fine-tune our model.", "SGD Regressor (as linear regressor) returned a loss of 0.4362 on cv data.", "Let\u2019s try Support Vector Regressor on normal data. The hyperparameter here is C that is also the reciprocal of alpha which we discussed in Ridge regression.", "Linear SVR returned a loss of 0.4326 on the CV of normal data.", "Now we\u2019ll try Support Vector Regressor on binary data. The hyperparameter here is again C that is also the reciprocal of alpha which we discussed in Ridge regression.", "Linear SVR returned a loss of 0.4325 on the cv of binary data.", "The tree-based models below were taking too much time to fit (more than 60 mins) so I reduced the features using Ridge regressor on binary data.", "Note: Another dimensionality technique that I tried was truncated-SVD but it required a lot of RAM (more than 16 GB) for computation and since this is a kernel challenge, using the complete data didn\u2019t make much sense.", "Selecting top features for tree-based models:", "Our first tree-based model is a Decision Tree, before using this on our dataset, let\u2019s first quickly understand how it works.", "Decision Trees are made up of simple if-else statements and using these conditions they decide how to predict the price of a product given its name, conditioning, etc. Geometrically speaking, they fit on the data using several hyperplanes that are parallel to the axes.While training a tree, the tree learns these if-else statements by using and verifying the train data. And when it is trained, it uses these learned if-else conditions to predict the value of test data.But how does it decide how to split the data or what feature to consider while splitting the data and construct a complete tree?Well, it uses something called entropy which is a measure of certainty to construct the tree.Decision trees have several hyperparameters but we\u2019ll be considering only the 2 important ones-- max_depth: It denotes the maximum depth of a decision tree. So if the max_depth is supposed 4, while training, the tree constructed will not have a depth more than 4. - min_samples_split: It denotes the minimum number of data points that must be present to perform a split or consider an if-else condition on it. So if the min_samples_split is supposed 32, while training, the tree constructed will not apply an if-else condition if it sees less than 32 data points.", "Both the above hyperparameters restrict a decision tree from either underfitting or overfishing. A high max_depth and a low min_samples_split value makes decision trees more prone to overfitting and vice-versa.", "I will not go into the internal working of decision trees in this blog since it will make it too long, to learn more about the internal working of a decision tree, you can check out this awesome blog.", "Let\u2019s perform some hyperparameter tuning on our decision tree using RandomSearchCV and check what are the best hyperparameters for our tree.", "The best hyperparameter values returned are max_depth=64 and min_samples_split = 64. Now let\u2019s check the loss obtained after training a decision tree on these hyperparameters.", "The loss values are not that great given that it took 14 mins to train. Our Linear models have outperformed the decision tree model by far.", "Now let\u2019s use another awesome tree-based model or I should say models to model our data.Random forests are ensembles that are made up of multiple models. The idea is to use random parts of the data to train multiple models and then use the average predictions from these multiple models as the final value. This makes sense because of training several models using random parts of complete data creates models that are to some extent biased in different ways. Now by taking the average prediction from all these models, in the end, results in a better-predicted value.", "The name Random Forest comes from Bootstrap sampling which we use in sampling data randomly from the training dataset and since we use multiple decision trees as our base models, it has the word forest.", "The above diagram denotes how Random Forest trains different base learners denoted as Tree 1, Tree 2, \u2026 using randomly sampled data and then collects and averages the predictions from these trees.", "Random Forest has multiple hyperparameters but for our data, we\u2019ll be using just 2:- n_estimator: this denotes the number of base models that we want our random forest model to have.- max_depth: This denotes the maximum depth of each base model i.e. the decision tree.", "Let\u2019s train a random forest model and perform some hyperparameter tuning on it.", "The training time for this model was about 23 mins.", "We can see that this model does not perform well on the given dataset and the results are not at all good.", "Here I\u2019ve used the same model but with some changes in the architecture.I\u2019ve increased the max_depth to 4 and the number of base learners to 200.Let\u2019s see how the model performs.", "The training time for this model was about 65 mins.", "The results are slightly better than the previous Random forest model but still not even close to our Linear models.", "This is the final tree-based model that we\u2019ll be trying and it is called XGBoost.XGBoost is a slightly enhanced version of GBDT which again is an ensemble modeling technique. In Gradient boosting, the purpose is to reduce the variance or reduce the underfitting behavior on a dataset. Let\u2019s see how it works.", "In GBDT, we start by training our first base model which is typically a high bias decision tree using the train data, then we take the predicted values from this model and calculate the error which is defined by how much the predictions differ from the actual values. Now we train our second base learner but this time instead of using only the train data, we use also use the error obtained from our first base learner and again we take the predicted values from this model and calculate the error. This goes on till all the base learners are covered and as we train the base learners one by one, we notice that the error value slowly diminishes. You can read more about GBDT here.XGBoost is a slightly modified version of GBDT and it uses techniques like row sampling and column sampling which are techniques from Random Forest to construct the base-learners.", "Let\u2019s quickly check out the code for XGBoost, I\u2019ll be using 2 hyperparameters:- n_estimators: which denotes the number of base-learners which are decision tree models.- max_depth: which denotes the maximum depth of the base learner decision tree.", "The model took about 27 mins to train.", "The results are not as bad as random forest but not as good as linear models also.", "We can see a decent amount of improvement from the previous model but it took the model 78 mins to train.", "In the above table, we can see that the tree-based models are taking too much time to compute, in fact, the data I\u2019m using for tree-based is much smaller, I\u2019m using only the top selected binary features from Ridge regressor. So the new data has only around 236k features instead of the original 700k that other linear models are trained on. We can also observe that the minimum loss on cross-validation data that we were able to obtain is 0.4232\u2026 let\u2019s try to reduce this further using ensemble modeling.", "The Linear models have outperformed other tree-based models so I\u2019ll be using these to create an Ensemble.", "Let\u2019s concatenate the results obtained from the top 6 linear models.", "Now let\u2019s quickly test a simple ensemble that takes these features as input and computes the output as a mean of these values.", "We can observe that the loss has increased slightly, which means that this method alone is not decent enough to produce good scores.", "Now let\u2019s check the correlation between these new features because all of them are from linear models and produce a similar loss. If they are heavily correlated, they will not improve the overall loss much.", "To tackle this, I increased the dimensionality of this data by adding the top features that were gathered from the Linear model on binary data that we used to train the tree-based models.", "It\u2019s time to try different models on these newly generated features to see if we can improve the loss.", "Let\u2019s try SGD Regressor using different hyperparameters", "The above code block represents the best hyperparameters returned by RandomSearchCV.", "The CV loss is not up to the mark since we already have a loss of 0.4232\u2026 and we are looking for a loss lower than that.", "Let\u2019s try Linear SVR and Ridge regressor on the new features", "Training a Ridge regressor with alpha = 100000", "Okay, by looking at the above table we can tell that the Ridge and LinearSVR models yield the best results, so we\u2019ll be using these to generate one more and the final layer of our ensemble.", "Let\u2019s quickly fit the data using these models and concatenate the output that we\u2019ll feed as input to our final ensemble layer.", "We\u2019ll now create the final layer of our ensemble using the generated output from the previous layer models. We\u2019ll be using some linear models but before that, let\u2019s test the simple mean results.", "The results are better than the LinearSVR model alone but the Ridge still outperforms every model till now.", "Let\u2019s try some linear models now for the final layer:", "Let\u2019s try Ridge and Linear-SVR as the final layer model", "Here are all the models that have been used for the ensemble, compared in a tabular form.", "Finally, let\u2019s predict the prices of the test dataset and check how our ensemble performs on the Kaggle leaderboard.", "Thank you for reading the blog. I hope it was useful for some of you aspiring to do projects on machine-learning, ensemble modeling, data processing, data visualizing.", "And if you have any doubts regarding this project, please leave a comment in the response section or in the GitHub repo of this project.", "Learning something new epoch by epoch."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F231824de50e1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@itssarthakvajpayee?source=post_page-----231824de50e1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----231824de50e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Sarthak Vajpayee"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd850bda2ea8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=post_page-d850bda2ea8c----231824de50e1---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F231824de50e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=-----231824de50e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F231824de50e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&source=-----231824de50e1---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www.mercari.com/", "anchor_text": "Mercari"}, {"url": "https://www.kaggle.com/wiki/RootMeanSquaredLogarithmicError", "anchor_text": "Root Mean Squared Logarithmic Error"}, {"url": "https://www.kaggle.com/c/mercari-price-suggestion-challenge/data", "anchor_text": "this"}, {"url": "https://www.mercari.com/", "anchor_text": "https://www.mercari.com/"}, {"url": "https://gifer.com/en/gifs/gradient", "anchor_text": "https://gifer.com/en/gifs/gradient"}, {"url": "https://www.pyimagesearch.com/2016/10/17/stochastic-gradient-descent-sgd-with-python/", "anchor_text": "this wonderful blog"}, {"url": "https://aws.amazon.com/blogs/machine-learning/train-faster-more-flexible-models-with-amazon-sagemaker-linear-learner/", "anchor_text": "https://aws.amazon.com/blogs/machine-learning/train-faster-more-flexible-models-with-amazon-sagemaker-linear-learner/"}, {"url": "https://www.researchgate.net/figure/Schematic-of-the-one-dimensional-support-vector-regression-SVR-model-Only-the-points_fig5_320916953", "anchor_text": "https://www.researchgate.net/figure/Schematic-of-the-one-dimensional-support-vector-regression-SVR-model-Only-the-points_fig5_320916953"}, {"url": "https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff", "anchor_text": "https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff"}, {"url": "https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff", "anchor_text": "this"}, {"url": "https://en.wikipedia.org/wiki/Support_vector_machine", "anchor_text": "this blog"}, {"url": "https://www.datasciencecentral.com/profiles/blogs/the-complete-guide-to-decision-trees", "anchor_text": "https://www.datasciencecentral.com/profiles/blogs/the-complete-guide-to-decision-trees"}, {"url": "https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html", "anchor_text": "https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html"}, {"url": "https://towardsdatascience.com/entropy-how-decision-trees-make-decisions-2946b9c18c8", "anchor_text": "blog"}, {"url": "https://towardsdatascience.com/random-forest-and-its-implementation-71824ced454f", "anchor_text": "https://towardsdatascience.com/random-forest-and-its-implementation-71824ced454f"}, {"url": "https://github.com/bgreenwell", "anchor_text": "https://github.com/bgreenwell"}, {"url": "http://uc-r.github.io/gbm_regression", "anchor_text": "http://uc-r.github.io/gbm_regression"}, {"url": "http://uc-r.github.io/gbm_regression", "anchor_text": "here"}, {"url": "https://www.kaggle.com/c/mercari-price-suggestion-challenge/submissions", "anchor_text": "https://www.kaggle.com/c/mercari-price-suggestion-challenge/submissions"}, {"url": "https://www.kaggle.com/c/mercari-price-suggestion-challenge/discussi", "anchor_text": "https://www.kaggle.com/c/mercari-price-suggestion-challenge/discussi"}, {"url": "https://www.youtube.com/watch?v=QFR0IHbzA30", "anchor_text": "https://www.youtube.com/watch?v=QFR0IHbzA30"}, {"url": "https://youtu.be/_PwhiWxHK8o", "anchor_text": "https://youtu.be/_PwhiWxHK8o"}, {"url": "https://youtu.be/UHBmv7qCey4", "anchor_text": "https://youtu.be/UHBmv7qCey4"}, {"url": "https://www.appliedaicourse.com/", "anchor_text": "https://www.appliedaicourse.com/"}, {"url": "https://github.com/SarthakV7/mercari_kaggle", "anchor_text": "https://github.com/SarthakV7/mercari_kaggle"}, {"url": "http://www.linkedin.com/in/sarthak-vajpayee", "anchor_text": "www.linkedin.com/in/sarthak-vajpayee"}, {"url": "https://medium.com/tag/data-science?source=post_page-----231824de50e1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----231824de50e1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----231824de50e1---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/kaggle?source=post_page-----231824de50e1---------------kaggle-----------------", "anchor_text": "Kaggle"}, {"url": "https://medium.com/tag/python?source=post_page-----231824de50e1---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F231824de50e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=-----231824de50e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F231824de50e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=-----231824de50e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F231824de50e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=post_page-----231824de50e1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----231824de50e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd850bda2ea8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=post_page-d850bda2ea8c----231824de50e1---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb72ebbfba4df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&newsletterV3=d850bda2ea8c&newsletterV3Id=b72ebbfba4df&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=-----231824de50e1---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Written by Sarthak Vajpayee"}, {"url": "https://medium.com/@itssarthakvajpayee/followers?source=post_page-----231824de50e1--------------------------------", "anchor_text": "136 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd850bda2ea8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=post_page-d850bda2ea8c----231824de50e1---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb72ebbfba4df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-powerful-can-an-ensemble-of-linear-models-be-231824de50e1&newsletterV3=d850bda2ea8c&newsletterV3Id=b72ebbfba4df&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=-----231824de50e1---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/ai-based-indian-license-plate-detector-de9d48ca8951?source=author_recirc-----231824de50e1----0---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=author_recirc-----231824de50e1----0---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=author_recirc-----231824de50e1----0---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Sarthak Vajpayee"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----231824de50e1----0---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/ai-based-indian-license-plate-detector-de9d48ca8951?source=author_recirc-----231824de50e1----0---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "AI-based Indian license plate detector.Inspiration: The guy who hit my car and got away with it!"}, {"url": "https://towardsdatascience.com/ai-based-indian-license-plate-detector-de9d48ca8951?source=author_recirc-----231824de50e1----0---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "\u00b711 min read\u00b7Sep 7, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fde9d48ca8951&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-based-indian-license-plate-detector-de9d48ca8951&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=-----de9d48ca8951----0-----------------clap_footer----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/ai-based-indian-license-plate-detector-de9d48ca8951?source=author_recirc-----231824de50e1----0---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde9d48ca8951&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-based-indian-license-plate-detector-de9d48ca8951&source=-----231824de50e1----0-----------------bookmark_preview----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----231824de50e1----1---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----231824de50e1----1---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----231824de50e1----1---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----231824de50e1----1---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----231824de50e1----1---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----231824de50e1----1---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----231824de50e1----1---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----231824de50e1----1-----------------bookmark_preview----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----231824de50e1----2---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----231824de50e1----2---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----231824de50e1----2---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----231824de50e1----2---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----231824de50e1----2---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----231824de50e1----2---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----231824de50e1----2---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----231824de50e1----2-----------------bookmark_preview----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-bert-bidirectional-encoder-representations-from-transformers-45ee6cd51eef?source=author_recirc-----231824de50e1----3---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=author_recirc-----231824de50e1----3---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=author_recirc-----231824de50e1----3---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Sarthak Vajpayee"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----231824de50e1----3---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/understanding-bert-bidirectional-encoder-representations-from-transformers-45ee6cd51eef?source=author_recirc-----231824de50e1----3---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "Understanding BERT \u2014 (Bidirectional Encoder Representations from Transformers)Part 2/3 of Transformers vs Google QUEST Q&A Labeling (Kaggle top 5%)."}, {"url": "https://towardsdatascience.com/understanding-bert-bidirectional-encoder-representations-from-transformers-45ee6cd51eef?source=author_recirc-----231824de50e1----3---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": "\u00b710 min read\u00b7Aug 6, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F45ee6cd51eef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-bert-bidirectional-encoder-representations-from-transformers-45ee6cd51eef&user=Sarthak+Vajpayee&userId=d850bda2ea8c&source=-----45ee6cd51eef----3-----------------clap_footer----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-bert-bidirectional-encoder-representations-from-transformers-45ee6cd51eef?source=author_recirc-----231824de50e1----3---------------------dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F45ee6cd51eef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-bert-bidirectional-encoder-representations-from-transformers-45ee6cd51eef&source=-----231824de50e1----3-----------------bookmark_preview----dedd68d1_5b4c_4dc0_85fd_f93a7eaf6df0-------", "anchor_text": ""}, {"url": "https://medium.com/@itssarthakvajpayee?source=post_page-----231824de50e1--------------------------------", "anchor_text": "See all from Sarthak Vajpayee"}, {"url": "https://towardsdatascience.com/?source=post_page-----231824de50e1--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----231824de50e1----0-----------------bookmark_preview----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----231824de50e1----1-----------------bookmark_preview----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----231824de50e1----0---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----231824de50e1----0-----------------bookmark_preview----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Albers Uzila"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Wanna Break into Data Science in 2023? Think Twice!It won\u2019t be smooth sailing for you"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "\u00b711 min read\u00b7Dec 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&user=Albers+Uzila&userId=159e5ce51250&source=-----26842e9a87fe----1-----------------clap_footer----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----231824de50e1----1---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&source=-----231824de50e1----1-----------------bookmark_preview----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----231824de50e1----2---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----231824de50e1----2---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----231824de50e1----2---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Josep Ferrer"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----231824de50e1----2---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----231824de50e1----2---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Stop doing this on ChatGPT and get ahead of the 99% of its usersUnleash the Power of AI Writing with Effective Prompts"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----231824de50e1----2---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "\u00b78 min read\u00b7Mar 31"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&user=Josep+Ferrer&userId=8213af8f3ccf&source=-----f3441bf7a25a----2-----------------clap_footer----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----231824de50e1----2---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "71"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&source=-----231824de50e1----2-----------------bookmark_preview----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----231824de50e1----3---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----231824de50e1----3---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----231824de50e1----3---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----231824de50e1----3---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----231824de50e1----3---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----231824de50e1----3---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----3-----------------clap_footer----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----231824de50e1----3---------------------bfdb9418_c757_4303_9063_4cb872f7c0ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----231824de50e1----3-----------------bookmark_preview----bfdb9418_c757_4303_9063_4cb872f7c0ca-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----231824de50e1--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----231824de50e1--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----231824de50e1--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}