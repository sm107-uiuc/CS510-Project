{"url": "https://towardsdatascience.com/on-policy-v-s-off-policy-learning-75089916bc2f", "time": 1683010895.531977, "path": "towardsdatascience.com/on-policy-v-s-off-policy-learning-75089916bc2f/", "webpage": {"metadata": {"title": "On-Policy v/s Off-Policy Learning | by Abhishek Suran | Towards Data Science", "h1": "On-Policy v/s Off-Policy Learning", "description": "In this article, we will try to understand the difference b/w On-Policy learning and Off-policy learning, which may be a bit confusing for people new to reinforcement learning. And will dive into the\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["In this article, we will try to understand the difference b/w On-Policy learning and Off-policy learning, which may be a bit confusing for people new to reinforcement learning. And will dive into the concept of Important sampling for Off-Policy learning. Let us first take a look at two terms before moving further.", "On-Policy learning algorithms are the algorithms that evaluate and improve the same policy which is being used to select actions. That means we will try to evaluate and improve the same policy that the agent is already using for action selection. In short , [Target Policy == Behavior Policy]. Some examples of On-Policy algorithms are Policy Iteration, Value Iteration, Monte Carlo for On-Policy, Sarsa, etc.", "Off-Policy learning algorithms evaluate and improve a policy that is different from Policy that is used for action selection. In short, [Target Policy != Behavior Policy]. Some examples of Off-Policy learning algorithms are Q learning, expected sarsa(can act in both ways), etc.", "Note: Behavior policy must cover the target policy i.e pi(a|s) > 0 where b(a|s) > 0.", "Some benefits of Off-Policy methods are as follows:", "As of now, we know the difference b/w off-policy and on-policy. So the question that arises is how can we get the expectation of state values under a policy while following another policy. This is where Important Sampling comes handy. Let us understand with the monte Carlo update rule.", "As you can see, the update rule consists of an average of all the sampled rewards from a state. These rewards are sampled by following behavior policy b(a|s), But we want to estimate values for target policy pi(a|s) and need rewards sampled from target policy pi(a|s). We can do this by simply multiplying \u2018\u03c1\u2019 with every reward that is sampled from behavior policy. The value of \u2018\u03c1\u2019 is equal to the probability of trajectory under target policy pi(a|s) divided by probability of trajectory under behavior policy b(a|s). These probabilities of trajectory are defined as the probability of taking action \u2018At\u2019 by an agent in the state St\u2019 and moves into state \u2018St+1' then taking action \u2018At+1\u2019 and so on until time T. This probability can be split into two parts i.e probability of taking action \u2018At\u2019 in some state \u2018St\u2019 and the probability of ending up in some state \u2018St+1\u2019 by taking action \u2018At\u2019 in the state \u2018S\u2019. In short stochastic policy and stochastic environment.", "Consider a random variable \u2018x\u2019 is being sampled from probability distribution \u2018b\u2019 and we want to estimate the expected value of \u2018x\u2019 with respect to target distribution \u2018pi\u2019. Expectation can be written as", "Now, we can multiply with the probability of sampling x via \u2018b\u2019. By shifting b(x) below pi(x) we got our important sampling ratio \u2018\u03c1\u2019.", "Now, if we treat x\u03c1(x) as a new variable then we can write it as expectation under \u2018b\u2019.", "Now the expectation from data can we write as a weighted sample average where \u2018\u03c1\u2019 are used as weights.", "Now we can sample \u2018x\u2019 from \u2018b\u2019 and can estimate its expected value under \u2018pi\u2019 using the above formula.", "So, this concludes this article. Thank you for reading, hope you enjoy and was able to understand what I wanted to explain. Hope you read my upcoming articles. Hari Om\u2026\ud83d\ude4f", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F75089916bc2f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----75089916bc2f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----75089916bc2f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@abhisheksuran?source=post_page-----75089916bc2f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@abhisheksuran?source=post_page-----75089916bc2f--------------------------------", "anchor_text": "Abhishek Suran"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F29d27a402526&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&user=Abhishek+Suran&userId=29d27a402526&source=post_page-29d27a402526----75089916bc2f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75089916bc2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75089916bc2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://app.diagrams.net/", "anchor_text": "https://app.diagrams.net/"}, {"url": "https://www.coursera.org/specializations/reinforcement-learning", "anchor_text": "Reinforcement LearningOffered by University of Alberta. The Reinforcement Learning Specialization consists of 4 courses exploring the power\u2026www.coursera.org"}, {"url": "https://mitpress.mit.edu/books/reinforcement-learning-second-edition", "anchor_text": "Reinforcement Learning, Second EditionThe significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most\u2026mitpress.mit.edu"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----75089916bc2f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----75089916bc2f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----75089916bc2f---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/technology?source=post_page-----75089916bc2f---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----75089916bc2f---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F75089916bc2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&user=Abhishek+Suran&userId=29d27a402526&source=-----75089916bc2f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F75089916bc2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&user=Abhishek+Suran&userId=29d27a402526&source=-----75089916bc2f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F75089916bc2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----75089916bc2f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F75089916bc2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----75089916bc2f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----75089916bc2f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----75089916bc2f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----75089916bc2f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----75089916bc2f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----75089916bc2f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----75089916bc2f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----75089916bc2f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----75089916bc2f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@abhisheksuran?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@abhisheksuran?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Abhishek Suran"}, {"url": "https://medium.com/@abhisheksuran/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "81 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F29d27a402526&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&user=Abhishek+Suran&userId=29d27a402526&source=post_page-29d27a402526--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa2377f3ed13d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-policy-v-s-off-policy-learning-75089916bc2f&newsletterV3=29d27a402526&newsletterV3Id=a2377f3ed13d&user=Abhishek+Suran&userId=29d27a402526&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}