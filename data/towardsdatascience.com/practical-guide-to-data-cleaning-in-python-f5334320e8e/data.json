{"url": "https://towardsdatascience.com/practical-guide-to-data-cleaning-in-python-f5334320e8e", "time": 1683010493.088591, "path": "towardsdatascience.com/practical-guide-to-data-cleaning-in-python-f5334320e8e/", "webpage": {"metadata": {"title": "Practical Guide to Data Cleaning in Python | by Asad Mumtaz | Towards Data Science", "h1": "Practical Guide to Data Cleaning in Python", "description": "A step by step guide to performing basic data cleaning, outlier detection, and missing values' imputation strategies in Python for Machine Learning"}, "outgoing_paragraph_urls": [{"url": "https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century", "anchor_text": "sexiest job of the 21st century", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/how-to-avoid-potential-machine-learning-pitfalls-a08781f3518e", "anchor_text": "previous articles", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Ordinal_data", "anchor_text": "ordinal", "paragraph_index": 15}, {"url": "https://en.wikipedia.org/wiki/Categorical_variable", "anchor_text": "categorical", "paragraph_index": 15}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html", "anchor_text": "VarianceThreshold", "paragraph_index": 20}, {"url": "https://en.wikipedia.org/wiki/Interquartile_range", "anchor_text": "IQR", "paragraph_index": 30}, {"url": "https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html", "anchor_text": "documentation", "paragraph_index": 32}, {"url": "https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf", "anchor_text": "here", "paragraph_index": 32}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html", "anchor_text": "LocalOutlierFactor", "paragraph_index": 33}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html", "anchor_text": "SimpleImputer", "paragraph_index": 41}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "Pipeline", "paragraph_index": 42}, {"url": "https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators", "anchor_text": "documentation", "paragraph_index": 42}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html", "anchor_text": "KNNImputer", "paragraph_index": 48}, {"url": "http://www.finlyticshub.com", "anchor_text": "me", "paragraph_index": 53}, {"url": "https://machinelearningmastery.com/", "anchor_text": "Machine Learning Mastery", "paragraph_index": 55}, {"url": "http://www.finltyicshub.com", "anchor_text": "www.finltyicshub.com", "paragraph_index": 58}], "all_paragraphs": ["There\u2019s just this one tiny hiccup before you dive into the fancy world of machine learning (ML) algorithms whereby you try to predict the future: Data Preparation or Data Preprocessing.", "Data preparation is the unsexy bit of the infamous sexiest job of the 21st century.", "Training ML algorithms and utilizing them to predict the target variable is the easy bit, thanks to various dedicated libraries and packages available in Python and R. However, the age-old adage of Garbage In, Garbage Out (GIGO) still holds in the data science and ML world.", "Data preparation activities transform raw data into a form, shape, and format that can be effectively and efficiently used by ML algorithms. It forms a vital component of the ML pipeline and can make or break an ML process.", "Practitioners agree that the vast majority of time in building a machine learning pipeline is spent on feature engineering and data cleaning. Yet, despite its importance, the topic is rarely discussed on its own.\u00b9", "Data cleaning is just one component of data preparation activities that also include feature selection, data transformation, feature engineering, and dimensionality reduction.", "Data processing activities, and data cleaning as well by definition, are unique for each set of raw data given the individual peculiarities inherent in a practical ML project. Despite that, certain activities are box-standard and should be applied, or at least checked on raw data before model training.", "Regardless of the type of data errors to be fixed, data cleaning activities usually consist of two phases: (1) error detection, where various errors and violations are identified and possibly validated by experts; and (2) error repair, where updates to the database are applied (or suggested to human experts) to bring data to a cleaner state suitable for downstream applications and analytics.\u00b2", "A word of caution before we explore the various standard data cleaning activities. As noted in one of my previous articles: all the following operations should be performed on the numerical training dataset after splitting your entire data into train/test/validation subsets to avoid data leakage. Only then once you have a clean training dataset, repeat the same set of activities on the test (and validation) datasets, and on the target variables, if required.", "In all code snippets below and following the conventional notation, X_train refers to the training input dataset.", "The following operations should form the starting point of your ML project, to be applied to every data that you get your hands on.", "Zero-variance predictors refer to input features that contain a single value across the entire spectrum of observations. Accordingly, they do not add any value to the prediction algorithm since the target variable is not affected by the input value, making them redundant. Some ML algorithms might also run into unexpected errors or output wrong results.", "Pandas provides a short and sweet function to count and list the number of unique values in each column of a Pandas dataframe:", "Dropping specific columns from a Pandas dataframe is simple enough through X_train.drop(columns=['column_A', 'column_B'], inplace=True) when there are not many columns to be dropped. A more robust way to achieve the same outcome with multiple zero-variance columns is:", "The above code will drop all columns that have a single value and update the X_train dataframe.", "Special consideration should be given to columns that have very few numbers of unique values (aka, low-variance, or near-zero variance). Such columns are not automatic candidates to be dropped from the dataset. For example, ordinal or categorical columns, by design, are not expected to have a high number of unique values.", "Intuitively, we can naively drop low-variance columns, but what if such predictors were actually informative for model learning? For example, assume that a binary feature in a classification problem has lots of zeroes and few ones (near-zero variance predictor). The target variable is always the same when this input feature is equal to one; however, it can be either of the possible target values in case this feature is zero. It is certainly justified to keep this column as one of our predictors.", "Therefore, contextual considerations and domain knowledge should be utilized to evaluate whether such low-variance columns should be dropped from our dataset or not. For example:", "We can either manually calculate the number of unique values in each column as a percentage of the total number of observations as below:", "The above code will print out a list of all columns, together with the count of unique values and its percentage to the total number of observations.", "Or, we can utilize the scikit-learn library\u2019s VarianceThreshold class to identify and drop low-variance columns. Exercise extreme caution when using VarianceThreshold class, as it is designed to drop columns that are below the parameterized threshold.", "Duplicate rows should, most probably, be dropped from your data, given that they would most likely be redundant anyway.", "Pandas provides a simple function to check for any duplicate rows in a dataframe. Note that this will show only the second (and any higher-order) row, as the first row that has been duplicated is not considered a duplicate.", "If, after analyzing the duplicate records, you want to proceed with dropping them, a single line of code can achieve this:", "Outliers are any data points that appear to be rare or unlikely in the context of a given dataset. Domain knowledge and subject matter expertise come in handy to identify outliers. Although there is no standard definition of outliers given their contextual nature, various statistical and plotting measures can be used to identify and appropriately deal with them.", "Similar to low-variance columns, outlier observations are not automatic candidates for dropping. Instead, these should be analyzed further to determine if they really are anomalous or not.", "Box and whisker plotting is a simple and basic way to visualize numerical outliers in your dataframe:", "Let us now have a look at some of the statistical techniques to identify outliers.", "SD techniques for outlier detection can be applied to all numerical features that exhibit a Gaussian or Gaussian-like distribution. As a refresher, recall that:", "The following lines of code will select and drop all rows with values that are greater than the specified SDx of each numeric column. 3 SDs is the standard threshold; however, 2 SDs can be used for small datasets and 4 SDs for relatively large datasets.", "We can use IQR to identify outliers in an input feature that does not follow a normal or normal-like distribution. Values that are outside a specified threshold (usually, 1.5 times IQR above the 75th percentile and below the 25th percentile) are filtered out for further analysis.", "The following code snippet will filter out outliers from all numerical columns with a threshold of 1.5.", "From scikit-learn\u2019s documentation, \u201cLOF algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors.\u201d. The original paper can be found here.", "LocalOutlierFactor's fit_predict method predicts whether each row in a dataframe includes numerical outliers (-1) or not (1). Rows with outliers are marked as -1 and as 1 otherwise. A simple, practical example is shown below:", "A word of caution with LOF: it does not allow null or missing values in data passed to the predict method.", "Just to reiterate the obvious, missing values are not rare occurrences in real-life data. Most ML algorithms are unable to handle missing values and will throw up an error during model training. Therefore, such missing values in a dataset should be either dropped (the most naive way, and to be avoided as much as possible \u2014 data is the new currency!) or be somehow imputed logically.", "Certain effective descriptive statistics that are usually applied for such imputation include:", "A few simple ways to find and detect missing or null values is by executing either of the following functions:", "Statistically imputing missing values is pretty straight-forward using Python\u2019s built-in functions. The following functions calculate the descriptive statistic for each column and use that calculated statistic to fill in all empty values in that particular column:", "However, remember that the descriptive statistic should only be calculated on the training dataset; and then the same statistic should be used to impute any missing values in both the training and test data. The above approach works well with a simple train/test split; however, it becomes practically impossible when evaluating a model using k-fold cross-validation \u2014 since the splitting is done and repeated multiple times within a single function call.", "Scikit-learn\u2019s Pipeline and SimpleImputer comes to our rescue here.", "The SimpleImputer class conducts a data transform through the following steps:", "Scikit-learn\u2019s Pipeline allows us to perform multiple data transformations sequentially before applying a final estimator model in a single step. This prevents data leakage \u201cfrom test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors\u201d (from the documentation).", "It is best practice to utilize Pipeline when using cross-validation, as demonstrated below:", "A simple for loop can also be used to analyze all the four different imputation strategies available in SimpleImputer:", "The above will list down the mean Accuracy scores of each imputation strategy.", "Predicting the target variable with new, live data with potential missing values is achieved as following using Pipeline:", "Other than using descriptive statistics to impute missing values, an ML algorithm can also be used to predict them. A simple regression model can be used to predict missing values; however, the k-nearest neighbors (kNN) model has been found to be effective in practice as well.", "Scikit-learn\u2019s KNNImputer class supports kNN imputation \u2014 which is very similar to SimpleImputer in its usage. Just like SimpleImputer I will first demonstrate KNNImputer's standalone usage before implementing it within a pipeline.", "Now let us see how it can be implemented within a pipeline for effective validation:", "We can also apply a for loop to go over multiple k_neighbors parameters to identify the best one based on our accuracy metric:", "Predicting the target variable with new live data containing missing values is achieved by the same means as demonstrated above with SimpleImputer.", "That\u2019s it from me this time on specific data cleaning tasks in Python for machine learning projects.", "Feel free to reach out to me if you would like to discuss anything related to data analytics and machine learning.", "Till next time \u2014 rock on!", "Jason Brownlee of Machine Learning Mastery", "[1] Zheng, A., & Casari, A. (2018). Preface. In Feature engineering for machine learning: Principles and techniques for data scientists (p. vii). Sebastopol, CA: O\u2019Reilly.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A finance professional by education with a keen interest in data analytics and machine learning. www.finltyicshub.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff5334320e8e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f5334320e8e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f5334320e8e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@asad_mumtaz?source=post_page-----f5334320e8e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@asad_mumtaz?source=post_page-----f5334320e8e--------------------------------", "anchor_text": "Asad Mumtaz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f9c6741ffa5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=post_page-1f9c6741ffa5----f5334320e8e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff5334320e8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff5334320e8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@suicide_chewbacca?utm_source=medium&utm_medium=referral", "anchor_text": "Ashwini Chaudhary"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century", "anchor_text": "sexiest job of the 21st century"}, {"url": "https://towardsdatascience.com/how-to-avoid-potential-machine-learning-pitfalls-a08781f3518e", "anchor_text": "previous articles"}, {"url": "https://en.wikipedia.org/wiki/Ordinal_data", "anchor_text": "ordinal"}, {"url": "https://en.wikipedia.org/wiki/Categorical_variable", "anchor_text": "categorical"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html", "anchor_text": "VarianceThreshold"}, {"url": "https://en.wikipedia.org/wiki/Interquartile_range", "anchor_text": "IQR"}, {"url": "https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html", "anchor_text": "documentation"}, {"url": "https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html", "anchor_text": "LocalOutlierFactor"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html", "anchor_text": "SimpleImputer"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "Pipeline"}, {"url": "https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators", "anchor_text": "documentation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html", "anchor_text": "KNNImputer"}, {"url": "http://www.finlyticshub.com", "anchor_text": "me"}, {"url": "https://machinelearningmastery.com/", "anchor_text": "Machine Learning Mastery"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f5334320e8e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----f5334320e8e---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f5334320e8e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----f5334320e8e---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/technology?source=post_page-----f5334320e8e---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff5334320e8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=-----f5334320e8e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff5334320e8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=-----f5334320e8e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff5334320e8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f5334320e8e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff5334320e8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f5334320e8e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f5334320e8e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f5334320e8e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f5334320e8e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f5334320e8e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f5334320e8e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f5334320e8e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f5334320e8e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f5334320e8e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@asad_mumtaz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@asad_mumtaz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Asad Mumtaz"}, {"url": "https://medium.com/@asad_mumtaz/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "457 Followers"}, {"url": "http://www.finltyicshub.com", "anchor_text": "www.finltyicshub.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f9c6741ffa5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=post_page-1f9c6741ffa5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F83025c62db23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-data-cleaning-in-python-f5334320e8e&newsletterV3=1f9c6741ffa5&newsletterV3Id=83025c62db23&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}