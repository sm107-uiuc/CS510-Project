{"url": "https://towardsdatascience.com/summarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944", "time": 1683017562.544816, "path": "towardsdatascience.com/summarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944/", "webpage": {"metadata": {"title": "Summarize Reddit Comments using T5, BART, GPT-2, XLNet Models | by Manmohan Singh | Towards Data Science", "h1": "Summarize Reddit Comments using T5, BART, GPT-2, XLNet Models", "description": "Reddit users spend an average of 11 minutes on social media Reddit. On an average of 3 minutes, they read the same stuff. Also, no one read the whole comment section of popular posts. Users only read\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pypi.org/project/bert-extractive-summarizer/", "anchor_text": "https://pypi.org/project/bert-extractive-summarizer/", "paragraph_index": 25}, {"url": "https://manmohan24nov.github.io/", "anchor_text": "https://manmohan24nov.github.io/", "paragraph_index": 38}], "all_paragraphs": ["Reddit users spend an average of 11 minutes on social media Reddit. On an average of 3 minutes, they read the same stuff.", "It shows that users spend around 27% of their time reading the same stuff.", "Also, no one read the whole comment section of popular posts. Users only read popular comments on popular posts.", "Also, most of the comments will not appear on your dashboard. You may get to know the trending topics, but you miss not trending topics. In trending topics, you might only read the best or hot posts and their comments.", "So, what are you going to do to avoid wastage of time on Reddit?", "I would say summarize your whole trending Reddit post and its comments. And, then you can finish reading all trending topics in less than 2\u20131 minutes.", "In this article, I will explain to you how you can leverage Natural Language Processing (NLP) pre-trained models to summarize the Reddit comment section. We will use 4 ( T5, BART, GPT-2, XLNet) pre-trained models for this job.", "Each pre-trained model has its own architecture and weights. So, the summarization output given by these models could be different from each other.", "Test the Reddit data on different models and then choose the model which shows summarization close to your understanding. And then deploy that model into production.", "Let\u2019s start with collecting the Reddit comment section dataset.", "You can get Reddit comment section data in 2 ways.", "1. Official Reddit API (https://www.reddit.com/prefs/apps). Follow this article to get a Reddit dataset.", "2. Use the Beautiful Soup library to scrape the data from Reddit.", "I will be using step 1 to fetch the data. Once you receive the credentials for Reddit API, follow the below code to get Reddit data through API.", "Now, let\u2019s start summarizing data using pre-trained models one by one.", "T5 is a state of the art model used in various NLP tasks that includes summarization. We will be using the transformers library to download the T5 pre-trained model and load that model in a code.", "The Transformers library is developed and maintained by the Hugging Face team. It\u2019s an open-source library.", "Know more about the T5 model here.", "Here is code to summarize the Reddit dataset using the T5 model.", "BART uses both BERT (bidirectional encoder) and GPT (left to the right decoder) architecture with seq2seq translation. BART achieves the state of the art results in the summarization task.", "BART pre-trained model is trained on CNN/Daily mail data for the summarization task, but it will also give good results for the Reddit dataset.", "We will take advantage of the hugging face transformer library to download the T5 model and then load the model in a code.", "Here is code to summarize the Reddit dataset using the BART model.", "GPT-2 model with 1.5 Billion parameters is a large transformer-based language model. It\u2019s trained for predicting the next word. So, we can use this specialty to summarize Reddit data.", "GPT-2 models come with various versions. And, each version\u2019s size is more than 1 GB.", "We will be using the bert-extractive-summarizer library to download GPT-2 models. Learn more about the bert-extractive-summarizer library here. (https://pypi.org/project/bert-extractive-summarizer/).", "Use pip install bert-extractive-summarizer command to install the library.", "Here is a code to summarize the Reddit dataset using the GPT-2 model.", "XLNet is an improved version of the BERT model which implement permutation language modeling in its architecture. Also, XLNet is a bidirectional transformer where the next tokens are predicted in random order.", "The XLNet model has two versions xlnet-base-cased and xlnet-large-cased.", "Here is a code to summarize the Twitter dataset using the XLNet model.", "1. Summarize each article and present it to the readers as a summary.", "2. You can use this method to generate high-quality SEO. It will help your articles to discover more on google.", "3. Summarize the whole comment section of the post. These posts may belong to Reddit or Twitter social media platform.", "4. You can summarize the whitepapers, e-books, or blog posts and share them on your social media platform.", "In this article, we have summarized the Reddit Comment section data using T5, BART, GPT-2, and XLNet pre-trained models. Each model generates a different summarize output for the same dataset. Summarization by the T5 model and BART has outperformed the GPT-2 and XLNet models.", "These pre-trained models can also summarize articles, e-books, blogs with human-level performance. In the future, you can see a lot of improvements in summarization tasks. And this will help you to solve many summarization related tasks.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Searching clue in DATA | Website : https://manmohan24nov.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa3e78a5ab944&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ManmohanS?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ManmohanS?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "Manmohan Singh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bee6bf707b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&user=Manmohan+Singh&userId=5bee6bf707b0&source=post_page-5bee6bf707b0----a3e78a5ab944---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3e78a5ab944&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3e78a5ab944&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/0Hk2z98qWqM", "anchor_text": "Image by Simona Sergi"}, {"url": "https://huggingface.co/transformers/model_doc/t5.html#:~:text=T5%20is%20an%20encoder%2Ddecoder,text%2Dto%2Dtext%20format", "anchor_text": "https://huggingface.co/transformers/model_doc/t5.html#:~:text=T5%20is%20an%20encoder%2Ddecoder,text%2Dto%2Dtext%20format"}, {"url": "https://pypi.org/project/bert-extractive-summarizer/", "anchor_text": "https://pypi.org/project/bert-extractive-summarizer/"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a3e78a5ab944---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/reddit?source=post_page-----a3e78a5ab944---------------reddit-----------------", "anchor_text": "Reddit"}, {"url": "https://medium.com/tag/transfer-learning?source=post_page-----a3e78a5ab944---------------transfer_learning-----------------", "anchor_text": "Transfer Learning"}, {"url": "https://medium.com/tag/gpt-2?source=post_page-----a3e78a5ab944---------------gpt_2-----------------", "anchor_text": "Gpt 2"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----a3e78a5ab944---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3e78a5ab944&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&user=Manmohan+Singh&userId=5bee6bf707b0&source=-----a3e78a5ab944---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3e78a5ab944&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&user=Manmohan+Singh&userId=5bee6bf707b0&source=-----a3e78a5ab944---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3e78a5ab944&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa3e78a5ab944&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a3e78a5ab944---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a3e78a5ab944--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ManmohanS?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ManmohanS?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Manmohan Singh"}, {"url": "https://medium.com/@ManmohanS/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "127 Followers"}, {"url": "https://manmohan24nov.github.io/", "anchor_text": "https://manmohan24nov.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bee6bf707b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&user=Manmohan+Singh&userId=5bee6bf707b0&source=post_page-5bee6bf707b0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc832064d5e86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummarize-reddit-comments-using-t5-bart-gpt-2-xlnet-models-a3e78a5ab944&newsletterV3=5bee6bf707b0&newsletterV3Id=c832064d5e86&user=Manmohan+Singh&userId=5bee6bf707b0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}