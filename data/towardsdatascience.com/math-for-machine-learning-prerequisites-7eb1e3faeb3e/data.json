{"url": "https://towardsdatascience.com/math-for-machine-learning-prerequisites-7eb1e3faeb3e", "time": 1683014215.418334, "path": "towardsdatascience.com/math-for-machine-learning-prerequisites-7eb1e3faeb3e/", "webpage": {"metadata": {"title": "Math for Machine Learning: Probability and Statistics Prerequisite | by Geraldi Dzakwan | Towards Data Science", "h1": "Math for Machine Learning: Probability and Statistics Prerequisite", "description": "Hi everyone, welcome to my second post! This is going to be the continuation from my first post. We\u2019re going to be technical here, or should I say somewhat \u201cMathy\u201d. Thus, for you who have been away\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.cs.columbia.edu/~djhsu/coms4771-f19/", "anchor_text": "COMS W4771 Machine Learning Fall 2019 by Daniel Hsu", "paragraph_index": 1}, {"url": "https://chrome.google.com/webstore/detail/math-anywhere/gebhifiddmaaeecbaiemfpejghjdjmhc/", "anchor_text": "Math Anywhere", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/a-simple-introduction-to-k-nearest-neighbors-algorithm-b3519ed98e", "anchor_text": "story", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f", "anchor_text": "article", "paragraph_index": 21}, {"url": "https://gist.github.com/geraldzakwan/ec67ca4d36c124c80002eb383e4d7aa8", "anchor_text": "log likelihood plot.ipynb", "paragraph_index": 37}, {"url": "https://chrome.google.com/webstore/detail/math-anywhere/gebhifiddmaaeecbaiemfpejghjdjmhc/", "anchor_text": "Math Anywhere", "paragraph_index": 41}, {"url": "https://chrome.google.com/webstore/detail/tex-to-unicode", "anchor_text": "Tex to Unicode", "paragraph_index": 42}, {"url": "https://linkedin.com/in/geraldzakwan", "anchor_text": "https://linkedin.com/in/geraldzakwan", "paragraph_index": 45}], "all_paragraphs": ["Hi everyone, welcome to my second post! This is going to be the continuation from my first post. We\u2019re going to be technical here, or should I say somewhat \u201cMathy\u201d. Thus, for you who have been away for some time from hands-on Math, I suggest you review the material around Probability, Statistics, and Calculus. You could do that along the way of reading this story so that you could follow my explanation comfortably.", "This story is inspired by the course that I took at Columbia. The syllabus and the high-level detail of the course could be accessed through this link: COMS W4771 Machine Learning Fall 2019 by Daniel Hsu.", "As you might realize, you couldn\u2019t access the assignment files (which is intended by the Prof). Thus, the problem sets that I\u2019m going to cover will also be somewhat different, I would say it will be some variations of what I did in the course. It will not be entirely different and I will try my best so that I could give something around the same level.", "I\u2019ll give you three different problems in this story that I feel cover all the basic concepts you need to know around ProbStat to start learning Machine Learning (particularly Bayesian ML). Since most of the solutions are not trivial, I would warn you that this story will be lengthy, so bear with me!", "Lastly, before we start, I would like to let you know that this post contains LaTeX formulas. To render them correctly, install Math Anywhere add-on and activate it on your browser (I suggest Google Chrome) while reading this post.", "First thing first, master your basic probability!", "We\u2019re going to use the k-Nearest-Neighbor (kNN) algorithm as our background story here. If you\u2019re not familiar with it or if you need some refreshment, I recommend you take a look at this amazing story from fellow Towards Data Science (TDS) author.", "Let\u2019s limit our scope to $k=1$, i.e. we will only find one nearest neighbor. Suppose we have $n$ training examples, then the complexity of this algorithm is $O(n)$ because we simply have to iterate over $n$ examples, each calculating the $L_2$ difference, then finally pick the neighbor with the least $L_2$ distance.", "Let say that you work in a company and your boss asks you to speed up the computation of this 1-NN process. He doesn\u2019t care that the result is not inch-perfect, as long as it falls to the least 10% neighbors. For example, if there are 1 million data, your picked neighbor must be within the 100k data with the least $L_2$ distance.", "Let\u2019s call this problem \u201capproximate-Nearest-Neighbor\u201d and we should have the following mathematical definition for it:", "Of course, the above problem can simply be solved by taking samples $\\lceil{0.9n}\\rceil + 1$ from the training examples. In other words, if you have one million data, just sample 900k + 1 data, without replacement, and you\u2019re good to go. However, this doesn\u2019t speed up the computation by much and that is rather useless.", "So, let me propose something rather unexpected, at least that\u2019s what I felt when I worked on a similar problem to this one. What if I say that by sampling exactly 50 examples, call this $T=50$, we could make sure that, mathematically, the probability that we get the neighbor outside that 10% examples with the least $L_2$ distance is very small, say at most 0.5%. This is regardless of the number of data ($n$). Could you prove that?", "The solution to Problem 1 is actually pretty straightforward even though the problem description feels a little bit overwhelming. See that this is basically just a sampling without replacement problem. The way I approach this problem would be: Since we\u2019re looking for the probability that all the sampled data are not in the top 10%, then it\u2019s the same as calculating the probability that all the sampled data (50 of them) are in the rest 90% of the data.", "Thus, we can write the probability, say $p$, as:", "$$p = \\frac{\\text{number of combinations of picking 50 examples from 0.9n data}}{\\text{number of combinations of picking 50 samples from n data}}$$", "We\u2019re interested to see the value of the above probability regardless of the size of the data. Hence, my approach would be we take $n \\to \\infty$. The probability value that comes of that would the highest (try to reason yourselves on why this is the case). Thus, we could prove that the chance is at most 0.5%.", "This is pretty much easy to solve, if not for the ceiling function. I\u2019ll leave to the reader to solve how if $0.9n$ is not an integer as an exercise. Here I\u2019ll just cover the simpler case, i.e. when $0.9n$ is an integer:", "We can see above that the chance that we don\u2019t get even one sample from the top 10% examples (regardless of data size) is at most around 0.5%.", "This is rather remarkable, we could reduce the complexity from $O(n)$ to $O(50)$, which is constant! However, in reality, this is not always true. In the comment section below, let me know if you have any idea on why that is the case!", "PS: There is another catch that you might find, notice that a sampling without replacement problem for $n \\to\\infty$ could be seen as (or be approached as) a sampling with replacement problem!", "This is going to be a standard textbook problem that you might find all over the place when you learn statistics, which is to derive formulas for Maximum Likelihood Estimation (MLE). But knowing this means you have a good foundation to dive into some subfields of ML, particularly Bayesian inference.", "If you\u2019re not familiar with the topic, consider checking this cool article, also by a fellow TDS author. You would want to also familiarize yourself with the terms that I\u2019ll use below (i.i.d, random variable, probability density function, likelihood, etc.). So, here we go!", "Consider a statistical model for i.i.d random variables $X_1, X_2, \u2026, X_n$, parameterized by $\\theta \\in \\Theta$ . The parameter space is the positive reals $\\Theta = \\{ \\theta \\in R : \\theta > 0 \\}$.", "We will consider two definitions of the p.d.f.:", "In this problem, you will take a look on some models to collect data that ensures some degree of privacy guarantee, a topic which some of you might be interested in these days.", "Since election days are coming for some countries, I think it would be interesting to use it as a background story here. Suppose that there are two presidential candidates in one of those countries, call it country $U$, namely Mr. Murpt and Mr. Nebid. Refer Mr. Murpt as $M$ while Mr. Nebid as $N$.", "Imagine that you are an independent data scientist and some parties hire you to estimate a proportion of people in that country who picks one of the candidate. You can of course easily ask people directly who they will vote for, but some people might find it uncomfortable to share their information with you outright since you\u2019re basically nobody.", "Here, I will introduce you to a concept called \u201cRandomized Response\u201d. Basically, it tries to address the privacy concern by not asking directly what their choice is. Instead, you do the following for each surveyed individual:", "Ask him/her to toss a coin twice and tell him/her to not let you know the outcome", "If at least one of the tosses is head, tell him/her to respond truthfully (e.g. if he/she votes for $M$ then he/she will tell you $M$)", "If both tosses are tails, tell him/her to give opposite response (e.g. if he/she votes for $M$, then he/she will tell you $N$)", "I would argue that the scheme above assures a high degree of privacy guarantee, unless of course the coin is rigged.", "Now we come to the main questions.", "Consider a statistical model for $n$ responses collected using the scheme above, where the responses are regarded as iid {0, 1}-valued random variables $Y_1, Y_2, \u2026, Y_n$, and all coin tosses are independent. Let $\\theta \\in [0, 1]$ denote the parameter of the model that equals the proportion of individuals in the population that votes for $M$.", "What is the probability that $Y_1=1$? The answer should be given in terms of $\\theta$.", "Using those probabilities, $Y_1=1$ occurs when a person chooses $M$ gets at least one head $P(X\\geq1)$ or when a person chooses $N$ get no heads $P(X=0)$. Also, remember that choosing $M$ has the probability of $\\theta$ and choosing $N$ has the probability of $1-\\theta$. Thus, $P(Y_1)=1$ is:", "Because this problem involves discrete random variable, we can model the likelihood with the same function as we model the probability. To compute the probability, there are two components that we need to define:", "Above is the plot of log-likelihood as a function of $\\theta\\in[0,1]$ given n=100 and $\\sum_{i=1}^{n}y_i=40$. The snippet of the code I use to generate such plot is in this GitHub Gist: log likelihood plot.ipynb.", "We can see that the $\\theta$ with the highest likelihood seems to be somewhere around $0.2$ and $0.4$. Let\u2019s verify that by deriving the optimal $\\theta$ for the log likelihood below, i.e. $\\hat{\\theta}_{MLE}$.", "The function that corresponds to the plot is derived below by substituting given values:", "We could see that this is consistent with what we see in the plot.", "I think that would be all for this story. My apologies that I require you to install Math Anywhere add-on to read this story because I couldn\u2019t find any more convenient way to write LaTeX on Medium.", "I prefer not to upload images for mathematical notation and Tex to Unicode doesn\u2019t work well for me. In the comment section below, please suggest me if you know any better way to present mathematical notation on Medium, I would really appreciate it.", "Also, please let me know if the topic is of interest to you and if the explanation is clear and concise because I feel like I\u2019m a little bit verbose here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "TDS Official Author | Search Data Scientist at Bukalapak | MS in CS at Columbia University | https://linkedin.com/in/geraldzakwan"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7eb1e3faeb3e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://geraldzakwan.medium.com/?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": ""}, {"url": "https://geraldzakwan.medium.com/?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "Geraldi Dzakwan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbb6dc14fa51&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&user=Geraldi+Dzakwan&userId=dbb6dc14fa51&source=post_page-dbb6dc14fa51----7eb1e3faeb3e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7eb1e3faeb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7eb1e3faeb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.cs.columbia.edu/~djhsu/coms4771-f19/", "anchor_text": "COMS W4771 Machine Learning Fall 2019 by Daniel Hsu"}, {"url": "https://chrome.google.com/webstore/detail/math-anywhere/gebhifiddmaaeecbaiemfpejghjdjmhc/", "anchor_text": "Math Anywhere"}, {"url": "https://towardsdatascience.com/a-simple-introduction-to-k-nearest-neighbors-algorithm-b3519ed98e", "anchor_text": "story"}, {"url": "https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f", "anchor_text": "article"}, {"url": "https://gist.github.com/geraldzakwan/ec67ca4d36c124c80002eb383e4d7aa8", "anchor_text": "log likelihood plot.ipynb"}, {"url": "https://chrome.google.com/webstore/detail/math-anywhere/gebhifiddmaaeecbaiemfpejghjdjmhc/", "anchor_text": "Math Anywhere"}, {"url": "https://chrome.google.com/webstore/detail/tex-to-unicode", "anchor_text": "Tex to Unicode"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7eb1e3faeb3e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/math?source=post_page-----7eb1e3faeb3e---------------math-----------------", "anchor_text": "Math"}, {"url": "https://medium.com/tag/probability?source=post_page-----7eb1e3faeb3e---------------probability-----------------", "anchor_text": "Probability"}, {"url": "https://medium.com/tag/data?source=post_page-----7eb1e3faeb3e---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/statistics?source=post_page-----7eb1e3faeb3e---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7eb1e3faeb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&user=Geraldi+Dzakwan&userId=dbb6dc14fa51&source=-----7eb1e3faeb3e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7eb1e3faeb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&user=Geraldi+Dzakwan&userId=dbb6dc14fa51&source=-----7eb1e3faeb3e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7eb1e3faeb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7eb1e3faeb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7eb1e3faeb3e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7eb1e3faeb3e--------------------------------", "anchor_text": ""}, {"url": "https://geraldzakwan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://geraldzakwan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Geraldi Dzakwan"}, {"url": "https://geraldzakwan.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "90 Followers"}, {"url": "https://linkedin.com/in/geraldzakwan", "anchor_text": "https://linkedin.com/in/geraldzakwan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbb6dc14fa51&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&user=Geraldi+Dzakwan&userId=dbb6dc14fa51&source=post_page-dbb6dc14fa51--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fdbb6dc14fa51%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-for-machine-learning-prerequisites-7eb1e3faeb3e&user=Geraldi+Dzakwan&userId=dbb6dc14fa51&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}