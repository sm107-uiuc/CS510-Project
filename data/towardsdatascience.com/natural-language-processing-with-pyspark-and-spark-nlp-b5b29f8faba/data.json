{"url": "https://towardsdatascience.com/natural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba", "time": 1683003620.3087869, "path": "towardsdatascience.com/natural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba/", "webpage": {"metadata": {"title": "Natural Language Processing with PySpark and Spark-NLP | by Allison Stafford | Towards Data Science", "h1": "Natural Language Processing with PySpark and Spark-NLP", "description": "Today we\u2019re diving deeper into the US Consumer Financial Protection Bureau\u2019s Financial Services Consumer Complaint database to look at the text of the complaints filed against companies. The\u2026"}, "outgoing_paragraph_urls": [{"url": "https://catalog.data.gov/dataset/consumer-complaint-database", "anchor_text": "Financial Services Consumer Complaint database", "paragraph_index": 1}, {"url": "https://www.johnsnowlabs.com/spark-nlp/", "anchor_text": "them", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Spark_NLP", "anchor_text": "wikipedia", "paragraph_index": 2}, {"url": "https://nlp.johnsnowlabs.com/docs/en/quickstart", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://github.com/JohnSnowLabs/spark-nlp", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://nlp.johnsnowlabs.com/docs/en/annotators", "anchor_text": "docs", "paragraph_index": 11}, {"url": "https://nlp.johnsnowlabs.com/docs/en/annotators", "anchor_text": "docs", "paragraph_index": 12}, {"url": "https://www.collinsdictionary.com/us/dictionary/english/tobe", "anchor_text": "Collins Dictionary", "paragraph_index": 23}, {"url": "https://github.com/allisonhonold/spark-blog-tfidf", "anchor_text": "repo", "paragraph_index": 36}], "all_paragraphs": ["The question: what words (from complaints) are distinctly Equifax-y?", "Today we\u2019re diving deeper into the US Consumer Financial Protection Bureau\u2019s Financial Services Consumer Complaint database to look at the text of the complaints filed against companies. The question: what words (from complaints) are distinctly Equifax-y? We\u2019re going to be looking at text cleaning, tokenization, and lemming with Spark-NLP, counting with PySpark, and tf-idf (term frequency-inverse document frequency) analysis.", "I used John Snow LABS\u2019 Spark-NLP library. You can learn more from them, or wikipedia (probably also written by them, but in a different style).", "John Snow LABS provides a couple of different quick start guides \u2014 here and here \u2014 that I found useful together.", "If you haven\u2019t already installed PySpark (note: PySpark version 2.4.4 is the only supported version):", "If you already have PySpark, make sure to install spark-nlp in the same channel as PySpark (you can check the channel from conda list). In my case, PySpark is installed on my conda-forge channel, so I used", "I already had PySpark installed and set up for use with Jupyter notebooks, but if you don\u2019t, you may need to set some additional environment variables in the terminal (as mentioned in the second quick start guide, but not the first, so \u2026)", "If you are looking to play around with pre-installed data sets, and therefore don\u2019t need to access the spark session, you can get started with the following two lines:", "In my case, I need the SparkSession to load my data from the parquet file, so I\u2019ll add .config(\u201cspark.jars.packages\u201d, \u201ccom.johnsnowlabs.nlp:spark-nlp_2.11:2.3.5\u201d) to my SparkSession.builder", "That\u2019s it! You\u2019re up and going!", "Spark-NLP does not come with a built-in stop words dictionary, so I chose to use the NLTK English Language stop words, as well as the \u2018xxxx\u2019 redacting string found in my data set.", "Most projects are going to need DocumentAssembler to convert the text into a Spark-NLP annotator-ready form at the beginning, and Finisher to convert back to human-readable form at the end. You can select the annotators you need from the annotator docs.", "Before you set up the pipeline, we need to initialize the annotators with the proper inputs. We\u2019ll use the typical Spark ML format of .setInputCols(list of columns) and .setOutputCol(output column name), along with other functions specific to the annotator (see docs). Each output column will be the input column for the following annotator.", "Now we\u2019re ready to define the pipeline:", "I import and select my data, and then use pipeline.fit(data).transform(data). For example:", "This returns a DataFrame with the added columns specified in the pipeline\u2019s annotators. So equifax.columns returns:", "When we look more closely at the output of the finisher, in this case the \u201cfinished_clean_lemma\u201d, we see that each record is a list of words \u2014 eg. [address, never, \u2026], [pay, satisfied, \u2026].", "In order to get each word on the same level, I used the pyspark.sql explode function.", "Now the text is ready to .groupby().count() to get the count for each word.", "I then converted the result to pandas and used a dictionary comprehension to convert the table into a dictionary (this may not be the most elegant strategy).", "Full disclosure: even using Spark running on all four cores, doing this for the top 20 complaint earners took a significant amount of time \u2014 this is a lot of computation!", "Now that I have the text from each company\u2019s complaints count vectorized (aka converted into a dictionary of {word1: count1, word2: count2\u2026}), I am ready to get the tf-idf for each word in each company\u2019s word set.", "To find the words that set each company apart, I found the words with the top tf-idf scores for my companies of interest.", "Unfortunately, this revealed that I hadn\u2019t done enough to clean my data. All of the highest tf-idf score words were typos or sets of words smashed together (eg. \u2018tobe\u2019, \u2018calledthem\u2019, etc.). Sometimes 1000 character strings without spaces. So here, I added a filter based on the nltk.corpus words.words() list. Unfortunately tobe is actually a word, so it still shows up in some of the top results. Given the issue with missing spaces in the dataset, I doubt that people were talking about \u201can outer garment traditionally word in some parts of north and central Africa, consisting of a length of cloth that is sewn into a long loose skirt or is draped around the body and fastened over one shoulder\u201d (Collins Dictionary).", "Let\u2019s take a look at some of the top tf-idf scoring words for our top ten companies:", "Equifax: reseller, accuser, reinsertion, certifiably, certifiable, runner", "Experian: reseller, accuser, certifiably, certifiable, runner, reinsertion", "BofA: merchant, foreclose, teller, platinum, mellon(?), firearm, mesne", "Wells Fargo: preservation, foreclose, appraisal, preservationist, teller, dealer", "JP Morgan Chase: sapphire, southwest, merchant, airway, explorer, teller", "CitiBank: depot, promotional, goodyear, prestige, merchant, dividend", "Capital One: kohl, quicksilver, savor, orchard, merchant, venture, rebill", "Navient Solutions: pioneer, mae, unsubsidized, diploma, recertify, graduation", "Ocwen Financial: homeward, foreclose, suspense, hooligan, duplex", "We have do see the different categories of financial institutions, with the financial bureaus producing different results from the banks that do more mortgage lending and storefront banking, and from the U.S. Department of Education loan servicer Navient.", "At the same time, this result is pretty disheartening. These most important words don\u2019t feel super insightful. I\u2019m thinking:", "As always, find more (code) in the GitHub repo.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist with a background in business, education, and environmental science."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb5b29f8faba&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@allison.stafford?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@allison.stafford?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "Allison Stafford"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87b1f621568d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&user=Allison+Stafford&userId=87b1f621568d&source=post_page-87b1f621568d----b5b29f8faba---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5b29f8faba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5b29f8faba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@its_tgain?utm_source=medium&utm_medium=referral", "anchor_text": "Tom Gainor"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://catalog.data.gov/dataset/consumer-complaint-database", "anchor_text": "Financial Services Consumer Complaint database"}, {"url": "https://www.johnsnowlabs.com/spark-nlp/", "anchor_text": "them"}, {"url": "https://en.wikipedia.org/wiki/Spark_NLP", "anchor_text": "wikipedia"}, {"url": "https://nlp.johnsnowlabs.com/docs/en/quickstart", "anchor_text": "here"}, {"url": "https://github.com/JohnSnowLabs/spark-nlp", "anchor_text": "here"}, {"url": "https://nlp.johnsnowlabs.com/docs/en/annotators", "anchor_text": "docs"}, {"url": "https://nlp.johnsnowlabs.com/docs/en/annotators", "anchor_text": "docs"}, {"url": "https://www.collinsdictionary.com/us/dictionary/english/tobe", "anchor_text": "Collins Dictionary"}, {"url": "https://github.com/allisonhonold/spark-blog-tfidf", "anchor_text": "repo"}, {"url": "https://unsplash.com/@schmidy?utm_source=medium&utm_medium=referral", "anchor_text": "Austin Schmid"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----b5b29f8faba---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/spark?source=post_page-----b5b29f8faba---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/tf-idf?source=post_page-----b5b29f8faba---------------tf_idf-----------------", "anchor_text": "Tf Idf"}, {"url": "https://medium.com/tag/nlp?source=post_page-----b5b29f8faba---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----b5b29f8faba---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb5b29f8faba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&user=Allison+Stafford&userId=87b1f621568d&source=-----b5b29f8faba---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb5b29f8faba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&user=Allison+Stafford&userId=87b1f621568d&source=-----b5b29f8faba---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5b29f8faba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb5b29f8faba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b5b29f8faba---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b5b29f8faba--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b5b29f8faba--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b5b29f8faba--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@allison.stafford?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@allison.stafford?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Allison Stafford"}, {"url": "https://medium.com/@allison.stafford/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "386 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87b1f621568d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&user=Allison+Stafford&userId=87b1f621568d&source=post_page-87b1f621568d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb4bbbb8c248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-pyspark-and-spark-nlp-b5b29f8faba&newsletterV3=87b1f621568d&newsletterV3Id=b4bbbb8c248&user=Allison+Stafford&userId=87b1f621568d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}