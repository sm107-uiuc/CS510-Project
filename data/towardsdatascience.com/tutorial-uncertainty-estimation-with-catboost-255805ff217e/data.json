{"url": "https://towardsdatascience.com/tutorial-uncertainty-estimation-with-catboost-255805ff217e", "time": 1683014899.572178, "path": "towardsdatascience.com/tutorial-uncertainty-estimation-with-catboost-255805ff217e/", "webpage": {"metadata": {"title": "Tutorial: Uncertainty estimation with CatBoost | by Liudmila Prokhorenkova | Towards Data Science", "h1": "Tutorial: Uncertainty estimation with CatBoost", "description": "Machine learning has been widely applied to a range of tasks. However, in certain high-risk applications, such as autonomous driving, medical diagnostics, and financial forecasting, a mistake can\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/catboost/catboost/blob/master/catboost/tutorials/uncertainty/uncertainty_regression.ipynb", "anchor_text": "this Jupyter Notebook", "paragraph_index": 1}], "all_paragraphs": ["This tutorial covers the following topics:", "You can follow all steps using this Jupyter Notebook.", "Machine learning has been widely applied to a range of tasks. However, in certain high-risk applications, such as autonomous driving, medical diagnostics, and financial forecasting, a mistake can lead to either a fatal outcome or large financial loss. In these applications, it is important to detect when the system makes a mistake and take safer actions. Furthermore, it is also desirable to collect these \u201cfailure scenarios\u201d, label them, and teach the system to make the correct prediction through active learning.", "Predictive uncertainty estimation can be used for detecting errors . Ideally, the model indicates a high level of uncertainty in situations where it is likely to make a mistake. That allows us to detect errors and take safer actions. Crucially, the choice of action can depend on why the model is uncertain. There are two main sources of uncertainty: data uncertainty (also known as aleatoric uncertainty) and knowledge uncertainty (also known as epistemic uncertainty). If our goal is to detect errors, it is not necessary to separate these two uncertainties. However, if our goal is active learning, then we would like to detect novel inputs, and knowledge uncertainty can be used for that.", "Data uncertainty arises due to the inherent complexity of the data, such as additive noise or overlapping classes. In these cases, the model knows that the input has attributes of multiple classes or that the target is noisy. Importantly, data uncertainty cannot be reduced by collecting more training data.", "Knowledge uncertainty arises when the model is given an input from a region that is either sparsely covered by the training data or far from the training data. In these cases, the model knows very little about this region and is likely to make a mistake. Unlike data uncertainty, knowledge uncertainty can be reduced by collecting more training data from a poorly understood region.", "This tutorial post details how to quantify both data and knowledge uncertainty in CatBoost.", "To illustrate the concepts, we\u2019ll use a simple synthetic example.", "Assume that we have two categorical features x\u2081 and x\u2082 with 9 values each, so there are 81 possible feature combinations. The target depends on the features as", "where mean(x\u2081,x\u2082) is some unknown fixed value and eps(x\u2081,x\u2082) is a normally distributed noise (i.e., data uncertainty) with mean 0 and variance var(x\u2081,x\u2082). In our examples, mean(x\u2081,x\u2082) is randomly generated, and var(x\u2081,x\u2082) has two values (0.01 and 0.04) that are distributed as follows:", "Thus, points on the heart have more noise in the targets than points outside the heart. Note that we enumerated the categories for a nicer visualization, but in the dataset, both features are categorical, i.e., the order is not given.", "When we generate the dataset with this distribution, we assume that we do not have any training examples inside the heart \u2014 these feature combinations are considered outliers for our dataset.", "The standard model optimized with the RMSE loss can only predict mean(x\u2081,x\u2082). Ok, but what if we want to estimate the variance of y, i.e., data uncertainty? In other words, what if we want to understand which predictions are noisy? To estimate data uncertainty, one has to use probabilistic regression models that predict both mean and variance. For this purpose, there is a new loss function in CatBoost called RMSEWithUncertainty. With this loss, CatBoost estimates the mean and variance of the normal distribution optimizing the negative log-likelihood and using natural gradients, similarly to the NGBoost algorithm [1]. For each example, CatBoost model returns two values: estimated mean and estimated variance.", "Let\u2019s try to apply this loss function to our simple example. We get the following variance:", "We can see that CatBoost successfully predicts the variance on the heart and outside it. Inside the heart, we have no training data, so anything can be predicted there.", "Ok, we know how to estimate noise in the data. But how to measure knowledge uncertainty coming from the lack of training data in a particular region? What to do if we want to detect outliers? Estimating knowledge uncertainty requires an ensemble of models. If all the models understand an input, they will give similar predictions (low knowledge uncertainty). However, if the models do not understand the input, then they are likely to provide diverse predictions and strongly disagree with each other (high knowledge uncertainty). For regression, knowledge uncertainty can be obtained by measuring the variance of the mean across multiple models. Note that this is different from the predicted variance of a single model, which captures data uncertainty.", "Let\u2019s consider ensembles of GBDT models generated as follows:", "The models are generated using the option posterior_sampling since this allows the obtained (random) predictions to be nicely distributed (with good theoretical properties, and here we refer to [2] for details).", "Then, to estimate the knowledge uncertainty, we just compute the variance of the mean values predicted by models:", "The model correctly detected knowledge uncertainty inside the heart (we can see no traces of the original heart border). This illustrates how, by estimating knowledge uncertainty, we can detect anomalous inputs.", "In practice, training an ensemble of several CatBoost models can be too expensive. Ideally, we would like to train a single model but still be able to detect outliers. There is a solution for that: we can use a virtual ensemble, obtained from a single trained model:", "Having a single trained model, CatBoost returns several predictions for each example. These predictions are obtained via truncating the model:", "Again, we use the option posterior_sampling to guarantee a desirable distribution of cropped predictions. Let\u2019s see what we obtain:", "Note that the predicted absolute values of knowledge uncertainty are now much smaller since the virtual ensemble elements are correlated. But still, it can successfully detect unoccupied regions (outliers).", "Instead of prediction_type=\u2019VirtEnsembles\u2019 that returns the predictions of several models, we could use prediction_type=\u2019TotalUncertainty\u2019 and get the same result easier. For this prediction type, CatBoost calculates all types of uncertainty using a virtual ensemble. Namely, for RMSEWithUncertainty it returns the following statistics: [Mean Prediction, Knowledge Uncertainty, Data Uncertainty]:", "Thanks for your attention! I hope this tutorial helped you to better understand the concept of uncertainty and how to estimate it with CatBoost. We\u2019ll tell you more about applications of uncertainty in future posts. Stay tuned \ud83d\ude3a", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F255805ff217e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----255805ff217e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----255805ff217e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ostroumova.la?source=post_page-----255805ff217e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ostroumova.la?source=post_page-----255805ff217e--------------------------------", "anchor_text": "Liudmila Prokhorenkova"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa53039bc0323&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&user=Liudmila+Prokhorenkova&userId=a53039bc0323&source=post_page-a53039bc0323----255805ff217e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F255805ff217e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F255805ff217e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/catboost/catboost/blob/master/catboost/tutorials/uncertainty/uncertainty_regression.ipynb", "anchor_text": "this Jupyter Notebook"}, {"url": "https://proceedings.icml.cc/static/paper_files/icml/2020/3337-Paper.pdf", "anchor_text": "NGBoost: Natural Gradient Boosting for Probabilistic Prediction"}, {"url": "https://arxiv.org/pdf/2006.10562.pdf", "anchor_text": "Uncertainty in Gradient Boosting via Ensembles"}, {"url": "https://medium.com/tag/catboost?source=post_page-----255805ff217e---------------catboost-----------------", "anchor_text": "Catboost"}, {"url": "https://medium.com/tag/uncertainty?source=post_page-----255805ff217e---------------uncertainty-----------------", "anchor_text": "Uncertainty"}, {"url": "https://medium.com/tag/gradient-boosting?source=post_page-----255805ff217e---------------gradient_boosting-----------------", "anchor_text": "Gradient Boosting"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----255805ff217e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----255805ff217e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F255805ff217e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&user=Liudmila+Prokhorenkova&userId=a53039bc0323&source=-----255805ff217e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F255805ff217e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&user=Liudmila+Prokhorenkova&userId=a53039bc0323&source=-----255805ff217e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F255805ff217e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----255805ff217e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F255805ff217e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----255805ff217e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----255805ff217e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----255805ff217e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----255805ff217e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----255805ff217e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----255805ff217e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----255805ff217e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----255805ff217e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----255805ff217e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ostroumova.la?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ostroumova.la?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Liudmila Prokhorenkova"}, {"url": "https://medium.com/@ostroumova.la/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "58 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa53039bc0323&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&user=Liudmila+Prokhorenkova&userId=a53039bc0323&source=post_page-a53039bc0323--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F823345975c5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-uncertainty-estimation-with-catboost-255805ff217e&newsletterV3=a53039bc0323&newsletterV3Id=823345975c5d&user=Liudmila+Prokhorenkova&userId=a53039bc0323&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}