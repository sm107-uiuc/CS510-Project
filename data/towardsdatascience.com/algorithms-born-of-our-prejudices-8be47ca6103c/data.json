{"url": "https://towardsdatascience.com/algorithms-born-of-our-prejudices-8be47ca6103c", "time": 1683009010.451277, "path": "towardsdatascience.com/algorithms-born-of-our-prejudices-8be47ca6103c/", "webpage": {"metadata": {"title": "Algorithms Born of our Prejudices | by Norbert Biedrzycki | Towards Data Science", "h1": "Algorithms Born of our Prejudices", "description": "As distant and aloof as mathematical equations may seem, they are also commonly associated with reliable, hard science. Every now and then, it nevertheless turns out that a sequence of numbers and\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www-07.ibm.com/innovation/my/exhibit/documents/pdf/IBM_SPSS_Memphis_Police_Department.pdf", "anchor_text": "Criminologists and data processing scholars at the University of", "paragraph_index": 1}, {"url": "https://www.theverge.com/2016/2/3/10895804/st-louis-police-hunchlab-predictive-policing-marshall-project", "anchor_text": "The HunchLab system from the startup Azavea", "paragraph_index": 2}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "ProPublica, which associates investigative journalists, published the article \u201cMachine Bias\u201d", "paragraph_index": 3}, {"url": "http://www-07.ibm.com/innovation/my/exhibit/documents/pdf/IBM_SPSS_Memphis_Police_Department.pdf", "anchor_text": "Link", "paragraph_index": 8}, {"url": "https://www.theverge.com/2016/2/3/10895804/st-louis-police-hunchlab-predictive-policing-marshall-project", "anchor_text": "Link", "paragraph_index": 9}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "Link", "paragraph_index": 10}, {"url": "https://norbertbiedrzycki.pl/en/learn-like-a-machine-if-not-harder/", "anchor_text": "Learn like a machine, if not harder", "paragraph_index": 11}, {"url": "https://norbertbiedrzycki.pl/en/time-we-talked-to-our-machines/", "anchor_text": "Time we talked to our machines", "paragraph_index": 12}, {"url": "https://norbertbiedrzycki.pl/en/will-algorithms-commit-war-crimes/", "anchor_text": "Will algorithms commit war crimes?", "paragraph_index": 13}, {"url": "https://norbertbiedrzycki.pl/en/machine-when-will-you-learn-to-make-love-to-me/", "anchor_text": "Machine, when will you learn to make love to me?", "paragraph_index": 14}, {"url": "https://norbertbiedrzycki.pl/en/hello-are-you-still-human/", "anchor_text": "Hello. Are you still a human?", "paragraph_index": 15}, {"url": "https://norbertbiedrzycki.pl/en/artificial-intelligence-is-new-electricity/", "anchor_text": "Artificial intelligence is a new electricity", "paragraph_index": 16}], "all_paragraphs": ["As distant and aloof as mathematical equations may seem, they are also commonly associated with reliable, hard science. Every now and then, it nevertheless turns out that a sequence of numbers and symbols conceals a more ominous potential. What is it that causes applications, which otherwise serve a good cause, to go bad? There could be any number of reasons. One of the first ones that spring to mind has to do with human nature. People are known to follow a familiar mechanism of letting stereotypes and prejudices guide their lives. They apply them to other individuals, social groups, and value systems. Such cognitive patterns can easily be driven by the lack of imagination and a reluctance to give matters proper consideration. The resulting explosive mixture spawns negative consequences. People who blindly trust computer data fail to see the complexity of situations and easily forgo subjective assessments of events. Once that happens, unfortunate events unfold causing huge problems for everyone involved. Our ignorance and the increasing autonomy of algorithms, which turn out to be far from infallible, generates a disturbing mix.", "The police are ideally suited for testing intelligent technologies. Such technologies have their quirks and industry is well aware that a useful algorithm can at times cause problems. But let us be fair. Smart data processing allows police computers to effectively group crimes, historical data and circumstances into categories and datasets. There is no disputing the usefulness of applications that help associate places, people, psychological profiles, the time crimes were committed and the instruments used. Criminologists and data processing scholars at the University of Memphis have chosen to use IBM software designed for predictive analyses. The project team created an analytical mechanism that takes into account such variables as air temperature, local geographies, population distribution, the locations of stores and restaurants, resident preferences and crime statistics. The underlying algorithms use these variables to identify potential flashpoints in the city. And they actually work. Tests of the system show it is indeed possible to predict the future with a certain degree of certainty, although no details are given on what that degree might be. The certainty is nevertheless sufficiently high to justify sending police officers to \u201chigh-risk\u201d zones identified in this manner. Claims are also made that this helps reduce police response time from the moment an incident is reported by a factor of three. I can only imagine that mere police presence in such locations could deter criminal activity. And although this example may be difficult for a layman to understand, it proves that modern technology offers \u201cdynamite\u201d innovations with a potential to produce spectacular results.", "The HunchLab system from the startup Azavea, which has been rolled out in the United States, sifts through massive amounts of data of various types (including phases of the moon) to help the police investigate crimes. As in the previous example, the idea is to create a map of locations where the probability of a crime emerging is particularly high. The program focuses on the locations of bars, schools and bus stops across the city. And it is proving helpful. While some of its findings are quite obvious, others can be surprising. It is easy to explain why fewer crimes are committed on a colder day. It is considerably harder though to find the reasons why cars parked near Philadelphia schools are more likely to get stolen. Would it ever occur to a police officer without such software to look into the connection between schools and auto theft? The above are all positive scenarios. However, it is difficult to get over the fact that smart machines not only make mistakes in their processing but also contribute to wrong interpretations. Quite often, they are unable to understand situational contexts. Not entirely unlike people.", "In 2016, the independent newsroom ProPublica, which associates investigative journalists, published the article \u201cMachine Bias\u201d on US courts\u2019 use of specialist software from Northpointe to profile criminals. Designed to assess the chances that prior offenders will re-offend, the software proved highly popular with US judges, noted the article. Northpointe tool estimated the likelihood of black convicts committing another crime at 45 percent. Meanwhile, the risk of a white person re-offending was put at 24 percent. To reach these interesting conclusions, algorithms assumed that blacks neighborhoods were a higher criminal-behavior risk than predominantly white districts. The presumptions propagated by the software have been questioned, ultimately putting an end to the analytical career of Northpointe\u2019s software suite. The root cause of the problem lied in basing assessments on historical data alone and in the lack of awareness or rather the failure to design algorithms to account for the latest demographic trends.", "In her 2016 book \u201cWeapon of Math Destruction\u201d, Cathy O\u2019Neil explores the interesting presumption that algorithms greatly influence various areas of people\u2019s lives. She suggests that people tend to give mathematical models too much credit. This, she claims, gives rise to biases which are formed in many ways and on many levels. Prejudices, she says, originate early, even before the data that algorithms use for analysis, is collected. The very same mechanism was discovered by Amazon managers. They noticed that the recruitment programs they were using regularly discriminated against women. Searches for promising prospects would always have women in the minority among the suggested hits. What caused the bias? Reliance on historical data showing more men applying for specific positions. This disrupted the gender parity of employment, tipping the scales in men\u2019s favor and ultimately leading to the formulation of biased employment policies.", "The above assessment software was built to rely on algorithms developed in an era in which gross gender-based inequalities plagued employment. That specific moment in time was characterized by an over-representation of men. Trained on historical data, algorithms worked on the \u201cbelief\u201d that the world has not changed. This meant that their assumptions and simplifications (such as that black means higher probability of crime and that men are more likely to be excellent professionals) were misguided.", "If you think that mechanisms similar to those described above may be common in professional and personal life, you may well be on to something. How many cases are there we are not aware of, in which data is organized on erroneous assumptions? How often do algorithms fail to account for economic and cultural changes?", "The black box is a term used to refer to human helplessness in the face of what happens in the \u201cbrains\u201d of artificial intelligence. Our ignorance and the increasing autonomy of algorithms, which turn out to be far from infallible, generates a disturbing mix. The prejudices of algorithms will not vanish at the wave of a magic wand. The key question therefore is whether their developers, who often do their design and training work all by themselves, will rise to the task and realize just how easily human biases and behavior patterns can rub off on software.", "IBM, Memphis Police Department, IBM SPSS: Memphis Police Department, A detailed ROI case study, Link, 2015.", "The Verge, by Maurice Chammah, with additional reporting by Mark Hansen, POLICING THE FUTURE. In the aftermath of Ferguson, St. Louis cops embrace crime-predicting software, Link, 2018.", "ProPublica, Machine Bias: There\u2019s software used across the country to predict future criminals. And it\u2019s biased against blacks, by Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, ProPublica, Link, 2018.", "\u2013 Learn like a machine, if not harder", "\u2013 Time we talked to our machines", "\u2013 Will algorithms commit war crimes?", "\u2013 Machine, when will you learn to make love to me?", "\u2013 Hello. Are you still a human?", "\u2013 Artificial intelligence is a new electricity", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Technology is my passion. Head of Microsoft Services CEE. Private opinions only"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8be47ca6103c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://n-biedrzycki.medium.com/?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": ""}, {"url": "https://n-biedrzycki.medium.com/?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "Norbert Biedrzycki"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fba5b91d4b474&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&user=Norbert+Biedrzycki&userId=ba5b91d4b474&source=post_page-ba5b91d4b474----8be47ca6103c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8be47ca6103c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8be47ca6103c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Markus Spiske"}, {"url": "https://unsplash.com/s/photos/programming?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "http://www-07.ibm.com/innovation/my/exhibit/documents/pdf/IBM_SPSS_Memphis_Police_Department.pdf", "anchor_text": "Criminologists and data processing scholars at the University of"}, {"url": "https://www.theverge.com/2016/2/3/10895804/st-louis-police-hunchlab-predictive-policing-marshall-project", "anchor_text": "The HunchLab system from the startup Azavea"}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "ProPublica, which associates investigative journalists, published the article \u201cMachine Bias\u201d"}, {"url": "http://www-07.ibm.com/innovation/my/exhibit/documents/pdf/IBM_SPSS_Memphis_Police_Department.pdf", "anchor_text": "Link"}, {"url": "https://www.theverge.com/2016/2/3/10895804/st-louis-police-hunchlab-predictive-policing-marshall-project", "anchor_text": "Link"}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "Link"}, {"url": "https://norbertbiedrzycki.pl/en/learn-like-a-machine-if-not-harder/", "anchor_text": "Learn like a machine, if not harder"}, {"url": "https://norbertbiedrzycki.pl/en/time-we-talked-to-our-machines/", "anchor_text": "Time we talked to our machines"}, {"url": "https://norbertbiedrzycki.pl/en/will-algorithms-commit-war-crimes/", "anchor_text": "Will algorithms commit war crimes?"}, {"url": "https://norbertbiedrzycki.pl/en/machine-when-will-you-learn-to-make-love-to-me/", "anchor_text": "Machine, when will you learn to make love to me?"}, {"url": "https://norbertbiedrzycki.pl/en/hello-are-you-still-human/", "anchor_text": "Hello. Are you still a human?"}, {"url": "https://norbertbiedrzycki.pl/en/artificial-intelligence-is-new-electricity/", "anchor_text": "Artificial intelligence is a new electricity"}, {"url": "https://norbertbiedrzycki.pl/en/how-machines-think-2/", "anchor_text": "How machines think"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----8be47ca6103c---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8be47ca6103c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/discrimination?source=post_page-----8be47ca6103c---------------discrimination-----------------", "anchor_text": "Discrimination"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8be47ca6103c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&user=Norbert+Biedrzycki&userId=ba5b91d4b474&source=-----8be47ca6103c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8be47ca6103c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&user=Norbert+Biedrzycki&userId=ba5b91d4b474&source=-----8be47ca6103c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8be47ca6103c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8be47ca6103c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8be47ca6103c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8be47ca6103c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8be47ca6103c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8be47ca6103c--------------------------------", "anchor_text": ""}, {"url": "https://n-biedrzycki.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://n-biedrzycki.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Norbert Biedrzycki"}, {"url": "https://n-biedrzycki.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "443 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fba5b91d4b474&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&user=Norbert+Biedrzycki&userId=ba5b91d4b474&source=post_page-ba5b91d4b474--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff04ee6c8e1ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-born-of-our-prejudices-8be47ca6103c&newsletterV3=ba5b91d4b474&newsletterV3Id=f04ee6c8e1ea&user=Norbert+Biedrzycki&userId=ba5b91d4b474&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}