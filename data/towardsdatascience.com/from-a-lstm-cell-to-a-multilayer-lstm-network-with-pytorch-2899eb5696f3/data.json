{"url": "https://towardsdatascience.com/from-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3", "time": 1683011646.255426, "path": "towardsdatascience.com/from-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3/", "webpage": {"metadata": {"title": "From a LSTM cell to a Multilayer LSTM Network with PyTorch | by Fernando L\u00f3pez | Towards Data Science", "h1": "From a LSTM cell to a Multilayer LSTM Network with PyTorch", "description": "The aim of this blog is to show a practical implementation on the use of the LSTMCell class from PyTorch. As it is well known, PyTorch provides a LSTM class to build multilayer long-short term memory\u2026"}, "outgoing_paragraph_urls": [{"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Understanding LSTM Networks", "paragraph_index": 4}], "all_paragraphs": ["How to build a multilayer long-short term memory neural net by only using LSTMCells?", "The aim of this blog is to show a practical implementation on the use of the LSTMCell class from PyTorch. As it is well known, PyTorch provides a LSTM class to build multilayer long-short term memory neural networks which is based on LSTMCells. In this blog, it\u2019s going to be explained how to build such a neural net by hand by only using LSTMCells with a practical example.", "The blog is organized as follows:", "LSTM networks are a kind of recurrent neural network. These kinds of neural networks are well-known to work properly with data that can be represented as a sequence, such as the case of text, music, frequencies, time series, etc. One of the main characteristics of the LSTM architecture is that it contains gates whose function is to keep meaningful information as well as forget useless data. However, it is important to mention that LSTMs tend to be slow when trained, essentially because of the number of parameters to be updated.", "If you want to delve into the LSTM core, please take a look at this amazing resource: Understanding LSTM Networks.", "If you want to avoid the mechanics of the LSTM cell architecture and how it works internally, you can jump directly into LSTMCell Class from PyTorch or at Multilayer LSTM.", "First, let\u2019s understand what about the mechanics of the LSTM Cell. The LSTM cell is mainly composed of 3 gates which are forget, input and output gates as well as the cell state. So, let\u2019s discover what it means by \u201cforget\u201d, \u201cinput\u201d and \u201coutput\u201d. Figure 1 shows the LSTM cell architecture.", "The forget gate determines which information is not relevant and should not be considered. The forget gate is composed of the previous hidden state h(t-1) as well as the current time step x(t) whose values are filtered by a sigmoid function, that means that values near zero will be considered as information to be discarded and values near 1 are considered useful information which is worth to keep. Then, the cell state is updated with the information to be kept according to the forget gate. Figure 2 highlights the operations followed in order to build the forget gate. Equation 1 shows the mathematical representation of the forget gate.", "The input gate determines what information should be part of the cell state (the memory of the LSTM). It is composed of the previous hidden state h(t-1) as well as the current time step x(t). The input gate considers two functions, the first one filters the previous hidden state as well as the current time step by a sigmoid function. The second one filters the previous hidden state and the current time step by a tanh function. So, before updating the cell state, both outputs (the one from the sigmoid function and the one from the tanh function) are operated together, the idea is that the sigmoid output will determine what information from the tanh output will be important to keep in the cell state. Figure 3 highlights the operations followed in order to build the input gate. Equation 2 shows the mathematical representation of the input gate.", "So far we have talked about the forget gate as well as the input gate. Now it is time to introduce the cell state.", "The cell state is known as the memory of the LSTM, it is updated by the forget gate and the input gate. Essentially, the forget gate defines what shouldn\u2019t be kept in the memory and the input gate defines what should be kept in such memory. Figure 4 highlights the process to update the cell state. Equation 3 shows the mathematical representation of the cell state.", "Finally we have the output gate which in consequence generates the new hidden state. The output gate makes use of the previous hidden state as well as the current time step whose values are filtered by a sigmoid function. In parallel it\u2019s extracted the current cell state which is filtered by a tanh function, both outputs are operated together in order to generate the new hidden state. Figure 5 highlights the process to build the output gate. Equations 4 and 5 shows the mathematical representation about output gate and hidden state respectively.", "So far we have seen how the LSTM cell works and how its components are. Now it is time see how to adapt real inputs into the LSTMClass from PyTorch.", "First, let\u2019s understand how the input-output parameters are when initializing the LSTMClass and how the input-output parameters are when using the initialized object.", "In order to be initialized, LSTMCell class needs two important parameters", "Once initialized, the object created by the LSTMClass receives three inputs:", "Figure 6 highlights the vector shapes for the input x(t), the hidden states h(t-1) and h(t) as well as the cell states C(t-1) and C(t).", "As we already know, LSTMs work with sequential data. So let\u2019s understand with a simple example how to feed the LSTMCell sequentially (i.e. how to unfold the LSTM network).", "Let\u2019s suppose we have the sentence \u201cthe sky is blue\u201d, the one we want to introduce into the LSTM. So, we would need to change these words into a readable format for neural networks. I have to say that there is a plenty of options in order to transform words into a LSTM-readable format, since these options are out of the scope of this blog, I\u2019m going to limit myself to choosing one of the most common options, which is word tokenization.", "So, in order to encode the words into a LSTM-readable format, we first would need to split the sentence into a set of words (word tokens), then we would need to transform each word token into an index-token form. After, we would need to use an embedder layer in order to transform each index-token into an embedded vector. Up to this point, we would already have everything necessary to feed the LSTM, we would only need to organize the sequence into a set of time steps, where each time step will be assigned a batch size.", "Imagining that we want to create a set of 2 time steps, where each time step contain a batch size of 2, we would have 2 input tensors, each one with a shape (batch_size = 2, input_size = 2), wherein batch_size refers to the number of samples per time step and input_size refers to the embedding dimension. Figure 7 visually explains the mentioned process.", "So, in order to feed the LSTM network with sequential data we would need to create a loop wherein each iteration will feed the current LSTM cell with a time step with shape (batch_size, input_size). So, in terms of the previous example, each time step will contain a batch size of 2 and input size of 2 as well. In Figure 8, the top image represents the unfolded version by using word token-based representation, the middle image represents the unfolded version by using index-token-based representation and the button image represents the unfolded version by using embeddings-based representation. (The three images are equivalent, top and middle images are only for a didactic representation).", "It is time to see what about the code. In PyTorch it is recommended to define the settings as well as the layers in the constructor. So, in terms of the toy example mentioned above the code snippet 1 shows how this initialization should be.", "It\u2019s worth to mention two important aspects, the first one is the input_size that the Embedding layer receives as input parameter, notice that it refers to the vocabulary size, in this toy example we only have 4 words, which means that the vocabulary size is 4. The second important aspect is the input size parameter that the LSTMCell receives, notice that it is of size embedding_dim which in this case is 2 (exactly as the above example).", "Once we have the constructor ready, we need to work in the forward function. First we would need to create and initialize the cell state as well as the hidden state such as:", "In lines 3 and 4 the hidden and cell states are initialized respectively, both have a shape (batch_size, hidden_dim). Right after in lines 7 and 8 both states are initialized (in this case I\u2019m using Xavier normal initialization, however you can chose the one you consider).", "Once we have initialized the hidden and cell states, we can proceed to transform each index-token into a embedding-based representation, such as:", "Here the embedding layer is receiving as input a tensor which contains index-tokens, so the out variable is assigned with a tensor of embedded values with shape (batch_size, embedding_dim).", "Now, everything is ready in order to feed the LSTM, however before doing it we need to adapt the shape of the out tensor. We only need to define the first dimension as the number of time steps, so we proceed to do the following:", "So now our out tensor has a shape (sequence_len, batch_size, embedding_dim). Well, it is time to unfold the LSTM network:", "As we can observe, within the loop we are feeding the LSTM cell with the current time step, which is out[i]. Likewise, through the loop the hidden state and the cell state are updated \u201ci\u201d times, where \u201ci\u201d means the time step a time \u201ci\u201d.", "So now let\u2019s take a look at the complete forward function:", "Now, what if you want to stack LSTM cells in order to build a multilayer LSTM? Figure 9 shows a simple architecture about a 2-layer LSTM network.", "What we would need to do first is to initialize a second cell in the constructor (if you want to build an \u201cn\u201d-stacked LSTM network, you will need to initialize \u201cn\u201d LSTMCell\u2019s).", "In consequence, we would need to initialize the hidden and cell state for each LSTM layer.", "Now it is time to feed the LSTM network. The first layer will receive the input tensors which contain the embedded version of each token for each word. The second layer will receive as input the hidden state of the LSTMCell at time step \u201ct\u201d.", "Right after, if you would like to use the last hidden state of the LSTM network, you should take the last updated version of hidden_state_layer_2.", "So, this is how the forward function should look like:", "In this blog was explained the maths behind the LSTM network, specifically how the LSTM cell works. Likewise it was explained how the LSTMCell class can be implemented as well as how to prepare the data in order to build an LSTM neural network as well as a multilayer LSTM network by only using the LSTM cell.", "It is always important to know how the mechanics are behind the scenes, in this time we broke down the components of the LSTM and how those components are implemented with one of the most popular and powerful frameworks for deep learning nowadays, PyTorch.", "Machine Learning Engineer | Data Scientist | Software Engineer"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2899eb5696f3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://ferneutron.medium.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Fernando L\u00f3pez"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd606f5d846f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=post_page-d606f5d846f2----2899eb5696f3---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2899eb5696f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----2899eb5696f3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2899eb5696f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&source=-----2899eb5696f3---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=73353", "anchor_text": "Pixabay"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Understanding LSTM Networks"}, {"url": "https://medium.com/tag/lstm?source=post_page-----2899eb5696f3---------------lstm-----------------", "anchor_text": "Lstm"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----2899eb5696f3---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/nlp?source=post_page-----2899eb5696f3---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/python?source=post_page-----2899eb5696f3---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/tex?source=post_page-----2899eb5696f3---------------tex-----------------", "anchor_text": "Tex"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2899eb5696f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----2899eb5696f3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2899eb5696f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----2899eb5696f3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2899eb5696f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd606f5d846f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=post_page-d606f5d846f2----2899eb5696f3---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F14c367392dfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&newsletterV3=d606f5d846f2&newsletterV3Id=14c367392dfa&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----2899eb5696f3---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Written by Fernando L\u00f3pez"}, {"url": "https://ferneutron.medium.com/followers?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "537 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd606f5d846f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=post_page-d606f5d846f2----2899eb5696f3---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F14c367392dfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3&newsletterV3=d606f5d846f2&newsletterV3Id=14c367392dfa&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----2899eb5696f3---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hypothesis-testing-z-scores-337fb06e26ab?source=author_recirc-----2899eb5696f3----0---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=author_recirc-----2899eb5696f3----0---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=author_recirc-----2899eb5696f3----0---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Fernando L\u00f3pez"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2899eb5696f3----0---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/hypothesis-testing-z-scores-337fb06e26ab?source=author_recirc-----2899eb5696f3----0---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Hypothesis Testing: Z-ScoresA guide to understanding what hypothesis testing is and how to interpret and implement the z-test"}, {"url": "https://towardsdatascience.com/hypothesis-testing-z-scores-337fb06e26ab?source=author_recirc-----2899eb5696f3----0---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "\u00b78 min read\u00b7Aug 29, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F337fb06e26ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhypothesis-testing-z-scores-337fb06e26ab&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----337fb06e26ab----0-----------------clap_footer----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hypothesis-testing-z-scores-337fb06e26ab?source=author_recirc-----2899eb5696f3----0---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F337fb06e26ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhypothesis-testing-z-scores-337fb06e26ab&source=-----2899eb5696f3----0-----------------bookmark_preview----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2899eb5696f3----1---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2899eb5696f3----1---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2899eb5696f3----1---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2899eb5696f3----1---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2899eb5696f3----1---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2899eb5696f3----1---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2899eb5696f3----1---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----2899eb5696f3----1-----------------bookmark_preview----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2899eb5696f3----2---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----2899eb5696f3----2---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----2899eb5696f3----2---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2899eb5696f3----2---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2899eb5696f3----2---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2899eb5696f3----2---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2899eb5696f3----2---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----2899eb5696f3----2-----------------bookmark_preview----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3?source=author_recirc-----2899eb5696f3----3---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=author_recirc-----2899eb5696f3----3---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=author_recirc-----2899eb5696f3----3---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Fernando L\u00f3pez"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2899eb5696f3----3---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3?source=author_recirc-----2899eb5696f3----3---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "SHAP: Shapley Additive ExplanationsA step-by-step guide for understanding how SHAP works and how to interpret ML models by using the SHAP library"}, {"url": "https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3?source=author_recirc-----2899eb5696f3----3---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": "\u00b712 min read\u00b7Jul 11, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5a2a271ed9c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-shapley-additive-explanations-5a2a271ed9c3&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----5a2a271ed9c3----3-----------------clap_footer----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3?source=author_recirc-----2899eb5696f3----3---------------------2c209daa_9fee_4f9b_a889_8d73df920ec4-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5a2a271ed9c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-shapley-additive-explanations-5a2a271ed9c3&source=-----2899eb5696f3----3-----------------bookmark_preview----2c209daa_9fee_4f9b_a889_8d73df920ec4-------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "See all from Fernando L\u00f3pez"}, {"url": "https://towardsdatascience.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@coucoucamille?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@coucoucamille?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Coucou Camille"}, {"url": "https://medium.com/codex?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "CodeX"}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Time Series Prediction Using LSTM in PythonImplementation of Machine Learning Algorithm for Time Series Data Prediction."}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "\u00b76 min read\u00b7Feb 10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcodex%2F19b1187f580f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Ftime-series-prediction-using-lstm-in-python-19b1187f580f&user=Coucou+Camille&userId=d796c2fbb274&source=-----19b1187f580f----0-----------------clap_footer----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F19b1187f580f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Ftime-series-prediction-using-lstm-in-python-19b1187f580f&source=-----2899eb5696f3----0-----------------bookmark_preview----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Youssef Hosni"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Building An LSTM Model From Scratch In PythonHow to build a basic LSTM using Basic Python libraries"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "\u00b717 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&user=Youssef+Hosni&userId=859af34925b7&source=-----1dedd89de8fe----1-----------------clap_footer----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&source=-----2899eb5696f3----1-----------------bookmark_preview----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://zainbaq.medium.com/?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://zainbaq.medium.com/?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Zain Baquar"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Time Series Forecasting with Deep Learning in PyTorch (LSTM-RNN)An in depth tutorial on forecasting a univariate time series using deep learning with PyTorch"}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "\u00b712 min read\u00b7Feb 9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1ba339885f0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c&user=Zain+Baquar&userId=d16fc4a70186&source=-----1ba339885f0c----0-----------------clap_footer----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----2899eb5696f3----0---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1ba339885f0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c&source=-----2899eb5696f3----0-----------------bookmark_preview----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Nikos Kafritsas"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Temporal Fusion Transformer: Time Series Forecasting with Deep Learning \u2014 Complete TutorialCreate accurate & interpretable predictions"}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "\u00b712 min read\u00b7Nov 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd32c1e51cd91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91&user=Nikos+Kafritsas&userId=bec849d9e1d2&source=-----d32c1e51cd91----1-----------------clap_footer----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----2899eb5696f3----1---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "15"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd32c1e51cd91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91&source=-----2899eb5696f3----1-----------------bookmark_preview----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@mrconnor/forecasting-the-stock-market-using-lstm-will-it-rise-tomorrow-94ff6b6a34b6?source=read_next_recirc-----2899eb5696f3----2---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@mrconnor?source=read_next_recirc-----2899eb5696f3----2---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@mrconnor?source=read_next_recirc-----2899eb5696f3----2---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Connor Roberts"}, {"url": "https://medium.com/@mrconnor/forecasting-the-stock-market-using-lstm-will-it-rise-tomorrow-94ff6b6a34b6?source=read_next_recirc-----2899eb5696f3----2---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Forecasting the stock market using LSTM; will it rise tomorrow.Using a machine learning model, this tutorial will predict a stock\u2019s future value in real time with high accuracy on a stock exchange. To\u2026"}, {"url": "https://medium.com/@mrconnor/forecasting-the-stock-market-using-lstm-will-it-rise-tomorrow-94ff6b6a34b6?source=read_next_recirc-----2899eb5696f3----2---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "\u00b76 min read\u00b7Jan 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F94ff6b6a34b6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40mrconnor%2Fforecasting-the-stock-market-using-lstm-will-it-rise-tomorrow-94ff6b6a34b6&user=Connor+Roberts&userId=14ca88ad1cb0&source=-----94ff6b6a34b6----2-----------------clap_footer----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@mrconnor/forecasting-the-stock-market-using-lstm-will-it-rise-tomorrow-94ff6b6a34b6?source=read_next_recirc-----2899eb5696f3----2---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94ff6b6a34b6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40mrconnor%2Fforecasting-the-stock-market-using-lstm-will-it-rise-tomorrow-94ff6b6a34b6&source=-----2899eb5696f3----2-----------------bookmark_preview----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----2899eb5696f3----3---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----2899eb5696f3----3---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----2899eb5696f3----3---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Yujian Tang"}, {"url": "https://medium.com/plain-simple-software?source=read_next_recirc-----2899eb5696f3----3---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Plain Simple Software"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----2899eb5696f3----3---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "Long Short Term Memory in KerasHow to create an LSTM model with Tensorflow Keras"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----2899eb5696f3----3---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": "\u00b76 min read\u00b7Dec 1, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fplain-simple-software%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&user=Yujian+Tang&userId=1c4e6640433f&source=-----acdf61c056da----3-----------------clap_footer----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----2899eb5696f3----3---------------------a3452857_0f36_48c5_9a5f_0224f8df4f64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&source=-----2899eb5696f3----3-----------------bookmark_preview----a3452857_0f36_48c5_9a5f_0224f8df4f64-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----2899eb5696f3--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}