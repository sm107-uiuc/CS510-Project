{"url": "https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34", "time": 1683011222.117416, "path": "towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34/", "webpage": {"metadata": {"title": "Best practices for caching in Spark SQL | by David Vrba | Towards Data Science", "h1": "Best practices for caching in Spark SQL", "description": "In Spark SQL caching is a common technique for reusing some computation. It has the potential to speedup other queries that are using the same data, but there are some caveats that are good to keep\u2026"}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.StorageLevel", "anchor_text": "Here", "paragraph_index": 2}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.checkpoint", "anchor_text": "checkpoint", "paragraph_index": 30}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.localCheckpoint", "anchor_text": "localCheckpoint", "paragraph_index": 30}, {"url": "https://towardsdatascience.com/be-in-charge-of-query-execution-in-spark-sql-c83d1e16b9b8", "anchor_text": "article", "paragraph_index": 31}], "all_paragraphs": ["In Spark SQL caching is a common technique for reusing some computation. It has the potential to speedup other queries that are using the same data, but there are some caveats that are good to keep in mind if we want to achieve good performance. In this article, we will take a look under the hood to see how caching works internally and we will try to demystify Spark's behavior related to data persistence.", "In DataFrame API, there are two functions that can be used to cache a DataFrame, cache() and persist():", "They are almost equivalent, the difference is that persist can take an optional argument storageLevel by which we can specify where the data will be persisted. The default value of the storageLevel for both functions is MEMORY_AND_DISK which means that the data will be stored in memory if there is space for it, otherwise, it will be stored on disk. Here you can see the (PySpark) documentation for other possible storage levels.", "Caching is a lazy transformation, so immediately after calling the function nothing happens with the data but the query plan is updated by the Cache Manager by adding a new operator \u2014 InMemoryRelation. So this is just some information that will be used during the query execution later on when some action is called. Spark will look for the data in the caching layer and read it from there if it is available. If it doesn\u2019t find the data in the caching layer (which happens for sure the first time the query runs), it will become responsible for getting the data there and it will use it immediately afterward.", "The Cache Manager is responsible to keep track of what computation has already been cached in terms of the query plan. When the caching function is called, the Cache Manager is invoked directly under the hood and it pulls out the analyzed logical plan of the DataFrame on which the caching function is called and stores that plan in an indexed sequence called cachedData.", "The phase of the Cache Manager is part of logical planning and it takes place after the analyzer and before the optimizer:", "When you run a query with an action, the query plan will be processed and transformed. In the step of the Cache Manager (just before the optimizer) Spark will check for each subtree of the analyzed plan if it is stored in the cachedData sequence. If it finds a match it means that the same plan (the same computation) has already been cached (perhaps in some previous query) and so Spark can use that and thus it adds that information to the query plan using the InMemoryRelation operator which will carry information about this cached plan. This InMemoryRelation is then used in the phase of physical planning to create a physical operator\u2014 InMemoryTableScan.", "Here in the above picture you can see graphical and string representation of a query which was using caching. To see what transformations were cached you need to look into the string representation of the plan because the graphical representation doesn\u2019t show this information.", "Let\u2019s see a simple example to understand better how the Cache Manager works:", "Consider the following three queries. Which one of them will leverage the cached data?", "The decisive factor is the analyzed logical plan. If it is the same as the analyzed plan of the cached query, then the cache will be leveraged. For query number 1 you might be tempted to say that it has the same plan because the filter will be pushed by the optimizer in both cases anyway. But this is actually not entirely accurate. The important thing to understand is that the phase of the Cache Manager takes place before the optimizer. What would be the same are the optimized plans but not analyzed plans. So query n. 1 will not leverage the cache simply because the analyzed plans are different.", "For query n. 2 you might be again tempted to assume that it will use the cached data because the filter is more restrictive than the filter in the cached query. We can logically see that the queried data is in the cache, but Spark will not read it from there because of the same reason as before \u2014 the analyzed plans are different \u2014 this time the filtering condition is not the same. To use the cached data we can, however, fix the second query just by adding the filter there:", "At first sight, the filter col2 > 0 seems to be useless here, but it is not because now part of the analyzed logical plan will be identical with the cached plan and the Cache Manager will be able to find it and use the InMemoryRelation in the query plan.", "Query number 3 is tricky, at first sight, it appears that it also will have a different analyzed plan because the query is different \u2014 we select only col1. The filtering condition is, however, using col2, which is not present in the previous projection and so the analyzer will invoke a rule ResolveMissingReferences and it will add col2 to the projection and the analyzed plan will actually become identical with the cached plan. This time the Cache Manager will find it and use it.", "So the final answer is that query n. 3 will leverage the cached data.", "Let\u2019s list a couple of rules of thumb related to caching:", "There are situations where caching doesn\u2019t help at all and on the contrary slows down the execution. This is related for instance to queries based on large datasets stored in a columnar file format that supports column pruning and predicate pushdown such as parquet. Let\u2019s consider the following example, in which we will cache the entire dataset and then run some queries on top of it. We will use the following dataset and cluster properties:", "First, let\u2019s measure the execution times for the queries where caching is not used:", "Now run the same queries with caching (the entire dataset doesn\u2019t fit in memory and about 30% is cached on disk):", "No wonder that the first count takes 1.3min, there is the overhead related to putting data to memory. However, as you can see, also the second count and the query with the filter take longer for the cached dataset as compared to reading directly from parquet. It is a combination of two major reasons. The first one is the properties of the parquet file format \u2014 queries based on top of parquet are fast on its own. In the case of reading from parquet, Spark will read only the metadata to get the count so it doesn\u2019t need to scan the entire dataset. For the filtering query, it will use column pruning and scan only the id column. On the other hand, when reading the data from the cache, Spark will read the entire dataset. This can be seen from Spark UI, where you can check the input size for the first stage (see the picture below).", "The second reason is that the dataset is large and doesn\u2019t fit entirely in ram. Part of the data is stored on disk as well and reading from the disk is much slower than reading from ram.", "If you prefer using directly SQL instead of DataFrame DSL, you can still use caching, there are some differences, however.", "The main difference is that using SQL the caching is eager by default, so a job will run immediately and will put the data to the caching layer. To make it lazy as it is in the DataFrame DSL we can use the lazy keyword explicitly:", "To remove the data from the cache, just call:", "Sometimes you may wonder what data is already cached. One possibility is to check Spark UI which provides some basic information about data that is already cached on the cluster.", "Here for each cached dataset, you can see how much space it takes in memory or on disk. You can even zoom more and click on the record in the table which will take you to another page with details about each partition.", "To check whether the entire table is cached we can use Catalog API:", "The Catalog API can also be used to remove all data from the cache as follows:", "In Scala API you can also use the internal API of the Cache Manager which provides some functions, for instance, you can ask whether the Cache Manager is empty:", "Caching is one of more techniques that can be used for reusing some computation. Apart from caching there is also checkpointing and exchange-reuse.", "The checkpointing is useful for instance in situations where we need to break the query plan because it is too large. A large query plan may become a bottleneck in the driver where it is processed because the processing of a very large plan will take to long. The checkpoint will however break the plan and materialize the query. For the next transformations, Spark will start building a new plan. The checkpointing is related to two functions checkpoint and localCheckpoint which differ by the storage used for the data.", "The exchange-reuse where Spark persists the output of a shuffle on disk, is, on the other hand, a technique that can not be controlled directly by some API function, but instead, it is an internal feature that Spark handles on its own. In some special situations, it can be controlled indirectly by rewriting the query trying to achieve identical exchange branches. To read more about exchange-reuse, you can check my other article, where I describe it more in detail.", "In this article, we tried to demystify Spark's behavior related to caching. We have seen how it works under the hood and what are the differences between using DSL vs SQL. We discussed some best practices on how to make caching as efficient as possible. On one example we showed that for big datasets that do not fit in memory, it might be faster to avoid caching especially if the data is stored in columnar file format. We also mentioned some alternatives to caching such as checkpointing or reused exchange that can be useful for data persistence in some situations.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior ML Engineer at Sociabakers and Apache Spark trainer and consultant. I lecture Spark trainings, workshops and give public talks related to Spark."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb22fb0f02d34&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@vrba.dave?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "David Vrba"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7f216c64e33&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&user=David+Vrba&userId=b7f216c64e33&source=post_page-b7f216c64e33----b22fb0f02d34---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.cache", "anchor_text": "here"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.persist", "anchor_text": "here"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.StorageLevel", "anchor_text": "Here"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.checkpoint", "anchor_text": "checkpoint"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.localCheckpoint", "anchor_text": "localCheckpoint"}, {"url": "https://towardsdatascience.com/be-in-charge-of-query-execution-in-spark-sql-c83d1e16b9b8", "anchor_text": "article"}, {"url": "https://medium.com/tag/apache-spark?source=post_page-----b22fb0f02d34---------------apache_spark-----------------", "anchor_text": "Apache Spark"}, {"url": "https://medium.com/tag/spark-sql?source=post_page-----b22fb0f02d34---------------spark_sql-----------------", "anchor_text": "Spark Sql"}, {"url": "https://medium.com/tag/query-optimization?source=post_page-----b22fb0f02d34---------------query_optimization-----------------", "anchor_text": "Query Optimization"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b22fb0f02d34---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----b22fb0f02d34---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&user=David+Vrba&userId=b7f216c64e33&source=-----b22fb0f02d34---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&user=David+Vrba&userId=b7f216c64e33&source=-----b22fb0f02d34---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b22fb0f02d34---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b22fb0f02d34--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "David Vrba"}, {"url": "https://medium.com/@vrba.dave/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7f216c64e33&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&user=David+Vrba&userId=b7f216c64e33&source=post_page-b7f216c64e33--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F83cdb92c0d8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&newsletterV3=b7f216c64e33&newsletterV3Id=83cdb92c0d8c&user=David+Vrba&userId=b7f216c64e33&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}