{"url": "https://towardsdatascience.com/everything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284", "time": 1682995734.619106, "path": "towardsdatascience.com/everything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284/", "webpage": {"metadata": {"title": "Everything you need to know about Google\u2019s new PlaNet reinforcement learning network | by Cecelia Shao | Towards Data Science", "h1": "Everything you need to know about Google\u2019s new PlaNet reinforcement learning network", "description": "Data efficient reinforcement learning using transfer learning with a latent dynamics model"}, "outgoing_paragraph_urls": [{"url": "https://cloud.google.com/automl/", "anchor_text": "Google", "paragraph_index": 1}, {"url": "https://engineering.salesforce.com/open-sourcing-transmogrifai-4e5d0e098da2", "anchor_text": "Salesforce", "paragraph_index": 1}, {"url": "https://www.ibm.com/watson/services/visual-recognition/", "anchor_text": "IBM", "paragraph_index": 1}, {"url": "https://azure.microsoft.com/en-us/blog/announcing-automated-ml-capability-in-azure-machine-learning/", "anchor_text": "Azure", "paragraph_index": 1}, {"url": "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html", "anchor_text": "BERT", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/1801.06146", "anchor_text": "ULMFIT", "paragraph_index": 1}, {"url": "http://ruder.io/nlp-imagenet/", "anchor_text": "NLP\u2019s ImageNet moment has arrived", "paragraph_index": 2}, {"url": "https://blog.openai.com/language-unsupervised/", "anchor_text": "made", "paragraph_index": 3}, {"url": "https://techcrunch.com/2018/06/15/machines-learn-language-better-by-using-a-deep-understanding-of-words/", "anchor_text": "headlines", "paragraph_index": 3}, {"url": "https://medium.com/u/ce4d7f282c52?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Paras Chopra", "paragraph_index": 4}, {"url": "http://the correlations present in the sequence of observations, the fact that small updates to Q may significantly change the policy and therefore change the data distribution, and the correlations between the action-values and the target values.", "anchor_text": "paper on RL with neural networks", "paragraph_index": 6}, {"url": "https://arxiv.org/pdf/1811.04551.pdf", "anchor_text": "Deep Planning Network (PlaNet) agent", "paragraph_index": 9}, {"url": "https://ai.googleblog.com/2019/02/introducing-planet-deep-planning.html", "anchor_text": "the original Google AI blog post introducing PlaNet", "paragraph_index": 11}, {"url": "https://deepdrive.berkeley.edu/node/209", "anchor_text": "the simultaneous training of a latent dynamics model in conjunction with a provided reward will create a latent embedding sensitive to factors of variation relevant the reward signal and insensitive to extraneous factors of the simulated environment used during training", "paragraph_index": 19}, {"url": "https://arxiv.org/abs/1903.10404", "anchor_text": "On the use of Deep Autoencoders for Efficient Embedded Reinforcement Learning", "paragraph_index": 20}, {"url": "http://karpathy.github.io/2016/05/31/rl/", "anchor_text": "Deep Reinforcement Learning: Pong from Pixel", "paragraph_index": 25}], "all_paragraphs": ["Transfer learning is all the rage in the machine learning community these days.", "Transfer learning serves as the basis for many of the managed AutoML services that Google, Salesforce, IBM, and Azure provide. It now figures prominently in the latest NLP research \u2014 appearing in Google\u2019s Bidirectional Encoder Representations from Transformers (BERT) model and in Sebastian Ruder and Jeremy Howard\u2019s Universal Language Model Fine-tuning for Text Classification (ULMFIT).", "As Sebastian writes in his blog post, \u2018NLP\u2019s ImageNet moment has arrived\u2019:", "These works made headlines by demonstrating that pretrained language models can be used to achieve state-of-the-art results on a wide range of NLP tasks. Such methods herald a watershed moment: they may have the same wide-ranging impact on NLP as pretrained ImageNet models had on computer vision.", "We\u2019re also starting to see examples of neural networks that can handle multiple tasks using transfer learning across domains. Paras Chopra has an excellent tutorial for one PyTorch network that can conduct an image search based on a textual description, search for similar images and words, and write captions for images (link to his post below).", "The main question at hand is: could transfer learning have applications within reinforcement learning?", "Compared to other machine learning methods, deep reinforcement learning has a reputation for being data hungry, subject to instability in its learning process (see Deepmind\u2019s paper on RL with neural networks), and a laggard in terms of performance. There\u2019s a reason why the main areas and use cases where we\u2018ve seen reinforcement learning being applied to are games or robotics \u2014 namely, scenarios that can generate significant amounts of simulated data.", "At the same time, many believe that reinforcement learning is still the most viable approach for achieving Artificial General Intelligence (AGI). Yet reinforcement learning continually bumps up against the ability to generalize to many tasks in diverse settings \u2014 a key attribute of intelligence.", "After all, learning is not an easy task. These reinforcement learning agents must process and derive efficient representations of their environment when these environments have both high-dimensional sensory inputs and either no notion of or an extremely delayed notion of progress, reward, or success. On top of that, they have to use this information to generalize past experiences to new situations.", "Up to this point, reinforcement learning techniques and research has primarily focused on mastery of individual tasks. I was interested to see if transfer learning could aid reinforcement learning research achieve generality \u2014 so I was very excited when the Google AI team released the Deep Planning Network (PlaNet) agent earlier this year.", "For the project, the PlaNet agent was tasked with \u2018planning\u2019 a sequence of actions to achieve a goal like pole balancing, teaching a virtual entity (human or cheetah) to walk, or keeping a box rotating by hitting it in a specific location.", "From the original Google AI blog post introducing PlaNet, here are the six tasks (plus the challenges associated with that task):", "There are a few common goals between these tasks that the PlaNet needed to achieve:", "So how did the Google AI team achieve these goals?", "PlaNet AI marked a departure from traditional reinforcement learning in three distinct ways:", "Let\u2019s dig into each one of these differentiators and see how they impact model performance.", "The authors\u2019 main decision here was whether to use compact latent states or original sensory inputs from the environment.", "There are a few trade-offs here. Using a compact latent space means an extra difficulty bump because now the agent not only has to learn to defeat the game but also has to build an understanding of the visual concepts within the game \u2014 this encoding and decoding of images requires significant computation.", "The key benefits to using compact latent state spaces are that it allows the agent to learn more abstract representations like the objects\u2019 positions and velocities and also avoid having to generate images. This means that the actual planning is much faster because the agent only needs to predict future rewards and not images or the scenario.", "Latent dynamics models are being more commonly used now since researchers argue that \u201cthe simultaneous training of a latent dynamics model in conjunction with a provided reward will create a latent embedding sensitive to factors of variation relevant the reward signal and insensitive to extraneous factors of the simulated environment used during training.\u201d", "Check out this excellent paper \u2018On the use of Deep Autoencoders for Efficient Embedded Reinforcement Learning\u2019, where they state:", "In autonomous embedded systems, it is often vital to reduce the amount of actions taken in the real world and energy required to learn a policy. Training reinforcement learning agents from high dimensional image representations can be very expensive and time consuming. Autoencoders are deep neural network used to compress high dimensional data such as pixelated images into small latent representations.", "Model-based reinforcement learning attempts to have agents learn how the world behaves in general. Instead of directly mapping observations to actions, this allows an agent to explicitly plan ahead, to more carefully select actions by \u201cimagining\u201d their long-term outcomes. The benefit of taking a model-based approach is that it\u2019s much more sample efficient \u2014 meaning that it doesn\u2019t learn each new task from scratch.", "One way to look at the difference between model-free and model-based reinforcement learning is to see whether we\u2019re optimizing for maximum rewards or least cost (model-free = max rewards while model-based = least cost).", "Model-free reinforcement learning techniques like using Policy Gradients can be brute force solutions, where the correct actions are eventually discovered and internalized into a policy. Policy Gradients have to actually experience a positive reward, and experience it very often in order to eventually and slowly shift the policy parameters towards repeating moves that give high rewards.", "One interesting note is how the type of task affects which approach you might choose to take. In Andrej Kaparthy\u2019s awesome post \u2018Deep Reinforcement Learning: Pong from Pixels\u2019, he describes games/tasks where Policy Gradients can beat humans:", "\u201cThere are many games where Policy Gradients would quite easily defeat a human. In particular, anything with frequent reward signals that requires precise play, fast reflexes, and not too much long-term planning would be ideal, as these short-term correlations between rewards and actions can be easily \u201cnoticed\u201d by the approach, and the execution meticulously perfected by the policy. You can see hints of this already happening in our Pong agent: it develops a strategy where it waits for the ball and then rapidly dashes to catch it just at the edge, which launches it quickly and with high vertical velocity. The agent scores several points in a row repeating this strategy. There are many ATARI games where Deep Q Learning destroys human baseline performance in this fashion \u2014 e.g. Pinball, Breakout, etc.\u201d", "After the first game, the PlaNet agent already had a rudimentary understanding of gravity and dynamics and was able to re-use knowledge in next games. As a result, PlaNet was often 50 times more efficient than previous techniques that learned from scratch. This meant that the agent only need to look at five frames of an animation (literally a 1/5 of second of footage) to be able to predict how the sequence will continue with remarkably high accuracy. Implementation-wise, it means that the team did not have to train six separate models to achieve solid performance on the tasks.", "From the paper: \u201cPlaNet solves a variety of image-based control tasks, competing with advanced model-free agents in terms of final performance while being 5000% more data efficient on average\u2026These learned dynamics can be independent of any specific task and thus have the potential to transfer well to other tasks in the environment\u201d", "Check out the stunning data efficiency gain that PlaNet had over D4PG with only 2,000 episodes:", "As well as these plots of the test performance against the number of collected episodes (PlaNet is in blue):", "These are incredibly exciting results that mean a new era for data efficient and generalizable reinforcement learning. Keep your eye on this space!", "Want to learn more? Here are some other great resources on reinforcement learning:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F144c2ca3f284&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ceceliashao?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ceceliashao?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Cecelia Shao"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F370d0382c596&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&user=Cecelia+Shao&userId=370d0382c596&source=post_page-370d0382c596----144c2ca3f284---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F144c2ca3f284&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F144c2ca3f284&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://cloud.google.com/automl/", "anchor_text": "Google"}, {"url": "https://engineering.salesforce.com/open-sourcing-transmogrifai-4e5d0e098da2", "anchor_text": "Salesforce"}, {"url": "https://www.ibm.com/watson/services/visual-recognition/", "anchor_text": "IBM"}, {"url": "https://azure.microsoft.com/en-us/blog/announcing-automated-ml-capability-in-azure-machine-learning/", "anchor_text": "Azure"}, {"url": "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html", "anchor_text": "BERT"}, {"url": "https://arxiv.org/abs/1801.06146", "anchor_text": "ULMFIT"}, {"url": "http://ruder.io/nlp-imagenet/", "anchor_text": "NLP\u2019s ImageNet moment has arrived"}, {"url": "https://blog.openai.com/language-unsupervised/", "anchor_text": "made"}, {"url": "https://techcrunch.com/2018/06/15/machines-learn-language-better-by-using-a-deep-understanding-of-words/", "anchor_text": "headlines"}, {"url": "https://medium.com/u/ce4d7f282c52?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Paras Chopra"}, {"url": "https://towardsdatascience.com/one-neural-network-many-uses-image-captioning-image-search-similar-image-and-words-in-one-model-1e22080ce73d", "anchor_text": "One neural network, many usesBuild image search, image captioning, similar words and similar images using a single modeltowardsdatascience.com"}, {"url": "http://the correlations present in the sequence of observations, the fact that small updates to Q may significantly change the policy and therefore change the data distribution, and the correlations between the action-values and the target values.", "anchor_text": "paper on RL with neural networks"}, {"url": "https://arxiv.org/pdf/1811.04551.pdf", "anchor_text": "Deep Planning Network (PlaNet) agent"}, {"url": "https://www.youtube.com/watch?v=tZk1eof_VNA&feature=youtu.be", "anchor_text": "See the longer video"}, {"url": "https://ai.googleblog.com/2019/02/introducing-planet-deep-planning.html", "anchor_text": "the original Google AI blog post introducing PlaNet"}, {"url": "https://deepdrive.berkeley.edu/node/209", "anchor_text": "the simultaneous training of a latent dynamics model in conjunction with a provided reward will create a latent embedding sensitive to factors of variation relevant the reward signal and insensitive to extraneous factors of the simulated environment used during training"}, {"url": "https://ai.googleblog.com/2019/02/introducing-planet-deep-planning.html", "anchor_text": "Learned Latent Dynamics Model"}, {"url": "https://arxiv.org/abs/1903.10404", "anchor_text": "On the use of Deep Autoencoders for Efficient Embedded Reinforcement Learning"}, {"url": "https://medium.com/@jonathan_hui/rl-model-based-reinforcement-learning-3c2b6f0aa323", "anchor_text": "Great diagram"}, {"url": "https://medium.com/u/bd51f1a63813?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Jonathan Hui"}, {"url": "http://karpathy.github.io/2016/05/31/rl/", "anchor_text": "Deep Reinforcement Learning: Pong from Pixel"}, {"url": "https://planetrl.github.io/", "anchor_text": "the paper"}, {"url": "https://arxiv.org/pdf/1811.04551.pdf", "anchor_text": "the PlaNet paper"}, {"url": "https://www.topbots.com/most-important-ai-reinforcement-learning-research/", "anchor_text": "TOPBOTS\u2019 Most Important AI Reinforcement Learning Research"}, {"url": "https://www.youtube.com/watch?v=fdY7dt3ijgY", "anchor_text": "Open AI\u2019s Spinning Up in Deep RL tutorial"}, {"url": "https://www.youtube.com/watch?v=2pWv7GOvuf0&list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT", "anchor_text": "DeepMind\u2019s David Silver\u2019s RL Course (Lectures 1\u201310)"}, {"url": "https://skymind.ai/wiki/deep-reinforcement-learning", "anchor_text": "Skymind.ai\u2019s Deep Reinforcement Learning"}, {"url": "http://karpathy.github.io/2016/05/31/rl/", "anchor_text": "Andrej Karparthy\u2019s Deep Reinforcement Learning: Pong from Pixels"}, {"url": "https://medium.com/u/6278d12b0682?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Dipanjan (DJ) Sarkar"}, {"url": "https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a", "anchor_text": "Transfer Learning Guide"}, {"url": "https://medium.com/comet-ml", "anchor_text": "ollow us on Medium"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----144c2ca3f284---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----144c2ca3f284---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----144c2ca3f284---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----144c2ca3f284---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/featured?source=post_page-----144c2ca3f284---------------featured-----------------", "anchor_text": "Featured"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F144c2ca3f284&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&user=Cecelia+Shao&userId=370d0382c596&source=-----144c2ca3f284---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F144c2ca3f284&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&user=Cecelia+Shao&userId=370d0382c596&source=-----144c2ca3f284---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F144c2ca3f284&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F144c2ca3f284&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----144c2ca3f284---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----144c2ca3f284--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----144c2ca3f284--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----144c2ca3f284--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ceceliashao?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ceceliashao?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Cecelia Shao"}, {"url": "https://medium.com/@ceceliashao/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.3K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F370d0382c596&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&user=Cecelia+Shao&userId=370d0382c596&source=post_page-370d0382c596--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F667173e72180&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feverything-you-need-to-know-about-googles-new-planet-reinforcement-learning-network-144c2ca3f284&newsletterV3=370d0382c596&newsletterV3Id=667173e72180&user=Cecelia+Shao&userId=370d0382c596&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}