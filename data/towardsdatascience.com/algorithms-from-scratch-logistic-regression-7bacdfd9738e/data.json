{"url": "https://towardsdatascience.com/algorithms-from-scratch-logistic-regression-7bacdfd9738e", "time": 1683010970.0075378, "path": "towardsdatascience.com/algorithms-from-scratch-logistic-regression-7bacdfd9738e/", "webpage": {"metadata": {"title": "Algorithms from Scratch: Logistic Regression | by Kurtis Pykes | Towards Data Science", "h1": "Algorithms from Scratch: Logistic Regression", "description": "Contrary to popular belief, I hereby state that Logistic Regression is NOT a classification algorithm (on its own) \u2014 In fact, Logistic Regression is actually a regression model so don\u2019t be surprised\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Regression_analysis", "anchor_text": "Wikipedia", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "Wikipedia", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Multiclass_classification#:~:text=%2Drest-,One%2Dvs.,all%20other%20samples%20as%20negatives.", "anchor_text": "this link", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/tagged/algorithms-from-scratch", "anchor_text": "Algorithms from Scratch", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Binomial_distribution", "anchor_text": "Binomial distribution", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Generalized_linear_model", "anchor_text": "Wikipedia", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model", "anchor_text": "Wikipedia", "paragraph_index": 15}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "Documentation", "paragraph_index": 21}, {"url": "https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d", "anchor_text": "The derivative of Cost function for Logistic Regression", "paragraph_index": 24}], "all_paragraphs": ["Contrary to popular belief, I hereby state that Logistic Regression is NOT a classification algorithm (on its own) \u2014 In fact, Logistic Regression is actually a regression model so don\u2019t be surprised \u201cregression\u201d is present in its naming. Regression analysis is a set of statistical process for estimating the relationships between a dependent variable and one or more independent variables (Source: Wikipedia). With that being stated, Logistic regression is empathetically not a classification algorithm \u2014 it does not perform statistical classification \u2014 since it is simply estimating the parameters of a logistic model.", "Logistic Regression is a statistical model that in its most basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. (Source: Wikipedia)", "What allows Logistic Regression to be used a classification algorithm, as we so commonly do in Machine Learning, is the use of a threshold (may also be referred to as a cut off or decision boundary), which in-turn will classify the inputs with a probability greater than the threshold as one class and probabilities below the threshold as another class.", "See this link to see how we may approach multiclass classification problem.", "Now that\u2019s out of the way, let\u2019s revert our attention back to the purpose of the Algorithms from Scratch series.", "Note: There are many Machine Learning frameworks with highly optimized code which makes coding Machine learning algorithms from scratch a redundant task in practical settings. However, when we build algorithms from scratch it helps us to gain a deeper intuition of what is happening in the models which may pay high returns when trying to improve our model.", "In the last episode of Algorithms from Scratch: Linear Regression, I stated \u201cIt is usually one of the first algorithms that is learnt when first learning Machine Learning, due to its simplicity and how it builds into other algorithms like Logistic Regression and Neural Networks\u201d \u2014 You\u2019ll now see what I meant.", "How do we go from predicting a continuous variable to Bernoulli variables (i.e. \u201csuccess\u201d or \u201cfailure\u201d)? Well, since the response data (what we are trying to predict) is binary (taking on values 0 and 1), ergo made of only 2 values, we can assume the distribution of our response variable is now from the Binomial distribution \u2014 This calls for a perfect time to introduce the Generalized Linear Model (GLM) which was formulated John Nelder and Robert Wedderburn.", "The GLM model allows for the response variable to have an error distribution other than the normal distribution. In our situation, where we now have a Binomial distribution, by using a GLM model we can generalize linear regression by allowing the linear model to be related to the response variable via a link function and allowing the magnitude of the variance of each measurement to be a function of its predicted value (Source: Wikipedia).", "Long story short, Logistic Regression is a special case of the GLM with a binomial conditional response and logit link.", "Before going any further we should clear up some statistical terms (In layman\u2019s terms that is):", "Probabilities range between 0 and 1, whereas odds are not constrained to be between 0 and 1, but can take any value from 0 to infinity.", "We can derive the odds from the probability by dividing the ratio of the probability of winning (using our example that would be 1/4) by the ratio of the probability of losing (3/4) which gives us 1/3 \u2014 the odds. See Figure 1 for how we can express that mathematically.", "If Chelsea were a bad Football Team (Unimaginable, I know) the odds would be against them winning therefore ranging between 0 and 1. However, since we all know that Chelsea is one of the greatest teams in the world (definitely the best in London without a doubt), as a consequence, the odds in favour of Chelsea winning will be between 1 and infinity. The asymmetry makes it difficult to compare the odds for or against Chelsea winning so we take the log of the odds to make everything symmetrical.", "Figure 1 shows us that we can calculate the odds with probabilities, that being the case, we can also calculate the log of the odds using the formula presented in Figure 1. The log of the ratio of the probabilities is called the logit function and forms the basis of Logistic Regression. Let\u2019s understand this better by considering a logistic model with given parameters and see how the coefficients can be estimated from the data.", "Note: The following example is Sourced from Wikipedia in the Example section of Logistic Regression.", "Consider a model that has two independent variables (X1 and X2) and a single Bernoulli response variable Y, which we denote p = P(Y=1). We assume there is a linear relationship between the independent variables and the log-odds of the event that Y=1 and can be expressed mathematically as:", "By exponentiating the log-odds we recover the odds like so:", "By simple algebraic manipulation, the probability that Y=1 is:", "On that account, Figure 4 shows us that we can easily compute the log-odds for a given observation or the probability that Y= 0 given that we have the parameters of the linear model. Without being used in combination with threshold that makes dichotomous the predicted probabilities of the response, Logistic Regression remains a regression model.", "For this section I leverage 3 Python Frameworks: NumPy for Linear Algebra, Pandas for Data Manipulation and Scikit-Learn for Machine Learning tools.", "First, we need a dataset. I use sklearn.datasets.load_breast_cancer which is a classic binary classification dataset \u2014 See Documentation.", "Next, we split the predictors and the response variables then create a training and test set.", "Plenty of the work we done to build Linear Regression from scratch (See link below) can borrowed with a few slight changes to adjust our model for classification using Logistic Regression.", "Notable differences are that we now apply a logit function to our linear model, on inference we make every output greater than 0.5 from our logit model to be classified as class one (class 0 otherwise), and we use a different cost function to work for our classification model, since MSE would make our loss function non-convex\u2014 To learn more about the cost function used then you should definitely read The derivative of Cost function for Logistic Regression.", "Great, we obtain the same accuracy as the Scikit-Learn implementation.", "Now, we will repeat this with Object oriented programming which is considered to be much better for collaboration.", "To check if we implemented it correctly we can see if the predictions are the same as our procedural implementation as we already know this is approximately equal to Scikit-learn\u2019s implementation.", "This returns an array that is True for each value.", "Logistic Regression is often what is taught after Linear Regression in most online Courses. Although generally Logistic Regression is used for regression in different domains, by combining it with a threshold we are able to use it as a very useful, easy to implement classifier which turns out to be a good first model to implement when approaching classification problems.", "Thank you for taking the time to go through this story. If there is anything that I have missed, said incorrectly, or you\u2019d like me to clarify then please leave a response in the comments. Additionally, If you\u2019d like to get in contact with me, I am most accessible on LinkedIn.", "You may access the full Algorithms from Scratch series here:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7bacdfd9738e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kurtispykes.medium.com/?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": ""}, {"url": "https://kurtispykes.medium.com/?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "Kurtis Pykes"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5ba760786877&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&user=Kurtis+Pykes&userId=5ba760786877&source=post_page-5ba760786877----7bacdfd9738e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bacdfd9738e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bacdfd9738e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/algorithms-from-scratch", "anchor_text": "Algorithms From Scratch"}, {"url": "https://unsplash.com/@marcinjozwiak?utm_source=medium&utm_medium=referral", "anchor_text": "Marcin Jozwiak"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Regression_analysis", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Multiclass_classification#:~:text=%2Drest-,One%2Dvs.,all%20other%20samples%20as%20negatives.", "anchor_text": "this link"}, {"url": "https://towardsdatascience.com/tagged/algorithms-from-scratch", "anchor_text": "Algorithms from Scratch"}, {"url": "https://github.com/kurtispykes/ml-from-scratch/blob/master/logistic_regression.ipynb", "anchor_text": "kurtispykes/ml-from-scratchPermalink Dismiss GitHub is home to over 50 million developers working together to host and review code, manage\u2026github.com"}, {"url": "https://en.wikipedia.org/wiki/Binomial_distribution", "anchor_text": "Binomial distribution"}, {"url": "https://en.wikipedia.org/wiki/Generalized_linear_model", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model", "anchor_text": "Wikipedia"}, {"url": "https://medium.com/u/102f526f83de?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "Saket Thavanani"}, {"url": "https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d", "anchor_text": "The derivative of Cost function for Logistic Regression"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "Documentation"}, {"url": "https://towardsdatascience.com/algorithms-from-scratch-linear-regression-c654353d1e7c", "anchor_text": "Algorithms From Scratch: Linear RegressionDetailing and Building a Linear Regression model from scratchtowardsdatascience.com"}, {"url": "https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d", "anchor_text": "The derivative of Cost function for Logistic Regression"}, {"url": "https://www.linkedin.com/in/kurtispykes/", "anchor_text": "Kurtis Pykes - AI Writer - Towards Data Science | LinkedInView Kurtis Pykes' profile on LinkedIn, the world's largest professional community. Kurtis has 1 job listed on their\u2026www.linkedin.com"}, {"url": "https://towardsdatascience.com/tagged/algorithms-from-scratch", "anchor_text": "Algorithms From Scratch - Towards Data ScienceRead writing about Algorithms From Scratch in Towards Data Science. A Medium publication sharing concepts, ideas, and\u2026towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7bacdfd9738e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7bacdfd9738e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7bacdfd9738e---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/algorithms-from-scratch?source=post_page-----7bacdfd9738e---------------algorithms_from_scratch-----------------", "anchor_text": "Algorithms From Scratch"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7bacdfd9738e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&user=Kurtis+Pykes&userId=5ba760786877&source=-----7bacdfd9738e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7bacdfd9738e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&user=Kurtis+Pykes&userId=5ba760786877&source=-----7bacdfd9738e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bacdfd9738e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7bacdfd9738e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7bacdfd9738e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7bacdfd9738e--------------------------------", "anchor_text": ""}, {"url": "https://kurtispykes.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kurtispykes.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kurtis Pykes"}, {"url": "https://kurtispykes.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.3K Followers"}, {"url": "https://www.fullstackfreelancershub.com/wisdom-wednesday", "anchor_text": "https://www.fullstackfreelancershub.com/wisdom-wednesday"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5ba760786877&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&user=Kurtis+Pykes&userId=5ba760786877&source=post_page-5ba760786877--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffde3d752d24c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-from-scratch-logistic-regression-7bacdfd9738e&newsletterV3=5ba760786877&newsletterV3Id=fde3d752d24c&user=Kurtis+Pykes&userId=5ba760786877&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}