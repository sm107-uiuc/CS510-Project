{"url": "https://towardsdatascience.com/building-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1", "time": 1683001884.758743, "path": "towardsdatascience.com/building-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1/", "webpage": {"metadata": {"title": "Building and Deploying a Data Science Project in Two weeks | by Harsh Rana | Towards Data Science", "h1": "Building and Deploying a Data Science Project in Two weeks", "description": "I\u2019m a kinesthetic learner; I learn by doing, building and breaking things. In this article, I\u2019ll share how I built a basic sentiment analysis machine learning model+web application and deployed it in\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/hr23232323/nlp_medium_p1", "anchor_text": "Github", "paragraph_index": 2}, {"url": "https://www.yelp.com/dataset", "anchor_text": "yelp reviews dataset", "paragraph_index": 3}, {"url": "https://github.com/hr23232323/nlp_medium_p1/blob/master/data_cleaning.ipynb", "anchor_text": "few lines of code", "paragraph_index": 4}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://www.linkedin.com/in/harshrana1997/", "anchor_text": "LinkedIn", "paragraph_index": 23}, {"url": "http://www.harshrana.com", "anchor_text": "website", "paragraph_index": 23}], "all_paragraphs": ["I\u2019m a kinesthetic learner; I learn by doing, building and breaking things. In this article, I\u2019ll share how I built a basic sentiment analysis machine learning model+web application and deployed it in under two weeks to learn three new technologies- natural language processing (NLP), flask and incremental/ongoing learning.", "My primary goals with this undertaking were the following:", "I wanted to do all this in a rapid building/learning mode with a focus on functionality, not on aesthetic. Some of the other topics I ended up exploring and learning along the way include model optimization, incremental/ongoing learning and jQuery. All Jupyter notebooks and code used in this article can be found on my Github.", "For this project, I needed a dataset which contained text data, but was already labelled and structured. This would enable me to focus on NLP-based preprocessing while skimming over other forms of data preparation. After looking at a few different options, I ended up choosing the yelp reviews dataset because it was pre-labelled (text review and 1\u20135 star ratings), but the actual text inside the reviews was messy and inconsistent. You can see an example record from the raw JSON dataset below-", "For my model, I was only interested in the text review and the 1\u20135 stars (maybe in the future I could try doing something fun with the other attributes). Additionally, to further simplify my training process and stick to the rapid development mindset, I decided to modify the labels from 1\u20135 ratings to a positive (4 or 5 stars) or negative (1 or 2 stars) sentiment associated with the textual review. I dropped the reviews with a 3 star rating because their classification would be difficult to validate. A few lines of code later, I had my data inside a pandas dataframe which can be seen below-", "There are many potential issues with the text. Some characters such as * and \\n serve no real purpose in helping understand the text, while others such as $ and !, may bring insight into how the reviewer was feeling. Additionally, there are many words/slangs which a human could understand ($8Gs = $8000), but would make little to no sense for a machine. All these and many more scenarios will be tackled in the next section.", "To prepare the data for classification, we have to first design a NLP pipeline to prepare the text data. There are several steps involved in an NLP pipeline, some of which can be seen below-", "In our case, steps such as part-of-speech tagging and named entity recognition would not be very beneficial, as the task at hand is a sample classification problem. So we\u2019ll focus on techniques which offer the most bang for our buck: tokenization, stop words removal and ngram utilization (discussed below).", "For the first iteration of my NLP model, I decided to implement a simple bag-of-words model using sklearn\u2019s CountVectorizer() method and train it on roughly 100,000 rows. I utilized sklearn\u2019s train_test_split() method to break up my data into training and testing blocks. After trying a few different classifiers such as logistic regression, multinomial naive bayes and linear support vector machine, I found that the logistic regression model worked best for this data. Here\u2019s the confusion matrix of the respective classifiers-", "Thinking further ahead, I found that the logistic regression model would be unable to utilize incremental learning later in the project, while the linear SVM (powered by sklearn\u2019s SGDClassifier()) would. The accuracy trade-off was small with the logistic regression having an average F1-score of 93%, while the SVM having an average F1-score of 92%. Thus, I decided to proceed with the linear SVM to utilize incremental learning later in the project.", "Additionally, I chose to replace CountVectorizer() with the HashingVectorizer() as it uses a technique called hashing to decrease the size of the input processing model by > 99%. The only major trade-off is the loss of ability to look at explicit words in the model (hashing converts all words to numbers), which wasn\u2019t a big concern for me. You can read more about this model here.", "I did a few things to optimize my model. As you can see from the confusion matrix above, my training and testing data both have a lower number of negative reviews, as compared to positive. This resulted in my F1-score for the negative label being 82% and for the positive label being 94%. To mitigate this disparity, I had to balance my dataset by making sure that the number of records corresponding to the two labels was comparable. After balancing my dataset, I proceeded to omit stop words like and, the, a etc. from the bag-of-words model.", "After these two steps my model\u2019s F1-score dropped from 92% to 91%, but the previous disparity between the two labels was smaller. The F1-score of my negative and positive reviews were 91% and 90% respectively, so overall the classifier was performing better. Next, I decided to utilize ngrams to further optimize my model.", "Ngrams simply refers to a continuous group of n words which co-occur. For example-", "You can even see from the example above why utilizing ngrams would be helpful. The 2-gram \u201cdata science\u201d appearing in a sentence would provide more information than just the 1-grams \u201cdata\u201d and \u201cscience\u201d. Now, back to the optimization: I utilized 1,2 grams for further strengthening my model. The confusion matrices before and after these optimizations can be seen below-", "As you can see, this was a major improvement as both positive and negative incorrect guesses dropped. The model\u2019s final F1-score moved up to 92%, and the disparity between the two classes was negligible. At this point, the model was ready. Next up, incremental/ongoing learning.", "As you all have already seen, our sentiment classification model is far from perfect. This is where the beauty of incremental learning comes in.", "Incremental learning is a machine learning paradigm where the learning process takes place whenever new example(s) emerge and adjusts what has been learned according to the new example(s).\u00b9", "If you think about how human beings learn language, you\u2019ll quickly see that they\u2019re learning incrementally. Every time a parent corrects a child, a teacher corrects a student or two friends correct each other, a form of incremental learning takes place. In this section, we\u2019ll build a similar system for our NLP model so users can \u201ccorrect\u201d it when it makes a classification error.", "Remember how we chose the SGDClassifier() due to this functionality earlier? The SGDClassifier has a built-in partial_fit() method which will help us implement incremental learning in a few lines of code as follows-", "Using this, we can train our model on new data whenever a mistake is made while still maintaining the initial training. An example can be seen below-", "So far we\u2019ve achieved quite a bit: we\u2019ve created a basic NLP classifier which can read a piece of text and classify the sentiment into either positive or negative. We\u2019ve optimized our model using NLP techniques such as stop words and ngrams to achieve a baseline F1-score of 92%. And lastly, we\u2019ve written code to incrementally train our classifier, whenever it makes a mistake, so the learning never stops!", "In the next part, we\u2019ll build on top of everything we\u2019ve covered so far and build a basic web application using Flask. In particular, we\u2019ll build APIs to classify user-entered text and incrementally teach/correct our model. This will enable us to interact with our model as a user and further learn about machine learning model deployment!", "I hope you enjoyed reading this article just as much as I enjoyed putting it together. If you have any questions, feedback or comments, feel free to get in touch with me through LinkedIn, or my website.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A software engineer with a passion for data, personal finance and health."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3c63f0acdab1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@hr23232323?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hr23232323?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "Harsh Rana"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe594c58dc55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&user=Harsh+Rana&userId=be594c58dc55&source=post_page-be594c58dc55----3c63f0acdab1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c63f0acdab1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c63f0acdab1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://towardsdatascience.com/tagged/data-science-sprints/", "anchor_text": "Data Science Sprints"}, {"url": "https://github.com/hr23232323/nlp_medium_p1", "anchor_text": "Github"}, {"url": "https://www.yelp.com/dataset", "anchor_text": "yelp reviews dataset"}, {"url": "https://github.com/hr23232323/nlp_medium_p1/blob/master/data_cleaning.ipynb", "anchor_text": "few lines of code"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/harshrana1997/", "anchor_text": "LinkedIn"}, {"url": "http://www.harshrana.com", "anchor_text": "website"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3c63f0acdab1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----3c63f0acdab1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/software-development?source=post_page-----3c63f0acdab1---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----3c63f0acdab1---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/tag/data-science-sprints?source=post_page-----3c63f0acdab1---------------data_science_sprints-----------------", "anchor_text": "Data Science Sprints"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c63f0acdab1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&user=Harsh+Rana&userId=be594c58dc55&source=-----3c63f0acdab1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c63f0acdab1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&user=Harsh+Rana&userId=be594c58dc55&source=-----3c63f0acdab1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c63f0acdab1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3c63f0acdab1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3c63f0acdab1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3c63f0acdab1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hr23232323?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hr23232323?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Harsh Rana"}, {"url": "https://medium.com/@hr23232323/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "348 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe594c58dc55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&user=Harsh+Rana&userId=be594c58dc55&source=post_page-be594c58dc55--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd6dd06d519e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-and-deploying-a-data-science-project-in-two-weeks-3c63f0acdab1&newsletterV3=be594c58dc55&newsletterV3Id=d6dd06d519e&user=Harsh+Rana&userId=be594c58dc55&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}