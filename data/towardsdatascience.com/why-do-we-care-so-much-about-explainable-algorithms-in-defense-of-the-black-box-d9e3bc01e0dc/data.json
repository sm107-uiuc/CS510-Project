{"url": "https://towardsdatascience.com/why-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc", "time": 1682993201.272332, "path": "towardsdatascience.com/why-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc/", "webpage": {"metadata": {"title": "Why do we care so much about explainable algorithms? In defense of the black box | by Alex P. Miller | Towards Data Science", "h1": "Why do we care so much about explainable algorithms? In defense of the black box", "description": "Algorithms are starting to be used in applications with high-stakes consequences across a variety of domains. These include sentencing criminals, making medical prescriptions, and hiring employees\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "ink has been spilled", "paragraph_index": 0}, {"url": "https://www.jacobinmag.com/2016/09/big-data-algorithms-math-facebook-advertisement-marketing/", "anchor_text": "many brows furled", "paragraph_index": 0}, {"url": "https://mobile.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html", "anchor_text": "the problem of \u201cblack box\u201d machine learning algorithms", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/are-machines-biased-or-are-we-biased-against-machines-17982310152b", "anchor_text": "As I\u2019ve mentioned elsewhere", "paragraph_index": 4}, {"url": "http://trustworthy-algorithms.org/whitepapers/Bo%20Cowgill.pdf", "anchor_text": "other researchers have emphasized as well", "paragraph_index": 4}, {"url": "http://www.pnas.org/content/108/17/6889", "anchor_text": "\u201chungry judges\u201d study", "paragraph_index": 7}, {"url": "http://economics.mit.edu/files/11713", "anchor_text": "[1]", "paragraph_index": 8}, {"url": "http://nautil.us/blog/impossibly-hungry-judges", "anchor_text": "[2]", "paragraph_index": 8}, {"url": "https://www.nytimes.com/2017/10/09/business/nobel-economics-richard-thaler.html?_r=0", "anchor_text": "Richard Thaler recently won the Nobel Prize", "paragraph_index": 8}, {"url": "http://www.wisebrain.org/papers/Self-ReportofInnerStates.pdf", "anchor_text": "Telling more than we can know", "paragraph_index": 10}, {"url": "https://academic.oup.com/qje/article/133/1/237/4095198", "anchor_text": "as they have been shown to do in existing studies on the topic", "paragraph_index": 16}], "all_paragraphs": ["Algorithms are starting to be used in applications with high-stakes consequences across a variety of domains. These include sentencing criminals, making medical prescriptions, and hiring employees. In response to this shift towards AI-driven decision making, much ink has been spilled and many brows furled in consternation about the problem of \u201cblack box\u201d machine learning algorithms. Many journalists and critics have thoughtfully pointed to the potential of algorithms discriminating against minorities, loading on spurious variables that shouldn\u2019t affect consequential decisions, and using inscrutably complicated logic that can\u2019t be rationalized by any human being.", "In many situations, these concerns are well-founded and algorithms should be implemented with a great deal of caution. However, as we continue to find new applications for machine learning algorithms, we should not let this focus on algorithmic explainability blind us from a harsh truth about the world: human decisions are often capricious, irrational, and not any more explainable than the most opaque algorithm out there.", "For purposes of this discussion, its useful to break down applications of algorithms into two categories: one category is for when algorithms are being used to automate a decision that is currently made by humans; the other category is for applications in which algorithms are being used to replace rule-based processes. Rule-based processes are those in which a simple set of easily-measured criteria are used to make a decision. Rule-based processes are great precisely because they are so scrutable. Of course, the rules themselves might not be great (as in many mandatory sentencing statutes), but at least rules-based processes have clearly articulated criteria that can be debated and evaluated against other proposals.", "The value of \u201cexplainability\u201d in this second category of applications is quite apparent. Moving from a rules-based world to the black box world of random forests and neural nets can understandably be disorienting for policymakers. If a university used to use simple SAT and GPA cut-offs for admissions decisions, replacing this process with a deep neural net trained on dozens of features would clearly raise some specific questions about how SAT scores and GPAs factor into the algorithm\u2019s admissions decisions.", "However, I do not think the same standards of explainability should be required for applications from the first category \u2014 when algorithms are being used to replace purely human decisions. As I\u2019ve mentioned elsewhere (and other researchers have emphasized as well), it is important to evaluate the utility of algorithms against the system that they are replacing. This is why the distinction between the two types of applications \u2014 those replacing humans and those replacing rules \u2014 is important. And when we focus specifically on applications in which algorithms are replacing humans, it becomes clear that explainability is an indefensible double standard.", "While the latest advancements in machine learning and algorithmic decision making have taken place fairly recently, human brains have been around for a long time. There is plenty of new research emerging about how algorithms make decisions, but researchers have had decades (if not millennia!) to investigate how the human brain makes decisions. And one of the most replicable and consistent findings from this research is that extraneous factors affect human decisions in almost every context imaginable.", "A simple example of this is what psychologists call the \u201canchoring effect\u201d. To demonstrate just how easily humans are influenced by irrelevant information, consider this classic study by Ariely, Lowenstein, & Prelec (2003): The researchers asked students to write down the last two digits of their social security numbers and indicate whether they would be willing to pay that amount for a box of chocolates. To elicit the students\u2019 true valuation of the chocolates, they then had the students bid on the box in an enforced auction. While it should be clear to you and me that the last two digits of your SSN (essentially a random number) should have no bearing on how much you value a box of chocolates, the researchers found a significant correlation between the SSN digits and the students\u2019 actual willingness-to-pay. Furthermore, despite statistical evidence to the contrary, the vast majority of students insisted that their SSN digits had zero impact on their bids.", "Another widely publicized example of irrelevant factors influencing human decisions is the \u201chungry judges\u201d study. The study\u2019s results suggest that judges are more likely to grant favorable parole decisions to defendants just after their lunch break (when their stomachs are full) than just before their lunch break (when their blood sugar is low).", "Maybe you have some misgivings about these particular examples: they feel too contrived, the stakes aren\u2019t high enough, the sample sizes weren\u2019t big enough, or the confounding variables weren\u2019t sufficiently controlled for. (Valid criticisms do exist; for example, see [1] and [2].) You are more than welcome to ignore these studies, but there are hundreds of well-researched examples of major cognitive biases. Indeed, the behavioral economist Richard Thaler recently won the Nobel Prize, largely for his career\u2019s worth of work demonstrating that these cognitive biases persist even in high-stakes situations with significant consequences. What you can\u2019t ignore is the overwhelming conclusion from this vast body of research on judgment and decision making: humans consistently let extraneous factors affect their decisions.", "While cognitive biases are pernicious themselves, what\u2019s worse is that when you ask people to explain their decisions, they often have no idea why they acted the way they did. Just as Ariely\u2019s students insisted that their social security numbers did not affect how they perceived the box of chocolates, we often aren\u2019t even aware of how biases enter into our thought processes. Furthermore, even when we do provide plausible reasons for a particular decision, there is ample evidence that these are often mere confabulations.", "A classic paper that demonstrates these effects is \u201cTelling more than we can know\u201d by Nisbett and Wilson (1977). I highly recommend reading the entire paper to fully appreciate just how absurdly common it is for humans to pull plausible rationalizations out of thin air, but I will let a simple summary from their abstract illustrate the point:", "Evidence is reviewed which suggests that there may be little or no direct introspective access to higher order cognitive processes. Subjects are sometimes (a) unaware of the existence of a stimulus that importantly influenced a response, (b) unaware of the existence of the response, and (c) unaware that the stimulus has affected the response.", "This is all a fancy academic way of saying that people often have no idea why they made a particular decision, even when researchers can statistically prove that extraneous factors are involved.", "When we properly evaluate the use algorithms to automate human decisions\u2014 by keeping in mind the prevalence and predictability of our own cognitive biases \u2014 they actually start to look quite favorable in comparison. At least with an algorithm will give you the same answer at both the beginning and end of its shift. Algorithms also don\u2019t have any social reputations or egos to maintain. So when we start peeking under the hood and investigating how they arrived at a particular decision, they can\u2019t defend themselves with seemingly plausible, post hoc, just-so rationalizations.", "Don\u2019t get me wrong: I am all for a better understanding of how opaque algorithms make their decisions. But it\u2019s time we stop fooling ourselves into believing that human beings are any less opaque when it comes to rationalizing their decisions. In fact, it is only with the determinism and consistency of algorithms \u2014 not the unpredictability and capriciousness of humans \u2014 that we can even begin to rigorously interrogate their logic and measure their improvement over time.", "To a social scientist or economist, explainability is absolutely paramount: the primary goal in most scientific research is to arrive a theory that explains how and why things work the way they do. However, to a consequentialist \u2014 i.e., someone who\u2019s principle concern is about what is actually happening in the world \u2014 explainability must take a back seat. If we care about reducing the amount of racial injustice and increasing equitable access for all classes of people, then this is the metric by which we should compare human and algorithmic decision makers.", "So long as algorithms actually do reduce bias and discrimination \u2014 as they have been shown to do in existing studies on the topic \u2014 we should sideline explainability as a secondary priority. Ensuring that algorithms be explainable is no doubt a valuable goal \u2014 but those who insist on explainability must ask whether this goal is more valuable than actual outcomes in the systems we are seeking to improve.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd9e3bc01e0dc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@alexpmiller?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexpmiller?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "Alex P. Miller"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9b65c585c9d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&user=Alex+P.+Miller&userId=9b65c585c9d&source=post_page-9b65c585c9d----d9e3bc01e0dc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9e3bc01e0dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9e3bc01e0dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "ink has been spilled"}, {"url": "https://www.jacobinmag.com/2016/09/big-data-algorithms-math-facebook-advertisement-marketing/", "anchor_text": "many brows furled"}, {"url": "https://mobile.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html", "anchor_text": "the problem of \u201cblack box\u201d machine learning algorithms"}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "There's a big problem with AI: even its creators can't explain how it worksLast year, a strange self-driving car was released onto the quiet roads of Monmouth County, New Jersey. The\u2026www.technologyreview.com"}, {"url": "https://towardsdatascience.com/are-machines-biased-or-are-we-biased-against-machines-17982310152b", "anchor_text": "As I\u2019ve mentioned elsewhere"}, {"url": "http://trustworthy-algorithms.org/whitepapers/Bo%20Cowgill.pdf", "anchor_text": "other researchers have emphasized as well"}, {"url": "https://towardsdatascience.com/are-machines-biased-or-are-we-biased-against-machines-17982310152b", "anchor_text": "Are Machines Biased or Are We Biased Against Machines?towardsdatascience.com"}, {"url": "http://www.pnas.org/content/108/17/6889", "anchor_text": "\u201chungry judges\u201d study"}, {"url": "http://economics.mit.edu/files/11713", "anchor_text": "[1]"}, {"url": "http://nautil.us/blog/impossibly-hungry-judges", "anchor_text": "[2]"}, {"url": "https://www.nytimes.com/2017/10/09/business/nobel-economics-richard-thaler.html?_r=0", "anchor_text": "Richard Thaler recently won the Nobel Prize"}, {"url": "https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making", "anchor_text": "Heuristics in judgment and decision-making - WikipediaCognitive scientist Herbert A. Simon originally proposed that human judgments are limited by available information\u2026en.wikipedia.org"}, {"url": "http://www.wisebrain.org/papers/Self-ReportofInnerStates.pdf", "anchor_text": "Telling more than we can know"}, {"url": "https://academic.oup.com/qje/article/133/1/237/4095198", "anchor_text": "as they have been shown to do in existing studies on the topic"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d9e3bc01e0dc---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----d9e3bc01e0dc---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d9e3bc01e0dc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d9e3bc01e0dc---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/economics?source=post_page-----d9e3bc01e0dc---------------economics-----------------", "anchor_text": "Economics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd9e3bc01e0dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&user=Alex+P.+Miller&userId=9b65c585c9d&source=-----d9e3bc01e0dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd9e3bc01e0dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&user=Alex+P.+Miller&userId=9b65c585c9d&source=-----d9e3bc01e0dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9e3bc01e0dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd9e3bc01e0dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d9e3bc01e0dc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d9e3bc01e0dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexpmiller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexpmiller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alex P. Miller"}, {"url": "https://medium.com/@alexpmiller/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "365 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9b65c585c9d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&user=Alex+P.+Miller&userId=9b65c585c9d&source=post_page-9b65c585c9d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcec8c7ae3018&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc&newsletterV3=9b65c585c9d&newsletterV3Id=cec8c7ae3018&user=Alex+P.+Miller&userId=9b65c585c9d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}