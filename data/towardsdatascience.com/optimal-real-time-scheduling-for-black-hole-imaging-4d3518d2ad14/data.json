{"url": "https://towardsdatascience.com/optimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14", "time": 1683002311.550685, "path": "towardsdatascience.com/optimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14/", "webpage": {"metadata": {"title": "Optimal Real-time Scheduling for Black Hole Imaging | by Ziyi Zhou | Towards Data Science", "h1": "Optimal Real-time Scheduling for Black Hole Imaging", "description": "This article serves primarily the goal of sharing the authors\u2019 findings and contributions during their capstone course project at Harvard University\u2019s Institute of Applied Computational Sciences\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.capstone.iacs.seas.harvard.edu", "anchor_text": "capstone course", "paragraph_index": 1}, {"url": "https://www.ceciliagarraffo.com", "anchor_text": "Cecilia Garraffo", "paragraph_index": 1}, {"url": "https://iacs.seas.harvard.edu/people/pavlos-protopapas", "anchor_text": "Pavlos Protopapas", "paragraph_index": 1}, {"url": "https://eventhorizontelescope.org", "anchor_text": "Event Horizon Telescope", "paragraph_index": 1}, {"url": "https://iacs.seas.harvard.edu/people/pavlos-protopapas", "anchor_text": "Pavlos Protopapas", "paragraph_index": 3}, {"url": "https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs", "anchor_text": "GFS", "paragraph_index": 10}], "all_paragraphs": ["Team Members: Shu Xu, Yiming Xu, Ziyi (Queena) Zhou", "This article serves primarily the goal of sharing the authors\u2019 findings and contributions during their capstone course project at Harvard University\u2019s Institute of Applied Computational Sciences (IACS) under the John A. Paulson School of Engineering and Applied Sciences. Their advisors are Cecilia Garraffo and Pavlos Protopapas. During this project that spanned an entire semester, we partnered with the Event Horizon Telescope (EHT) Collaboration to make an impact in human\u2019s discovery of the universe.", "You have probably seen this famous image before \u2014 the first image of a black hole in human history. On April 10, 2019, the EHT released this photo and they won the 2020 Breakthrough Prize in Fundamental Physics.", "Shepard Doeleman is one of the founding directors of the EHT. After the photo of the black hole was taken, he approached Pavlos Protopapas, the leading instructor of the capstone project, asking for some help.", "He said, to achieve a high resolution in the image of the black hole, they used the technique of very long baseline interferometry, in which radio dishes across the globe are synchronized to form a virtual telescope with the highest angular resolution currently possible from the surface of the Earth. How high is this resolution? It is equivalent to being able to read a newspaper in Los Angeles while sitting in Boston, or equivalently being able to see an atom held at arm\u2019s length. To operate in this way, the EHT requires reasonably good weather across most of the array at the same time. Currently there are eleven radio dishes in the array. Observing conditions can be excellent in some locations, but if there aren\u2019t enough telescopes that can participate due to poor weather elsewhere, observations cannot proceed as they wouldn\u2019t produce high quality data.", "However, it\u2019s very expensive to operate these giant telescopes and scientists constantly compete for observing time, so the EHT is only provided with a 10-day window in each year, when the telescopes are available to use together. Every year, the 10-day window would be different. Not only that, out of this 10-day window, they can only trigger 5\u20136 nights due to some other constraints. Currently, one person on their team, that is Shep, manually decides whether to trigger the night. He makes the decision by calling his friends working at each telescope and asking, \u2018what do you think about the weather?\u2019", "As you can probably tell, the current decision making process is not as efficient and profound as it should be. Therefore, Shep wanted us to build some real-time algorithms, that can facilitate his decision-making process. Our goal would be to maximize the number of high-quality photos of the black hole. Given the weather data and the date information, the algorithm should make suggestions on-the-go, namely whether to trigger on that day, and the optimal strategy for the future remaining days. In total, we could only select five days out of 10 consecutive days.with the constraint of the total of 5 days triggered.", "If possible, the EHT also wanted our models to output the confidence level and second optimal strategy.", "Here is a demonstration of what this problem is. The x axis represents the dates in the 10-day window, while the y axis represents the number of days that have been triggered so far. On each day, if we determine to trigger on the next day, we move up in the diagonal, and if we suggest skipping the next day, we move horizontally. In the end, we must reach one of the points in the top line. The green line here shows a possible path that suggests triggering Oct 6, 8, 10, 13, and 14.", "Our motivations are two-fold. Currently, the EHT made their decisions by humans. If our model is successful, they are for sure going to use it to facilitate making their decision. This is a huge motivation for us, as we know we also contribute to human\u2019s discovery of the universe by increasing the chance of capturing the black hole.", "We collected our data from the GFS, which is a weather forecast model produced by the national centers for environmental information. It is publicly available. It provides layer-by-layer atmosphere forecast all over the globe. You can think of its data in a 3D shape. Every 6 hours, the GFS produces a set of predictions and we pull the data that is relevant to us: the weather conditions at each telescope\u2019s location. We do that by specifying the telescopes\u2019 longitudes, latitudes, and altitudes.", "After we pulled some data, we began our exploratory data analysis process and drew this graph. There are five plots here, because the GFS makes predictions for five variables at a time. On each graph, you see there is one black line and seven gray lines. This corresponds to each set of weather forecast data forecasted every 6 hours. The black line represents the most updated forecast data, while the grey lines are predictions made in the past 48 hours. Each prediction covers 16 days in the future. We can see that the first 5-day forecast is pretty accurate, but after that it becomes very uncertain. We were told by the experts that the first variable, Tau-225, is the most important one to indicate clarity of the atmosphere, as it is the absorption rate directly above head. A smaller Tau-225 is more preferred than a larger one.", "That\u2019s all the data we got. Before meeting meeting with the partners and seeing the data, we considered using reinforcement learning to approach this problem. However, after we met with the partner and saw the data, we realized that this is an optimization problem and we had to be creative in designing models well suited for it. When we cannot find any literature or previous works that did a similar thing, we designed this baseline model and it serves as the bare bone for all the other models we later created.", "We borrowed the idea of reward functions from reinforcement learning. Each telescope would get a reward value based on its weather condition. The reward function for each telescope is being called the small f. Each day is assigned a reward value, for which the reward function is called the big F. In the baseline model, we construct the reward function using the predictions of Tau-225. The small f is defined to be negative expectation of Tau-225 over the telescope\u2019s observation window. (The reason for the negative sign is because intuitively we want the reward value to be as large as possible, but Tau-225 is always positive and it\u2019s the best when it\u2019s close to zero.) The big F is defined to be some weighted average of the small f\u2019s. We used the sizes of telescopes as part of the weights, because the larger telescopes are more important in the array. We also incorporated the distance matrix in the formula, as we want the telescopes to be spread out on the surface of the earth.", "Once we calculate the reward values for each day, we then want to solve the optimization problem. For example, on day 0, we calculate the reward values from day 1 to day 10. Since we have 5 days to trigger and we haven\u2019t used any of them, we find the five largest rewards and see if day 1 is one of these days. Here, the pink boxes represent the largest five values. On day 1, we have the reward values from day 2 to day 10. Notice here that these values get updated because new weather forecast has been made. Since we have triggered day 1, we have four days remaining to trigger. We find the four days that have the largest reward values. We see that day 2 is in one of them, so we suggest triggering day 2. On day 2, we want to find the top 3 rewards in the remaining days. We see that day 3 is not in them. Then on day 3, we continue searching for the top 3 rewards and see whether day 4 is in them.", "Those are the basics of the baseline model. Now we move onto more advanced models that take uncertainty into account. Uncertainty means that we can trust the GFS forecast data only to certain extent. Our partner has emphasized many times that they\u2019d rather trigger an observation earlier than later in order to minimize risk.", "The first type of uncertainty we considered only depends on how far in the future the GFS is predicting for, namely the time lag. To incorporate this, we can multiply the rewards for each day by a discount factor to get the present value. And then perform the same optimization technique we used in the baseline model. The single discount factor is considered as a hyperparameter that needs to be tuned from cross-validation.", "We believe a single discount factor is not enough to explain the uncertainty in the future, so we introduced different uncertainty quantification to build a second method. In this method, we look for a pattern in GFS model\u2019s accuracy, based on the time lag. Therefore, we used historical data to calculate the average error the prediction can have based on how many days into the future the prediction is. We plot the results on the left, in which the x axis is the number of days into the future and the y axis is a measurement of the error. We see the GFS model is less accurate once it passed the six-day mark. Just like with the discount factor in the previous model, we use a multiplicative penalty term on the reward value. (We could do this through either the small f or the big F value).The penalty term depends on the time lag and a hyper-parameter called \u201cpenalty level\u201d.", "Method 3: Prediction Difficulty of Specific Time", "The previous two models assume that the uncertainty comes from the time lag. This model and the next assume that the uncertainty relates to the specific date the forecast is made for. Remember that the GFS makes prediction every 6 hours for the next 16 days? Thus, for each time point there are multiple forecast predictions. The yellow region in the graph is bounded by the minimum and maximum forecast data of Tau-225.", "For this method, we want to find the latest prediction made for a time point, and calculate the Root Mean Square Error (RMSE) of the other forecasts with respect to this latest prediction. We then use a similar formula as before to get the reward value, but this time the reward and penalty are both tailored to the time points.", "Method 4: Sampling from Normal Distribution", "Lastly, we still assume that the uncertainty differs for each time point, but we want to get a confidence level associated with the optimal path we suggest. We assume that the true weather would come from a normal distribution. Following the guidance of Monte Carlo methods, we randomly sampled reward values from the distribution for every time point enough times, and each time we find an optimal path. At the end, we summarize the frequencies of paths and conclude the best path is the one with the highest frequency. We also use its frequency to indicate our confidence level of the suggested path. We believe that our partner can make informative decisions better if they see this number.", "We back-tested our models by comparing the suggested path given by different models to the ground-truth path. This is an example. We ran simulations on forecast data pulled from Nov 9 to Nov 18, so each model would give us a suggested path. We also knew the ground-truth path, so we compared each model\u2019s average reward with the best path\u2019s score. In this example, only the baseline method and the sampling from distribution method failed to generate the best path. The lack of further-days-penalization resulted in predicted one day later.", "We collected GFS data dated from Oct 25 to Nov 30 and ran simulations in each consecutive 10-day window. There are 26 10-day windows in total. One can think of all the data we received in a 10-day window as x, and the average reward when we look back as the predicted y. We can naturally compare our predicted y with the best path and compute the mean square error. We also compute a score that is defined in the formula shown below. It is a relative score. If our predicted path is equal to the best path, then it will be equal to 1. Ifour predicted path is equal to the random path, the score will be 0.", "With these two metrics we are able to decide the best penalty level for each method and, also, the best model. Here method 3 is the best performing model, which is expected because it incorporates the uncertainty of weather prediction variance for each day. Method 2 is the second best performer because it only takes into account the uncertainty of the weather forecast in terms of how far in the future the prediction lies. Sampling method here is only as good as the baseline because it doesn\u2019t include any sort of penalty. However, it\u2019s still useful because it\u2019s the only model that outputs the confidence level of the selected path.", "We built a software package for the EHT to use in the future. The software encompasses the procedures of processing the data, running the optimization models, and making suggestions with provided uncertainty measurement.", "Here is a demonstration on how to use the software:", "It was not easy to get to the stage where we currently at with this project. Initially, when we got the project assigned, we thought about fancy machine learning models to solve the problem. However, after seeing the data and meeting with the partner, we realized that a much more simple model is appropriate to approach this problem. There was a period when the data pulled from the GFS had unexpected zeros in them, and it took us quite some time to resolve it with the help from our partners. Building the software required us to construct a graphical user interface (GUI) and connect the GUI with all the model inputs and outputs. We didn\u2019t have any experience in doing this kind of modeling before, but we were able to learn a lot and conquer every concept at the end. We are very proud of this project and hope that it will be useful for others.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4d3518d2ad14&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ziyi_zhou?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ziyi_zhou?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "Ziyi Zhou"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7131724e2478&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&user=Ziyi+Zhou&userId=7131724e2478&source=post_page-7131724e2478----4d3518d2ad14---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4d3518d2ad14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4d3518d2ad14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.capstone.iacs.seas.harvard.edu", "anchor_text": "capstone course"}, {"url": "https://www.ceciliagarraffo.com", "anchor_text": "Cecilia Garraffo"}, {"url": "https://iacs.seas.harvard.edu/people/pavlos-protopapas", "anchor_text": "Pavlos Protopapas"}, {"url": "https://eventhorizontelescope.org", "anchor_text": "Event Horizon Telescope"}, {"url": "https://iacs.seas.harvard.edu/people/pavlos-protopapas", "anchor_text": "Pavlos Protopapas"}, {"url": "https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs", "anchor_text": "GFS"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4d3518d2ad14---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4d3518d2ad14---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/astronomy?source=post_page-----4d3518d2ad14---------------astronomy-----------------", "anchor_text": "Astronomy"}, {"url": "https://medium.com/tag/software?source=post_page-----4d3518d2ad14---------------software-----------------", "anchor_text": "Software"}, {"url": "https://medium.com/tag/optimization?source=post_page-----4d3518d2ad14---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4d3518d2ad14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&user=Ziyi+Zhou&userId=7131724e2478&source=-----4d3518d2ad14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4d3518d2ad14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&user=Ziyi+Zhou&userId=7131724e2478&source=-----4d3518d2ad14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4d3518d2ad14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4d3518d2ad14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4d3518d2ad14---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4d3518d2ad14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ziyi_zhou?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ziyi_zhou?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ziyi Zhou"}, {"url": "https://medium.com/@ziyi_zhou/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7131724e2478&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&user=Ziyi+Zhou&userId=7131724e2478&source=post_page-7131724e2478--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F7131724e2478%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimal-real-time-scheduling-for-black-hole-imaging-4d3518d2ad14&user=Ziyi+Zhou&userId=7131724e2478&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}