{"url": "https://towardsdatascience.com/innovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc", "time": 1683012920.898925, "path": "towardsdatascience.com/innovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc/", "webpage": {"metadata": {"title": "Innovative Chatbot using 1-Dimensional Convolutional Layers | by Bharath K | Towards Data Science", "h1": "Innovative Chatbot using 1-Dimensional Convolutional Layers", "description": "The popularity of chatbots has been on the rise since the past decade. Chatbots are usually used for quick responses to most commonly asked questions on a particular website. Chatbots save time as\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/microsoft/BotBuilder-PersonalityChat/tree/master/CSharp/Datasets/qnaFormat/english", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://keras.io/api/layers/convolution_layers/convolution1d/", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://keras.io/api/preprocessing/text/", "anchor_text": "here", "paragraph_index": 15}, {"url": "https://github.com/Bharath-K3/Innovative-Chatbot-using-1-Dimensional-Convolutional-Layers", "anchor_text": "here", "paragraph_index": 35}, {"url": "https://github.com/Bharath-K3/Innovative-Chatbot-using-1-Dimensional-Convolutional-Layers", "anchor_text": "GitHub", "paragraph_index": 35}, {"url": "https://www.appliedaicourse.com/", "anchor_text": "Applied AI", "paragraph_index": 35}, {"url": "http://www.linkedin.com/in/bharath-k-421090194", "anchor_text": "www.linkedin.com/in/bharath-k-421090194", "paragraph_index": 37}], "all_paragraphs": ["The popularity of chatbots has been on the rise since the past decade. Chatbots are usually used for quick responses to most commonly asked questions on a particular website. Chatbots save time as well as reduce human labor and expenditure. There are so many types of chatbots and each of them specializes, in particular, one or a few fields. The best approach for knowing what kind of chatbot you want to build is as follows \u2014", "If you want to build chatbots, the best approach is to look for what are your target audience, companies, or businesses. Making specific chatbots is ideal as you can greatly improve the performance of the distinct task.", "In this article, we will be covering how you can build a cool chatbot using one-dimensional convolutional layers. The purpose of this chatbot is to serve as a smart chatbot for the virtual assistant project. I will be using a witty.txt dataset. The link for the pre-processed dataset will be provided along with the code at the end of the article. You can choose other datasets like professional or caring. I prefer a witty dataset because I would like to receive sarcastic funny comments from my chatbot rather than serious stuff. The link to the other set of data can be referred to from here. This is Microsoft\u2019s official bot builder personality chat. They are all in the form of questions and answers. The other personality chat datasets in English are caring, enthusiastic, friendly, and professional. You can feel free to choose any of these as per your convenience.", "Note: This is part-3 of the virtual assistant series. There will be more upcoming parts on the same topic where we will cover how you can build your very own virtual assistant using deep learning technologies and python.", "We will be building an innovative chatbot with the use of one-dimensional convolutional layers. This method allows us to maximize or minimize the intensity of a particular set of values. This is best for the text data where we will be prioritizing a bunch of selective text data. We will be using a \u201ctext classification\u201d based approach for building our chatbot. To understand more about 1-D convolution layers, we can refer to them as a layer that creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not \u201cNone\u201d, it is applied to the outputs as well. To learn more about one-dimensional convolution layers refer here. There are a lot of unique chatbots that are being built nowadays and the demand for them is higher than ever before. The chatbot will play an important role in our virtual assistant project as we will use this to communicate with us. The chatbot will also act as a replacement for us in our absence to communicate with other users when required.", "We will be using a \u201ctext classification\u201d based approach for our chatbot. Our first step will be to load the witty.txt dataset into a variable. I will be providing the pre-processed dataset in the GitHub repository at the end of the post. This means we don\u2019t need to worry too much about the cleaning part. However, it is important to segregate our questions and responses and store them in separate variables. We will then proceed to split the data into train and validation datasets.", "Our next step is to tokenize the data and convert the texts to sequences. We will then apply padding on the data after converting our test and train responses into categorical data. Finally, we will make sure we expand the dimensions of train and test questions so that it is in a suitable format to be passed through a one-dimensional convolution layer. We can also use the glove vectors if required as it contains pre-trained word vectors.", "We will then proceed to build our model architecture which will be entirely custom-built using lots of one-dimensional convolutional layers. We will then look at the model plots and train our model i.e. fit the model. Finally, we will visualize using graphs, the performance of the model on both train and validation data. We will also look into how to build a prediction network using our saved weights.", "As suggested earlier, I will be using the witty.txt dataset. The first step we will be performing on the dataset is splitting them into 2 separate lists. These lists will be the questions list and the responses list. The questions list will store all the questions and the responses list will store all the respective answers. There are many repeated answers to a bunch of questions. There is a total of 89 unique answers but the repetitions make sense. This is because many questions can have pretty much the same answer.", "Our dataset before segregation looks as shown below:", "The first question and answer of our dataset after separating them looks as follows:", "Question 1: Can you ask me something about me?Answer 1: Nah, I\u2019m good.", "After completion of the segregation step, we will split the current question and response dataset into train and validation datasets in an 80:20 ratio.", "In the next step, we will tokenize the data using the Keras Tokenizer function.", "Tokenization: Tokenization refers to splitting bigger text data, essays, or corpus\u2019s into smaller segments. These smaller segments can be in the form of smaller documents or lines of text data. They can also be a dictionary of words.", "The Keras Tokenizer allows us to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf. To learn more about the Tokenizer class and text data pre-processing using Keras visit here.", "After the tokenization of the train and test questions, we will dump the tokenizer for the dataset into a pickle file. This can be accessed later by loading the pickle file while performing the prediction by the model. We will also convert the train and test responses into categorical format i.e. words into a vector class of binary integers.", "Then we will pad the sequences of the questions train and test accordingly. This is to ensure our training and validation inputs are of a fixed shape. The final step is to expand the test and train outputs into a 3-dimensional array. This is the required shape to pass the inputs into a 1-D convolutional layer. The code snippet for the pre-processing is as shown below. The entire code will be provided at the end of the article with a link to the GitHub repository.", "We will construct the model in a functional API manner. We will have an input layer that will take an input with the shape of (max_len, ). This is because all of our text data is padded according to the order of the max length. So, the maximum size will be limited to the max length. We will then pass this input into an embedding layer. The main reason for this is to create an embedding for the higher dimensional input data i.e. turn positive integers into dense vectors of fixed size.", "We will then pass this embedding layer into 3 separate 1-D convolution layers. Each of the conv-1D layers have a filters of increasing size by 4. We start with 4 initial filters for the first conv-1D layer, then we have 8 for the next convolution layer, and 12 for the final conv-1D layer. All of them have an activation function as relu. This is usually the most preferred activation function for most tasks. We will have a kernel size as 3 and assign the initializer as he_normal. We will concatenate the entire output received for the 3 convolution layers and pass them through a maxpool layer. The maxpool layer is used for downsampling the output received from the concatenate layer. We will then pass it through a dropout layer. This is to avoid over-fitting during the validation of text data.", "Our next step is to pass the entire data from the dropout layer into 3 more conv-1D layers. These 3 convolution layers will perform exactly the same as our previous ones. We do not need to modify anything. After computing these three convolution layers, we will once again concatenate them and pass it through a maxpool 1-D layer for downsampling. We will then pass it through the next dropout layer to drop some of the additional data to prevent over-fitting.", "The next block of code will consist of a final 1-D convolution layer, a flatten layer, and a final dropout layer. Our next step is to pass the data from the previous dropout layer into a final conv1D layer. We will flatten this output received so we can pass it through the dense layers. Before passing through the dense layer, we will once again use a final dropout to prevent over-fitting during validation.", "The final block of our code will contain the fully connected layers. We will have one hidden layer with a relu activation function with 50 hidden nodes. Then, we will have the final output layer with a softmax activation function and the number of nodes will be equal to the number of unique outputs possible. The softmax layer will give us a list of probabilities for each of our predictions. Finally, we will define our model with the input layer and the output layer. The readers can feel free to add or remove certain layers. It is nice to explore and play around with the various activation functions, initializers, and the number of units.", "Let us look at the entire code for building our model. Then we will proceed to look at the model summary and model plot.", "The callbacks we will be using are similar to our previous callbacks in the Virtual Assistant Project series. Let us look at them first \u2014", "We will be importing the 3 required callbacks for training our model. The 3 important callbacks are ModelCheckpoint, ReduceLROnPlateau, and Tensorboard. Let us look at what task each of these individual callbacks performs.", "We will be saving the best models based on the metric loss to the file chatbot.h5. This file will be crucial while accessing the predict function and trying to predict the response for each question asked. We will wait for 3 epochs for the loss to improve. If it does not improve, then we will reduce the learning rate. Finally, we will be using the tensorboard function for visualizing the graphs and histograms if needed.", "Below is the code block for compiling and fitting of the model.", "We are compiling and fitting our model in the final step. Here, we are training the model and saving the best weights to chatbot.h5 so that we don\u2019t have to re-train the model repeatedly and we can use our saved model when required. Here I have trained on both the training and validation data. However, you can choose to train with only train data if you choose to do so. The loss we have used is categorical_crossentropy which computes the cross-entropy loss between the labels and predictions. The optimizer we will be using is Adam with a learning rate of 0.001 and we will compile our model with the metric accuracy as well. Our result after 50 epochs of training is as shown below:", "We will be making our prediction on the user input text. For this, it is important to load our tokenizer which we have stored in a pickle file. Then we will load the weights of our saved model. We will tokenize and pad the input text sequences. After tokenization and padding, we will predict the response for the input question by the user. The prediction will be done by the saved model weights. The model which we have loaded will make each of the predictions. We will be using a try and except block of statements during the prediction stage. If there is an error during the prediction we don\u2019t want the program to be terminated. The program will only end if the user specifically passes the command \u201cstop the script\u201d. Let us see some of the predictions using this script \u2014", "Enter your line: what is upSometimes I like to take a break from being awesome.Enter your line: are you okay?Nah, I'm good.", "Enter your line: What do you find attractive?I\u2019m not a recognized expert in beauty.Enter your line: stop the scriptEnding The Program\u2026..", "The model is able to make decent predictions for most of the questions. There is room for improvement as our model starts to over-fit after about 70% validation accuracy. More things like regularization and finding the optimum dropout rate are some of the improvements that can be made. The model can be slightly improved with better pre-processing steps which can be done. Other methods like sequence to sequence implementation with attention can also be used. The entire code for this post will be provided in the next section of the article.", "Note: Sometimes when you enter an input text there is a chance it does not return any output. This is probably because it makes an out of bounds prediction. However, re-enter the same text and it will give you an output.", "We are able to achieve an overall high accuracy and validation accuracy and an overall low loss as well as validation loss. The model is able to make decent predictions on the user input text data. There is room for improvement as mentioned previously. All in all, this is a good model for a \u201ctext classification\u201d based chatbot.", "With this, we have reached the end of the article. We were able to develop an innovative chatbot using 1-Dimensional convolutional layers. The entire code for the project can be found here. Feel free to explore and innovate on the notebooks that are provided for the reference. The GitHub repository contains all the required files and notebooks for this project. I hope all of you enjoyed reading this article as much as I did writing this. A big shout out to Applied AI for being awesome. If you guys find any improvements, then feel free to let me know. Thank you so much for your time and I hope all of you have a wonderful day!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Love to explore and learn new concepts. Extremely interested in AI, deep learning, robots, and the universe. LinkedIn \u2014 www.linkedin.com/in/bharath-k-421090194"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2cab4090b0fc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://bharath-k1297.medium.com/?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": ""}, {"url": "https://bharath-k1297.medium.com/?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "Bharath K"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2b0fa005e971&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&user=Bharath+K&userId=2b0fa005e971&source=post_page-2b0fa005e971----2cab4090b0fc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2cab4090b0fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2cab4090b0fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/virtual-assistant-project", "anchor_text": "Virtual Assistant Project"}, {"url": "https://www.freepik.com/free-vector/chatbot-technology-website-template_5710493.htm#page=1&query=chatbot&position=0", "anchor_text": "Source:"}, {"url": "https://github.com/microsoft/BotBuilder-PersonalityChat/tree/master/CSharp/Datasets/qnaFormat/english", "anchor_text": "here"}, {"url": "https://www.freepik.com/free-vector/cute-bot-say-users-hello-chatbot-greets-online-consultation_4015765.htm#page=1&query=chatbot&position=0", "anchor_text": "Source:"}, {"url": "https://keras.io/api/layers/convolution_layers/convolution1d/", "anchor_text": "here"}, {"url": "https://unsplash.com/photos/SNf-hZz6zOY", "anchor_text": "Source:"}, {"url": "https://keras.io/api/preprocessing/text/", "anchor_text": "here"}, {"url": "https://unsplash.com/photos/m_HRfLhgABo", "anchor_text": "Source:"}, {"url": "https://unsplash.com/photos/hpjSkU2UYSU", "anchor_text": "Source:"}, {"url": "https://github.com/Bharath-K3/Innovative-Chatbot-using-1-Dimensional-Convolutional-Layers", "anchor_text": "here"}, {"url": "https://github.com/Bharath-K3/Innovative-Chatbot-using-1-Dimensional-Convolutional-Layers", "anchor_text": "GitHub"}, {"url": "https://www.appliedaicourse.com/", "anchor_text": "Applied AI"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2cab4090b0fc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2cab4090b0fc---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2cab4090b0fc---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----2cab4090b0fc---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/virtual-assistant-project?source=post_page-----2cab4090b0fc---------------virtual_assistant_project-----------------", "anchor_text": "Virtual Assistant Project"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2cab4090b0fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&user=Bharath+K&userId=2b0fa005e971&source=-----2cab4090b0fc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2cab4090b0fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&user=Bharath+K&userId=2b0fa005e971&source=-----2cab4090b0fc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2cab4090b0fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2cab4090b0fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2cab4090b0fc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2cab4090b0fc--------------------------------", "anchor_text": ""}, {"url": "https://bharath-k1297.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://bharath-k1297.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Bharath K"}, {"url": "https://bharath-k1297.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.6K Followers"}, {"url": "http://www.linkedin.com/in/bharath-k-421090194", "anchor_text": "www.linkedin.com/in/bharath-k-421090194"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2b0fa005e971&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&user=Bharath+K&userId=2b0fa005e971&source=post_page-2b0fa005e971--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F480a0310a215&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finnovative-chatbot-using-1-dimensional-convolutional-layers-2cab4090b0fc&newsletterV3=2b0fa005e971&newsletterV3Id=480a0310a215&user=Bharath+K&userId=2b0fa005e971&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}