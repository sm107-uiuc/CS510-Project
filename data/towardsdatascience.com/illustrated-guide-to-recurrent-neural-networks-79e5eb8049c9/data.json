{"url": "https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9", "time": 1682993726.550781, "path": "towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9/", "webpage": {"metadata": {"title": "Illustrated Guide to Recurrent Neural Networks | by Michael Phi | Towards Data Science", "h1": "Illustrated Guide to Recurrent Neural Networks", "description": "Hi and welcome to an Illustrated guide to recurrent neural networks. I\u2019m Michael also known as LearnedVector. I\u2019m a machine learning engineer in the A.I. voice assistant space. If you are just\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.michaelphi.com/", "anchor_text": "michaelphi.com", "paragraph_index": 44}, {"url": "https://www.michaelphi.com/build-your-own-deep-learning-machine-what-you-need-to-know/", "anchor_text": "https://www.michaelphi.com", "paragraph_index": 45}, {"url": "https://www.youtube.com/channel/UCYpBgT4riB-VpsBBBQkblqQ?view_as=subscriber", "anchor_text": "Youtube", "paragraph_index": 46}, {"url": "http://eepurl.com/gwy3hj", "anchor_text": "email newsletter", "paragraph_index": 47}, {"url": "http://www.michaelphi.com", "anchor_text": "www.michaelphi.com", "paragraph_index": 48}], "all_paragraphs": ["Hi and welcome to an Illustrated guide to recurrent neural networks. I\u2019m Michael also known as LearnedVector. I\u2019m a machine learning engineer in the A.I. voice assistant space. If you are just getting started in ML and want to get some intuition behind Recurrent neural networks, this post is for you.", "You can also watch the video version of this post if you prefer.", "If you want to get into machine learning, recurrent neural networks are a powerful technique that is important to understand. If you use a smartphone or frequently surf the internet, odd\u2019s are you\u2019ve used applications that leverages RNN\u2019s. Recurrent neural networks are used in speech recognition, language translation, stock predictions; It\u2019s even used in image recognition to describe the content in pictures.", "So I know there are many guides on recurrent neural networks, but I want to share illustrations along with an explanation, of how I came to understand it. I\u2019m going to avoid all the math and focus on the intuition behind RNNs instead. By the end of this post, you should have a good understanding of RNN\u2019s and hopefully, have that light bulb moment.", "Ok so RNN\u2019s are neural networks that are good at modeling sequence data. To understand what that means let\u2019s do a thought experiment. Say you take a still snapshot of a ball moving in time.", "Let\u2019s also say you want to predict the direction that the ball was moving. So with only the information that you see on the screen, how would you do this? Well, you can go ahead and take a guess, but any answer you\u2019d come up with would be that, a random guess. Without knowledge of where the ball has been, you wouldn\u2019t have enough data to predict where it\u2019s going.", "If you record many snapshots of the ball\u2019s position in succession, you will have enough information to make a better prediction.", "So this is a sequence, a particular order in which one thing follows another. With this information, you can now see that the ball is moving to the right.", "Sequence data comes in many forms. Audio is a natural sequence. You can chop up an audio spectrogram into chunks and feed that into RNN\u2019s.", "Text is another form of sequences. You can break Text up into a sequence of characters or a sequence of words.", "Ok so, RNN\u2019s are good at processing sequence data for predictions. But how??", "Well, they do that by having a concept I like to call sequential memory. To get a good intuition behind what sequential memory means\u2026", "I want to invite you to say the alphabet in your head.", "That was pretty easy right. If you were taught this specific sequence, it should come quickly to you.", "Now try saying the alphabet backward.", "I bet this is much harder. Unless you\u2019ve practiced this specific sequence before, you\u2019ll likely have a hard time.", "Here\u2019s a fun one, start at the letter F.", "At first, you\u2019ll struggle with the first few letters, but then after your brain picks up the pattern, the rest will come naturally.", "So there is a very logical reason why this can be difficult. You learn the alphabet as a sequence. Sequential memory is a mechanism that makes it easier for your brain to recognize sequence patterns.", "Alright so RNN\u2019s have this abstract concept of sequential memory, but how the heck does an RNN replicate this concept? Well, let\u2019s look at a traditional neural network also known as a feed-forward neural network. It has its input layer, hidden layer, and the output layer.", "How do we get a feed-forward neural network to be able to use previous information to effect later ones? What if we add a loop in the neural network that can pass prior information forward?", "And that\u2019s essentially what a recurrent neural network does. An RNN has a looping mechanism that acts as a highway to allow information to flow from one step to the next.", "This information is the hidden state, which is a representation of previous inputs. Let\u2019s run through an RNN use case to have a better understanding of how this works.", "Let\u2019s say we want to build a chatbot. They\u2019re pretty popular nowadays. Let\u2019s say the chatbot can classify intentions from the users inputted text.", "To tackle this problem. First, we are going to encode the sequence of text using an RNN. Then, we are going to feed the RNN output into a feed-forward neural network which will classify the intents.", "Ok, so a user types in\u2026 what time is it?. To start, we break up the sentence into individual words. RNN\u2019s work sequentially so we feed it one word at a time.", "The first step is to feed \u201cWhat\u201d into the RNN. The RNN encodes \u201cWhat\u201d and produces an output.", "For the next step, we feed the word \u201ctime\u201d and the hidden state from the previous step. The RNN now has information on both the word \u201cWhat\u201d and \u201ctime.\u201d", "We repeat this process, until the final step. You can see by the final step the RNN has encoded information from all the words in previous steps.", "Since the final output was created from the rest of the sequence, we should be able to take the final output and pass it to the feed-forward layer to classify an intent.", "For those of you who like looking at code here is some python showcasing the control flow.", "First, you initialize your network layers and the initial hidden state. The shape and dimension of the hidden state will be dependent on the shape and dimension of your recurrent neural network. Then you loop through your inputs, pass the word and hidden state into the RNN. The RNN returns the output and a modified hidden state. You continue to loop until you\u2019re out of words. Last you pass the output to the feedforward layer, and it returns a prediction. And that\u2019s it! The control flow of doing a forward pass of a recurrent neural network is a for loop.", "You may have noticed the odd distribution of colors in the hidden states. That is to illustrate an issue with RNN\u2019s known as short-term memory.", "Short-term memory is caused by the infamous vanishing gradient problem, which is also prevalent in other neural network architectures. As the RNN processes more steps, it has troubles retaining information from previous steps. As you can see, the information from the word \u201cwhat\u201d and \u201ctime\u201d is almost non-existent at the final time step. Short-Term memory and the vanishing gradient is due to the nature of back-propagation; an algorithm used to train and optimize neural networks. To understand why this is, let\u2019s take a look at the effects of back propagation on a deep feed-forward neural network.", "Training a neural network has three major steps. First, it does a forward pass and makes a prediction. Second, it compares the prediction to the ground truth using a loss function. The loss function outputs an error value which is an estimate of how poorly the network is performing. Last, it uses that error value to do back propagation which calculates the gradients for each node in the network.", "The gradient is the value used to adjust the networks internal weights, allowing the network to learn. The bigger the gradient, the bigger the adjustments and vice versa. Here is where the problem lies. When doing back propagation, each node in a layer calculates it\u2019s gradient with respect to the effects of the gradients, in the layer before it. So if the adjustments to the layers before it is small, then adjustments to the current layer will be even smaller.", "That causes gradients to exponentially shrink as it back propagates down. The earlier layers fail to do any learning as the internal weights are barely being adjusted due to extremely small gradients. And that\u2019s the vanishing gradient problem.", "Let\u2019s see how this applies to recurrent neural networks. You can think of each time step in a recurrent neural network as a layer. To train a recurrent neural network, you use an application of back-propagation called back-propagation through time. The gradient values will exponentially shrink as it propagates through each time step.", "Again, the gradient is used to make adjustments in the neural networks weights thus allowing it to learn. Small gradients mean small adjustments. That causes the early layers not to learn.", "Because of vanishing gradients, the RNN doesn\u2019t learn the long-range dependencies across time steps. That means that there is a possibility that the word \u201cwhat\u201d and \u201ctime\u201d are not considered when trying to predict the user\u2019s intention. The network then has to make the best guess with \u201cis it?\u201d. That\u2019s pretty ambiguous and would be difficult even for a human. So not being able to learn on earlier time steps causes the network to have a short-term memory.", "Ok so RNN\u2019s suffer from short-term memory, so how do we combat that? To mitigate short-term memory, two specialized recurrent neural networks were created. One called Long Short-Term Memory or LSTM\u2019s for short. The other is Gated Recurrent Units or GRU\u2019s. LSTM\u2019s and GRU\u2019s essentially function just like RNN\u2019s, but they\u2019re capable of learning long-term dependencies using mechanisms called \u201cgates.\u201d These gates are different tensor operations that can learn what information to add or remove to the hidden state. Because of this ability, short-term memory is less of an issue for them. If you\u2019d like to learn more about LSTM\u2019s and GRU\u2019s you can view my post on them.", "To sum this up, RNN\u2019s are good for processing sequence data for predictions but suffers from short-term memory. The short-term memory issue for vanilla RNN\u2019s doesn\u2019t mean to skip them entirely and use the more evolved versions like LSTM\u2019s or GRU\u2019s. RNN\u2019s have the benefit of training faster and uses less computational resources. That\u2019s because there are fewer tensor operations to compute. You should use LSTM\u2019s or GRU\u2019s when you expect to model longer sequences with long-term dependencies.", "If you\u2019re interested in going deeper, here are some links explaining RNN\u2019s and it\u2019s variants.", "I had a lot of fun making this post so let me know in the comments if this was helpful or what you would like to see in the next one. Thanks for reading!", "Check out michaelphi.com for more content like this.", "\u270d\ud83c\udffd Want more Content? Check out my blog at https://www.michaelphi.com", "\ud83d\udcfa Like to watch project-based videos? Check out my Youtube!", "\ud83e\udd47 Stay up to date on articles and videos by signing up for my email newsletter!", "Software and Machine Learning Research Engineer. Here to make complex things simple. Follow me to stay on top of A.I. www.michaelphi.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F79e5eb8049c9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://learnedvector.medium.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Michael Phi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1bdc81ea939d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&user=Michael+Phi&userId=1bdc81ea939d&source=post_page-1bdc81ea939d----79e5eb8049c9---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F79e5eb8049c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&user=Michael+Phi&userId=1bdc81ea939d&source=-----79e5eb8049c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79e5eb8049c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&source=-----79e5eb8049c9---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21", "anchor_text": "Illustrated Guide to LSTM\u2019s and GRU\u2019s: A step by step explanationHi and welcome to an Illustrated Guide to LSTM\u2019s and GRU\u2019s. I\u2019m Michael, and I\u2019m a Machine Learning Engineer in the AI\u2026towardsdatascience.com"}, {"url": "https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/", "anchor_text": "Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN) - i am traskA machine learning craftsmanship blog.iamtrask.github.io"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Understanding LSTM Networks -- colah's blogThese loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that\u2026colah.github.io"}, {"url": "https://www.michaelphi.com/", "anchor_text": "michaelphi.com"}, {"url": "https://www.michaelphi.com/build-your-own-deep-learning-machine-what-you-need-to-know/", "anchor_text": "https://www.michaelphi.com"}, {"url": "https://www.youtube.com/channel/UCYpBgT4riB-VpsBBBQkblqQ?view_as=subscriber", "anchor_text": "Youtube"}, {"url": "http://eepurl.com/gwy3hj", "anchor_text": "email newsletter"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----79e5eb8049c9---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----79e5eb8049c9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----79e5eb8049c9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----79e5eb8049c9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/recurrent-neural-network?source=post_page-----79e5eb8049c9---------------recurrent_neural_network-----------------", "anchor_text": "Recurrent Neural Network"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F79e5eb8049c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&user=Michael+Phi&userId=1bdc81ea939d&source=-----79e5eb8049c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F79e5eb8049c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&user=Michael+Phi&userId=1bdc81ea939d&source=-----79e5eb8049c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79e5eb8049c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1bdc81ea939d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&user=Michael+Phi&userId=1bdc81ea939d&source=post_page-1bdc81ea939d----79e5eb8049c9---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F394127cfcacb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&newsletterV3=1bdc81ea939d&newsletterV3Id=394127cfcacb&user=Michael+Phi&userId=1bdc81ea939d&source=-----79e5eb8049c9---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Written by Michael Phi"}, {"url": "https://learnedvector.medium.com/followers?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "4.4K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "http://www.michaelphi.com", "anchor_text": "www.michaelphi.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1bdc81ea939d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&user=Michael+Phi&userId=1bdc81ea939d&source=post_page-1bdc81ea939d----79e5eb8049c9---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F394127cfcacb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-recurrent-neural-networks-79e5eb8049c9&newsletterV3=1bdc81ea939d&newsletterV3Id=394127cfcacb&user=Michael+Phi&userId=1bdc81ea939d&source=-----79e5eb8049c9---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0?source=author_recirc-----79e5eb8049c9----0---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=author_recirc-----79e5eb8049c9----0---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=author_recirc-----79e5eb8049c9----0---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Michael Phi"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----79e5eb8049c9----0---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0?source=author_recirc-----79e5eb8049c9----0---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Illustrated Guide to Transformers- Step by Step ExplanationTransformers are taking the natural language processing world by storm. These incredible models are breaking multiple NLP records and\u2026"}, {"url": "https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0?source=author_recirc-----79e5eb8049c9----0---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "12 min read\u00b7Apr 30, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff74876522bc0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0&user=Michael+Phi&userId=1bdc81ea939d&source=-----f74876522bc0----0-----------------clap_footer----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0?source=author_recirc-----79e5eb8049c9----0---------------------50c86659_4473_4a38_9f94_58904052b1e6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff74876522bc0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0&source=-----79e5eb8049c9----0-----------------bookmark_preview----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----79e5eb8049c9----1---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----79e5eb8049c9----1---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----79e5eb8049c9----1---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----79e5eb8049c9----1---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----79e5eb8049c9----1---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----79e5eb8049c9----1---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----79e5eb8049c9----1---------------------50c86659_4473_4a38_9f94_58904052b1e6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----79e5eb8049c9----1-----------------bookmark_preview----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----79e5eb8049c9----2---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----79e5eb8049c9----2---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----79e5eb8049c9----2---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----79e5eb8049c9----2---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----79e5eb8049c9----2---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----79e5eb8049c9----2---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----79e5eb8049c9----2---------------------50c86659_4473_4a38_9f94_58904052b1e6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----79e5eb8049c9----2-----------------bookmark_preview----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=author_recirc-----79e5eb8049c9----3---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=author_recirc-----79e5eb8049c9----3---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=author_recirc-----79e5eb8049c9----3---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Michael Phi"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----79e5eb8049c9----3---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=author_recirc-----79e5eb8049c9----3---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "Illustrated Guide to LSTM\u2019s and GRU\u2019s: A step by step explanationHi and welcome to an Illustrated Guide to Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU). I\u2019m Michael, and I\u2019m a Machine\u2026"}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=author_recirc-----79e5eb8049c9----3---------------------50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": "10 min read\u00b7Sep 24, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F44e9eb85bf21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21&user=Michael+Phi&userId=1bdc81ea939d&source=-----44e9eb85bf21----3-----------------clap_footer----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21?source=author_recirc-----79e5eb8049c9----3---------------------50c86659_4473_4a38_9f94_58904052b1e6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "111"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F44e9eb85bf21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21&source=-----79e5eb8049c9----3-----------------bookmark_preview----50c86659_4473_4a38_9f94_58904052b1e6-------", "anchor_text": ""}, {"url": "https://learnedvector.medium.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "See all from Michael Phi"}, {"url": "https://towardsdatascience.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Youssef Hosni"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Building An LSTM Model From Scratch In PythonHow to build a basic LSTM using Basic Python libraries"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "\u00b717 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&user=Youssef+Hosni&userId=859af34925b7&source=-----1dedd89de8fe----0-----------------clap_footer----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&source=-----79e5eb8049c9----0-----------------bookmark_preview----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@coucoucamille?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@coucoucamille?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Coucou Camille"}, {"url": "https://medium.com/codex?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "CodeX"}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Time Series Prediction Using LSTM in PythonImplementation of Machine Learning Algorithm for Time Series Data Prediction."}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "\u00b76 min read\u00b7Feb 10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcodex%2F19b1187f580f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Ftime-series-prediction-using-lstm-in-python-19b1187f580f&user=Coucou+Camille&userId=d796c2fbb274&source=-----19b1187f580f----1-----------------clap_footer----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F19b1187f580f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Ftime-series-prediction-using-lstm-in-python-19b1187f580f&source=-----79e5eb8049c9----1-----------------bookmark_preview----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@prateekgaurav?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@prateekgaurav?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Prateek Gaurav"}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "NLP: Zero To Hero [Part 2: Vanilla RNN, LSTM, GRU & Bi-Directional LSTM]Link to Part 1of this article: NLP: Zero To Hero [Part 1: Introduction, BOW, TF-IDF & Word2Vec] Link to Part 3 of this article: NLP: Zero\u2026"}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "\u00b78 min read\u00b7Mar 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F77fd60fc0b44&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40prateekgaurav%2Fnlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44&user=Prateek+Gaurav&userId=966fe9bb6729&source=-----77fd60fc0b44----0-----------------clap_footer----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----79e5eb8049c9----0---------------------b02262b7_31d4_4537_be08_15789133bf23-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77fd60fc0b44&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40prateekgaurav%2Fnlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44&source=-----79e5eb8049c9----0-----------------bookmark_preview----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Yujian Tang"}, {"url": "https://medium.com/plain-simple-software?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Plain Simple Software"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Long Short Term Memory in KerasHow to create an LSTM model with Tensorflow Keras"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "\u00b76 min read\u00b7Dec 1, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fplain-simple-software%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&user=Yujian+Tang&userId=1c4e6640433f&source=-----acdf61c056da----1-----------------clap_footer----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----79e5eb8049c9----1---------------------b02262b7_31d4_4537_be08_15789133bf23-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&source=-----79e5eb8049c9----1-----------------bookmark_preview----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----79e5eb8049c9----2---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----79e5eb8049c9----2---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----79e5eb8049c9----2---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----79e5eb8049c9----2---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----79e5eb8049c9----2---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----79e5eb8049c9----2---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----2-----------------clap_footer----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----79e5eb8049c9----2---------------------b02262b7_31d4_4537_be08_15789133bf23-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----79e5eb8049c9----2-----------------bookmark_preview----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----79e5eb8049c9----3---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----79e5eb8049c9----3---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----79e5eb8049c9----3---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----79e5eb8049c9----3---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----79e5eb8049c9----3---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----79e5eb8049c9----3---------------------b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----3-----------------clap_footer----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----79e5eb8049c9----3---------------------b02262b7_31d4_4537_be08_15789133bf23-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----79e5eb8049c9----3-----------------bookmark_preview----b02262b7_31d4_4537_be08_15789133bf23-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----79e5eb8049c9--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}