{"url": "https://towardsdatascience.com/watch-this-neural-network-learn-to-see-545492272440", "time": 1683002109.909676, "path": "towardsdatascience.com/watch-this-neural-network-learn-to-see-545492272440/", "webpage": {"metadata": {"title": "Watch this Neural Network Learn to See | by Conor Lazarou | Towards Data Science", "h1": "Watch this Neural Network Learn to See", "description": "The primary advantage that deep learning has over other machine learning techniques is its ability to automatically learn abstract representations of the input data. This wasn\u2019t always known to be\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Perceptrons_(book)#The_XOR_affair", "anchor_text": "a book", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/MNIST_database", "anchor_text": "MNIST dataset", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Rectifier_(neural_networks)", "anchor_text": "ReLU", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Hyperbolic_function#Tanh", "anchor_text": "tanh", "paragraph_index": 6}, {"url": "https://github.com/ConorLazarou/medium/blob/master/visualizing_mnist_12019_12/tanh/visualizations/conv6.gif", "anchor_text": "click this link", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Gabor_filter#", "anchor_text": "Gabor Filters", "paragraph_index": 13}, {"url": "https://openreview.net/references/pdf?id=Sy2fzU9gl", "anchor_text": "as a single feature", "paragraph_index": 14}, {"url": "http://flatland.ai", "anchor_text": "flatland.ai", "paragraph_index": 18}], "all_paragraphs": ["A warning to mobile users: this article has some chunky gifs in it.", "The primary advantage that deep learning has over other machine learning techniques is its ability to automatically learn abstract representations of the input data. This wasn\u2019t always known to be the case, however. Back in 1969, Minsky and Papert published a book that demonstrated (among other things) that single-layer perceptrons, the ancestors of artificial neural networks, can\u2019t solve the XOR problem. For those of us without a computer science background or with lives otherwise, the XOR problem is the task of accepting two binary inputs, A and B, and returning true if and only if exactly one of A or B is true, hence the name \u201cexclusive or\u201d, or XOR. The reason that single-layer perceptrons are unable to solve this problem is that they can only resolve linearly-separable classes. If you were to draw the possible inputs to the XOR problem and their outputs, the space would look like this:", "Now, can you draw a single straight line across this image and separate the circles from the crosses? Spoiler: you can\u2019t, and neither can perceptrons. Fortunately, brave pioneers had the insight to stick two perceptrons together, and the field of deep learning was born (more or less). The reason why this works is that each layer of a neural network can be considered an embedding of the previous layer; while the circles and crosses in the above image may not be linearly-separable in their original form, they are linearly-separable with a simple encoding. Take the top-left and bottom-right corners of the image and hold them still in your mind. Then, with the power of your imagination, fold the image in half through the third dimension, dragging the top-right corner out of your screen and pressing it back down onto the bottom-left corner. If you did it right, it should look something like this:", "Now, can you draw a straight line across this image and separate the circles from the crosses? I sincerely hope so. This action, taking information and encoding it as some other, more useful form, is the primary task that neural networks excel at. In fact, training neural networks not for their predictive ability but for the learned representations they discover has been a mainstay of deep learning research.", "Convolutional Neural Networks (CNNs) are the most popular architecture for applying deep learning to image data. In a nutshell, CNNs learn many filters which they apply to each pixel of an image and its layers. Through the application of these filters to the image, as well as repeated down-sampling, the neural network learns to recognize simple, low-level features in its first layers and complex, high-level features in its last layers. Or at least, that\u2019s how they\u2019re typically explained.", "As you can see, the model learns to recognize various edges, then facial features, then entire faces (many intermediate layers removed). If you google \u201cconvolutional neural network layer visualization\u201d, you\u2019ll find plenty of the above sort of image. However, I\u2019ve never seen CNN layers visualized during the training process, so I thought I\u2019d see how they looked. For this exploration, I used the common MNIST dataset, a set of 60 000 hand-drawn digits in black and white, each with a height and width of 28 pixels. I used a simple convolutional model, illustrated here:", "The neural network was trained for five epochs, with a minibatch size of 1024 images, totaling 290 training steps. After every step, a pre-selected set of ten sample images (one of each digit) were fed into the model and the activations of each convolutional layer were saved. Although it\u2019s fallen out of fashion in recent years in favour of the more easily-trainable ReLU function, I decided to use tanh as the activation function in the convolutional layers. This is because tanh is bounded between -1 and 1, making it simple to visualize. When the activations of the first layer are applied to a red-blue colourmap, this is the result:", "Conv1 appears to have learned to recognize stroke width in the first and second channels, as the insides of each digit are dark red while the outsides are light red. In the third and fourth channels, it appears to have learned the concept of edges, with the digits being blue, the background being pink, and the digit edges being white. These activations are a long-shot from what the deep learning canon would suggest, however, which is that each channel would learn a clear and distinct feature, such as vertical and horizontal edges; Conv1 is largely reproducing the original input with slight annotation.", "Similar to Conv1, Conv2 also appear to be reproducing the original input. Channels one, two, and four are nearly identical to each other and to the edge-highlighting behaviour seen in Conv1, and channel three is simply a fuzzy reproduction of the input.", "In Conv3, we see what may be the first real learned features. In the sixth channel, towards the end of training, we see that the digits are blue, most of the background is pink, and the background directly beneath each part of the digit is red. This suggests that this channel has learned to recognize the bottoms of horizontal edges. Similarly, the seventh channel has red digits, pink background, and white horizontal edges above each digit. The other channels appear to be simple reproductions of the original images, however.", "In Conv4, we see more clearly defined features. In particular, we see edges at different angles. The first, second, and sixth channels identify the tops of horizontal edges. The third, seventh, and eighth channels identify diagonal edges. The other two channels are coarse reproductions of the original.", "Conv5 has had substantial downsampling, with a resolution of only 7x7 pixels, but appears to have meaningful feature extraction. At the earliest steps in training, each channel is a pink wash, largely void of information. By step 70, the layer has learned to produce a blob that vaguely resembles the input. However, by the end of training, the channels have clearly differentiated themselves from each other, and show sharp changes in activation. It\u2019s unclear what features have been learned here due to the low resolution and entangling of what we would call independent features, but it\u2019s clear that each channel here has something useful.", "Unfortunately, Conv6 is just over Medium\u2019s file size limit, you\u2019ll have to click this link in order to watch it learn. Similar to Conv5, the learned features are clearly visible, but it\u2019s nearly impossible to tell what they actually correspond to.", "So what\u2019s the moral of this story? I propose there are three. First, deep learning outcomes are rarely as clear-cut as the canon suggests. Many textbooks, including Deep Learning (Goodfellow et al.), liken low-level convolutional layers to Gabor Filters and other hand-crafted computer vision filters. Despite the model achieving over 95% accuracy on the testing data, the first four convolutional layers did very little as far as feature extraction goes. Granted, this was a very simple model for a very simple task, and it\u2019s likely that a more complex model trained for a harder task would have learned at least some useful low-level features, but the way that deep learning is typically taught (in my experience) suggests that feature refinement and extraction is inevitable, even for simple tasks; this is plainly not the case.", "The second lesson is that learned features are unlikely to be intuitive, independent qualities that a human might select for. Conv5 and Conv6 have clearly learned something, and the original images have been encoded in such a way that the dense layers of the network can classify them by digit type, but it isn\u2019t immediately obvious what they\u2019ve learned to detect. This is a common problem in deep learning, and especially in generative modelling, where a model may learn to embed two or more seemingly unrelated qualities as a single feature.", "The third lesson here is one that I\u2019m reminded of daily in my work as a data scientist, and that\u2019s that it pays to visualize everything. I went into this project expecting to write a very different article. I was excited to show the network learning and refining features, from low-level edge detection to high-level loops and whirls. Instead, I found a lazy layabout that hardly refined features until the eleventh hour. Most notably, I was surprised to see that, once the layers learned some representation of the input, they hardly changed over the course of the training process. Visualizing this has bolstered my understanding of convolutional neural network training. I hope you\u2019ve learned something here as well.", "For those curious, the code used to train this network and produce these visualizations is available in this Github repo:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data science and ML consultant, generative artist, writer. flatland.ai"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F545492272440&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----545492272440--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----545492272440--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://conor-lazarou.medium.com/?source=post_page-----545492272440--------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=post_page-----545492272440--------------------------------", "anchor_text": "Conor Lazarou"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdeb461dc9d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&user=Conor+Lazarou&userId=deb461dc9d26&source=post_page-deb461dc9d26----545492272440---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F545492272440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F545492272440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://sianmolloy.com/", "anchor_text": "Sian Molloy"}, {"url": "https://en.wikipedia.org/wiki/Perceptrons_(book)#The_XOR_affair", "anchor_text": "a book"}, {"url": "https://en.wikipedia.org/wiki/MNIST_database", "anchor_text": "MNIST dataset"}, {"url": "https://en.wikipedia.org/wiki/Rectifier_(neural_networks)", "anchor_text": "ReLU"}, {"url": "https://en.wikipedia.org/wiki/Hyperbolic_function#Tanh", "anchor_text": "tanh"}, {"url": "https://github.com/ConorLazarou/medium/blob/master/visualizing_mnist_12019_12/tanh/visualizations/conv6.gif", "anchor_text": "gif"}, {"url": "https://github.com/ConorLazarou/medium/blob/master/visualizing_mnist_12019_12/tanh/visualizations/conv6.gif", "anchor_text": "click this link"}, {"url": "https://en.wikipedia.org/wiki/Gabor_filter#", "anchor_text": "Gabor Filters"}, {"url": "https://openreview.net/references/pdf?id=Sy2fzU9gl", "anchor_text": "as a single feature"}, {"url": "https://github.com/ConorLazarou/medium/tree/master/12019/visualizing_mnist", "anchor_text": "ConorLazarou/mediumVisualizations of a convolutional neural network as it learns to recognize handwritten digitsgithub.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----545492272440---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----545492272440---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/visualization?source=post_page-----545492272440---------------visualization-----------------", "anchor_text": "Visualization"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----545492272440---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/data-science?source=post_page-----545492272440---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F545492272440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&user=Conor+Lazarou&userId=deb461dc9d26&source=-----545492272440---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F545492272440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&user=Conor+Lazarou&userId=deb461dc9d26&source=-----545492272440---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F545492272440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----545492272440--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F545492272440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----545492272440---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----545492272440--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----545492272440--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----545492272440--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----545492272440--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----545492272440--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----545492272440--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----545492272440--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----545492272440--------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Conor Lazarou"}, {"url": "https://conor-lazarou.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "http://flatland.ai", "anchor_text": "flatland.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdeb461dc9d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&user=Conor+Lazarou&userId=deb461dc9d26&source=post_page-deb461dc9d26--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F51220adfabae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwatch-this-neural-network-learn-to-see-545492272440&newsletterV3=deb461dc9d26&newsletterV3Id=51220adfabae&user=Conor+Lazarou&userId=deb461dc9d26&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}