{"url": "https://towardsdatascience.com/googles-efficientdet-an-overview-8d010fa15860", "time": 1683004411.772141, "path": "towardsdatascience.com/googles-efficientdet-an-overview-8d010fa15860/", "webpage": {"metadata": {"title": "Google\u2019s EfficientDet: An Overview | by Harpal Sahota | Towards Data Science", "h1": "Google\u2019s EfficientDet: An Overview", "description": "If you\u2019re like me and you read Google\u2019s EfficientDet paper and you\u2019re like \u201cwhat the hell is going on?\u201d. Don\u2019t fret I\u2019ve reviewed the paper and will try to explain the model as best I can. This model\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["If you\u2019re like me and you read Google\u2019s EfficientDet paper and you\u2019re like \u201cwhat the hell is going on?\u201d. Don\u2019t fret I\u2019ve reviewed the paper and will try to explain the model as best I can.", "This model is built on previous work (like so many other models), more specifically, a key piece of work known as EfficientNet:", "Before we delve into the details of Google\u2019s new objected detection model let\u2019s do the background work on EfficientNets.", "The authors of this paper focus on how to efficiently scale Convolutional Neural Networks (ConvNets) to improve performance. The typical way of scaling ConvNets for improved performance is to increase one of the following: network depth, width or image resolution. Though it is possible to scale two or more of these together it is currently a tedious process and generally leads to models with sub-optimal accuracy and efficiency. Below is an illustration of the different scaling methods, directly lifted from the paper:", "The authors aim to answer the question:", "Is there a principled method to scale up ConvNets that can achieve better accuracy and efficiency?", "You may have guessed it, but the answer is yes. They discover is it important to balance all dimensions of network width/depth/resolution. What will surprise you is the simplicity of their scaling method. They simply scaling each dimension by a constant ratio. That\u2019s it! They term this method compound scaling. As images used to train ConvNets get larger compound scaling starts to make sense because larger images need deeper networks to increase the receptive field and more channels to capture smaller details in the bigger image.", "What was quickly discovered is that the performance improvement from model scaling is heavily dependent on the baseline network. The authors take this one step further and use an algorithm called neural architecture search (NAS) to find an optimum baseline network. The NAS algorithm at a high level uses reinforcement learning to determine optimum structures, given an objective function. Using NAS a new family of models was created called EfficientNets. The performance of these models is compared against ConvNets on the ImageNet dataset and the results are shown in the image below:", "What is striking from these results is the margin these models outperform other state of the art models both in terms of accuracy and the number of parameters. The authors also showed these models transfer well to other datasets becoming the top scoring models in 5 out of 8 publicly available datasets, all while having 21x less fewer parameters.", "So how does compound scaling actually work? First, let\u2019s define a ConvNet as:", "They essentially describe it as a list of layers composed of operations (e.g. convolution) which are applied to input tensors.", "Compound scaling attempts to expand the network length (L\u1d62), Width (C\u1d62) and/or resolution (H\u1d62, W\u1d62) all without changing predefined F\u1d62 in the baseline network. The rationale for fixing F\u1d62 was to reduce the design space, but the design space is still rather large considering that L\u1d62, C\u1d62, H\u1d62 and W\u1d62 can still be explored for each layer. To reduce the design space further a restriction is applied in that all layers must be scaled uniformly with a constant ratio. The target of compound scaling is to maximise the accuracy of the model given resource constraints, which is formulated as an optimisation problem:", "w, d and r are coefficients for scaling the network width, depth and resolution. The predefined parameters have a ^ above their notation. An example of a predefined network is shown below:", "The difficulty in scaling the depth (d), width (w) and resolution (r) of a ConvNet is that all three depend on each other and can change under different resource constraints. As a result, ConvNets are usually only scaled in a single dimension.", "Depth: Scaling the depth is the most common way of scaling a ConvNet. The networks are made deeper with the rationale that deeper ConvNets can extract richer and more complex features. On the downside, deeper ConvNets are more difficult to train due to the vanishing gradients problem. This issue has been alleviated with skip connections and batch normalisation, but there are diminishing returns for very deep networks.", "Width: Usually used for smaller models. Theses networks are typically better at capturing fine-grained features is images and are easier to train.", "Resolution: Increasing the input resolution of images, ConvNets can capture fine-grained patterns in the images. Early ConvNets were trained on 224x224 where more recent ConvNets are trained on 480x480. The figure below shows the performance of scaling each of these dimensions individually (scaling performed on the pre-defined network, shown above):", "The key observation from this result shows scaling up the depth, width and resolution of a network improves accuracy, but the accuracy diminishes for deeper and bigger models.", "So far it is clear that scaling dimensions are not independent. As an example, the authors state that:", "high resolution images should require deeper networks, so that larger receptive fields can capture similar features that include more pixel in bigger images.", "As a result of increasing the resolution, the network width should also be increased to capture more fine-grained details. These intuitions suggest that models need to be scaled in all of these dimensions and not in a single dimension. To validate their intuitions the authors scaled the width (w) of a network over different combinations of depth (d) and resolution (r) (image below). The example of scaling in the graph below starts with a baseline network (d=1.0, r=1.0) and has 18 convolutional layers with a resolution of 224x224. The last baseline network (d=2.0, r=1.3) results in 36 convolutional layers and a resolution of 299x299.", "This result leads the authors to an observation that to obtain better model accuracy and efficiency, it is important to balance for all the dimensions of the network during scaling. From this observation, they propose a compound scaling method. This method uses a compound scaling coefficient \u03a6 to uniformly scale the network dimensions:", "In the equation \u03b1, \u03b2 and \u03b3 are constants which can be determined by a grid search. The user-defined coefficient (\u03a6) controls how the resources are allocated for model scaling. While \u03b1, \u03b2 and \u03b3 define how to assign these resources to the network width, depth and resolution respectively.", "The scaling method is evaluated by scaling existing ConvNets. To truly take advantage of the new method, a new architecture family was created called EfficientNet. They build the baseline network by using NAS to optimise for both accuracy and FLOPS. Their search produces an efficient network called EfficientNet-B0. The table below illustrates the EfficientNet-B0 network (it\u2019s exactly the same as the pre-defined network shown earlier):", "Their next step was to scale up the EfficientNet-B0 by applying compound scaling in two steps:", "The performance of these new networks compared to other state of the art networks are shown in the table below:", "The EfficientNets consistently perform better and reduce both the number of parameters and FLOPS compared to existing ConvNets. The table and figure below further reinforce this:", "The latency on a CPU for EfficientNet-B1 is 5.7x faster compared to ResNet-152 even though they have comparable accuracy. At the top end of the accuracy scale, the GPipe model has a latency of 19.0s for a single image with 84.3% accuracy on the dataset. The largest EfficientNet model (B7) only has a latency of 3.1s which is a 6.1x speedup. The figure below shows how the FLOPS vs. the Imagenet Top-1 Accuracy.", "The figure clearly shows the EfficientNet family makes far better use of the resources available, with the model performing better in terms of accuracy and a significant reduction in the number of FLOPS.", "To deconvolute the contribution of the compound scaling method from the EfficientNet architecture the B0 architecture was scaled only in a single dimension. Those results are shown in the figure below:", "It is clear to see that compound scaling is far superior than scaling only a single dimension which quickly results in diminishing returns. This highlights the importance of compound scaling. To further understand why compound scaling is so effective the figure below compares the class activation maps from a selection of scaled B0 models:", "The compound scaling model tends to focus on regions with more relevant object details. The other models show less focus on these details.", "Overall the authors of this paper showed that balancing network depth, width and resolution is critical for optimising performance given a set of resource constraints. The compound scaling method provides an elegant way of effectively scaling a model in all of these dimensions. This now brings up to the next section of this post, Google\u2019s EfficientDet which builds on top of the work discussed above.", "Over recent years progress in object detection has been tremendous resulting in models which are more accurate but at the cost of increased computation. These large computation costs will deter their deployment in many real-world applications such as self-driving cars where low latency predictions are a necessity. With such constraints, model efficiency is incredibly important for object detection. Model detector architectures such as one-stage and anchor-free detectors are more efficient but usually at the cost of accuracy. It is therefore natural to ask:", "Is it possible to build a scalable detection architecture with both higher accuracy and better efficiency?", "Google\u2019s EfficientDet aims to tackle this question and to answer this question we first need to understand the challenges of the current design choices for object detectors:", "Challenge 1 - Efficient Multi-Scale Feature Fusion: Feature Pyramid Networks (FPN) are widely used for multi-scale feature fusion. Recent works such as PANet and NAS-FPN allow for cross-scale feature fusion. Previous feature fusion methods simply sum the features together, however, these features are at different resolutions and have been observed to contribute to the output fused feature unequally. To get around this issue a weighted bi-directional feature pyramid network (BiFPN) is proposed. The BiFPN has learnable weights to determine the importance of different input features, which apply top-down and bottom-up multi-scale feature fusion.", "Challenge 2 - Model Scaling: Model scaling of object detectors usually sacrifices either accuracy or efficiency. Inspired by the work done by the authors of EfficientNets a compound scaling method for object detectors is proposed. Like EfficientNets this scaling method also scales the depth, width and resolution of the network.", "The combination of EfficientNet with the proposed BiFPN and compound scaling resulted in the creation of a new family of detectors knows as EfficientDet. This family of models consistently achieved higher accuracy and reduced the number of FLOPS by an order of magnitude compared to previous object detectors. The contribution of the EfficentDet to the object detection community can be summarised into three points:", "To understand the contribution of the BiFPN we need to first formulate the problem. Multi-scale feature fusion aims to aggregate features at different resolutions. This can be represented as a list of multi-scale features:", "where each element above represents the feature at level l\u1d62. The aim is to find a transformation f that can aggregate the features and output a list of new features:", "To understand why this is important let's take a look at the traditional FPN which integrates features at different scales:", "It has 3\u20137 input features (P\u2083 - P\u2087) where each input feature represents a feature level with a given resolution. This FPN aggregates multi-scale features in a top-down manner:", "Resize is typically the upsampling or downsampling operations for resolution matching. Finally, Conv is a convolution operation for feature processing.", "The FPN shown above is inherently limited by the flow of information in one direction. To get around this issue PANet adds a bottom-up path and the NAS-FPN uses neural architecture search to find better cross-scale feature network topology. Both these network designs are shown in the image below:", "The authors show that PANet achieves better accuracy than NAS-FPN, but at the cost of more parameters and computations. Several optimisations were proposed:", "With these optimisations, the new feature network is termed bidirectional feature pyramid network (BiFPN). The BiFPN is illustrated in the figure below:", "As mentioned earlier, the fusion of features at different resolutions typically involves resizing them followed by a sum operation. The drawback of this method is that all features are treated equally. Since these features are at different resolutions they usually contribute to the output feature unequally. To get around this an additional weight for each input feature is calculated to allow the network to learn the importance of each feature. A total of three weighted fusion approaches were tested:", "The final BiFPN integrates both bidirectional cross-scale connections the fast normalisation method. An example of this is shown below, which is the 6th layer in the BiFPN:", "The top equation is the intermediate for the top-down pathway and the bottom is the equation for the bottom-up pathway.", "With the invention of the BiFPN, a new family of detectors has been created called EfficientDet. The architecture of EfficientDet is shown below and uses the EfficientNet as a backbone network.", "The BiFPN in this network serves as a feature network. It takes the features from the levels 3 - 7 from the backbone network and repeatedly applies the BiFPN. The fused features are fed into a class and box network to predict the object class and bounding box.", "Inspired by the compound scaling used in EfficientNets a new compound scaling method was proposed for object detection. This method uses a coefficient (\u03a6) to jointly scale-up all dimensions of the backbone network, BiFPN network, class/box network and resolution. The scaling of each network component is described below:", "Using the three equations shown above a family networks is created from EfficientDet-D0 (\u03a6 = 0) to D6 (\u03a6 = 6). This further elaborated upon in the table below:", "The table also contains a D7 model which could not fit into memory unless the batch size was changed or other settings. As a result, the D6 model was expanded to D7 by only increasing the input image resolution.", "How do these models compare to other detectors? The table below shows the comparison of the EfficientDet family to other models which are grouped together by accuracy:", "The EfficientDet family of models achieves better accuracy and efficiency than previous detectors across a wide range of accuracy levels and resource constraints.", "To understand how much the BiFPN contributes to the model performance, the table below compares the impact of the backbone and BiFPN:", "It is clear to the see that a strong backbone structure improved performance, but the addition of the BiFPN improved performance further not only by increasing mAP but also by decreasing the number of parameters and FLOPs. Another key addition is that of weighted connections. How do weighted connections influence performance compared to other FPNs:", "You can see the vanilla FPN which is limited by the one-directional flow of information has the lowest accuracy. The PANet and NAS-FPN models show improved accuracy but require more parameters and FLOPS. Overall the BiFPN achieves the best accuracy with fewer parameters and FLOPS.", "The EfficientDet network is heavily inspired by the work done on the EfficientNet models. Using compound scaling the performance of the model in terms of both accuracy and efficiency has been improved compared to other modern object detection models. The EfficientDet family of models have been shown to have significant speedup on GPU and CPUs which is critical for applications that require low latency. I believe we are entering a phase in object detection development where optimising current models are going to become critical. We can always build bigger and deeper models for more accuracy, but can we optimise them to get the most out of them?", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8d010fa15860&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8d010fa15860--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8d010fa15860--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@harpalsahota?source=post_page-----8d010fa15860--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@harpalsahota?source=post_page-----8d010fa15860--------------------------------", "anchor_text": "Harpal Sahota"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F63149bc3725a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&user=Harpal+Sahota&userId=63149bc3725a&source=post_page-63149bc3725a----8d010fa15860---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d010fa15860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d010fa15860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/photos/m31-space-astronomy-astronomical-3613931/", "anchor_text": "Source"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "Tan & Le, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://arxiv.org/abs/1911.09070", "anchor_text": "Tan et al, 2019"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8d010fa15860---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----8d010fa15860---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----8d010fa15860---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/convolution-neural-net?source=post_page-----8d010fa15860---------------convolution_neural_net-----------------", "anchor_text": "Convolution Neural Net"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d010fa15860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&user=Harpal+Sahota&userId=63149bc3725a&source=-----8d010fa15860---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d010fa15860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&user=Harpal+Sahota&userId=63149bc3725a&source=-----8d010fa15860---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d010fa15860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8d010fa15860--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8d010fa15860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8d010fa15860---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8d010fa15860--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8d010fa15860--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8d010fa15860--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8d010fa15860--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8d010fa15860--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8d010fa15860--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8d010fa15860--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8d010fa15860--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@harpalsahota?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@harpalsahota?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Harpal Sahota"}, {"url": "https://medium.com/@harpalsahota/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "46 Followers"}, {"url": "https://www.linkedin.com/in/harpalsahota/", "anchor_text": "https://www.linkedin.com/in/harpalsahota/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F63149bc3725a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&user=Harpal+Sahota&userId=63149bc3725a&source=post_page-63149bc3725a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea125248b5d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgoogles-efficientdet-an-overview-8d010fa15860&newsletterV3=63149bc3725a&newsletterV3Id=ea125248b5d0&user=Harpal+Sahota&userId=63149bc3725a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}