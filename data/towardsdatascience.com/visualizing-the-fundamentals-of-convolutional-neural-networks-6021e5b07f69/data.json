{"url": "https://towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69", "time": 1683001845.637889, "path": "towardsdatascience.com/visualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69/", "webpage": {"metadata": {"title": "Visualizing the Fundamentals of Convolutional Neural Networks | by Mark C. F. Sousa | Towards Data Science", "h1": "Visualizing the Fundamentals of Convolutional Neural Networks", "description": "Illustrations of the convolution, cross-correlation, stride, ReLU, and pooling in Convolutional Neural Networks"}, "outgoing_paragraph_urls": [{"url": "https://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf", "anchor_text": "inspired", "paragraph_index": 0}, {"url": "https://www.ncbi.nlm.nih.gov/pubmed/14449617", "anchor_text": "Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex", "paragraph_index": 0}, {"url": "https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf", "anchor_text": "Neocognitron", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1703.04691.pdf", "anchor_text": "time series", "paragraph_index": 0}, {"url": "https://ieeexplore.ieee.org/document/6857341?reload=true", "anchor_text": "speech recognition", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "graphs", "paragraph_index": 0}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "Imagenet Large Scale Visual Recognition Challenge (ILSVRC)", "paragraph_index": 0}, {"url": "https://qz.com/1307091/the-inside-story-of-how-ai-got-good-enough-to-dominate-silicon-valley/", "anchor_text": "Alex Krizhevsky", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Geoffrey_Hinton", "anchor_text": "Geoffrey Hinton", "paragraph_index": 0}, {"url": "https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf", "anchor_text": "Backpropagation", "paragraph_index": 0}, {"url": "https://www.acm.org/media-center/2019/march/turing-award-2018", "anchor_text": "fathers of Deep Learning", "paragraph_index": 0}, {"url": "https://deepai.org/machine-learning-glossary-and-terms/multilayer-perceptron", "anchor_text": "Multilayer Perceptron (MLP)", "paragraph_index": 1}, {"url": "https://mathinsight.org/linear_function_one_variable", "anchor_text": "are not linear", "paragraph_index": 28}, {"url": "https://www.britannica.com/science/nervous-system/The-neuronal-membrane", "anchor_text": "doesn\u2019t fire when it receives a stimulus under a certain threshold", "paragraph_index": 37}, {"url": "https://www.di.ens.fr/willow/pdfs/icml2010b.pdf", "anchor_text": "increases the invariance of the network to translations", "paragraph_index": 42}], "all_paragraphs": ["Convolutional Neural Networks (CNNs) are a subtype of Artificial Neural Networks (ANNs) mostly used for image classification. CNNs follow the biological principle of the replication of a structure capable of identifying patterns to identify these patterns in different locations. It was inspired by the model of cats\u2019 visual system proposed by the Nobel prizes winners Hubel and Wiesel at \u201cReceptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex\u201d, published in 1962. One of the works that used this inspiration was the Fukushima\u2019s Neocognitron, in 1980, although the word Convolution was not used at the time. Therefore, it is not a coincidence that CNNs are very successful in image recognition. However, they have also shown good results dealing with temporal data such as time series and speech recognition, or even when applied on graphs. The CNNs became very popular after winning the 2012 edition of the competition Imagenet Large Scale Visual Recognition Challenge (ILSVRC) by a margin of roughly 10%. Alex Krizhevsky and Ilya Sutskever, under the guidance of Geoffrey Hinton, submitted the CNN architecture that became famous under the name of \u201cAlexNet\u201d. At the time, Geoffrey Hinton had already made significant scientific contributions to the field of ANNs. He was one of the contributors of the Backpropagation algorithm in 1986, and Boltzmann Machines in 1983. These are some of the reasons that Geoffrey Hinton was recognised as one of the fathers of Deep Learning.", "A typical CNN is composed by a series of convolutional layers, that act as features extractors, followed by a classifier, usually a Multilayer Perceptron (MLP), also known as Fully Connected Layers (FC layers), as shown by Figure 1.", "The first layer receives the input image represented in three colour channels, the RGB channels. Then, the first layer executes the convolutions of the input image with multiple kernels, resulting in a set of feature maps of the first layer. Each feature map determines the intensity and location of a specific feature. The feature map extracted by a convolutional layer can be submitted to a downsampling operation known as Pooling. The Pooling operation is optional, so it may not follow every convolutional layer. The result of a Pooling layer is another set of feature maps, with the same number of maps, but with reduced resolution. The following convolutional layer uses the feature map from the previous layer to execute more convolutions and generate new feature maps. The feature maps from the last layers are the input of the classifier, the FC layers.", "The convolution operation, which is denoted by an \u2217 (asterisk), can be described as:", "being \ud835\udc65 some type of input, such as a sensor signal, \ud835\udc61 a given time, and \ud835\udc58 the kernel applied.", "One important property of the convolution operation is that it is commutative, which means that (\ud835\udc65\u2217 \ud835\udc58)=( \ud835\udc58\u2217\ud835\udc65) as follows:", "On the other hand, the cross-correlation operation, denoted by \u22c6 (five-pointed star), is not commutative and can be described as:", "The commutative property of the convolution emerges from the fact that the kernel is flipped relative to the input. The flip occurs as a result of index manipulation. Note that the index for the input \ud835\udc65 is \ud835\udc4e and the index for kernel is \ud835\udc61\u2212\ud835\udc4e. Even though the commutative is a valuable property for writing mathematical proofs, it is not as relevant for neural network implementation. In fact, many machine learning libraries implement the cross-correlation instead of convolution and refer to both operations as convolution. As a consequence, the kernel that is learned during training will be flipped in comparison to a library that actually implements the convolution as described by equation 1. We will follow the same convention in this text and call the cross-correlation convolution.", "We can adapt the equation 3 for the convolution with 2D data, such as grey-scale images:", "In other words, the convolution operation extracts multiple patches of pixels from the image to multiply by the kernel. The kernel is basically a matrix of weights. The patch of pixels extracted from the image is often known as receptive field \u2014 in biology, the receptive field is a sensorial region that stimulates a neuron. The multiplication between the receptive field and the kernel consists of an element-wise multiplication between each pixel and the respective element of the kernel. After the multiplications, the results are added to form one element of the feature map, defined in equation 4 by \ud835\udc5f[\ud835\udc56,\ud835\udc57].", "The following animation shows the convolution operation between a 5x5 grey-scale image and a 3x3 kernel. The receptive field is highlighted by the red square. The output of this convolution is a 3x3 feature map.", "The actual image used in the animation can be seen in Figure 3 below. The values in the kernel and the feature map were rescaled to fit into the interval between 0 and 255 to be represented as grey-scale pixels. The brighter pixels in the image represent higher values from convolution, while the darker pixels represent lower values.", "The convolution above uses kernel 3x3, consequently, there are nine possible receptive fields in the input, each with size 3x3. Note that the receptive fields composed of mostly white pixels or composed of mostly dark pixels result in a very dark pixel after the convolution. On the other hand, the receptive fields that are composed by three bright pixels on the left, intermediate pixels in the middle and dark pixels on the right, result in the brightest pixels after the convolution. This is because this type of kernel is useful to highlight edges, specifically edges transitioning from a bright region on the left to a dark region on the right.", "Now, see what happens when we apply the same kernel to an image that also contains the opposite transition, from a dark region on the left to a bright region on the right. In Figure 4, the receptive fields that exhibit the transition from dark to bright resulted in the darkest pixels. Note that the former transition (from bright to dark) still resulted in the brighter pixels. It means that this kernel not only detects the edges transitioning from bright to dark but also detects the opposite edges, from dark to bright. One type of edge results in the most positive values, while the other type of edge results in the most negative values.", "The convolution for RGB images is quite similar to the grey-scale case. The equation 4 can be adapted to RGB image adding another loop to iterate over the RGB channels as follows:", "The additional loop over the variable \ud835\udc50 allows the iteration on the channels RBG. As a result, the sum is done over three-dimensional data, instead of bi-dimensional, and still results in a single value for each three-dimensional receptive field and kernel.", "Let\u2019s start this topic with a practical example. Look at the result of the following three convolutions in Figure 5. In order to illustrate the result of the convolutions, each of the three kernels in the following examples consists of a small patch extracted from the image.", "In the first example, the patch composing the kernel comprises the region of the plane with the number six in white. The grey-scale image on the right is essentially the result of the convolution between the kernel and the image. The darkest pixels represent the smallest results of the operation between a receptive field and the kernel, on the other hand, the brightest pixels represent the highest values for the operation between a receptive field and the kernel.", "In the second example, the kernel consists of the patch of pixels forming the wheel of the plane. In the third example, the kernel consists of a patch of yellow pixels copied from the tail of the plane.", "Note that the brightest pixels in each resulting image correspond to the location that originated each kernel. In the first example, it corresponds to the location of the number 6. In the second example, it corresponds to the location of the wheels. Even though the kernel is a copy of one of the wheels, the other wheel is quite similar and also resulted in bright pixels. In the third example, the brightest pixels correspond to all the yellow region of the plane.", "The stride is the distance between each receptive field. All the examples we have shown so far use a stride of one. The adoption of such small strides results in a big overlap between receptive fields. As a result, a lot of information is repeated in adjacent receptive fields, as shown in Figure 6.", "In the case of a kernel with dimensions 3x3, the adoption of a stride of 2 results in one column or one row overlapping with adjacent receptive fields. This overlap is desired to guarantee that the stride doesn\u2019t skip important information.", "Increasing the stride will reduce the computational cost of the convolutions. If we change the stride from one to two, the reduction in the computational cost is about four. It happens because the stride affects the distance between receptive fields in both dimensions. Similarly, if we triple the stride, we can expect a computational cost reduction of roughly nine times. The computation cost is reduced because the increase in stride reduces the number of receptive fields extracted from the input, consequently, the dimension of the output is also reduced.", "Figure 7 shows four results of convolution using strides of 2, 4, 8, and 16. The kernel size used in the convolutions is 70x70. Note that increasing the stride by a factor of two, the execution time is reduced by almost four.", "In Figure 7, the result of the convolution using a stride of 16 has four times fewer pixels than the result using the stride of 8. Note that adopting the stride of 16 results in an overlapping of 54 rows or columns, because the receptive field size is 70x70. With the stride of 16, it is still possible to identify the highest values of the convolution by the brightest pixels in the wheel of the plane.", "In this section, we will study how the forward propagation works in the convolutional layers. To do so, we will understand how a single convolutional layer works and then understand how multiple layers work together. In this study, we will learn two new concepts: non-linear activation and pooling operation.", "Figure 8 shows the forward propagation in a typical convolutional layer, which consists of three stages: convolutions, non-linear activations, and pooling. The convolution operation was already discussed in the first section. Now, we will see the other two operations.", "The non-linear activation is also known as the detector stage. In this stage, the result of the convolutions and the bias are submitted to a non-linear activation such as the ReLU function. The non-linear activation doesn\u2019t change the dimensions of the feature map, it only modulates the values in it.", "First, what is linear activation? A linear activation is a function that follows the rule f(x)=ax, where a is a constant and x the variable. Its graph is a straight line through the origin (0, 0). It means that the functions in the shape f(x)=ax + b, in which a and b are constant, are not linear. Both are affine functions, but only the one with a single constant multiplying the variable is a linear function.", "To a function be linear, when we multiply the input by a constant \ud835\udefc, we should also see the output multiplied by the same constant \ud835\udefc. That means:", "Another requirement is that when we apply the sum of two inputs in a linear function, we should get the output equivalent of the sum of the two variable applied individually to the function:", "Now, why we do we use non-linear activation? Because when we apply linear combinations (additions or multiplications) in linear functions, the result is also linear. Even though many models can be roughly approximated by linear models, using non-linearities in ANNs makes it capable of representing both linear and non-linear models. In other words, non-linearities make ANNs more powerful function approximators.", "One of the most common non-linear activation used in deep learning is the ReLU function, which stands for Rectified Linear Unit. This function is given by:", "This function, when applied with a bias, results in a graph illustrated in Figure 9.", "Figure 10 shows how the ReLU modulates the result of the convolution. Here, the same results from Figure 2 are used to apply the ReLU function.", "The equivalent image of the ReLU function used in the example above is shown in Figure 11. Note that some of the intermediate values were blacked-out, highlighting the brightest three pixels.", "Next, in Figure 12, you can see some options of bias in the ReLU function. The function takes the result of the convolution of the plane with the patch of the image containing the wheel as input. Note that the bias behaves like a threshold that determines what is shown and what is not.", "The threshold behaviour depicted in Figure 12 resembles the biological neurons, that doesn\u2019t fire when it receives a stimulus under a certain threshold. If the stimulus surpasses the threshold, the neuron starts to fire, and also fires more frequently as the stimulus increases. In Figure 12, when the bias is 500, it is contributing to the activity of the artificial neuron. However, if we define the bias as -1000, the artificial neuron only fires with the strongest stimulus.", "To conclude, the ReLU function works as an artificial neuron. That is why this phase is called the detection phase. The ReLU function is responsible for detecting the presence of the feature extracted by the kernel. Consequently, there is a single bias for each the kernel, because each feature requires a different threshold.", "At last, but not least, the pooling operation. It is a downsampling operation executed over each feature map. It extracts receptive fields from the feature map and replaces it with a single value. This single value can be obtained by different aggregation criteria, such as maximum value, average, or weighted average according to the distance from the centre of the receptive field.", "Besides the aggregation criteria, there are other two hyperparameters in the pooling operation, the size of the receptive field and the stride.", "Similar to the stride, the pooling operation results in fewer data processed by the convolutions. One difference is that instead of skipping data, the pooling operation tries to summarise the receptive field into a single value. Another difference is that the stride is applied before the convolution, while pooling is applied over the result of a convolution, reducing the volume of data to the next layer. Furthermore, the receptive field of the pooling operation is bi-dimensional, because it is applied to each feature map individually, while the receptive field of the convolution is three-dimensional, comprising a section of all the feature maps in a layer.", "One desired side-effect of the pooling operation is that is increases the invariance of the network to translations of the input. This effect is amplified as more convolutional layers are followed by pooling layers.", "Figure 13 shows the propagation of values through two pooling layers with pooling size of 3x3 and stride of 2. Any activation in the region covered in blue the input feature map affects the region covered in blue in the outcome of pooling 1. Similarly, the activations in the region covered in blue in the outcome of pooling 1 affect the region covered in blue in the outcome of pooling 2. The same relationship is valid between the regions covered in green.", "Considering that the pooling in Figure 13 is max pooling, it doesn\u2019t matter where in the blue region the highest value occurs in the input feature map, because it will be propagated to the blue activation in the outcome pooling 2 in the same way. This is the reason why pooling layers enhance translation invariance, small translations in the input don\u2019t change the values in the output.", "Figure 14 shows the effect of different combinations of strides in convolution, biases in the ReLU function, pooling sizes, and pooling strides. On the left, there are three examples of strides: 2, 9, and 16. For each option of stride, there are three examples of bias: 500, -250, and -1000. For each bias, there are three examples of pooling size and stride: pooling size 3x3 and stride of 2, pooling size 5x5 and stride of 3, and pooling size 7x7 and stride of 4x4.", "The effect of the stride in the convolution and the stride in the max pooling is cumulative. When we use a stride of two in both convolution and in the max pooling, the final result is a reduction of roughly four times in the width and in the height of the feature map.", "The values 16 for stride in the convolution and four in the stride of max pooling are unusual. They were intentionally exaggerated to illustrate the impact they have in the final result of the convolutional layer. The resulting feature map has only 100 elements (10 x 10), much smaller than the feature map with 37636 elements (194 x 194).", "We will come back to the AlexNet, the first famous CNN architecture. This is a good practical example to understand how the components of CNNs work together. The building blocks of AlexNet is represented in Figure 14. The dashed pyramids represent the execution of convolutions using a receptive field from the input or the feature map from the previous layer. The big boxes represent the feature maps and the small boxes inside the feature maps are the receptive fields. This CNN can classify objects in 1000 different classes.", "One peculiarity of this architecture is that it was trained using two GPUs. The top elements of Figure 15 were allocated in one GPU, while the elements at the bottom were allocated in another GPU.", "You can get this CNN already trained in some frameworks, such as PyTorch. It is relatively easy to use. You can also use transfer learning to apply this architecture to other image datasets. It requires a little data processing to normalize and rescale the images to match the requirements of AlexNet, but it worth the try. It would be something like:", "You can import the model in PyTorch as follows:", "You can disable the training of the convolutional layers and create your own classifier to override the original AlexNet Fully Connected Layers:", "In addition to AlexNet, there are also other models in PyTorch that can be used to classify your own image dataset, given the necessary customizations. It is really recommended to test these models or even build your own CNN from scratch to understand how CNN works.", "Even if you were already familiar with the concepts presented here, I hope you could at least see them from another perspective. There were some other concepts from CNNs that were not discussed here. If you are curious or are not sure about a particular aspect of CNNs, please, let me know.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I hold a BSc degree in Computer Science and an MSc degree in Electrical Engineering. I have over ten years of experience working with Software Engineering."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6021e5b07f69&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@markfsousa?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@markfsousa?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "Mark C. F. Sousa"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F856073c3ec58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&user=Mark+C.+F.+Sousa&userId=856073c3ec58&source=post_page-856073c3ec58----6021e5b07f69---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6021e5b07f69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6021e5b07f69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@pactovisual?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Pacto Visual"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf", "anchor_text": "inspired"}, {"url": "https://www.ncbi.nlm.nih.gov/pubmed/14449617", "anchor_text": "Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex"}, {"url": "https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf", "anchor_text": "Neocognitron"}, {"url": "https://arxiv.org/pdf/1703.04691.pdf", "anchor_text": "time series"}, {"url": "https://ieeexplore.ieee.org/document/6857341?reload=true", "anchor_text": "speech recognition"}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "graphs"}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "Imagenet Large Scale Visual Recognition Challenge (ILSVRC)"}, {"url": "https://qz.com/1307091/the-inside-story-of-how-ai-got-good-enough-to-dominate-silicon-valley/", "anchor_text": "Alex Krizhevsky"}, {"url": "https://en.wikipedia.org/wiki/Geoffrey_Hinton", "anchor_text": "Geoffrey Hinton"}, {"url": "https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf", "anchor_text": "Backpropagation"}, {"url": "https://www.acm.org/media-center/2019/march/turing-award-2018", "anchor_text": "fathers of Deep Learning"}, {"url": "https://deepai.org/machine-learning-glossary-and-terms/multilayer-perceptron", "anchor_text": "Multilayer Perceptron (MLP)"}, {"url": "https://mathinsight.org/linear_function_one_variable", "anchor_text": "are not linear"}, {"url": "https://www.britannica.com/science/nervous-system/The-neuronal-membrane", "anchor_text": "doesn\u2019t fire when it receives a stimulus under a certain threshold"}, {"url": "https://www.di.ens.fr/willow/pdfs/icml2010b.pdf", "anchor_text": "increases the invariance of the network to translations"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6021e5b07f69---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/convolution?source=post_page-----6021e5b07f69---------------convolution-----------------", "anchor_text": "Convolution"}, {"url": "https://medium.com/tag/convolutional-neural-net?source=post_page-----6021e5b07f69---------------convolutional_neural_net-----------------", "anchor_text": "Convolutional Neural Net"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6021e5b07f69---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6021e5b07f69---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6021e5b07f69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&user=Mark+C.+F.+Sousa&userId=856073c3ec58&source=-----6021e5b07f69---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6021e5b07f69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&user=Mark+C.+F.+Sousa&userId=856073c3ec58&source=-----6021e5b07f69---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6021e5b07f69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6021e5b07f69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6021e5b07f69---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6021e5b07f69--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6021e5b07f69--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6021e5b07f69--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@markfsousa?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@markfsousa?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mark C. F. Sousa"}, {"url": "https://medium.com/@markfsousa/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "35 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F856073c3ec58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&user=Mark+C.+F.+Sousa&userId=856073c3ec58&source=post_page-856073c3ec58--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F856073c3ec58%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-fundamentals-of-convolutional-neural-networks-6021e5b07f69&user=Mark+C.+F.+Sousa&userId=856073c3ec58&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}