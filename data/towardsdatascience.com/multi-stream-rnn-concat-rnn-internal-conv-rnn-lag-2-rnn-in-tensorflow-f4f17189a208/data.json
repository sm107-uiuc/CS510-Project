{"url": "https://towardsdatascience.com/multi-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208", "time": 1682988321.765429, "path": "towardsdatascience.com/multi-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208/", "webpage": {"metadata": {"title": "Multi-Stream RNN, Concat RNN, Internal Conv RNN, Lag 2 RNN in Tensorflow | by Jae Duk Seo | Towards Data Science", "h1": "Multi-Stream RNN, Concat RNN, Internal Conv RNN, Lag 2 RNN in Tensorflow", "description": "For the last two week I have been dying to implement different kinds of Recurrent Neural Networks (RNN) and finally I have the time to implement all of them. Below is the list of different RNN cases\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "Recurrent Neural Networks", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/nips-2017-tensorflow-gated-recurrent-convolution-neural-network-for-ocr-part-1-with-47bb2a8a7ab3", "anchor_text": "Gated Recurrent Convolution NN for OCR", "paragraph_index": 2}, {"url": "https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-back-propagation-practice-math-956fbea32704", "anchor_text": "Only Numpy: Vanilla Recurrent Neural Network Deriving Back propagation Through Time Practice", "paragraph_index": 4}, {"url": "https://colab.research.google.com/drive/1d4cKR1VxFsxyXAck1Mk-zQGvlVuWdOEw", "anchor_text": "case a click here", "paragraph_index": 35}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/casea/casea.txt", "anchor_text": "logs click here.", "paragraph_index": 35}, {"url": "https://colab.research.google.com/drive/1U4zthQ9CmcwAi_mWrKVuTPqf88R0lxZz", "anchor_text": "case b click here", "paragraph_index": 35}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/caseb/caseb.txt", "anchor_text": "logs click here.", "paragraph_index": 35}, {"url": "https://colab.research.google.com/drive/1oYvkITUp4WdfAx_xYw_Otg7dJr2rc2mz", "anchor_text": "case c click here", "paragraph_index": 35}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/casec/casec.txt", "anchor_text": "logs click here.", "paragraph_index": 35}, {"url": "https://colab.research.google.com/drive/1cQ48nzeBCGm5shW634TQmi9mYLIzP4JE", "anchor_text": "case c click here", "paragraph_index": 35}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/cased/cased.txt", "anchor_text": "logs click here.", "paragraph_index": 35}, {"url": "https://colab.research.google.com/drive/1ahrQMwLMhpqQLjO7AHSL3707JdnMH-VN", "anchor_text": "case c click here", "paragraph_index": 35}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/casee/casee.txt", "anchor_text": "logs click here.", "paragraph_index": 35}, {"url": "https://jaedukseo.me/", "anchor_text": "view my website here", "paragraph_index": 37}, {"url": "https://twitter.com/JaeDukSeo", "anchor_text": "here", "paragraph_index": 38}, {"url": "https://jaedukseo.me/", "anchor_text": "my website", "paragraph_index": 38}, {"url": "https://www.youtube.com/c/JaeDukSeo", "anchor_text": "Youtube channel", "paragraph_index": 38}, {"url": "https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec", "anchor_text": "Wide Residual Networks, please click here to view the blog pos", "paragraph_index": 38}], "all_paragraphs": ["For the last two week I have been dying to implement different kinds of Recurrent Neural Networks (RNN) and finally I have the time to implement all of them. Below is the list of different RNN cases I wanted to try out.", "Case a: Vanilla Recurrent Neural Network Case b: Multi-Stream Recurrent Neural NetworkCase c: Concatenated Recurrent Neural NetworkCase d: Internal Convolutional Recurrent Neural NetworkCase e: Lag 2 Recurrent Neural Network", "Please note that all of these models are just for fun and to express my creativity. Also, the base code that I am going to use in this post is from my old post \u201cGated Recurrent Convolution NN for OCR\u201d.", "There is in total of 5 different case of RNN I wish to implement. However, in order to fully understand all of the implementations it would be a good idea to have a strong understanding of vanilla RNN (Case a is vanilla RNN so if you understand code for case a you are good to go.)", "If anyone wishes to review simple RNN please visit my old blog post \u201cOnly Numpy: Vanilla Recurrent Neural Network Deriving Back propagation Through Time Practice \u201d.", "Case a: Vanilla Recurrent Neural Network ( Results)", "Red Box \u2192 3 Convolutional LayerOrange \u2192 Global Average Pooling and SoftMaxGreen Circle \u2192 Hidden Unit at Time 0Blue Circle \u2192 Input in 4 Time StampBlack Box \u2192 Recurrent Neural Network with 4 Time Stamp", "As seen above, the base network is simple RNN combined with convolutional neural network for classification. The RNN have time stamp of 4, which means we are going to give the network 4 different kinds of input at each time stamp. And to do that I am going to add some noise to the original image.", "Blue Line \u2192 Train Cost Over TimeOrange Line \u2192 Train Accuracy Over TimeGreen Line \u2192 Test Cost Over TimeRed Line \u2192 Test Accuracy Over Time", "As seen above our base network already performs well. Now the question is how other methods performs and would it be able to regularize better than our base network.", "Case b: Multi-Stream Recurrent Neural Network (Idea / Results)", "Red Box \u2192 3 Convolutional LayerOrange \u2192 Global Average Pooling and SoftMaxGreen Circle \u2192 Hidden Unit at Time 0Blue Circle \u2192 Convolution Input Stream Yellow Circle \u2192 Fully Connected Network StreamBlack Box \u2192 Recurrent Neural Network with 4 Time Stamp", "The idea behind this RNN is simply to give different representation of data to the RNN. In our base network we have the network either the raw image or image with some noise added.", "Red Box \u2192 Additional Four CNN/FNN layers to \u2018process\u2019 the inputBlue Box \u2192 Creating Inputs at each different time stamps", "As seen below now our RNN takes in input of tensor size with [batch_size, 26, 26, 1] reducing the width and the height by 2. And I was hoping that different representation of the data would act as a regularization. (Similar to data augmentation)", "Blue Line \u2192 Train Cost Over TimeOrange Line \u2192 Train Accuracy Over TimeGreen Line \u2192 Test Cost Over TimeRed Line \u2192 Test Accuracy Over Time", "As seen above the network did pretty well, and have outperformed our base network by 1 percent on the testing images.", "Case c: Concatenated Recurrent Neural Network (Idea / Results)", "Red Box \u2192 3 Convolutional LayerOrange \u2192 Global Average Pooling and SoftMaxGreen Circle \u2192 Hidden Unit at Time 0Blue Circle \u2192 Input in 4 Time StampBlack Box \u2192 Recurrent Neural Network with 4 Time StampBlack Curved Arrow \u2192 Concatenated Input for Each Time Stamp", "This approach is very simple, the idea was that on each time stamp different features will be extracted and it might be useful for the network to have more features overtime. (For the Recurrent Layers.)", "Blue Line \u2192 Train Cost Over TimeOrange Line \u2192 Train Accuracy Over TimeGreen Line \u2192 Test Cost Over TimeRed Line \u2192 Test Accuracy Over Time", "Sadly, this was a huge failure. I guess the empty hidden values does not help (one bit) for the network to perform well.", "Case d: Internal Convolutional Recurrent Neural Network (Idea/Results)", "Red Box \u2192 3 Convolutional LayerOrange \u2192 Global Average Pooling and SoftMaxGreen Circle \u2192 Hidden Unit at Time 0Blue Circle \u2192 Input in 4 Time StampBlack Box \u2192 Recurrent Neural Network with 4 Time StampGray Arrow \u2192 Performing Internal Convolution before passing onto the next time stamp", "As seen above, this network takes in the exact same input as our base network. However this time we are going to perform additional convolution operations in the internal representation of the data.", "Right Image \u2192 Declaring 3 new convolution layerLeft Image (Red Box) \u2192 If the current internal layer is not None, we are going to perform additional convolution operation.", "I actually had no theoretical reason behind this implementation, I just wanted to see if it works LOL.", "Blue Line \u2192 Train Cost Over TimeOrange Line \u2192 Train Accuracy Over TimeGreen Line \u2192 Test Cost Over TimeRed Line \u2192 Test Accuracy Over Time", "As seen above the network did a fine job at converging, however it was not able to outperform our base network. (Sadly).", "Case e: Lag 2 Recurrent Neural Network (Idea / Results)", "Red Box \u2192 3 Convolutional LayerOrange \u2192 Global Average Pooling and SoftMaxGreen Circle \u2192 Hidden Unit at Time 0 (or Lag of 1)Blue Circle \u2192 Input in 4 Time StampBlack Box \u2192 Recurrent Neural Network with 4 Time StampPurple Circle \u2192 Hidden State Lag of 2", "In a traditional RNN setting we only rely on the most previous values to determine the current value. For a while I was thinking that there is no reason for us to limit the look back time (or lag) as 1. We can extend this idea into lag 3 or lag 4 etc. (Just for simplicity I took lag 2)", "Blue Line \u2192 Train Cost Over TimeOrange Line \u2192 Train Accuracy Over TimeGreen Line \u2192 Test Cost Over TimeRed Line \u2192 Test Accuracy Over Time", "Thankfully the network did better than the base network. (But with very small margin), however this type of network would be most suitable for time series data.", "For Google Colab, you would need a google account to view the codes, also you can\u2019t run read only scripts in Google Colab so make a copy on your play ground. Finally, I will never ask for permission to access your files on Google Drive, just FYI. Happy Coding! Also for transparency I uploaded all of the training logs on my github.", "To access the code for case a click here, for the logs click here. To access the code for case b click here, for the logs click here.To access the code for case c click here, for the logs click here.To access the code for case c click here, for the logs click here.To access the code for case c click here, for the logs click here.", "I wanted to Review RNN for quite a long time now, finally I get to do it.", "If any errors are found, please email me at jae.duk.seo@gmail.com, if you wish to see the list of all of my writing please view my website here.", "Meanwhile follow me on my twitter here, and visit my website, or my Youtube channel for more content. I also implemented Wide Residual Networks, please click here to view the blog post.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Exploring the intersection of AI, deep learning, and art. Passionate about pushing the boundaries of multi-media production and beyond. #AIArt"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff4f17189a208&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f4f17189a208--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f4f17189a208--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jdseo?source=post_page-----f4f17189a208--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jdseo?source=post_page-----f4f17189a208--------------------------------", "anchor_text": "Jae Duk Seo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F70eb2d57a447&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&user=Jae+Duk+Seo&userId=70eb2d57a447&source=post_page-70eb2d57a447----f4f17189a208---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4f17189a208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4f17189a208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://giphy.com/stickers/parley-happy-4NkrKIHNO2fLtfxuWa", "anchor_text": "website"}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "Recurrent Neural Networks"}, {"url": "https://towardsdatascience.com/nips-2017-tensorflow-gated-recurrent-convolution-neural-network-for-ocr-part-1-with-47bb2a8a7ab3", "anchor_text": "Gated Recurrent Convolution NN for OCR"}, {"url": "https://machinelearning-blog.com/2018/02/21/recurrent-neural-networks/", "anchor_text": "website"}, {"url": "https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-back-propagation-practice-math-956fbea32704", "anchor_text": "Only Numpy: Vanilla Recurrent Neural Network Deriving Back propagation Through Time Practice"}, {"url": "https://colab.research.google.com/drive/1d4cKR1VxFsxyXAck1Mk-zQGvlVuWdOEw", "anchor_text": "case a click here"}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/casea/casea.txt", "anchor_text": "logs click here."}, {"url": "https://colab.research.google.com/drive/1U4zthQ9CmcwAi_mWrKVuTPqf88R0lxZz", "anchor_text": "case b click here"}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/caseb/caseb.txt", "anchor_text": "logs click here."}, {"url": "https://colab.research.google.com/drive/1oYvkITUp4WdfAx_xYw_Otg7dJr2rc2mz", "anchor_text": "case c click here"}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/casec/casec.txt", "anchor_text": "logs click here."}, {"url": "https://colab.research.google.com/drive/1cQ48nzeBCGm5shW634TQmi9mYLIzP4JE", "anchor_text": "case c click here"}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/cased/cased.txt", "anchor_text": "logs click here."}, {"url": "https://colab.research.google.com/drive/1ahrQMwLMhpqQLjO7AHSL3707JdnMH-VN", "anchor_text": "case c click here"}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/review_RNN/casee/casee.txt", "anchor_text": "logs click here."}, {"url": "https://jaedukseo.me/", "anchor_text": "view my website here"}, {"url": "https://twitter.com/JaeDukSeo", "anchor_text": "here"}, {"url": "https://jaedukseo.me/", "anchor_text": "my website"}, {"url": "https://www.youtube.com/c/JaeDukSeo", "anchor_text": "Youtube channel"}, {"url": "https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec", "anchor_text": "Wide Residual Networks, please click here to view the blog pos"}, {"url": "https://towardsdatascience.com/nips-2017-tensorflow-gated-recurrent-convolution-neural-network-for-ocr-part-1-with-47bb2a8a7ab3", "anchor_text": "https://towardsdatascience.com/nips-2017-tensorflow-gated-recurrent-convolution-neural-network-for-ocr-part-1-with-47bb2a8a7ab3"}, {"url": "https://towardsdatascience.com/soft-sign-activation-function-with-tensorflow-manual-back-prop-with-tf-5a04f3c8e9c1", "anchor_text": "https://towardsdatascience.com/soft-sign-activation-function-with-tensorflow-manual-back-prop-with-tf-5a04f3c8e9c1"}, {"url": "https://machinelearning-blog.com/2018/02/21/recurrent-neural-networks/", "anchor_text": "https://machinelearning-blog.com/2018/02/21/recurrent-neural-networks/"}, {"url": "https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-back-propagation-practice-math-956fbea32704", "anchor_text": "https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-back-propagation-practice-math-956fbea32704"}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "https://en.wikipedia.org/wiki/Recurrent_neural_network"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f4f17189a208---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----f4f17189a208---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f4f17189a208---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/tensor?source=post_page-----f4f17189a208---------------tensor-----------------", "anchor_text": "Tensor"}, {"url": "https://medium.com/tag/python?source=post_page-----f4f17189a208---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff4f17189a208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&user=Jae+Duk+Seo&userId=70eb2d57a447&source=-----f4f17189a208---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff4f17189a208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&user=Jae+Duk+Seo&userId=70eb2d57a447&source=-----f4f17189a208---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4f17189a208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f4f17189a208--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff4f17189a208&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f4f17189a208---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f4f17189a208--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f4f17189a208--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f4f17189a208--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f4f17189a208--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f4f17189a208--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f4f17189a208--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f4f17189a208--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f4f17189a208--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jdseo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jdseo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jae Duk Seo"}, {"url": "https://medium.com/@jdseo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "5.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F70eb2d57a447&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&user=Jae+Duk+Seo&userId=70eb2d57a447&source=post_page-70eb2d57a447--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd9ea20dd433a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-stream-rnn-concat-rnn-internal-conv-rnn-lag-2-rnn-in-tensorflow-f4f17189a208&newsletterV3=70eb2d57a447&newsletterV3Id=d9ea20dd433a&user=Jae+Duk+Seo&userId=70eb2d57a447&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}