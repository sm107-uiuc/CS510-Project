{"url": "https://towardsdatascience.com/style-transfer-with-gans-on-hd-images-88e8efcf3716", "time": 1682997375.673146, "path": "towardsdatascience.com/style-transfer-with-gans-on-hd-images-88e8efcf3716/", "webpage": {"metadata": {"title": "Style Transfer with GANs on HD Images | by Marco Pasini | Towards Data Science", "h1": "Style Transfer with GANs on HD Images", "description": "A number of recent studies explored some ways and techniques to generate High Definition images (1024x1024 pixels) using GANs (Generative Adversarial Networks). It\u2019s incredibily surprising to see\u2026"}, "outgoing_paragraph_urls": [{"url": "https://colab.research.google.com", "anchor_text": "Google Colaboratory", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737", "anchor_text": "this article", "paragraph_index": 14}, {"url": "https://colab.research.google.com", "anchor_text": "Google Colaboratory", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737", "anchor_text": "here", "paragraph_index": 39}], "all_paragraphs": ["A number of recent studies explored some ways and techniques to generate High Definition images (1024x1024 pixels) using GANs (Generative Adversarial Networks). It\u2019s incredibily surprising to see super realistic, HD images of human faces, animals and other things generated by an algorithm, especially remembering the first GAN images from just a few years back. We have gone from low quality, pixelated images to close-to-reality images in no time: this is a really clear proof of how quickly research in this field advances.", "But reading those recent studies (the most relevant being the StyleGAN paper by Nvidia and the BigGAN paper by Google) I always find an aspect that manages to bring down my sense of surprise and excitement: computing power. Finding out the huge computing capabilities used to pull off those images makes me realise that between me and those results lays an invalicable obstacle. This thought alone makes me feel that the whole new technology explored in the studies feels to me as very distant, and therefore less surprising.", "This is why in this article I would like to explore how to make GANs and HD images work together without the need of highly expensive hardware, opening new opportunities for people who don\u2019t necessarily have access to high level GPUs. Everything explained here can be achieved using the freely available Google Colaboratory platform, which offers a free GPU for all your machine/deep learning projects.", "We will try to perform a Style Transfer between 2 domains of High Definition Images, using a special but simple GAN architecture to perform our task. More specifically, we are going to apply the painting style of Van Gogh to high resolution images of landscapes. It\u2019s fair to say that Style Transfer has been a trendy subject in Computer Vision for the last few years; the original paper that started the trend is \u201cA Neural Algorithm of Artistic Style\u201d (Gatys et al.), which used a Content and Style loss on a pretrained convolutional network to perform the task. While this method can work on HD images, it can only use a single image (let\u2019s say \u2018Starry Night\u2019) as the representation of the Style of the painter, which isn\u2019t what we want.", "A GAN on the other hand generally needs a domain of images to train on and is consequently able in our case to capture the style of the painter in its entirety (the CycleGAN paper shows interesting results on style transfer).", "However, training GANs is extremely computationally expensive: the generation of High Resolution images is only possible with very high end hardware and long training times. I hope the tricks and techniques explained in this article will be able to help you in your HD image generation adventures.", "What we are going to try to achieve is called image-to-image translation (from domain A to domain B). There are different ways and network architectures to achieve it: the most famous may be CycleGAN, but a number of other papers on the same subject exists as well.", "For my experiments I used a custom architecture that consists in a Siamese Network as Discriminator and a special (but super easy) loss function. I chose this method because it doesn\u2019t rely on per-pixel differences in any of the losses: this simply means that the network doesn\u2019t follow any geometric constraints on the generated image and is thus able to create more convincing image translations (this is valid in our case).", "A deep and thorough explanation of this kind of architecture and how it works can be found in this other article I wrote here.", "Here\u2019s a brief introduction to the Siamese GAN architecture.", "It is made of a single generator (G) and discriminator (D): G takes an image as input and outputs the translated image; D takes an image as input and outputs a latent vector.", "The Siamese Discriminator has 2 objectives: telling G how to generate more realistic images and maintaining in those fake images a correlation (same \u2018content\u2019) with the original ones.", "Calling A1,A2 and B1,B2 random images from domains A and B respectively, X a random image, and G(X) the images generated by the Generator, the Discriminator must encode images into vectors D(X) such as:", "1. D(B1) must be close (euclidean distance) to a fixed point (the origin for example), while D(G(A1)) must be far from the same point. Consequently, vectors closer to the fixed points represent more realistic images. The Generator on the other hand tries to minimize the distance from D(G(A1)) to the fixed point, in classic adversarial fashion.", "With these 2 constraints (losses) in place, the first relying on Magnitude of vectors while the second relying on Angle between vectors, our full objective is satisfied and we can achieve our end goal of image to image translation from domain A to domain B. I really suggest you read this article where I give a more comprehensive and deep explanation of this architecture, while showing illustrations and examples.", "Now that we have the architecture locked in, let\u2019s explore how and what to feed to the network in order to reach HD image generation.", "We need 2 image datasets of High Definition images: in our case we are going to use a dataset of landscapes (domain A) and a dataset of Van Gogh paintings (domain B). Bear in mind that the bigger the images you choose to work with, the longer it will take to preprocess (cutting, resizing) those images (it will not increase the time exclusively spent on training the network though!).", "Now we need to choose the size of the images that will be fed to the Generator: obviously we can\u2019t use the size of the whole HD images from the datasets, otherwise training times and network sizes would be huge and no problem would be solved. Thus we choose a small enough size SxS (64x64 pixels for example) so that training times can be kept under control and everything stays computationally feasible even for mid-end GPUs (like the ones freely available on Google Colaboratory).", "Consequently, as you may have thought, the images, before being fed to the Generator, have to be cut (or cropped) into smaller SxS images. Thus, after reading the image and turning it into a tensor, we perform a random SxS crop on the image, adding it to a batch and feeding the batch to the Network. It sounds extremely easy and it really is!", "Now, let\u2019s say we train a GAN using this method until every small SxS crop gets translated to Van Gogh style by the Generator in a way that satisfies us: how can we now translate an entire HD image from domain A to domain B?", "Again, extremely simple: the image is divided into small SxS pieces (if size of HD image is BxB, then we will have (B//S)x(B//S) small SxS images), each SxS image gets translated by the Generator, and finally everything is joined back together.", "However, if we try and train a GAN using this simple idea of extracting smaller images out of bigger ones, during test time we will soon notice quite an annoying problem: the small images extracted by the big image we want to translate, when converted by the Generator to domain B, do not blend organically together. The edges of each SxS image are clearly visible in the final composition, ruining the \u2018magic\u2019 of the otherwise successful Style Transfer. This is a relatively tiny problem that can be quite annoying: even using pixel-based methods such as CycleGAN the same obstacle still appears.", "The solution that I used is easy to understand and quite elegant in my opinion, and it represents the core idea that I hope you will remember (and maybe use) from this article.", "Firstly, we need to revisit our data pipeline: while before we directly cut SxS crops from the BxB HD image, we now have to get 2Sx2S crops (if S=64, then we need 128x128 crops). Then, after defining our Generator, we create a new model, called Combo, that does the following operations:", "1. Take batch of 2Sx2S images (from domain A) as input (INP);", "2. Cut each image in INP into 4 SxS images (INPCUT);", "3. Feed each of the 4 SxS images of INPCUT to the Generator and obtain OUTCUT (same exact shape as INPCUT, but with translated version of each SxS image);", "4. Join each group of 4 SxS images in OUTCUT and get OUT (same exact shape as INP, but with translated version of each 2Sx2S image);", "The output of Combo is then passed as input to the Discriminator, which now accepts inputs of double the size than previously (2Sx2S). This little tweak doesn\u2019t require much more computation time and can effectively solve our previous problem. How?", "The Generator is now forced to generate images that are coherent regarding edges and colors, because the Discriminator will not classify incoherent joined images as realistic and thus will notify the Generator on where it can improve. Diving a bit deeper, the Generator is forced to learn how to generate realistic edges on each of the 4 edges of the SxS image: in the final 2x2 joined image each of the 4 edges is in contact with another one, and even one badly-generated edge would ruin the 2x2 images realism.", "To make sure everything up to here is clear and understood, let\u2019s sum up how the whole network works.", "The goal is to apply the style of B to images in A. Images of size 2Sx2S are cut from High Resolution images in both domains A and B. Images from A are the input of Combo; this model cuts the images in 4 smaller ones (SxS), then uses the Generator G to convert them, and finally joins them together. We call these fake images AB.", "Now let\u2019s focus on the Siamese Discriminator D: the size of its input is double the size of the Generator input (2Sx2S), while the output is a vector of size LENVEC.", "D encodes images into vectors D(X) such as:", "1. D(B) must be close to the origin (vector of zeros of size VECLEN ):", "LossD1 is the square of the Euclidean distance of D(B) from the origin point, so Eucl(D(A))\u00b2;", "2. D(AB) must be far from the origin:", "On the other hand, the Generator must generate (joined) images AB such as:", "1. D(AB) must be close to the origin:", "A deeper explanation on how each one of these losses works can be found in my article here, where I explain in detail how a Siamese Discriminator works (I think it is worth a read!).", "Following this method, the Generator is able to learn how to generate small stylized images that can be joined together without any edge discrepancy. Thus, when translating a whole HD image, after cutting it into separate smaller SxS images and feeding them to the Generator, we are able to join them together into a final, visually pleasing and coherent HD image.", "The technique explained in this article still presents some problems that we need to address.", "If extremely High Definition images are chosen, the smaller crops used to train the network may not contain any relevant information (they might be just solid colors, similar to single pixels) and thus the training may not be successful: both the Generator and Discriminator need some kind of information to process (the Discriminator must encode images based on their \u2018content\u2019) and may face some problems if that information is not available.", "Even if the training ends successfully, when joining all the different crops of an image with very high resolution, the stylistic contribution of each small translated image is not enough for the whole HD image, which often appears similar to the original one with only a shift in its colors.", "In my experiments I find that, for the training phase, using a resized (lower resolution) version of the HD dataset, while switching to the whole HD images when translating, certainly helps regarding the first problem.", "This technique leaves a lot to be explored: other kinds of image translations different from a traditional Style Transfer can be possible. It is important to remember that the Generator in the presented case has no idea about the context of the whole HD image and only \u2018sees\u2019 the lower resolution crops. Thus, giving the Generator some context (maybe in form of an encoded \u2018context vector\u2019?) about the whole images can surely extend the range of applications of the technique, opening possibilities for far more complex \u2018context aware\u2019 kinds of HD image translations (objects to other objects, faces, animals).", "So, as you may have understood, the possibilities are endless and yet to be uncovered!", "I would love to sincerely thank you for the attention you donated to this article, it is greatly appreciated, and I hope you walk away with something new.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Studying Energy Engineering. Artificial Intelligence is pretty cool too."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F88e8efcf3716&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@marco.pasini?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marco.pasini?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "Marco Pasini"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c9bed459710&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&user=Marco+Pasini&userId=5c9bed459710&source=post_page-5c9bed459710----88e8efcf3716---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F88e8efcf3716&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F88e8efcf3716&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://colab.research.google.com", "anchor_text": "Google Colaboratory"}, {"url": "https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737", "anchor_text": "this article"}, {"url": "https://colab.research.google.com", "anchor_text": "Google Colaboratory"}, {"url": "https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----88e8efcf3716---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----88e8efcf3716---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----88e8efcf3716---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/art?source=post_page-----88e8efcf3716---------------art-----------------", "anchor_text": "Art"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----88e8efcf3716---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F88e8efcf3716&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&user=Marco+Pasini&userId=5c9bed459710&source=-----88e8efcf3716---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F88e8efcf3716&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&user=Marco+Pasini&userId=5c9bed459710&source=-----88e8efcf3716---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F88e8efcf3716&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F88e8efcf3716&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----88e8efcf3716---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----88e8efcf3716--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----88e8efcf3716--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----88e8efcf3716--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marco.pasini?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marco.pasini?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marco Pasini"}, {"url": "https://medium.com/@marco.pasini/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "342 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c9bed459710&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&user=Marco+Pasini&userId=5c9bed459710&source=post_page-5c9bed459710--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4a9556d568a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstyle-transfer-with-gans-on-hd-images-88e8efcf3716&newsletterV3=5c9bed459710&newsletterV3Id=4a9556d568a3&user=Marco+Pasini&userId=5c9bed459710&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}