{"url": "https://towardsdatascience.com/convolution-layers-e2e5ba340565", "time": 1683011868.1230562, "path": "towardsdatascience.com/convolution-layers-e2e5ba340565/", "webpage": {"metadata": {"title": "Overview of Advanced Convolution layers | by Jehill Parikh | Towards Data Science", "h1": "Overview of Advanced Convolution layers", "description": "Convolution layers are fundamental building blocks of computer vision architectures. Neural networks employing convolutions layers are employed in wide-ranging applications in Segmentation\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@prvnk10/the-convolution-operation-48d72a382f5a", "anchor_text": "post", "paragraph_index": 6}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "team", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "post", "paragraph_index": 11}, {"url": "https://theaisummer.com/skip-connections/", "anchor_text": "blog", "paragraph_index": 11}, {"url": "https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8", "anchor_text": "Thom Lane", "paragraph_index": 13}, {"url": "https://github.com/JP-MRPhys/fastMRI-GAN/blob/master/model/layers/PixelCNN2.py", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://arxiv.org/pdf/1606.05328.pdf", "anchor_text": "Ord et al, 2016", "paragraph_index": 19}, {"url": "https://github.com/JP-MRPhys/fastMRI-GAN/blob/master/model/layers/PixelCNN2.py", "anchor_text": "here", "paragraph_index": 20}, {"url": "https://deepgenerativemodels.github.io/notes/flow/", "anchor_text": "here", "paragraph_index": 24}, {"url": "https://en.wikipedia.org/wiki/Change_of_variables", "anchor_text": "change of variable formulation", "paragraph_index": 26}, {"url": "https://www.youtube.com/watch?v=JBb5sSC0JoY&t=5604s", "anchor_text": "lecture", "paragraph_index": 27}, {"url": "https://en.wikipedia.org/wiki/LU_decomposition", "anchor_text": "LU decomposition", "paragraph_index": 29}, {"url": "https://arxiv.org/pdf/1807.03039.pdf", "anchor_text": "paper", "paragraph_index": 29}, {"url": "https://ehoogeboom.github.io/authors/emiel-hoogeboom/", "anchor_text": "Hoogeboom", "paragraph_index": 30}, {"url": "https://deepgenerativemodels.github.io/assets/slides/cs236_lecture7.pdf", "anchor_text": "7", "paragraph_index": 30}, {"url": "https://deepgenerativemodels.github.io/assets/slides/cs236_lecture8.pdf", "anchor_text": "8", "paragraph_index": 30}, {"url": "https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html", "anchor_text": "Lilian Weng.", "paragraph_index": 30}], "all_paragraphs": ["Convolution layers are fundamental building blocks of computer vision architectures. Neural networks employing convolutions layers are employed in wide-ranging applications in Segmentation, Reconstruction, Scene Understanding, Synthesis, Object detection and more", "The goal of this post is to provide a summary and overview of advanced convolution layers and techniques which have emerged in the recent literature. We start with basics of convolution, for completeness, however, more rigorous explanations can be obtained from references within.", "Convolution: Mathematically speak convolution is an \u201coperation\u201d performed to combine two signals into one, below is an illustration from wikipedia which highlights convolution between two functions/signals f(t) and f(t-z). Convolution to obtain the (f*g)(t)", "The main convolution operations in deep learning are", "Pictorially we convolve \u201cslide\u201d a kernel (green size) over an image (blue) and learn weights for these kernels. This kernel\u2019s spatial extent (F) is 3 and filters i.e. depth of the kernel is 1, therefore number of weights are 3*3*1=9. We can skip pixels by \u201cstride\u201d and pad regions our original image, here the stride is 0", "Convolution block of accepts a image or feature map of size W1\u00d7H1\u00d7D1 and kernel of size (F*F*K) and typical requires four hyper-parameters:", "These there operations combined provide a final output feature map of W2*H2*D2 for details of working see post", "With convolution, two additional operations are employed", "Spatial extent of filter (F) is the main contributor of the number of weights for each kernel. As explained in CS231n lecture notes with F=3 and F=7 there is a three fold increase in number of weights. Typically, a full deep-net consists of multiples layers of CONV + RELU + POOL operations to extract features. Thus generally F=3 is employed as a trade off to learn features vectors at each layer without increasing cost of computational cost.", "Please see the computation considerations section on C231n lecture notes as additional reference", "Key architectures for object classification tasks which use these three layers are well summarised in the CS231n notes, they are LeNet, AlexNet, ZFNet, GoogLeNet, VGGnet, Resnet. These were developed towards winning the Imagenet challenge. Over the years, there was a trend for larger/deeper the network deeper to improve performance.", "These were introduced in 2015 by a Microsoft team to maintain accuracy in deeper networks as part of the ImageNet challenge. A single network skipped connection is shown below, it aims to learn Residual R(x). In deeper networks this allows to learning \u201cresidual information\u201d at each layer. Hence the name residual connection. This technique has experimentally has proven to increase accuracy in deeper networks. Implementing a residual/skipped connection is very straight forward, as shown below. Skipping the connection also allows us to over come to issue of vanishing gradients, in deep layers, and speeds up training. This experimental results has been widely adopted across a range of computer vision algorithms since original introduction. Variants of the resnets are highlighted in this post, and additional detail and illustrations please see the blog.", "Above layers are critical components of neural networks employed for computer vision task, and find application in wide range of domains and different architecture. Now we turn to more specialised layers.", "Convolution operation with stride (\u22652) and/or padding reduces the dimension of the resultant feature map. Convolution transpose is the reverse process employed to learn kernels to, up-sample features maps to larger dimensions. With stride >1 being typically employed to upsample the image, this process is well illustrated in a post by Thom Lane and below, where are 2*2 input with padding and strided convolution with a 3*3 kernel leads to a 5*5 feature map", "Strided convolutions find wide ranging application in different areas", "Implementation: All major DL frameworks have strided convolution, then need to employed with proper initialisation i.e. random or Xavier initialisation.", "Masked and Gated convolution started gaining popularity around 2016, in there seminal work Aaron van den Oord, et al introduced Pixel RNN and Pixel-CNN. These are autoregressive approaches to sample pixel from a probability distribution conditional on the previous pixels.", "Since each pixel is generated via conditioning on previous pixels, to ensure conditioning on pixel from the left and top rows mask are employed while applying convolution operations. Two types of masks are Mask: A, used in first channel and prior pixels. Mask: B, mask B all channels and prior pixels, following layers, both available here", "Notes: Inputs must be binarized: 2\u2078 e.g. 256 bits of colour, or each sample is between 0\u2013256 in a RGB image", "Masked gated convolutions were introduced to avoid blind-spots in masked convolutions. Ord et al, 2016 proposed to isolate horizontal and vertical stacks i.e gates with 1*1 convolution, with residual connections in the horizontal stacks, as shown below. Residual connections in vertical stacks didn\u2019t offer additional performance improvement, therefore were not implemented.", "Implementation of masked gate convolutions is available here.", "Applications: Mainly employed in decoders for e.g. in VAE frameworks for prior sampling to avoid issues with training GAN\u2019s such as mode collapse and generate high resolution images.", "Invertible convolutions, are based on normalising flows, are currently applied in generative models to learn underlying probability distribution p(x) of image in computer vision. The maintain motivation is to provide a better loss function i.e. negative log likelihood.", "The two most common generative frameworks modelling suffer from approximation inference time issues, i.e. loss function function for VAE (evidence based lower bound i.e. ELBO) is an approximation is lower bound on log-likelihood, therefore inference/reconstruction is approximation. Adversarial loss employed in GAN\u2019s is a \u201csearch\u201d based approach and suffer issues with sampling diversity and are hard to train i.e. mode collapse.", "Mathematical preliminaries of Normalising flows are best outlined in the Stanford class notes here, we use there summary.", "In normalising flow, the mapping between random variable Z and X, given by, function f, paramaterized \u03b8, which is deterministic and invertible such that", "Then probability distributions of X and Z can then be obtained using the change of variable formulation, in this case the two probability distributions are related via determinant term. Loosely speaking the determinant is the \u201cscaling\u201d or normalising constant.", "Note: function can be a single function, or a series of sequential function, transforming generally, transforming from simple e.g. latent vectors (Z) to complex distributions e.g. (X) images. This formulation allows to us \u201cexactly\u201d between transform between two distribution, and thus can derive the negative log likehood loss function, see the lecture for derivation.", "Normalising flow and neural networks: Works of Dinh et al, 2014 (NICE) and Dinh et al, 2017 (Real-NVP), started providing neural network architecture, to employ normalising flow for the density estimation. Glow from Kingma et al, is the current (2018) state of art, which builds on these works, In which which introduced 1*1 invertible convolution, to synthesis high resolution images.", "The key novelty was to reduce the computation cost of the determinant term for the weight matrix, for 1*1 learning invertible convolutions. This was achieved with LU decomposition with permutation, i.e. PLU decomposition, for the weight matrix. Random permutations were employed to maintain \u201cflow\u201d at each iteration. The mathematical details are covered in section 3.2, of the paper they also provide an implementation using numpy and tensorflow, for easier interrogation.", "These were further generalised to N*N convolutions by Hoogeboom, et al, please see the blog post for additional details and implementations (with optimisation). Our aim was just to highlight these models, for more comprehensive details we refer the reader to, CS236 lectures 7 and 8 and Glow paper and blog post by Lilian Weng.", "Application area: Image synthesis and generative modelling", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Neuroscientist | ML Practitioner | Physicist"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe2e5ba340565&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jehillparikh.medium.com/?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "Jehill Parikh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc972081b627e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&user=Jehill+Parikh&userId=c972081b627e&source=post_page-c972081b627e----e2e5ba340565---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2e5ba340565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2e5ba340565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1", "anchor_text": "Image source"}, {"url": "https://medium.com/@prvnk10/the-convolution-operation-48d72a382f5a", "anchor_text": "post"}, {"url": "https://www.coursera.org/lecture/neural-networks-deep-learning/why-do-you-need-non-linear-activation-functions-OASKH", "anchor_text": "Non-linearity"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "team"}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "post"}, {"url": "https://theaisummer.com/skip-connections/", "anchor_text": "blog"}, {"url": "https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8", "anchor_text": "Thom Lane"}, {"url": "https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8", "anchor_text": "Image credit"}, {"url": "https://arxiv.org/pdf/1601.06759.pdf", "anchor_text": "Pixel RNN"}, {"url": "https://github.com/JP-MRPhys/fastMRI-GAN/blob/master/model/layers/PixelCNN2.py", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1601.06759.pdf", "anchor_text": "Image from Pixel RNN"}, {"url": "https://arxiv.org/pdf/1606.05328.pdf", "anchor_text": "Ord et al, 2016"}, {"url": "https://arxiv.org/pdf/1606.05328.pdf", "anchor_text": "Gate Convolution block introduced by van den Oord et al 2016"}, {"url": "https://github.com/JP-MRPhys/fastMRI-GAN/blob/master/model/layers/PixelCNN2.py", "anchor_text": "here"}, {"url": "https://openreview.net/pdf?id=BJrFC6ceg", "anchor_text": "PixelCNN++"}, {"url": "https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/PixelCNN", "anchor_text": "Tensorflow Probability"}, {"url": "https://github.com/JP-MRPhys/fastMRI-GAN/blob/master/model/VAE-PixelCNN.py", "anchor_text": "here"}, {"url": "https://deepgenerativemodels.github.io/notes/flow/", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Change_of_variables", "anchor_text": "change of variable formulation"}, {"url": "https://www.youtube.com/watch?v=JBb5sSC0JoY&t=5604s", "anchor_text": "lecture"}, {"url": "https://arxiv.org/pdf/1807.03039.pdf", "anchor_text": "ref"}, {"url": "https://en.wikipedia.org/wiki/LU_decomposition", "anchor_text": "LU decomposition"}, {"url": "https://arxiv.org/pdf/1807.03039.pdf", "anchor_text": "paper"}, {"url": "https://ehoogeboom.github.io/authors/emiel-hoogeboom/", "anchor_text": "Hoogeboom"}, {"url": "https://deepgenerativemodels.github.io/assets/slides/cs236_lecture7.pdf", "anchor_text": "7"}, {"url": "https://deepgenerativemodels.github.io/assets/slides/cs236_lecture8.pdf", "anchor_text": "8"}, {"url": "https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html", "anchor_text": "Lilian Weng."}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----e2e5ba340565---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----e2e5ba340565---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e2e5ba340565---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e2e5ba340565---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/convolution-neural-net?source=post_page-----e2e5ba340565---------------convolution_neural_net-----------------", "anchor_text": "Convolution Neural Net"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe2e5ba340565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&user=Jehill+Parikh&userId=c972081b627e&source=-----e2e5ba340565---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe2e5ba340565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&user=Jehill+Parikh&userId=c972081b627e&source=-----e2e5ba340565---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2e5ba340565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe2e5ba340565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e2e5ba340565---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e2e5ba340565--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e2e5ba340565--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e2e5ba340565--------------------------------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "150 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc972081b627e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&user=Jehill+Parikh&userId=c972081b627e&source=post_page-c972081b627e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3d9061f946c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolution-layers-e2e5ba340565&newsletterV3=c972081b627e&newsletterV3Id=3d9061f946c9&user=Jehill+Parikh&userId=c972081b627e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}