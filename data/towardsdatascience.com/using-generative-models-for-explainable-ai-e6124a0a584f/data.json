{"url": "https://towardsdatascience.com/using-generative-models-for-explainable-ai-e6124a0a584f", "time": 1683016689.9113212, "path": "towardsdatascience.com/using-generative-models-for-explainable-ai-e6124a0a584f/", "webpage": {"metadata": {"title": "Using generative models for explainable AI | by Jeremie Harris | Towards Data Science", "h1": "Using generative models for explainable AI", "description": "Editor\u2019s note: This episode is part of our podcast series on emerging problems in data science and machine learning, hosted by Jeremie Harris. Apart from hosting the podcast, Jeremie helps run a data\u2026"}, "outgoing_paragraph_urls": [{"url": "http://sharpestminds.com", "anchor_text": "SharpestMinds", "paragraph_index": 0}, {"url": "https://twitter.com/DavidDuvenaud", "anchor_text": "follow David on Twitter here", "paragraph_index": 7}, {"url": "https://twitter.com/jeremiecharris", "anchor_text": "follow me on Twitter here", "paragraph_index": 7}, {"url": "http://shorturl.at/jtMN0", "anchor_text": "shorturl.at/jtMN0", "paragraph_index": 90}], "all_paragraphs": ["Editor\u2019s note: This episode is part of our podcast series on emerging problems in data science and machine learning, hosted by Jeremie Harris. Apart from hosting the podcast, Jeremie helps run a data science mentorship startup called SharpestMinds. You can listen to the podcast below:", "In the early 1900s, all of our predictions were the direct product of human brains. Scientists, analysts, climatologists, mathematicians, bankers, lawyers and politicians did their best to anticipate future events, and plan accordingly.", "Take physics, for example, where every task we think of as part of the learning process, from data collection to cleaning to feature selection to modeling, all had to happen inside a physicist\u2019s head. When Einstein introduced gravitational fields, what he was really doing was proposing a new feature to be added to our model of the universe. And the gravitational field equations that he put forward at the same time were an update to that very model.", "Einstein didn\u2019t come up with his new model (or \u201ctheory\u201d as physicists call it) of gravity by running model.fit() in a jupyter notebook. In fact, he never outsourced any of the computations that were needed to develop it to machines.", "Today, that\u2019s somewhat unusual, and most of the predictions that the world runs on are generated in part by computers. But only in part \u2014 until we have fully general artificial intelligence, machine learning will always be a mix of two things: first, the constraints that human developers impose on their models, and second, the calculations that go into optimizing those models, which we outsource to machines.", "The human touch is still a necessary and ubiquitous component of every machine learning pipeline, but it\u2019s ultimately limiting: the more of the learning pipeline that can be outsourced to machines, the more we can take advantage of computers\u2019 ability to learn faster and from far more data than human beings. But designing algorithms that are flexible enough to do that requires serious outside-of-the-box thinking \u2014 exactly the kind of thinking that University of Toronto professor and researcher David Duvenaud specializes in. I asked David to join me for the latest episode of the podcast to talk about his research on more flexible and robust machine learning strategies.", "Here were some of my favourite take-homes.", "You can follow David on Twitter here, and you can follow me on Twitter here.", "Jeremie (00:00):Hello, and welcome to another episode of the Towards Data Science podcast. My name is Jeremie and I\u2019m on the team over at the SharpestMinds data science mentorship program. Now, in the early 1900s a lot of our predictions were the direct product of the human brain. Scientists, analysts, climatologists, mathematicians, bankers, lawyers, politicians, they all did their best to anticipate future events and plan accordingly. To take just one example, think of physics, where every single task we currently think of as being part of the learning process from data collection to data cleaning, feature selection, modeling, all that stuff.", "Jeremie (00:32):It all happens inside a physicists head. So when Einstein, for example, introduced gravitational fields, what he was really doing was proposing a new feature to be added to our model of the universe, and the gravitational field equations that he put forward at the same time were an update to the very model that those features would then be used in. Einstein didn\u2019t come up with this model by running model.fit in a Jupyter notebook. He never outsourced any of the computations that he needed to develop any of his algorithms, any of his laws of physics in other words, to machines. Now today, that\u2019s actually somewhat unusual. Most of the predictions that the world runs on are generated in part by computers, but only in part.", "Jeremie (01:09):Until we have fully general artificial intelligence, machine learning is always going to be a mix of two things. First, the constraints that human developers impose on their models. And second, the calculations that go into optimizing those models, which we can outsource to machines. Now, the human touch is still a necessary and ubiquitous component of every machine learning pipeline, but it\u2019s ultimately limiting. The more of the machine learning pipeline that can be outsourced to machines, the more we can take advantage of computer\u2019s ability to learn faster and from far more data than human beings.", "Jeremie (01:39):But designing algorithms that are flexible enough to do that requires some serious out of the box thinking. And that\u2019s exactly the kind of thinking that University of Toronto professor and researcher David Duvenaud specializes in. So I\u2019ve got David Duvenaud joining me for today\u2019s episode. I\u2019m really excited. We\u2019re going to be talking about everything from machine learning philosophy to generative models and explainable AI. So I\u2019m really looking forward to diving into this one. David, thanks so much for joining us for the podcast.", "Jeremie (02:04):Well, really happy to have you here. We had you on the podcast before actually, and I think you\u2019re our first returning guest, if I\u2019m not wrong. I definitely recommend that folks who are tuning in for this one check out that episode because we covered a lot of interesting topics. We covered the Frequentist versus Bayesian age-old debate, among other things. But just by way of background, for people who haven\u2019t heard that episode before, of course you\u2019re a machine learning prof at the university of Toronto, you did your postdoc at Harvard.", "Jeremie (02:30):You spent time working at Google and you even had your own consulting firm in [inaudible 00:02:33]. There are a couple of topics that we really wanted to hit today that we didn\u2019t get the chance to cover on our last podcast. And I\u2019d like to start with one that\u2019s maybe a bit more of the cutting edge of things. And that\u2019s this idea of automatic differentiation, some of the activity we\u2019re seeing with programming languages and deep learning. Maybe we can start with the basics here, so what is auto differentiation?", "David Duvenaud (02:56):Oh sure. So automatic differentiation just refers to the process by which you write down a function and the machine computes another function that gives you it\u2019s a derivative, its rate of change or its output with respect to its input.", "Jeremie (03:11):So if we contrast that, for example, with back propagation, this would be just a more general kind of back propagation? Or back propagation is a special case?", "David Duvenaud (03:19):Oh, that\u2019s a great question. I think back propagation hasn\u2019t been defined in most discussions, but the general consensus among auto diff people is to\u2026 Or the way they usually frame it is that back propagation refers to a particular way of doing automatic differentiation, and specifically it\u2019s called reverse mode automatic differentiation. And it\u2019s much more time efficient for large models than forward mode differentiation.", "Jeremie (03:45):So it\u2019s a subclass essentially then of automatic differentiation. Is that sort of fair to say that?", "David Duvenaud (03:51):Yeah. Well the problem is that the original session of back propagation was as an entire learning algorithm, and the papers from [inaudible 00:03:58] were saying, how do we update waits? And today we kind of separate these two things that we say, a grading based learning algorithm, number one computes gradients. And then number two, feeds that to an optimizer that decides how to change the waits. So this is part of the reason for the confusion is that back propagation can refer to the entire learning algorithm or it can refer to just the part that confused the gradients.", "Jeremie (04:22):Okay. So the wait update is kind of the separate ingredient. It\u2019s what you do with the gradients afterwards that makes it back propagation?", "David Duvenaud (04:30):Exactly. And you don\u2019t have to move in the direction of the gradient. You can rescale it. And for instance, like the popular atom optimizer says let\u2019s scale the direction we move in by the variance of the gradients.", "Jeremie (04:40):Great. With that background, I think that\u2019s really useful. Obviously automatic differentiation has immediate applications in machine learning, but one of the things that I think you\u2019ve talked about a bit and we were discussing just before we started the podcast here was this idea that different programming languages make automatic differentiation a more natural fit or a less natural fit. And that can sort of bias the way that we ended up using them, and in turn the innovations that we come up with on the deep learning side. Do you mind sort of exploring that topic a little bit?", "David Duvenaud (05:10):Sure. So for most of its history, machine learning as a field was kind of limited by the fact that most scalable learning algorithms require gradients and most gradients were derived by hand. And so for instance, when I was a PhD student in Cambridge, the guy who sat next to me, Andrew McCutchen, spent at least half of his time during his PhD I\u2019d say working out and coding up gradients for [inaudible 00:05:34] processes. And basically for every possible quantity you might want to optimize, he would write down the gradient of the quantity with respect to some aspect of the model.", "David Duvenaud (05:44):And there was maybe 20 or 30 of these in each one was a mathematical puzzle that then you had to worry about how to [inaudible 00:05:51] efficiently and then check that it was correct. Or for instance, major machine learning packages at the time we\u2019re just writing, filled with code for custom gradients. And actually I was just talking to Jeff Hinton the other day, and he was saying that this used to be kind of almost a good thing in that it forced people to keep their models simple because if they wrote a complicated model, you\u2019d have to break\u2026 But it also massively slows down the pace of experimentation.", "David Duvenaud (06:11):And it also stops you from being able to automatically explore a model space. So, I mean, it\u2019s kind of cruel to think about how this poor guy has spent so much time creating gradients. And in fact I spend a lot of time on this, but basically everyone did. And it\u2019s like thinking of the poor kid mining coal by hand or whatever, and then someone invents a machine to do it and it\u2019s like, it was never really necessary. We just hadn\u2019t built the technology yet, and now it\u2019s inhumane. It\u2019s like when we used to have humans computers, it\u2019s just not a good use of human intellect.", "David Duvenaud (06:41):And the crazy thing though is that we were working in that lab and it wasn\u2019t as if automatic compution Hadn\u2019t been already invented 30 or 40 years ago. So there was in the physical sciences, like in Fortran, there exists these tools. They could automatically differentiate pretty complicated Fortran code, and by doing my source to source transformation, they basically would slip in the source code and reverse all the loops and do all the transformations automatically, and give you something that efficiently computed your gradient, a new code that would officially compute your gradients. And they were pretty sophisticated.", "David Duvenaud (07:12):Yeah. I mean, the thing is that the\u2026 I think the software ecosystem was not nearly as developed. Some of them were closed source. Some of them were pretty fiddly. And the hard thing is that most of these systems were somewhat limited in the types of code that they could transform. So for instance, if you have a complicated if statements, or sometimes you can end up with loop conditions or, basically you would have to restrict yourself to a sort of simpler version of the language that you were writing in. The point is that these tools and the math behind these were mostly, entirely worked out pretty early on. And then we kind of went through a little dark ages at the beginning of the field of machine learning back when everyone was MATLAB, and then again, when everyone started using GPU\u2019s, when we didn\u2019t have good auto diff tools.", "Jeremie (07:55):So the libraries, the languages, the tooling, that we use really serve to bias us in specific directions when it comes to which algorithms we end up developing, which strategies we explore. This is potentially, I guess, creating vacuums in various places where ideas that should have been explored by now really happened.", "David Duvenaud (08:14):Yeah. I\u2019ll say that people made a huge\u2026 So when the initial auto diff frameworks came to Michigan, like Theano was a big one, it was relatively straightforward to train big classifiers with them. Things that had a very simple structure. Adding loops was kind of a little tricky, but that was added for [inaudible 00:08:32]. And then pretty soon researchers started to realize that if they want to do something a little bit off piece, a little bit out there, they would almost always end up fighting their tools. In fact, me and a few people in, let\u2019s say 2015 to even 2018, had the big advantage in terms of being able to do research in that there was this nice package that was mainly written by Dougal Maclaurin and Matthew Johnson.", "David Duvenaud (09:02):And I helped sort of write some of the rules for it, but AutoCAD was the name of a package. It actually was born in the ashes of a much worse, or rather more naively architected, system that had been initially started by Ryan Adams. And at the time, this was back when Theano was the king, and so it was already a step up, this patch that no one uses anymore. And it\u2019s how we all learned auto diff is by, or all the algorithms, was by working on Ryan\u2019s package when we were at Harvard in the HIPs lab.", "Jeremie (09:35):First off, are analogous packages necessary in, say, PyTorch today? Or are there packages for it that get explored? And then what are the use cases where automatic differentiation really helps? What are some of the significant areas that that\u2019s opened up?", "David Duvenaud (09:50):Yeah. So maybe I should give some examples. First of all, I want to say that the origin of auto\u2026 So, it\u2019s benefits [inaudible 00:09:57] Dougal Maclaurin read The Structure and Interpretation of Computer Programs, which is this Seminole texts in computer science that basically outlines the case for functional programming and sort of lists languages, and has this very purist style. And I remember Dougal saying to me, just sort of sitting on the couch, thinking, he\u2019s like, \u201cDavid, everything is a function. Lists are functions, tables are functions.\u201d And he realized that he could rewrite our sort of clunky auto diff system that had been a source of, I don\u2019t know, we were taking it as limitations already.", "David Duvenaud (10:35):He realized that he could rewrite the whole thing to be much simpler and also crucially composable with itself so that you could take the gradient of the gradient. And that would just be as part of taking the gradient of sign or co-sign. And so he sat down and wrote this whole thing in two weeks, and got it running, and dealt with a lot of like minor social problems. Suddenly, we had a much more powerful tool than the norm was. And again, equally powerful tools I think had been written for other languages already, but in Python there was no nice way to do sort of this higher order auto diff.", "David Duvenaud (11:18):And so this immediately sort of freed our minds to say, \u201cWait, we can just take the gradient of anything we can write, pretty much.\u201d And one of the first things we did was Dougal started saying, \u201cOh, well, what if\u2026\u201d We were talking about taking gradients of the validation loss with respect to the parameters of our model for kernel density estimation or something like that. And Dougal said, \u201cWell, why don\u2019t we just take the gradient of the validation loss with respect to our learning hyper-parameters, through training an entire deep neural network.\u201d", "David Duvenaud (11:50):Right, exactly. That\u2019s what we would call meta-learning today. And [inaudible 00:11:56] proposed doing things like this a long time ago as well. And I guess [inaudible 00:12:01] because he also called it, I think, meta-learning at the time. But I think people hadn\u2019t considered learning through the training dynamics for hundreds of iterations of huge neural networks at that point. Anyway, the point is, I thought it was not going to work. I thought, yes, okay, we can certainly compute the gradient. The software will work, we will be able to compute the gradient exactly. But I thought it just must be too chaotic of a system for that ever to make sense, and that we would just be basically optimizing a super wiggly function.", "David Duvenaud (12:34):In which case, the gradient wouldn\u2019t tell you about how to make much progress. It would just tell you what all the local wiggles were. In the setting of meta-learning where we were trying to say, \u201cNo, no, I\u2019m going to take the gradient of the validation loss of my neural network with respect to, let\u2019s say, the initial conditions of restraining or the learning rates or something, or it\u2019s prioritization. The idea is that it\u2019s not that we\u2019re going to get stuck in the Optima, it\u2019s that the local gradients will change at a much higher rate than the global structure. So this is hard to, it\u2019s really easy to explain with the whiteboard, it\u2019s hard by audio, but I\u2019ll give it a shot.", "David Duvenaud (13:13):So imagine I\u2019m on top of a huge hill and the overall gradient is quite clear in which direction I should go to move off that hill, but then someone has come along and put little egg cartons down everywhere. And so if I look at the gradient of the egg cartons there, I mean there a local minimum, but in high dimensions, that\u2019s not really the problem. In high dimensions, it\u2019s just the problem is that the variance of the gradients, or rather the scale of the changing gradients, is so tiny that they don\u2019t really tell you what the overall direction of the hill is very reliably.", "Jeremie (13:46):So sometimes to climb a tall mountain, you have to move through a couple of short valleys.", "David Duvenaud (13:50):Yeah. But it\u2019s more like what if there was jagged rocks everywhere and you were sort of measuring the size of these jagged rocks to say which direction pointed upwards in the mountain. They would just be pointing you all over the place and they would be changing so quickly, it would be hard to average them. And it turned out actually we need to [inaudible 00:14:06] an amazing guy, Brett Perlmutter, who had actually written about this in his thesis, and he\u2019s one of the early auto diff pioneers. And he had actually characterized this and found that actually sort of me and [inaudible 00:14:23] were both right in that for high learning rates, when you train a neural network, the dynamics are chaotic.", "David Duvenaud (14:29):And people talk [inaudible 00:14:32] talks about how when you\u2019re training, you want to be on edge of chaos. You want to have learning rate as large as it can be, but still have stable or absolute convergence. And so anyway, so Brett Perlmutter had actually run these experiments to ask like, \u201cWhat does this optimization landscape look like?\u201d And what it looks like is for low learning rates, for small learning rates, it\u2019s a nice, smooth curve, that\u2019s very easy to optimize with gradients. And then at some point there\u2019s a phase transition for high learning rates, it becomes this chaotic system for which the gradients just go up, and plus a million, then minus a million, plus a million. And it\u2019s basically impossible to ever\u2026", "David Duvenaud (15:05):The gradients just doesn\u2019t help you very much there. And if you then need some help you then in high dimensions, you just really can\u2019t make any progress. The point is that, that was one of the early instances where just being able to take gradients through stuff we had written actually turned out to be sort of more powerful than at least I had thought. And so we wrote this paper, it was called Gradient-Based Hyper Parameter Optimization Through Reversible Learning. And we spent a lot of time talking about how the big problem with this approach is that you need a lot of memory to store all the steps on the FordPass, so you can actually retrace those steps by running the optimization backwards and having a few little hints to correct that.", "David Duvenaud (15:45):Anyway, so of course we all have a little bit of [inaudible 00:15:49] in all of us. And I like to think of this as one of the first meta-learning papers, although we didn\u2019t have the foresight to name it as successfully as the paper that came out a year later of [inaudible 00:16:00], which it\u2019s not the same thing, but it\u2019s a pretty similar idea. And then after that paper, there was a whole string of papers that we wrote where it was just like, oh, let\u2019s take gradients through things that other people have a hard time with because they\u2019re using Theano basically.", "Jeremie (16:17):Right. And are there still examples of languages or frameworks that suffer from this problem? Or more or less, although the main ones anyway, TensorFlow, PyTorch, are they all up to par now?", "David Duvenaud (16:31):Yeah, so PyTorch is pretty well architected now. And I guess I\u2019ll say, I still hear about TensorFlow not being able to do fancy things. Like for instance, one of the fancy gradient tricks we did was neural ordinary differential equations where we wrote the gradient for ODEINT, the function that solves an ODE. And we express that in terms of another call to an ODE, whose dynamics are given by the gradient of the function, the gradient of the dynamics of the original problem. So when you\u2019re defining the ingredient of ODEINT, you have to take another gradient inside of there. And so that\u2019s just one example of where composability is important. And where TensorFlow, the way it was architected just happened not to be able to do that. So you can code up ODEs in TensorFlow, but you have to do that last little bit manually.", "Jeremie (17:23):Which fortunately now is changing. I mean, it\u2019s nice to hear that so many of these languages are starting to become more flexible in that way. And now another area that\u2019s gotten a lot of attention, and I do want to spend some time talking a little bit about this because I think it\u2019s so relevant nowadays especially, is this idea of AI explainability, which I think at least everyone\u2019s heard of.", "Jeremie (17:43):Whether that\u2019s in the context of debugging neural networks, where it\u2019s helpful to explain why a particular prediction or output is being rendered, or even in the context of AI ethics where sometimes you want to know the rationale behind someone being denied a bank loan. But you\u2019re approaching explainability from a very specific direction using generative models. Can you maybe explain, well first off, what a generative model is, and then how they can be used to help with explainability?", "David Duvenaud (18:08):Sure. So when I say generative model, I just mean a model that, if it\u2019s trying to model, let\u2019s say the relationship between some inputs X and some outputs Y, like we do when we do classification where the input X is an image and the output Y is a label. Generative models typically will also say, \u201cLet\u2019s build a model of the density of X. Let\u2019s model the distribution of images.\u201d And it will let us do things like regularize our models better through semi-supervised learning, take advantage of the partially labeled datasets, and also sort of, as I\u2019m going to argue, explain another models output automatically.", "Jeremie (18:46):Right, okay. And now what\u2019s the\u2026 I think I can see the connection to explainability. I mean, you referred to this as a way of generating counterfactuals. So essentially I guess, generating images that could have been, or texts that could have been. Can you walk us through what the application of that is to explainability?", "David Duvenaud (19:05):So, one thing I want to say is that the standard approaches to explainability usually take the gradients of the X, the output of your function, with respect to the inputs. So these are called saliency maps, which is kind of cheating because you\u2019re just calling your answer salient. But that\u2019s sort of been the bread and butter of explanation of the image class [inaudible 00:00:19:26], as you say. How would I need to change the pixels so that I change the output label? So certainly they talk about that crop to the inputs and the thing about that is taking gradients of the log probability of the class label with respects to all the pixel colors.", "David Duvenaud (19:48):And so I think most people don\u2019t think of this as a counterfactual approach, but I would say gradients are counterfactuals, they\u2019re instantaneous counterfactuals. If you think of the definition of a derivative, in English, it is how much would my function output change if I changed the input in this direction? So I would say we\u2019re already using counterfactuals as sort of the standard way of explaining almost all of our machine learning methods. And let\u2019s say the unsatisfying part about this is that they only ask about instantaneous changes. So they don\u2019t answer this question of what if I replaced in this image this seagull with a dog or something?", "David Duvenaud (20:32):That\u2019s just something that the gradient isn\u2019t going to meaningfully tell you the answer to. I\u2019m not the only person making these arguments, but the point is that gradients are a great starting point to explain the output of our classifiers. And where they break down is sometimes the way in which we might have to change an image to make the output different is sort of implausible. It\u2019s like, if I have an image of an elephant and then I start changing it to turn the elephant into the big, massive white noise or something like that, it\u2019s not really clear. That\u2019s a bad explanation because it\u2019s not plausible. So maybe we can talk a little bit about what maybe it means for something to be an explanation?", "David Duvenaud (21:16):Yeah. So I think it is kind of crazy. At the beginning of every field, of course it makes sense that we sort of need to grope around in the dark before we\u2019ve defined things and really know what we\u2019re talking about. But I\u2019d say at this point we should have some more concrete definitions of what an explanation is, and sometimes I\u2019ve even asked job faculty candidates who are doing human computer interaction and talking about explainability. And I say, \u201cOkay, so what is an explanation?\u201d And usually they don\u2019t really have an answer except in terms of, it\u2019s something that makes the system more useful to a user.", "David Duvenaud (21:44):Which I think, okay, I\u2019m in favor of usability, but we need to become more specific. So I\u2019m pretty sure that there\u2019s philosophy that\u2019s covered all this. My favorite definition is just that the explanation of why something is true can be answered by saying what needs to be different for that not to be true. In particular, I want to make a strong claim, which is that pretty much anytime someone asks, \u201cWhy is X true?\u201d We could rewrite their question without changing the meaning to, \u201cWhat would need to be different in order for X not to be true?\u201d", "Jeremie (22:17):Interesting. I\u2019m trying to think of counter examples here and it\u2019s not immediately obvious.", "David Duvenaud (22:21):Yeah. So, I mean, I\u2019ll give an example. So if someone says, \u201cOh, why wasn\u2019t I allowed on the roller coaster?\u201d Someone would say, \u201cBecause you\u2019re not tall enough.\u201d And we can think of the first person having asked like, \u201cOh, what would have needed to be different for me to be able to ride the roller coaster?\u201d", "Jeremie (22:34):Okay, this is interesting. Maybe this is sort of more on the philosophical side, but so this argues though that an explanation really is a list\u2026 No, not a list of facts or situations that would not meet the criteria. It\u2019s actually more like the rule that generates that list.", "David Duvenaud (22:53):Well, I think that\u2019s a great point. So I think we can\u2026 So first of all, these explanations aren\u2019t unique. As you say, there\u2019s many, many things that could be different. In fact, innumerably many things that could have been different in any situation pretty much that would\u2019ve made that be true. Another good\u2026 Why wasn\u2019t I allowed on the roller coaster? Oh, because they made the rule so that you have to be this height. If they changed the rule, you might\u2019ve been able to ride on the roller.", "David Duvenaud (23:16):So as you say, you can equivalently express either a giant endless set, but that\u2019s kind of long way to talk about this. But sometimes you can summarize this in a rule and say, \u201cHere\u2019s the rule that generates this set.\u201d And that\u2019s a much more concise way of conveying this set.", "Jeremie (23:32):And that rule itself. I mean, I guess you keep going down the rabbit hole, but I guess there are meta rules and meta rules piled on top of each other that take you all the way down, sort of turtles all the way down, so to speak. Is there a sense in which there\u2019s a philosophically satisfying cap to the depth of that logical structure?", "David Duvenaud (23:54):I don\u2019t think so. I think that this definition is pretty useful or pretty\u2026 But it doesn\u2019t really tell us how to prioritize these explanations. So all I can say is any one of these innumerable things would count as an explanation. Now we have to go back again and talk about which ones are useful in what situation. And I mean, usually we at this point ask, \u201cWhat are the actions available to the person that you\u2019re explaining something to?\u201d Because the answer to almost anything is, oh, the laws of physics could have been [inaudible 00:24:22] and it\u2019s like, well, okay, I can\u2019t change those.", "Jeremie (24:24):So, that\u2019s actually just at a higher level, a philosophical level, really fascinating because that is true. I mean, you could be a sort of pseudo determinist and say, \u201cWell, because at the moment of the Big Bang particle number 675 was right where it was and everything just played out from there.\u201d But none of that information maps onto the space of possible actions that we as agents can take in the world.", "David Duvenaud (24:47):That kind of brings us back to the why generative models here. So the idea is that, okay, we\u2019ve defined our answer. It basically can be any one of these, any verbal counterfactuals. Then we want to prioritize them by things that the user could change. And of course, usually when we\u2019re giving someone explanation, we don\u2019t actually know what their situation is very well. Maybe we have to design these black box systems ahead of time that will hopefully give useful explanations to a whole bunch of different people. So I think a good compromise is to at least restrict ourselves to plausible counterfactuals and say, \u201cHere are other sorts of things that I would actually expect to reasonably see.\u201d And maybe I have seen before that did give different outcomes.", "Jeremie (25:25):And so how do you define a plausible counterfactual? I guess that\u2019s just based on adversarial training or?", "David Duvenaud (25:31):No. So probabilities are what\u2019s going to tell us what\u2019s possible. So maybe we can define plausible as something meeting some threshold of at least some small probability of being possible. Why did my image detector say this is a dog? Well, a plausible alternative image would be one in which the dog is replaced by the background, or something like that, or a cat or something. And a bad explanation would be one where it just shows some white noise or some crazy impossible object or something like that. And a generative model is what\u2019s going to constrain this space of counterfactuals to be things that have moderate probability, at least some probability under our learned distribution over inputs.", "Jeremie (26:13):Okay. And so this really is then where that generative model becomes important, is in determining what plausible meter, what things are plausible essentially.", "Jeremie (26:24):Okay. What kinds of explanations or explainability statements can then be made once we start using a generative model to create these counterfactuals, and then essentially to probe an existing, say, classifier or aggressor?", "David Duvenaud (26:38):Yeah, that\u2019s a good question. And so here, these are a little bit wide open and we have a few sort of approaches that I think work pretty well, but I\u2019d say this is kind of where the field is at in not\u2026 I think the question you\u2019re asking right now is one that\u2019s kind of not well answered by the field right now. So we have a few standard approaches. So one is to say, again, this gradient based instantaneous counterfactual in a recent paper for [inaudible 00:27:02], we said, \u201cOkay, let\u2019s ask what region of an image, if you didn\u2019t observe it, if someone just came up to you and put a hand in your face and covered up this part of the world.", "David Duvenaud (27:16):Where, if they covered it up, would change your answer?\u201d So if there\u2019s an empty field and then someone puts their hand up in front of you, you\u2019re not sure if there\u2019s something behind it or not. And the idea is\u2026 You also have to assume that they\u2019re not trying to cover up something important because then the fact that their hand\u2019s there tells you something. So if part of the image was missing at random, which part of the image being missing would most change your prediction.", "David Duvenaud (27:44):And so if you kind of search over parts of the image that you could remove in this way or somehow mask, then you end up masking the important part, the crux of the evidence. So, that actually works pretty well. And the cool thing is you can actually ask the, I think it\u2019s the converse or the overse, I forget the definition of these, where you can say, \u201cOkay, if I could only see one part of the image and that would change my answer, which part of the image would most change my answer if that was the only thing I saw?\u201d", "Jeremie (28:09):There seem to be a ton of implication as well for improving the quality of predictions and improving existing models. I mean, it just sounds like there\u2019s an immediate tie in, for example, to attention and the idea of where a model should be looking and where it shouldn\u2019t be. And maybe related to that is the idea of what dropout strategies would be most effective. Is that fair to say or?", "David Duvenaud (28:32):Yeah, exactly. So I think that\u2019s a great connection that if we were trying to train an intention system, we should be asking a similar question, which is, where if I did look would most make my answer correspond to the truth? Or something like that.", "Jeremie (28:43):What\u2019s really cool about it too, these fully convolutional networks that do actually give you the ability to see where\u2019s this model looking at in this particular image, for example? Those strategies are very architecture specific, but what strikes me as being particularly exciting about what you\u2019re working on here is, at no point did you say, \u201cOh, we\u2019re working on a convolutional network or a computer vision problem even,\u201d this seems like it\u2019s a fully general strategy, right?", "David Duvenaud (29:10):Yeah, exactly. So I should have mentioned that. So that\u2019s the cool thing about these approaches is that they\u2019re sort of model agnostic in terms of the model that we\u2019re trying explain. And then also you can pretty much plug in any generative model here or there. Practically speaking, you do need pretty much everything to be differentiable if you want to make these things fast to generate explanations. But yeah, the details of the particular architecture don\u2019t matter beyond that.", "Jeremie (29:32):So I find that really interesting, because it does seem like a major through-line in all your research where\u2026 When I spoke to your student Will earlier he was talking about this idea of generalizability, essentially being able to make generative models that could leverage some architectures that previously couldn\u2019t be leveraged through his energy based approach, the one that you\u2019ve been exploring together.", "Jeremie (29:58):And it just seems like this is coming up over and over where earlier you were talking about programming languages that can propagate gradients through optimizers. Just sort of breaking a lot of the shackles, the framework, that we\u2019ve been using for a long time in the machine learning community to sort of open up the space of possible optimization schemes. Is that sort of a fair assessment of what your global research goal is?", "David Duvenaud (30:22):Well, I think it\u2019s more like a research cheat code where there\u2019s a series of papers that we can write because we had these slightly more general tools that\u2026 And I think most of the ideas that we were writing about, I think other people had thought of them, and it just was such a pain. I remember explaining some of these ideas to people saying, \u201cOh, we\u2019re going to take the gradients through the variance of our gradient [inaudible 00:30:43].\u201d", "David Duvenaud (30:44):And them just kind of going, \u201cOh man, I guess if you do a stop gradient here and you initialize this thing this way,\u201d and sort of imagining how they could coax Theano or whatever language they were using at the time to do such a thing. And it\u2019s like, for your mind, just think about it in terms of math, we\u2019re not afraid of writing gradients in front of anything in math, because we know it\u2019ll exist as long as the function is differentiable. So I think it was one of the things where having sufficiently good tools just lets you spend more time at the conceptual level without stopping and possibly thinking, but can I code this up in TensorFlow?", "Jeremie (31:21):Right. Because I guess there are two different kinds of constraints that historically had been applied to machine learning models. One of them is, what I might think of as an intentional architectural constraint, something like what we see with convolutional networks, where we recognize that the image data has the symmetry, that it\u2019s translationally invariant. And so therefore why don\u2019t we hard-code essentially that symmetry in the form of basically like a prior as an architecture in our neural network. And say, \u201cOkay, we\u2019ll take advantage of that. We\u2019ll spare the neural network the need to actually learn that translational and variants on the fly.\u201d", "Jeremie (31:57):And as a result, we\u2019ll essentially give it a big leg up and make this model much faster, much more effective in that context. But then there are these other arbitrary constraints that are a little bit more subtle and less obvious that you alluded to earlier when we were talking about programming languages and the interaction between our tooling and the models that we build. And that seems like a much more pathological kind of constraint. It\u2019s not something that reflects what we might assume through reason, through sort of the logic and life experience our models could actually benefit from.", "David Duvenaud (32:29):Yeah. And I want to say that I think the old guard, the original auto diff people, for instance, and a lot of the programming languages community, I think, probably look at the machine learning and deep learning communities with kind of thinking that we\u2019re hilarious and sad for having such limited tools because they sort of already did all this in the \u201980s and \u201990s. And for instance, in 2001 [inaudible 00:32:49], and one other person I forget, released this amazing book and software package called The Structure and Interpretation of Classical Mechanics, where they basically had fully fledged automatic implication, differential equation solvers, symbolic manipulators, such that they could write down for instance, [inaudible 00:33:08] equations in code and then automatically prove different implications or [inaudible 00:33:15], using their program transformation tools.", "David Duvenaud (33:20):And it\u2019s just that I think everything was kind of scaling math. They didn\u2019t have the hardware acceleration story. And I think in general, it\u2019s kind of strange how all these amazing old bits of software didn\u2019t catch on, but the point is all this isn\u2019t that new. And I think it\u2019s probably just an artifact of all the different sub communities, not enough people knowing enough about a bunch of different communities, and especially people in machine learning just not having a background in programming languages, numerics, and software design for the most part.", "Jeremie (33:55):Well, it\u2019s funny that you mentioned physics too. And I think I saw a tweet from Balaji Srinivasan on Twitter a couple of days ago where he was talking about, he managed to mention physics and essentially machine learning or computational science and statistics as being these fields from which we essentially see the most leverage. Or physics was one of the fields where if you did that in the early 1900s you\u2019d be set for life work-wise, and now it\u2019s sort of stats and CS. And they keep coming up together over and over.", "Jeremie (34:30):And as far as I can tell, I feel like this has something to do with the fact that they\u2019re in a way very, almost symmetrical or at least analogous. In physics, we\u2019re outsourcing all of our compute to physicists. Human minds are trying to come up with the feature set that we\u2019re going to exploit to derive laws and principles that can make predictions. Our predictions basically come from people. Whereas you go all the way over into machine learning, at least at the furthest extremes where you start relaxing all these extra constraints, and machines are doing all the optimization, we\u2019re outsourcing our compute to them.", "Jeremie (35:02):What\u2019s happening right now, it seems to be we\u2019re somewhere in the middle, where there\u2019s a mix of these human imposed priors and then the compute that\u2019s being done by machines. And what you\u2019re doing here is kind of moving us more and more towards that, higher levels of abstraction, outsourcing more and more of the more abstract reasoning to these machines through your algorithm.", "David Duvenaud (35:20):Oh yeah, I definitely see that. And every year there comes out another paper, that\u2019s like, automatically learning the laws of physics with machine learning. And they\u2019re always fairly basic concepts. [inaudible 00:35:32] having written such a paper and understanding its limitations very clearly. I do think it\u2019s funny though that initially most of the math and the early software tools that machine learning used came from physics, statistical mechanics in particular.", "David Duvenaud (35:45):And then I think just because there\u2019s been so much money and talent pouring into machine learning and deep learning in the last few years that now it\u2019s kind of a risk where this community is the one that developed this new generation of software. Well, I don\u2019t want to say this community, I\u2019ll just say at least there has been a new generation of software and hardware tools that has been developed for deep learning, that now is becoming general enough to be applied back to physics.", "Jeremie (36:09):Yes. Actually before I dropped out, I was doing a PhD in physics and dropped out two years in. But right before I dropped out, we were just starting to see that. We were starting to see people say, \u201cOh, you know what? We could use genetic algorithms for this, or we could use this hardware,\u201d whether it was GPU\u2019s or whatever else, for their applications. So yeah, really cool to see some of that crossover starting to happen. Cross pollination is always a good thing. Thanks so much, David, for all of this. I think we\u2019ve covered a lot of ground and a lot of really cool insights along the way. Do you mind sharing your Twitter handle?", "David Duvenaud (36:41):Sure. It\u2019s just David Duvenaud, my full name. So I guess you have to spell my name, which my last name is D-U-V-E-N-A-U-D.", "Jeremie (36:50):And we\u2019ll provide a link to that in the blog post that\u2019ll accompany this podcast as well. David, thanks so much for joining us for this. It was great.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Co-founder of Gladstone AI \ud83e\udd16 an AI safety company. Author of Quantum Mechanics Made Me Do It (preorder: shorturl.at/jtMN0)."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe6124a0a584f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@JeremieHarris?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@JeremieHarris?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "Jeremie Harris"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59564831d1eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&user=Jeremie+Harris&userId=59564831d1eb&source=post_page-59564831d1eb----e6124a0a584f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6124a0a584f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6124a0a584f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2", "anchor_text": "APPLE"}, {"url": "https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz", "anchor_text": "GOOGLE"}, {"url": "https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU", "anchor_text": "SPOTIFY"}, {"url": "https://anchor.fm/towardsdatascience", "anchor_text": "OTHERS"}, {"url": "https://towardsdatascience.com/podcast/home", "anchor_text": "TDS podcast"}, {"url": "http://sharpestminds.com", "anchor_text": "SharpestMinds"}, {"url": "https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2", "anchor_text": "Apple"}, {"url": "https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz", "anchor_text": "Google"}, {"url": "https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU", "anchor_text": "Spotify"}, {"url": "https://twitter.com/DavidDuvenaud", "anchor_text": "follow David on Twitter here"}, {"url": "https://twitter.com/jeremiecharris", "anchor_text": "follow me on Twitter here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e6124a0a584f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----e6124a0a584f---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/tds-podcast?source=post_page-----e6124a0a584f---------------tds_podcast-----------------", "anchor_text": "Tds Podcast"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e6124a0a584f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----e6124a0a584f---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe6124a0a584f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&user=Jeremie+Harris&userId=59564831d1eb&source=-----e6124a0a584f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe6124a0a584f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&user=Jeremie+Harris&userId=59564831d1eb&source=-----e6124a0a584f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe6124a0a584f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe6124a0a584f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e6124a0a584f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e6124a0a584f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e6124a0a584f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e6124a0a584f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@JeremieHarris?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@JeremieHarris?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jeremie Harris"}, {"url": "https://medium.com/@JeremieHarris/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "122K Followers"}, {"url": "http://shorturl.at/jtMN0", "anchor_text": "shorturl.at/jtMN0"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59564831d1eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&user=Jeremie+Harris&userId=59564831d1eb&source=post_page-59564831d1eb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F15c61aaa3274&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-generative-models-for-explainable-ai-e6124a0a584f&newsletterV3=59564831d1eb&newsletterV3Id=15c61aaa3274&user=Jeremie+Harris&userId=59564831d1eb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.amazon.ca/Quantum-Physics-Made-Fundamental-Everything/dp/0735244138", "anchor_text": "Quantum Physics Made Me Do It: A Simple Guide to the Fundamental Nature of Everything2023"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}