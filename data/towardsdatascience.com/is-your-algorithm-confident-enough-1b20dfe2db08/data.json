{"url": "https://towardsdatascience.com/is-your-algorithm-confident-enough-1b20dfe2db08", "time": 1682995693.7250931, "path": "towardsdatascience.com/is-your-algorithm-confident-enough-1b20dfe2db08/", "webpage": {"metadata": {"title": "Is your algorithm confident enough? | by Daniel Rothmann | Towards Data Science", "h1": "Is your algorithm confident enough?", "description": "There are several techniques for measuring uncertainty in neural networks and some of them are very easy to implement."}, "outgoing_paragraph_urls": [{"url": "https://eng.uber.com/neural-networks-uncertainty-estimation/", "anchor_text": "Prediction uncertainty can be divided into 3 categories", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Uncertainty_quantification", "anchor_text": "things that could be correctly captured by the model but isn\u2019t", "paragraph_index": 8}, {"url": "https://engineering.taboola.com/using-uncertainty-interpret-model/", "anchor_text": "Yoel and Inbar from Taboola provide a fun example:", "paragraph_index": 9}, {"url": "https://stat.duke.edu/research-areas/model-uncertainty", "anchor_text": "considered to be particularly challenging", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Bayes_error_rate", "anchor_text": "Bayes error rate", "paragraph_index": 14}, {"url": "https://towardsdatascience.com/what-uncertainties-tell-you-in-bayesian-neural-networks-6fbd5f85648e", "anchor_text": "taking a look at this article", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/@laumannfelix", "anchor_text": "Felix Laumann", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/@rathi.ankit", "anchor_text": "Ankit Rathi", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/bayesian-statistics-for-data-science-45397ec79c94", "anchor_text": "series of great articles on the subject", "paragraph_index": 16}, {"url": "https://github.com/kyle-dorman/bayesian-neural-network-blogpost", "anchor_text": "Bayesian neural network", "paragraph_index": 18}, {"url": "https://arxiv.org/abs/1506.02142", "anchor_text": "Yarin and Zoubin from University of Cambridge found a way", "paragraph_index": 21}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST problem", "paragraph_index": 24}, {"url": "https://keras.io/", "anchor_text": "Keras", "paragraph_index": 24}, {"url": "https://www.semanticscholar.org/paper/Risk-versus-Uncertainty-in-Deep-Learning-%3A-Bayes-%2C-Osband/dde4b95be20a160253a6cc9ecd75492a13d60c10", "anchor_text": "The technique was critiqued by Ian Osband from Deepmind", "paragraph_index": 27}, {"url": "http://blog.s-schoener.com/2017-12-20-uncertainty-in-dl/", "anchor_text": "Sebastian Sch\u00f6ner has written a great blog post summarizing the critique", "paragraph_index": 28}, {"url": "https://www.kanda.dk/", "anchor_text": "Kanda", "paragraph_index": 29}, {"url": "https://arxiv.org/pdf/1707.07012.pdf", "anchor_text": "NASNet Mobile architecture", "paragraph_index": 31}], "all_paragraphs": ["When machine learning techniques are used in \u201cmission critical\u201d applications, the acceptable margin of error becomes significantly lower.", "Imagine that your model is driving a car, assisting a doctor or even just interacting directly with an (perhaps easily annoyed) end user. In these cases, you\u2019ll want to ensure that you can be confident in the predictions your model makes before acting on them.", "Measuring prediction uncertainty grows more important by the day, as fuzzy systems become an increasing part of our fuzzy lives.", "Here\u2019s the good news: There are several techniques for measuring uncertainty in neural networks and some of them are very easy to implement! First, let\u2019s get a feel for what we\u2019re about to measure.", "When you make models of the world, your models cannot always provide accurate answers.", "This is partly due to that fact that models are simplifications of a seriously complicated world. Since some information is unknown, the predictions from your model are subject to some degree of uncertainty.", "Parts of our world (and the ways we measure it) are simply chaotic. Some things happen randomly, and this randomness is also a source of uncertainty in your model\u2019s predictions.", "Prediction uncertainty can be divided into 3 categories:", "Model uncertainty comes from \u201cignorance\u201d of the problem. That is, model uncertainty quantifies the things that could be correctly captured by the model but isn\u2019t.", "Yoel and Inbar from Taboola provide a fun example:", "Sometimes it is also referred to as epistemic or structural uncertainty. Measuring model uncertainty is an area of statistics which is considered to be particularly challenging. One reason for this, is that principled techniques like Bayesian model averaging become very costly as models grow more complex.", "If your model produces good predictions during training and validation but not during evaluation (or in production), it might be misspecified.", "Model misspecification uncertainty captures scenarios where your model is making predictions on new data with very different patterns from the training data.", "This is uncertainty produced by noise present in the dataset. It could be attributed to imperfect measurement techniques or an inherent randomness in the thing being measured.", "Inherent noise is also sometimes called aleatoric or statistical uncertainty. The amount of inherent noise is linked to the Bayes error rate which the lowest achievable error rate of a given classifier. As you can imagine, the lowest possible error rate that a model can achieve is tightly linked to the amount of error produced by noise in the data itself.", "These concepts lean heavily on Bayesian statistics. I have outlined these ideas in a simple way, but that\u2019s just scratching the surface on these deep topics.", "To learn more about uncertainty measures in Bayesian neural networks, I recommend taking a look at this article by Felix Laumann. For an in-depth explanation of Bayesian statistics in the context of data science, Ankit Rathi has written a series of great articles on the subject.", "At this point, you may be thinking: \u201cThat sounds good, but how do I implement uncertainty in my model?\u201d.", "The Bayesian neural network integrates uncertainty by default in addition to generally being more robust to overfitting and handling smaller datasets. However, the toolchain for building Bayesian neural networks is still emerging and the models tend to be more computationally costly, both during training and when making predictions.", "Also, migrating your work to a probabilistic model (like a Bayesian neural network) is going to be annoying.", "In the long run, probabilistic deep learning will likely become the default. For now though, practical techniques to integrate the probabilistic perspective in our existing work is a good first step!", "A couple of years ago, Yarin and Zoubin from University of Cambridge found a way to approximate model uncertainty without changing the structure or optimization techniques of the neural network.", "Here\u2019s the short version: By using dropout before each weight layer at test time and running your predictions for several iterations, you can approximate Bayesian uncertainty. They call this process Monte Carlo dropout:", "Intuitively, I think of it like this: The more your prediction fluctuates with tiny structural changes to the model, the more uncertain that prediction is.", "Implementing Monte Carlo dropout is really easy. Here, I start with a simple dense network for the MNIST problem built with Keras. By default, dropout layers are only enabled during training. To enable the dropout layers at test time, set training=True for each layer.", "Next, we need a custom prediction function which can predict iteratively and return the mean and variance of those iterations. In this example, we measure the standard deviation instead of the variance, because it\u2019s expressed in the same units as the mean.", "Now you\u2019re ready to predict with approximated uncertainty:", "As we saw, using Monte Carlo dropout is really easy. Maybe even too easy. The technique was critiqued by Ian Osband from Deepmind who noted that the predictive uncertainty of a simple model with Monte Carlo dropout did not decrease with more data. This raises the question of whether it is an inaccurate approximation of Bayesian uncertainty or if there are any underlying assumptions that need to be made more clear.", "For more that issue, Sebastian Sch\u00f6ner has written a great blog post summarizing the critique.", "In my workplace at Kanda, we have had mixed experiences with the effectiveness of the Monte Carlo dropout.", "For a simple fully connected model trained on MNIST like my previous example, the uncertainty approximations behaved as expected: When presented with noise instead of a handwritten digit, the approximated uncertainty was higher. We found that 50\u2013100 iterations of Monte Carlo dropout produced satisfactory results.", "Later, we had a scenario, where we needed to run an image recognition task locally on a smartphone as part of an AR application. We used transfer learning, building a classifier on top of the NASNet Mobile architecture.", "Running 100 iterations of NASNet on a smartphone is not a good idea.", "Even with heavy parallelization, we were only realistically able to run ~20 iterations on the device in order to provide a prediction in good time.", "Secondly, the uncertainty estimates were inaccurate. When fed a picture of random noise, the uncertainty was surprisingly low. It is worth noting that we only implemented dropout in the densely connected part of the classifier which sat on top of NASNet. If you\u2019d like to share intuitions about what went wrong here, I\u2019d be very interested to read a response from you!", "First, we had a look at why it\u2019s important to quantify uncertainty in machine learning models. Then, I introduced you to 3 different ways of thinking about prediction uncertainty: Model uncertainty, model misspecification and inherent noise.", "Monte Carlo dropout is an easy-to-implement technique to approximate Bayesian uncertainty, but there is some disagreement to whether the approximation is indeed accurate. Practically, I have found Monte Carlo dropout effective for simpler models, but have had some problems with the approach for complex models, both in terms of accuracy and performance.", "Integrating Bayesian probability in machine learning will only become more important in the future, and I look forward to seeing more probabilistic techniques become part of the toolchain.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1b20dfe2db08&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@danielrothmann?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@danielrothmann?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "Daniel Rothmann"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc078747a2b73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&user=Daniel+Rothmann&userId=c078747a2b73&source=post_page-c078747a2b73----1b20dfe2db08---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b20dfe2db08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b20dfe2db08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@earbiscuits?utm_source=medium&utm_medium=referral", "anchor_text": "Juan Rumimpunu"}, {"url": "https://eng.uber.com/neural-networks-uncertainty-estimation/", "anchor_text": "Prediction uncertainty can be divided into 3 categories"}, {"url": "https://en.wikipedia.org/wiki/Uncertainty_quantification", "anchor_text": "things that could be correctly captured by the model but isn\u2019t"}, {"url": "https://engineering.taboola.com/using-uncertainty-interpret-model/", "anchor_text": "Yoel and Inbar from Taboola provide a fun example:"}, {"url": "https://stat.duke.edu/research-areas/model-uncertainty", "anchor_text": "considered to be particularly challenging"}, {"url": "https://en.wikipedia.org/wiki/Bayes_error_rate", "anchor_text": "Bayes error rate"}, {"url": "https://towardsdatascience.com/what-uncertainties-tell-you-in-bayesian-neural-networks-6fbd5f85648e", "anchor_text": "taking a look at this article"}, {"url": "https://towardsdatascience.com/@laumannfelix", "anchor_text": "Felix Laumann"}, {"url": "https://towardsdatascience.com/@rathi.ankit", "anchor_text": "Ankit Rathi"}, {"url": "https://towardsdatascience.com/bayesian-statistics-for-data-science-45397ec79c94", "anchor_text": "series of great articles on the subject"}, {"url": "https://unsplash.com/@avirichards?utm_source=medium&utm_medium=referral", "anchor_text": "Avi Richards"}, {"url": "https://github.com/kyle-dorman/bayesian-neural-network-blogpost", "anchor_text": "Bayesian neural network"}, {"url": "https://arxiv.org/abs/1506.02142", "anchor_text": "Yarin and Zoubin from University of Cambridge found a way"}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST problem"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "https://unsplash.com/@punttim?utm_source=medium&utm_medium=referral", "anchor_text": "Tim Gouw"}, {"url": "https://www.semanticscholar.org/paper/Risk-versus-Uncertainty-in-Deep-Learning-%3A-Bayes-%2C-Osband/dde4b95be20a160253a6cc9ecd75492a13d60c10", "anchor_text": "The technique was critiqued by Ian Osband from Deepmind"}, {"url": "http://blog.s-schoener.com/2017-12-20-uncertainty-in-dl/", "anchor_text": "Sebastian Sch\u00f6ner has written a great blog post summarizing the critique"}, {"url": "https://www.kanda.dk/", "anchor_text": "Kanda"}, {"url": "https://arxiv.org/pdf/1707.07012.pdf", "anchor_text": "NASNet Mobile architecture"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1b20dfe2db08---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----1b20dfe2db08---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/bayesian-statistics?source=post_page-----1b20dfe2db08---------------bayesian_statistics-----------------", "anchor_text": "Bayesian Statistics"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----1b20dfe2db08---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----1b20dfe2db08---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b20dfe2db08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&user=Daniel+Rothmann&userId=c078747a2b73&source=-----1b20dfe2db08---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b20dfe2db08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&user=Daniel+Rothmann&userId=c078747a2b73&source=-----1b20dfe2db08---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b20dfe2db08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1b20dfe2db08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1b20dfe2db08---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1b20dfe2db08--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@danielrothmann?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@danielrothmann?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Daniel Rothmann"}, {"url": "https://medium.com/@danielrothmann/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc078747a2b73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&user=Daniel+Rothmann&userId=c078747a2b73&source=post_page-c078747a2b73--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F385004d73127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fis-your-algorithm-confident-enough-1b20dfe2db08&newsletterV3=c078747a2b73&newsletterV3Id=385004d73127&user=Daniel+Rothmann&userId=c078747a2b73&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}