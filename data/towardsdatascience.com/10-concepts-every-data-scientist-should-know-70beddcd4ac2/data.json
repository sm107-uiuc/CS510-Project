{"url": "https://towardsdatascience.com/10-concepts-every-data-scientist-should-know-70beddcd4ac2", "time": 1683011383.859405, "path": "towardsdatascience.com/10-concepts-every-data-scientist-should-know-70beddcd4ac2/", "webpage": {"metadata": {"title": "10 Concepts Every Data Scientist Should Know | by Soner Y\u0131ld\u0131r\u0131m | Towards Data Science", "h1": "10 Concepts Every Data Scientist Should Know", "description": "Data science is such a broad field. If it was a recipe, the main ingredients would be linear algebra, statistics, software, analytical skills, storytelling and all seasoned with some domain\u2026"}, "outgoing_paragraph_urls": [{"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/", "paragraph_index": 46}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14", "paragraph_index": 46}], "all_paragraphs": ["Data science is such a broad field. If it was a recipe, the main ingredients would be linear algebra, statistics, software, analytical skills, storytelling and all seasoned with some domain knowledge. The amount of ingredients change according to the tasks you are working on.", "Whatever you do as a data scientist, there are some terms and concepts you should definitely be familiar with. In this post, I will cover 10 of these concepts. Please note that this post is by no means aimed to be a comprehensive list of the topics you need to know. However, knowing the following concepts will absolutely add value to your skillset and help you in your journey to learn more.", "We first need to introduce the normal (gaussian) distribution for central limit theorem to make sense. Normal distribution is a probability distribution that looks like a bell:", "X-axis represents the values and y-axis represents the probabilities of observing these values. Normal distribution is used to represent random variables with unknown distributions. Thus, it is widely used in many fields including natural and social sciences. The reason to justify why it can used to represent random variables with unknown distributions is the central limit theorem (CLT).", "According to the CLT, as we take more samples from a distribution, the sample averages will tend towards a normal distribution regardless of the population distribution.", "Consider a case that we need to learn the distribution of the heights of all 20-year-old people in a country. It is almost impossible and, of course not practical, to collect this data. So, we take samples of 20-year-old people across the country and calculate the average height of the people in samples. According to the CLT, as we take more samples from the population, sampling distribution will get close to a normal distribution.", "Why is it so important to have a normal distribution? Normal distribution is described in terms of mean and standard deviation which can easily be calculated. And, if we know the mean and standard deviation of a normal distribution, we can compute pretty much everything about it.", "P-value is the probability of getting our observed value or values that have same or less chance to be observed. Consider the following probability distribution of a random variable A. It is highly likely to observe a value around 10. As the values get higher or lower, the probabilities decrease.", "We have another random variable B and want to see if B is greater than A. The average sample means obtained from B is 12.5 . The p value for 12.5 is the green area in the graph below. The green area indicates the probability of getting 12.5 or a more extreme value (higher than 12.5 in our case).", "Let\u2019s say the p value is 0.11 but how do we interpret it? A p value of 0.11 means that we are 89% sure of the results. In other words, there is 11% chance that the results are due to random chance. Similarly, a p value of 0.5 means that there is 5% chance that the results are due to random chance.", "Lower p values show more certainty in the result.", "If the average of sample means from the random variable B turns out to be 15 which is a more extreme value, the p value will be lower than 0.11.", "Bias occurs when we try to approximate a complex or complicated relationship with a much simpler model. I think of it as a lazy model. Consider a case in which the relationship between independent variables (features) and dependent variable (target) is very complex and nonlinear. But, we try to build a model using linear regression. In this case, even if we have millions of training samples, we will not be able to build an accurate model. By using a simple model, we restrict the performance. The true relationship between the features and the target cannot be reflected.The models with high bias tend to underfit.", "Variance occurs when the model is highly sensitive to the changes in the independent variables (features). The model tries to pick every detail about the relationship between features and target. It even learns the noise in the data which might randomly occur. A very small change in a feature might change the prediction of the model. Thus, we end up with a model that captures each and every detail on the training set so the accuracy on the training set will be very high. However, the accuracy of new, previously unseen samples will not be good because there will always be different variations in the features. This situation is also known as overfitting. The model overfits to the training data but fails to generalize well to the actual relationships within the dataset.", "So neither high bias nor high variance is good. The perfect model is the one with low bias and low variance. However, perfect models are very challenging to find, if possible at all. There is a trade-off between bias and variance. We should aim to find the right balance between them. The key to success as a machine learning engineer is to master finding the right balance between bias and variance.", "Overfitting is a significant issue in the field of data science that needs to handled carefully in order to build a robust and accurate model. Overfitting arises when a model tries to fit the training data so well that it cannot generalize to new observations. An overfit model captures the details and noise in training data rather than the general trend.", "A solution to overfitting problem is to reduce the model complexity. For instance, if we have a polynomial model, we can reduce the model complexity by decreasing the degrees of freedom. Polynomial models are non-linear. We need another regularization technique for linear model which is regularization.", "Regularization controls the model complexity by penalizing higher terms in the model. If a regularization terms is added, the model tries to minimize both loss and complexity of model.", "It is also called regularization for sparsity. As the name suggests, it is used to handle sparse vectors which consist of mostly zeroes. Sparse vectors typically result in very high-dimensional feature vector space. Thus, the model becomes very difficult to handle.", "L1 regularization forces the weights of uninformative features to be zero by substracting a small amount from the weight at each iteration and thus making the weight zero, eventually.", "It is also called regularization for simplicity. If we take the model complexity as a function of weights, the complexity of a feature is proportinal to the absolute value of its weight.", "L2 regularization forces weights toward zero but it does not make them exactly zero. L2 regularization acts like a force that removes a small percentage of weights at each iteration. Therefore, weights will never be equal to zero.", "Note: Ridge regression uses L2 regularization whereas Lasso regression uses L1 regularization. Elastic net regression combines L1 and L2 regularization.", "In simplest terms, the curse of dimensionality indicates having too many features. More data is good but if it is well-structuted. If we have many features (columns) but not enough observations (rows) to cope with, then we have a problem.", "Having many features but not enough observations causes overfitting. The model, as expected, captures the details of the observations in the dataset rather than generalizing well to the true relationship among features and target.", "Another downside arises when we try to cluster the observations. Clustering algorithms use distance measures. Having too many features causes to have very similar distances between observations and thus makine it very hard to group observations into clusters.", "One solution for the curse of dimensionality would be to gather more observations (rows) by keeping the number of features the same. However, this would be time-consuming and not always be feasible. Furthermore, it will add an extra computation burden to the model. A better solution would be to use a dimensionality reduction algorithm such as PCA. Dimensionality reduction is reducing the number of features by deriving new features from the existing ones with an aim to preserve the variance in the dataset.", "In the field of machine learning, emsemble learning methods are designed by combining many base estimators (i.e. algorithms). For instance, random forest is an ensemble learning algorithm created by combining several decision trees. Bagging and boosting are two different ways used in combining base estimators.", "Bagging means aggregating the predictions of several weak learners. We can think of it combining weak learners in parallel. The average of the predictions of several weak learners is used as the overall prediction.", "Boosting means combining several weak learners in series. We end up having a strong learner from many sequentially connected weak learners. One of most commonly used ensemble learning algorithm that uses boosting is gradient boosted decision tree (GBDT). Like in random forests, weak learners (or base estimators) in GBDT are decision trees.", "Entropy is a measure of uncertainty or randomness. The more randomness a variable has, the higher the entropy is. The variables with uniform distribution have the highest entropy. For example, rolling a fair dice has 6 possible outcomes with equal probabilities so it has a uniform distribution and high entropy.", "We are likely to come across entropy and information gain when dealing with decision trees. They are the determining factors when the algorithm decides on splits. Splits that result in more pure nodes are chosen. All these indicate \u201cinformation gain\u201d which is basically the difference between entropy before and after the split.", "When choosing a feature to split, decision tree algorithm tries to achieve", "Precision and recall are metrics used to evaluate classification models. Before describing these metrics, it is better to explain the confusion matrix.", "Confusion matrix shows the correct and incorrect (i.e. true or false) predictions on each class. In case of a binary classification task, a confusion matrix is a 2x2 matrix. If there are three different classes, it is a 3x3 matrix and so on.", "Let\u2019s assume class A is positive class and class B is negative class. The key terms of confusion matrix are as follows:", "Precision indicates how many positive predictions are correct. The focus of precision is positive predictions.", "Recall indicates how many of the positive classes the model is able to predict correctly. The focus of recall is actual positive classes.", "ROC (receiver operating characteristics) curve summarizes the performance of a classification model by combining confusion matrices at all threshold values. X axis of ROC curve is the true positive rate (sensitivity) and y axis of the ROC curve is the false positive rate (1- specificity).", "If the threshold is set to 0, the model predicts all samples as positive. In this case, TPR (sensitivity) is 1. However, FPR(1-specificity) is also 1 because there is no negative prediction. If the threshold is set to 1, both TPR and FPR become 0. Hence, it is not a good choice to set the threshold to 0 or 1.", "We aim to increase the true positive rate (TPR) while keeping false positive rate (FPR) low. As we can see on the ROC curve, as TPR increases, FPR also increases. So it comes down to decide how many false positives we can tolerate.", "Instead of trying to find the optimum threshold value on ROC curve, we can use another metric called AUC (Area under the curve). AUC is the area under ROC curve between (0,0) and (1,1) which can be calculated using integral calculus. AUC basically aggregates the performance of the model at all threshold values. The best possible value of AUC is 1 which indicates a perfect classifier. The closer the AUC is to 1, the better the classifier is. In the figure below, classifier A is better than classifier B.", "As other supervised learning algorithms, naive bayes uses features to make a prediction on a target variable. The key difference is that naive bayes assumes that features are independent of each other and there is no correlation between features. However, this is not the case in real life. This naive assumption of features being uncorrelated is the reason why this algorithm is called \u201cnaive\u201d.", "The assumption that all features are independent makes naive bayes algorithm very fast compared to complicated algorithms. In some cases, speed is preferred over higher accuracy. It works well with high-dimensional data such as text classification and email spam detection.", "Thank you for reading. Please let me know if you have any feedback.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Top 10 Writer in AI and Data Science | linkedin.com/in/soneryildirim/ | twitter.com/snr14"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F70beddcd4ac2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sonery.medium.com/?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----70beddcd4ac2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70beddcd4ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70beddcd4ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@tylercaseyprod?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Tyler Casey"}, {"url": "https://unsplash.com/s/photos/light-up?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc", "anchor_text": "Figure source"}, {"url": "https://link.springer.com/referenceworkentry/10.1007%2F978-1-4419-9863-7_209", "anchor_text": "Figure source"}, {"url": "https://medium.com/tag/data-science?source=post_page-----70beddcd4ac2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----70beddcd4ac2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----70beddcd4ac2---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70beddcd4ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----70beddcd4ac2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70beddcd4ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----70beddcd4ac2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70beddcd4ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F70beddcd4ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----70beddcd4ac2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----70beddcd4ac2--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://sonery.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21K Followers"}, {"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/"}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7cdf5377373a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-concepts-every-data-scientist-should-know-70beddcd4ac2&newsletterV3=2cf6b549448&newsletterV3Id=7cdf5377373a&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}