{"url": "https://towardsdatascience.com/building-analysis-pipelines-with-kaggle-c745671d273e", "time": 1683009697.975429, "path": "towardsdatascience.com/building-analysis-pipelines-with-kaggle-c745671d273e/", "webpage": {"metadata": {"title": "Building Analysis Pipelines with Kaggle | by David Mezzetti | Towards Data Science", "h1": "Building Analysis Pipelines with Kaggle", "description": "Kaggle is one of the most popular places to get started with data science and machine learning. Most in the data science world have used or at least heard of it. Kaggle is well-known as a site that\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/", "anchor_text": "Kaggle", "paragraph_index": 0}, {"url": "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge", "anchor_text": "COVID-19 Open Research Dataset (CORD-19)", "paragraph_index": 1}, {"url": "https://www.kaggle.com/notebooks", "anchor_text": "Kaggle Notebooks", "paragraph_index": 2}, {"url": "https://github.com/Kaggle/docker-python", "anchor_text": "Docker containers", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Graphics_processing_unit", "anchor_text": "GPUs", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Tensor_processing_unit", "anchor_text": "TPUs", "paragraph_index": 3}, {"url": "https://www.kaggle.com/davidmezzetti/cord-19-report-builder/", "anchor_text": "CORD-19 Report Builder notebook", "paragraph_index": 6}, {"url": "https://github.com/Kaggle/kaggle-api", "anchor_text": "full featured Python API", "paragraph_index": 12}, {"url": "https://github.com/Kaggle/kaggle-api#api-credentials", "anchor_text": "API has documentation", "paragraph_index": 13}, {"url": "https://github.com/neuml/kernelpipes", "anchor_text": "kernelpipes project", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/YAML", "anchor_text": "YAML", "paragraph_index": 20}, {"url": "https://www.kaggle.com/learn/overview", "anchor_text": "micro-courses", "paragraph_index": 31}], "all_paragraphs": ["Kaggle is one of the most popular places to get started with data science and machine learning. Most in the data science world have used or at least heard of it. Kaggle is well-known as a site that hosts machine learning competitions and while that is a big part of the platform, it can do much more.", "This year with the COVID-19 Open Research Dataset (CORD-19), I had the chance to use the platform more consistently. Honestly, Jupyter notebooks and GUI-based development hasn\u2019t been my preferred approach (Vim is often good enough for me). But over the last few months, I\u2019ve been impressed with the capabilities of the platform. This article gives an overview of Kaggle Notebooks, the Kaggle API and demonstrates a way to build automated analysis pipelines.", "Kaggle Notebooks is a cloud-hosted Jupyter notebook environment. Notebooks can be built in Python or R. Notebooks execute within Docker containers and we can think of them as a bundle of logic. Notebooks can contain all the logic for a data analysis project or they can be chained together to build modular components. Notebooks can be publicly shared or kept private.", "Notebooks have access to multiple CPU cores and a healthy amount of RAM. Additionally, GPUs and TPUs can be added, which can accelerate the training of deep learning models. The resources available are extremely impressive for a free service. Spinning up a comparable host on one of the big cloud providers is a sizeable cost.", "Notebooks read data using a couple different methods. The main way is through datasets. Anyone with an account can upload data and create their own datasets. There also are a large number of publicly available datasets already on Kaggle. As with notebooks, datasets can be publicly shared or private. Notebooks can have one to many datasets as inputs. Additionally, the output of other notebooks can be used as input, allowing a chain of notebooks to be constructed.", "Blank notebooks can be created using the \u201cNew Notebook\u201d button shown in the previous image. Once a notebook is created, there will be an editor available to build logic. This example will copy an existing notebook to focus on methods to run notebooks.", "We\u2019ll use the CORD-19 Report Builder notebook. After following the referenced link, we can copy the notebook via the \u201cCopy and Edit\u201d button. This will create a notebook as <your Kaggle user name>/cord-19-report-builder. Please note that all the following links will show davidmezzetti as the user name, please substitute with your Kaggle user name.", "Copying the notebook will bring us to the interface to edit the notebook. From this screen, we can also add/remove inputs, modify settings and save/run a notebook.", "The example above shows importing a utility script from another notebook. This is a powerful feature that allows sharing functionality across notebooks, preventing having to copy/paste boilerplate code. The example has two input datasets and one notebook as an input.", "Clicking the \u201cSave Version\u201d button will execute the logic in the notebook and save a new version. There are multiple options:", "If the notebook has been fully run while editing, \u201cQuick Save\u201d works well. Otherwise \u201cSave & Run All\u201d should be used.", "If we have a couple notebooks that we want to update occasionally as additional logic is added, what has been described is often good enough.", "For more complex cases or frequent use, Kaggle has a full featured Python API available. The Kaggle API is available via PyPi:", "The API has documentation on how to setup authorization and create access keys to enable usage. Once the API is setup, a simple example of running a notebook via the API is shown below:", "This runs two commands. The first one pulls the cord-19-report-builder notebook, stores it and it\u2019s metadata in a directory called cord-19-report-builder. The second runs the notebook.", "Once the commands above are run, we can go to Kaggle to monitor the progress of the job. The image below shows the versions screen where we can see a new version of the notebook is running. This screen can be brought up by clicking on the version text (in the right corner highlighted).", "The Kaggle API is powerful and allows running notebooks outside the main web interface (along with many other features). Scripts can be built around it to enable more complex functionality and interactions with external processes.", "With the CORD-19 dataset, the number of notebooks to support that effort grew to a point where there were 10+ notebooks that needed to be refreshed each time new data came in. On top of that, the dataset moved to a point where it was updated every day and the notebooks had dependencies on each other (i.e. one would need to run before another could run).", "For this use case, it became apparent that full automation would be necessary. To enable automated pipelines, NeuML created the kernelpipes project.", "kernelpipes can be installed via pip:", "kernelpipes uses the Kaggle API to execute a series of notebooks sequentially or in parallel. Checks can be added to only enable running the pipeline if a source has been updated. Additionally, pipelines have a built-in cron scheduling feature to enable continuous execution. The following is a simple example pipeline in YAML.", "Assuming the above content is saved in file named pipeline.yml, it can be run as follows:", "This simple pipeline executes a notebook and checks for completion status every 2.5 minutes. Once the kernel is complete, the process will exit.", "Optional field to enable running jobs through a scheduler. System cron can be used in place of this, depending on preference. One advantage the internal scheduler vs system cron is that new jobs won\u2019t be spawned while a prior job is running. For example if a job is scheduled to run every hour and a run takes 1.5 hours, it will skip the 2nd run and start again on the 3rd hour.", "Allows conditionally running a pipeline based on dataset update status. Retrieves dataset metadata and compares the latest version against the last run version and only allows processing to proceed if the dataset has been updated. If there is no local metadata for the dataset, the run will proceed.", "Returns the kernel specified at /kaggle/kernel/path", "Checks the status of preceding kernel steps at the specified duration.", "To give an idea of a complex use case, below is a full pipeline used for processing the CORD-19 dataset.", "The example above runs 3 times a day. Before execution, it compares the version of the dataset to the previous run, if it\u2019s unchanged, the process exits. Otherwise, notebooks are started up until a status step. At that point, kernelpipes will wait for all notebooks to complete before continuing.", "In the above configuration, cord-19-article-entry-dates starts and kernelpipes will check every minute until it\u2019s complete, then start the cord-19-analysis notebook and check for completion every 15 minutes. Once that is complete, the next series of notebooks are started in parallel and kernelpipes waits for all to complete and so on.", "This pipeline refreshes each time the CORD-19 dataset updates without any user action. It effectively enables a series of \u201cliving\u201d notebooks that continually are updated as new COVID-19 articles are added.", "The Kaggle platform brings a lot to the table in a number of different areas, this article just scratched the surface (micro-courses also look great). Overall, I\u2019ve been very impressed with the suite of capabilities and was able to engineer a complex, fully-automated data analysis pipeline. Keep these features in mind when building with Kaggle in the future!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Founder/CEO at NeuML \u2014 applying machine learning to solve everyday problems. Previously co-founded and built Data Works into a successful IT services company."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc745671d273e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c745671d273e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c745671d273e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@davidmezzetti?source=post_page-----c745671d273e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@davidmezzetti?source=post_page-----c745671d273e--------------------------------", "anchor_text": "David Mezzetti"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbd6fa5e6030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&user=David+Mezzetti&userId=bd6fa5e6030&source=post_page-bd6fa5e6030----c745671d273e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc745671d273e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc745671d273e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@lukechesser?utm_source=medium&utm_medium=referral", "anchor_text": "Luke Chesser"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge", "anchor_text": "COVID-19 Open Research Dataset (CORD-19)"}, {"url": "https://www.kaggle.com/notebooks", "anchor_text": "Kaggle Notebooks"}, {"url": "https://www.kaggle.com/notebooks", "anchor_text": "Kaggle Notebooks"}, {"url": "https://github.com/Kaggle/docker-python", "anchor_text": "Docker containers"}, {"url": "https://en.wikipedia.org/wiki/Graphics_processing_unit", "anchor_text": "GPUs"}, {"url": "https://en.wikipedia.org/wiki/Tensor_processing_unit", "anchor_text": "TPUs"}, {"url": "https://www.kaggle.com/davidmezzetti/cord-19-report-builder/", "anchor_text": "CORD-19 Report Builder notebook"}, {"url": "https://github.com/Kaggle/kaggle-api", "anchor_text": "full featured Python API"}, {"url": "https://github.com/Kaggle/kaggle-api#api-credentials", "anchor_text": "API has documentation"}, {"url": "https://github.com/neuml/kernelpipes", "anchor_text": "kernelpipes project"}, {"url": "https://en.wikipedia.org/wiki/YAML", "anchor_text": "YAML"}, {"url": "https://www.kaggle.com/learn/overview", "anchor_text": "micro-courses"}, {"url": "https://medium.com/tag/kaggle?source=post_page-----c745671d273e---------------kaggle-----------------", "anchor_text": "Kaggle"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c745671d273e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c745671d273e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----c745671d273e---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/software-development?source=post_page-----c745671d273e---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc745671d273e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&user=David+Mezzetti&userId=bd6fa5e6030&source=-----c745671d273e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc745671d273e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&user=David+Mezzetti&userId=bd6fa5e6030&source=-----c745671d273e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc745671d273e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c745671d273e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc745671d273e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c745671d273e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c745671d273e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c745671d273e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c745671d273e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c745671d273e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c745671d273e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c745671d273e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c745671d273e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c745671d273e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@davidmezzetti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@davidmezzetti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "David Mezzetti"}, {"url": "https://medium.com/@davidmezzetti/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "616 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbd6fa5e6030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&user=David+Mezzetti&userId=bd6fa5e6030&source=post_page-bd6fa5e6030--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F752e5f25d5d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-analysis-pipelines-with-kaggle-c745671d273e&newsletterV3=bd6fa5e6030&newsletterV3Id=752e5f25d5d1&user=David+Mezzetti&userId=bd6fa5e6030&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}