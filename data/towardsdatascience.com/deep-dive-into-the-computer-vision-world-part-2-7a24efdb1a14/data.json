{"url": "https://towardsdatascience.com/deep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14", "time": 1682997228.4903119, "path": "towardsdatascience.com/deep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14/", "webpage": {"metadata": {"title": "Deep Dive into the Computer Vision World: Part 2 | by Jiwon Jeong | Towards Data Science", "h1": "Deep Dive into the Computer Vision World: Part 2", "description": "This is the second story of \u201cDeep Dive into the Computer Vision world,\u201d and the complete set of the series is as follows: In the previous post, we discussed five popular networks, VGG, ResNet\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.huppelen.nl/publications/selectiveSearchDraft.pdf", "anchor_text": "the original paper", "paragraph_index": 7}, {"url": "https://stats.stackexchange.com/questions/208936/what-is-translation-invariance-in-computer-vision-and-convolutional-neural-netwo", "anchor_text": "What is translation invariant?", "paragraph_index": 21}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "LinkedIn", "paragraph_index": 25}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "https://www.linkedin.com/in/jiwon-jeong/", "paragraph_index": 26}], "all_paragraphs": ["This is the second story of \u201cDeep Dive into the Computer Vision world,\u201d and the complete set of the series is as follows:", "In the previous post, we discussed five popular networks, VGG, ResNet, Inception Network, Xception and MobileNet. These networks are now a major component in advanced networks, hence it\u2019s necessary to know their architectures.", "Now, we\u2019re going to the next page. From image classification to object detection. So far, what we\u2019ve discussed was one large convolutional neural network. Although they have many layers, they are one network at the end. But R-CNN and its variants that will be our focus, have this network as a part. A CNN is now a part of an entire \u201csystem\u201d processing more complex tasks such as object detection and image segmentation. Starting with R-CNN, we\u2019re going to see how these networks had been transformed and the underlying idea for the changes.", "Before we jump right into the R-CNN \u201cfamily,\u201d let\u2019s briefly check the basic idea of image classification and image detection. What\u2019s the difference between them? What additional work do we need to do for detecting objects in an image?", "First, whatever the number of classes we have, there is going to be an additional class- the background. An object detector is required to answer the question, \u201cis there an object?\u201d, which is not the case for image classification. Second, when there is an object, it\u2019s still not sufficient with \u201cyes, there is!\u201d (Quite ridiculous to imagine..\ud83d\ude05) It should also tell us, \u201cwhere is the object located?\u201d We need the position of the detected objects. This may sound simple but the implementation isn\u2019t. And when we take speed and efficiency challenges into account, things get even more complicated.", "Therefore object detection would be like.. looking for the regions of an object, localizing it and classifying what it is. Having this basic concept in mind, we\u2019re now ready to start the second topic from R-CNN.", "R-CNN answers the question, \u201cto what extent can the CNN classification results on ImageNet generalize to object detection results?\u201d So this network can be said to be the beginning of object detection family tree, which has great importance in the application of a neural network. The basic structure is composed of three steps-extracting region proposals, computing CNN, and classification.", "First, we extract some regions that seem promising to have an object from an input image. R-CNN used selective search for getting those regions of interest (ROI). Selective search is a region proposal algorithm that segments an image based on the intensity of the pixels. If you\u2019d like to get an in-depth understanding of Selective Search, here is the original paper. The basic idea is shown below. It first starts with the overly segmented picture and draws a bounding box around each segment. And based on their similarities in color, texture, size and shape compatibility, it keeps grouping adjacent ones and forming larger segments. R-CNN extracts around 2000 region proposals by this method and feeds them to the CNN. And this is the reason it is named R-CNN, Regions with CNN features.", "After getting the candidates, the second step is entering a large convolutional neural network. Each proposal is resized into a fixed size and is input into the CNN separately. R-CNN used AlexNet (It was 2014, there weren\u2019t ResNet or InceptionNet at that time) and we get 4096-dimensional feature vector from each proposal.", "And at the last step, the output extracted from the CNN is fed into a set of class-specific linear SVM models. We optimize one linear SVM per each class, and we get the output image with the bounding boxes whose score is higher than a threshold value. In case of having overlapping boxes, it only takes one by applying non-maximum suppression.", "One interesting part worth mentioning is how it overcame the data scarcity issue. The researchers had the challenge to train such a large network with only a small quantity of labeled data. And the solution was pre-training the CNN on a different data with labels (which is supervised learning), and then do fine-tuning with the original dataset.", "You may have noticed some inefficient parts that could be enhanced. The selective search is computation intensive. And processing the CNN for each ROI was repetitive work, which requires a huge amount of computation cost again. The need for the pre-training process and the separate classifiers were unattractive. And the storage for these models is too big. Although R-CNN was a milestone achievement, it had several drawbacks to be improved.", "Fast R-CNN is the next version of the previous work. What changes had been made here? Processing convolutional mapping repetitively was improved. The first change occurred at the repetitive convolution layers.", "Let\u2019s assume it takes N seconds to compute one single convolutional network. As R-CNN input 2000 RoI to the network separately, the total processing time will be 2000*N seconds. Instead of processing the CNN individually, now we do it only once by sharing the convolution with the proposals altogether.", "As you can see above, this network takes two data input, an original image and a set of the region proposals as input. The whole image feeds forward through the network to produce a feature map. With this feature map, each region proposal passes a pooling layer and fully connected layers to create a feature vector. Therefore, the convolutional computation is done once, not for each proposal.", "And the multiple classifiers are replaced with two sibling layers. One is a softmax function for classifying the object with the possibility estimates for each class, and the other is a bounding-box regressor returning the coordinates of the detected object. So the resulting feature vector is fed into these two layers and we get the outcome from the two layers.", "Now, this model made changes to share convolutions and to detach the additional classifiers. By merging \u201cmultiple bodies\u201d into one and taking off the \u201cheavy tail,\u201d we could achieve less computation and storage. This architecture allows us to train all the weights together, including even that of the softmax classifier and the multiple regressors. And this means the propagation will flow back and forth updating all the weights. Awesome progress! However, we still have a chance to get better performance.", "Still, Fast R-CNN was hard to be used in real time detection. And the major reason for such time delay stemmed from selective search. It had computation bottleneck and it needed to be replaced with a more efficient way. But how? How could we get region proposals without Selective Search? What about maximizing the usage of the ConvNet? Researchers found that the feature maps in Fast R-CNN also can be used for generating region proposals. Therefore by being free from Selective Search, much efficient network could be developed.", "Faster R-CNN is composed of two modules, Region Proposal Network (RPN) and Fast R-CNN. We first input an image to a \u201cmini-network\u201d and it will output the feature maps. By sliding a small window over the feature maps, we extract region proposals. And each proposal is fed into two sibling layers, a softmax classifier and a bounding-box regressor.", "These two layers may seem similar to the last layers of Fast R-CNN, but they are derived for a different purpose. For each proposal, the classifier estimates the probability of the presence of an object in an image. And the regressor returns the coordinates of the bounding box. So they are for generating candidates, not predicting the actual objects.", "We only take the proposals whose scores are higher than a threshold and input them with the feature map together to Fast R-CNN. The following steps are the same. They are input into a convolutional network and RoI pooling layers. And then the last layers will be a classifier and a regressor that finally predicts the real objects in images.", "One important property of this network is translation invariant, which is achieved by anchors and the way it computes proposals relative to the anchors. What is translation invariant? Simply put, it means we can detect an object regardless of its rotation, relocation, size change and what not. An object in an image can be at the center or the upper left. The same object can be at wide or long scale depending on the perspective. To prevent a model from failing to locate an object because of translation, we make anchor boxes of multiple scales and aspect ratios as in the picture shown above. These boxes are put at the center of the sliding window. So if there\u2019s K number of the boxes at a certain position, we get 2K scores and 4K coordinates of K boxes.", "In conclusion, at the Region Proposal Network, we slide a window with multiple anchor boxes over the feature map and evaluate each box by the classifier and the regressor. The proposals below the threshold are rejected, hence, feeding only the promising one to the next steps.", "More than that, this model optimized in 4 steps of alternative training by fine-tuning the layers unique to RPN and Fast R-CNN separately while fixing the shared layers. This allows the model to share weights forming a unified network and brought higher performance both in efficiency and accuracy. To compare the performance, The time for proposals of Faster R-CNN was 10 milliseconds per image (5 frames per second for the whole process), while 2 seconds for Selective Search using CPU.", "From R-CNN to Faster R-CNN, the networks got transformed removing dependence on other components. R-CNN could be enhanced by dropping linear SVMs and sharing convolution computations. And Fast R-CNN also changed to share the convolution to remove Selective Search. By integrating the whole process into one network, we could achieve higher accuracy as well as faster speed.", "Did this story resonate with you? Please share your insight with us. I\u2019m always open to talk, so feel free to leave comments below and share your thoughts. I also share interesting and useful resources on LinkedIn so feel free to follow and reach out to me. I\u2019ll be back with another interesting story, next time. As always, stay tuned!", "Data Science Researcher / Data geek \ud83e\udd13 Bookworm \ud83d\udcda Travel lover \ud83c\udf0f LinkedIn: https://www.linkedin.com/in/jiwon-jeong/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7a24efdb1a14&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@jiwon.jeong?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Jiwon Jeong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df293b5ca56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&user=Jiwon+Jeong&userId=1df293b5ca56&source=post_page-1df293b5ca56----7a24efdb1a14---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7a24efdb1a14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----7a24efdb1a14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a24efdb1a14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&source=-----7a24efdb1a14---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/deep-dive-into-the-computer-vision-world-f35cd7349e16?source=friends_link&sk=449ea5da20c884dadca23b907efb7e13", "anchor_text": "Starting from VGG, ResNet, Inception Network and MobileNet"}, {"url": "https://towardsdatascience.com/deep-dive-into-the-computer-vision-world-part-3-abd7fd2c64ef?source=friends_link&sk=876a90f05dcef8f9f0546b42adaec42d", "anchor_text": "YOLO, SSD and RetinaNet, more unified ones"}, {"url": "http://www.huppelen.nl/publications/selectiveSearchDraft.pdf", "anchor_text": "the original paper"}, {"url": "http://www.huppelen.nl/publications/selectiveSearchDraft.pdf", "anchor_text": "Selective Search for Object Recognition"}, {"url": "http://www.huppelen.nl/publications/selectiveSearchDraft.pdf", "anchor_text": "R-CNN architecture"}, {"url": "https://arxiv.org/pdf/1504.08083.pdf", "anchor_text": "Fast R-CNN architecture"}, {"url": "https://arxiv.org/pdf/1506.01497.pdf", "anchor_text": "Faster R-CNN architecture (left) and Region Proposal Network (right)"}, {"url": "https://stats.stackexchange.com/questions/208936/what-is-translation-invariance-in-computer-vision-and-convolutional-neural-netwo", "anchor_text": "What is translation invariant?"}, {"url": "http://www.huppelen.nl/publications/selectiveSearchDraft.pdf", "anchor_text": "Selective Search for Object Recognition"}, {"url": "https://arxiv.org/pdf/1311.2524.pdf", "anchor_text": "Rich feature hierarchies for accurate object detection and semantic segmentation"}, {"url": "http://Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition", "anchor_text": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"}, {"url": "https://arxiv.org/pdf/1504.08083.pdf", "anchor_text": "Fast R-CNN"}, {"url": "https://arxiv.org/pdf/1506.01497.pdf", "anchor_text": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"url": "https://arxiv.org/abs/1703.06870", "anchor_text": "Mask R-CNN"}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7a24efdb1a14---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----7a24efdb1a14---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----7a24efdb1a14---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7a24efdb1a14---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/object-detection?source=post_page-----7a24efdb1a14---------------object_detection-----------------", "anchor_text": "Object Detection"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7a24efdb1a14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----7a24efdb1a14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7a24efdb1a14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----7a24efdb1a14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a24efdb1a14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df293b5ca56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&user=Jiwon+Jeong&userId=1df293b5ca56&source=post_page-1df293b5ca56----7a24efdb1a14---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd0a222fc96e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&newsletterV3=1df293b5ca56&newsletterV3Id=d0a222fc96e6&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----7a24efdb1a14---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Written by Jiwon Jeong"}, {"url": "https://medium.com/@jiwon.jeong/followers?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "1.4K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "https://www.linkedin.com/in/jiwon-jeong/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df293b5ca56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&user=Jiwon+Jeong&userId=1df293b5ca56&source=post_page-1df293b5ca56----7a24efdb1a14---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd0a222fc96e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14&newsletterV3=1df293b5ca56&newsletterV3Id=d0a222fc96e6&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----7a24efdb1a14---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480?source=author_recirc-----7a24efdb1a14----0---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=author_recirc-----7a24efdb1a14----0---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=author_recirc-----7a24efdb1a14----0---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Jiwon Jeong"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7a24efdb1a14----0---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480?source=author_recirc-----7a24efdb1a14----0---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "The Most Intuitive and Easiest Guide for CNNDemystifying Convolutional Neural Network for complete starters"}, {"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480?source=author_recirc-----7a24efdb1a14----0---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "9 min read\u00b7Jan 24, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3607be47480&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----3607be47480----0-----------------clap_footer----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480?source=author_recirc-----7a24efdb1a14----0---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3607be47480&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480&source=-----7a24efdb1a14----0-----------------bookmark_preview----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7a24efdb1a14----1---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----7a24efdb1a14----1---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----7a24efdb1a14----1---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7a24efdb1a14----1---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7a24efdb1a14----1---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7a24efdb1a14----1---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7a24efdb1a14----1---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----7a24efdb1a14----1-----------------bookmark_preview----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7a24efdb1a14----2---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----7a24efdb1a14----2---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----7a24efdb1a14----2---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7a24efdb1a14----2---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7a24efdb1a14----2---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7a24efdb1a14----2---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7a24efdb1a14----2---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----7a24efdb1a14----2-----------------bookmark_preview----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/computer-vision-for-beginners-part-1-7cca775f58ef?source=author_recirc-----7a24efdb1a14----3---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=author_recirc-----7a24efdb1a14----3---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=author_recirc-----7a24efdb1a14----3---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Jiwon Jeong"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7a24efdb1a14----3---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/computer-vision-for-beginners-part-1-7cca775f58ef?source=author_recirc-----7a24efdb1a14----3---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "Computer Vision for Beginners: Part 1Introduction to OpenCV and Image Processing in Python"}, {"url": "https://towardsdatascience.com/computer-vision-for-beginners-part-1-7cca775f58ef?source=author_recirc-----7a24efdb1a14----3---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": "\u00b710 min read\u00b7Mar 13, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7cca775f58ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomputer-vision-for-beginners-part-1-7cca775f58ef&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----7cca775f58ef----3-----------------clap_footer----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/computer-vision-for-beginners-part-1-7cca775f58ef?source=author_recirc-----7a24efdb1a14----3---------------------e89c74fe_4432_4668_90aa_abfce372dd58-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7cca775f58ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomputer-vision-for-beginners-part-1-7cca775f58ef&source=-----7a24efdb1a14----3-----------------bookmark_preview----e89c74fe_4432_4668_90aa_abfce372dd58-------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "See all from Jiwon Jeong"}, {"url": "https://towardsdatascience.com/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----0-----------------clap_footer----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----7a24efdb1a14----0-----------------bookmark_preview----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----7a24efdb1a14----1-----------------bookmark_preview----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7a24efdb1a14----0---------------------a0d414a4_db01_469b_8a48_242c511f6630-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----7a24efdb1a14----0-----------------bookmark_preview----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://salvatore-raieli.medium.com/?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://salvatore-raieli.medium.com/?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Salvatore Raieli"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "META\u2019S SAM: A Unique Model to Segment AnythingSegmentation needs a foundation model: why is it important?"}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "\u00b714 min read\u00b7Apr 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fc3a956bf5d62&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fmetas-sam-a-unique-model-to-segment-anything-c3a956bf5d62&user=Salvatore+Raieli&userId=f1a08d9452cd&source=-----c3a956bf5d62----1-----------------clap_footer----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----7a24efdb1a14----1---------------------a0d414a4_db01_469b_8a48_242c511f6630-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc3a956bf5d62&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fmetas-sam-a-unique-model-to-segment-anything-c3a956bf5d62&source=-----7a24efdb1a14----1-----------------bookmark_preview----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/top-10-theoretical-practical-computer-vision-books-c32be0913104?source=read_next_recirc-----7a24efdb1a14----2---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----7a24efdb1a14----2---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----7a24efdb1a14----2---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Youssef Hosni"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----7a24efdb1a14----2---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/top-10-theoretical-practical-computer-vision-books-c32be0913104?source=read_next_recirc-----7a24efdb1a14----2---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Top 10 Theoretical & Practical Computer Vision BooksComputer vision is a subset of computer science that, simply, allows computers to see, comprehend, and analyze visual data. With computer\u2026"}, {"url": "https://medium.com/geekculture/top-10-theoretical-practical-computer-vision-books-c32be0913104?source=read_next_recirc-----7a24efdb1a14----2---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "\u00b714 min read\u00b7Dec 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Fc32be0913104&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Ftop-10-theoretical-practical-computer-vision-books-c32be0913104&user=Youssef+Hosni&userId=859af34925b7&source=-----c32be0913104----2-----------------clap_footer----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/top-10-theoretical-practical-computer-vision-books-c32be0913104?source=read_next_recirc-----7a24efdb1a14----2---------------------a0d414a4_db01_469b_8a48_242c511f6630-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc32be0913104&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Ftop-10-theoretical-practical-computer-vision-books-c32be0913104&source=-----7a24efdb1a14----2-----------------bookmark_preview----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----7a24efdb1a14----3---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----7a24efdb1a14----3---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----7a24efdb1a14----3---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----7a24efdb1a14----3---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----7a24efdb1a14----3---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----7a24efdb1a14----3---------------------a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----3-----------------clap_footer----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----7a24efdb1a14----3---------------------a0d414a4_db01_469b_8a48_242c511f6630-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----7a24efdb1a14----3-----------------bookmark_preview----a0d414a4_db01_469b_8a48_242c511f6630-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----7a24efdb1a14--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}