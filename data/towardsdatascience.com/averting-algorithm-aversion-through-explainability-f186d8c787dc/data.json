{"url": "https://towardsdatascience.com/averting-algorithm-aversion-through-explainability-f186d8c787dc", "time": 1683009834.9119391, "path": "towardsdatascience.com/averting-algorithm-aversion-through-explainability-f186d8c787dc/", "webpage": {"metadata": {"title": "Explainability Matters \u2014 Here\u2019s Proof | by Sanghamesh Vastrad | Towards Data Science", "h1": "Explainability Matters \u2014 Here\u2019s Proof", "description": "Imagine you\u2019re applying to grad school and the admissions committee at your dream university decides that admission decisions this year will be made by Machine Learning (ML) algorithms instead of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://dx.doi.org/10.2139/ssrn.2466040", "anchor_text": "2014", "paragraph_index": 4}, {"url": "https://dx.doi.org/10.2139/ssrn.2616787", "anchor_text": "2016", "paragraph_index": 4}, {"url": "https://www.kaggle.com/mohansacharya/graduate-admissions", "anchor_text": "Graduate Admissions", "paragraph_index": 9}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP", "paragraph_index": 12}, {"url": "https://www.qualtrics.com/", "anchor_text": "Qualtrics", "paragraph_index": 13}, {"url": "https://www.mturk.com/", "anchor_text": "Amazon MTurk", "paragraph_index": 13}, {"url": "http://rotman.az1.qualtrics.com/jfe/form/SV_eM710alg1gp99SB", "anchor_text": "The survey", "paragraph_index": 14}, {"url": "https://dx.doi.org/10.2139/ssrn.2466040", "anchor_text": "http://dx.doi.org/10.2139/ssrn.2466040", "paragraph_index": 29}, {"url": "https://www.linkedin.com/in/sanghamesh-vastrad/", "anchor_text": "LinkedIn", "paragraph_index": 30}], "all_paragraphs": ["Imagine you\u2019re applying to grad school and the admissions committee at your dream university decides that admission decisions this year will be made by Machine Learning (ML) algorithms instead of human reviewers. Would you be comfortable with ML algorithms evaluating you and making a decision? Some of us probably wouldn\u2019t want that. But why?", "Research shows that evidence-based algorithms (ML algorithms) more accurately predict the future than human forecasters. Algorithmic forecasts are seen to be superior to human forecasts in an array of applications, be it stock market forecasting or gameplay forecasting (in AlphaGo). Admission decisions can also be seen as a forecasting task as they are nothing but a prediction of how good a fit the candidate is to a particular program or a forecast of how successful the candidate will be. Yet, why do some of us want a human to evaluate us?", "If algorithms are better forecasters than humans, then people should choose algorithmic forecasts over human forecasts. However, they often don\u2019t. This phenomenon, which we call algorithm aversion, is costly, and it is important to understand its causes (Dietvorst, Simmons, and Massey, 2014).", "We know very little about when and why people exhibit algorithm aversion. There is no agreed-upon mechanism on when people use human forecasters instead of superior algorithms, or why people fail to use algorithms for forecasting. As the amount of data we produce daily has now reached a point where almost all forecasting tasks need some kind of an algorithm involved, it is important to tackle the problem of algorithm aversion so that most of us can rely on better-performing algorithms to forecast the future for us.", "Dietvorst, Simmons, and Massey (2014 and 2016) carried out several studies to find the causes of algorithm aversion. They found that:", "However, we know that providing control may not be possible in many cases. Thereby, we need to look at other options for overcoming or averting algorithm aversion.", "Modern forecasting algorithms are mostly seen as black boxes by a majority of the population as it involves a complex machine learning model, which very few understand. Add to this the fact that algorithm complexity and performance are seen to be inversely proportional to its explainability. For example, a linear regression model might be easy to interpret but might have poor performance. On the other hand, a neural network could have great performance but could be difficult to interpret at the same time. So, can explaining the model\u2019s predictions or understanding what the model has learned help overcome algorithm aversion? Let\u2019s find out!", "I conducted an online experiment to combine these two areas of model explainability and algorithm aversion to answer the broader question of the possible mechanism of algorithm aversion. In particular, I wanted to explore the question: What role does model explainability play in algorithm aversion and can explanations help in overcoming aversion towards algorithms? I operationalized the question by observing if people choose the same algorithm more frequently (or rate it higher) over human forecasters (themselves) if it comes along with explanations.", "Before beginning my experiment, I needed to choose a machine learning algorithm that would act as my forecaster/predictor. For training any machine learning algorithm, we require data, and in our case labeled data. For this purpose, I used an open dataset from Kaggle which is similar to the admissions scenario discussed above.", "To make sure that the participants aren\u2019t overwhelmed by numbers, I gave special importance to keeping the number of features/predictors to under ten during the process of dataset selection. The Graduate Admissions dataset has a \u2018chance of admit\u2019 measure ranging from 0 to 1 for each student profile along with the following 7 parameters:", "I converted the \u2019chance of admit\u2019 measure into \u2019Admission Score\u2019 by multiplying it by 100 so that it is easier for participants to play around with, i.e., they can enter whole numbers as predictions. \u2018Admission Score\u2019 can be thought of as the prediction of the success of the student or profile strength. The score ranges from 0\u2013100 and a higher score indicates higher chances of admit/profile strength. The dataset had 500 entries in total. The dataset was clean and didn\u2019t require any other major data preprocessing or data wrangling steps.", "I trained several models on the dataset and XGBoost was one of the best performing models. I decided to stick with XGBoost as the graduate admission predictor as I got good enough results even with minimum parameter tuning and preprocessing. After having the machine learning model ready, I had to choose a library to generate explanations for the algorithm\u2019s predictions. Thankfully, the machine learning community has been receptive to the problem of model explainability and has developed several new methodologies to explain machine learning models.", "One such explainer is SHAP (SHapley Additive exPlanations), a game-theoretic approach to explaining the output of any machine learning model. SHAP can produce explanations for individual rows showing features each contributing to pushing the model output from the base value. Summary plots and contribution dependence plots indicating overall model explanations can also be produced using the SHAP library. The following resources have been very helpful in understanding model explainability using SHAP and I recommend you check them out:", "The experiment was a simple randomized controlled experiment to check if adding explanations had any effect on the choices people made or how they perceived/rated the algorithm. It was built on the Qualtrics survey platform and participants were recruited on Amazon MTurk and outside of crowdsourcing platforms through friends and connections. The total number of participants was 445, with 350 participants from MTurk and the rest 95 from various sources. The participants had an average age of 30.76 years with around 43% of them being female and 57% male.", "The survey (Please take a look to get a better idea of the flow) started by asking the participants about their age, gender, and familiarity with probability, computer science, and machine learning on a scale of 1\u20134. This was for exploring the heterogeneity of treatment effects once the experiment is completed. Then, all participants were familiarized with the imaginary scenario of a Canadian University utilizing a machine learning algorithm in their admissions committee. Following that, participants were presented with the value of features for 10 applicants and asked to predict the Admission Score for them. After the participant scored each applicant, the participant\u2019s prediction was displayed alongside the algorithm\u2019s prediction if the participant belonged to the control group. For the treatment group, however, in addition to both the participant and the algorithm\u2019s prediction, an explanation of what features were affecting the model was displayed.", "Also, a participant in the treatment group had a page explaining about Shapley Values displayed before the 10 questions and a page with feature importance and the contribution dependence plots, i.e., overall model explanation displayed after the 10 questions.", "The control group (without explanation) and the treatment group (with explanation) had 227 and 218 participants respectively, each of who were randomized at the start of the survey. Once these questions were completed, the participants were asked a set of follow-up questions regarding what they saw. Three questions were particularly focused on in this section:", "These questions represented scenarios where the outcome of the algorithm (i)had a direct impact on the participants, (ii)the participants were accountable for the algorithm\u2019s outcomes, and (iii)a general rating without any connection to them respectively.", "The following results were observed for the three follow up questions mentioned in the experiment design section:", "1. When applying for admissions, i.e., when the algorithm\u2019s forecast had an impact on them, the percentage of participants choosing ML Algorithm in the control group, without explanations was 48.13% and in the treatment group, with explanations was 49.78%.", "2. When present in the admissions committee, i.e., when the algorithm eased their job but held them accountable, the percentage of participants choosing ML Algorithm in the control group, without explanations was 47.95% and in the treatment group, with explanations was 49.50%.", "3. When asked to rate the algorithm in general, participants in the control group rated it 70.81 out of 100 on average, while participants in the treatment group gave it an average score of 71.07. The Cohen\u2019s d value for the two groups was 0.016.", "From the above results, we can see that there is a pretty distinct difference between the two groups. In questions 1 and 2, a higher percentage of participants chose to use the algorithm when it came along with the SHAP explanations. Also, in question 3, Cohen\u2019s d value of 0.016 shows that the difference between the means is positive and in favour of the group with explainability, but the effect size is very small. Overall, a larger sample size would make conclusions and effect size a lot clearer.", "Heterogeneity of Treatment Effects: Like for any other experiment, I explored the heterogeneity of treatment effects amongst the participants on three grounds: age, gender, and familiarity with probability, computer science, and machine learning. The treatment effect was the same across all age groups. Gender didn\u2019t play a role in determining the algorithm score as well.", "When we look at the algorithm score or the way the participants perceived the algorithm, the overall difference wasn\u2019t much. However, when we look at the subgroups based on their familiarity with probability, computer science, and machine learning, the results we as follows.", "An important observation was that the algorithm score given by the participants without a technical background (i.e., who had never heard of Probability, Computer Science and Machine Learning) is always higher in the treatment group with explanations, compared to the control group without explanations. The Cohen\u2019s d value also increases significantly for this subgroup, suggesting that there is a large positive effect on how people rate algorithms with explanations compared to a sheer number presented to them.", "Through this experiment, I tried to find empirical proof that algorithm aversion can be overcome by explainability. It holds good in cases where the participants were the ones being affected by the algorithm\u2019s predictions and also in cases where the participants were the ones accountable for its accuracy. In further experiments, the heterogeneity of treatment effects should be the primary focus. We can focus specifically on non-STEM (Science, Technology, Engineering, and Math) participants with additional questions to understand their reason for choosing the way they did. If we can prove the external validity of this experiment on a much larger dataset, simple methodologies like SHAP can be incorporated in our daily machine learning forecasters to help people avert algorithm aversion!", "The world is moving towards \u2018Explainable AI\u2019 and many see it as a necessity for deep learning algorithms now. This experiment only proves that such steps are necessary for the process of building trust towards algorithms.", "Even though algorithm aversion isn\u2019t a big problem, for now, it is a problem we need to tackle with all seriousness. Although we might think of today\u2019s forecasting tasks as simply a grad school admission problem or a house price estimation task; it will be the task of forecasting the speed of the truck in front of you on a self-driving car tomorrow. It is inevitable for algorithms to take over such tasks where human lives are at stake, be it healthcare or space exploration. No matter what the scenario, we need to find a way through which we can build trust in these algorithms. Therefore, it is very encouraging to see the machine learning community working towards this problem by taking explainability as seriously as complexity in our path of innovation.", "[1] Dietvorst, Berkeley and Simmons, Joseph P. and Massey, Cade, Algorithm Aversion: People Erroneously Avoid Algorithms after Seeing Them Err (July 6, 2014). Forthcoming in Journal of Experimental Psychology: General. Available at SSRN: http://dx.doi.org/10.2139/ssrn.2466040", "Please feel free to comment with your feedback and suggestions on the post or connect with me on LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist at Google | MSc in Applied Computing (Data Science), University of Toronto"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff186d8c787dc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sanghamesh-vastrad.medium.com/?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": ""}, {"url": "https://sanghamesh-vastrad.medium.com/?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "Sanghamesh Vastrad"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F34ab04053782&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&user=Sanghamesh+Vastrad&userId=34ab04053782&source=post_page-34ab04053782----f186d8c787dc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff186d8c787dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff186d8c787dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@coleito?utm_source=medium&utm_medium=referral", "anchor_text": "Cole Keister"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://dx.doi.org/10.2139/ssrn.2466040", "anchor_text": "2014"}, {"url": "https://dx.doi.org/10.2139/ssrn.2616787", "anchor_text": "2016"}, {"url": "https://towardsdatascience.com/guide-to-interpretable-machine-learning-d40e8a64b6cf", "anchor_text": "Source"}, {"url": "https://www.kaggle.com/mohansacharya/graduate-admissions", "anchor_text": "Graduate Admissions"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "https://www.kaggle.com/learn/machine-learning-explainability", "anchor_text": "Learn Machine Learning Explainability TutorialsExtract human-understandable insights from any machine learning model.www.kaggle.com"}, {"url": "https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d", "anchor_text": "One Feature Attribution Method to (Supposedly) Rule Them All: Shapley ValuesAmong the papers that caught my eye at NIPS was this one, that made the lofty claim to have discovered a framework\u2026towardsdatascience.com"}, {"url": "https://www.qualtrics.com/", "anchor_text": "Qualtrics"}, {"url": "https://www.mturk.com/", "anchor_text": "Amazon MTurk"}, {"url": "http://rotman.az1.qualtrics.com/jfe/form/SV_eM710alg1gp99SB", "anchor_text": "The survey"}, {"url": "https://dx.doi.org/10.2139/ssrn.2466040", "anchor_text": "http://dx.doi.org/10.2139/ssrn.2466040"}, {"url": "https://dx.doi.org/10.2139/ssrn.2616787", "anchor_text": "http://dx.doi.org/10.2139/ssrn.2616787"}, {"url": "https://doi.org/10.1038/s42256-019-0138-9", "anchor_text": "https://doi.org/10.1038/s42256-019-0138-9"}, {"url": "https://www.linkedin.com/in/sanghamesh-vastrad/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----f186d8c787dc---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f186d8c787dc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f186d8c787dc---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f186d8c787dc---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/a-b-testing?source=post_page-----f186d8c787dc---------------a_b_testing-----------------", "anchor_text": "A B Testing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff186d8c787dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&user=Sanghamesh+Vastrad&userId=34ab04053782&source=-----f186d8c787dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff186d8c787dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&user=Sanghamesh+Vastrad&userId=34ab04053782&source=-----f186d8c787dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff186d8c787dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff186d8c787dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f186d8c787dc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f186d8c787dc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f186d8c787dc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f186d8c787dc--------------------------------", "anchor_text": ""}, {"url": "https://sanghamesh-vastrad.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sanghamesh-vastrad.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sanghamesh Vastrad"}, {"url": "https://sanghamesh-vastrad.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "31 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F34ab04053782&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&user=Sanghamesh+Vastrad&userId=34ab04053782&source=post_page-34ab04053782--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5a72ac14491f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faverting-algorithm-aversion-through-explainability-f186d8c787dc&newsletterV3=34ab04053782&newsletterV3Id=5a72ac14491f&user=Sanghamesh+Vastrad&userId=34ab04053782&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}