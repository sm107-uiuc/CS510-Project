{"url": "https://towardsdatascience.com/predicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc", "time": 1683009109.6784809, "path": "towardsdatascience.com/predicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc/", "webpage": {"metadata": {"title": "Predicting Forest Cover Type with Tensorflow and model deployment in GCP | by Dipika Baad | Towards Data Science", "h1": "Predicting Forest Cover Type with Tensorflow and model deployment in GCP", "description": "Data used in this project is from Kaggle competition of forest cover type. Although this is not an active competition on Kaggle, this fit right into my criteria of numerical/categorical data to make\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/forest-cover-type-prediction/data", "anchor_text": "Kaggle competition of forest cover type.", "paragraph_index": 1}, {"url": "https://www.kaggle.com/dipikabaad0107/forest-cover-classification", "anchor_text": "Kaggle", "paragraph_index": 4}, {"url": "https://www.tensorflow.org/overview", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data/Dataset", "anchor_text": "tensorflow dataset", "paragraph_index": 16}, {"url": "https://www.tensorflow.org/tutorials/structured_data/feature_columns", "anchor_text": "building the input pipeline", "paragraph_index": 16}, {"url": "https://cloud.google.com/ai-platform/training/docs/runtime-version-list", "anchor_text": "here", "paragraph_index": 31}, {"url": "https://cloud.google.com/ai-platform/prediction/docs/custom-prediction-routines", "anchor_text": "here", "paragraph_index": 32}, {"url": "https://github.com/dipikabaad/Forest_Cover_Type_Classification", "anchor_text": "my repository", "paragraph_index": 32}, {"url": "https://github.com/dipikabaad/Forest_Cover_Type_Classification", "anchor_text": "Github repository", "paragraph_index": 36}, {"url": "https://towardsdatascience.com/reflecting-and-comparing-different-sentiment-classification-models-for-restaurant-reviews-d109105b2cb7", "anchor_text": "my previous articles", "paragraph_index": 38}], "all_paragraphs": ["In this post, I will share:", "Data used in this project is from Kaggle competition of forest cover type. Although this is not an active competition on Kaggle, this fit right into my criteria of numerical/categorical data to make predictions which is easy to work with so we could focus on building the model in Tensorflow and also to build a small pipeline for GCP. Details of the data are provided on their data description page. Data is provided by US Geological Survey and USFS (Forest Service). Seven types of forest cover types will be predicted in this problem:", "1 \u2014 Spruce/Fir2 \u2014 Lodgepole Pine3 \u2014 Ponderosa Pine4 \u2014 Cottonwood/Willow5 \u2014 Aspen6 \u2014 Douglas-fir7 \u2014 Krummholz", "I will dive into solving this problem with the following steps:", "Download the data from above Kaggle competition and store it in your google drive or locally in an appropriate folder. Set your folder path to FOLDER_NAME variable. In my case, I am storing the data in google drive and using Google Colab to read the input files. If you wish to write the code in Kaggle notebooks, you can follow the code I have published on Kaggle along with this article. The changes are only in the cases of loading and storing data in case of Kaggle notebook.", "Let\u2019s get started with Google Colab by mounting the drive:", "This will give a link to get code and you need to enter that into input box presented. Once that is done, we are ready to load the data in dataframe.", "Train dataset has 15120 rows. From the describe table, it can be seen that the soil type 7 and 15 have constant 0 values so it should be removed. Some of the columns having numerical values except the categorical columns (Soil_Types and Wilderness_Areas ) should be normalized to get better results. In the next step, we will do all the preprocessing steps to make the data ready for prediction.", "Category data columns of all soil types would be merged into one column from one hot coded form and similarly wilderness area column would be converted as well.", "Soil Type 8 and 25 had only one row per type so they were converted to another column with NA subscript. This is optional, you can drop those columns too.", "For numerical columns, MinMaxScaler is the transformer that will be applied to get normalised columns. Before we do that, we need to split the data into train, test and validation so that the data is normalised for those pieces of data.", "Data will be split into train, validation and test. Train having 60%, test 20% and validation 20%.", "Once the data is split, normalisation can be applied as follows:", "Tensorflow is Google\u2019s open source deep learning library based on Theano (Python library) which is used in research as well as production. Some of the core components that you need to know are tensor and graph. Tensor is a vector or matrix of n-dimensional in which data will be stored and functions would be performed. Graph is where all the operations and connections between nodes are described and can be run on multiple CPUs or GPUs.", "In this post, I would be explaining how I created my first model using Tensorflow and not so much into very basics of tensorflow. If you are interested in learning, you can go through basic tutorials from here. I must admit going through Tensorflow documentation wasn\u2019t as easy as PyTorch. With PyTorch I was able to build my first model within a week but with Tensorflow documentation it is hard to understand what is the right way to load data itself and on top of that there are conflicts between function formats and it\u2019s backward compatibility with other versions. Hence following tutorials will end up in other errors that are not always easy to solve.", "Install tensorflow in your machine or Google Colab. I have used Google Colab with GPU runtime. Tensorflow 2 is used in this problem.", "After all the processing, we will get the data into tensorflow dataset. This will help in building the input pipeline for model. For the dataset, batch_size has to be defined which is the size in which the data can be accessed in batches rather than at once. Optionally you can shuffle the rows as well.", "Model will be built with tensorflow Keras having feed forward neural architecture. Feature layer is built with tensorflow Keras layers.DenseFeatures. Categorical and numerical columns are handled separately for creating this input layer which is shown in the code. Model is defined in build_model function with two hidden layers of 100 and 50 followed by output layer containing the number of output neurons to 8. It is 8 since the types are integer values from 1\u20138 rather than 0\u20137. In confusion matrix we ignore the class 0. Optimizer adam is used and activation function relu is used. Code for building model and pipeline is as follows:", "For training, we provide the training and validation dataset to model\u2019s fit function. Validation loss makes it easier to look out for overfitting of the model during training. Model is trained for 100 epochs.", "In the output, it was clear that the network is learning based on train accuracy increasing along side validation accuracy. If at some point the validation accuracy was increasing while training accuracy was increasing, that\u2019s the point where the model would have been overfitting. That way you can know to stop the epochs at that point. If it is random then the model is not learning anything. With the architecture designed, I got a good accuracy of ~85% for train and ~84% for validation set.", "In model summary, you can see the number of parameters at each layer. In the first hidden layer, 51 input features are connected to 100 hidden nodes with 5100 weights for the fully connected network and 100 bias params for each node which adds up to 5200 params. In the next layer, 100 nodes connected to 50 nodes with 5000 connections with 50 bias params for each node in second hidden layer making up to 5050 params. Similarly, the next number of params are calculated. This is how you read the model summary. It shows how many total params are learned at the end. Model at the end is saved to a directory.", "To test how the model works on test data, we will classification report from sklearn. Classification report would show precision, recall and f1-score for each forest cover type as well as average accuracy and so on.", "The average accuracy of ~80% was achieved with this model. This was a good enough result with a simple architecture of feed forward neural network. Now we can get the results for kaggle test dataset using the model and submit it to kaggle.", "We need to predict the cover type for test data given on kaggle. This data is in the same folder as the data downloaded in the first step. Output expected is csv file with Id and Cover_Type columns. Similar transformations done on train data has to be done on test data. Following code shows how to get the results for test data:", "Once you have the file ready, you can upload it in my submissions section on Kaggle competition page. Once submitted you can see the score after a while. After the submission, I got the accuracy of ~62% on the test data. You can do as many submission as possible with different experiments and try to increase this score. That\u2019s all, you can start participating in different competitions and experiment with different kinds of dataset. I started mine with simple prediction problem having numeric/categorical data. My goal was to learn Tensorflow with a real world example so I started with Kaggle dataset of competition which was not active but it had simple problem to work with.", "Model saved in the previous section can be used to deploy in google cloud so that it can be accessible by any application you have. I am considering that you have basic knowledge about Google Cloud and you have worked on it a little bit. As I would not be explaining, how to get started with GCP (there are many beginner courses on that in coursera / GCP Qwiklabs which you can take).", "You can create a free google cloud account which has 300$ free credits if you don\u2019t have yet. We would need that in the next steps. Also install the GCP SDK on your computer. Create a project in Google Cloud if there isn\u2019t any. Make sure to have a service account key downloaded in IAM and store in environment variable. (Refer to Google Cloud documentation for basic setup to interact with GCP via command console)", "Run the following command to authenticate with Google Cloud account and set the project by given instructions in the output.", "As a first step, upload the folder forest_model_layer_100_50_epoch_100 from the previous section to Google Cloud Storage. I created a bucket forest-cover-model and uploaded the folder in that location.", "Once that is done, you are ready to deploy the model.", "This is needed before deploying model.", "The v7 version was the one that worked after some experiments for me. You can start with v1 as version name. This way you can keep different versions of the model. Runtime versions which are suitable can be found here. Origin parameter is the path to the google storage path where model is stored.", "Initially I was planning to make custom prediction routine with preprocessor classes etc. but unfortunately after creating all of that, at the time of deployment I got to know that it only works for tensorflow>=1.13,<2. It is evolving so it might be that it will support in future, check here for updates. ( Code for the custom pipeline exists in my repository which I have shared for those who are interested)", "To test the model deployed, you can browse to the AI Platform > Models and click on the version number you want to test under the model name. There is Test & Use option where you can give custom input. The input format is as follows, use the following example for testing.", "You can see the output as follows:", "Output gives probabilities for each cover type for input.", "Once this is all working fine, you can use the model to do predictions for any input data. I have shared the code in the Github repository. The file forest_classification.py contains the code for calling the model and input pipeline.", "I had split the input data into small chunks since it failed to return results for all the rows at once. These are the things that you need to manage in applications and so on. You can refer to that if you are interested in exploring how to create a pipeline for model deployed in GCP.", "Tadaa! You are ready to use the model in practical solution with versioning maintained for various experiments and track the performances based on that. In the real world, apart from just building a model, these skills are very important. For fun, you can try to see how these pipelines are built in other cloud environments if that\u2019s what you prefer. If you wish to experiment with how to optimize the model with various parameters or other optimizing functions then you can refer to my previous articles where I have suggested improvements/other opportunities for building models in deep neural networks. Although that was for PyTorch, the basics of changing architectures and parameters remain the same regardless of which framework you use. You will have to just find ways of defining and doing the same stuff in other libraries. Hope this helps you to get started on GCP and Kaggle as well as Tensorflow framework!", "As always \u2014 Happy experimenting and learning :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Big Data Consultant @Netlight | CoFounder @HuskyCodes | Web developer | Passionate about coding, dancing, reading"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffbce9c047dcc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://dipikabaad.medium.com/?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": ""}, {"url": "https://dipikabaad.medium.com/?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "Dipika Baad"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb4f6856d71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&user=Dipika+Baad&userId=cb4f6856d71b&source=post_page-cb4f6856d71b----fbce9c047dcc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffbce9c047dcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffbce9c047dcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/u/cb4f6856d71b?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "Dipika Baad"}, {"url": "https://www.kaggle.com/c/forest-cover-type-prediction/data", "anchor_text": "Kaggle competition of forest cover type."}, {"url": "https://www.kaggle.com/dipikabaad0107/forest-cover-classification", "anchor_text": "Kaggle"}, {"url": "https://www.tensorflow.org/overview", "anchor_text": "here"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data/Dataset", "anchor_text": "tensorflow dataset"}, {"url": "https://www.tensorflow.org/tutorials/structured_data/feature_columns", "anchor_text": "building the input pipeline"}, {"url": "https://cloud.google.com/ai-platform/training/docs/runtime-version-list", "anchor_text": "here"}, {"url": "https://cloud.google.com/ai-platform/prediction/docs/custom-prediction-routines", "anchor_text": "here"}, {"url": "https://github.com/dipikabaad/Forest_Cover_Type_Classification", "anchor_text": "my repository"}, {"url": "https://github.com/dipikabaad/Forest_Cover_Type_Classification", "anchor_text": "Github repository"}, {"url": "https://towardsdatascience.com/reflecting-and-comparing-different-sentiment-classification-models-for-restaurant-reviews-d109105b2cb7", "anchor_text": "my previous articles"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----fbce9c047dcc---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/gcp?source=post_page-----fbce9c047dcc---------------gcp-----------------", "anchor_text": "Gcp"}, {"url": "https://medium.com/tag/kaggle?source=post_page-----fbce9c047dcc---------------kaggle-----------------", "anchor_text": "Kaggle"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----fbce9c047dcc---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----fbce9c047dcc---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffbce9c047dcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&user=Dipika+Baad&userId=cb4f6856d71b&source=-----fbce9c047dcc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffbce9c047dcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&user=Dipika+Baad&userId=cb4f6856d71b&source=-----fbce9c047dcc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffbce9c047dcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffbce9c047dcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fbce9c047dcc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fbce9c047dcc--------------------------------", "anchor_text": ""}, {"url": "https://dipikabaad.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://dipikabaad.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dipika Baad"}, {"url": "https://dipikabaad.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "294 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb4f6856d71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&user=Dipika+Baad&userId=cb4f6856d71b&source=post_page-cb4f6856d71b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1b12599791a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-forest-cover-type-with-tensorflow-and-model-deployment-in-gcp-fbce9c047dcc&newsletterV3=cb4f6856d71b&newsletterV3Id=1b12599791a9&user=Dipika+Baad&userId=cb4f6856d71b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}