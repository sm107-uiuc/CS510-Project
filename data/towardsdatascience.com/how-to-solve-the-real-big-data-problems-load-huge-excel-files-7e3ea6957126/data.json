{"url": "https://towardsdatascience.com/how-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126", "time": 1683008768.8461802, "path": "towardsdatascience.com/how-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126/", "webpage": {"metadata": {"title": "How to Solve the Real Big Data Problems - Load Huge Excel Files | by Shravankumar Suvarna | Towards Data Science", "h1": "How to Solve the Real Big Data Problems - Load Huge Excel Files", "description": "More and more companies have started to realize the importance of data. Hence, they come with requests to load huge CSV or Excel files from their legacy systems or manual processes to a database for\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pandas.pydata.org/", "anchor_text": "pandas", "paragraph_index": 0}, {"url": "https://dask.org/", "anchor_text": "dask", "paragraph_index": 0}, {"url": "https://pypi.org/project/vaex/", "anchor_text": "vaex", "paragraph_index": 0}, {"url": "https://www.stats.govt.nz/assets/Uploads/Business-price-indexes/Business-price-indexes-March-2020-quarter/Download-data/business-price-indexes-march-2020-quarter-csv.csv", "anchor_text": "link", "paragraph_index": 6}, {"url": "https://docs.djangoproject.com/en/3.0/topics/db/models/", "anchor_text": "Django Models", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Create,_read,_update_and_delete", "anchor_text": "CRUD", "paragraph_index": 14}], "all_paragraphs": ["More and more companies have started to realize the importance of data. Hence, they come with requests to load huge CSV or Excel files from their legacy systems or manual processes to a database for data-driven analytics. I know, we now have a lot of solutions to solve this problem like pandas, dask, vaex python libraries or tools like Informatica etc.", "However, it\u2019s always fun to learn different approaches to solve a problem statement. We will be using PDI to solve this problem statement and use PostgreSQL as our database. The idea here will be to optimally utilize our system capabilities. I know not all of us have the perk of memory-optimized servers at our disposal.", "If you are new to data pipeline building process, then I will recommend you to go through the below story.", "I like to define the user stories for our problem statement first. This helps me design the high-level architecture for the data pipeline. We need to always break the problem in small easy individual pieces.", "We are trying to replicate the real-world scenario by adding a little complexity of data manipulation as well.", "It is a good practice to understand the input data files. Now, in our case, it might be difficult to open huge CSV files and check the columns and rows. However, there are methods by which we can determine or check sample data. PDI provides you to read sample data and check other metadata by creating a small transformation.", "Here, I Googled the term \u2018huge data file in csv\u2019 and downloaded the file from the first website. Here\u2019s the link.", "Now, I wanted to crash the system and create huge file; like we are dealing with Big Data, right? The downloaded file had 66,526 records, so I appended the same records multiple times to create a huge file with around 11,974,697 records; yeah not that big.", "Defining test cases are important here since we cannot manually check the entire data. We need to make sure, we check good enough sample data to cross-validate the accuracy.", "We have a pretty simple project set up for this project. Just one directory and one transformation file.", "I prefer to create all the work-related projects in one single project directory named \u2018Work\u2019; I know, how creative! We need to perform the below; you can skip this step.", "If you are not aware of the words like transformations or job, then I will recommend the below-mentioned story.", "I am assuming that you have the database already installed here. We are using PostgreSQL.", "Now, I prefer to create tables using Django Models. You don\u2019t necessarily have to use this methodology.", "Having said so, it makes our life easy by writing Django models instead of manually creating tables and column natively. Django models does that for us using the simple migrations command and also get CRUD (create, read, update and delete) functionality out of the box.", "You can choose below mentioned two options to create the database and table. I have create a table medium_db", "If you are interested in understanding how we can benefit from Django in our data pipeline, then please do let me know the same in the response section below.", "We have our table ready. Now, let create our transformation.", "We need to create a loader transformation which read our input CSV, perform manipulation and load the data onto the database.", "We need to open our Main.ktr file and drag some plugin as mentioned below.", "Now that we have configured the properties, we can speed the process by creating multiple threads for inserting data. This will boost the performance. PDI provides us with the facility to configure multi-threading per steps. If we use it in an input step, it will multiply the records. Whereas, if we use it for output steps like database, it will distribute the records.", "PDI provides us with many options to optimize the performance. We can perform the below steps to boost the performance.", "Wow! we have so many options, should we change all the performance optimizer? Short answer is NO. We need to try with sample data and perform multiple tests on what works best for us.", "Let\u2019s run the flow without performance optimizer and then compare it by applying the optimizer.", "We reduced the time taken by almost 50% to perform the same activity by adding some simple performance optimizer.", "If we want to read multiple files and create a loop to process the same, then I will recommend you to go through the below story.", "We took a problem statement and tried solving it using multiple approaches and tried optimizing it as well. In theory, you can apply this process to fit your requirement and try to optimize it further as well. PDI provides us with PostgreSQL bulk loader step as well; I have tried that step as well. However, there was not any significant performance booster provided by the same.", "We cannot optimize the code/pipeline at the beginning and will have to perform multiple tests to get the ideal results. However, to shorten the learning curve you can always read through my experiences and find solutions to the problem statement by subscribing to my email list using the below link.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Constantly learning about new technologies. Nobody."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7e3ea6957126&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@shravankumar.suvarna?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shravankumar.suvarna?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "Shravankumar Suvarna"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F77216d1e856b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&user=Shravankumar+Suvarna&userId=77216d1e856b&source=post_page-77216d1e856b----7e3ea6957126---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e3ea6957126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e3ea6957126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pandas.pydata.org/", "anchor_text": "pandas"}, {"url": "https://dask.org/", "anchor_text": "dask"}, {"url": "https://pypi.org/project/vaex/", "anchor_text": "vaex"}, {"url": "https://unsplash.com/@ev?utm_source=medium&utm_medium=referral", "anchor_text": "ev"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/swlh/build-your-first-data-pipeline-in-just-ten-minutes-2a490867b901", "anchor_text": "Build Your First Data Pipeline in just Ten MinutesStep-by-step process to build your first data pipeline with a real-world use case using PDI.medium.com"}, {"url": "https://medium.com/ai-in-plain-english/pentaho-data-integration-installation-guide-easy-yet-powerful-etl-tool-80930cff46c6", "anchor_text": "link"}, {"url": "https://www.enterprisedb.com/downloads/postgres-postgresql-downloads", "anchor_text": "link"}, {"url": "https://www.stats.govt.nz/assets/Uploads/Business-price-indexes/Business-price-indexes-March-2020-quarter/Download-data/business-price-indexes-march-2020-quarter-csv.csv", "anchor_text": "link"}, {"url": "https://medium.com/ai-in-plain-english/getting-started-with-pentaho-data-integration-kettle-and-its-components-ef1e71101323", "anchor_text": "Getting Started with Pentaho Data Integration (Kettle) and its Components.Understanding the key components like Spoon, Pan, Kitchen, etc will enable us to get a better idea about the PDI toolmedium.com"}, {"url": "https://docs.djangoproject.com/en/3.0/topics/db/models/", "anchor_text": "Django Models"}, {"url": "https://en.wikipedia.org/wiki/Create,_read,_update_and_delete", "anchor_text": "CRUD"}, {"url": "https://wiki.pentaho.com/display/eai/user+defined+java+expression", "anchor_text": "similar"}, {"url": "https://towardsdatascience.com/how-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042", "anchor_text": "How to Automate Multiple Excel Workbooks and Perform AnalysisApply this step-by-step guide to solve the problem using PDI with Magical Metadata Injection.towardsdatascience.com"}, {"url": "https://wryteex.com/", "anchor_text": "WryteEx - Platform to Find Solutions using Real World Use CasesI write blogs on Data Engineering, Finance, Python, Python Django, Project Management, Web Development and Many More\u2026wryteex.com"}, {"url": "https://medium.com/tag/programming?source=post_page-----7e3ea6957126---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7e3ea6957126---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/optimization?source=post_page-----7e3ea6957126---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7e3ea6957126---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/big-data?source=post_page-----7e3ea6957126---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e3ea6957126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&user=Shravankumar+Suvarna&userId=77216d1e856b&source=-----7e3ea6957126---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e3ea6957126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&user=Shravankumar+Suvarna&userId=77216d1e856b&source=-----7e3ea6957126---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e3ea6957126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7e3ea6957126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7e3ea6957126---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7e3ea6957126--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7e3ea6957126--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7e3ea6957126--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shravankumar.suvarna?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shravankumar.suvarna?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Shravankumar Suvarna"}, {"url": "https://medium.com/@shravankumar.suvarna/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "156 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F77216d1e856b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&user=Shravankumar+Suvarna&userId=77216d1e856b&source=post_page-77216d1e856b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3bf0723f2733&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-solve-the-real-big-data-problems-load-huge-excel-files-7e3ea6957126&newsletterV3=77216d1e856b&newsletterV3Id=3bf0723f2733&user=Shravankumar+Suvarna&userId=77216d1e856b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}