{"url": "https://towardsdatascience.com/some-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a", "time": 1683010467.008256, "path": "towardsdatascience.com/some-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a/", "webpage": {"metadata": {"title": "Some Call it Genius, Others Call it Stupid: The Most Controversial Neural Network Ever Created | by Andre Ye | Towards Data Science", "h1": "Some Call it Genius, Others Call it Stupid: The Most Controversial Neural Network Ever Created", "description": "Some believe that the Extreme Learning Machine is one of the smartest neural network inventions ever created \u2014 so much so that there\u2019s even a conference dedicated exclusively to the study of ELM\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126", "anchor_text": "Universal Approximation Theorem", "paragraph_index": 3}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership", "paragraph_index": 21}], "all_paragraphs": ["Some believe that the Extreme Learning Machine is one of the smartest neural network inventions ever created \u2014 so much so that there\u2019s even a conference dedicated exclusively to the study of ELM neural network architectures. Proponents of ELMs argue that it can perform standard tasks at exponentially faster training times, with few training examples. On the other hand, besides from the fact that it\u2019s not big in the machine learning community, it\u2019s got plenty of criticism from experts in deep learning, including Yann LeCun, who argue that it\u2019s gotten far more publicity and credibility than it deserves.", "Mostly, people seem to think it\u2019s an interesting concept.", "An ELM architecture is composed of two layers; the first is randomly initialized and fixed, whereas the second is trainable. Essentially, the network randomly projects the data into a new space and performs a multiple regression (then passing it through an output activation function, of course). The random projection entails a dimensionality reduction (or enlargement) method, which multiplies random matrices by the input \u2014 although the idea may sound odd, pulling randomly from strategic distributions can actually work very well (as we\u2019ll see with an intuitive analogy later). It applies a random distortion of sorts that applies noise \u2014 in a good way, if done correctly \u2014 and lets the remainder of the network to adapt, opening up new doors in terms of learning opportunities.", "In fact, it is because of this randomness that Extreme Learning Machines have been shown to possess Universal Approximation Theorem powers with relatively small nodes in the hidden layer.", "In fact, the idea of random projections have been explored early in the field of neural network development, in the 1980s and 1990s, under that name \u2014 which is the reasoning behind one critique that ELMs are nothing new; just old research packaged under a new name. Many other architectures like echo state machines and liquid state machines also utilize random skip connections and other sources of randomness.", "Perhaps the largest difference, however, between ELMs and other neural network architectures is that it doesn\u2019t use backpropagation. Instead, since the trainable half of the network is simply a multiple regression, the parameters are trained in roughly the same way coefficients are fitted in regression. This represents a fundamental shift in the way neural networks are thought to be trained.", "Almost every neural network developed since the vanilla artificial neural network has been optimized using iterative updating (or call it tuning, if you\u2019d like) by bouncing information signals forward and backward throughout the network. Because this method has been around for so long, one must assume that it\u2019s been tried and tested as the best one, but researchers acknowledge that standard backpropagation has many issues, like being very slow to train or falling into very luring local minima.", "On the other hand, ELM uses a much more mathematically involved formula to set weights, and without going too deeply into the math, one can think of using the random layer as compensating for more computationally expensive details that it would otherwise be replaced with. If it helps, technically, the wildly successful Dropout layer is a sort of random projection.", "Because ELMs employ both randomness and a no-backpropagation algorithm, they are exponentially faster to train than standard neural networks.", "Whether they perform better or not, on the other hand, is another question.", "One could make the argument that ELMs are more reflective of how humans learn than standard neural networks (although both are far) in that it can solve simpler tasks very quickly with only a few examples, but iterative neural networks need to run through, at the very least, tens of thousands of samples to generalize and perform well. Humans may have their weaknesses in comparison to machines, but their vast superiority in learning-to-examples ratio (examples being the number of training examples they are exposed to) is what makes us truly intelligent.", "The concept of the Extreme Learning Machine is very simple \u2014 so simple that some people may call it stupid. Yann LeCun, the great computer scientist and deep learning pioneer, declared that \u201cconnecting the first layer randomly is just about the stupidest thing you could do,\u201d following this argument by listing more developed methods to non-linearly transform the dimensionality of vectors, such as kernel methods used in SVM, which are further strengthened via positioning with backpropagation.", "In essence, LeCun says, the ELM is essentially an SVM, with a worse transformation kernel; the limited scope of problems that ELM is able to address would probably be better modelled with an SVM. The only rebuttal to this would be computational efficiency using a \u2018random kernel\u2019 instead of a specialized ones, as SVMs are notoriously high-power models; although whether it is worth a decrease in performance ELM may bring is another discussion to be had.", "Yet, like the ELM or not \u2014 empirically, using random projections or filters in simple neural networks and other models have shown to perform shockingly well on a variety of (now, considered \u2018simple\u2019) standard training tasks, like MNIST. While these performances are not top-of-the-class, the fact that an architecture who has drawn so much scrutiny and whose concept almost comes across as ridiculous can edge itself up there on the leaderboard with state-of-the-art neural networks \u2014 in addition, with a much more lightweight architecture and an exponentially smaller computational bill \u2014 is something, at the very least, to be considered interesting.", "Why would using fixed random connections work?", "It\u2019s the million dollar question: evidently, something with the random connections in the ELM is working if it performs just as well, if not better, than a vanilla backprop-neural network. While the mathematics of it is unintuitive, the author of the original Extreme Learning Machine paper, Guang Bin-Huang, told a parable to, illustrate the concept (edited for language, conciseness, and drawing deep learning parallels):", "You want to fill up a lake with rocks until you get a horizontal surface filled with stones instead of water, and you can see the bottom of the empty lake, which is a curve (function representing the data). The engineer carefully calculates the size of the lake, the sizes of stones to fill it, and a plethora of other small factors that play a role in optimizing the task. (Optimizing many parameters that go into fitting the function.)", "The rural farmer, on the other hand, blows up the nearby mountain and begins throwing or pushing the rocks that fall off into the lake. When the rural farmer picks up a stone (hidden layer node), he doesn\u2019t need to know what the size of the lake or the size of the stone is \u2014 he just randomly throws them and spreads the rocks over. If rocks begin piling above the surface in one area, the farmer takes a hammer and smashes it (beta parameter \u2014 regularization of sorts), levelling the surface.", "While the engineer is still calculating heights and volumes of the rocks and the shape of the lake, the farmer has already filled up the lake. To the farmer, it doesn\u2019t matter how many rocks he threw: he got the job done faster.", "Although this analogy has a few issues in direct application of differing scenarios, it is an intuitive explanation of the nature of the ELM and the role randomness plays in the model. The essence of ELM is that being na\u00efve isn\u2019t always a bad thing: simpler solutions may be able to address less complex problems better.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML enthusiast. Join Medium through my referral link: https://andre-ye.medium.com/membership."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2224ed22795a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2224ed22795a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2224ed22795a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://andre-ye.medium.com/?source=post_page-----2224ed22795a--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=post_page-----2224ed22795a--------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006----2224ed22795a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2224ed22795a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2224ed22795a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126", "anchor_text": "Universal Approximation Theorem"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2224ed22795a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----2224ed22795a---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----2224ed22795a---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2224ed22795a---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2224ed22795a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2224ed22795a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&user=Andre+Ye&userId=be743a65b006&source=-----2224ed22795a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2224ed22795a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&user=Andre+Ye&userId=be743a65b006&source=-----2224ed22795a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2224ed22795a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2224ed22795a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2224ed22795a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2224ed22795a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2224ed22795a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2224ed22795a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2224ed22795a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2224ed22795a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2224ed22795a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2224ed22795a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2224ed22795a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2224ed22795a--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://andre-ye.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.8K Followers"}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff44a966e4ff1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsome-call-it-genius-others-call-it-stupid-the-most-controversial-neural-network-ever-created-2224ed22795a&newsletterV3=be743a65b006&newsletterV3Id=f44a966e4ff1&user=Andre+Ye&userId=be743a65b006&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}