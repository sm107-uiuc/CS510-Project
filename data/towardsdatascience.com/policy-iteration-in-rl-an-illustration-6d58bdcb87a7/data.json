{"url": "https://towardsdatascience.com/policy-iteration-in-rl-an-illustration-6d58bdcb87a7", "time": 1683005158.129899, "path": "towardsdatascience.com/policy-iteration-in-rl-an-illustration-6d58bdcb87a7/", "webpage": {"metadata": {"title": "Policy Iteration in RL: A step by step Illustration | by Raghuveer Bhandarkar | Towards Data Science", "h1": "Policy Iteration in RL: A step by step Illustration", "description": "Overview of Policy Iteration algorithm in ReInforcement Learning."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Policy Iteration\u00b9 is an algorithm in \u2018ReInforcement Learning\u2019, which helps in learning the optimal policy which maximizes the long term discounted reward. These techniques are often useful, when there are multiple options to chose from, and each option has its own rewards and risks.", "In this article, we are going to apply the \u2018Policy Iteration\u2019 algorithm to a simple game involving some pirates who will have to reach their destination, amidst risky and beneficial situations.", "Let us consider a pirate ship, which is currently anchored at an island and, has to reach its homeland safely. There are two routes it could choose from.", "If it takes the route to the north, then it can reach an island which is full of gold, which it can collect, and then move south to reach the homeland. However, there is an area with a very high gravity (like the Bermuda triangle) to the north of the gold island. If the ship reaches there by mistake, then it will be sucked into it and the ship is lost forever.", "If it takes the route to the south, then it can reach an island, which is full of silver, which it can collect, and then move north to reach the homeland. There is a prison island to the south of the silver island. If the ship lands there by mistake, then the ship will be captured and the crew will be imprisoned.", "All looks good so far, however, there is a twist in the game. There is no fun if our life is deterministic. Let\u2019s introduce stochasticity into the game.", "Remember Jack Sparrow, in the \u2018Pirates of the Caribbean\u2019 movie?!. Let us say our ship\u2019s captain possesses a broken compass, similar to the one possessed by Jack. So, every time, the captain makes a move towards north, he moves north with a probability of 0.8, however, he might miss the mark and reach south with a probability of 0.2. Similarly, if he moves south, there is a 0.8 probability of going south and 0.2 probability of going north.", "Let us assign some rewards to each of the ship\u2019s landing.", "Given this context, our goal is to find the optimal policy for the ship to reach its homeland safely with maximum rewards.", "There are three steps in Policy Iteration\u00b9:", "Policy is a mapping of an action to every possible state in the system\u00b2. An optimal policy is that policy which maximizes the long term reward\u00b2. Thus, for this example, we can have multiple policies. i.e, multiple set of actions at each state (island), however, there is probably only one policy which gives us final maximum reward. Our goal is to find that optimum policy.", "Randomly initialize the policy. Initialize actions randomly at every state of the system.", "Step 2 is based on Bellman\u2019s equation which is provided below\u00b9:", "Get action for every state in the policy and evaluate the value function using the above equation. Here is p is the transition probability, also denoted by T.", "For every state, get the best action from value function using:", "If the best action is better than the present policy action, then replace the current action by the best action.", "Iterate steps 2 and 3, until convergence. If the policy did not change throughout an iteration, then we can consider that the algorithm has converged.", "The first thing to do is to understand the states and actions and build a state transition diagram. In our example, each island is a state and there are two actions, \u2018north\u2019 and \u2018south\u2019. Rewards for each state is as outlined in the above illustration. Based on these facts, we can build a state transition diagram as below:", "There are six states including start and destination states and four intermediary islands where they can hop on. Let us label the states from S1 to S6 as follows:", "Since the game is stochastic, we need to compute transition probabilities for each state/action pair. Based on the probabilities provided above and the state transition diagram, we can draw this up as below. Note that there are two actions and we need a transition probability matrix for both of these actions. Note that while applying Bellman\u2019s equation, T(S, a, S\u2019) refers to the transition probability of moving from state S to state S\u2019 after taking an action \u2018a\u2019.", "With this information at hand, let us apply the above-mentioned algorithm step by step. We can assume the discounted factor (gamma) to be 1.", "Let us randomly initialize the policy (state to action mapping) as moving north for all states.", "If we observe the state transition diagram, the states S4, S5, S6 do not have any actions supported in these states, as these are end states. So let us curtail our policy to apply to only the first three states where we can take an action.", "Let us assume the initial value V(s) for all states as 0. Thus, the Bellman equation would reduce to V(s) = R(s), where R(s) is the reward for entering a state.", "Let us apply the equation provided above for Policy Improvement.", "The policy obtained based on the above table is as follows:", "Policy Evaluation for the second iteration:", "The values for each state could be summarized as below:", "The policy obtained based on above table is as follows:", "Values for each state could be summarized as below:", "The policy obtained based on above table is as follows:", "If we compare this policy, to the policy we obtained in second iteration, we can observe that policies did not change, which implies algorithm has converged and this is the optimal policy.", "We have obtained the optimal policy as {South, South, North} by applying the algorithm. If we observe the example, it might be tempting to go north initially as gold island has more rewards, but it is fraught with risk, as we might lose 2 points and end the game. So, it is better to sacrifice short term rewards and take the south route which eventually maximizes our long term reward.", "I hope this illustration helps in better understanding the algorithm.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning, Architecture, Georgia Tech Alumni."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6d58bdcb87a7&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://raghumb.medium.com/?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": ""}, {"url": "https://raghumb.medium.com/?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "Raghuveer Bhandarkar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faf43977391fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&user=Raghuveer+Bhandarkar&userId=af43977391fa&source=post_page-af43977391fa----6d58bdcb87a7---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d58bdcb87a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d58bdcb87a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/AnnaliseArt-7089643/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3946618", "anchor_text": "Annalise Batista"}, {"url": "https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3946618", "anchor_text": "Pixabay"}, {"url": "https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html", "anchor_text": "https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6d58bdcb87a7---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----6d58bdcb87a7---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6d58bdcb87a7---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/policy-iteration?source=post_page-----6d58bdcb87a7---------------policy_iteration-----------------", "anchor_text": "Policy Iteration"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6d58bdcb87a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&user=Raghuveer+Bhandarkar&userId=af43977391fa&source=-----6d58bdcb87a7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6d58bdcb87a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&user=Raghuveer+Bhandarkar&userId=af43977391fa&source=-----6d58bdcb87a7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d58bdcb87a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6d58bdcb87a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6d58bdcb87a7---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6d58bdcb87a7--------------------------------", "anchor_text": ""}, {"url": "https://raghumb.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://raghumb.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Raghuveer Bhandarkar"}, {"url": "https://raghumb.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "14 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faf43977391fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&user=Raghuveer+Bhandarkar&userId=af43977391fa&source=post_page-af43977391fa--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9126fa9a4d9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-iteration-in-rl-an-illustration-6d58bdcb87a7&newsletterV3=af43977391fa&newsletterV3Id=9126fa9a4d9c&user=Raghuveer+Bhandarkar&userId=af43977391fa&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}