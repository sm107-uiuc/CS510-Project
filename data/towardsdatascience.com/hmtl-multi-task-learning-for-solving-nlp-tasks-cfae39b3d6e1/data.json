{"url": "https://towardsdatascience.com/hmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1", "time": 1682994058.108835, "path": "towardsdatascience.com/hmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1/", "webpage": {"metadata": {"title": "HMTL - Multi-task Learning for solving NLP Tasks | by Rani Horev | Towards Data Science", "h1": "HMTL - Multi-task Learning for solving NLP Tasks", "description": "The field of Natural Language Processing includes dozens of tasks, among them machine translation, named-entity recognition, and entity detection. While the different NLP tasks are often trained and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1811.06031.pdf", "anchor_text": "HMTL", "paragraph_index": 1}, {"url": "https://huggingface.co/hmtl/", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT", "paragraph_index": 13}, {"url": "https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/", "anchor_text": "here", "paragraph_index": 13}], "all_paragraphs": ["The field of Natural Language Processing includes dozens of tasks, among them machine translation, named-entity recognition, and entity detection. While the different NLP tasks are often trained and evaluated separately, there exists a potential advantage in combining them into one model, i.e., learning one task might be helpful in learning another task and improve its results.", "Hierarchical Multi-Task Learning model (HMTL) provides an approach to learn different NLP tasks by training on the \u201csimple\u201d tasks first, and using the knowledge to train on more complicated tasks. The model presents state-of-the-art performance in several tasks and an in-depth analysis of the importance of each part of the model, from different aspects of the word embeddings to the order of the tasks.", "Several papers from recent years showed that combining multiple NLP tasks can generate better and deeper representation of text. For example, identifying entities in a sentence, such as names of locations or people, can help with finding mentions of them in subsequent sentences. However, not all NLP tasks are related, and it\u2019s essential to select relevant tasks that can be beneficial for other tasks.", "The HMTL model focuses on four different tasks: Named Entity Recognition, Entity Mention Detection, Coreference Resolution, Relation Extraction.", "The following text illustrates the difference between the tasks (a great demo can be found here):\u201cWhen we were in Spain, my mom taught me how to drive with a car. She also explained how to fuel it\u201d", "All four tasks are related to identifying entities in a text and the relations between them, with different levels of complexity \u2014 while NER is the simplest one, CR and RE require a deeper understanding of the text. Therefore, learning one task might help learn others.", "HMTL is a hierarchical model in which initially simpler tasks, such as NER, are learned, and their results are then used to train the following tasks. Each task is built from three components: Word embeddings, Encoder, and Task-specific layer.", "The base of the model is the word representation that embeds each word from the input sentence into a vector using three models:", "In addition, each task is trained with a dedicated encoder \u2014 a multi-layer recurrent neural network that generates word embeddings tailored for the task. The encoder is implemented using bidirectional GRU-cells networks and its output is a concatenation of the last layer of the forward and backward networks. The input of the encoder consists of the base word representation and the output of the previous task\u2019s encoder (when available).", "On top of the encoders, each task uses a different neural network as described below:", "One of the challenges in training a hierarchical model is catastrophic forgetting, in which training new tasks causes the model to \u201cforget\u201d previous tasks and achieve a degraded performance on them. HMTL deals with catastrophic forgetting by randomly picking one of the previous tasks during the current task\u2019s training (after each parameters update), and training the model on a random sample from the random task dataset. The probability of picking a task for training isn\u2019t uniform but proportional to the size of its dataset, a technique which the authors found to be more effective.", "The model was trained on several datasets for comparison, with two key datasets \u2014 OntoNotes 5.0 for NER and ACE05 for the rest of the tasks. ACE05 was used in two configurations \u2014 regular and Gold Mentions (GM), with the GM configuration consisting of two parts:", "The paper claims state-of-the-art results in Entity Mention Detection (EMD) and Relation Extraction (RE) by training the full model using the Gold Mention (GM) configuration. According to the paper, using the GM configuration in training improves the F1-score of the CR task by 6 points, while it improves the EMD and RE tasks by 1\u20132 points.", "The paper also claims to achieve state-of-the-art results in Named-Entity Recognition, although it seems that the recent BERT model reached slightly better results. However, it\u2019s hard to compare the two since the HMTL model wasn\u2019t fine-tuned for the dataset used by BERT. A summary of BERT can be found here.", "Another interesting result from the paper is a reduction in the required training time to reach the same performance. The full model (with GM) needs less time than most single tasks \u2014 NER (-16%), EMD (-44%) and CR (-28%) \u2014 while requiring more time than RE (+78%).", "A possible concern regarding the GM configuration is \u201cinformation leakage\u201d- due to the different split, records that are used for training one task might later be used as a test for another task. The knowledge regarding those records might be stored in one of the shared layers, allowing for artificially improved results.", "Task CombinationsTo gain a deeper understanding of the hierarchical approach, the paper compares the results of different combinations of tasks without the GM configuration, as shown in the table below (F1 scores of several configurations). It appears that the contribution of multi-task training is inconclusive and depends on the task:", "Word representationAs mentioned previously, the base of the model is the word representation, which consists of three models \u2014 GloVe, ELMo and Character-level word embeddings. The selection of these models also has a significant effect on the model performance, as shown in the table below. Elmo embeddings and character-level embeddings add 2\u20134 points each to the F-1 score of most tasks.", "The paper presents an interesting technique of combining seemingly separate NLP tasks and techniques to achieve top results in language analysis. The results emphasize the need for further research into the field as it\u2019s currently difficult to understand when a specific NLP task can be useful to improve results in an unrelated NLP task.", "Special thanks to Victor Sanh, one of the paper\u2019s authors, for valuable insights on the workings of HMTL.", "Learn something new every day. Currently Deep Learning :)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcfae39b3d6e1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@ranihorev?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Rani Horev"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8----cfae39b3d6e1---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcfae39b3d6e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----cfae39b3d6e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcfae39b3d6e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&source=-----cfae39b3d6e1---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arxiv.org/pdf/1811.06031.pdf", "anchor_text": "HMTL"}, {"url": "https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-rdc-v4.3.2.PDF", "anchor_text": "here"}, {"url": "https://huggingface.co/hmtl/", "anchor_text": "here"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe"}, {"url": "https://allennlp.org/elmo", "anchor_text": "ELMo"}, {"url": "https://gluebenchmark.com/leaderboard", "anchor_text": "GLUE Benchmark"}, {"url": "http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1707.07045.pdf", "anchor_text": "the model"}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT"}, {"url": "https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1811.06031.pdf", "anchor_text": "Sanh et al."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----cfae39b3d6e1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----cfae39b3d6e1---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----cfae39b3d6e1---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcfae39b3d6e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----cfae39b3d6e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcfae39b3d6e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----cfae39b3d6e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcfae39b3d6e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8----cfae39b3d6e1---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9bc3579798b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&newsletterV3=53f9e9fdd8d8&newsletterV3Id=9bc3579798b7&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----cfae39b3d6e1---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Written by Rani Horev"}, {"url": "https://medium.com/@ranihorev/followers?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "1.7K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8----cfae39b3d6e1---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9bc3579798b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1&newsletterV3=53f9e9fdd8d8&newsletterV3Id=9bc3579798b7&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----cfae39b3d6e1---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----cfae39b3d6e1----0---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----cfae39b3d6e1----0---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----cfae39b3d6e1----0---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Rani Horev"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cfae39b3d6e1----0---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----cfae39b3d6e1----0---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "BERT Explained: State of the art language model for NLPAn approachable and understandable explanation of BERT, a recent paper by Google that achieved SOTA results in wide variety of NLP tasks."}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----cfae39b3d6e1----0---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "7 min read\u00b7Nov 10, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff8b21a9b6270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----f8b21a9b6270----0-----------------clap_footer----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270?source=author_recirc-----cfae39b3d6e1----0---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "29"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8b21a9b6270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270&source=-----cfae39b3d6e1----0-----------------bookmark_preview----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cfae39b3d6e1----1---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----cfae39b3d6e1----1---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----cfae39b3d6e1----1---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cfae39b3d6e1----1---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cfae39b3d6e1----1---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cfae39b3d6e1----1---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cfae39b3d6e1----1---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----cfae39b3d6e1----1-----------------bookmark_preview----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cfae39b3d6e1----2---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----cfae39b3d6e1----2---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----cfae39b3d6e1----2---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cfae39b3d6e1----2---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cfae39b3d6e1----2---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cfae39b3d6e1----2---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cfae39b3d6e1----2---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----cfae39b3d6e1----2-----------------bookmark_preview----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----cfae39b3d6e1----3---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----cfae39b3d6e1----3---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=author_recirc-----cfae39b3d6e1----3---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Rani Horev"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cfae39b3d6e1----3---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----cfae39b3d6e1----3---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "Explained: A Style-Based Generator Architecture for GANs - Generating and Tuning Realistic\u2026NVIDIA\u2019s novel architecture for Generative Adversarial Networks"}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----cfae39b3d6e1----3---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": "9 min read\u00b7Dec 30, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cb2be0f431&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----6cb2be0f431----3-----------------clap_footer----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431?source=author_recirc-----cfae39b3d6e1----3---------------------d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cb2be0f431&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431&source=-----cfae39b3d6e1----3-----------------bookmark_preview----d4dbc6a3_2982_41ec_80cc_7f613d1e9d1b-------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "See all from Rani Horev"}, {"url": "https://towardsdatascience.com/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Skanda Vivek"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Fine-Tune Transformer Models For Question Answering On Custom DataA tutorial on fine-tuning the Hugging Face RoBERTa QA Model on custom data and obtaining significant performance boosts"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "\u00b75 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&user=Skanda+Vivek&userId=220d9bbb8014&source=-----513eaac37a80----0-----------------clap_footer----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&source=-----cfae39b3d6e1----0-----------------bookmark_preview----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----cfae39b3d6e1----1-----------------bookmark_preview----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "LucianoSphere"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Build ChatGPT-like Chatbots With Customized Knowledge for Your Websites, Using Simple ProgrammingLike ChatGPT but in a form that you can plug into your website and expand with any kind of tailored information by combining basic\u2026"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "\u00b711 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&user=LucianoSphere&userId=d28939b5ab78&source=-----f393206c6626----0-----------------clap_footer----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----cfae39b3d6e1----0---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&source=-----cfae39b3d6e1----0-----------------bookmark_preview----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cfae39b3d6e1----1---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----cfae39b3d6e1----1-----------------bookmark_preview----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----cfae39b3d6e1----2---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----cfae39b3d6e1----2---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----cfae39b3d6e1----2---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----cfae39b3d6e1----2---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----cfae39b3d6e1----2---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----cfae39b3d6e1----2---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----2-----------------clap_footer----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----cfae39b3d6e1----2---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----cfae39b3d6e1----2-----------------bookmark_preview----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----cfae39b3d6e1----3---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----cfae39b3d6e1----3---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----cfae39b3d6e1----3---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----cfae39b3d6e1----3---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----cfae39b3d6e1----3---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----cfae39b3d6e1----3---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----3-----------------clap_footer----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----cfae39b3d6e1----3---------------------b5d849f7_cc22_466d_a454_184d41b9bafc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----cfae39b3d6e1----3-----------------bookmark_preview----b5d849f7_cc22_466d_a454_184d41b9bafc-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----cfae39b3d6e1--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}