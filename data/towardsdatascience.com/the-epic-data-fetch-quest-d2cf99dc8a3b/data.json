{"url": "https://towardsdatascience.com/the-epic-data-fetch-quest-d2cf99dc8a3b", "time": 1683013997.778031, "path": "towardsdatascience.com/the-epic-data-fetch-quest-d2cf99dc8a3b/", "webpage": {"metadata": {"title": "The Epic Data Fetch Quest. It\u2019s dangerous to go alone! Take this. | by Randy Au | Towards Data Science", "h1": "The Epic Data Fetch Quest", "description": "Special thanks to the person on twitter who messaged me with this question and is letting me use it as a starting point of a post. Poking at real scenarios is real fun, and I can always take a bit of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://twitter.com/Randy_Au/status/1235991970230816768", "anchor_text": "your chances of failure", "paragraph_index": 8}, {"url": "https://panoply.io/data-warehouse-guide/data-warehouse-architecture-traditional-vs-cloud/", "anchor_text": "well-known patterns", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Athena#Birth", "anchor_text": "fully formed from your forehead, ready to provide wisdom to the world", "paragraph_index": 15}, {"url": "https://aws.amazon.com/training/course-descriptions/data-warehousing/", "anchor_text": "cloud", "paragraph_index": 29}, {"url": "https://cloud.google.com/solutions/marketing-data-warehouse-on-gcp", "anchor_text": "service", "paragraph_index": 29}, {"url": "https://azure.microsoft.com/en-us/solutions/data-warehouse/", "anchor_text": "provider", "paragraph_index": 29}, {"url": "https://www.cooladata.com/cost-of-building-a-data-warehouse/", "anchor_text": "Those", "paragraph_index": 34}, {"url": "https://aws.amazon.com/getting-started/projects/deploy-data-warehouse/services-costs/#:~:text=Using%20the%20default%20configuration%20recommended,usage%20of%20each%20individual%20service.", "anchor_text": "bills", "paragraph_index": 34}, {"url": "https://support.office.com/en-us/article/excel-specifications-and-limits-1672b34d-7043-467e-8e27-269d656771c3", "anchor_text": "Excel only supports ~1 million rows per worksheet", "paragraph_index": 34}, {"url": "http://www.catb.org/~esr/writings/taoup/html/ch01s06.html", "anchor_text": "fairly UNIX-y", "paragraph_index": 38}, {"url": "https://counting.substack.com", "anchor_text": "Counting Stuff", "paragraph_index": 43}], "all_paragraphs": ["Special thanks to the person on twitter who messaged me with this question and is letting me use it as a starting point of a post. Poking at real scenarios is real fun, and I can always take a bit of creative liberty in anonymizing details.", "I recently became a data analyst at a company. It looks like I need to do a lot of organization database creation work first. A lot of data is in Excel files in different systems. I want to gather everything, organize it, make it queryable and visualizable for users. Do you have any advice for a DB, tools, ways to design?", "So there\u2019s two parts to this question: 1) the overt question: things to do if I was going to embark on such an epic quest to increase my chances of success, and 2) the implied question: is the best thing to do right now?", "The general form that problems like this resemble a big RPG game, you\u2019re dropped into a brand new world, everything is shiny and important-seeming, and lacking any stronger storyline quests thrust upon you by the gods, you are sent to fetch objects from all over the world in exchange for unspecified rewards. This is how I wind up spending a hundred hours doing side-quests and level grinding, which may be good as a leisure activity, but perhaps not ideal for your career.", "I think people with some project management experience behind them are likely to have some alarm bells going off in their head \u201cWarning! Unbounded scope!\u201d", "So let\u2019s go into it, from most important questions first:", "This is probably the key question for this endeavor. There are ways to be effective and impactful without embarking on a giant mission with no true end.", "Putting everything into \u201cone centralized place that everyone shares and is more powerful\u201d is a seemingly natural goal to have. \u201cEverything is so hard right now because it\u2019s scattered around. It takes work to put things together to even begin doing analysis work, this is why everything is horrible!\u201d", "Such projects are also, in my personal experience, where projects go to die. I firmly believe that the second you attach the term \u201cdata warehouse\u201d to a project, your chances of failure go up a ton. And I say this as someone who has designed and built/prototyped three of the damned things in my career. I hope there isn\u2019t a fourth.", "The reason DW projects are hard has little to do with technical difficulty. They all fit well-known patterns. The tech part is relatively easy.", "The main reason these projects are hard is because the assumptions ignore the very human part of why things came to be as \u201cmessy\u201d as they are in the first place. The desire for a grand \u201clet\u2019s sweep all the ugliness away and get everyone on the same page!\u201d vision partly stems from not understanding that disparate systems were created by different people to fulfill a specific set of needs. Those systems then evolved until they worked reasonably well for their limited scopes. But because they were never coordinated at the beginning, getting them to work together now comes with a huge human cost.", "Every input dataset has these things:", "It takes a lot of skill, patience, and resources to work with all these people and get the desired result. Many of those skills have nothing to do with software development or data analysis. So when you\u2019re thinking about gathering literally everything into one system, this is what you\u2019re signing up for.", "You\u2019ll be working with Alice from engineering to get access the analytics side of production systems, and have to debug all the data issues there as you use the system. You\u2019ll then talk to Bob of customer support to learn about the 3rd party support ticketing system with custom in-house tooling, and the engineer maintaining it left last month. Then Eve from finance is totally swamped working on the Series B preparation and doesn\u2019t have time to explain how any of the financial data works this quarter.", "Once you overcome the hurdles, understand, and merge all these data sources together into once place. You\u2019re then trapped maintaining the system because you\u2019re the only one who knows how the thing works and no one is invested in keeping it up to date.", "Nothing says a data warehouse must spring forth, fully formed from your forehead, ready to provide wisdom to the world. As I went into above, to do so is generally fatal. You might call it, head-splitting. Instead, by invoking the time honored project management spell of \u201climiting scope\u201d there are ways to survive.", "While any organization will have a many functions and processes within it, an endless sea of analytic possibilities, there should be only a small handful of core functions that everything else supports. Whether it\u2019s production of widgets or sales of subscriptions, some things are inherently more important than others. If it significantly threatens the life of the business when it goes bad, it\u2019s probably worthy of attention.", "Identify those systems, and think of some good analyses that could help people understand them better. The goal is to build out something that supports just those core business questions first. It could be understanding costs, sales, repeat sales, getting new customers, keeping current customers, etc. It is most likely not how many coffee filters are used every month in the office (I\u2019m sure you can find some data on this in the office manager\u2019s data.)", "More often than not, the data that surrounds those core business questions are located in only a small handful of systems. They might even be on a single system, because this is the core of the business and everything grew up around the core. You only really want to work on a single system at a time at the best, and up to two systems at the absolute worst.", "Now that your scope is limited down to a handful of questions targeting a handful of questions, the next thing you need to do is work on doing some basic analysis.", "Pick a question, whatever makes you feel excited. You\u2019re going to need that motivation for the next step. You\u2019re going to make a one-off analysis to examine that question. Maybe it\u2019s about customer retention, or time-to-sale, or cost of customer acquisition. Go through the actual mechanics of getting the data, understanding how it works, and most importantly, using the data to create an artifact that someone else finds useful.", "You\u2019re going to learn so much about how those systems work just by doing this, it will make the rest of the process easier. You\u2019ll most likely have to talk to people, ask them what various bits of data mean, where are things unreliable, where can data collection be improved. You\u2019ll find weird bugs in the data that will break your analysis pipelines. It will take surprisingly longer than you would expect, even to do the hackiest, jankiest, throw-away analysis. You will likely be fixing bugs for weeks along the way.", "But do not despair, this is all work you would have had to do to build the data warehouse to begin with, but now you are doing it for a concrete purpose instead of a vague abstract system in the future. There is an end in sight with a single deliverable.", "Finally, once you create your analysis result, you can show people. Hopefully they\u2019re excited about what you created because it helped them understand something better, or offered insight. They might even have follow-up questions that you\u2019ll have to go analyze further. But guess what you just did? You\u2019ve built excitement for your project. You\u2019ve shown them how you can help them, and they\u2019re going to be a lot more willing to help you in the future if you need them to change their data processes for your data warehouse.", "Now that you\u2019ve actually done an analysis end-to-end, you should be familiar enough with the system to have a decent idea of how to automate it. So go ahead and do it.", "You\u2019re going to find new issues and hiccups when you do. The most important one being \u201cwait, how do I automate this stuff, on what system?\u201d If you\u2019re the first person, there may not be any infrastructure for this. Time to put on your data engineer hat and figure stuff out (while working together w/ the operations folk).", "This is when you can start evaluating your technical needs. Do you use a simple relational database? (Answer: yes in 99% of cases). What languages do you want to use? Who\u2019s responsible for keeping the systems up?", "There\u2019s a huge amount of details and potential choices to be made here. The only thing I can stress is, consult your engineering partners! You want to avoid being the odd one out.", "If you\u2019re the only person who knows R and everyone else is using Java, please don\u2019t use R without a super, important, pressing reason. Doing so means volunteering to either be the only person to maintain the system forever, or you have to teach others a language they don\u2019t know. This applies to your other infrastructure too. If you\u2019re a SQL Server shop, don\u2019t spin up a PostgreSQL instance without a good reason.", "Luckily, data warehouse solutions are plentiful. Every cloud service provider offers entire solutions that can cost as much money as you\u2019re wiling to spend. You can spin up your own using open source tech, including just a simple PostgreSQL database. Pick what works for your environment and budget.", "Once you do all this stuff and you finally finish automating, congratulations, you\u2019ve created a data pipeline! You even have users who are waiting to consume the output.", "Now that you have one system working with an analysis, you can think about expanding. Find a new analysis, a new outcome you want, test it, build it, automate it, and integrate it into your system. Maybe this will involve integrating a new data source into your system, or you might just do a new analysis with the existing data.", "Repeat this over and over. It\u2019s sorta exhausting, but again, thanks to having limited scope there\u2019s always an end in sight. You also will have to do less data engineering the second time around.", "You could use those, if they fit your need. They\u2019re designed for large volumes of data. They\u2019re often nice in that you can throw CSV files into those systems and they\u2019ll ingest but presents you with a very zippy SQL interface. Since CSV is the lingua franca of data, it can make a lot of your ETL jobs easier. I used to have to write raw MapReduce jobs to do the things RedShift and BQ do in SQL. From that background, those new tools are amazing.", "At the same time, you\u2019re going to be paying for those amazing features, both in terms of log storage, as well as the cost of running queries. Those bills can be nontrivial. They\u2019re marketed as being the foundation tech of data warehousing solutions, but they\u2019re complete overkill if your data sources are primarily Excel. ( Excel only supports ~1 million rows per worksheet, that easily fits in your laptop\u2019s RAM.)", "My recommendation is to stick with the much cheaper small local relational databases to start, you can migrate and scale up with some medium amount of discomfort later.", "You can plan ahead a bit in your programming and system architecture. You can avoid writing too much throwaway code because you know your data pipelines and systems are going to be reused for other systems.", "Design in a certain amount of flexibility from the start. A few extra layers of abstraction here and there will save you some refactoring in the future. It\u2019s a bit of an art form to balance the level of abstraction, you can certainly go too far, but it only takes a few minutes to split things out into functions and methods instead of one giant mess of spaghetti. Avoid having your present self inflicting pain on your future self.", "A decent rule of thumb I use is be fairly UNIX-y in the separation of concerns, with an eye towards making modules of functionality that will represent different data systems in the future. The modules can then be swapped around/iterated over as needed.", "People will make or break the process. If what you\u2019re building doesn\u2019t interface with their world, they won\u2019t use it. You\u2019re going to depend on them to give you data, so don\u2019t disrupt their processes without their input. When your pipelines are complete, you\u2019re going to depend on them to warn you if changes are incoming.", "If people are invested in your new system because they\u2019re directly getting value out of it, then they\u2019ll be interested in helping you keep all the moving parts running smoothly. Managing this relationship is critical. If people stop caring, things will start breaking.", "This is not a one-week project. Make sure everyone involved has realistic expectations. Make sure they know things can derail due to bugs and issues.", "Then it\u2019s just a matter of continuing on. Good luck!", "Originally published on Randy\u2019s free weekly newsletter, Counting Stuff, covering the more mundane, important parts of data and tech.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I stress about data quality a lot. Data nerd/scientist, camera junkie. Quant UXR @Google Cloud. Formerly @bitly, @Meetup, @primarydotcom. Opinions are my own."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd2cf99dc8a3b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://randy-au.medium.com/?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": ""}, {"url": "https://randy-au.medium.com/?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "Randy Au"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bd01667d4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&user=Randy+Au&userId=5bd01667d4e5&source=post_page-5bd01667d4e5----d2cf99dc8a3b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2cf99dc8a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2cf99dc8a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://twitter.com/Randy_Au/status/1235991970230816768", "anchor_text": "your chances of failure"}, {"url": "https://panoply.io/data-warehouse-guide/data-warehouse-architecture-traditional-vs-cloud/", "anchor_text": "well-known patterns"}, {"url": "https://en.wikipedia.org/wiki/Data_warehouse#History", "anchor_text": "long line of older data stores"}, {"url": "https://en.wikipedia.org/wiki/Athena#Birth", "anchor_text": "fully formed from your forehead, ready to provide wisdom to the world"}, {"url": "https://aws.amazon.com/training/course-descriptions/data-warehousing/", "anchor_text": "cloud"}, {"url": "https://cloud.google.com/solutions/marketing-data-warehouse-on-gcp", "anchor_text": "service"}, {"url": "https://azure.microsoft.com/en-us/solutions/data-warehouse/", "anchor_text": "provider"}, {"url": "https://www.cooladata.com/cost-of-building-a-data-warehouse/", "anchor_text": "Those"}, {"url": "https://aws.amazon.com/getting-started/projects/deploy-data-warehouse/services-costs/#:~:text=Using%20the%20default%20configuration%20recommended,usage%20of%20each%20individual%20service.", "anchor_text": "bills"}, {"url": "https://support.office.com/en-us/article/excel-specifications-and-limits-1672b34d-7043-467e-8e27-269d656771c3", "anchor_text": "Excel only supports ~1 million rows per worksheet"}, {"url": "http://www.catb.org/~esr/writings/taoup/html/ch01s06.html", "anchor_text": "fairly UNIX-y"}, {"url": "https://counting.substack.com", "anchor_text": "Counting Stuff"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d2cf99dc8a3b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----d2cf99dc8a3b---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2cf99dc8a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&user=Randy+Au&userId=5bd01667d4e5&source=-----d2cf99dc8a3b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2cf99dc8a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&user=Randy+Au&userId=5bd01667d4e5&source=-----d2cf99dc8a3b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2cf99dc8a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd2cf99dc8a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d2cf99dc8a3b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d2cf99dc8a3b--------------------------------", "anchor_text": ""}, {"url": "https://randy-au.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://randy-au.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Randy Au"}, {"url": "https://randy-au.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bd01667d4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&user=Randy+Au&userId=5bd01667d4e5&source=post_page-5bd01667d4e5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc29d9b065bd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-epic-data-fetch-quest-d2cf99dc8a3b&newsletterV3=5bd01667d4e5&newsletterV3Id=c29d9b065bd4&user=Randy+Au&userId=5bd01667d4e5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}