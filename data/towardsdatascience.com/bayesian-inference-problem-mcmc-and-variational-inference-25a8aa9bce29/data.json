{"url": "https://towardsdatascience.com/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29", "time": 1682996897.628546, "path": "towardsdatascience.com/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29/", "webpage": {"metadata": {"title": "Bayesian inference problem, MCMC and variational inference | by Joseph Rocca | Towards Data Science", "h1": "Bayesian inference problem, MCMC and variational inference", "description": "Bayesian inference is a major problem in statistics that is also encountered in many machine learning methods. For example, Gaussian mixture models, for classification, or Latent Dirichlet\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/20ad1309823a?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Baptiste Rocca", "paragraph_index": 0}, {"url": "http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf", "anchor_text": "reference paper on LDA", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/brief-introduction-to-markov-chains-2c8cab9c98ab", "anchor_text": "introductory post on Markov Chains", "paragraph_index": 22}, {"url": "https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29", "anchor_text": "post about GANs", "paragraph_index": 24}, {"url": "https://arxiv.org/pdf/1601.00670.pdf", "anchor_text": "Variational Inference: A Review For Statisticians", "paragraph_index": 71}, {"url": "https://pdfs.semanticscholar.org/21a9/2825dcec23c743e77451ff5b5ee6b1091651.pdf", "anchor_text": "general introduction", "paragraph_index": 71}, {"url": "https://www.cs.ubc.ca/~arnaud/andrieu_defreitas_doucet_jordan_intromontecarlomachinelearning.pdf", "anchor_text": "machine learning oriented introduction", "paragraph_index": 71}, {"url": "http://u.cs.biu.ac.il/~89-680/darling-lda.pdf", "anchor_text": "Tutorial on Topic Modelling and Gibbs Sampling", "paragraph_index": 71}, {"url": "http://www2.cs.uh.edu/~arjun/courses/advnlp/LDA_Derivation.pdf", "anchor_text": "lecture note on LDA Gibbs Sampler", "paragraph_index": 71}, {"url": "https://medium.com/u/20ad1309823a?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Baptiste Rocca", "paragraph_index": 74}, {"url": "http://www.linkedin.com/in/joseph-rocca-b01365158", "anchor_text": "www.linkedin.com/in/joseph-rocca-b01365158", "paragraph_index": 76}], "all_paragraphs": ["This post was co-written with Baptiste Rocca.", "Bayesian inference is a major problem in statistics that is also encountered in many machine learning methods. For example, Gaussian mixture models, for classification, or Latent Dirichlet Allocation, for topic modelling, are both graphical models requiring to solve such a problem when fitting the data.", "Meanwhile, it can be noticed that Bayesian inference problems can sometimes be very difficult to solve depending on the model settings (assumptions, dimensionality, \u2026). In large problems, exact solutions require, indeed, heavy computations that often become intractable and some approximation techniques have to be used to overcome this issue and build fast and scalable systems.", "In this post we will discuss the two main methods that can be used to tackle the Bayesian inference problem: Markov Chain Monte Carlo (MCMC), that is a sampling based approach, and Variational Inference (VI), that is an approximation based approach.", "In the first section we will discuss the Bayesian inference problem and see some examples of classical machine learning applications in which this problem naturally appears. Then in the second section we will present globally MCMC technique to solve this problem and give some details about two MCMC algorithms: Metropolis-Hasting and Gibbs Sampling. Finally in the third section we will introduce Variational Inference and see how an approximate solution can be obtained following an optimisation process over a parametrised family of distributions.", "Note. The subsection marked by a (\u221e) are pretty mathematical and can be skipped without hurting the global understanding of this post. Notice also that in this post p(.) is used to denote either probability, probability density or probability distribution depending on the context.", "In this section we present the Bayesian inference problem and discuss some computational difficulties before giving the example of Latent Dirichlet Allocation, a concrete machine learning technique of topic modelling in which this problem is encountered.", "Statistical inference consists in learning about what we do not observe based on what we observe. In other words, it is the process of drawing conclusions such as punctual estimations, confidence intervals or distribution estimations about some latent variables (often causes) in a population, based on some observed variables (often effects) in this population or in a sample of this population.", "In particular, Bayesian inference is the process of producing statistical inference taking a Bayesian point of view. In short, the Bayesian paradigm is a statistical/probabilistic paradigm in which a prior knowledge, modelled by a probability distribution, is updated each time a new observation, whose uncertainty is modelled by another probability distribution, is recorded. The whole idea that rules the Bayesian paradigm is embed in the so called Bayes theorem that expresses the relation between the updated knowledge (the \u201cposterior\u201d), the prior knowledge (the \u201cprior\u201d) and the knowledge coming from the observation (the \u201clikelihood\u201d).", "A classical example is the Bayesian inference of parameters. Let\u2019s assume a model where data x are generated from a probability distribution depending on an unknown parameter \u03b8. Let\u2019s also assume that we have a prior knowledge about the parameter \u03b8 that can be expressed as a probability distribution p(\u03b8). Then, when data x are observed, we can update the prior knowledge about this parameter using the Bayes theorem as follows", "The Bayes theorem tells us that the computation of the posterior requires three terms: a prior, a likelihood and an evidence. The first two can be expressed easily as they are part of the assumed model (in many situation, the prior and the likelihood are explicitly known). However, the third term, that is a normalisation factor, requires to be computed such that", "Although in low dimension this integral can be computed without too much difficulties, it can become intractable in higher dimensions. In this last case, the exact computation of the posterior distribution is practically infeasible and some approximation techniques have to be used to get solutions to problems that require to know this posterior (such as mean computation, for example).", "We can notice that some other computational difficulties can arise from Bayesian inference problem such as, for example, combinatorics problems when some variables are discrete. Among the approaches that are the most used to overcome these difficulties we find Markov Chain Monte Carlo and Variational Inference methods. Later in this post, we will describe these two approaches focusing especially on the \u201cnormalisation factor problem\u201d but one should keep in mind that these methods can also be precious when facing other computational difficulties related to Bayesian inference.", "In order to make things a lit bit more general for the upcoming sections, we can observe that, as x is supposed to be given and can, so, be teated as a parameter, we face a situation where we have a probability distribution on \u03b8 defined up to a normalisation factor", "Before describing MCMC and VI in the next two sections, let\u2019s give a concrete example of Bayesian inference problem in machine learning with Latent Dirichlet Allocation.", "Bayesian inference problem naturally appears, for example, in machine learning methods that assume a probabilistic graphical model and where, given some observations, we want to recover latent variables of the model. In topic modelling, the Latent Dirichlet Allocation (LDA) method defines such a model for the description of texts in a corpus. Thus, given the full corpus vocabulary of size V and a given number of topics T, the model assumes:", "The purpose of the method, whose name comes from the Dirichlet priors assumed in the model, is then to infer the latent topics in the observed corpus as well as the topic decomposition of each documents. Even if we won\u2019t dive into details of LDA, we can say very roughly, denoting w the vector of words in the corpus and z the vector of topics associated to these words, that we want to infer z based on the observed w in a Bayesian way:", "Here, beyond the fact that the normalisation factor is absolutely intractable due to a huge dimensionality, we face a combinatoric challenge (as some variables of the problem are discrete) that require to use either MCMC or VI to get an approximate solution. The reader interested by topic modelling and its specific underlying Bayesian inference problem can take a look at this reference paper on LDA.", "As we mentioned before, one of the main difficulty faced when dealing with a Bayesian inference problem comes from the normalisation factor. In this section we describe MCMC sampling methods that constitute a possible solution to overcome this issue as well as some others computational difficulties related to Bayesian inference.", "The idea of sampling methods is the following. Let\u2019s assume first that we have a way (MCMC) to draw samples from a probability distribution defined up to a factor. Then, instead of trying to deal with intractable computations involving the posterior, we can get samples from this distribution (using only the not normalised part definition) and use these samples to compute various punctual statistics such as mean and variance or even to approximate the distribution by Kernel Density Estimation.", "Contrarily to VI methods described in the next section, MCMC approaches assume no model for the studied probability distribution (the posterior in the Bayesian inference case). As a consequence, these methods have a low bias but a high variance and it implies that results are most of the time more costly to obtain but also more accurate than the one we can get from VI.", "To conclude this subsection, we outline once more the fact that this sampling process we just described is not constrained to the Bayesian inference of posterior distribution and can also, more generally, be used in any situation where a probability distribution is defined up to its normalisation factor.", "In statistics, Markov Chain Monte Carlo algorithms are aimed at generating samples from a given probability distribution. The \u201cMonte Carlo\u201d part of the method\u2019s name is due to the sampling purpose whereas the \u201cMarkov Chain\u201d part comes from the way we obtain these samples (we refer the reader to our introductory post on Markov Chains).", "In order to produce samples, the idea is to set up a Markov Chain whose stationary distribution is the one we want to sample from. Then, we can simulate a random sequence of states from that Markov Chain that is long enough to (almost) reach the steady state and then keep some generated states as our samples.", "Among the random variables generation techniques, MCMC is a pretty advanced kind of methods (we already discussed an other method in our post about GANs) that makes possible to get samples from a very difficult probability distribution potentially defined only up to a multiplicative constant. The counter-intuitive fact that we can obtain, with MCMC, samples from a distribution not well normalised comes from the specific way we define the Markov Chain that is not sensitive to these normalisation factor.", "The whole MCMC approach is based on the ability to build a Markov Chain whose stationary distribution is the one we want to sample from. In order to do so, Metropolis-Hasting and Gibbs Sampling algorithms both use a particular property of Markov Chains: reversibility.", "A Markov Chain over a state space E with transition probabilities denoted by", "is said to be reversible if there exists a probability distribution \u03b3 such that", "For such Markov Chain, we can easily verify that we have", "and, then, \u03b3 is a stationary distribution (the only one if the Markov Chain is irreducible).", "Let\u2019s now assume that the probability distribution \u03c0 we want to sample from is only defined up to a factor", "(where C is the unknown multiplicative constant). We can notice that the following equivalence holds", "and, then, a Markov Chain with transition probabilities k(.,.) defined to verify the last equality will have, as expected, \u03c0 as stationary distribution. Thus, we can define a Markov Chain that have for stationary distribution a probability distribution \u03c0 that can\u2019t be explicitly computed.", "Let\u2019s assume that the Markov Chain we want to define is D-dimensional, such that", "The Gibbs Sampling method is based on the assumption that, even if the joint probability is intractable, the conditional distribution of a single dimension given the others can be computed. Based on this idea, transitions are defined such that, at iteration n+1, the next state to be visited is given by the following process.", "First we randomly choose an integer d among the D dimensions of X_n. Then we sample a new value for that dimension according to the corresponding conditional probability given that all the other dimensions are kept fixed:", "is the conditional distribution of the d-th dimension given all the other dimensions.", "the transition probabilities can then be written", "and, so, the local balance is verified as expected with, for the only non-trivial case,", "Sometimes even conditional distributions involved in Gibbs methods are far too complex to be obtained. In such cases, Metropolis-Hasting can then be used. For this, we start by defining a side transition probability h(.,.) that will serve at suggesting transitions. Then, at iteration n+1, the next state to be visited by the Markov Chain is defined by the following process. We first draw a \u201csuggested transition\u201d x from h and compute a related probability r to accept it:", "Then the effective transition is chosen such that", "Formally, the transition probabilities can then be written", "and, so, the local balance is verified as expected", "Once our Markov Chain has been defined, we can simulate a random sequence of states (randomly initialised) and keep some of them chosen such as to obtain samples that, both, follow the targeted distribution and are independent.", "First, in order to have samples that (almost) follow the targeted distribution, we need to only consider states far enough from the beginning of the generated sequence to have almost reach the steady state of the Markov Chain (the steady state being, in theory, only asymptotically reached). Thus, the first simulated states are not usable as samples and we call this phase required to reach stationarity the burn-in time. Notice that, in practice it is pretty difficult to know how long this burn-in time has to be.", "Second, in order to have (almost) independent samples, we can\u2019t keep all the successive states of the sequence after the burn-in time. Indeed, the Markov Chain definition implies a strong correlation between two successive states and we then need to keep as samples only states that are far enough from each other to be considered as almost independent. In practice, the lag required between two states to be considered as almost independent can be estimated through the analysis of the autocorrelation function (only for numeric values).", "So, in order to get our independent samples that follow the targeted distribution, we keep states from the generated sequence that are separated from each other by a lag L and that come after the burn-in time B. Thus, if the successive states of the Markov Chain are denoted", "we only keep as our samples the states", "Another possible way to overcome computational difficulties related to inference problem is to use Variational Inference methods that consist in finding the best approximation of a distribution among a parametrised family. In order to find this best approximation, we follow an optimisation process (over the family parameters) that only require the targeted distribution to be defined up to a factor.", "VI methods consist in searching for the best approximation of some complex target probability distribution among a given family. More specifically, the idea is to define a parametrised family of distributions and to optimise over the parameters to obtain the closest element to the target with respect to a well defined error measure.", "Let\u2019s still consider our probability distribution \u03c0 defined up to a normalisation factor C:", "Then, in more mathematical terms, if we denote the parametrised family of distributions", "and we consider the error measure E(p,q) between two distributions p and q, we search for the best parameter such that", "If we can solve this minimisation problem without having to explicitly normalise \u03c0, we can use f_\ud835\udf14* as an approximation to estimate various quantities instead of dealing with intractable computations. The optimisation problem implied by variational inference approaches is, indeed, supposed to be much simpler to handle than issues coming from direct computations (normalisation, combinatorics, \u2026).", "Contrarily to sampling approaches, a model is assumed (the parametrised family), implying a bias but also a lower variance. In general VI methods are less accurate that MCMC ones but produce results much faster: these methods are better adapted to big scale, very statistical, problems.", "The first thing we need to set up is the parametrised family of distributions that defines the space in which we search for our best approximation.", "The choice of the family defines a model that control both the bias and the complexity of the method. If we assume a pretty restrictive model (simple family) then we have a high bias but the optimisation process is simple. On the contrary, if we assume a pretty free model (complex family) the bias is much lower but the optimisation is harder (if not intractable). Thus, we have to find the right balance between a family that is complex enough to ensure a good quality of the final approximation and a family that is simple enough to make the optimisation process tractable. We should keep in mind that if no distribution in the family is close to the target distribution, then even the best approximation can give poor results.", "The mean-field variational family is a family of probability distributions where all the components of the considered random vector are independent. Distributions from this family have product densities such that each independent component is governed by a distinct factor of the product. Thus, a distribution that belongs to the mean-field variational family has a density that can be written", "where we have assumed a m-dimensional random variable z. Notice that, even if it has been omitted in the notation, all the densities f_j are parametrised. So, for example, if each density f_j is a Gaussian with both mean and variance parameters, the global density f is then defined by a set of parameters coming from all the independent factors and the optimisation is done over this entire set of parameters.", "Once the family has been defined, one major question remains: how to find, among this family, the best approximation of a given probability distribution (explicitly defined up to its normalisation factor)? Even if the best approximation obviously depends on the nature of the error measure we consider, it seems pretty natural to assume that the minimisation problem should not be sensitive to normalisation factors as we want to compare masses distributions more than masses themselves (that have to be unitary for probability distributions).", "So, let\u2019s now define the Kullback-Leibler (KL) divergence and see that this measure makes the problem insensitive to normalisation factors. If p and q are two distributions, the KL divergence is defined as follows", "From that definition, we can pretty easily see that we have", "which implies the following equality for our minimisation problem", "Thus, when choosing KL divergence as our error measure, the optimisation process is not sensitive to multiplicative coefficients and we can search for the best approximation among our parametrised family of distributions without having to compute the painful normalisation factor of the targeted distribution, as it was expected.", "Finally, as a side fact, we can conclude this subsection by noticing for the interested readers that the KL divergence is the cross-entropy minus the entropy and has a nice interpretation in information theory.", "Once both the parametrised family and the error measure have been defined, we can initialise the parameters (randomly or according to a well defined strategy) and proceed to the optimisation. Several classical optimisation techniques can be used such as gradient descent or coordinate descent that will lead, in practice, to a local optimum.", "In order to better understand this optimisation process, let\u2019s take an example and go back to the specific case of the Bayesian inference problem where we assume a posterior such that", "In this case, if we want to get an approximation of this posterior using variational inference, we have to solve the following optimisation process (assuming the parametrised family defined and KL divergence as error measure)", "The last equality helps us to better understand how the approximation is encouraged to distribute its mass. The first term is the expected log-likelihood that tends to adjust parameters so that to place the mass of the approximation on values of the latent variables z that explain the best the observed data. The second term is the negative KL divergence between the approximation and the prior that tends to adjust the parameters in order to make the approximation be close to the prior distribution. Thus, this objective function expresses pretty well the usual prior/likelihood balance.", "The main takeways of this article are:", "As already mentioned, MCMC and VI methods have different properties that imply different typical use cases. In one hand, the sampling process of MCMC approaches is pretty heavy but has no bias and, so, these methods are preferred when accurate results are expected, without regards to the time it takes. In the other hand, although the choice of the family in VI methods can clearly introduce a bias, it comes along with a reasonable optimisation process that makes these methods particularly adapted to very large scale inference problem requiring fast computations.", "Additional comparisons between MCMC and VI can be found in the excellent Variational Inference: A Review For Statisticians, that we also highly recommend for readers interested in VI only. For further readings about MCMC, we recommend this general introduction as well as this machine learning oriented introduction. The reader interested to learn more about Gibbs Sampling applied to LDA can refer to this Tutorial on Topic Modelling and Gibbs Sampling (combined with these lecture note on LDA Gibbs Sampler for cautious derivation).", "Finally, let\u2019s conclude with a little bit of teasing and mention that in an upcoming post we will discuss Variational Auto Encoder, a deep learning approach that is based on variational inference\u2026 so stay tuned!", "Thanks for reading and feel free to share if you think it deserves to be!", "Last articles written with Baptiste Rocca:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Engineer at Meta. Towards Data Science writer. Mathematics instructor at UTC. www.linkedin.com/in/joseph-rocca-b01365158"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F25a8aa9bce29&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@joseph.rocca?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joseph.rocca?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Joseph Rocca"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb17ebd108358&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&user=Joseph+Rocca&userId=b17ebd108358&source=post_page-b17ebd108358----25a8aa9bce29---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F25a8aa9bce29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F25a8aa9bce29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/fr/users/free-photos-242387/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1030852", "anchor_text": "Free-Photos"}, {"url": "https://pixabay.com/", "anchor_text": "Pixabay"}, {"url": "https://medium.com/u/20ad1309823a?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Baptiste Rocca"}, {"url": "http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf", "anchor_text": "reference paper on LDA"}, {"url": "https://towardsdatascience.com/brief-introduction-to-markov-chains-2c8cab9c98ab", "anchor_text": "introductory post on Markov Chains"}, {"url": "https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29", "anchor_text": "post about GANs"}, {"url": "https://arxiv.org/pdf/1601.00670.pdf", "anchor_text": "Variational Inference: A Review For Statisticians"}, {"url": "https://pdfs.semanticscholar.org/21a9/2825dcec23c743e77451ff5b5ee6b1091651.pdf", "anchor_text": "general introduction"}, {"url": "https://www.cs.ubc.ca/~arnaud/andrieu_defreitas_doucet_jordan_intromontecarlomachinelearning.pdf", "anchor_text": "machine learning oriented introduction"}, {"url": "http://u.cs.biu.ac.il/~89-680/darling-lda.pdf", "anchor_text": "Tutorial on Topic Modelling and Gibbs Sampling"}, {"url": "http://www2.cs.uh.edu/~arjun/courses/advnlp/LDA_Derivation.pdf", "anchor_text": "lecture note on LDA Gibbs Sampler"}, {"url": "https://medium.com/u/20ad1309823a?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Baptiste Rocca"}, {"url": "https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada", "anchor_text": "Introduction to recommender systemsOverview of some major recommendation algorithms.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205", "anchor_text": "Ensemble methods: bagging, boosting and stackingUnderstanding the key concepts of ensemble learning.towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----25a8aa9bce29---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----25a8aa9bce29---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/statistics?source=post_page-----25a8aa9bce29---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----25a8aa9bce29---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----25a8aa9bce29---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F25a8aa9bce29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&user=Joseph+Rocca&userId=b17ebd108358&source=-----25a8aa9bce29---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F25a8aa9bce29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&user=Joseph+Rocca&userId=b17ebd108358&source=-----25a8aa9bce29---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F25a8aa9bce29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F25a8aa9bce29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----25a8aa9bce29---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----25a8aa9bce29--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joseph.rocca?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joseph.rocca?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Joseph Rocca"}, {"url": "https://medium.com/@joseph.rocca/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4.97K Followers"}, {"url": "http://www.linkedin.com/in/joseph-rocca-b01365158", "anchor_text": "www.linkedin.com/in/joseph-rocca-b01365158"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb17ebd108358&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&user=Joseph+Rocca&userId=b17ebd108358&source=post_page-b17ebd108358--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F164289aafbe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29&newsletterV3=b17ebd108358&newsletterV3Id=164289aafbe3&user=Joseph+Rocca&userId=b17ebd108358&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}