{"url": "https://towardsdatascience.com/unlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07", "time": 1683001532.584537, "path": "towardsdatascience.com/unlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07/", "webpage": {"metadata": {"title": "Unlocking Drug Discovery With Machine Learning | by Joey Mach | Towards Data Science", "h1": "Unlocking Drug Discovery With Machine Learning", "description": "Despite all the innovation that is happening in the pharmaceutical industry recently, especially in the cancer research space, there\u2019s still a huge gap for improvement! In 1928, Alexander Fleming, a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/analytics-vidhya/teaching-machines-to-detect-skin-cancer-bd165566f0fe", "anchor_text": "this article", "paragraph_index": 74}, {"url": "https://zinc.docking.org/", "anchor_text": "zinc dataset", "paragraph_index": 76}, {"url": "https://github.com/joeym-09/Leveraging-VAE-to-generate-molecules", "anchor_text": "Github here", "paragraph_index": 106}, {"url": "https://medium.com/u/bd6ad9886982?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Aryan Misra", "paragraph_index": 107}, {"url": "https://medium.com/u/b295dac7f56?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Elias Kountouris", "paragraph_index": 107}, {"url": "https://towardsdatascience.com/questions-96667b06af5", "anchor_text": "rules and guidelines", "paragraph_index": 108}, {"url": "https://towardsdatascience.com/readers-terms-b5d780a700a4", "anchor_text": "Reader Terms", "paragraph_index": 108}], "all_paragraphs": ["The way we discover drugs is EXTREMELY inefficient. Something needs to be done.", "Despite all the innovation that is happening in the pharmaceutical industry recently, especially in the cancer research space, there\u2019s still a huge gap for improvement!", "Our current approach to drug discovery hasn\u2019t changed much since the 1920s.", "This is the story of how drugs were once discovered:", "In 1928, Alexander Fleming, a pathologist, often described as being \u201ccare-free\u201d accidentally left his petri dish uncovered beside a window before leaving for his month-long vacation.", "Arriving back from his lovely vacation, something even lovelier happened. *To his surprise*, the discarded culture dish led Fleming to the remarkable discovery of the world\u2019s first antibiotic, Penicillin, which disrupted the pharmaceutical industry \ud83e\udd2f.", "Just one of the many examples of how a petty mistake manifested itself into a therapeutic breakthrough.", "Fast forward 8-ish decades later, this is how drugs are currently being discovered:", "Recently, New Zealand researchers *unexpectedly* discovered that the vaccine previously used to combat the meningitis epidemic in the early 2000s also subsequently lowers the risk against gonorrhoea.", "The secret sauce to drug discovery has never seemed to escape the magic of serendipity despite all the progression that has occurred.", "Over the past 8 decades, technological advancement has taken an exponential growth trajectory, but progress in the field of drug discovery has remained relatively stagnant.", "Cell phones weren\u2019t even a thing, let alone Apple in 1928 (if you\u2019re not an apple fan, we\u2019re not friends \u2014 just kidding \ud83d\ude01), and now we not only have Apple, but we also have brain-computer interfaces, artificial intelligence bringing innovation into every industry, quantum computing (recently, Google announced quantum supremacy) and the emergence of tons more exponential technologies.", "But, in comparison, there is little progression made in improving the process of drug discovery.", "There\u2019s tons of evidence which indicates that the current drug discovery process is just inadequate, and shortcoming for those in the most need \u2014 people living with chronic and deadly diseases.", "Taking a drug from research to market is estimated to cost on average 2.6 billion dollars, and more than 10+ years \ud83d\ude31. Since drug discovery is so resource-consuming, most of the advancement lately has been focused on high-return markets like cancer research.", "This partly explains the lack of effective treatment for more than 90% of rare diseases.", "But why is this even the case? Let\u2019s take a look at the drug discovery pipeline (aka the multifaceted process of drug development).", "We all want these life-saving drugs to be in the hands of patients in need quicker and cheaper.", "The simple answer as to why this process is so lengthy and costly is the sheer complexity.", "The drug discovery pipeline looks something like this:", "Complicated right? Let\u2019s break it down\u2026", "There are seven phases in drug discovery:", "The first step isn\u2019t even about the drug, it\u2019s all about understanding the targets that are responsible for the disease. These targets often consist of DNA mutations, misfolded proteins, and other potential disease biomarkers. However, this is obviously not the case in the discovery of Penicillin, which was purely driven by serendipity.", "Issue #1: Though the desired route is to identify targets, then develop drugs that specifically combat the disease targets, there is no guarantee in this process. The discovery of Penicillin clearly was an exception to this process, and there are many more exceptions. There are just so many possible compounds, and so many possible targets, it\u2019s extremely difficult for human beings to make sense of all of these possible combinations.", "This is the process of screening thousands of compounds designed to interfere with the disease targets. The objective is the significantly narrow the domain of the variety of potential compounds.", "This phase involves the process of further testing the compounds to analyze their interaction with disease targets. Some analysis that may be conducted includes, for instance, investigating the interaction of compounds taking into account their 3D configuration. In accordance with the results derived from analysis, compounds are further optimized towards the intended targets.", "As proof of concept, compounds that make it to this stage are tested in a cell system, an in-vitro model of the disease. This is the phase where the petri dish studies occur. In vitro studies attempt to scrutinize the effectiveness of the compound is at interfering with the target.", "Issue #2: Results from in-vitro studies often don\u2019t reflect results from animal or clinical studies, causing a high failure rate. According to an MIT study, clinical trial success rate hovers just about14%, that\u2019s insane! This is because our in-vitro models of the cell system is often a gross simplification of our complex human system. Biology just doesn\u2019t operate in 2D mode, but petri dish studies are 2D models of cells and is a widely used in-vitro study method.", "After success from in-vitro studies (YAY, but the hard part has yet to come), the compound is typically tested in animal models like rat or mouse models. The results from animal studies are usually more representative compared to the 2D in-vitro cell culture models. However, it is significantly more expensive than in-vitro studies. The failure rate at this stage is also higher since the results from in-vitro studies don\u2019t necessarily correlate with animal studies due to the disparity in the architecture of the cell model.", "Note to keep in mind: What if we can fail earlier, instead of failing later? It doesn\u2019t make sense to fail at such expensive phases, what if we fail during the phase of in-vitro studies?", "If the results from all the above phases showed promise in the compound, it then proceeds to clinical trials. There are three phases in clinical trials and each with a different objective. The main goal of clinical trials is to validate the efficacy and safety of the compound or potential drug in a human setting.", "Issue #3: There are many regulatory aspects of clinical trials, which is why it\u2019s the most lengthy and expensive phase. Proving the efficacy of drugs is often not an easy task; specifically, the long-term side effects of compounds usually remained unknown after a period of time. Testing new drugs on human beings always exists a significant inherent risk. The average cost of phase 3 clinical trial is estimated to be $19 million dollars.", "Once all testing is completed, the compound can be submitted to be reviewed by the FDA for approval. Once approved, the drug can finally be able to be commercially available in the hands of patients to improve lives and treat diseases!!!!!! \u2014 The most exciting part of all the time, but this was an extremely long and costly journey!", "Issue #4: Newly available drugs are often extremely expensive because of how costly research and development is. Companies often have a 20-year patent to protect their drug/product from the competition. This means that they can price their drugs at whatever price they think seems sound. Sometimes, this price can be at hundreds of thousands of dollars, making it unaffordable for the general public.", "Note to keep in mind: How can we accelerate the process of drug discovery?", "Wow, that was a journey \ud83c\udf04!", "But what if there was a way to significantly accelerate the process of early phase drug discovery (all phases except clinical trials + commercialization) from 6 years to 6 days? I\u2019m optimistic, and I don\u2019t think this is sci-fi at all! In fact, this is POSSIBLE! We don\u2019t lack the tools needed to realize this, we just lack optimism and the right people.", "People are the single most important factor in driving growth, not anything else. It doesn\u2019t matter if you\u2019re a 16-year-old/high schooler (spoiler: that\u2019s me), or if you\u2019re a renowned AI researcher, I believe there\u2019s something for all of us to do in order to create impact. And that\u2019s also fundamentally why I decided to do something, as a curious 16-year-old.", "We\u2019ve been stuck with the same process of doing tons of wet-lab experiments and going through a bunch of trial and error for drug discovery for way too long! The manual process of drug discovery MUST change!", "It\u2019s time for something new, introducing Synbiolic: extrapolating the potential of artificial intelligence, specifically variational auto-encoders (VAE) to generate novel & valid molecules in the format of SMILES (Simplified molecular-input line-entry system).", "Here\u2019s an inside look of what the magic is all about!", "Variational autoencoder (VAE) is a type of generative machine learning algorithm. A generative model is a type of AI architecture that generates new data that is similar characteristically to the training data.", "It consists of two components which are neural networks: (1) the encoder, and (2) the decoder. Note: different neural networks can be used for the encoder and the decoder.", "The encoder network is responsible for reducing the dimensions of the data that is inputted into the model, and the decoder network reverses the process by reconstructing the compact representation of the data back into its original dimensions/input.", "The compact representation of the data is termed the latent space representation (aka the bottleneck).", "Synbiolic leverages VAE to generate new molecules that have drug-like properties similar to that of the molecules used to train the model. The generated molecules are not exactly the same as the training molecules but are rather variations of the training molecules.", "To more intuitively understanding what the encoder and decoder models do, let\u2019s play a game of charades!", "Let\u2019s enter into programming mode and start by declaring some variables \ud83e\udd16:", "The lady guessing the phrase \u201cFinding Nemo\u201d (*compact representation of molecules*) is similar to the encoder since she condenses the \u201caction\u201d (*molecules*) into a phrase (*compact representation of molecules*). In terms of AI language, she is essentially constructing the latent representation of the \u201cactions\u201d (*molecules*). This is an analogy to how the encoder reduces the dimensions used to represent the molecules into a more compact form.", "The gentlemen acting \u201cFinding Nemo\u201d (*compact representation of molecules*) is similar to the decoder since he attempts to reinterpret the phrase into actions (*molecules*), which is the expanded representation. In terms of generating molecules, the decoder does this by reconstructing the molecule based on its condensed features, or the latent space representation.", "A variational autoencoder has an encoder and decoder network just like a regular vanilla autoencoder pictured in the image above (the one before the finding Nemo)\ud83d\udc46. However, it\u2019s not just a regular machine learning model, VAE uses a probabilistic approach for its encoder network.", "The reason why VAE was used instead of autoencoders is mainly because vanilla autoencoders can\u2019t generate data. This is the case since vanilla autoencoders (specifically the encoder) can\u2019t seem to figure out a good approach that creates \u201cusable\u201d latent space representation to feed into the decoder network in order to generate \u201cgood\u201d molecules.", "What ends up happening when autoencoders try to generate new data is that a random latent representation/vector is fed into the decoder model, which in turn generates really funky and useless data. This is because vanilla autoencoders don\u2019t know how to derive \u201cgood\u201d latent vectors apart from forcing the encoder to create latent vectors from the training data.", "The latent space of vanilla autoencoders is not continuous, which is why they\u2019re no good for generating data.", "This means that taking the latent representation in the above picture, the decoder is able to generate a decent looking picture, but if one of the latent parameters like skin tone is altered just a bit from 0.85 to 0.84, then the decoder network gets completely screwed over and might end up generating something like this:", "This is all because the latent space representation isn\u2019t continuous.", "It\u2019s also not all so magical generating random data. What\u2019s magical about VAE that autoencoders can\u2019t achieve is that it\u2019s one of the best generative models that can be used to apply variations to the data you already have in desired directions.", "The encoder network is denoted as q(z|x) and the decoder network is denoted as p(x|z) for x represents the input into the network and z is the latent representation (which is a vector).", "What\u2019s different about variational autoencoders is that its encoder network leverages a probabilistic model. This allows for the latent space to be continuous.", "VAE does this by making its encoder assemble two vectors: a vector which takes the mean, and another vector which takes the standard deviation of the input data. Then the latent vector z is constructed by sampling from the vector of means and the vector of standard deviation.", "By sampling, this allows the latent space to be continuous, instead of discrete. This is the reason why VAEs can generate synthetic data which essentially variations of the training data. (We can make apply these \u201cvariations\u201d intentionally by optimizing the latent space to generate new data in with desired properties.)", "Let\u2019s move on to the secret sauce behind all of this, aka the models used for Synbiolic\u2019s VAE.", "For the encoder and decoder models, the following neural networks are used:", "Before we dive into CNNs, let\u2019s first explore what dimensionality reduction actually is.", "Dimensionality reduction is the technique in machine learning used to downside the data by reducing its features.", "There are two techniques the encoder model can use to perform dimensionality reduction:", "The difference between the two techniques is that feature selection doesn\u2019t alter the features, while feature extraction does since it applies transformations to \u201cinput features/data\u201d to arrive at the latent space representation.", "Convolutional neural network (CNN) is a type of deep learning algorithm that is widely used in image classification because of its ability to detect features.", "They do this by implementing feature extraction, and therefore subsequently reducing the dimensions of the input data.", "Like other deep learning algorithms, CNN are composed of [1] input layers, [2] hidden layers, and [3] output layers.", "The hidden layers are made up of several different types of layers like convolutional layers, pooling layers, and fully connected (aka vanilla) layers.", "What makes a \u201cconvolutional neural network\u201d a \u201cconvolutional neural network\u201d is the convolutional layer(s). Yup, it\u2019s that simple, actually, maybe not that simple\u2026", "The convolutional layers essentially perform the dot product between the input and the filter to arrive at a lower-dimensional representation of the data (aka, the convolutional layers are powered by math).", "As you can see, the convolved feature is dimensionally more compact than the original input.", "To learn more about convolutional neural networks and its applications in skin cancer detection, check this article out!", "Instead of using CNN for image classification like for detecting skin cancer from images of moles, I trained the CNN on a dataset of molecules.", "The VAE is trained on the zinc dataset containing 250 000 molecules. The encoder (CNN) transmutes the representation of the features of the molecules into the more compact representation.", "For the decoder, a specific type of recurrent neural network (RNN) known as gated recurrent unit (GRU) is used.", "Unlike other types of neural networks, RNNs have an internal memory capacity. RNNs are typically applied to sequential data since their special property is that their decisions are influenced by the previous inputs and outputs within the network.", "Vanilla neural networks also have the ability to \u201cremember\u201d things, but they are limited to remembering things from previous training iterations.", "In contrast, RNNs remember things within each training iteration and make their decisions based on the inputs and generated outputs from the previous hidden state.", "Think of it like this: remember how your math teacher used to tell you how if you don\u2019t know how to add, subtract, multiply and divide numbers, you will never be able to master calculus! That\u2019s because as human beings, we understand concepts based on the previous concepts we\u2019ve learned.", "This is similar to how as you are reading this sentence, you understand it based on your understanding of the previous words. If I only wrote \u201cprevious words\u201d as the sentence, you wouldn\u2019t be able to understand what I was trying to say. Essentially, this is what RNNs are really good at doing: dissecting the meaning of sequential data like sentence structures.", "RNNs internal memory capacity refers to its ability to remember previous information within the network to help it make decisions. They have the ability to predict the next value in sequential data by understanding the connection between the previous values in the sequence.", "All machine learning is powered by math, and the math of RNNs consists of hidden states (h), which are the hidden nodes.", "The hidden states are connected to each other. In each hidden states, there are gates, which are neural networks that control the transfer of information.", "For the hidden state to compute the information, it has to be pre-processed and transformed into a matrix/vector representation.", "The hidden state of \u201cvanilla\u201d RNNs look something like this:", "However, traditional RNN suffers from an issue known as vanishing gradient descent.", "What happens when training a traditional RNN is that as the weight is being updated, the gradient becomes so small that it renders the updated weight insignificant. If the original weight has practically remained unchanged, this means that there is little to no learning occurring within this model.", "A small gradient update doesn\u2019t result in any significant learning, thus preventing the model from doing its job.", "In response to this issue, I implemented the gated recurrent unit (RNN, but with a twist) for the decoder instead of using \u201ctraditional\u201d RNN.", "There are two gates involved in the gated recurrent unit (GRU): the update gate and the reset gate. In essence, gates are just neural networks within the hidden nodes.", "Instead of remembering every single word in a sentence, unlike RNN, GRU only remembers significant phrases and words.", "For example, let\u2019s take a look at this sentence:", "\u201cTo examine the question of how to best accelerate rare diseases research, we will review some of the challenges in rare diseases research and opportunities for therapy development that recent scientific advances are presenting.\u201d", "Words like \u201cto\u201d, \u201cthe\u201d, \u201cof\u201d, \u201cthat\u201d, and \u201cfor\u201d are not really relevant to the meaning of the sentence, and thus the GRU would forget those words.", "\u201cTo examine the question of how to best accelerate rare diseases research, we will review some of the challenges in rare diseases research and opportunities for therapy development that recent scientific advances are presenting.\u201d", "While the RNN may attempt to memorize the entire sentence, GRU only memorizes the significant terms (which are bolded above).", "The update gate\u2019s responsibility is to determine how much of the information from the previous hidden states needs to be kept. Vanishing gradient descent problem is resolved by passing through this gate since the model gets to decide how much of the past information it needs to pass to the future hidden states.", "The output from the previous hidden state and the current input combine to form a vector which includes information about the current input and the previous inputs. Each vector contains not only information in the current hidden state, but also previous hidden states.", "Reset gate\u2019s job is to decide what past information should the model forget. Essentially, the functionality of this gate is opposite that of the update gate.", "In the scenario of generating molecules, the input for the GRU or the decoder is a vector representing the compressed form or latent space representation of the molecules. The final output of the GRU is the reconstruction of the molecule in its original/expanded representation.", "The quantity which measures the drug-likeness of a molecule is called QED (quantitative estimation of drug-likeness). I obtained the QED of the generated molecules to validate that they are drug-like molecules.", "All generated molecules with a QED below 0.5 are disregarded, this ensures the quality of the generated molecules. The molecules with the highest QED values can be synthesized to further validate their properties through in-vitro and in-vivo studies!", "YAY! We were able to successfully design and validate molecules! This same process which is classified under early phase drug design would\u2019ve taken at least 3 years of traditional research to arrive at!", "If you\u2019re interested, feel free to check out the source code from Github here.", "This was possible thanks to my wonderful team: Aryan Misra & Elias Kountouris!", "Note from Towards Data Science\u2019s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author\u2019s contribution. You should not rely on an author\u2019s works without seeking professional advice. See our Reader Terms for details.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8b2a64333e07&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@joeym.mach?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joeym.mach?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Joey Mach"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F831a4b5b46b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&user=Joey+Mach&userId=831a4b5b46b9&source=post_page-831a4b5b46b9----8b2a64333e07---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8b2a64333e07&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8b2a64333e07&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.technologyreview.com/f/614251/an-ai-system-identified-a-potential-new-drug-in-just-46-days/", "anchor_text": "Insilico Medicine"}, {"url": "https://deepmind.com/blog/article/alphafold", "anchor_text": "AlphaFold"}, {"url": "https://medium.com/analytics-vidhya/teaching-machines-to-detect-skin-cancer-bd165566f0fe", "anchor_text": "this article"}, {"url": "https://zinc.docking.org/", "anchor_text": "zinc dataset"}, {"url": "https://github.com/joeym-09/Leveraging-VAE-to-generate-molecules", "anchor_text": "Github here"}, {"url": "https://medium.com/u/bd6ad9886982?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Aryan Misra"}, {"url": "https://medium.com/u/b295dac7f56?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Elias Kountouris"}, {"url": "http://synbiolic.com", "anchor_text": "Synbiolic\u2019s website"}, {"url": "https://www.linkedin.com/in/joey-mach-6293b1175/?originalSubdomain=ca", "anchor_text": "LinkedIn"}, {"url": "https://towardsdatascience.com/questions-96667b06af5", "anchor_text": "rules and guidelines"}, {"url": "https://towardsdatascience.com/readers-terms-b5d780a700a4", "anchor_text": "Reader Terms"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8b2a64333e07---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/drug-discovery?source=post_page-----8b2a64333e07---------------drug_discovery-----------------", "anchor_text": "Drug Discovery"}, {"url": "https://medium.com/tag/autoencoder?source=post_page-----8b2a64333e07---------------autoencoder-----------------", "anchor_text": "Autoencoder"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----8b2a64333e07---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/therapy?source=post_page-----8b2a64333e07---------------therapy-----------------", "anchor_text": "Therapy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8b2a64333e07&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&user=Joey+Mach&userId=831a4b5b46b9&source=-----8b2a64333e07---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8b2a64333e07&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&user=Joey+Mach&userId=831a4b5b46b9&source=-----8b2a64333e07---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8b2a64333e07&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8b2a64333e07&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8b2a64333e07---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8b2a64333e07--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8b2a64333e07--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8b2a64333e07--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joeym.mach?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joeym.mach?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Joey Mach"}, {"url": "https://medium.com/@joeym.mach/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "172 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F831a4b5b46b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&user=Joey+Mach&userId=831a4b5b46b9&source=post_page-831a4b5b46b9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5065d4dcf64f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-drug-discovery-through-machine-learning-part-1-8b2a64333e07&newsletterV3=831a4b5b46b9&newsletterV3Id=5065d4dcf64f&user=Joey+Mach&userId=831a4b5b46b9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}