{"url": "https://towardsdatascience.com/visualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3", "time": 1683002189.273876, "path": "towardsdatascience.com/visualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3/", "webpage": {"metadata": {"title": "Visualizing Text Embeddings and Context in a Graph with Neo4j | by Utkarsh Garg | Towards Data Science", "h1": "Visualizing Text Embeddings and Context in a Graph with Neo4j", "description": "One of the challenge to analyze text quantitatively is to categorize strings. Say, we want to study the occupational profile of our existing customers. We would like to send them targeted campaigns\u2026"}, "outgoing_paragraph_urls": [{"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf", "anchor_text": "this", "paragraph_index": 9}, {"url": "https://radimrehurek.com/gensim/models/word2vec.html", "anchor_text": "Gensim", "paragraph_index": 12}, {"url": "https://tfhub.dev/google/universal-sentence-encoder/2", "anchor_text": "DAN model", "paragraph_index": 14}, {"url": "https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1", "anchor_text": "t-SNE", "paragraph_index": 17}, {"url": "https://plot.ly/python/plotly-express/", "anchor_text": "plotly express", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9", "anchor_text": "Deep Transfer Learning for Natural Language Processing", "paragraph_index": 39}, {"url": "https://medium.com/u/6278d12b0682?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Dipanjan (DJ) Sarkar", "paragraph_index": 39}], "all_paragraphs": ["One of the challenge to analyze text quantitatively is to categorize strings. Say, we want to study the occupational profile of our existing customers. We would like to send them targeted campaigns on the basis of their professional profile. Our customers are from variety of backgrounds. When a person creates a profile, there are fields that they enter as free text. Occupation is one of them. Since these are free text strings, people with similar occupation (similar industry or job) may enter their\u2019s differently.", "We wanted to solve a problem based on the above scenario. We had to create different contents of targeted, cross selling campaigns for the customers on the basis of the occupation entered when they registered.", "We had around 10,000 distinct strings which we wanted to cluster into 30\u201340 industry specific groups input by customers as their occupations. We found a lot of themes related to Engineers, Doctors, Artists, Defense, Education, Designers, Labor, Guard, Food, Transportation, business owner etc. The challenge was to find these themes in an unsupervised manner.", "This is a great use case for embedding models. With the advent of models like Word2Vec, Glove, ELMo and recently BERT, it has become possible to solve complex NLP tasks with ease. In this article, we will try to understand, the advantages of sentence embeddings over word embeddings for multi word strings. Also, we\u2019ll see how these embeddings can be used to analyze \u201cconcept transfer\u201d within similar strings in a graph database\u200a\u2014\u200aNeo4j.", "Models like Word2Vec and glove have certainly given \u201ccontext\u201d to our lives and made it easier. These models have been trained on large corpora coming from a variety of sources. The intuition behind these models is,", "Words which occur and used in same context, are semantically similar to each other and have similar meanings.", "These models enable us to use transfer learning for our NLP tasks. We can use these model\u2019s embeddings directly to get fixed size floating vectors or fine tune a model on our corpus. This enables us to find meaningful clusters with even small amount of data.", "The above figure shows the actual strings entered by the customers which we feel can be categorized under \u201cMedical\u201d umbrella.\u00a0By observing the strings we can straight off see some challenges in data:", "So, we need a way to bring all these strings together in a group somehow. One way to achieve this is using the Word2Vec model. Word2Vec is a neural network trained on a large corpus which spits out a fixed size vector of floating numbers for each word. Words occurring in similar context have similar vectors. So, \u201cdoctor\u201d, \u201cdocter\u201d, \u201cdr\u201d are all used in similar contexts and therefore have similar embeddings.", "However, our data can have multi word strings and we would like to use the models for inference instead of fine tuning. Word2Vec returns a vector for a single word. One way would be to take an average of the embedding of each word in the multi word string. Even though, this strategy may work with our occupation data, it would not give great results for longer sentences. Since, we are taking an avg of embedding for each word, we lose context of the sentence as a whole. This is where sentence encoders come in. Google\u2019s Universal sentence encoder, embeds any variable length text into a vector of 512 size vector. There are two variations of the models available on TF-hub. One is based in a Transformer Network and the the second based on Deep Averaging Network based embeddings. To understand how these work, check out this paper from Google research.", "Let us take some concrete examples to understand the advantage of sentence embeddings over word embeddings for multi word strings. Say we have two occupations\u200a\u2014\u200a\u201cSpecialist Dentist\u201d and \u201cHealthcare Consultant\u201d\u00a0. Since, both the occupations are of medical fields, we can expect these to have similar embedding and hence a high cosine similarity. Let us see a comparison of cosine similarities returned by the two approaches below.", "Approach 1 \u2014 Taking mean of Word2Vec embeddings", "Here, we first split the strings into words and get the word embeddings using Word2Vec model in Gensim (GoogleNews-vectors-negative300). We take the mean of the word embedding vectors returned for the corresponding occupation. Then, we calculate the cosine similarity between the two mean vectors.", "Approach 2 \u2014 Using Google Sentence Encoder", "Here, we get the sentence embeddings using the DAN model from Tensorflow hub. Then we simply take the cosine similarities between the returned vectors.", "We can see that the second approach gave us better results. Some more cosine similarity comparison with Word2Vec and Google Universal Sentence Encoder :", "For all the occupation pairs, we observe that the sentence encoder out performs word embeddings. This is quite understandable as a \u201cSpecialist\u201d can be of anything. Therefore, the embedding returned by Word2Vec for \u201cSpecialist\u201d is generic and does not depend upon the word \u201cDentist\u201d (see figure 3.1). Similarly, \u201cConsultant\u201d in the second occupation can be of anything. The sentence encoder returns the embedding which is interdependent on both the word \u201cHealthcare\u201d and \u201cConsultant\u201d. Hence, we get embedding vectors which have a much higher cosine similarity.Also, note the high cosine similarity returned by sentence encoder for HSBC Employee and Bank Manager. The algorithm knows HSBC is a bank! We wouldn\u2019t be able to achieve this with count vectorizers and tf-idf approaches with the small amount of data we had.", "Once we have the embeddings for our strings, we use t-SNE to reduce the dimensionality of our data from 512 (the size of sentence encoder vector) to 2. Also, we generate multiple clusters using K nearest neighbor. We plot the results on a scatter plot using plotly express a high-level wrapper around plotly graph objects.", "As we can see above, similar professions have been clustered together. For example, all textile related professions (the cluster in sky blue) like \u201ctailors\u201d, \u201cwomen\u2019s wear shop\u201d, \u201csaree whole seller\u201d, \u201croohi garments\u201d, have come closer to each other. We can tag all these clusters into \u201cTextile\u201d category. Similarly, all \u201cEducation\u201d related (the cluster in violet) professions have clustered together. The green smudge on the left side is a category of hardcore spelling mistakes which were totally different from other clusters and hence, similar to each other :)", "The t-SNE plot was able to give us a static 2D representation of our data. Similarly, a correlation plot of the embeddings would give us first degree relationships among the occupation strings. What if we want to track 2nd or greater degree relationships?", "To achieve this, we can create a graph with each occupation connected to the other with a correlation cutoff. Something like this:", "Here, \u201clawyer\u201d has a second degree connection to \u201csupreme court judge\u201d. The weight of edges (relationships) represent the cosine similarity between the nodes. Note that we only connect those nodes which have a cosine similarity \u2265 0.75. This ensures that only highly related data is connected in the graph.", "The above schema was applied in Neo4j. One of the most used graph databases. Do observe how it moves from \u201cconcept\u201d to \u201cconcept\u201d. (Note: Highly suggest to zoom in for better viewing if on a browser)", "Theme 1 \u2014 Pilot to Hospitality", "Pilot -> Aviation -> Airlines Professional -> Flight Attendant ->Cabin Attendant -> Hotel Job -> Other Hotel Stuff", "Pilot -> Airforce -> Army -> Navy and Merchant Navy", "A pilot can be both for a private airline or an air force pilot. That is what we see in the above two themes. One branch moves towards hospitality and the other to defense.", "Theme \u2014 Writer to News Reporter", "writer->document writer -> editor -> journalist-> reporter -> tv news reporter", "Theme \u2014 Mechanic to Construction worker and Structural Engineer", "mechanic->ac mechanic -> ac technician-> electrician -> welder -> steel worker -> construction", "Theme 1 \u2014 Photographer to Architect", "Photographer -> Fashion Photographer -> Fashion Designer ->Interior Designer-> Architect", "Them 2 \u2014 Photographer to Film stuff", "Photographer -> vfx artist -> assistant cinematographer -> video director -> film maker -> more film stuff", "Theme \u2014 Farmer to Milk Suppliers", "Farmer-> agriculture -> dairy farm -> milk and dairy business -> milk suppliers", "Graphs in combination with embeddings become a powerful visualization tool to understand information flow. We provided a simple example of how graphs can be used to understand and track context in textual documents. Due to the small nature of the problem, it is easy to see why \u201cpilot\u201d leads to both \u201cairforce\u201d and \u201chotels\u201d. However,", "We can extend it to applications with bigger documents like research papers, legal documents, books and build a recommendation or a search system on top of a graph.", "If you want to learn more on text embeddings, check out this amazing article: Deep Transfer Learning for Natural Language Processing by Dipanjan (DJ) Sarkar.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc5f92b2f3db3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ug2409?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ug2409?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Utkarsh Garg"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4cd18428e7fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&user=Utkarsh+Garg&userId=4cd18428e7fb&source=post_page-4cd18428e7fb----c5f92b2f3db3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5f92b2f3db3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5f92b2f3db3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@alinnnaaaa?utm_source=medium&utm_medium=referral", "anchor_text": "Alina Grubnyak"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf", "anchor_text": "this"}, {"url": "https://radimrehurek.com/gensim/models/word2vec.html", "anchor_text": "Gensim"}, {"url": "https://tfhub.dev/google/universal-sentence-encoder/2", "anchor_text": "DAN model"}, {"url": "https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1", "anchor_text": "t-SNE"}, {"url": "https://plot.ly/python/plotly-express/", "anchor_text": "plotly express"}, {"url": "https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9", "anchor_text": "Deep Transfer Learning for Natural Language Processing"}, {"url": "https://medium.com/u/6278d12b0682?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Dipanjan (DJ) Sarkar"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c5f92b2f3db3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----c5f92b2f3db3---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/neo4j?source=post_page-----c5f92b2f3db3---------------neo4j-----------------", "anchor_text": "Neo4j"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c5f92b2f3db3---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/word2vec?source=post_page-----c5f92b2f3db3---------------word2vec-----------------", "anchor_text": "Word2vec"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc5f92b2f3db3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&user=Utkarsh+Garg&userId=4cd18428e7fb&source=-----c5f92b2f3db3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc5f92b2f3db3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&user=Utkarsh+Garg&userId=4cd18428e7fb&source=-----c5f92b2f3db3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5f92b2f3db3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc5f92b2f3db3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c5f92b2f3db3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c5f92b2f3db3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ug2409?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ug2409?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Utkarsh Garg"}, {"url": "https://medium.com/@ug2409/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "51 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4cd18428e7fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&user=Utkarsh+Garg&userId=4cd18428e7fb&source=post_page-4cd18428e7fb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc5423a38a26c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3&newsletterV3=4cd18428e7fb&newsletterV3Id=c5423a38a26c&user=Utkarsh+Garg&userId=4cd18428e7fb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}