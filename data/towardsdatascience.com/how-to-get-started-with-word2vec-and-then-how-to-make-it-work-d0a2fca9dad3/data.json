{"url": "https://towardsdatascience.com/how-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3", "time": 1682993246.030237, "path": "towardsdatascience.com/how-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3/", "webpage": {"metadata": {"title": "How to get started with Word2Vec \u2014 and then how to make it work | by Kavita Ganesan | Towards Data Science", "h1": "How to get started with Word2Vec \u2014 and then how to make it work", "description": "The idea behind Word2Vec is pretty simple. We\u2019re making an assumption that the meaning of a word can be inferred by the company it keeps. This is analogous to the saying, \u201cshow me your friends, and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1301.3781.pdf", "anchor_text": "Word2Vec implementation by Google", "paragraph_index": 4}, {"url": "http://kavita-ganesan.com/entity-ranking-data/", "anchor_text": "OpinRank", "paragraph_index": 7}, {"url": "http://kavita-ganesan.com/opinion-based-entity-ranking/", "anchor_text": "Ph.D work", "paragraph_index": 7}, {"url": "https://radimrehurek.com/gensim/utils.html", "anchor_text": "Gensim documentation site", "paragraph_index": 11}, {"url": "https://github.com/kavgan/data-science/tree/master/word2vec", "anchor_text": "Word2Vec OpinRank", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "here", "paragraph_index": 19}, {"url": "https://github.com/kavgan/data-science/blob/master/word2vec/Word2Vec.ipynb", "anchor_text": "Jupyter Notebook", "paragraph_index": 20}, {"url": "https://github.com/kavgan/data-science/tree/master/word2vec", "anchor_text": "GitHub repo", "paragraph_index": 29}, {"url": "https://www.amazon.com/Business-Case-Strategies-Real-World-Applications-dp-1544528728/dp/1544528728/ref=mt_other?_encoding=UTF8&me=&qid=", "anchor_text": "The Business Case for AI: A Leader\u2019s Guide to AI Strategies, Best Practices & Real-World Applications", "paragraph_index": 30}, {"url": "http://www.kavita-ganesan.com", "anchor_text": "www.kavita-ganesan.com", "paragraph_index": 30}, {"url": "http://Kavita-Ganesan.com", "anchor_text": "Kavita-Ganesan.com", "paragraph_index": 32}, {"url": "http://AIBusinessCaseBook.com", "anchor_text": "AIBusinessCaseBook.com", "paragraph_index": 32}], "all_paragraphs": ["The idea behind Word2Vec is pretty simple. We\u2019re making an assumption that the meaning of a word can be inferred by the company it keeps. This is analogous to the saying, \u201cshow me your friends, and I\u2019ll tell who you are.\u201d", "If you have two words that have very similar neighbors (meaning: the context in which its used is about the same), then these words are probably quite similar in meaning or are at least related. For example, the words shocked, appalled, and astonished are usually used in a similar context.", "Using this underlying assumption, you can use Word2Vec to surface similar concepts, find unrelated concepts, compute similarity between two words, and more!", "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work. I\u2019ve long heard complaints about poor performance in general, but it really is a combination of two things: (1) your input data and (2) your parameter settings.", "Note that the training algorithms in the Gensim package were actually ported from the original Word2Vec implementation by Google and extended with additional functionality.", "First, we start with our imports and get logging established:", "Our next task is finding a really good dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data in the relevant domain. For example, if your goal is to build a sentiment lexicon, then using a dataset from the medical domain or even Wikipedia may not be effective. So, choose your dataset wisely.", "For this tutorial, I am going to use data from the OpinRank dataset from some of my Ph.D work. This dataset has full user reviews of cars and hotels. I have specifically gathered all of the hotel reviews into one big file which is about 97 MB compressed and 229 MB uncompressed. We will use the compressed file for this tutorial. Each line in this file represents a hotel review.", "Now, let\u2019s take a closer look at this data below by printing the first line.", "You can see that this is a pretty good, full review with lots of words and that\u2019s what we want. We have approximately 255,000 such reviews in this dataset.", "To avoid confusion, the Gensim\u2019s Word2Vec tutorial says that you need to pass a sequence of sentences as the input to Word2Vec. However, you can actually pass in a whole review as a sentence (that is, a much larger size of text) if you have a lot of data and it should not make much of a difference. In the end, all we are using the dataset for is to get all neighboring words for a given target word.", "Now that we\u2019ve had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below that I am directly reading the compressed file. I\u2019m also doing a mild pre-processing of the reviews using gensim.utils.simple_preprocess (line). This does some basic pre-processing such as tokenization, lowercasing, and so on and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official Gensim documentation site.", "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step. So, we are essentially passing on a list of lists, where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.", "The above code should start the training process. Behind the scenes we are actually training a simple neural network with a single hidden layer. But we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we\u2019re trying to learn.", "Training on the Word2Vec OpinRank dataset takes several minutes. So please sip a cup of tea and wait patiently.", "Let\u2019s get to the fun stuff already! Since we trained on user reviews, it would be nice to see similarity on some adjectives. This first example shows a simple look up of words similar to the word \u2018dirty\u2019. All we need to do here is to call the most_similar function and provide the word \u2018dirty\u2019 as the positive example. This returns the top 10 similar words.", "Ooh, that looks pretty good. Let\u2019s look at more.", "Overall, the results actually make sense. All of the related words tend to be used in the same context for the given query word.", "Now you could even use Word2Vec to compute similarity between two words in the vocabulary by invoking the similarity(...) function and passing in the relevant words.", "Under the hood, the above three snippets compute the cosine similarity between the two specified words using word vectors of each. From the scores above, it makes sense that dirty is highly similar to smelly but dirty is dissimilar to clean. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity can go from [-1 to 1] and sometimes bounded between [0,1] depending on how it\u2019s being computed and if your vectors have both positive and negative values. You can read more about cosine similarity scoring here.", "You will find more examples of how you could use Word2Vec in my Jupyter Notebook.", "To train the model earlier, we had to set some parameters. Now, let\u2019s try to understand what some of them mean. For reference, this is the command that we used to train the model.", "The size of the dense vector that is to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100\u2013150 has worked well for me for similarity lookups.", "The maximum distance between the target word and its neighboring word. If your neighbor\u2019s position is greater than the maximum window width to the left or the right, then some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its not overly narrow or overly broad. If you are not too sure about this, just use the default value.", "Minimium frequency count of words. The model would ignore words that do not satisfy the min_count. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.", "How many threads to use behind the scenes?", "How many epochs to train for? I typically use 10 or more for a small to medium dataset.", "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary.", "Beyond raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million StackOverflow questions and answers, you could find related tags and recommend those for exploration. You can do this by treating each set of co-occuring tags as a \u201csentence\u201d and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work.", "To use this tutorial\u2019s Jupyter Notebook, you can go to my GitHub repo and follow the instructions on how to get the notebook running locally. I plan to upload the pre-trained vectors which could be used for your own work.", "Kavita Ganesan is the author of The Business Case for AI: A Leader\u2019s Guide to AI Strategies, Best Practices & Real-World Applications. To learn more about Kavita, visit www.kavita-ganesan.com.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Author of The Business Case For AI | AI Integration Advisor & Consultant | Learn More: Kavita-Ganesan.com or AIBusinessCaseBook.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd0a2fca9dad3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kavita-ganesan.medium.com/?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": ""}, {"url": "https://kavita-ganesan.medium.com/?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "Kavita Ganesan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcd869a6dee38&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&user=Kavita+Ganesan&userId=cd869a6dee38&source=post_page-cd869a6dee38----d0a2fca9dad3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0a2fca9dad3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0a2fca9dad3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@2hrrc?utm_source=medium&utm_medium=referral", "anchor_text": "Hugo Ruiz"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1301.3781.pdf", "anchor_text": "Word2Vec implementation by Google"}, {"url": "http://kavita-ganesan.com/entity-ranking-data/", "anchor_text": "OpinRank"}, {"url": "http://kavita-ganesan.com/opinion-based-entity-ranking/", "anchor_text": "Ph.D work"}, {"url": "https://github.com/kavgan/data-science/tree/master/word2vec", "anchor_text": "OpinRank Word2Vec"}, {"url": "https://radimrehurek.com/gensim/utils.html", "anchor_text": "Gensim documentation site"}, {"url": "https://github.com/kavgan/data-science/tree/master/word2vec", "anchor_text": "Word2Vec OpinRank"}, {"url": "https://unsplash.com/@vimarovi?utm_source=medium&utm_medium=referral", "anchor_text": "Victor Rodriguez"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "here"}, {"url": "https://github.com/kavgan/data-science/blob/master/word2vec/Word2Vec.ipynb", "anchor_text": "Jupyter Notebook"}, {"url": "https://unsplash.com/@emilianovittoriosi?utm_source=medium&utm_medium=referral", "anchor_text": "Emiliano Vittoriosi"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/kavgan/data-science/tree/master/word2vec", "anchor_text": "GitHub repo"}, {"url": "https://www.amazon.com/Business-Case-Strategies-Real-World-Applications-dp-1544528728/dp/1544528728/ref=mt_other?_encoding=UTF8&me=&qid=", "anchor_text": "The Business Case for AI: A Leader\u2019s Guide to AI Strategies, Best Practices & Real-World Applications"}, {"url": "http://www.kavita-ganesan.com", "anchor_text": "www.kavita-ganesan.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d0a2fca9dad3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d0a2fca9dad3---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/tech?source=post_page-----d0a2fca9dad3---------------tech-----------------", "anchor_text": "Tech"}, {"url": "https://medium.com/tag/programming?source=post_page-----d0a2fca9dad3---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/technology?source=post_page-----d0a2fca9dad3---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd0a2fca9dad3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&user=Kavita+Ganesan&userId=cd869a6dee38&source=-----d0a2fca9dad3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd0a2fca9dad3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&user=Kavita+Ganesan&userId=cd869a6dee38&source=-----d0a2fca9dad3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0a2fca9dad3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd0a2fca9dad3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d0a2fca9dad3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d0a2fca9dad3--------------------------------", "anchor_text": ""}, {"url": "https://kavita-ganesan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kavita-ganesan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kavita Ganesan"}, {"url": "https://kavita-ganesan.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "640 Followers"}, {"url": "http://Kavita-Ganesan.com", "anchor_text": "Kavita-Ganesan.com"}, {"url": "http://AIBusinessCaseBook.com", "anchor_text": "AIBusinessCaseBook.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcd869a6dee38&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&user=Kavita+Ganesan&userId=cd869a6dee38&source=post_page-cd869a6dee38--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F19439f593d32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3&newsletterV3=cd869a6dee38&newsletterV3Id=19439f593d32&user=Kavita+Ganesan&userId=cd869a6dee38&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}