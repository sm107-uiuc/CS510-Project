{"url": "https://towardsdatascience.com/what-the-heck-is-word-embedding-b30f67f01c81", "time": 1682994963.4961238, "path": "towardsdatascience.com/what-the-heck-is-word-embedding-b30f67f01c81/", "webpage": {"metadata": {"title": "What the heck is Word Embedding. Looking at text data through the lens\u2026 | by Samarth Agrawal | Towards Data Science", "h1": "What the heck is Word Embedding", "description": "Word Embedding is really all about improving the ability of networks to learn from text data. By representing that data as lower dimensional vectors. These vectors are called Embedding. This\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Word Embedding => Collective term for models that learned to map a set of words or phrases in a vocabulary to vectors of numerical values.", "Neural Networks are designed to learn from numerical data.", "Word Embedding is really all about improving the ability of networks to learn from text data. By representing that data as lower dimensional vectors. These vectors are called Embedding.", "This technique is used to reduce the dimensionality of text data but these models can also learn some interesting traits about words in a vocabulary.", "General approach for dealing with words in your text data is to one-hot encode your text. You will have tens of thousands of unique words in your text vocabulary. Computations with such one-hot encoded vectors for these words will be very inefficient because most values in your one-hot vector will be 0. So, the matrix calculation that will happen in between a one-hot vector and a first hidden layer will result in a output that will have mostly 0 values", "We use embeddings to solve this problem and greatly improve the efficiency of our network. Embeddings are just like a fully-connected layer. We will call this layer as\u2014 embedding layer and the weights as \u2014 embedding weights.", "Now, instead of doing the matrix multiplication between the inputs and hidden layer we directly grab the values from embedding weight matrix. We can do this because the multiplication of one-hot vector with weight matrix returns the row of the matrix corresponding to the index of \u20181\u2019 input unit", "So, we use this Weight Matrix as lookup table. We encode the words as integers, for example \u2018cool\u2019 is encoded as 512, \u2018hot\u2019 is encoded as 764. Then to get hidden layer output value for \u2018cool\u2019 we just simply need to lookup the 512th row in the weight matrix. This process is called Embedding Lookup. The number of dimension in the hidden layer output is the embedding dimension", "a) The embedding layer is just a hidden layer", "b) The lookup table is just a embedding weight matrix", "c) The lookup is just a shortcut for matrix multiplication", "d) The lookup table is trained just like any weight matrix", "Popular off-the-shelf word embedding models in use today:", "This model is provided by Google and is trained on Google News data. This model has 300 dimensions and is trained on 3 million words from google news data.", "Team used skip-gram and negative sampling to build this model. It was released in 2013.", "Global Vectors for words representation (GloVe) is provided by Stanford. They provided various models from 25, 50, 100, 200 to 300 dimensions based on 2, 6, 42, 840 billion tokens", "Team used word-to-word co-occurrence to build this model. In other words, if two words co-occur many times, it means they have some linguistic or semantic similarity.", "This model is developed by Facebook. They provide 3 models with 300 dimensions each.", "fastText is able to achieve good performance for word representations and sentence classifications because they are making use of character level representations.", "Each word is represented as bag of characters n-grams in addition to the word itself. For example, for the word partial, with n=3, the fastText representation for the character n-grams is <pa, art, rti, tia, ial, al>. <and> are added as boundary symbols to separate the n-grams from the word itself.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "15 years in Data Science. I'm sharing valuable tips, ideas, and code snippets on Machine Learning & Deep Learning"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb30f67f01c81&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://samarthagrawal86.medium.com/?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": ""}, {"url": "https://samarthagrawal86.medium.com/?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "Samarth Agrawal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2c9c1e60de25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&user=Samarth+Agrawal&userId=2c9c1e60de25&source=post_page-2c9c1e60de25----b30f67f01c81---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb30f67f01c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb30f67f01c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@ratushny?utm_source=medium&utm_medium=referral", "anchor_text": "Dmitry Ratushny"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://code.google.com/archive/p/word2vec/", "anchor_text": "Word2Vec"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe"}, {"url": "https://fasttext.cc/", "anchor_text": "fastText:"}, {"url": "https://medium.com/@samarth.agrawal.86", "anchor_text": "follow me on medium"}, {"url": "https://www.linkedin.com/in/samarth-agrawal-2501/", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b30f67f01c81---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----b30f67f01c81---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----b30f67f01c81---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----b30f67f01c81---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/ai?source=post_page-----b30f67f01c81---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb30f67f01c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&user=Samarth+Agrawal&userId=2c9c1e60de25&source=-----b30f67f01c81---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb30f67f01c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&user=Samarth+Agrawal&userId=2c9c1e60de25&source=-----b30f67f01c81---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb30f67f01c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb30f67f01c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b30f67f01c81---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b30f67f01c81--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b30f67f01c81--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b30f67f01c81--------------------------------", "anchor_text": ""}, {"url": "https://samarthagrawal86.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://samarthagrawal86.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Samarth Agrawal"}, {"url": "https://samarthagrawal86.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "491 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2c9c1e60de25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&user=Samarth+Agrawal&userId=2c9c1e60de25&source=post_page-2c9c1e60de25--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd946063b0300&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-the-heck-is-word-embedding-b30f67f01c81&newsletterV3=2c9c1e60de25&newsletterV3Id=d946063b0300&user=Samarth+Agrawal&userId=2c9c1e60de25&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}