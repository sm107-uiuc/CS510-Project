{"url": "https://towardsdatascience.com/the-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674", "time": 1683014831.350467, "path": "towardsdatascience.com/the-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674/", "webpage": {"metadata": {"title": "The Counter-Intuitiveness of Fairness in Machine Learning | by Wai On | Towards Data Science", "h1": "The Counter-Intuitiveness of Fairness in Machine Learning", "description": "The idea that what happened in the past can serve as a good predictor of the future is the central tenet behind much of the incredible success of Machine Learning (ML). However, this\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.washingtonpost.com/business/2019/11/11/apple-card-algorithm-sparks-gender-bias-allegations-against-goldman-sachs/", "anchor_text": "Apple credit card algorithm", "paragraph_index": 0}, {"url": "https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/", "anchor_text": "discriminating against black defendants", "paragraph_index": 0}, {"url": "https://www.nature.com/articles/nature08785", "anchor_text": "hardwired sense of fairness", "paragraph_index": 0}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899", "anchor_text": "Barocas & Selbst", "paragraph_index": 1}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3144831", "anchor_text": "Huq", "paragraph_index": 1}, {"url": "https://press.uchicago.edu/ucp/books/book/chicago/F/bo10672189.html", "anchor_text": "one scholar puts it", "paragraph_index": 4}, {"url": "https://dl.acm.org/doi/10.1145/3194770.3194776", "anchor_text": "Verma & Rubin", "paragraph_index": 6}, {"url": "https://perma.cc/HE3CGXDU", "anchor_text": "Narayan", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Protected_group", "anchor_text": "protected groups", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Civil_Rights_Act_of_1964", "anchor_text": "Title VII", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Equal_Protection_Clause", "anchor_text": "Equal Protection Clause", "paragraph_index": 7}, {"url": "https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf", "anchor_text": "correlated variables that are tantamount to the use of protected variables", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Omitted-variable_bias#:~:text=In%20statistics%2C%20omitted%2Dvariable%20bias,to%20those%20that%20were%20included.", "anchor_text": "omitted-variable-bias formula", "paragraph_index": 34}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3144831", "anchor_text": "Huq", "paragraph_index": 45}, {"url": "https://www.loc.gov/law/foreign-news/article/netherlands-court-prohibits-governments-use-of-ai-software-to-detect-welfare-fraud/", "anchor_text": "banning of use of a benefit fraud prediction tool in the Netherlands", "paragraph_index": 51}, {"url": "https://www.technologyreview.com/2020/06/26/1004500/a-new-us-bill-would-ban-the-police-use-of-facial-recognition/", "anchor_text": "banning of face recognition software in the US", "paragraph_index": 51}, {"url": "https://en.wikipedia.org/wiki/2020_UK_GCSE_and_A-Level_grading_controversy", "anchor_text": "withdrawal of A-levels grades prediction in the UK", "paragraph_index": 51}, {"url": "https://en.wikipedia.org/wiki/A_Theory_of_Justice", "anchor_text": "philosophy and ethics", "paragraph_index": 57}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3462379", "anchor_text": "Equal Protection Under Algorithms: A New Statistical and Legal Framework", "paragraph_index": 58}, {"url": "https://www.aeaweb.org/articles?id=10.1257/pol.3.3.206", "anchor_text": "Implementing Anti-Discrimination Policies in Statistical Profiling Models", "paragraph_index": 59}], "all_paragraphs": ["The idea that what happened in the past can serve as a good predictor of the future is the central tenet behind much of the incredible success of Machine Learning (ML). However, this \u201cpast-as-prelude\u201d approach to predicting behavior is increasingly under scrutiny due to its perceived failures relating to bias, discrimination, and fairness. For example, the revelation that the Apple credit card algorithm was giving women less credit than men; the accusation that a widely used software for assessing recidivism risk was discriminating against black defendants. These reports not only grab news headlines, they rile our hardwired sense of fairness\u00b9.", "In criminal justice, there is a sustained debate on whether existing anti-discrimination laws are adequate for the oversight of predictive algorithms. In addition, there is a burgeoning research community examining how we can safeguard fairness in predictive algorithms under these laws (e.g. Barocas & Selbst, Huq). As recent unrest and protests over systemic discrimination have shown, the consequence of getting it wrong is severe. As more and more of our lives become automated, there is an urgency in accelerating our effort in making this technology acceptable to the society as a whole.", "In this article, I will review an idea on how to bring fairness to ML. The idea appears to be counter-intuitive at first blush, but as a couple of articles have illustrated, it has a solid statistical and legal grounding.", "This article is intended for anyone with a basic understanding of ML and is interested in how we can work towards implementing fairness in ML.", "Fairness is a social ideal. As one scholar puts it,", "Fairness is whatever people say it is, as long as they agree.", "In a free society, this ideal is both contentious and ever evolving. It is not surprising then that we have so many definitions of fairness in the ML literature (e.g. Verma & Rubin, Narayan).", "Despite the lack of a definitive agreement on fairness, there are well established laws in the US that protect the basic rights of individuals despite their differences. Most notably, differences such as race, gender, and religion represent a set of \u201cprotected groups\u201d that enables individuals to be treated \u201cfairly\u201d, particularly in the areas of employment (Title VII of the Civil Rights Act of 1964) and criminal justice (Equal Protection Clause of the Fourteenth Amendment).", "As a consequence of these laws and the history of discrimination in the past, the mainstream approach to bringing fairness to ML, and predictive algorithms in general, is to eliminate the use of data from protected groups. Yang and Dobbie\u00b2 compiled a list of eight commercially available tools most commonly used in the criminal justice system and found that all of them exclude race (a protected group) as an input.", "Eliminating protected groups as input is not sufficient however. As a number of scholars point out, we are still left with correlated variables that are tantamount to the use of protected variables. For example, ZIP code can act as a proxy for race. Yet, there is no agreement on whether these should also be excluded. In the same list of commercially available tools, Yang and Dobbie found that only three out of eight exclude the use of correlated variables. In other words, a high proportion of the most commonly used predictive algorithms, 5/8 (62.5%), can be argued to be breaching established laws protecting individuals with protected attributes. These are potential lawsuits waiting to happen!", "The current approaches can be summarized as follows.", "Restrictive (Exclude protected groups and correlated variables):", "The quandary for algorithm makers is that further eliminating variables based on their correlation to protected groups will ultimately render the algorithm virtually useless. For example, in Yang and Dobbie\u2019s study, they found that all their input variables were correlated with the protected variables. So following the spirit of the mainstream approach of elimination of protected attributes would deprive an ML algorithm of any input!", "How do we bring fairness into ML while at the same time preserve its utility?", "Pope and Sydnor\u00b3 introduced a simple statistical framework for eliminating the effects of protected variables and their proxies. This framework was used and further examined by Yang and Dobbie\u00b2 in the context of pretrial predictions.", "It works like this: Let\u2019s say we are making a prediction. For example, the likelihood that a defendant will reoffend before their trial. Based on this prediction, we can then decide if we should release the defendant before the trial.", "In this framework, we represent defendants\u2019 characteristics by three types of variables:", "For simplicity, the authors assume a predictive model using Linear Regression (Ordinary Least Square):", "In other words, the prediction equals the sum of a constant (Beta-0) plus unprotected variables, correlated variables, protected variables and their weight coefficients (Beta-1, Beta-2, Beta-3), plus an error term (E). The authors also discussed how this model can be extended to more complex non-linear models under the proposed framework.", "The method for making a prediction under this framework consists of 2 steps:", "Step 1: Train a predictive model and obtain coefficient estimates. That is, Beta-0, Beta-1, Beta-2, and Beta-3 from the equation above.", "Step 2: Make predictions using coefficient estimates from step 1 and the average values of the protected variables.", "That\u2019s all there is to it! Not only is this method deceptively simple, it is also counter-intuitive in the sense that we are using protected variables and their proxies as part of the algorithm to ensure fairness!", "Let\u2019s start backwards with the second step since this step contains the major change and is actually quite intuitive.", "With the exception of using the estimated coefficients, the only difference between this step and the first step is that instead of using data with protected characteristics we use the average of it.", "More precisely, we are using the average vector of protected groups for the population. This means that two individuals who differ only in terms of a protected characteristic will not receive different predictions. For example, if race is a protected variable then the model would not know the racial profile of the individual. It is said to be \u201cblind\u201d to the effects of the protected variable. This is precisely what we want from a fair ML algorithm.", "But what about the correlated term? That is,", "Doesn\u2019t this include the proxy effects of the protected variable? The answer is no because of the first step. Pope and Sydnor explain it like this:", "First, let\u2019s look at the estimate for the commonly accepted approach:", "That is, the sum of a constant and the uncorrelated and correlated variables with their associated coefficients; which we know contains proxy effects due to the inclusion of correlated variables.", "Now compare this to the estimate for the benchmark equation:", "Assuming that Beta-3 is greater than zero, we see that Gamma-2 cannot be equal to Beta-2.", "This is because in (ii) we are estimating with the protected variable and in (i) we are estimating without it. Our intuition tells us that the coefficient Gamma-2 is carrying the estimation power of the proxy. In other words, Gamma-2 is carrying a term that allows Xc to be a correlate of Xp.", "Let\u2019s unpack this further. Since Xc is correlated with Xp, we can assume that:", "Using the standard omitted-variable-bias formula from Economics literature, we can substitute the benchmark equation with (iii):", "Compare this to the commonly accepted approach (i),", "Ignoring the constant and error terms, we now see that Gamma-2 estimates towards Beta-2 plus Beta-3 times Alpha-C, where Beta-2 is the uncorrelated weight coefficient (what the authors call the orthogonal coefficient), and Alpha-C is the weighted correlation coefficient. That is,", "By including the protected variable Xp in step 1, we are actually making the coefficient for Xc independent of Xp. Yang and Dobbie put it like this:", "\u201cEstimating this benchmark model allows us to obtain predictive weights on correlated characteristics that are not contaminated by proxy effects, exactly because we explicitly include X_protected. Thus, this first estimation step ensures that we eliminate all proxy effects from including X_correlated\u201d (p.34)", "We can therefore be confident that Beta-2 is not \u201ccontaminated\u201d by the correlates. In other words, it does not contain proxy effects from the Protected variables.", "Using sum of squared errors as the measure, Pope and Sydnor analyzed the predictive accuracy of the different formulations of the statistical framework. The result shows that their proposed framework is the third most accurate, behind the Benchmark model and the Common model but more accurate than the Restrictive model:", "As expected, the Benchmark model and Common model were more accurate than the Proposed model since they include the use of protected variables and their proxies. However, because of the tenuous legal standing of such a practice, algorithm makers may need to use a more restrictive model (providing they can find variables that can be considered as uncorrelated with other variables). The Proposed model provides a way to avoid the need to resort to a restrictive approach.", "Yang and Dobbie applied the models to a large dataset of pretrial cases between 2008 and 2013 from New York City. They also painstakingly cross-referenced pretrial cases to whether the defendant actually appeared in court. The result is a data corpus of around 200,000 defendants.", "Their findings corroborate the accuracy findings from Pope and Sydnor. Furthermore, although it is true that we are sacrificing accuracy for fairness, Yang and Sydnor showed that the differences in accuracy between the different algorithms are extremely small. For example, at a 50% release rate, the rates of failure to appear in court were:", "Under the dataset examined, the proposed model would result in only eight additional failures-to-appear.", "Since this framework uses data from protected groups, does it potentially violate the law? For example, the Equal Protection Clause of the Fourteenth Amendment imposes two fundamental protections with respect to race (see Huq\u2074 ):", "So if race is used under this framework, does it violate discrimination laws? Yang and Dobbie argued that it does not. Even though the framework uses protected groups, it does so in order to achieve a \u201crace-neutral prediction\u201d.", "Classifications based on \u201cprotected characteristics\u201d are given \u201cstrict scrutiny\u201d by the courts (i.e., #1 above). However, Yang and Dobbie argued that the Constitution \u201cbars all racial classifications, except as a remedy for specific wrongdoing\u201d. They argued that the framework", "\u201cshould not be subject to strict scrutiny given that the use/consideration of race is not meant to distinguish or treat individuals differently on the basis of membership in a particular racial group, but the exact opposite.\u201d. (p.37)", "Even if it does get flagged, they argue that it would withstand any legal scrutiny since the purpose of the procedure is \u201ctailored towards the aim of remedying and correcting for proxy effects and historical biases that can be \u2018baked in\u2019 to an algorithm\u2026\u201d (i.e., #2 above, see p.37)", "Yang and Dobbie acknowledge, however, that a \u201clack of understanding of the underlying statistical properties of direct and proxy effects in algorithms may lead a na\u00efve observer to conclude that both proposals are illegal because they run up against the widely accepted prohibition on the use or consideration of protected characteristics.\u201d (p.36) The onus is on us, the ML and related communities, to educate and communicate the framework in a way that is easily understood by the Courts and by the public at large.", "It is often said that AI, and ML in particular, will profoundly change the world. However, what types of relationships we establish with this nascent technology and how our lives will change are still to be determined. The recent pushbacks against predictive algorithms, e.g. the banning of use of a benefit fraud prediction tool in the Netherlands, the banning of face recognition software in the US, and the withdrawal of A-levels grades prediction in the UK, show the struggles that we have as a free society to craft a symbiosis that is acceptable by everyone.", "We cannot stumble into the future without being cognizant of our past, nor should we stifle technologies that grant us unprecedented opportunities to transform society for the better. For ML to mature, we need to learn, educate, and come to an informed decision about what the desirable characteristics of this technology should be.", "\u201cMan will only become better when you make him see what he is like.\u201c Anton Chekhov", "In this article, I highlighted a statistical framework that aims to bring fairness to ML whilst retaining the usefulness of the algorithm. Although counterintuitive at first glance, Pope and Sydnor\u2019s framework has been shown to be both theoretically and legally sound. The model created using this framework does lose some degree of accuracy when compared to legally contentious models; however, it does so in a way that eliminates the influence of input from protected variables and their proxies.", "This work also raises an important question about what \u201caccuracy\u201d means in ML. For example, is accuracy a simple question of the number of correct predictions made by an algorithm? As Pope and Sydnor put it, the question becomes:", "\u201cis it more important to predict the outcomes correctly (\u201cget it right on average\u201d) or to weight the different characteristics properly (\u201cget it right at the margins\u201d)?\u201d", "Seeing it this way, many of the heated debates in algorithm fairness mentioned earlier can essentially be thought of as a difference in emphasis. Such debates have a long history in philosophy and ethics. No doubt, as long as we differ with respect to the ideals to which we subscribe, these debates will likely continue. The work highlighted here therefore deserves more attention. It provides a practical solution that theoretically satisfies the demands of the law without severely compromising the predictive power of the algorithm.", "[2] Crystal Yang & Will Dobbie, Equal Protection Under Algorithms: A New Statistical and Legal Framework, AVAILABLE SSRN 3462379 (2019)", "[3] Devin G. Pope & Justin R. Sydnor, Implementing Anti-Discrimination Policies in Statistical Profiling Models,3 AEJ: Policy 206 (2011)", "Thanks to Mark David, Ryan Richards, and Ron Espeseth for comments on an earlier draft.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI Researcher, UI Designer, Psychologist, User Researcher, Plastics Climber, and follower of the Bourdain trail."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6a27a6a53674&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@waion?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@waion?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "Wai On"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fffc520ef72ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&user=Wai+On&userId=ffc520ef72ba&source=post_page-ffc520ef72ba----6a27a6a53674---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a27a6a53674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a27a6a53674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.washingtonpost.com/business/2019/11/11/apple-card-algorithm-sparks-gender-bias-allegations-against-goldman-sachs/", "anchor_text": "Apple credit card algorithm"}, {"url": "https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/", "anchor_text": "discriminating against black defendants"}, {"url": "https://www.nature.com/articles/nature08785", "anchor_text": "hardwired sense of fairness"}, {"url": "https://unsplash.com/@unseenhistories?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unseen Histories"}, {"url": "https://unsplash.com/@unseenhistories?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899", "anchor_text": "Barocas & Selbst"}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3144831", "anchor_text": "Huq"}, {"url": "https://press.uchicago.edu/ucp/books/book/chicago/F/bo10672189.html", "anchor_text": "one scholar puts it"}, {"url": "https://dl.acm.org/doi/10.1145/3194770.3194776", "anchor_text": "Verma & Rubin"}, {"url": "https://perma.cc/HE3CGXDU", "anchor_text": "Narayan"}, {"url": "https://en.wikipedia.org/wiki/Protected_group", "anchor_text": "protected groups"}, {"url": "https://en.wikipedia.org/wiki/Civil_Rights_Act_of_1964", "anchor_text": "Title VII"}, {"url": "https://en.wikipedia.org/wiki/Equal_Protection_Clause", "anchor_text": "Equal Protection Clause"}, {"url": "https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf", "anchor_text": "correlated variables that are tantamount to the use of protected variables"}, {"url": "https://en.wikipedia.org/wiki/Omitted-variable_bias#:~:text=In%20statistics%2C%20omitted%2Dvariable%20bias,to%20those%20that%20were%20included.", "anchor_text": "omitted-variable-bias formula"}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3144831", "anchor_text": "Huq"}, {"url": "https://www.loc.gov/law/foreign-news/article/netherlands-court-prohibits-governments-use-of-ai-software-to-detect-welfare-fraud/", "anchor_text": "banning of use of a benefit fraud prediction tool in the Netherlands"}, {"url": "https://www.technologyreview.com/2020/06/26/1004500/a-new-us-bill-would-ban-the-police-use-of-facial-recognition/", "anchor_text": "banning of face recognition software in the US"}, {"url": "https://en.wikipedia.org/wiki/2020_UK_GCSE_and_A-Level_grading_controversy", "anchor_text": "withdrawal of A-levels grades prediction in the UK"}, {"url": "https://en.wikipedia.org/wiki/A_Theory_of_Justice", "anchor_text": "philosophy and ethics"}, {"url": "https://science.sciencemag.org/content/320/5879/1092", "anchor_text": "https://science.sciencemag.org/content/320/5879/1092"}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3462379", "anchor_text": "Equal Protection Under Algorithms: A New Statistical and Legal Framework"}, {"url": "https://www.aeaweb.org/articles?id=10.1257/pol.3.3.206", "anchor_text": "Implementing Anti-Discrimination Policies in Statistical Profiling Models"}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3144831#", "anchor_text": "Duke Law Journal, Vol. 68,"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6a27a6a53674---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/fairness?source=post_page-----6a27a6a53674---------------fairness-----------------", "anchor_text": "Fairness"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6a27a6a53674---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----6a27a6a53674---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/bias?source=post_page-----6a27a6a53674---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a27a6a53674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&user=Wai+On&userId=ffc520ef72ba&source=-----6a27a6a53674---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a27a6a53674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&user=Wai+On&userId=ffc520ef72ba&source=-----6a27a6a53674---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a27a6a53674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6a27a6a53674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6a27a6a53674---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6a27a6a53674--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6a27a6a53674--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6a27a6a53674--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@waion?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@waion?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Wai On"}, {"url": "https://medium.com/@waion/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "36 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fffc520ef72ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&user=Wai+On&userId=ffc520ef72ba&source=post_page-ffc520ef72ba--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F142465632daa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-counter-intuitiveness-of-fairness-in-machine-learning-6a27a6a53674&newsletterV3=ffc520ef72ba&newsletterV3Id=142465632daa&user=Wai+On&userId=ffc520ef72ba&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}