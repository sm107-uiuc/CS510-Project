{"url": "https://towardsdatascience.com/map-reduce-gradient-descent-276e6ed0b002", "time": 1683001970.292455, "path": "towardsdatascience.com/map-reduce-gradient-descent-276e6ed0b002/", "webpage": {"metadata": {"title": "Map-Reduce: Gradient Descent. Using PySpark and vanilla Python | by Harsh Darji | Towards Data Science", "h1": "Map-Reduce: Gradient Descent", "description": "Some statistical models \ud835\udc53(\ud835\udc65) are learned by optimizing a loss function \ud835\udc3f(\u0398) that depends on a set of parameters \u0398. There are several ways of finding the optimal \u0398 for the loss function, one of\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Some statistical models \ud835\udc53(\ud835\udc65) are learned by optimizing a loss function \ud835\udc3f(\u0398) that depends on a set of parameters \u0398. There are several ways of finding the optimal \u0398 for the loss function, one of which is to iteratively update following the gradient:", "Because we assume independence between data points, the gradient becomes a summation:", "where \ud835\udc3f\ud835\udc56 is the loss function for the \ud835\udc56-th data point.", "Then the loss function for each of them is", "if we start with a solution \ud835\udc4f0=0, \ud835\udc4f1=1 then the gradients are:", "Now, we create a function that will receive parameters b and one data point x as lists and return the prediction (y) for that data point.", "We define a function that receives predicted y and actual y and returns squared error between them.", "Function gf_linear(f, b, x, y) will return the gradient of the function f with parameter b with respect to the squared loss function, evaluated at x and actual outcome y. This function should return a vector with each element \ud835\udc57 corresponding to the gradient with respect \ud835\udc4f\ud835\udc57, with \ud835\udc57={0,1,\u2026,\ud835\udc5d}.", "We develop a map-reduce job that produces a value so that the first element of the value is the mean loss function across all the data. We implement our map function as map_mse(f, b, L, xy) where f is the function b are the parameters of the function L is the loss function and xy is the data. Assume that the data will come as an RDD where each element is of the format:", "[x, y] where x is a list and y is a scalar", "Now we create a reduce job that receives two values of a previous reduce (or map) and merge them appropriately. At the end of the reduce job, the first element of the value is the mean squared error.", "So, now we will compute the cumulative gradient of a model on the data. We will define a map function map_gradient(f, gf, b, xy) that would receive a function f, its gradient gf, its parameters b, and a data point xy = [x, y]. Also, we will define a function reduce_gradient(v1, v2) that combines the two values appropriately.", "Now, to get an optimized value, we run the following code such that MSE decreases everytime.", "Thank you for reading, I hope you got to learn or at least understand how gradient descent works and how it can be implemented using Map-Reduce.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Illustrator & Writer sharing insights on self-discovery and human potential. Currently writing The Daily Visuals \ud83d\udcd5"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F276e6ed0b002&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://harsh-darji.medium.com/?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": ""}, {"url": "https://harsh-darji.medium.com/?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "Harsh Darji"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F703114a951d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&user=Harsh+Darji&userId=703114a951d3&source=post_page-703114a951d3----276e6ed0b002---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F276e6ed0b002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F276e6ed0b002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=70509", "anchor_text": "Gerd Altmann"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=70509", "anchor_text": "Pixabay"}, {"url": "https://www.linkedin.com/in/harshdarji23/", "anchor_text": "Harsh Darji - Contributing Writer - Medium | LinkedInI am a Data Science enthusiast in pursuit of applying advanced analytics, standing up big-data analytical tools\u2026www.linkedin.com"}, {"url": "https://github.com/harshdarji23", "anchor_text": "harshdarji23 - OverviewSign up for your own profile on GitHub, the best place to host code, manage projects, and build software alongside 40\u2026github.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----276e6ed0b002---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----276e6ed0b002---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----276e6ed0b002---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/big-data?source=post_page-----276e6ed0b002---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/mapreduce?source=post_page-----276e6ed0b002---------------mapreduce-----------------", "anchor_text": "Mapreduce"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F276e6ed0b002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&user=Harsh+Darji&userId=703114a951d3&source=-----276e6ed0b002---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F276e6ed0b002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&user=Harsh+Darji&userId=703114a951d3&source=-----276e6ed0b002---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F276e6ed0b002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F276e6ed0b002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----276e6ed0b002---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----276e6ed0b002--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----276e6ed0b002--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----276e6ed0b002--------------------------------", "anchor_text": ""}, {"url": "https://harsh-darji.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://harsh-darji.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Harsh Darji"}, {"url": "https://harsh-darji.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F703114a951d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&user=Harsh+Darji&userId=703114a951d3&source=post_page-703114a951d3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fdeca08ab9ae1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmap-reduce-gradient-descent-276e6ed0b002&newsletterV3=703114a951d3&newsletterV3Id=deca08ab9ae1&user=Harsh+Darji&userId=703114a951d3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}