{"url": "https://towardsdatascience.com/using-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56", "time": 1683002286.660932, "path": "towardsdatascience.com/using-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56/", "webpage": {"metadata": {"title": "Using Convolutional Neural Networks to Generate Harmony | by Luke Griswold | Towards Data Science", "h1": "Using Convolutional Neural Networks to Generate Harmony", "description": "Using Neural Networks (NN) to generate music has been discussed several times on Towards Data Science, but usually under the context of sequence generation using Recurrent Neural Networks (RNNs) and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/generating-music-with-artificial-intelligence-9ce3c9eef806", "anchor_text": "several times", "paragraph_index": 0}, {"url": "https://web.mit.edu/music21/", "anchor_text": "Music21", "paragraph_index": 2}, {"url": "https://magenta.tensorflow.org/coconet", "anchor_text": "Google AI Team", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1903.07227", "anchor_text": "interesting paper", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33", "anchor_text": "skip connections", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1812.01060", "anchor_text": "Bach2Bach", "paragraph_index": 9}, {"url": "https://github.com/Kickflip89/Convolution-Music-AI", "anchor_text": "GitHub repository", "paragraph_index": 14}], "all_paragraphs": ["Using Neural Networks (NN) to generate music has been discussed several times on Towards Data Science, but usually under the context of sequence generation using Recurrent Neural Networks (RNNs) and some Convolutional Neural Networks (CNNs). This article is about an approach using convolution to generating harmonies with four instruments capable of generating one pitch at any given time.", "The major advantage of using Convolutional Neural Networks is that, like image recognition, music is invariant under time (themes / motifs) and pitch (transposition). Thus, convolution is an ideal operation to find patterns in music such as chord progressions or cadences when the data is organized as a matrix representing time and pitch. Specifically for this project, time is organized into discrete time based on sampling the pitches of a given instrument (voice) at a certain frequency. Choosing the frequency has consequences on how the model performs, as we shall soon see.", "This project eventually settled on eighth note discrete time scales and a 128 chromatic pitch vector based on .midi file capabilities. For the data set, 163 Bach Chorales were chosen based on parsing through the Music21 corpus for the chorales that had four voices and were in a 4:4 time signature. This data representation and model architecture was first done by a Google AI Team who also published an interesting paper about their techniques. This project uses many of those techniques but is implemented in Keras and with Music21.", "The basic idea of using a CNN is to use several filters for different patterns (cadences, chords, etc.) to generate probability distributions over all the possible pitches for each discrete time step. A piece of music can be generated from either no input or from partial inputs by repeatedly sampling from the unknown notes and generating new probability distributions.", "Music21\u2019s corpus works with music files in musicXML format, so a helper class needs to be built in order to turn those files into a numpy array representing a piano roll (found in utils.py in the github repository). Another method that I built was a method to transpose a piano roll into a random key by adding or subtracting a number on the interval [1,11] from the pitches (the chromatic scale has 12 notes). In this way, batches of inputs can be generated by selecting a random 4 measures from one of the Bach chorales and transposing it to a random key.", "The four piano rolls (one for each Soprano, Alto, Tenor, and Bass voice) are then stacked together with four mask matrices that represent what time steps contain known pitches for each voice. The model is then trained by taking batches of Bach Chorales and erasing the same notes for each piece in the batch. A custom loss function then minimizes the sum of the negative log-likelihoods for the correct pitches of the erased values (divided by the total number of erased notes in order to avoid weighting batches with more erased notes or batches with different orderings more heavily).", "Implementing this in Keras required the use of a custom defined generator to make the batches of inputs, as well as a custom loss function, which makes the model a little difficult to save and load. Luckily, once a model is trained, .json and .h5 files can load a model for inference purposes.", "The paper this model follows used 64 convolution layers with 128 filters. They were eventually able to use dilated convolution in order to save computing power. Since I had to train this model on a single computer without large numbers of GPUs, the architecture I used was 20 convolutional layers with 64 5x5 filters. Like the original paper, BatchNormalization and skip connections were used every two layers. For the convolution layers, ReLU activations were used with padding to keep the original size of the input in terms of time and pitch.", "The final layer is a convolution layer that outputs four channels and uses the softmax activation. In this way, the output can be trained to become the four voices with probability distributions over the 128 pitches at each time step. The loss is then computed by summing the negative logs of the probabilities corresponding to the actual notes for the erased notes in the input.", "Several papers have looked at different sampling and resampling methods for music generation. Bach2Bach\u2019s architecture used a pseudo-Gibbs Sampling procedure to rewrite parts of a generated score. Coconet\u2019s paper looked at different techniques and found that the one that created the best generated music samples was to use an annealed probability for sampling from erased or unknown notes. The equation for this annealed probability is fairly simple to understand, it is: \u03b1_n = max(\u03b1_min, n(\u03b1_max \u2014 \u03b1_min)/BN, Where the \u03b1 values represent probabilities that an erased note in the input will be erased for the next iteration of the sampling. B represents the fraction of steps the sampling should occur above \u03b1_min, and N is the total number of steps, generally set to the number of voices (4) times the number of time steps (32).", "The way Gibbs sampling works and why it works so well has to do with the probability distributions converging on a coherent piece of music. If we feed a mostly erased score (or random noise) into the model, the probability distributions will generally be spread out across several pitches since each pitch depends on what comes before and after it, as well as what is happening in the other voices. In effect, we have are trying to model a joint probability distribution without enough context of the other variables.", "So, we sample from the probability distributions to obtain pitches at each unknown time step, then erase all of those pitches again with probability \u03b1_n. In this way, the block sampling that occurs at the beginning of the Gibbs sampling keeps the music from simply staying on the same note. As the process moves forward, fewer and fewer notes are being re sampled, which allows the probability distributions over the erased notes to converge on musically coherent pitches.", "Using the metric of Negative Log Likelihood, it can appear that higher temporal resolution is beneficial to the music quality. For training the network, for example, the minimum loss function when using sixteenth note resolution was .168, or about an average probability of 85% over the erased notes. The quarter note resolution\u2019s best loss function was .487, or about an average probability of 61%. However, the sixteenth note resolution can achieve better success by highly weighting the pitches before and after the current time step in its own voice, since a quarter note represents four time steps in sixteenth note resolution. A better metric is to see if the Gibbs sampling procedure reduces the average negative log-likelihood.", "With the trained models, it appears 1/16th note resolution is over-fit, as it does very well on the training data and can achieve low NLLs there, but the NLL does not converge during the Gibbs sampling process. The best behavior was exhibited by the eighth note resolution where a melody was input into the model, with the other voices unknown.", "Code base and music samples for the project can be found at the following GitHub repository.", "[1] M. Cuthbert and C. Ariza. music21: A Toolkit for Computer-Aided Musicology and Symbolic Music Data. 2010. In Proceedings of the International Society for Music Information Retrieval.", "[2] G. Hadjeres, F. Pachet, and F. Nielsen. DeepBach: a Steerable Model for Bach Chorales Generation. 2010. In Proceedings of the 34th International Conference on Machine Learning.", "[3] C. Huang, T. Cooijmans, A. Roberts, et. al. Counterpoint by Convolution. 2017. In Proceedings of the 18th International Society for Music Information Retrieval Conference.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Former F/A-18 Weapons System Officer and current Data Scientist at Naval Air Warfare Center \u2014 Training Systems Division."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1a1cdfd7ec56&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lukedgriswold.medium.com/?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": ""}, {"url": "https://lukedgriswold.medium.com/?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "Luke Griswold"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feeeb494bd3e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&user=Luke+Griswold&userId=eeeb494bd3e7&source=post_page-eeeb494bd3e7----1a1cdfd7ec56---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a1cdfd7ec56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a1cdfd7ec56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/generating-music-with-artificial-intelligence-9ce3c9eef806", "anchor_text": "several times"}, {"url": "https://web.mit.edu/music21/", "anchor_text": "Music21"}, {"url": "https://magenta.tensorflow.org/coconet", "anchor_text": "Google AI Team"}, {"url": "https://arxiv.org/abs/1903.07227", "anchor_text": "interesting paper"}, {"url": "https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33", "anchor_text": "skip connections"}, {"url": "https://arxiv.org/abs/1812.01060", "anchor_text": "Bach2Bach"}, {"url": "https://github.com/Kickflip89/Convolution-Music-AI", "anchor_text": "GitHub repository"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1a1cdfd7ec56---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----1a1cdfd7ec56---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/music?source=post_page-----1a1cdfd7ec56---------------music-----------------", "anchor_text": "Music"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a1cdfd7ec56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&user=Luke+Griswold&userId=eeeb494bd3e7&source=-----1a1cdfd7ec56---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a1cdfd7ec56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&user=Luke+Griswold&userId=eeeb494bd3e7&source=-----1a1cdfd7ec56---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a1cdfd7ec56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1a1cdfd7ec56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1a1cdfd7ec56---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1a1cdfd7ec56--------------------------------", "anchor_text": ""}, {"url": "https://lukedgriswold.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lukedgriswold.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Luke Griswold"}, {"url": "https://lukedgriswold.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "10 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feeeb494bd3e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&user=Luke+Griswold&userId=eeeb494bd3e7&source=post_page-eeeb494bd3e7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Feeeb494bd3e7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-convolutional-neural-networks-to-generate-harmony-1a1cdfd7ec56&user=Luke+Griswold&userId=eeeb494bd3e7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}