{"url": "https://towardsdatascience.com/from-research-to-production-with-deep-semi-supervised-learning-7caaedc39093", "time": 1683014347.721662, "path": "towardsdatascience.com/from-research-to-production-with-deep-semi-supervised-learning-7caaedc39093/", "webpage": {"metadata": {"title": "From Research to Production with Deep Semi-Supervised Learning | by Varun Nair | Towards Data Science", "h1": "From Research to Production with Deep Semi-Supervised Learning", "description": "The success of most deep learning algorithms today is largely the result of decades of research, the growing availability of GPUs, and data. But not just any kind of data \u2014 the kind that is abundant\u2026"}, "outgoing_paragraph_urls": [{"url": "http://uizard.io", "anchor_text": "Uizard", "paragraph_index": 3}, {"url": "https://www-cs.stanford.edu/~pliang/papers/meng-thesis.pdf", "anchor_text": "Liang et al., 2005", "paragraph_index": 15}, {"url": "https://www.sciencedirect.com/science/article/abs/pii/S0167639304000962", "anchor_text": "Tur et al., 2005", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/1804.09170.pdf", "anchor_text": "Oliver et al., 2018", "paragraph_index": 18}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019", "paragraph_index": 21}, {"url": "https://ieeexplore.ieee.org/document/1053799", "anchor_text": "Scudder, 1965", "paragraph_index": 25}, {"url": "https://www.tandfonline.com/doi/abs/10.1080/01621459.1975.10479874", "anchor_text": "McLachlan, 1975", "paragraph_index": 25}, {"url": "http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf", "anchor_text": "Lee, 2013", "paragraph_index": 25}, {"url": "https://www.ri.cmu.edu/pub_files/pub4/rosenberg_charles_2005_1/rosenberg_charles_2005_1.pdf", "anchor_text": "Rosenberg et al., 2005", "paragraph_index": 31}, {"url": "https://arxiv.org/abs/1911.04252", "anchor_text": "Xie et al., 2019", "paragraph_index": 41}, {"url": "https://arxiv.org/pdf/1912.00594.pdf", "anchor_text": "Song et al., 2020", "paragraph_index": 41}, {"url": "https://arxiv.org/pdf/2006.06882.pdf", "anchor_text": "Zoph et al., 2020", "paragraph_index": 44}, {"url": "https://arxiv.org/pdf/2005.04757.pdf", "anchor_text": "Sohn et al., 2020-B", "paragraph_index": 46}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019", "paragraph_index": 46}, {"url": "https://uizard.io/", "anchor_text": "Uizard", "paragraph_index": 51}, {"url": "https://uizard.io/", "anchor_text": "our website", "paragraph_index": 52}, {"url": "https://arxiv.org/pdf/1912.08766.pdf", "anchor_text": "Nair et al., 2019", "paragraph_index": 55}, {"url": "https://arxiv.org/pdf/1804.09170.pdf", "anchor_text": "Oliver et al., 2018", "paragraph_index": 55}], "all_paragraphs": ["The success of most deep learning algorithms today is largely the result of decades of research, the growing availability of GPUs, and data. But not just any kind of data \u2014 the kind that is abundant, clean, and labeled.", "Datasets like ImageNet, CIFAR10, SVHN, and others, have allowed researchers and practitioners to make remarkable progress on computer vision tasks and were immensely useful for our own experimentation. Yet the elephant in the room for many applications that seek to benefit from this progress, such as medicine, is precisely the fact that the data must be abundant, clean, and labeled.", "Semi-supervised learning (SSL), a subfield that combines both supervised and unsupervised learning, has grown in popularity in the deep learning research community over the past few years. It\u2019s very possible that, at least in the short-term, SSL approaches could be the bridge between label-heavy supervised learning and a future of data-efficient modeling.", "In this post, we talk about when you should consider using SSL approaches in your production environments and the lessons we\u2019ve learned using them to improve our object detection models at Uizard. Of course, we\u2019ll do our best to share the big picture but keep some details of the wizardry to ourselves.", "Our hope is that by displaying how and when SSL worked and didn\u2019t work for us and by sharing tips learned on our journey from research to production, we can inspire you to take a chance on SSL for your work and unlock the potential of your unlabeled data.", "In short, here are a few lessons we emphasize:", "True to its name, Semi-Supervised Learning (SSL) refers to a class of algorithms between supervised and unsupervised learning \u2014 aiming to model a distribution using both labeled and unlabeled data.", "The goal of SSL is often to do so better than using labeled data alone and aspirationally, able to model the target distribution as if we had access to labels for all of the unlabeled data as well.", "Such algorithms are not a new idea, although in deep semi-supervised learning there has been a considerable amount of interest, progress, and applications made in the past 18 months that we\u2019ll discuss below.", "If you\u2019re considering SSL for a problem you\u2019re tackling, it must be because your dataset is large and has many unlabeled data points. A portion of your dataset may be labeled and of course the more labeled data the merrier \u2014 but hopefully there is at least as much unlabeled data as labeled data or perhaps orders of magnitude more.", "If most of the data available to you is labeled or the unlabeled dataset comes from a significantly different distribution than the labeled dataset, then SSL probably isn\u2019t a good fit for your application right now. For the latter case, check out domain adaptation instead.", "With this is mind, there are two main settings that justify the study of SSL approaches in real-world applications:", "In this setting, we stress that the likelihood of production-worthy performance is lower \u2014 but it could make sense to attempt SSL for a task that has little labeled data given an order of magnitude or more of unlabeled data and enough incentive, time, and resources.", "In this setting, you likely already have a model that is doing well or almost as well as required \u2014 but you\u2019d like to continue to push performance higher without expending much effort on labeling new data. As such, SSL could be considered among one of many other tools to improve modeling, such as obtaining a cleaner labeled dataset, training larger models, etc. For performance-critical applications where a 5\u201310%+ relative reduction in error rates is significant and where unlabeled data is available, SSL can be especially relevant.", "It\u2019s worth noting that especially since Uizard is a startup with a fast growing beta user-base, SSL used in a continuous/active learning setting also has the potential to create the cycle you see below. The unlabeled data is used to train and deploy improved models in our platform, which in turn drives additional users, resulting in additional unlabeled data to start the process all over.", "Here are a few of the approaches we tried below for image classification and object detection, but SSL can just as well be applied to other domains like NLP (Liang et al., 2005) and audio/speech processing (Tur et al., 2005).", "While we will not go through each of the above approaches in detail, the following blogs on semi-supervised learning are great and cover many of the techniques listed above.", "During our initial literature review of semi-supervised learning approaches in June 2019, it was fascinating to read about MixMatch and UDA making remarkable strides in SSL, especially in the setting with extremely limited labeled data. We were able to reproduce their results on CIFAR10 and SVHN with relative ease, giving us confidence in their ability to translate those gains in performance to our datasets.", "However, our experience doing so was less than optimal, primarily because of \u2014 surprise! \u2014 hyper-parameter tuning. Many of the out-of-the-box hyper-parameters meant for datasets used in the papers were more sensitive to performance shifts with our dataset. We also noticed that our labeled dataset was slightly different in distribution to the unlabeled dataset, an issue which generally decreased performance in SSL techniques and was brought up in Oliver et al., 2018 as a challenge SSL would need to overcome to be used in \u201crealistic\u201d setups (see Appendix A at the end of this blog for our work studying this). As of September of 2019, it didn\u2019t seem that existing state-of-the-art techniques for SSL were simple or flexible enough for us to proceed.", "Fast forward to June of 2020, two new works in SSL had since been released that focused on simple implementations \u2014 FixMatch and Self-Training with Noisy Student.", "FixMatch was a simpler yet more effective version of its predecessor, MixMatch, and we successfully replicated their results on the datasets presented in the paper (CIFAR10, SVHN). This time we were able to see good results on our own image classification datasets, with performance less sensitive to the choice of hyper-parameters and of which fewer were available to tune.", "Noisy Student training consists of an iterative process in which we train a teacher model (model with access to labeled data), use this model to infer outputs on unlabeled data, then re-train a new model, known as a student, on the labeled data and pseudo-labeled data. We can then repeat this cycle, known as self-training, by inferring new pseudo-labels on the unlabeled set with this student model. In Xie et al., 2019, they showed how this framework presented above improved ImageNet classification accuracy when using 300M unlabeled images and emphasized the addition of various types of noise (augmentation, dropout, etc.) in student models as the key to success in several ablation studies.", "It\u2019s important to note that the Noisy Student approach is a task-agnostic framework that can be applied widely: image classification, object detection, sentiment analysis, etc. For us, the Noisy Student approach was the most successful for object detection among all of the techniques we attempted. We discuss why FixMatch\u2019s object detection counterpart (STAC) and other approaches may not have worked for us in lesson #3, but we firmly believe Noisy Student\u2019s simplicity and flexibility compared to other approaches were the reasons we saw improvements in our production models.", "Why was it simple? There was little to no change to existing training hyper-parameters and settings. Here\u2019s what was needed for the full pipeline:", "Overall, when it came to image classification or object detection, simplicity was king. FixMatch was markedly easier to adapt to our custom image classification datasets than MixMatch was and Noisy Student required very little changes to our existing object detection pipelines to see improved performance.", "Pseudo-labeling, also known as self-training, is a paradigm in SSL that appeared as early as the 1960s and 70s and has stuck around because of its simplicity (Scudder, 1965; McLachlan, 1975). The introduction of pseudo-labeling for deep SSL (Lee, 2013) showcased how simple yet powerful the idea of training a model with labeled data, using that model to infer labels on unlabeled data (which are now called pseudo-labels), and then retraining with the labeled and pseudo-labeled data could be. Many SSL techniques today use some form of pseudo-labeling, including FixMatch and Self-Training with Noisy Student.", "However, these pseudo-labels can often be noisy and require some form of refinement in order to be used. In FixMatch and Noisy Student, this means applying a threshold (say 0.7 or 0.9) to the inferred pseudo-labels and taking only those predictions with a softmax confidence score above it. We found this to be a useful heuristic for getting high-quality pseudo-labels, but also found applying other domain-specific heuristics to the pseudo-labels to help significantly in the Noisy Student setup.", "What kinds of heuristics are we talking about? For example, let\u2019s say you were building an object detection classifier for a real-estate firm that requires bounding box annotations for different objects in a home. You notice that the predictions of the (teacher) model are generally good, however, the classifier tends to produce several incorrect, high-confidence predictions on the unlabeled set that some of the dressers are in fact kitchen islands.", "Here are some example heuristics we can choose from to refine this label:", "Which of the above heuristics make the most sense? That would depend on your dataset and what kinds of errors are most common. If the model was doing a great job detecting beds, perhaps a heuristic like the first or third examples might be useful since we don\u2019t expect beds and kitchen islands to appear in the same image.", "In object detection especially, when the position and size of the objects follow certain rules in your application domain, you can define heuristics like these to refine noisy pseudo-labels and help your student model learn better representations that your teacher model could not.", "We were able to achieve even better performance in our own Noisy Student models using heuristic pseudo-label refinement and, in some cases, with an order of magnitude less unlabeled data than labeled data. We also find it interesting that this lesson sounds strikingly similar to this observation from a paper by Rosenberg et al., 2005 titled Semi-Supervised Self-Training of Object Detection Models:", "\u2026a training data selection metric that is defined independently of the detector greatly outperforms a selection metric based on the detection confidence generated by the detector.", "Is this the solution to all of your data and modeling problems? Of course not \u2014 but it illustrates how heuristics can still be a useful part of a deep (semi-supervised) learning pipeline. Again, the heuristics applied here are domain-specific and only careful exploration of your data and the model\u2019s biases will reveal useful pseudo-label refinements.", "Much of the progress in SSL research that we followed measured performance on image classification with hopes of easily adapting techniques for similar improvements on other tasks, like object detection. However, in our own attempts adapting image classification approaches for object detection we encountered several challenges \u2014 leading us to stick with the simplest of semi-supervised object detection approaches mentioned in Lesson #1. Here are a few of those challenges:", "In many SSL techniques for image classification (FixMatch, UDA, etc.), the pseudo-label targets for unlabeled data are updated/computed during training, or online. In offline learning training is split into multiple stages. A model is first trained with labeled samples, which is then used to generate pseudo-labels. A new model can then be trained with labeled and pseudo-labeled samples.", "FixMatch and UDA are examples of SSL techniques that use online learning to good effect with a threshold, allowing only unlabeled samples predicted above a certain threshold to contribute to training signal \u2014 in Noisy Student and STAC (an object detection variant of FixMatch), however, the pseudo-labels are generated offline.", "While it appears that online learning is advantageous \u2014 allowing for poor pseudo-labels early in training to be corrected in later training steps \u2014 it makes training more computationally expensive and even more so for training object detection models. Why? Two things: data augmentation and batch sizes. On data augmentation, let\u2019s revisit the diagram first presented in lesson #1 on FixMatch.", "We see that each unlabeled example is both \u201cweakly-augmented\u201d and \u201cstrongly-augmented\u201d during training and requires a forward pass of both augmented images through the network to compute loss. Such data augmentation is a cornerstone of many SSL approaches and while practical for image classification, processing training time augmentations for object detection tasks on large images (512x512+) slows down training significantly.", "On batch size, many works (MixMatch, UDA, FixMatch, Noisy Student) and our own experiments also highlight that having an unlabeled batch size several times the size of the labeled batch is critical (5\u201310x+) to the success of SSL approaches. This requirement for object detection tasks compounded with large images in memory and the necessary augmentations for all samples in the unlabeled batch creates an extremely large computational burden. These two challenges of data augmentation and unlabeled batch sizing were ultimately the reasons we failed to convert works like FixMatch one-to-one for object detection.", "In discussions with the authors of STAC, they also noted the heavy resource overhead that comes with online learning in the semi-supervised object detection space. We hope that future work will study this problem more in-depth and that computational gains made in the coming years make such work more accessible for researchers.", "Many datasets benchmarked in SSL research like CIFAR10, CIFAR100, and STL-10 use class-balanced labeled training sets. Our datasets, like many real-world datasets, are extremely long-tailed. Class-balancing has been noted as a key component for many SSL approaches (Xie et al., 2019, Song et al., 2020) and in image classification, upsampling and downsampling techniques are common practice. However, in object detection settings effective class-balancing techniques aren\u2019t so straightforward.", "If class-balancing is critical to the success of SSL in practice, then how do we class-balance in semi-supervised object detection? Future research that addresses this problem would certainly be welcomed.", "Transfer Learning and Self-Training were additive", "As was found in Zoph et al., 2020 on COCO training, performing transfer learning from COCO to our datasets and then performing self-training in the Noisy Student setup yielded results that were better than doing either of the two steps alone. It\u2019s likely that any transfer learning that\u2019s being applied to your production models can also be applied to SSL models with equal or more benefit.", "Since data augmentation is a major component of modern SSL approaches, make sure the augmentations make sense for your domain. For example, a classifier that should be trained to distinguish between bounding boxes of a left-arrow and a right-arrow would obviously suffer if the set of augmentations available include horizontal flips.", "Additionally, in STAC (Sohn et al., 2020-B) and Noisy Student (Xie et al., 2019), they observe that, in self-training, using data augmentation on the teacher model results in poorer downstream student models.", "However, we found performance of noisy student and STAC on our datasets with augmented teacher models to be equal to or slightly better than non-augmented teacher models. While our result may be a special case for our own datasets, we believe this shows the importance of experimenting extensively and being curious about the purported success and failings of ideas that you read in papers. Empirical results shown in papers are a great prior to start from, but success is certainly not guaranteed and there is much in SSL that is still not well-understood from a theoretical perspective.", "Semi-Supervised Learning (SSL) has been an exciting field for us to work in for the past year and its end results in our production models show us, and hopefully you all, that SSL can and should be considered in certain situations.", "In particular, Self-Training with Noisy Student was effective for improving our object detection models. Here\u2019s a recap of the 3 main lessons we learned researching and productionizing deep SSL techniques:", "So much of deep learning engineering today is still trial and error with informed priors for potential applications \u2014 we hoped that you walked away with a few more priors for your work moving forward with semi-supervised learning.", "Written by Varun Nair, 4th year undergraduate at Duke University and former deep learning research intern at Uizard.", "A big thank you goes to Javier Fuentes Alonso and Tony Beltramelli for reading several early drafts of this post and for being amazing colleagues and mentors during my time at Uizard. Thank you as well to the entire team at Uizard for supporting me and creating a fantastic environment to work in, both in-person and remotely. If you\u2019re interested in learning more about what Uizard does and its job openings, please check out our website.", "Thank you also to Dr. Colin Raffel at UNC/Google for offering great insights and feedback on early drafts of this piece, and to Dr. Kihyuk Sohn at Google for being responsive and open to answering my questions about his works.", "A \u2014 Robustness to Out-of-Distribution Samples", "In our past work, RealMix (Nair et al., 2019), we studied the robustness to out-of-distribution unlabeled samples in SSL networks by mimicking an experiment first established in Oliver et al., 2018.", "We recently ran the same robustness experiment on FixMatch at the 75% label mismatch setting and present those results below. FixMatch is a better SSL application at 0% mismatch and 75% mismatch between the labeled and unlabeled distributions, however, its performance suffers just as MixMatch does in this setting. It\u2019s possible that by combining the elements from RealMix with FixMatch this combined technique could overcome this problem."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7caaedc39093&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/making-sense-of-big-data", "anchor_text": "Making Sense of Big Data"}, {"url": "https://nairvarun.medium.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": ""}, {"url": "https://nairvarun.medium.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Varun Nair"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30509bf8c463&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=post_page-30509bf8c463----7caaedc39093---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7caaedc39093&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=-----7caaedc39093---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7caaedc39093&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&source=-----7caaedc39093---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "http://uizard.io", "anchor_text": "Uizard"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019"}, {"url": "https://www-cs.stanford.edu/~pliang/papers/meng-thesis.pdf", "anchor_text": "Liang et al., 2005"}, {"url": "https://www.sciencedirect.com/science/article/abs/pii/S0167639304000962", "anchor_text": "Tur et al., 2005"}, {"url": "https://arxiv.org/pdf/1905.02249.pdf", "anchor_text": "pdf"}, {"url": "https://github.com/google-research/mixmatch", "anchor_text": "code"}, {"url": "https://arxiv.org/pdf/1904.12848.pdf", "anchor_text": "pdf"}, {"url": "https://github.com/google-research/uda", "anchor_text": "code"}, {"url": "https://arxiv.org/pdf/2001.07685.pdf", "anchor_text": "pdf"}, {"url": "https://github.com/google-research/fixmatch", "anchor_text": "code"}, {"url": "https://papers.nips.cc/paper/9259-consistency-based-semi-supervised-learning-for-object-detection.pdf", "anchor_text": "pdf"}, {"url": "https://github.com/soo89/CSD-SSD", "anchor_text": "code"}, {"url": "https://arxiv.org/pdf/2005.04757.pdf", "anchor_text": "pdf"}, {"url": "https://github.com/google-research/ssl_detection/", "anchor_text": "code"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "pdf"}, {"url": "https://github.com/google-research/noisystudent", "anchor_text": "code"}, {"url": "https://amitness.com/2020/07/semi-supervised-learning/", "anchor_text": "Semi-Supervised Learning in Computer Vision"}, {"url": "https://yassouali.github.io/ml-blog/deep-semi-supervised/", "anchor_text": "Deep Semi-Supervised Learning"}, {"url": "https://ruder.io/semi-supervised/", "anchor_text": "An overview of proxy-label approaches for semi-supervised learning"}, {"url": "https://arxiv.org/pdf/1804.09170.pdf", "anchor_text": "Oliver et al., 2018"}, {"url": "https://arxiv.org/pdf/2001.07685.pdf", "anchor_text": "Sohn et al., 2020"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019"}, {"url": "https://ieeexplore.ieee.org/document/1053799", "anchor_text": "Scudder, 1965"}, {"url": "https://www.tandfonline.com/doi/abs/10.1080/01621459.1975.10479874", "anchor_text": "McLachlan, 1975"}, {"url": "http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf", "anchor_text": "Lee, 2013"}, {"url": "https://www.ri.cmu.edu/pub_files/pub4/rosenberg_charles_2005_1/rosenberg_charles_2005_1.pdf", "anchor_text": "Rosenberg et al., 2005"}, {"url": "https://arxiv.org/pdf/2001.07685.pdf", "anchor_text": "Sohn et al., 2020"}, {"url": "https://arxiv.org/abs/1911.04252", "anchor_text": "Xie et al., 2019"}, {"url": "https://arxiv.org/pdf/1912.00594.pdf", "anchor_text": "Song et al., 2020"}, {"url": "https://arxiv.org/pdf/2006.06882.pdf", "anchor_text": "Zoph et al., 2020"}, {"url": "https://arxiv.org/pdf/2005.04757.pdf", "anchor_text": "Sohn et al., 2020-B"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019"}, {"url": "https://arxiv.org/pdf/1911.04252.pdf", "anchor_text": "Xie et al., 2019"}, {"url": "https://uizard.io/", "anchor_text": "Uizard"}, {"url": "https://uizard.io/", "anchor_text": "our website"}, {"url": "https://arxiv.org/pdf/1912.08766.pdf", "anchor_text": "Nair et al., 2019"}, {"url": "https://arxiv.org/pdf/1804.09170.pdf", "anchor_text": "Oliver et al., 2018"}, {"url": "https://arxiv.org/pdf/1912.08766.pdf", "anchor_text": "Nair et al., 2019"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----7caaedc39093---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/semi-supervised-learning?source=post_page-----7caaedc39093---------------semi_supervised_learning-----------------", "anchor_text": "Semi Supervised Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7caaedc39093---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/research?source=post_page-----7caaedc39093---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/tag/making-sense-of-big-data?source=post_page-----7caaedc39093---------------making_sense_of_big_data-----------------", "anchor_text": "Making Sense Of Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7caaedc39093&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=-----7caaedc39093---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7caaedc39093&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=-----7caaedc39093---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7caaedc39093&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://nairvarun.medium.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30509bf8c463&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=post_page-30509bf8c463----7caaedc39093---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F30509bf8c463%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=-----7caaedc39093---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://nairvarun.medium.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Written by Varun Nair"}, {"url": "https://nairvarun.medium.com/followers?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "68 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30509bf8c463&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=post_page-30509bf8c463----7caaedc39093---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F30509bf8c463%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-research-to-production-with-deep-semi-supervised-learning-7caaedc39093&user=Varun+Nair&userId=30509bf8c463&source=-----7caaedc39093---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/improving-ui-layout-understanding-with-hierarchical-positional-encodings-b19e1e9235e?source=author_recirc-----7caaedc39093----0---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://nairvarun.medium.com/?source=author_recirc-----7caaedc39093----0---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://nairvarun.medium.com/?source=author_recirc-----7caaedc39093----0---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Varun Nair"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7caaedc39093----0---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/improving-ui-layout-understanding-with-hierarchical-positional-encodings-b19e1e9235e?source=author_recirc-----7caaedc39093----0---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Improving UI Layout Understanding with Hierarchical Positional EncodingsHow can we modify transformers for UI-centric tasks?"}, {"url": "https://towardsdatascience.com/improving-ui-layout-understanding-with-hierarchical-positional-encodings-b19e1e9235e?source=author_recirc-----7caaedc39093----0---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "11 min read\u00b7Feb 26, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb19e1e9235e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-ui-layout-understanding-with-hierarchical-positional-encodings-b19e1e9235e&user=Varun+Nair&userId=30509bf8c463&source=-----b19e1e9235e----0-----------------clap_footer----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/improving-ui-layout-understanding-with-hierarchical-positional-encodings-b19e1e9235e?source=author_recirc-----7caaedc39093----0---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb19e1e9235e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-ui-layout-understanding-with-hierarchical-positional-encodings-b19e1e9235e&source=-----7caaedc39093----0-----------------bookmark_preview----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7caaedc39093----1---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----7caaedc39093----1---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----7caaedc39093----1---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7caaedc39093----1---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7caaedc39093----1---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7caaedc39093----1---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7caaedc39093----1---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----7caaedc39093----1-----------------bookmark_preview----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7caaedc39093----2---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----7caaedc39093----2---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----7caaedc39093----2---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7caaedc39093----2---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7caaedc39093----2---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7caaedc39093----2---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7caaedc39093----2---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----7caaedc39093----2-----------------bookmark_preview----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7caaedc39093----3---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----7caaedc39093----3---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----7caaedc39093----3---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7caaedc39093----3---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7caaedc39093----3---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7caaedc39093----3---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----3-----------------clap_footer----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----7caaedc39093----3---------------------859d6a29_947e_4f5d_8bb9_c864f8d6112e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----7caaedc39093----3-----------------bookmark_preview----859d6a29_947e_4f5d_8bb9_c864f8d6112e-------", "anchor_text": ""}, {"url": "https://nairvarun.medium.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "See all from Varun Nair"}, {"url": "https://towardsdatascience.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----0-----------------clap_footer----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----7caaedc39093----0-----------------bookmark_preview----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----1-----------------clap_footer----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----7caaedc39093----1-----------------bookmark_preview----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----7caaedc39093----0---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----7caaedc39093----0-----------------bookmark_preview----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Steins"}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Diffusion Model Clearly Explained!How does AI artwork work? Understanding the tech behind the rise of AI-generated art."}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "\u00b77 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcd331bd41166&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40steinsfu%2Fdiffusion-model-clearly-explained-cd331bd41166&user=Steins&userId=a36be384d77d&source=-----cd331bd41166----1-----------------clap_footer----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----7caaedc39093----1---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcd331bd41166&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40steinsfu%2Fdiffusion-model-clearly-explained-cd331bd41166&source=-----7caaedc39093----1-----------------bookmark_preview----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----7caaedc39093----2---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/?source=read_next_recirc-----7caaedc39093----2---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/?source=read_next_recirc-----7caaedc39093----2---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Babar M Bhatti"}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----7caaedc39093----2---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Essential Guide to Foundation Models and Large Language ModelsThe term Foundation Model (FM) was coined by Stanford researchers to introduce a new category of ML models. They defined FMs as models\u2026"}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----7caaedc39093----2---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "\u00b714 min read\u00b7Feb 6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F27dab58f7404&operation=register&redirect=https%3A%2F%2Fthebabar.medium.com%2Fessential-guide-to-foundation-models-and-large-language-models-27dab58f7404&user=Babar+M+Bhatti&userId=10dee34829b&source=-----27dab58f7404----2-----------------clap_footer----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----7caaedc39093----2---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27dab58f7404&operation=register&redirect=https%3A%2F%2Fthebabar.medium.com%2Fessential-guide-to-foundation-models-and-large-language-models-27dab58f7404&source=-----7caaedc39093----2-----------------bookmark_preview----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----7caaedc39093----3---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://angeleastbengal.medium.com/?source=read_next_recirc-----7caaedc39093----3---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://angeleastbengal.medium.com/?source=read_next_recirc-----7caaedc39093----3---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Angel Das"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----7caaedc39093----3---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----7caaedc39093----3---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "Generating Word Embeddings from Text Data using Skip-Gram Algorithm and Deep Learning in PythonIntroduction to embeddings in natural language processing using Artificial Neural Network and Gensim"}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----7caaedc39093----3---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": "\u00b713 min read\u00b7Nov 9, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8873b225ab6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6&user=Angel+Das&userId=8418ab50405a&source=-----a8873b225ab6----3-----------------clap_footer----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----7caaedc39093----3---------------------a51ebd96_e742_4d81_85a4_41fe16ef4e76-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8873b225ab6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6&source=-----7caaedc39093----3-----------------bookmark_preview----a51ebd96_e742_4d81_85a4_41fe16ef4e76-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7caaedc39093--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----7caaedc39093--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}