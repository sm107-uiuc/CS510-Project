{"url": "https://towardsdatascience.com/support-vector-machines-explained-with-python-examples-cb65e8172c85", "time": 1683010470.140064, "path": "towardsdatascience.com/support-vector-machines-explained-with-python-examples-cb65e8172c85/", "webpage": {"metadata": {"title": "Support Vector Machines explained with Python examples | by Carolina Bento | Towards Data Science", "h1": "Support Vector Machines explained with Python examples", "description": "Support vector machines (SVM) is a supervised machine learning technique. And, even though it\u2019s mostly used in classification, it can also be applied to regression problems."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/bias-variance-tradeoff-in-machine-learning-models-a-practical-example-cf02fb95b15d", "anchor_text": "Bias-Variance tradeoff", "paragraph_index": 23}], "all_paragraphs": ["Support vector machines (SVM) is a supervised machine learning technique. And, even though it\u2019s mostly used in classification, it can also be applied to regression problems.", "SVMs define a decision boundary along with a maximal margin that separates almost all the points into two classes. While also leaving some room for misclassifications.", "Support vector machines are an improvement over maximal margin algorithms. Its biggest advantage is that it can define both a linear or a non-linear decision boundary by using kernel functions. This makes it more suitable for real-world problems, where data are not always completely separable with a straight line.", "The main goal of an SVM is to define an hyperplane that separates the points in two different classes. The hyperplane is also called separating hyperplane or decision boundary.", "So let\u2019s start with hyperplanes. The easiest away to visualize an hyperplane is if think about a 2-dimensional dataset.", "There\u2019s going to be an infinite number of hyperplanes that separate points into two classes. But, since we\u2019re working in a 2-dimensional space, any hyperplane we define will always have (2\u20131) = 1 dimensions. So, we can represent the hyperplane with a simple regression line.", "With the decision boundary defined, we can now classify points based on where they fall in relation to it.", "If you are working with more than two dimensions, as in, your feature vector X has more than two features, you\u2019re classifying vectors, instead of points.", "So, to generalize, all vectors that fall below the decision boundary belong to class -1, and if they fall above it they belong to class 1.", "We used training data to define the decision boundary. But what about the quality of predictions for the testing set?", "If a vector is far from the decision boundary we can be confident about its class, even if the model has some error. But, what happens when we classify a vector and it is very close to decision boundary? How can we be sure about which class to assign?", "To tackle this issue, support vector machines also draws a margin around the decision boundary. The goal of this margin is to separate the vectors from the decision boundary, as much as possible. The intuition behind it is that a margin gives us more confidence in our predictions. Because the vectors are at least the length of the margin away from the decision boundary, there\u2019s less ambiguity during classification.", "The position of the margin is defined using the vectors that are closest to the decision boundary. That\u2019s why the vectors that lie on top of the margin are the support vectors.", "And with the margin working as a buffer, we can classify a vector based on where they fall relative to the margin. Where M is the width of the margin.", "The addition of a margin improves the quality of the predictions in the testing set, but it assumes the classes are completely separable.", "But, in most real world problems, data is messy and it\u2019s usually not completely separable.", "That\u2019s why SVM shares an important characteristic with the algorithm that came before it, support vector classifiers. It allows the algorithm to make mistakes, and assign the wrong class to some vectors.", "So, instead of trying to completely separate the vectors in into two classes, SMV make a trade-off. It allows for some vectors to fall inside the margin and on the wrong side of the decision boundary.", "Support vector machines allow some misclassification during the learning process. So they can do a better job at classifying most vectors in the testing set.", "Besides the margin, our model now includes slack variables, which will tell us two things:", "Slack variables can have three possible values:", "And number of misclassified vectors is bound by a parameter C.", "We can see the model captures much more nuance. But it\u2019s still built on top of maximum margin classifiers. For instance, if you set parameter C to zero, meaning it allows zero slack variables, it falls back to a maximum margin classifier. So you have a linear decision boundary, a margin that is as large as possible and no vectors allowed inside it.", "The higher the number of slack variables, the higher the number of misclassified vectors allowed. This impacts the width of the margin, because picking different support vectors. And it also controls the Bias-Variance tradeoff of the model.", "Having some room for misclassification makes SMVs more flexibility, but it only applies to a limited set of problems.", "In most real world problems, it\u2019s hard to separate data into two classes with a linear decision boundary. Even with some room for error.", "SVMs share the characteristics of the margin classifiers that came before it. What is unique about them is how they can define both linear and non-linear decision boundaries.", "To support non-linear decision boundaries, SMVs use functions to transform the original feature space into a new space can represent those non-linear relationships.", "For instance, say you augment the original feature space with the square its features. In this case, you applied a quadratic function to the original feature set to create the square of those features. Now you have your original feature and their quadratic version, in this augmented space. And so, implicitly, there\u2019s a function that maps these two feature spaces.", "If you try to draw the decision boundary in the original feature space it has a quadratic shape. But if you train your model in the augmented feature space, you\u2019ll find a linear decision boundary that separates the two classes. Because it is a transformation, the quadratic boundary in original feature space corresponds to a linear one in the augmented feature space.", "The functions that define these transformations are called kernels. They work as similarity functions between observations in the training and testing sets.", "Whenever you have a model that is represented with inner products, you can plug in a kernel function. For instance, a linear kernel is the same as applying linear transformations to feature space. And, in this case, it\u2019s the same as a support vector classifier, because the decision boundary is linear.", "With polynomial kernels, you\u2019re projecting the original feature space into a polynomial feature space. So the decision boundary that separates the classes is defined with a higher order polynomial.", "The use of kernels is what distinguishes support vector classifiers from support vector machines. And they open up the possibility to tackle more complex problems. But augmenting the feature space could mean extra computational needs. Because, with a big enough feature space, it can be expensive to fit a model, both in terms of both time and resources.", "Despite the the augmented feature space, kernels bring a significant advantage. SVMs don\u2019t actually compute the transformation of each observation into the augmented space. They use a trick and instead compute the inner product of observations in the augmented space which, computationally, is much cheaper. This is called the kernel trick.", "In the end, SVMs make two important assumptions:", "To see support vector machines in action, I\u2019ve generated a random dataset and split it into two different classes. Here's the code snippet that generates and plots the data.", "Before any classification, the training set looks like this.", "There\u2019s a little space between the two groups of data points. But closer to the center, it\u2019s not clear which data point belongs to which class.", "A quadratic curve might be a good candidate to separate these classes. So let\u2019s fit an SVM with a second-degree polynomial kernel.", "To see the result of fitting this model, we can plot the decision boundary and the margin along with the dataset.", "Here\u2019s the code to plot the decision boundary and margins.", "If we calculate the accuracy of this model against the testing set we get a good result, granted the dataset is very small and generated at random.", "The accuracy is good, but let's see if a more simplistic approach could have solved our problem. To fit an SVM with a linear kernel we just need to update the kernel parameter.", "And plot the decision boundary the same way we did back there.", "Now it looks like there are fewer points inside the margin, and fewer misclassified points. Calculating the accuracy of this model, it has slightly better accuracy than the one with a polynomial kernel.", "So it turns out that for this problem a simpler model, an SVM with a linear kernel, was the best solution.", "Hope you enjoyed these examples, and that you got a better understanding of SVMs and what kinds of problems they can be applied to.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Articles about Data Science and Machine Learning | @carolinabento"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcb65e8172c85&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://carolinabento.medium.com/?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": ""}, {"url": "https://carolinabento.medium.com/?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "Carolina Bento"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe960c0367546&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&user=Carolina+Bento&userId=e960c0367546&source=post_page-e960c0367546----cb65e8172c85---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb65e8172c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb65e8172c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/bias-variance-tradeoff-in-machine-learning-models-a-practical-example-cf02fb95b15d", "anchor_text": "Bias-Variance tradeoff"}, {"url": "https://medium.com/tag/data-science?source=post_page-----cb65e8172c85---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----cb65e8172c85---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----cb65e8172c85---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/support-vector-machine?source=post_page-----cb65e8172c85---------------support_vector_machine-----------------", "anchor_text": "Support Vector Machine"}, {"url": "https://medium.com/tag/supervised-learning?source=post_page-----cb65e8172c85---------------supervised_learning-----------------", "anchor_text": "Supervised Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb65e8172c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&user=Carolina+Bento&userId=e960c0367546&source=-----cb65e8172c85---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb65e8172c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&user=Carolina+Bento&userId=e960c0367546&source=-----cb65e8172c85---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb65e8172c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcb65e8172c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----cb65e8172c85---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cb65e8172c85--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----cb65e8172c85--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----cb65e8172c85--------------------------------", "anchor_text": ""}, {"url": "https://carolinabento.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://carolinabento.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Carolina Bento"}, {"url": "https://carolinabento.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.9K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe960c0367546&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&user=Carolina+Bento&userId=e960c0367546&source=post_page-e960c0367546--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F635709f8047b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-with-python-examples-cb65e8172c85&newsletterV3=e960c0367546&newsletterV3Id=635709f8047b&user=Carolina+Bento&userId=e960c0367546&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}