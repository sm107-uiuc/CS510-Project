{"url": "https://towardsdatascience.com/learning-parameters-part-3-ee8558f65dd7", "time": 1682996252.1786299, "path": "towardsdatascience.com/learning-parameters-part-3-ee8558f65dd7/", "webpage": {"metadata": {"title": "Learning Parameters, Part 3: Stochastic & Mini-Batch Gradient Descent | by Akshay L Chandra | Towards Data Science", "h1": "Learning Parameters, Part 3: Stochastic & Mini-Batch Gradient Descent", "description": "In part 2, we looked at two useful variants of gradient descent \u2014 Momentum-Based and Nesterov Accelerated Gradient Descent. In this post, we are going to look at stochastic versions of gradient\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12", "anchor_text": "Momentum-Based and Nesterov Accelerated Gradient Descent", "paragraph_index": 0}, {"url": "https://www.cse.iitm.ac.in/~miteshk/CS7015.html", "anchor_text": "CS7015: Deep Learning", "paragraph_index": 1}, {"url": "https://www.cse.iitm.ac.in/~miteshk/", "anchor_text": "Prof. Mitesh Khapra", "paragraph_index": 1}, {"url": "https://www.cse.iitm.ac.in/~miteshk/", "anchor_text": "Prof. Mitesh M Khapra", "paragraph_index": 19}, {"url": "https://www.cse.iitm.ac.in/~miteshk/CS7015.html", "anchor_text": "CS7015: Deep Learning", "paragraph_index": 19}, {"url": "http://M.Sc", "anchor_text": "M.Sc", "paragraph_index": 20}], "all_paragraphs": ["In part 2, we looked at two useful variants of gradient descent \u2014 Momentum-Based and Nesterov Accelerated Gradient Descent. In this post, we are going to look at stochastic versions of gradient descent. You can check out all the posts in the Learning Parameters series by clicking on the kicker tag at the top of this post.", "Citation Note: Most of the content and figures in this blog are directly taken from Lecture 5 of CS7015: Deep Learning course offered by Prof. Mitesh Khapra at IIT-Madras.", "Let us look at vanilla gradient descent we talked about in part-1 of the series.", "If you observe the block of code between the two weirdly commented lines, you notice that the gradient is calculated across the entire dataset. Meaning, the algorithm goes over the entire data once before updating the parameters. Why? Because this is the true gradient of the loss as derived earlier in part-1 (the sum of the gradients of the losses corresponding to each data point). This is a good thing as we are not approximating anything. Hence, all theoretical assumptions and guarantees hold (in other words each step guarantees that the loss will decrease). Is this desirable? Sure it is, but what is the flipside?", "Imagine we have a million points in the training data. To make 1 update to w, b the algorithm makes a million calculations. Obviously, this could be very slow!! Can we do something better? Yes, let\u2019s look at stochastic gradient descent.", "Stochastic gradient descent (often shortened to SGD) is an iterative method for optimizing a differentiable objective function, a stochastic approximation of gradient descent optimization. Basically, you are going with an approximation of some sort instead of the noble \u2018true gradient\u2019. Stochastic gradient descent is the dominant method used to train deep learning models. Let\u2019s straightaway look at the code for SGD.", "Here\u2019s what\u2019s going on \u2014 instead of making an update by calculating gradients for all the data points, we make an update with gradients of just one data point at a time. Thus, the name stochastic, as we are estimating the total gradient based on a single data point. Almost like tossing a coin only once and estimating P(heads). Now if we have a million data points we will make a million updates in each epoch (1 epoch = 1 pass over the data; 1 step = 1 update). What is the flipside? It is an approximate (rather stochastic) gradient so no guarantee that each step will decrease the loss.", "Let us see this algorithm geometrically when we have a few data points.", "If you look closely, you can see that our descent makes many tiny oscillations. Why? Because we are making greedy decisions. Each point is trying to push the parameters in a direction most favorable to it (without being aware of how this affects other points). A parameter update which is locally favorable to one point may harm other points (its almost as if the data points are competing with each other). Can we reduce the oscillations by improving our stochastic estimates of the gradient (currently estimated from just 1 data point at a time)? Yes, let\u2019s look at mini-batch gradient descent.", "In the case of mini-batch, instead of making an update with gradients of one data point at a time, we calculate gradients of a batch of data points, of size, say k. Let\u2019s look at the code of MBGD.", "Notice that the algorithm updates the parameters after it sees a mini_batch_size number of data points. The stochastic estimates should now be slightly better.", "Let\u2019s see this algorithm in action when we have k/mini_batch_size = 2.", "Even with a batch size of k=2, the oscillations have reduced slightly. Why? Because we now have somewhat better estimates of the gradient (analogy: we are now tossing the coin k=2 times to estimate P(heads)). The higher the value of k, the more accurate the estimates will be. In practice, typical values of k are 16, 32, 64. Of course, there are still oscillations, and they will always be there as long as we are using an approximate gradient as opposedto the \u2018true gradient.\u2019", "The illustration isn\u2019t clear, and on top of that the k is just 2, so it is hard to see much of a difference. But trust the math, mini-batch helps us get slightly better gradient estimates.", "We can have stochastic versions of momentum based gradient descent and Nesterov accelerated gradient descent.", "While the stochastic versions of both Momentum (red)and NAG (blue) exhibit oscillations the relative advantage of NAG over Momentum still holds (i.e., NAG takes relatively shorter u-turns). Furthermore, both of them are faster than stochastic gradient descent (after 60 steps, stochastic gradient descent [black - left figure] still exhibits a very high error whereas NAG and momentum are close to convergence).", "And, of course, we can also have the mini-batch versions of Momentum and NAG but just not in this post.", "In this part of the learning parameters series, we looked at variations of the gradient descent algorithm that approximate the gradients updates \u2014 Stochastic Gradient Descent and Mini-Batch Gradient Descent. We looked at the key differences between them, python code implementations of both the methods and also illustrated their convergence graphically on a toy problem. We also visualized stochastic versions of Momentum and NAG. In the next post, we will discuss a few useful tips for adjusting the learning rate and momentum related parameters and briefly look at what line search is.", "Read all about it in the next post of this series at:", "A lot of credit goes to Prof. Mitesh M Khapra and the TAs of CS7015: Deep Learning course by IIT Madras for such rich content and creative visualizations. I merely just compiled the provided lecture notes and lecture videos concisely.", "M.Sc. Student @ University of Freiburg"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fee8558f65dd7&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/tag/learning-parameters/latest", "anchor_text": "Learning Parameters"}, {"url": "https://medium.com/@acl21?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Akshay L Chandra"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F202534492f47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&user=Akshay+L+Chandra&userId=202534492f47&source=post_page-202534492f47----ee8558f65dd7---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fee8558f65dd7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&user=Akshay+L+Chandra&userId=202534492f47&source=-----ee8558f65dd7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fee8558f65dd7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&source=-----ee8558f65dd7---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12", "anchor_text": "Momentum-Based and Nesterov Accelerated Gradient Descent"}, {"url": "https://www.cse.iitm.ac.in/~miteshk/CS7015.html", "anchor_text": "CS7015: Deep Learning"}, {"url": "https://www.cse.iitm.ac.in/~miteshk/", "anchor_text": "Prof. Mitesh Khapra"}, {"url": "https://towardsdatascience.com/learning-parameters-part-4-6a18d1d3000b", "anchor_text": "Learning Parameters, Part 4: Tips For Adjusting Learning Rate & Momentum, Line Search"}, {"url": "https://www.cse.iitm.ac.in/~miteshk/", "anchor_text": "Prof. Mitesh M Khapra"}, {"url": "https://www.cse.iitm.ac.in/~miteshk/CS7015.html", "anchor_text": "CS7015: Deep Learning"}, {"url": "https://medium.com/tag/optimization?source=post_page-----ee8558f65dd7---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/learning-parameters?source=post_page-----ee8558f65dd7---------------learning_parameters-----------------", "anchor_text": "Learning Parameters"}, {"url": "https://medium.com/tag/gradient-descent?source=post_page-----ee8558f65dd7---------------gradient_descent-----------------", "anchor_text": "Gradient Descent"}, {"url": "https://medium.com/tag/stochastic-gradient?source=post_page-----ee8558f65dd7---------------stochastic_gradient-----------------", "anchor_text": "Stochastic Gradient"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----ee8558f65dd7---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fee8558f65dd7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&user=Akshay+L+Chandra&userId=202534492f47&source=-----ee8558f65dd7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fee8558f65dd7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&user=Akshay+L+Chandra&userId=202534492f47&source=-----ee8558f65dd7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fee8558f65dd7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F202534492f47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&user=Akshay+L+Chandra&userId=202534492f47&source=post_page-202534492f47----ee8558f65dd7---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4c4c11d45430&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&newsletterV3=202534492f47&newsletterV3Id=4c4c11d45430&user=Akshay+L+Chandra&userId=202534492f47&source=-----ee8558f65dd7---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Written by Akshay L Chandra"}, {"url": "https://medium.com/@acl21/followers?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "http://M.Sc", "anchor_text": "M.Sc"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F202534492f47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&user=Akshay+L+Chandra&userId=202534492f47&source=post_page-202534492f47----ee8558f65dd7---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4c4c11d45430&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-3-ee8558f65dd7&newsletterV3=202534492f47&newsletterV3Id=4c4c11d45430&user=Akshay+L+Chandra&userId=202534492f47&source=-----ee8558f65dd7---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1?source=author_recirc-----ee8558f65dd7----0---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=author_recirc-----ee8558f65dd7----0---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=author_recirc-----ee8558f65dd7----0---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Akshay L Chandra"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ee8558f65dd7----0---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1?source=author_recirc-----ee8558f65dd7----0---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "McCulloch-Pitts Neuron \u2014 Mankind\u2019s First Mathematical Model Of A Biological NeuronIt is very well known that the most fundamental unit of deep neural networks is called an artificial neuron/perceptron. But the very first\u2026"}, {"url": "https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1?source=author_recirc-----ee8558f65dd7----0---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "10 min read\u00b7Jul 24, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5fdf65ac5dd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmcculloch-pitts-model-5fdf65ac5dd1&user=Akshay+L+Chandra&userId=202534492f47&source=-----5fdf65ac5dd1----0-----------------clap_footer----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1?source=author_recirc-----ee8558f65dd7----0---------------------eee00be3_280f_4033_8760_0d119371e1d9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5fdf65ac5dd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmcculloch-pitts-model-5fdf65ac5dd1&source=-----ee8558f65dd7----0-----------------bookmark_preview----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ee8558f65dd7----1---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ee8558f65dd7----1---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ee8558f65dd7----1---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ee8558f65dd7----1---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ee8558f65dd7----1---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ee8558f65dd7----1---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ee8558f65dd7----1---------------------eee00be3_280f_4033_8760_0d119371e1d9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----ee8558f65dd7----1-----------------bookmark_preview----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ee8558f65dd7----2---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ee8558f65dd7----2---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ee8558f65dd7----2---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ee8558f65dd7----2---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ee8558f65dd7----2---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ee8558f65dd7----2---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ee8558f65dd7----2---------------------eee00be3_280f_4033_8760_0d119371e1d9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----ee8558f65dd7----2-----------------bookmark_preview----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975?source=author_recirc-----ee8558f65dd7----3---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=author_recirc-----ee8558f65dd7----3---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=author_recirc-----ee8558f65dd7----3---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Akshay L Chandra"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ee8558f65dd7----3---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975?source=author_recirc-----ee8558f65dd7----3---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "Perceptron Learning Algorithm: A Graphical Explanation Of Why It WorksThis post will discuss the famous Perceptron Learning Algorithm, originally proposed by Frank Rosenblatt in 1943, later refined and\u2026"}, {"url": "https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975?source=author_recirc-----ee8558f65dd7----3---------------------eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": "8 min read\u00b7Aug 22, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd5db0deab975&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fperceptron-learning-algorithm-d5db0deab975&user=Akshay+L+Chandra&userId=202534492f47&source=-----d5db0deab975----3-----------------clap_footer----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975?source=author_recirc-----ee8558f65dd7----3---------------------eee00be3_280f_4033_8760_0d119371e1d9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd5db0deab975&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fperceptron-learning-algorithm-d5db0deab975&source=-----ee8558f65dd7----3-----------------bookmark_preview----eee00be3_280f_4033_8760_0d119371e1d9-------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "See all from Akshay L Chandra"}, {"url": "https://towardsdatascience.com/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Amy @GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Gradient Descent vs Stochastic Gradient Descent vs Batch Gradient Descent vs Mini-batch Gradient\u2026Data science interview questions and answers"}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "\u00b74 min read\u00b7Dec 16, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgrabngoinfo%2F616ba269de8d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fgradient-descent-vs-616ba269de8d&user=Amy+%40GrabNGoInfo&userId=ef6171ffb4ed&source=-----616ba269de8d----0-----------------clap_footer----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F616ba269de8d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fgradient-descent-vs-616ba269de8d&source=-----ee8558f65dd7----0-----------------bookmark_preview----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://blog.devgenius.io/optimization-algorithms-in-deep-learning-bdd44d221013?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@sharanharsoor?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@sharanharsoor?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Sharan Harsoor"}, {"url": "https://blog.devgenius.io/?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Dev Genius"}, {"url": "https://blog.devgenius.io/optimization-algorithms-in-deep-learning-bdd44d221013?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Part 1: Optimization algorithms in Deep Learning. (Learning algorithms)Part 1: Optimization algorithms in Deep Learning. (Learning algorithms)"}, {"url": "https://blog.devgenius.io/optimization-algorithms-in-deep-learning-bdd44d221013?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "7 min read\u00b7Feb 26"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdev-genius%2Fbdd44d221013&operation=register&redirect=https%3A%2F%2Fblog.devgenius.io%2Foptimization-algorithms-in-deep-learning-bdd44d221013&user=Sharan+Harsoor&userId=a32ede907c1d&source=-----bdd44d221013----1-----------------clap_footer----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://blog.devgenius.io/optimization-algorithms-in-deep-learning-bdd44d221013?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbdd44d221013&operation=register&redirect=https%3A%2F%2Fblog.devgenius.io%2Foptimization-algorithms-in-deep-learning-bdd44d221013&source=-----ee8558f65dd7----1-----------------bookmark_preview----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ee8558f65dd7----0---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----ee8558f65dd7----0-----------------bookmark_preview----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----ee8558f65dd7----1---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----ee8558f65dd7----1-----------------bookmark_preview----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----ee8558f65dd7----2---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----ee8558f65dd7----2---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----ee8558f65dd7----2---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Rukshan Pramoditha"}, {"url": "https://medium.com/data-science-365?source=read_next_recirc-----ee8558f65dd7----2---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Data Science 365"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----ee8558f65dd7----2---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Determining the Right Batch Size for a Neural Network to Get Better and Faster ResultsGuidelines for choosing the right batch size to maintain optimal training speed and accuracy while saving computer resources"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----ee8558f65dd7----2---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "\u00b74 min read\u00b7Sep 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-365%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----7a8662830f15----2-----------------clap_footer----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----ee8558f65dd7----2---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&source=-----ee8558f65dd7----2-----------------bookmark_preview----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----ee8558f65dd7----3---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@msayef?source=read_next_recirc-----ee8558f65dd7----3---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@msayef?source=read_next_recirc-----ee8558f65dd7----3---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Sayef"}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----ee8558f65dd7----3---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "Logistic Regression with Gradient Descent and Regularization: Binary & Multi-class ClassificationLearn how to implement logistic regression with gradient descent optimization from scratch."}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----ee8558f65dd7----3---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": "\u00b713 min read\u00b7Apr 9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcc25ed63f655&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40msayef%2Flogistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655&user=Sayef&userId=e05fb963b9fd&source=-----cc25ed63f655----3-----------------clap_footer----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----ee8558f65dd7----3---------------------0cf87105_3b1b_49ee_a52e_5790d7deec4a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc25ed63f655&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40msayef%2Flogistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655&source=-----ee8558f65dd7----3-----------------bookmark_preview----0cf87105_3b1b_49ee_a52e_5790d7deec4a-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----ee8558f65dd7--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}