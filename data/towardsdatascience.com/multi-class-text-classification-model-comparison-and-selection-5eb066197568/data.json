{"url": "https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568", "time": 1682993745.3950899, "path": "towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568/", "webpage": {"metadata": {"title": "Multi-Class Text Classification Model Comparison and Selection | by Susan Li | Towards Data Science", "h1": "Multi-Class Text Classification Model Comparison and Selection", "description": "When working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Supervised_learning", "anchor_text": "supervised machine learning", "paragraph_index": 0}, {"url": "https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice", "anchor_text": "The answer to the question \u201cWhat machine learning model should I use?\u201d is always \u201cIt depends.\u201d Even the most experienced data scientists can\u2019t tell which algorithm will perform best before experimenting them", "paragraph_index": 0}, {"url": "https://bigquery.cloud.google.com/dataset/bigquery-public-data:stackoverflow", "anchor_text": "Google BigQuery", "paragraph_index": 2}, {"url": "https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv", "anchor_text": "https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv", "paragraph_index": 2}, {"url": "http://scikit-learn.org/stable/", "anchor_text": "Scikit-Learn library", "paragraph_index": 11}, {"url": "http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes", "anchor_text": "Naive Bayes", "paragraph_index": 12}, {"url": "http://scikit-learn.org/stable/modules/svm.html#svm", "anchor_text": "Linear Support Vector Machine", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Word2vec", "paragraph_index": 21}, {"url": "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e", "anchor_text": "doc2vec", "paragraph_index": 21}, {"url": "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit", "anchor_text": "100 billion word Google News corpus", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec", "paragraph_index": 29}, {"url": "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e", "anchor_text": "Doc2Vec", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec", "paragraph_index": 29}, {"url": "https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4", "anchor_text": "Multi-Class Text Classification with Doc2vec and Logistic Regression", "paragraph_index": 30}, {"url": "https://radimrehurek.com/gensim/models/doc2vec.html", "anchor_text": "Gensim\u2019s Doc2Vec", "paragraph_index": 31}, {"url": "https://github.com/RaRe-Technologies/gensim/blob/ca0dcaa1eca8b1764f6456adac5719309e0d8e6d/docs/notebooks/doc2vec-IMDB.ipynb", "anchor_text": "Gensim doc2vec tutorial", "paragraph_index": 32}, {"url": "https://keras.io/", "anchor_text": "Keras", "paragraph_index": 38}, {"url": "https://github.com/tensorflow/workshops/blob/master/extras/keras-bag-of-words/keras-bow-model.ipynb", "anchor_text": "Google workshop", "paragraph_index": 39}, {"url": "https://github.com/susanli2016/NLP-with-Python/blob/master/Text%20Classification%20model%20selection.ipynb", "anchor_text": "Jupyter notebook", "paragraph_index": 41}, {"url": "https://github.com/susanli2016/NLP-with-Python/blob/master/Text%20Classification%20model%20selection.ipynb", "anchor_text": "Github", "paragraph_index": 41}, {"url": "https://www.linkedin.com/in/susanli/", "anchor_text": "https://www.linkedin.com/in/susanli/", "paragraph_index": 43}], "all_paragraphs": ["When working on a supervised machine learning problem with a given data set, we try different algorithms and techniques to search for models to produce general hypotheses, which then make the most accurate predictions possible about future instances. The same principles apply to text (or document) classification where there are many models can be used to train a text classifier. The answer to the question \u201cWhat machine learning model should I use?\u201d is always \u201cIt depends.\u201d Even the most experienced data scientists can\u2019t tell which algorithm will perform best before experimenting them.", "This is what we are going to do today: use everything that we have presented about text classification in the previous articles (and more) and comparing between the text classification models we trained in order to choose the most accurate one for our problem.", "We are using a relatively large data set of Stack Overflow questions and tags. The data is available in Google BigQuery, it is also publicly available at this Cloud Storage URL: https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv.", "We have over 10 million words in the data.", "The classes are very well balanced.", "We want to have a look a few post and tag pairs.", "As you can see, the texts need to be cleaned up.", "The text cleaning techniques we have seen so far work very well in practice. Depending on the kind of texts you may encounter, it may be relevant to include more complex text cleaning steps. But keep in mind that the more steps we add, the longer the text cleaning will take.", "For this particular data set, our text cleaning step includes HTML decoding, remove stop words, change text to lower case, remove punctuation, remove bad characters, and so on.", "Now we can have a look a cleaned post:", "After text cleaning and removing stop words, we have only over 3 million words to work with!", "After splitting the data set, the next steps includes feature engineering. We will convert our text documents to a matrix of token counts (CountVectorizer), then transform a count matrix to a normalized tf-idf representation (tf-idf transformer). After that, we train several classifiers from Scikit-Learn library.", "After we have our features, we can train a classifier to try to predict the tag of a post. We will start with a Naive Bayes classifier, which provides a nice baseline for this task. scikit-learn includes several variants of this classifier; the one most suitable for text is the multinomial variant.", "To make the vectorizer => transformer => classifier easier to work with, we will use Pipeline class in Scilkit-Learn that behaves like a compound classifier.", "Linear Support Vector Machine is widely regarded as one of the best text classification algorithms.", "We achieve a higher accuracy score of 79% which is 5% improvement over Naive Bayes.", "Logistic regression is a simple and easy to understand classification algorithm, and Logistic regression can be easily generalized to multiple classes.", "We achieve an accuracy score of 78% which is 4% higher than Naive Bayes and 1% lower than SVM.", "As you can see, following some very basic steps and using a simple linear model, we were able to reach as high as an 79% accuracy on this multi-class text classification data set.", "Using the same data set, we are going to try some advanced techniques such as word embedding and neural networks.", "Now, let\u2019s try some complex features than just simply counting words.", "Word2vec, like doc2vec, belongs to the text preprocessing phase. Specifically, to the part that transforms a text into a row of numbers. Word2vec is a type of mapping that allows words with similar meaning to have similar vector representation.", "The idea behind Word2vec is rather simple: we want to use the surrounding words to represent the target words with a Neural Network whose hidden layer encodes the word representation.", "First we load a word2vec model. It has been pre-trained by Google on a 100 billion word Google News corpus.", "We may want to explore some vocabularies.", "BOW based approaches that includes averaging, summation, weighted addition. The common way is to average the two word vectors. Therefore, we will follow the most common way.", "We will tokenize the text and apply the tokenization to \u201cpost\u201d column, and apply word vector averaging to tokenized text.", "Its time to see how logistic regression classifiers performs on these word-averaging document features.", "It was disappointing, worst we have seen so far.", "The same idea of word2vec can be extended to documents where instead of learning feature representations for words, we learn it for sentences or documents. To get a general idea of a word2vec, think of it as a mathematical average of the word vector representations of all the words in the document. Doc2Vec extends the idea of word2vec, however words can only capture so much, there are times when we need relationships between documents and not just words.", "The way to train doc2vec model for our Stack Overflow questions and tags data is very similar with when we train Multi-Class Text Classification with Doc2vec and Logistic Regression.", "First, we label the sentences. Gensim\u2019s Doc2Vec implementation requires each document/paragraph to have a label associated with it. and we do this by using the TaggedDocument method. The format will be \u201cTRAIN_i\u201d or \u201cTEST_i\u201d where \u201ci\u201d is a dummy index of the post.", "According to Gensim doc2vec tutorial, its doc2vec class was trained on the entire data, and we will do the same. Let\u2019s have a look what the tagged document looks like:", "When training the doc2vec, we will vary the following parameters:", "We initialize the model and train for 30 epochs.", "Next, we get vectors from trained doc2vec model.", "Finally, we get a logistic regression model trained by the doc2vec features.", "We achieve an accuracy score of 80% which is 1% higher than SVM.", "Finally, we are going to do a text classification with Keras which is a Python Deep Learning library.", "The following code were largely taken from a Google workshop. The process is like this:", "So, which model is the best for this particular data set? I will leave it to you to decide.", "Jupyter notebook can be found on Github. Have a productive day!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Changing the world, one post at a time. Sr Data Scientist, Toronto Canada. https://www.linkedin.com/in/susanli/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5eb066197568&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb066197568--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb066197568--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://actsusanli.medium.com/?source=post_page-----5eb066197568--------------------------------", "anchor_text": ""}, {"url": "https://actsusanli.medium.com/?source=post_page-----5eb066197568--------------------------------", "anchor_text": "Susan Li"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F731d8566944a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&user=Susan+Li&userId=731d8566944a&source=post_page-731d8566944a----5eb066197568---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5eb066197568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5eb066197568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Supervised_learning", "anchor_text": "supervised machine learning"}, {"url": "https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice", "anchor_text": "The answer to the question \u201cWhat machine learning model should I use?\u201d is always \u201cIt depends.\u201d Even the most experienced data scientists can\u2019t tell which algorithm will perform best before experimenting them"}, {"url": "https://bigquery.cloud.google.com/dataset/bigquery-public-data:stackoverflow", "anchor_text": "Google BigQuery"}, {"url": "https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv", "anchor_text": "https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv"}, {"url": "http://scikit-learn.org/stable/", "anchor_text": "Scikit-Learn library"}, {"url": "http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes", "anchor_text": "Naive Bayes"}, {"url": "http://scikit-learn.org/stable/modules/svm.html#svm", "anchor_text": "Linear Support Vector Machine"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Word2vec"}, {"url": "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e", "anchor_text": "doc2vec"}, {"url": "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit", "anchor_text": "100 billion word Google News corpus"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec"}, {"url": "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e", "anchor_text": "Doc2Vec"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec"}, {"url": "https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4", "anchor_text": "Multi-Class Text Classification with Doc2vec and Logistic Regression"}, {"url": "https://radimrehurek.com/gensim/models/doc2vec.html", "anchor_text": "Gensim\u2019s Doc2Vec"}, {"url": "https://github.com/RaRe-Technologies/gensim/blob/ca0dcaa1eca8b1764f6456adac5719309e0d8e6d/docs/notebooks/doc2vec-IMDB.ipynb", "anchor_text": "Gensim doc2vec tutorial"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "https://github.com/tensorflow/workshops/blob/master/extras/keras-bag-of-words/keras-bow-model.ipynb", "anchor_text": "Google workshop"}, {"url": "https://github.com/susanli2016/NLP-with-Python/blob/master/Text%20Classification%20model%20selection.ipynb", "anchor_text": "Jupyter notebook"}, {"url": "https://github.com/susanli2016/NLP-with-Python/blob/master/Text%20Classification%20model%20selection.ipynb", "anchor_text": "Github"}, {"url": "https://github.com/RaRe-Technologies/movie-plots-by-genre/blob/master/ipynb_with_output/Document%20classification%20with%20word%20embeddings%20tutorial%20-%20with%20output.ipynb", "anchor_text": "https://github.com/RaRe-Technologies/movie-plots-by-genre/blob/master/ipynb_with_output/Document%20classification%20with%20word%20embeddings%20tutorial%20-%20with%20output.ipynb"}, {"url": "https://github.com/tensorflow/workshops/blob/master/extras/keras-bag-of-words/keras-bow-model.ipynb", "anchor_text": "https://github.com/tensorflow/workshops/blob/master/extras/keras-bag-of-words/keras-bow-model.ipynb"}, {"url": "https://datascience.stackexchange.com/questions/20076/word2vec-vs-sentence2vec-vs-doc2vec", "anchor_text": "https://datascience.stackexchange.com/questions/20076/word2vec-vs-sentence2vec-vs-doc2vec"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5eb066197568---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----5eb066197568---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----5eb066197568---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/python?source=post_page-----5eb066197568---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/keras?source=post_page-----5eb066197568---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5eb066197568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&user=Susan+Li&userId=731d8566944a&source=-----5eb066197568---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5eb066197568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&user=Susan+Li&userId=731d8566944a&source=-----5eb066197568---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5eb066197568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb066197568--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5eb066197568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5eb066197568---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5eb066197568--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5eb066197568--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5eb066197568--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5eb066197568--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5eb066197568--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5eb066197568--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5eb066197568--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5eb066197568--------------------------------", "anchor_text": ""}, {"url": "https://actsusanli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://actsusanli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Susan Li"}, {"url": "https://actsusanli.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "27K Followers"}, {"url": "https://www.linkedin.com/in/susanli/", "anchor_text": "https://www.linkedin.com/in/susanli/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F731d8566944a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&user=Susan+Li&userId=731d8566944a&source=post_page-731d8566944a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1f2b19329694&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-class-text-classification-model-comparison-and-selection-5eb066197568&newsletterV3=731d8566944a&newsletterV3Id=1f2b19329694&user=Susan+Li&userId=731d8566944a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}