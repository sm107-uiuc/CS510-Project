{"url": "https://towardsdatascience.com/build-a-simple-neural-network-with-tensorflow-js-d434a30fcb8", "time": 1682997248.084144, "path": "towardsdatascience.com/build-a-simple-neural-network-with-tensorflow-js-d434a30fcb8/", "webpage": {"metadata": {"title": "Build a simple Neural Network with TensorFlow.js | by Venelin Valkov | Towards Data Science", "h1": "Build a simple Neural Network with TensorFlow.js", "description": "Build a simple Neural Network model in TensorFlow.js to make a laptop buying decision. Learn why Neural Networks need activation functions and how should you initialize their weights."}, "outgoing_paragraph_urls": [{"url": "https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf", "anchor_text": "A logical calculus of the ideas immanent in nervous activity", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Support_vector_machine", "anchor_text": "Support Vector Machines", "paragraph_index": 7}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2647&rep=rep1&type=pdf", "anchor_text": "Universal approximation theorem", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/George_Cybenko", "anchor_text": "George Cybenko", "paragraph_index": 8}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&rep=rep1&type=pdf", "anchor_text": "for sigmoid activation functions", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Frank_Rosenblatt", "anchor_text": "Frank Rosenblatt", "paragraph_index": 10}, {"url": "https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf", "anchor_text": "Rectified Linear Units Improve Restricted Boltzmann Machines", "paragraph_index": 36}, {"url": "https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf", "anchor_text": "Rectifier Nonlinearities Improve Neural Network Acoustic Models", "paragraph_index": 38}, {"url": "https://js.tensorflow.org/api/latest/#leakyRelu", "anchor_text": "tf.leakyRelu()", "paragraph_index": 39}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "Stochastic gradient descent (SGD)", "paragraph_index": 41}, {"url": "https://en.wikipedia.org/wiki/Normal_distribution", "anchor_text": "Normal distribution", "paragraph_index": 45}, {"url": "https://js.tensorflow.org/api/latest/#Initializers", "anchor_text": "TensorFlow.js Initializers", "paragraph_index": 46}, {"url": "https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy", "anchor_text": "binary crossentropy", "paragraph_index": 54}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "Stochastic gradient descent", "paragraph_index": 55}, {"url": "https://js.tensorflow.org/api/latest/#train.adam", "anchor_text": "Adam optimizer", "paragraph_index": 55}, {"url": "https://gluon.mxnet.io/chapter06_optimization/gd-sgd-scratch.html", "anchor_text": "Gradient descent and stochastic gradient descent from scratch", "paragraph_index": 65}, {"url": "https://stats.stackexchange.com/questions/267024/what-if-do-not-use-any-activation-function-in-the-neural-network", "anchor_text": "What if do not use any activation function in the neural network?", "paragraph_index": 66}], "all_paragraphs": ["TL;DR Build a simple Neural Network model in TensorFlow.js to make a laptop buying decision. Learn why Neural Networks need activation functions and how should you initialize their weights.", "It is in the middle night, and you\u2019re dreaming some rather alarming dreams with a smile on your face. Suddenly, your phone starts ringing, rather internationally. You pick up, half-asleep, and listen to something bizarre.", "A friend of yours is calling, from the other side of our planet, asking for help in picking a laptop. After all, it is Black Friday!", "You\u2019re a bit dazzled by the fact that this is the first time you hear from your friend in 5 years. Still, you\u2019re a good person and agree to help out. Maybe it is time to put your TensorFlow.js skills into practice?", "How about you build a model to help out your friend so you can get back to sleep? You heard that Neural Networks are pretty hot right now. It is 3 in the morning, there isn\u2019t much need for persuasion in your mind. You\u2019ll use a Neural Network for this one!", "Run the complete source code for this tutorial right in your browser:", "What is a Neural Network? In a classical cliff-hanger fashion, we\u2019ll start far away from answering this question.", "Neural Networks were around for a while (since 1950s)? Why did they become popular just recently (last 5\u201310 years)? First introduced by Warren McCulloch and Walter Pitts in A logical calculus of the ideas immanent in nervous activity Neural Networks were really popular until the mid-1980s when Support Vector Machinesand other methods overtook the community.", "The Universal approximation theorem states that a Neural Networks can approximate any function (under some mild assumptions), even with a single hidden layer (more on that later). One of the first proves was done by George Cybenko in 1989 for sigmoid activation functions (will have a look at those in a bit).", "More recently, more and more advances in the field of Deep Learning made Neural Networks a hot topic again. Why? We\u2019ll discuss that a bit later. First, let\u2019s start with the basics!", "The original model, intended to model how the human brain processed visual data and learned to recognize objects, was suggested by Frank Rosenblatt in the 1950s. The Perceptron takes one or more binary inputs x1, x2, \u2026, xn and produces a binary output:", "To compute the output you have to:", "Let\u2019s have a look at an example. Imagine you need to decide whether or not you need a new laptop. The most important features are its color and size (that\u2019s what she said). So, you have two inputs:", "You can represent these factors with binary variables x_pink, x_small and assign weights/importance w_pink, w_small to each one. Depending on the importance you assign to each factor, you can get different models.", "We can simplify the Perceptron even further. We can rewrite \u2211 w_j x_j as a dot product of two vectors w . x. Next, we\u2019ll introduce the Perceptron\u2019s bias, b = -threshold. Using it, we can rewrite the model as:", "The bias is a measure of how easy it is for a perceptron to output 1 (to fire). Large positive bias makes outputting 1 easy, while a large negative bias makes it difficult.", "Let\u2019s build the Perceptron model using TensorFlow.js:", "An offer for a laptop comes around. It is not pink, but it is small x = [0 , 1]. You\u2019re biased towards not buying a laptop because you\u2019re broke. You can encode that with a negative bias. You\u2019re one of the brainier users, and you put more emphasis on size, rather than color w = [0.5, 0.9]:", "Yes, you have to buy that laptop!", "To make learning from data possible, we want the weights of our model to change only by a small amount when presented with an example. That is, each example should cause a small change in the output.", "That way, one can continuously adjust the weights while presenting new data and not worrying that a single example will wipe out everything the model has learned so far.", "The Perceptron is not an ideal for that purpose since small changes in the inputs are propagated linearly to the output. We can overcome this using a sigmoid neuron.", "The sigmoid neuron has inputs x1, x2, \u2026, xn that can have values between 0 and 1. The output is given by \u03c3(w . x + b) where \u03c3 is the sigmoid function, defined by:", "Let\u2019s have a look at it using TensorFlow.js and Plotly:", "Using the weights and inputs we get:", "Let\u2019s dive deeper into the sigmoid neuron and understand the similarities with the Perceptron:", "Let\u2019s build the sigmoid neuron model using TensorFlow.js:", "Another offer for a laptop comes around. This time you can specify the degree of how close the color is to pink and how small it is.", "The color is somewhat pink, and the size is just about right x = [0.6, 0.9]. The rest stays the same:", "Yes, you still want to buy this laptop, but this model also outputs the confidence of its decision. Cool, right?", "A natural way to extend the models presented above is to group them in some way. One way to do that is to create layers of neurons. Here\u2019s a simple Neural Network that can be used to make the decision of buying a laptop:", "Neural Networks are a collection of neurons, connected in an acyclic graph. Outputs of some neurons are used as inputs to other neurons. They are organized into layers. Our example is composed of fully-connected layers (all neurons between two adjacent layers are connected), and it is a 2 layer Neural Network (we do not count the input layer). Neural Networks can make complex decisions thanks to a combination of simple decisions made by the neurons that construct them.", "Of course, the output layer contains the answer(s) you\u2019re looking for. Let\u2019s have a look at some of the ingredients that make training Neural Networks possible:", "The Perceptron model is just a linear transformation. Stacking multiple such neurons on each other results in a vector product and a bias addition. Unfortunately, there are a lot of functions that can\u2019t be estimated by a linear transformation.", "The activation function makes it possible for the model to approximate non-linear functions (predict more complex phenomena). The good thing is, you\u2019ve already met one activation function \u2014 the sigmoid:", "One major disadvantage of the Sigmoid function is the is that it becomes really flat outside the [-3, +3] range. This leads to weights getting close to 0 \u2014 no learning is happening.", "ReLU, introduced in the context of Neural Networks in Rectified Linear Units Improve Restricted Boltzmann Machines, have a linear output at values greater than 0 and 0 otherwise.", "One disadvantage of ReLU is that negative values \u201cdie out\u201d and stay at 0 \u2014 no learning.", "Leaky ReLU, introduced in Rectifier Nonlinearities Improve Neural Network Acoustic Models, solves the dead values introduced by ReLU:", "Note that negative values get scaled instead of zeroed out. Scaling is adjustable by a parameter in tf.leakyRelu().", "The process of teaching a Neural Network to make \u201creasonable\u201d predictions involves adjusting the weights of the neurons multiple times. Those weights need to have initial values. How should you choose those?", "The initialization process must take into account the algorithm we\u2019re using to train our model. More often than not, that algorithm is Stochastic gradient descent (SGD). Its job is to do a search over possible parameters/weights and choose those that minimize the errors our model makes. Moreover, the algorithm heavily relies on randomness and a good starting point (given by the weights).", "Imagine that we initialize the weights using the same constant (yes, including 0). Every neuron in the network will compute the same output, which results in the same weight/parameter update. We just defeated the purpose of having multiple neurons.", "Let\u2019s initialize the weights with a set of small values. Passing those values to the activation functions will decrease them exponentially, leaving every weight equally unimportant.", "On the other hand, initializing with large values will lead to an exponential increase, making the weights equally unimportant again.", "We can use a Normal distribution with a mean 0 and standard deviation 1 to initialize the weights with small random numbers.", "Every neuron will compute different output, which leads to different parameter updates. Of course, multiple other ways exist. Check the TensorFlow.js Initializers", "Now that you know some Neural Network kung-fu, we can use TensorFlow.js to build a simple model and decide whether you should buy a given laptop.", "Let\u2019s say that for your friend, size is much more important than the degree of pinkness! You sit down and devise the following dataset:", "Well done! You did well on incorporating your friend preferences.", "Recall the Neural Network we\u2019re going to build:", "Let\u2019s translate it into a TensorFlow.js model:", "We have a 2-layer network with an input layer containing 2 neurons, a hidden layer with 3 neurons and an output layer containing 2 neurons.", "Note that we use ReLU activation function in the hidden layer and softmax for the output layer. We have 2 neurons in the output layer since we want to obtain how certain our Neural Network is in its buy/no-buy decision.", "We\u2019re using binary crossentropy to measure the quality of the current weights/parameters of our model by measuring how \u201cgood\u201d the predictions are.", "Our training algorithm, Stochastic gradient descent, is trying to find weights that minimize the loss function. For our example, we\u2019re going to use the Adam optimizer.", "Now that our model is defined, we can use our training dataset to teach it about our friend preferences:", "We\u2019re shuffling the data before training and log the progress after each epoch is complete:", "After 20 epochs or so seems like the model has learned the preferences of your friend.", "You save the model and send it over to your friend. After connecting to your friend computer, you find somewhat appropriate laptop and encode the information into the model:", "After waiting a few long milliseconds, you receive an answer:", "The model agrees with you. It \u201cthinks\u201d that your friend should buy the laptop but it is not that certain about it. You did good!", "Your friend seems happy with the results, and you\u2019re thinking of making millions with your model by selling it as a browser extension. Either way, you learned a lot about:", "Run the complete source code for this tutorial right in your browser:", "Laying back on the comfy pillow, you start thinking. Could I\u2019ve used Deep Learning for this?", "Gradient descent and stochastic gradient descent from scratch", "What if do not use any activation function in the neural network?", "Build Machine Learning models (especially Deep Neural Networks) that you can easily integrate with existing or new web apps. Think of your ReactJs, Vue, or Angular app enhanced with the power of Machine Learning models:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd434a30fcb8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://venelinvalkov.medium.com/?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": ""}, {"url": "https://venelinvalkov.medium.com/?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "Venelin Valkov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F102e34a0beb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&user=Venelin+Valkov&userId=102e34a0beb1&source=post_page-102e34a0beb1----d434a30fcb8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd434a30fcb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd434a30fcb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/curiousily/Simple-Neural-Network-with-TensorFlow-js", "anchor_text": "Complete source code on GitHub"}, {"url": "https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf", "anchor_text": "A logical calculus of the ideas immanent in nervous activity"}, {"url": "https://en.wikipedia.org/wiki/Support_vector_machine", "anchor_text": "Support Vector Machines"}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2647&rep=rep1&type=pdf", "anchor_text": "Universal approximation theorem"}, {"url": "https://en.wikipedia.org/wiki/George_Cybenko", "anchor_text": "George Cybenko"}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&rep=rep1&type=pdf", "anchor_text": "for sigmoid activation functions"}, {"url": "https://en.wikipedia.org/wiki/Frank_Rosenblatt", "anchor_text": "Frank Rosenblatt"}, {"url": "https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf", "anchor_text": "Rectified Linear Units Improve Restricted Boltzmann Machines"}, {"url": "https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf", "anchor_text": "Rectifier Nonlinearities Improve Neural Network Acoustic Models"}, {"url": "https://js.tensorflow.org/api/latest/#leakyRelu", "anchor_text": "tf.leakyRelu()"}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "Stochastic gradient descent (SGD)"}, {"url": "https://en.wikipedia.org/wiki/Normal_distribution", "anchor_text": "Normal distribution"}, {"url": "https://js.tensorflow.org/api/latest/#Initializers", "anchor_text": "TensorFlow.js Initializers"}, {"url": "https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy", "anchor_text": "binary crossentropy"}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "Stochastic gradient descent"}, {"url": "https://js.tensorflow.org/api/latest/#train.adam", "anchor_text": "Adam optimizer"}, {"url": "https://github.com/curiousily/Simple-Neural-Network-with-TensorFlow-js", "anchor_text": "Complete source code on GitHub"}, {"url": "https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent", "anchor_text": "Reducing Loss: Gradient Descent"}, {"url": "https://gluon.mxnet.io/chapter06_optimization/gd-sgd-scratch.html", "anchor_text": "Gradient descent and stochastic gradient descent from scratch"}, {"url": "https://www.deeplearning.ai/ai-notes/initialization/", "anchor_text": "Initializing neural networks"}, {"url": "https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/#types-of-weight-intializations", "anchor_text": "Types of weight intializations"}, {"url": "https://stats.stackexchange.com/questions/267024/what-if-do-not-use-any-activation-function-in-the-neural-network", "anchor_text": "What if do not use any activation function in the neural network?"}, {"url": "https://www.curiousily.com/posts/build-a-simple-neural-network-with-tensorflow-js/", "anchor_text": "https://www.curiousily.com"}, {"url": "https://leanpub.com/deep-learning-for-javascript-hackers", "anchor_text": "Deep Learning for JavaScript HackersBuild Machine Learning models (especially Deep Neural Networks) that you can easily integrate with existing or new web\u2026leanpub.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d434a30fcb8---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----d434a30fcb8---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/javascript?source=post_page-----d434a30fcb8---------------javascript-----------------", "anchor_text": "JavaScript"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----d434a30fcb8---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d434a30fcb8---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd434a30fcb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&user=Venelin+Valkov&userId=102e34a0beb1&source=-----d434a30fcb8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd434a30fcb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&user=Venelin+Valkov&userId=102e34a0beb1&source=-----d434a30fcb8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd434a30fcb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd434a30fcb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d434a30fcb8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d434a30fcb8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d434a30fcb8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d434a30fcb8--------------------------------", "anchor_text": ""}, {"url": "https://venelinvalkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://venelinvalkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Venelin Valkov"}, {"url": "https://venelinvalkov.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.5K Followers"}, {"url": "https://mlexpert.io", "anchor_text": "https://mlexpert.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F102e34a0beb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&user=Venelin+Valkov&userId=102e34a0beb1&source=post_page-102e34a0beb1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5323954064aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-simple-neural-network-with-tensorflow-js-d434a30fcb8&newsletterV3=102e34a0beb1&newsletterV3Id=5323954064aa&user=Venelin+Valkov&userId=102e34a0beb1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}