{"url": "https://towardsdatascience.com/fashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661", "time": 1682996832.2560608, "path": "towardsdatascience.com/fashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661/", "webpage": {"metadata": {"title": "Fashion product image classification using Neural Networks | Machine Learning from Scratch (Part VI) | by Venelin Valkov | Towards Data Science", "h1": "Fashion product image classification using Neural Networks | Machine Learning from Scratch (Part VI)", "description": "Build Neural Network in Python from scratch. Use the model to classify images of fashion products into 1 of 10 classes."}, "outgoing_paragraph_urls": [{"url": "https://github.com/zalandoresearch/fashion-mnist", "anchor_text": "Fashion-MNIST", "paragraph_index": 5}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST", "paragraph_index": 7}, {"url": "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/", "anchor_text": "Well, it might be too easy to make predictions on", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding", "anchor_text": "t-SNE", "paragraph_index": 12}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html", "anchor_text": "scikit-learn", "paragraph_index": 12}, {"url": "https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems", "anchor_text": "state-of-the-art results (SOTA)", "paragraph_index": 14}, {"url": "https://paperswithcode.com/sota", "anchor_text": "Browse papers with source code achieving SOTA", "paragraph_index": 15}, {"url": "https://en.wikipedia.org/wiki/Sigmoid_function", "anchor_text": "The sigmoid function", "paragraph_index": 22}, {"url": "http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/", "anchor_text": "L1 and L2 Regularization", "paragraph_index": 48}, {"url": "https://en.wikipedia.org/wiki/Cross_entropy", "anchor_text": "Cross-Entropy loss", "paragraph_index": 50}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "Maximum likelihood estimation (MLE)", "paragraph_index": 56}, {"url": "https://arxiv.org/abs/1502.03167", "anchor_text": "Training Neural Nets converge much faster when data is normalized", "paragraph_index": 66}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html", "anchor_text": "scale", "paragraph_index": 67}], "all_paragraphs": ["TL;DR Build Neural Network in Python from scratch. Use the model to classify images of fashion products into 1 of 10 classes.", "We live in the age of Instagram, YouTube, and Twitter. Images and video (a sequence of images) dominate the way millennials and other weirdos consume information.", "Having models that understand what images show can be crucial for understanding your emotional state (yes, you might get a personalized Coke ad right after you post your breakup selfie on Instagram), location, interests and social group.", "Predominantly, models that understand image data used in practice are (Deep) Neural Networks. Here, we\u2019ll implement a Neural Network image classifier from scratch in Python.", "Hopefully, it\u2019s not a complete surprise to you that computers can\u2019t actually see images as we do. Each image on your device is represented/stored as a matrix, where each pixel is one or more numbers.", "Fashion-MNIST is a dataset of Zalando\u2019s article images \u2014 consisting of a training set of _60,000_ examples and a test set of _10,000_ examples. Each example is a _28x28_ grayscale image, associated with a label from _10_ classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.", "Here is a sample of the images:", "You might be familiar with the original handwritten digits MNIST dataset and wondering why we\u2019re not using it? Well, it might be too easy to make predictions on. And of course, fashion is cooler, right?", "The product images are grayscale, 28x28 pixels and look something like this:", "Here are the first 3 rows from the pixel matrix of the image:", "Note that the values are in the 0\u2013255 range (grayscale).", "We have 10 classes of possible fashion products:", "Let\u2019s have a look at a lower dimensional representation of some of the products using t-SNE. We\u2019ll transform the data into 2-dimensional using the implementation from scikit-learn:", "You can observe a clear separation between some classes and significant overlap between others. Let\u2019s build a Neural Network that can try to separate between different fashion products!", "Neural Networks (NNs), Deep Neural Networks in particular, are all the rage in the last couple of years in the Machine Learning realm. That\u2019s hardly a surprise since most state-of-the-art results (SOTA) on various Machine Learning problems are obtained via Neural Nets.", "Browse papers with source code achieving SOTA", "The goal of modeling our biological neuron has led to the invention of the artificial neuron. Here is how a single neuron in your brain looks like:", "On the other side, we have a vastly simplified mathematical model that turns out to be extremely useful in practice (as evident by the success of Neural Nets):", "The idea of the artificial neuron is simple \u2014 you have data vector X coming from somewhere, a vector of parameters W and a bias vector b. The output of a neuron is given by:", "where f is an activation function that controls how strong the output signal of the neuron is.", "You can use a single neuron as a classifier, but the fun part begins when you group them into layers. Concretely, the neurons are connected into an acyclic graph with the data flowing between layers:", "Want to build a Deep Neural Network? Just add at least one more hidden layer:", "The sigmoid function is quite commonly used activation function, at least it was until recently. It has a distinct S shape, it is a differentiable real function for any real input value and output values between 00 and 11. Additionally, it has a positive derivative at each point. More importantly, we will use it as an activation function for the hidden layer of our model.", "Here is how we can implement it:", "Its first derivative (which we will use during the backpropagation step of our training algorithm) has the following formula:", "Our implementation reuses the sigmoid implementation itself:", "The softmax function can be easily differentiated, it is pure (output depends only on input) and the elements of the resulting vector sum to 1. Here it is:", "In probability theory, the output of the softmax function is sometimes used as a representation of a categorical distribution. Let\u2019s see an example result:", "The output has most of its weight corresponding to the input 8. The softmax function highlights the largest value(s) and suppresses the smaller ones.", "Backpropagation is the backbone of almost anything we do when using Neural Networks. The algorithm consists of 3 subtasks:", "In the first step, backprop uses the data and the weights of the network to compute a prediction. Next, the error is computed based on the prediction and the provided labels. The final step propagates the error through the network, starting from the final layer. Thus, the weights get updated based on the error, little by little.", "Let\u2019s build more intuition about what the algorithm is actually doing:", "We will try to create a Neural Network that can properly predict values from the XOR function. Here is its truth table:", "Let start by defining some parameters:", "The epochs parameter controls how many times our algorithm will \u201csee\u201d the data during training. Then we set the number of neurons in the input, hidden and output layers \u2014 we have 2 numbers as input and 1 number as output size. The learning rate parameter controls how quickly our Neural Network will learn from new data and forget what already knows.", "Our training data (from the table) looks like this:", "The W vectors in our NN need to have some initial values. We\u2019ll sample a uniform distribution, initialized with proper size:", "Finally, implementation of the Backprop algorithm:", "That error seems to be decreasing! YaY! And the implementation is not that scary, isn\u2019t it?", "During the forward step, we take the dot product of the data X and W_hidden\u200b and apply our activation function to obtain the output of our hidden layer. We obtain the predictions by taking the dot product of the hidden layer output and W_output\u200b.", "To obtain the error, we calculate the difference between the true values and the predicted ones. Note that this is a very crude metric, but it works fine for our example.", "Finally, we use the calculated error to adjust the weights. Note that we need the results from the forward pass act_hidden to calculate W_output\u200b and calculate the first derivative using sigmoid_prime to update W_hidden\u200b.", "In order to make an inference (predictions) we\u2019ll do just the forward step (since we won\u2019t adjust W based on the result):", "Our sorcery seems to be working! The prediction is correct!", "Our Neural Network will have only 1 hidden layer. We will implement a somewhat more sophisticated version of our training algorithm shown above along with some handy methods.", "We\u2019ll sample a uniform distribution with values between -1 and 1 for our initial weights. Here is the implementation:", "Let\u2019s have a look at the training method:", "For each epoch, we apply the backprop algorithm, evaluate the error and the gradient with respect to the weights. We then use the learning rate and gradients to update the weights.", "Doing a backprop step is a bit more complicated than our XOR example. We do an additional step before returning the gradients \u2014 apply L1 and L2 Regularization. Regularization is used to guide our training towards simpler methods by penalizing large values for our parameters W.", "Our forward and backward steps are very similar to the one in our previous example, how about the error?", "We\u2019re going to use Cross-Entropy loss (known as log loss) function to evaluate the error. This function measures the performance of a classification model whose output is a probability. It penalizes (harshly) predictions that are wrong and confident. Here is the definition:", "where C is the number of classes, y is a binary indicator if class label is the correct classification for the observation and p is the predicted probability that o is of class c", "The implementation in Python looks like this:", "Now that we have our loss function, we can finally define the error for our model:", "After computing the Cross-Entropy loss, we add the regularization terms and calculate the mean error. Here is the implementation for L1 and L2 regularizations:", "Now that our model can learn from data, it is time to make predictions on data it hasn\u2019t seen before. We\u2019re going to implement two methods for prediction \u2014 predict and predict_proba:", "Recall that predictions in NN (generally) includes applying a forward step on the data. But the result of it is a vector of values representing how strong the belief for each class is for the data. We\u2019ll use Maximum likelihood estimation (MLE) to obtain our final predictions:", "MLE works by picking the highest value and return it as a predicted class for the input.", "The method predict_proba returns a probability distribution over all classes, representing how likely each class is to be correct. Note that we obtain it by applying the softmax function to the result of the forward step.", "Time to put our NN model to the test. Here\u2019s how we can train it:", "The training might take some time, so please be patient. Let\u2019s get the predictions:", "First, let\u2019s have a look at the training error:", "Something looks fishy here, seems like our model can\u2019t continue to reduce the error 150 epochs or so. Let\u2019s have a look at a single prediction:", "That one seems correct! Let\u2019s have a look at few more:", "Not too good. How about the training & testing accuracy:", "Well, those don\u2019t look that good. While a random classifier will return ~10% accuracy, ~50% accuracy on the test dataset will not make a practical classifier either.", "That \u201cjagged\u201d line on the training error chart shows the inability of our model to converge. Recall that we use the Backpropagation algorithm to train our model. Training Neural Nets converge much faster when data is normalized.", "We\u2019ll use scikit-learn`s scale to normalize our data. The documentation states that:", "Center to the mean and component wise scale to unit variance.", "Here is the new training method:", "Let\u2019s have a look at the error:", "The error seems a lot more stable and settles at a lower point \u2014 ~200 vs ~400. Let\u2019s have a look at some predictions:", "Those look much better, too! Finally, the accuracy:", "~87% (vs ~50%) on the training set is a vast improvement over the unscaled method. Finally, your hard work paid off!", "What a ride! I hope you got a blast working on your first Neural Network from scratch, too!", "You learned how to process image data, transform it, and use it to train your Neural Network. We used some handy tricks (scaling) to vastly improve the performance of the classifier.", "Like what you read? Do you want to learn even more about Machine Learning? Level up your ML understanding:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe9fda9e47661&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://venelinvalkov.medium.com/?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": ""}, {"url": "https://venelinvalkov.medium.com/?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "Venelin Valkov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F102e34a0beb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&user=Venelin+Valkov&userId=102e34a0beb1&source=post_page-102e34a0beb1----e9fda9e47661---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9fda9e47661&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9fda9e47661&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://drive.google.com/file/d/1S59KWV8KmZTI-A6OpXge3yG87HXyIcUz/view?usp=sharing", "anchor_text": "7.neural_nets.ipynbColaboratory notebookdrive.google.com"}, {"url": "https://github.com/zalandoresearch/fashion-mnist", "anchor_text": "Fashion-MNIST"}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST"}, {"url": "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/", "anchor_text": "Well, it might be too easy to make predictions on"}, {"url": "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding", "anchor_text": "t-SNE"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html", "anchor_text": "scikit-learn"}, {"url": "https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems", "anchor_text": "state-of-the-art results (SOTA)"}, {"url": "https://paperswithcode.com/sota", "anchor_text": "Browse papers with source code achieving SOTA"}, {"url": "https://cs231n.github.io/", "anchor_text": "CS231n"}, {"url": "https://cs231n.github.io/", "anchor_text": "CS231n"}, {"url": "https://cs231n.github.io/", "anchor_text": "CS231n"}, {"url": "https://cs231n.github.io/", "anchor_text": "CS231n"}, {"url": "https://en.wikipedia.org/wiki/Sigmoid_function", "anchor_text": "The sigmoid function"}, {"url": "http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/", "anchor_text": "L1 and L2 Regularization"}, {"url": "https://en.wikipedia.org/wiki/Cross_entropy", "anchor_text": "Cross-Entropy loss"}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "Maximum likelihood estimation (MLE)"}, {"url": "https://arxiv.org/abs/1502.03167", "anchor_text": "Training Neural Nets converge much faster when data is normalized"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html", "anchor_text": "scale"}, {"url": "https://drive.google.com/file/d/1S59KWV8KmZTI-A6OpXge3yG87HXyIcUz/view?usp=sharing", "anchor_text": "7.neural_nets.ipynbColaboratory notebookdrive.google.com"}, {"url": "https://www.curiousily.com/posts/fashion-product-image-classification-using-neural-networks/", "anchor_text": "https://www.curiousily.com"}, {"url": "https://leanpub.com/hmls", "anchor_text": "Hands-On Machine Learning from Scratch\u201cWhat I cannot create, I do not understand\u201d \u2014 Richard Feynman This book will guide you on your journey to deeper\u2026leanpub.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e9fda9e47661---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e9fda9e47661---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e9fda9e47661---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----e9fda9e47661---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----e9fda9e47661---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9fda9e47661&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&user=Venelin+Valkov&userId=102e34a0beb1&source=-----e9fda9e47661---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9fda9e47661&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&user=Venelin+Valkov&userId=102e34a0beb1&source=-----e9fda9e47661---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9fda9e47661&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe9fda9e47661&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e9fda9e47661---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e9fda9e47661--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e9fda9e47661--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e9fda9e47661--------------------------------", "anchor_text": ""}, {"url": "https://venelinvalkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://venelinvalkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Venelin Valkov"}, {"url": "https://venelinvalkov.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.5K Followers"}, {"url": "https://mlexpert.io", "anchor_text": "https://mlexpert.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F102e34a0beb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&user=Venelin+Valkov&userId=102e34a0beb1&source=post_page-102e34a0beb1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5323954064aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661&newsletterV3=102e34a0beb1&newsletterV3Id=5323954064aa&user=Venelin+Valkov&userId=102e34a0beb1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}