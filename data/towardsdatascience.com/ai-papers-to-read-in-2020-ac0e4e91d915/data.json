{"url": "https://towardsdatascience.com/ai-papers-to-read-in-2020-ac0e4e91d915", "time": 1683005016.487912, "path": "towardsdatascience.com/ai-papers-to-read-in-2020-ac0e4e91d915/", "webpage": {"metadata": {"title": "AI Papers to Read in 2020. Reading suggestions to keep you\u2026 | by Ygor Serpa | Towards Data Science", "h1": "AI Papers to Read in 2020", "description": "Artificial Intelligence is one of the most rapidly growing fields in science and is one of the most sought skills of the past few years, commonly labeled as Data Science. The area has far-reaching\u2026"}, "outgoing_paragraph_urls": [{"url": "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networ", "anchor_text": "\u201cImagenet classification with deep convolutional neural networks.\u201d", "paragraph_index": 3}, {"url": "https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53", "anchor_text": "ZF Net", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1409.1556", "anchor_text": "VGG", "paragraph_index": 7}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html", "anchor_text": "Inception-v1,", "paragraph_index": 7}, {"url": "http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html", "anchor_text": "ResNet", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1801.04381", "anchor_text": "v2", "paragraph_index": 11}, {"url": "https://arxiv.org/abs/1905.02244", "anchor_text": "v3", "paragraph_index": 11}, {"url": "https://arxiv.org/abs/1602.07360", "anchor_text": "SqueezeNet", "paragraph_index": 11}, {"url": "https://arxiv.org/abs/1608.08710", "anchor_text": "downsize regular models with minimal accuracy loss.", "paragraph_index": 11}, {"url": "https://ieeexplore.ieee.org/abstract/document/8050276", "anchor_text": "This paper", "paragraph_index": 11}, {"url": "http://papers.nips.cc/paper/7181-attention-is-all-you-need", "anchor_text": "\u201cAttention is all you need.\u201d", "paragraph_index": 12}, {"url": "https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/PAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask-%20Learners.pdf", "anchor_text": "GPT-2", "paragraph_index": 14}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT", "paragraph_index": 14}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "Self-Attention GAN", "paragraph_index": 16}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT", "paragraph_index": 17}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "SAGAN", "paragraph_index": 17}, {"url": "https://arxiv.org/abs/1911.11423", "anchor_text": "Stop Thinking With Your Head", "paragraph_index": 19}, {"url": "https://arxiv.org/abs/1704.04861", "anchor_text": "MobileNet paper", "paragraph_index": 21}, {"url": "http://openaccess.thecvf.com/content_iccv_2017/html/Martinez_A_Simple_yet_ICCV_2017_paper.html", "anchor_text": "\u201cSimple baselines for human pose estimation and tracking.\u201d", "paragraph_index": 22}, {"url": "https://nanonets.com/blog/human-pose-estimation-2d-guide/", "anchor_text": "this comprehensive state-of-the-art review.", "paragraph_index": 27}, {"url": "https://arxiv.org/abs/1812.01187", "anchor_text": "\u201cBag of tricks for image classification with convolutional neural networks.\u201d", "paragraph_index": 28}, {"url": "https://www.tensorflow.org/api_docs/python/tf/nn/elu", "anchor_text": "ELU", "paragraph_index": 31}, {"url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Cui_Class-Balanced_Loss_Based_on_Effective_Number_of_Samples_CVPR_2019_paper.pdf", "anchor_text": "this paper on class weights for unbalanced datasets", "paragraph_index": 32}, {"url": "https://arxiv.org/abs/1706.02515", "anchor_text": "\u201cSelf-normalizing neural networks.\u201d", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/a-comprehensive-guide-on-activation-functions-b45ed37a4fa5", "anchor_text": "guide on activation functions", "paragraph_index": 38}, {"url": "https://arxiv.org/abs/1904.00760", "anchor_text": "\u201cApproximating cnns with bag-of-local-features models works surprisingly well on imagenet.\u201d", "paragraph_index": 39}, {"url": "https://towardsdatascience.com/why-default-cnn-are-broken-in-keras-and-how-to-fix-them-ce295e5e5f2", "anchor_text": "which might not always be the best option.", "paragraph_index": 48}, {"url": "https://arxiv.org/abs/1511.06422", "anchor_text": "\u201cAll You Need is a Good Init\u201d", "paragraph_index": 48}, {"url": "https://phillipi.github.io/pix2pix/", "anchor_text": "Image-to-image translation with conditional adversarial networks.\u201d", "paragraph_index": 49}, {"url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.html", "anchor_text": "\u201cUnpaired image-to-image translation using cycle-consistent adversarial networks.\u201d", "paragraph_index": 50}, {"url": "https://www.sbgames.org/sbgames2019/files/papers/ComputacaoFull/197880.pdf", "anchor_text": "For instance, at being a virtual assistant to artists.", "paragraph_index": 53}, {"url": "https://www.tensorflow.org/tutorials/generative/dcgan", "anchor_text": "Here are the official Tensorflow 2 docs on the matter", "paragraph_index": 56}, {"url": "https://arxiv.org/abs/1905.06484", "anchor_text": "semi-supervised learning", "paragraph_index": 56}, {"url": "https://www.linkedin.com/in/ygorreboucas/", "anchor_text": "connect with me", "paragraph_index": 59}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "subscribing", "paragraph_index": 59}, {"url": "https://stackoverflow.com/", "anchor_text": "StackOverflow", "paragraph_index": 59}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "my affiliate link when signing up.", "paragraph_index": 59}], "all_paragraphs": ["Artificial Intelligence is one of the most rapidly growing fields in science and is one of the most sought skills of the past few years, commonly labeled as Data Science. The area has far-reaching applications, being usually divided by input type: text, audio, image, video, or graph; or by problem formulation: supervised, unsupervised, and reinforcement learning. Keeping up with everything is a massive endeavor and usually ends up being a frustrating attempt. In this spirit, I present some reading suggestions to keep you updated on the latest and classic breakthroughs in AI and Data Science.", "Although most papers I listed deal with image and text, many of their concepts are fairly input agnostic and provide insight far beyond vision and language tasks. Alongside each suggestion, I listed some of the reasons I believe you should read (or re-read) the paper and added some further readings, in case you want to dive a bit deeper into a given subject.", "Before we begin, I would like to apologize to the Audio and Reinforcement Learning communities for not adding these subjects to the list, as I have only limited experience with both.", "Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \u201cImagenet classification with deep convolutional neural networks.\u201d Advances in neural information processing systems. 2012.", "In 2012, the authors proposed the use of GPUs to train a large Convolutional Neural Network (CNN) for the ImageNet challenge. This was a bold move, as CNNs were considered too heavy to be trained on such a large scale problem. To everyone surprise, they won first place, with a ~15% Top-5 error rate, against ~26% of the second place, which used state-of-the-art image processing techniques.", "Reason #1: While most of us know AlexNet\u2019s historical importance, not everyone knows which of the techniques we use today were already present before the boom. You might be surprised by how familiar many of the concepts introduced in the paper are, such as dropout and ReLU.", "Reason #2: The proposed network had 60 million parameters, complete insanity for 2012 standards. Nowadays, we get to see models with over a billion parameters. Reading the AlexNet paper gives us a great deal of insight on how things developed since then.", "Further Reading: Following the history of ImageNet champions, you can read the ZF Net, VGG, Inception-v1, and ResNet papers. This last one achieved super-human performance, solving the challenge. After it, other competitions took over the researchers\u2019 attention. Nowadays, ImageNet is mainly used for Transfer Learning and to validate low-parameter models, such as:", "MobileNet is one of the most famous \u201clow-parameter\u201d networks. Such models are ideal for low-resources devices and to speed-up real-time applications, such as object recognition on mobile phones. The core idea behind MobileNet and other low-parameter models is to decompose expensive operations into a set of smaller (and faster) operations. Such compound operations are often orders-of-magnitude faster and use substantially fewer parameters.", "Reason #1: Most of us have nowhere near the resources the big tech companies have. Understanding the low-parameter networks is crucial to make your own models less expensive to train and use. In my experience, using depth-wise convolutions can save you hundreds of dollars in cloud inference with almost no loss to accuracy.", "Reason #2: Common knowledge is that bigger models are stronger models. Papers such as MobileNet show that there is a lot more to it than adding more filters. Elegance matters.", "Further Reading: So far, MobileNet v2 and v3 have been released, providing new enhancements to accuracy and size. In parallel, other authors have devised many techniques to further reduce the model size, such as the SqueezeNet, and to downsize regular models with minimal accuracy loss. This paper gives a comprehensive summary of several models size vs accuracy.", "Vaswani, Ashish, et al. \u201cAttention is all you need.\u201d Advances in neural information processing systems. 2017.", "The paper that introduced the Transformer Model. Prior to this paper, language models relied extensively on Recurrent Neural Networks (RNN) to perform sequence-to-sequence tasks. However, RNNs are awfully slow, as they are terrible to parallelize to multi-GPUs. In contrast, the Transformer model is based solely on Attention layers, which are CNNs that capture the relevance of any sequence element to each other. The proposed formulation achieved significantly better state-of-the-art results and trains markedly faster than previous RNN models.", "Reason #1: Nowadays, most of the novel architectures in the Natural-Language Processing (NLP) literature descend from the Transformer. Models such as GPT-2 and BERT are at the forefront of innovation. Understanding the Transformer is key to understanding most later models in NLP.", "Reason #2: Most transformer models are in the order of billions of parameters. While the literature on MobileNets addresses more efficient models, the research on NLP addresses more efficient training. In combination, both views provide the ultimate set of techniques for efficient training and inference.", "Reason #3: While the transformer model has mostly been restricted to NLP, the proposed Attention mechanism has far-reaching applications. Models such as Self-Attention GAN demonstrate the usefulness of global-level reasoning a variety of tasks. New papers on Attention applications pop-up every month.", "Further Reading: I highly recommend reading the BERT and SAGAN paper. The former is a continuation of the Transformer model, and the latter is an application of the Attention mechanism to images in a GAN setup.", "Transformer / Attention models have attracted a lot of attention. However, these tend to be resource-heavy models, not meant for ordinary consumer hardware. Both mentioned papers criticize the architecture, providing computationally efficient alternatives to the Attention module. As for the MobileNet discussion, elegance matters.", "Reason #1: \u201cStop Thinking With Your Head\u201d is a damn funny paper to read. This counts as a reason on its own.", "Reason #2: Big companies can quickly scale their research to a hundred GPUs. We, normal folks, can\u2019t. Scaling the size of models is not the only avenue for improvement. I can\u2019t overstate that. Reading about efficiency is the best way to ensure you are efficiently using your current resources.", "Further Reading: Since these are late 2019 and 2020, there isn\u2019t much to link. Consider reading the MobileNet paper (if you haven\u2019t already) for other takes on efficiency.", "Xiao, Bin, Haiping Wu, and Yichen Wei. \u201cSimple baselines for human pose estimation and tracking.\u201d Proceedings of the European conference on computer vision (ECCV). 2018.", "So far, most papers have proposed new techniques to improve the state-of-the-art. This paper, on the opposite, argues that a simple model, using current best practices, can be surprisingly effective. In sum, they proposed a human pose estimation network based solely on a backbone network followed by three de-convolution operations. At the time, their approach was the most effective at handling the COCO benchmark, despite its simplicity.", "Reason #1: Being simple is sometimes the most effective approach. While we all want to try the shiny and complicated novel architectures, a baseline model might be way faster to code and, yet, achieve similar results. This paper reminds us that not all good models need to be complicated.", "Reason #2: Science moves in baby steps. Each new paper pushes the state-of-the-art a bit further. Yet, it does not need to be a one-way road. Sometimes it is worthwhile to backtrack a bit and take a different turn. \u201cStop Thinking with Your Head,\u201d and \u201cReformer\u201d are two other good examples of this.", "Reason #3: Proper data augmentation, training schedules, and a good problem formulation matter more than most people would acknowledge.", "Further Reading: If interested in the Pose Estimation topic, you might consider reading this comprehensive state-of-the-art review.", "He, Tong, et al. \u201cBag of tricks for image classification with convolutional neural networks.\u201d Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.", "Many times, what you need is not a fancy new model, just a couple of new tricks. In most papers, one or two new tricks are introduced to achieve a one or two percentage points improvement. However, these are often forgotten amid the major contributions. This paper collects a set of tips used throughout the literature and summarizes them for our reading pleasure.", "Reason #1: Most tips are easily applicable", "Reason #2: High are the odds you are unaware of most approaches. These are not the typical \u201cuse ELU\u201d kind of suggestions.", "Further Readings: Many other tricks exist, some are problem-specific, some are not. A topic I believe deserves more attention is class and sample weights. Consider reading this paper on class weights for unbalanced datasets.", "Klambauer, G\u00fcnter, et al. \u201cSelf-normalizing neural networks.\u201d Advances in neural information processing systems. 2017.", "Most of us use Batch Normalization layers and the ReLU or ELU activation functions. In the SELU paper, the authors propose a unifying approach: an activation that self-normalizes its outputs. In practice, this renders batch normalization layers obsolete. Therefore, models using SELU activations are simpler and need fewer operations.", "Reason #1: In the paper, the authors mostly deal with standard machine learning problems (tabular data). Most data scientists deal primarily with images. Reading a paper on purely dense networks is a bit of a refreshment.", "Reason #2: If you have to deal with tabular data, this is one of the most up-to-date approaches to the topic within the Neural Networks literature.", "Reason #3: The paper is math-heavy and uses a computationally derived proof. This, in itself, is a rare but beautiful thing to be seen.", "Further Reading: If you want to dive into the history and usage of the most popular activation functions, I wrote a guide on activation functions here on Medium. Check it out :)", "Brendel, Wieland, and Matthias Bethge. \u201cApproximating cnns with bag-of-local-features models works surprisingly well on imagenet.\u201d arXiv preprint arXiv:1904.00760 (2019).", "If you break an image into jigsaw-like pieces, scramble them, and show them to a kid, it won\u2019t be able to recognize the original object; a CNN might. In this paper, the authors found that classifying all 33x33 patches of an image and then averaging their class predictions achieves near state-of-the-art results on ImageNet. Moreover, they further explore this idea with VGG and ResNet-50 models, showing evidence that CNNs rely extensively on local information, with minimal global reasoning", "Reason #1: While many believe that CNNs \u201csee,\u201d this paper shows evidence that they might be way dumber than we would dare to bet our money.", "Reason #2: Only once in a while we get to see a paper with a fresh new take on the limitations of CNNs and their interpretability.", "Further Reading: Related in its findings, the adversarial attacks literature also shows other striking limitations of CNNs. Consider reading the following article (and its reference section):", "Continuing on the theoretical papers, Frankle et al. found that if you train a big network, prune all low-valued weights, rollback the pruned network, and train again, you will get a better performing network. The lottery analogy is seeing each weight as a \u201clottery ticket.\u201d With a billion tickets, winning the prize is certain. However, most of the tickets won\u2019t win, only a couple will. If you could go back in time and buy only the winning tickets, you would maximize your profits. \u201cA billion tickets\u201d is a big initial network. \u201cTraining\u201d is running the lottery and seeing which weights are high-valued. \u201cGoing back in time\u201d is rolling-back to the initial untrained network and rerunning the lottery. In the end, you will get a better performing network.", "Reason #1: The idea is insanely cool.", "Reason #2: As for the Bag-of-Features paper, this sheds some light on how limited our current understanding of CNNs is. After reading this paper, I realized how underutilized our millions of parameters are. An open question is how much. The authors managed to reduce networks to a tenth of their original sizes, how much more might be possible in the future?", "Reason #3: These ideas also give us more perspective on how inefficient behemoth networks are. Consider the Reformer paper, mentioned before. It drastically reduced the size of the Transformer by improving the algorithm. How much more could be reduced by using the lottery technique?", "Further Reading: Weight initialization is an often overlooked topic. In my experience, most people stick to the defaults, which might not always be the best option. \u201cAll You Need is a Good Init\u201d is a seminal paper on the topic. As for the lottery hypothesis, the following is an easy to read review:", "Isola, Phillip, et al. \u201cImage-to-image translation with conditional adversarial networks.\u201d Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.", "Zhu, Jun-Yan, et al. \u201cUnpaired image-to-image translation using cycle-consistent adversarial networks.\u201d Proceedings of the IEEE international conference on computer vision. 2017.", "This list would not be complete without some GAN papers.", "Pix2Pix and CycleGAN are the two seminal works on conditional generative models. Both perform the task of converting images from a domain A to a domain B and differ by leveraging paired and unpaired datasets. The former perform tasks such as converting line drawings to fully rendered images, and the latter excels at replacing entities, such as turning horses into zebras or apples into oranges. By being \u201cconditional,\u201d these models allow users to have some degree of control over what is being generated by tweaking the inputs.", "Reason #1: GAN papers are usually focused on the sheer quality of the generated results and place no emphasis on artistic control. Conditional models, such as these, provide an avenue for GANs to actually become useful in practice. For instance, at being a virtual assistant to artists.", "Reason #2: Adversarial approaches are the best examples of multi-network models. While generation might not be your thing, reading about multi-network setups might be inspiring for a number of problems.", "Reason #3: The CycleGAN paper, in particular, demonstrates how an effective loss function can work wonders at solving some difficult problems. A similar idea is given by the Focal loss paper, which considerably improves object detectors by just replacing their traditional losses for a better one.", "Further Reading: While AI is growing fast, GANs are growing faster. I highly recommend coding a GAN if you never have. Here are the official Tensorflow 2 docs on the matter. One application of GANs that is not so well known (and you should check out) is semi-supervised learning.", "With these twelve papers and their further readings, I believe you already have plenty of reading material to look at. This surely isn\u2019t an exhaustive list of great papers. However, I tried my best to select the most insightful and seminal works I have seen and read. Please let me know if there are any other papers you believe should be on this list.", "Edit: After writing this list, I compiled a second one with ten more AI papers read in 2020 and a third on GANs. If you enjoyed reading this list, you might enjoy its continuations:", "Feel free to comment or connect with me. If you are new to Medium, I highly recommend subscribing. Medium articles are the perfect pair to StackOverflow for Data and IT professionals, and even more so for new comers. Please consider using my affiliate link when signing up.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Former game developer turned data scientist after falling in love with AI and all its branches."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fac0e4e91d915&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ygorserpa.medium.com/?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": ""}, {"url": "https://ygorserpa.medium.com/?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "Ygor Serpa"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F857d8734c7da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&user=Ygor+Serpa&userId=857d8734c7da&source=post_page-857d8734c7da----ac0e4e91d915---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac0e4e91d915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac0e4e91d915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@alfonsmc10?utm_source=medium&utm_medium=referral", "anchor_text": "Alfons Morales"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networ", "anchor_text": "\u201cImagenet classification with deep convolutional neural networks.\u201d"}, {"url": "https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53", "anchor_text": "ZF Net"}, {"url": "https://arxiv.org/abs/1409.1556", "anchor_text": "VGG"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html", "anchor_text": "Inception-v1,"}, {"url": "http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html", "anchor_text": "ResNet"}, {"url": "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networ", "anchor_text": "The Alexnet Paper"}, {"url": "https://arxiv.org/abs/1704.04861", "anchor_text": "\u201cMobilenets: Efficient convolutional neural networks for mobile vision applications.\u201d"}, {"url": "https://arxiv.org/abs/1801.04381", "anchor_text": "v2"}, {"url": "https://arxiv.org/abs/1905.02244", "anchor_text": "v3"}, {"url": "https://arxiv.org/abs/1602.07360", "anchor_text": "SqueezeNet"}, {"url": "https://arxiv.org/abs/1608.08710", "anchor_text": "downsize regular models with minimal accuracy loss."}, {"url": "https://ieeexplore.ieee.org/abstract/document/8050276", "anchor_text": "This paper"}, {"url": "http://papers.nips.cc/paper/7181-attention-is-all-you-need", "anchor_text": "\u201cAttention is all you need.\u201d"}, {"url": "https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/PAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask-%20Learners.pdf", "anchor_text": "GPT-2"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT"}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "Self-Attention GAN"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT"}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "SAGAN"}, {"url": "https://arxiv.org/abs/1911.11423", "anchor_text": "Single Headed Attention RNN: Stop Thinking With Your Head"}, {"url": "https://arxiv.org/abs/2001.04451", "anchor_text": "Reformer: The Efficient Transformer."}, {"url": "https://arxiv.org/abs/1911.11423", "anchor_text": "Stop Thinking With Your Head"}, {"url": "https://arxiv.org/abs/1704.04861", "anchor_text": "MobileNet paper"}, {"url": "http://openaccess.thecvf.com/content_iccv_2017/html/Martinez_A_Simple_yet_ICCV_2017_paper.html", "anchor_text": "\u201cSimple baselines for human pose estimation and tracking.\u201d"}, {"url": "https://nanonets.com/blog/human-pose-estimation-2d-guide/", "anchor_text": "this comprehensive state-of-the-art review."}, {"url": "https://arxiv.org/abs/1812.01187", "anchor_text": "\u201cBag of tricks for image classification with convolutional neural networks.\u201d"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/nn/elu", "anchor_text": "ELU"}, {"url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Cui_Class-Balanced_Loss_Based_on_Effective_Number_of_Samples_CVPR_2019_paper.pdf", "anchor_text": "this paper on class weights for unbalanced datasets"}, {"url": "https://arxiv.org/abs/1706.02515", "anchor_text": "\u201cSelf-normalizing neural networks.\u201d"}, {"url": "https://towardsdatascience.com/a-comprehensive-guide-on-activation-functions-b45ed37a4fa5", "anchor_text": "guide on activation functions"}, {"url": "https://arxiv.org/abs/1904.00760", "anchor_text": "\u201cApproximating cnns with bag-of-local-features models works surprisingly well on imagenet.\u201d"}, {"url": "https://towardsdatascience.com/breaking-neural-networks-with-adversarial-attacks-f4290a9a45aa", "anchor_text": "Breaking neural networks with adversarial attacksAre the machine learning models we use intrinsically flawed?towardsdatascience.com"}, {"url": "https://arxiv.org/abs/1803.03635", "anchor_text": "\u201cThe lottery ticket hypothesis: Finding sparse, trainable neural networks.\u201d"}, {"url": "https://towardsdatascience.com/why-default-cnn-are-broken-in-keras-and-how-to-fix-them-ce295e5e5f2", "anchor_text": "which might not always be the best option."}, {"url": "https://arxiv.org/abs/1511.06422", "anchor_text": "\u201cAll You Need is a Good Init\u201d"}, {"url": "https://towardsdatascience.com/breaking-down-the-lottery-ticket-hypothesis-ca1c053b3e58", "anchor_text": "Breaking down the Lottery Ticket HypothesisDistilling the ideas from MIT CSAIL\u2019s intriguing paper: \u201cThe Lottery Ticket Hypothesis: Finding Sparse, Trainable\u2026towardsdatascience.com"}, {"url": "https://phillipi.github.io/pix2pix/", "anchor_text": "Image-to-image translation with conditional adversarial networks.\u201d"}, {"url": "http://openaccess.thecvf.com/content_iccv_2017/html/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.html", "anchor_text": "\u201cUnpaired image-to-image translation using cycle-consistent adversarial networks.\u201d"}, {"url": "https://www.sbgames.org/sbgames2019/files/papers/ComputacaoFull/197880.pdf", "anchor_text": "For instance, at being a virtual assistant to artists."}, {"url": "https://www.tensorflow.org/tutorials/generative/dcgan", "anchor_text": "Here are the official Tensorflow 2 docs on the matter"}, {"url": "https://arxiv.org/abs/1905.06484", "anchor_text": "semi-supervised learning"}, {"url": "https://towardsdatascience.com/ten-more-ai-papers-to-read-in-2020-8c6fb4650a9b", "anchor_text": "Ten More AI Papers to Read in 2020Additional reading suggestions to keep you up-to-date with the latest and classic breakthroughs in AI and Data Sciencetowardsdatascience.com"}, {"url": "https://towardsdatascience.com/gan-papers-to-read-in-2020-2c708af5c0a4", "anchor_text": "GAN Papers to Read in 2020Reading suggestions on Generative Adversarial Networks.towardsdatascience.com"}, {"url": "https://www.linkedin.com/in/ygorreboucas/", "anchor_text": "connect with me"}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "subscribing"}, {"url": "https://stackoverflow.com/", "anchor_text": "StackOverflow"}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "my affiliate link when signing up."}, {"url": "https://medium.com/tag/ai?source=post_page-----ac0e4e91d915---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ac0e4e91d915---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/science?source=post_page-----ac0e4e91d915---------------science-----------------", "anchor_text": "Science"}, {"url": "https://medium.com/tag/research?source=post_page-----ac0e4e91d915---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----ac0e4e91d915---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac0e4e91d915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&user=Ygor+Serpa&userId=857d8734c7da&source=-----ac0e4e91d915---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac0e4e91d915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&user=Ygor+Serpa&userId=857d8734c7da&source=-----ac0e4e91d915---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac0e4e91d915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fac0e4e91d915&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ac0e4e91d915---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ac0e4e91d915--------------------------------", "anchor_text": ""}, {"url": "https://ygorserpa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ygorserpa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ygor Serpa"}, {"url": "https://ygorserpa.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F857d8734c7da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&user=Ygor+Serpa&userId=857d8734c7da&source=post_page-857d8734c7da--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3644829c90d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-papers-to-read-in-2020-ac0e4e91d915&newsletterV3=857d8734c7da&newsletterV3Id=3644829c90d9&user=Ygor+Serpa&userId=857d8734c7da&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}