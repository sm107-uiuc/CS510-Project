{"url": "https://towardsdatascience.com/tf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c", "time": 1683012147.09083, "path": "towardsdatascience.com/tf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c/", "webpage": {"metadata": {"title": "TF-IDF Calculation Using Map-Reduce Algorithm in PySpark | by Saket Thavanani | Towards Data Science", "h1": "TF-IDF Calculation Using Map-Reduce Algorithm in PySpark", "description": "Although, Spark MLlib has an inbuilt function to compute TD-IDF score which exploits the map/reduce algorithm to run the code in a distributed manner. In this article, we will be using Resilient\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@saketthavananilindan", "anchor_text": "Medium", "paragraph_index": 25}], "all_paragraphs": ["Although, Spark MLlib has an inbuilt function to compute TD-IDF score which exploits the map/reduce algorithm to run the code in a distributed manner. In this article, we will be using Resilient Distributed Datasets(RDDs) to implement map/reduce algorithm in order to get a better understanding of the underlying concept. The figure given below explains the basic idea of map/ reduce algorithm for the word count example. Initially, we split the words present in each line of the text data and generate a list of new key/value pairs in the map step. Further, in the reduce step we take a list of values for each distinct key (word) and produce new aggregated values for each distinct key.", "In this article, We will not be going into the theory of map/reduce algorithm. For people who are new to this, I would suggest them to first go through the following articles given below, in order to grasp the concept of map/reduce in Spark and Hadoop.", "TF-IDF is a way for extracting features for any textual data. It calculated using the term frequency and inverse document frequency.", "where N represents the frequency of a word in a document. The IDF score tells us how important is a particular word in the whole corpus. For instance, if a word is appearing in each document then the IDF score will be zero for that.", "Term Frequency is the number of times a particular word appears in a document. First, let\u2019s create a toy dataset as follows-", "Our dataset consists of three lines/documents associated with respective document-Ids. We can think of it like a key/ value pairs where the key is the document id and value is the text associated with respective document-id.", "Step 1: Mapping key/value pairs to a new key/value pairs.", "In this step, we map our existing key/value pair to a new key-value pair comprising of document-id and token as the key and 1(representing count) as the value. We will be using the flatMap transformation here to combine all the tokens in a single list.", "In this step, we will be grouping the key/value pairs with the common key and further aggregate the values for the same key to get the term frequency for a particular word corresponding to its document-id.", "We can see that word \u201cmy\u201d occurs twice in the third document, hence it is been grouped and values are summed to 2 (1+1).", "In this step, we will change the key/value pairs to a new set of key/ value/pairs with tokens as the key and its document-id and respective term frequency as the values.", "The IDF score tells us how important is a particular word in the whole corpus. For instance, if a word is appearing in each document then the IDF score will be zero for that.", "We know that the total number of documents for our case is 3 since we have three lines in the full corpus. So, our next step will be to compute how many documents contain a particular token w. Further, we can use this information to calculate the IDF scores for all the tokens in the corpus.", "We will be chaining the previous map/reduce computation to calculate IDF in this section. After the reduced step in the previous section, we obtained key/value pairs for respective tokens along with its term frequency.", "In this step, we will map the previous key/value pair to a new key/value pair. Here, the key will the token and its value will be the document id TF for that token along with a counter of 1. This one here indicates the presence of a word in document id associated with that.", "In this step, we will extract the token and the number of counter of 1 representing its occurrence in certain documents.", "In this step, we will reduce by key to obtain the count of documents containing a particular token w. For instance, knitting occurs in two documents so its sum will be 2 (1+1) after grouping and aggregating.", "Now since we have the number of documents containing each token w, we will just map this final output with the logarithmic transformation to compute the IDF score.", "Now we have two RDDs one having the document id along with its document term frequency for each token. Another RDD having IDF scores for each token.", "We will perform an inner join to assign each token with a document id, TF, and IDF score.", "Now we will map this function to multiply TF and IDF values of each token associated with respective document id.", "Let\u2019s convert the final output to a Pyspark data frame to visualize the scores more clearly and compare it with the actual theoretically calculated TF-IDF scores.", "We can clearly see from the above data frame and table that all the TF-IDF scores exactly align with the theoretical scores.", "The full code for the above implementation is shown below. It might look scary but there is nothing extraordinary in it. It only comprises of multiple map/ reduce steps chained together to get the final output.", "If you like my work and want to support me:", "1-The BEST way to support me is by following me on Medium.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Masters Student | University of Toronto | IIT Kharagpur | Data Science, Machine Learning and Deep Learning Enthusiast"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe89b5758e64c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@saketuoft?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saketuoft?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "Saket Thavanani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F102f526f83de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&user=Saket+Thavanani&userId=102f526f83de&source=post_page-102f526f83de----e89b5758e64c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe89b5758e64c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe89b5758e64c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@ev?utm_source=medium&utm_medium=referral", "anchor_text": "ev"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@elmaslouhy.mouaad/understanding-hadoop-mapreduce-f3e206cc3598", "anchor_text": "Understanding Hadoop MapReduceMapReduce is a clustered data processing framework. Composed of Map and Reduce functions, it distributes data\u2026medium.com"}, {"url": "https://medium.com/@francescomandru/mapreduce-explained-45a858c5ac1d", "anchor_text": "MapReduce explainedIntroduction and brief explanationmedium.com"}, {"url": "http://datacamp.com/community/tutorials/text-analytics-beginners-nltk", "anchor_text": "datacamp.com/community/tutorials/text-analytics-beginners-nltk"}, {"url": "https://medium.com/@saketthavananilindan", "anchor_text": "Medium"}, {"url": "https://www.linkedin.com/in/saket-thavanani-b1a149a0/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/big-data?source=post_page-----e89b5758e64c---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e89b5758e64c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/hadoop?source=post_page-----e89b5758e64c---------------hadoop-----------------", "anchor_text": "Hadoop"}, {"url": "https://medium.com/tag/spark?source=post_page-----e89b5758e64c---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e89b5758e64c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe89b5758e64c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&user=Saket+Thavanani&userId=102f526f83de&source=-----e89b5758e64c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe89b5758e64c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&user=Saket+Thavanani&userId=102f526f83de&source=-----e89b5758e64c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe89b5758e64c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe89b5758e64c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e89b5758e64c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e89b5758e64c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e89b5758e64c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e89b5758e64c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saketuoft?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saketuoft?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Saket Thavanani"}, {"url": "https://medium.com/@saketuoft/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "396 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F102f526f83de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&user=Saket+Thavanani&userId=102f526f83de&source=post_page-102f526f83de--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5dae2614ed2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftf-idf-calculation-using-map-reduce-algorithm-in-pyspark-e89b5758e64c&newsletterV3=102f526f83de&newsletterV3Id=5dae2614ed2d&user=Saket+Thavanani&userId=102f526f83de&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}