{"url": "https://towardsdatascience.com/interperable-vs-explainable-machine-learning-1fa525e12f48", "time": 1683014004.7930481, "path": "towardsdatascience.com/interperable-vs-explainable-machine-learning-1fa525e12f48/", "webpage": {"metadata": {"title": "Interpretable vs Explainable Machine Learning | by Conor O'Sullivan | Towards Data Science", "h1": "Interpretable vs Explainable Machine Learning", "description": "The difference between an interpretable and explainable machine learning model and how the concept of interpretability is related to this definition."}, "outgoing_paragraph_urls": [{"url": "https://medium.com/towards-data-science/what-is-interpretable-machine-learning-2d217b62185a", "anchor_text": "interpretable machine learning", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/AlexNet", "anchor_text": "AlexNet", "paragraph_index": 13}, {"url": "https://github.com/kundajelab/deeplift", "anchor_text": "DeepLIFT", "paragraph_index": 14}, {"url": "https://medium.com/towards-data-science/what-are-model-agnostic-methods-387b0e8441ef", "anchor_text": "model-agnostic approaches", "paragraph_index": 14}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME", "paragraph_index": 14}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP", "paragraph_index": 14}, {"url": "https://medium.com/towards-data-science/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa", "anchor_text": "PDPs and ICE Plots", "paragraph_index": 14}, {"url": "https://adataodyssey.com/courses/shap-with-python/", "anchor_text": "SHAP course", "paragraph_index": 24}, {"url": "https://mailchi.mp/aa82a5ce1dc0/signup", "anchor_text": "Newsletter", "paragraph_index": 24}, {"url": "https://conorosullyds.medium.com/membership", "anchor_text": "referred members", "paragraph_index": 25}, {"url": "http://www.flaticon.com/", "anchor_text": "www.flaticon.com", "paragraph_index": 26}, {"url": "https://support.flaticon.com/hc/en-us/articles/202798201-What-are-Flaticon-Premium-licenses-", "anchor_text": "Premium Plan", "paragraph_index": 26}, {"url": "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/", "anchor_text": "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/", "paragraph_index": 27}], "all_paragraphs": ["When you first dive into the field of interpretable machine learning you will notice similar terms flying around. Interpretability vs explainability. Interpretations vs explanations. We can\u2019t even seem to decide on the name for the field \u2014 is it interpretable machine learning (IML) or explainable AI (XAI)?", "We\u2019re going to discuss one definition and, hopefully, clarify some things. That is the difference between an interpretable and an explainable model. Although, we should warn you\u2026", "Part of the problem is IML is a new field. Definitions are still being proposed and debated. Machine learning researchers are also quick to create new terms for concepts that already exist. So, we\u2019ll focus on one potential definition [1]. Specifically, we will:", "We say that something is interpretable if it is capable of being understood. With that in mind, we say a model is interpretable if it is capable of being understood by humans on its own. We can look at the model parameters or a model summary and understand exactly how a prediction was made. Another term for these types of models is an intrinsically interpretable model [2].", "Interpretable models can be understood by a human without any other aids/techniques.", "A decision tree is a good example of this type of model. Figure 1 gives a tree trained to predict whether someone would default (Yes) or not default (No) on a car loan. To understand how a prediction was made, we simply have to traverse down the nodes of the tree.", "For example, suppose a 29-year-old with a $3000 monthly income makes an application. We want to understand why she was given a loan by an automated underwriting system based on this model. The person is over 25 so we go right at the first node. Then, she has an income \u2265 2000 so we go right again to a \u201cNo\u201d leaf node. In other words, the model predicts that the student will not default and the loan is sanctioned.", "Suppose we also want a model that predicts the maximum loan size (Y) given to a person. We use a person\u2019s age and income as features. Using linear regression, we get the following equation:", "We can easily see why the student above has a predicted maximum loan size of $33,100. That is loan size increases by:", "So, like the decision tree, we can look at this model\u2019s parameters and understand how it makes predictions. This is because these models are relatively simple. The decision tree has a few nodes and the linear regression model has 3 parameters. As models become more complicated we can no longer understand them in this way.", "You can think of an ML model as a function. The model features are the input and the predictions are the output. An explainable model is a function that is too complicated for a human to understand. Another name for this is a black-box model. We need an additional method/technique to be able to peer into the black-box and understand how the model works.", "Explainable models require additional techniques to be understood by humans", "An example of such a model is a Random Forest. A random forest is made up of many decision trees. The predictions of all the individual trees are taken into account when making the final prediction. To understand how a random forest works we would have to simultaneously understand how all of the individual trees work. Even with a small number of trees, this would not be possible for a human.", "Things get even more complicated when we start to look at algorithms like neural networks. To put it into perspective, AlexNet, a convolutional neural network used for image recognition, has 62,378,344 parameters [4]. In comparison, our regression model above only had 3 parameters. It is simply not possible for a human to comprehend how a model like AlexNet works by looking at only the parameter weights.", "So, we need some additional techniques to understand how these algorithms work. These include methods created for specific models. For example, DeepLIFT was created to explain neural networks. They also include model-agnostic approaches which can be applied to any model. These are methods like LIME, SHAP, PDPs and ICE Plots.", "Keep in mind that, even with these techniques, we cannot be as certain about how a model works as we can be with interpretable models. These techniques only provide approximations of how the model makes predictions. They all have their own assumptions and limitations.", "This means a level of caution should be taken when making conclusions using any of the techniques. If possible, multiple techniques should be used in combination. Conclusions should also be validated using visualisations of data and domain knowledge.", "Up to this point, we have discussed models as either being interpretable or explainable. Yet, it may not always make sense to apply this binary flag. The interpretability of a model is on a spectrum. One model is more interpretable than another if it is easier for a human to understand how it makes predictions than the other model.", "Interpretability is the degree to which a model can be understood in human terms [2]", "Figure 2 gives the interpretability spectrum. A convolutional neural network is less interpretable than a random forest which is less interpretable than a decision tree. Most models could generally be classified as interpretable or explainable. However, there is a grey area where people would disagree on the classification.", "This grey area is where we find our first issue with this definition. We may agree that a random forest with 2 trees is interpretable. Yet, a random forest with 100 trees is not interpretable. At what point (i.e. how many trees), does the model go from interpretable to explainable? Even a decision tree with many nodes or regression with many parameters could become too complicated for a human to understand without additional techniques.", "The issue is that we are trying to classify a model based on human comprehension. There is no formal way to measure this. Your ability to understand a model will depend on your technical skills and professional experience. Even amongst professionals, there will be disagreement.", "Another issue is what we define as an additional technique. To understand even the simplest models we seek help from other methods. For example, it is common to use a correlation matrix when explaining the weights of linear regression. Does this mean regression is now an explainable model?", "This leads to the question, do we even need this definition? The goal of IML is to understand and explain our models. We do not need to classify them as interpretable or explainable to do this. The methods we choose will ultimately depend on the type of model and the specific questions we seek to answer.", "If you are interested in IML, you may find my articles below helpful. Otherwise, check out my SHAP course. It will teach you everything you need to know about explaining your models using the Python package. You can get free access if you sign up for my Newsletter :)", "If you found this article helpful and want to see more, you can support me by becoming one of my referred members", "Images are my own or obtain from www.flaticon.com. In the case of the latter, I have a \u201cFull license\u201d as defined under their Premium Plan.", "[4] S. Mallick & S. Nayak, Number of Parameters and Tensor Sizes in a Convolutional Neural Network (CNN) (2018), https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Writer | Houseplant Addict | I write about IML, XAI, Algorithm Fairness and Data Exploration | New article (nearly) every week!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1fa525e12f48&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://conorosullyds.medium.com/?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "Conor O'Sullivan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4ae48256fb37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=post_page-4ae48256fb37----1fa525e12f48---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1fa525e12f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1fa525e12f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/towards-data-science/what-is-interpretable-machine-learning-2d217b62185a", "anchor_text": "interpretable machine learning"}, {"url": "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/", "anchor_text": "Satya Mallick & Sunita Nayak"}, {"url": "https://en.wikipedia.org/wiki/AlexNet", "anchor_text": "AlexNet"}, {"url": "https://github.com/kundajelab/deeplift", "anchor_text": "DeepLIFT"}, {"url": "https://medium.com/towards-data-science/what-are-model-agnostic-methods-387b0e8441ef", "anchor_text": "model-agnostic approaches"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "https://medium.com/towards-data-science/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa", "anchor_text": "PDPs and ICE Plots"}, {"url": "https://adataodyssey.com/courses/shap-with-python/", "anchor_text": "SHAP course"}, {"url": "https://mailchi.mp/aa82a5ce1dc0/signup", "anchor_text": "Newsletter"}, {"url": "https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454", "anchor_text": "Introduction to SHAP with PythonHow to create and interpret SHAP plots: waterfall, force, mean SHAP, beeswarm and dependencetowardsdatascience.com"}, {"url": "https://towardsdatascience.com/the-ultimate-guide-to-pdps-and-ice-plots-4182885662aa", "anchor_text": "The Ultimate Guide to PDPs and ICE PlotsThe intuition, maths and code (R and Python) behind partial dependence plots and individual conditional expectation\u2026towardsdatascience.com"}, {"url": "https://conorosullyds.medium.com/membership", "anchor_text": "referred members"}, {"url": "http://www.flaticon.com/", "anchor_text": "www.flaticon.com"}, {"url": "https://support.flaticon.com/hc/en-us/articles/202798201-What-are-Flaticon-Premium-licenses-", "anchor_text": "Premium Plan"}, {"url": "https://arxiv.org/abs/1811.10154", "anchor_text": "https://arxiv.org/abs/1811.10154"}, {"url": "https://christophm.github.io/interpretable-ml-book/taxonomy-of-interpretability-methods.html", "anchor_text": "https://christophm.github.io/interpretable-ml-book/taxonomy-of-interpretability-methods.html"}, {"url": "https://www.kdnuggets.com/2018/12/machine-learning-explainability-interpretability-ai.html", "anchor_text": "https://www.kdnuggets.com/2018/12/machine-learning-explainability-interpretability-ai.html"}, {"url": "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/", "anchor_text": "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1fa525e12f48---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1fa525e12f48---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----1fa525e12f48---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----1fa525e12f48---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----1fa525e12f48---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1fa525e12f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=-----1fa525e12f48---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1fa525e12f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=-----1fa525e12f48---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1fa525e12f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1fa525e12f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1fa525e12f48---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1fa525e12f48--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1fa525e12f48--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1fa525e12f48--------------------------------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Conor O'Sullivan"}, {"url": "https://conorosullyds.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.3K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4ae48256fb37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=post_page-4ae48256fb37--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F93bef42da4fd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterperable-vs-explainable-machine-learning-1fa525e12f48&newsletterV3=4ae48256fb37&newsletterV3Id=93bef42da4fd&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}