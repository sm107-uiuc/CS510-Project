{"url": "https://towardsdatascience.com/what-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9", "time": 1683016099.612772, "path": "towardsdatascience.com/what-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9/", "webpage": {"metadata": {"title": "What if multiple receptive fields are used for Image Inpainting? | by Chu-Tak Li | Towards Data Science", "h1": "What if multiple receptive fields are used for Image Inpainting?", "description": "Hello guys! Long time no see! Today, we are going to talk about another inpainting paper called Image Inpainting via Generative Multi-column CNNs (GMCNN). The network architecture used in this paper\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "before", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "previous posts", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "previous post", "paragraph_index": 3}, {"url": "https://medium.com/analytics-vidhya/review-high-resolution-image-inpainting-using-multi-scale-neural-patch-synthesis-4bbda21aa5bc", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://medium.com/analytics-vidhya/review-high-resolution-image-inpainting-using-multi-scale-neural-patch-synthesis-4bbda21aa5bc", "anchor_text": "previous work", "paragraph_index": 18}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper", "paragraph_index": 20}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "previous work", "paragraph_index": 21}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper", "paragraph_index": 21}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/a-milestone-in-deep-image-inpainting-review-globally-and-locally-consistent-image-completion-505413c300df", "anchor_text": "encoder-decoder structure", "paragraph_index": 26}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "coarse-to-fine structure", "paragraph_index": 26}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "Image Inpainting via Generative Multi-column Convolutional Neural Networks", "paragraph_index": 37}, {"url": "https://chutakcode.wixsite.com/website", "anchor_text": "https://chutakcode.wixsite.com/website", "paragraph_index": 40}], "all_paragraphs": ["Hello guys! Long time no see! Today, we are going to talk about another inpainting paper called Image Inpainting via Generative Multi-column CNNs (GMCNN). The network architecture used in this paper is similar to those papers we have introduced before. The main contribution of this paper is several modifications to the loss function.", "As mentioned in my previous posts, how to make use of the information given by the remaining pixels in an image is crucial to superior image inpainting. A very straightforward sense of image inpainting is to directly copy the most similar image patches found in the image itself and paste on the missing areas. Interestingly, we should realize that there is no \u201ccorrect\u201d answer to the missing areas in practice. In reality, given a corrupted/masked image, you cannot know the original image (ground truth) for comparison. So, we have so many answers to the missing areas.", "From previous inpainting papers, we know that receptive field is important to the task of image inpainting. For a 3\u00d73 kernel, we can adjust the dilation rate to control the receptive field of it. If the dilation rate is 1, we have a 3\u00d73 receptive field. If the dilation rate is 2, we have a 5\u00d75 receptive field by skipping one neighboring pixel, and so on. You may refer to my previous post to find more details. Here, what if we employ 3\u00d73, 5\u00d75, and 7\u00d77 kernels with dilated convolutions? This is defined as a multi-column structure in this paper.", "In my previous post related to the contextual attention layer, the process of searching for the most similar image patches to the missing areas is embedded in the generator network (i.e. this process is used in both training and testing stages). In this work, this process is used during training only by designing a new loss term.", "Due to the fact that there is no \u201ccorrect\u201d answer to the missing areas, pixel-wise reconstruction accuracy loss term (i.e. L1 loss) seems inappropriate for image inpainting. The authors proposed to weight the L1 loss term based on the spatial locations of the missing pixels. Spatial locations where are close to the valid (remaining) pixels should have higher weights to the L1 loss as they have more reasonable references for the reconstruction, and vice versa.", "In my opinion, this paper follows the trend in image inpainting that we have covered previously. First, the authors adopt multi-branches CNNs with dilated convolutions instead of single branch. Three different kernel sizes are used in three different branches for achieving various receptive fields and extracting features at different resolutions.", "Second, two new loss terms are introduced to train the network, namely confidence-driven reconstruction loss and implicit diversified Markov Random Field (ID-MRF) loss. Confidence-driven reconstruction loss is a weighted L1 loss while ID-MRF loss relates to the feature patch comparison computed by pre-trained VGG network. We have talked about the MRF loss [here]. You may refer to it for a brief recall.", "Figure 1 shows some inpainting results by the proposed method. You may zoom in for a better view of these high quality results.", "Figure 2 shows the network architecture of the proposed Generative Multi-column Convolution Neural Networks (GMCNN). As you can see, there are one multi-column generator network, two discriminators (both global and local), and a pre-train VGG19 for calculating the ID-MRF loss.", "There are three columns in the generator network and each column uses filters with three different sizes, namely 3\u00d73, 5\u00d75 and 7\u00d77. Note that the outputs from the three columns are concatenated to feed to other two convolutional layers to get the completed images.", "Simply speaking, for MRF objective, we would like to minimize the difference between the generated features and the most nearest-neighbor features from the ground truth computed by a pre-trained network. In most previous work, cosine similarity measure has been employed to search for the nearest neighbors (you may read my previous post [here] for reviewing the cosine similarity measure). However, this similarity measure usually gives the same nearest neighbor to different generated feature patches and results in blurry inpainting results as shown in Figure 3(a).", "To avoid blurry completed images that may be caused by the employment of the cosine similarity measure, the authors adopt a relative distance measure and the inpainting results are shown in Figure 3(b). You can see that the completed image is with better local fine textures.", "Let\u2019s talk about how they perform the relative distance measure. Let Y(hat)_g be the generated content for the missing areas, Y(hat)^L_g and Y^L are the features at the L-th layer of a pre-trained network. For the feature patches v and s extracted from Y(hat)^L_g and Y^L respectively, the relative similarity from v to s is computed,", "where mu(. , .) is the cosine similarity. r belongs to Y^L excluding v. h and epsilon are positive constants. Clearly, if v is more similar to s than other feature patches, RS(v, s) will be large. You may also consider that if v has two similar patches s and r, then RS(v, s) will be small. We encourage to find similar patches outside the missing regions.", "Then, RS is normalized as follows.", "Finally, the proposed ID-MRF loss between Y(hat)^L_g and Y^L is calculated,", "where the argument max RS(bar)(v, s) means that s is the nearest neighbor to v and Z is a normalization factor. If we consider the extreme case that all generated feature patches are close to a particular feature patch s, then max RS(bar) (v, r) will be small and thus the ID-MRF loss will be large.", "On the other hand, if each r in Y^L has its own nearest neighbor in Y(hat)^L_g, then max RS(bar) (v, r) will be large and thus the ID-MRF loss will be small. Here, the main idea is to force/guide the generated feature patches to have different nearest neighbors, and thus the generated features are with better local textures.", "Same as previous work, the authors use a pre-trained VGG19 to calculate the ID-MRF loss. Note that the middle layers conv3_2 and conv4_2 represent the structural and semantic features respectively.", "The authors claim that this loss is related to the nearest neighbor searching and is only employed during the training stage. This is different from methods which search for the nearest neighbors during the testing stage.", "The proposed spatial variant reconstruction loss is actually a weighted L1 loss. There are many ways to decide the weights and the authors use a Gaussian filter to convolve the mask to create a weighted mask for calculating the weighted L1 loss. Interested readers may refer to the paper for details. The main idea of the weighted L1 loss is that the missing pixels close to the valid pixels are highly constrained than those missing pixels far away from the valid pixels. Hence, the missing pixels located at the center of the missing region should have lower L1 loss weights (i.e. less constrained).", "Similar to the previous work, the authors employ the improved WGAN loss and both local and global discriminators. Again, interested readers are highly recommended to read the paper.", "This is the final loss function used to train the proposed model. Similar to most inpainting papers, the importance of the weighted L1 loss (the first loss term) is 1. Lambda_mrf and lambda_adv are the parameters to control the importance of the local texture MRF regularization and the adversarial training.", "The authors evaluate their method on 5 public datasets, namely Paris StreetView, Places2, ImageNet, CelebA, and CelebA-HQ datasets. During their training, all the images are resized to 256\u00d7256 with the largest center hole of size 128\u00d7128. For your information, their generator network has 12.562M parameters. It takes around 49.37 ms and 146.11 ms per image on GPU for testing images with size of 256\u00d7256 and 512\u00d7512 respectively.", "Figure 4 shows the qualitative comparisons on Paris StreetView and ImageNet datasets. Please zoom in for a better view of the inpainting results. It is clear that the proposed method, GMCNN, gives the inpainting results with the best visual quality. If you are interested in more inpainting results, please refer to the paper or their project website.", "As mentioned in my previous posts and at the beginning of this post, PSNR is related to the pixel-wise reconstruction accuracy which may not be appropriate for evaluating image inpainting. Researchers still report PSNR and SSIM for readers\u2019 reference as these numerical metrics are fundamental for all image processing tasks. As you can see in Table 1, the proposed method achieves comparable or even better PSNR and SSIM on the five datasets.", "The authors evaluate the performance of different network structures used in the task of image inpainting. We have covered the encoder-decoder structure and coarse-to-fine structure. For the coarse-to-fine structure in their experiments, no contextual attention is employed. For GMCNN with fixed receptive field in all the 3 branches, they employ filter with size of 5\u00d75. For GMCNN with varied receptive fields, 3\u00d73, 5\u00d75, and 7\u00d77 filters are used in the 3 branches respectively. The quantitative and qualitative results are shown in Table 2 and Figure 5 respectively. Obviously, GMCNN with varied receptive fields provides the best inpainting results.", "Apart from the choice of the network architecture and the employment of multiple receptive fields, the authors also study the effectiveness of the two proposed loss terms, namely confidence-driven reconstruction loss and the ID-MRF loss.", "Figure 6 shows the visual comparisons of different reconstruction losses, namely spatial discounted loss and the proposed confidence-driven reconstruction loss. Note that the spatial discounted loss gets the weight mask based on the spatial locations of the missing pixels while the proposed confidence-driven reconstruction loss gets the weight mask by convolving the mask image multiple times with a Gaussian filter. The authors claim that their confidence-driven reconstruction loss works better. From my own experience, both reconstruction losses are similar to each other. Perhaps you may have a try on it.", "More importantly, the ID-MRF loss term is the strongest claim of this paper. So, the authors show the importance of this loss term and the quantitative results are listed in Table 3. Figure 7 shows the difference between model trained using the ID-MRF loss and not using the ID-MRF loss. We can see that the use of the ID-MRF can enhance the local details of the generated pixels. Additionally, Figure 8 shows the effects of using different lambda_mrf to control the importance of the ID-MRF loss. You can zoom in for a better view of the results. Personally, the inpainting results are similar. From Table 3, lambda_mrf = 0.02 offers a good balance between the PSNR and the visual quality.", "To conclude, the key novelty of this paper is the ID-MRF loss term to further enhance the local details of the generated content. The main idea of this loss is to guide the generated feature patches to find their nearest neighbors outside the missing areas as references and the nearest neighbors should be diverse such that the more local details can be simulated.", "The use of the multiple receptive fields (multi-column or multiple branches) is due to the fact that the size of the receptive field is important to the task of image inpainting. As the local neighboring pixels are missing, we have to borrow information given by distant spatial locations to fill in the missing pixels. I think this idea is not difficult for you to understand if you have followed my previous posts.", "The use of the weighted L1 loss is also due to the fact that there is no \u201ccorrect\u201d answer to the missing regions. For those missing pixels which are closer to the boundary of the missing areas, they are relatively constrained by the near valid pixels, hence higher weights to the L1 loss should be assigned. On the other hand, for missing pixels which are located at the center of the missing areas, they should be less L1 constrained.", "Refer to my conclusion in above, I hope that you can understand the meaning of the proposed ID-MRF loss as this is the key idea of this paper. For other two ideas in this paper, namely the multi-column structure and the weighted L1 loss. Actually, I think you can understand the reasons behind well if you have followed my previous posts. I would say that the concept of multiple/various receptive fields is a common practice in deep image inpainting.", "For the weighted L1 loss, from my own experience, I don\u2019t think it can bring an obvious improvement in the inpainting performance. Of course, there are many ways to achieve weighted L1 loss. If you are interested in this, you may have a try on it. I will also keep doing experiments on this! :)", "In my next post, I will talk about how to deal with irregular masks. So far we have introduced several famous deep image inpainting methods. However, they mainly focus on regular masks (usually a large center rectangular mask or sometimes multiple small rectangular masks). So, let\u2019s see how researchers deal with irregular masks recently.", "If you are interested in deep generative models for image inpainting, I highly recommend you skim all of my previous posts. Hope you guys enjoy :)", "[1] Yi Wang, Xin Tao, Xiaojuan Qi, Xiaoyong Shen, and Jiaya Jia, \u201cImage Inpainting via Generative Multi-column Convolutional Neural Networks,\u201d Proc. Neural Information Processing Systems, 2018.", "Again, many thanks for reading my post! If you have any questions, please feel free to send my an email or leave comments here. Any suggestions are welcome. It is extremely important for us to learn systematically. Thank you very much and see you next time! :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "DO IT FIRST. ONLY U CAN DEFINE YOURSELF. I have started my PhD journey accidentally. To know more about me at: https://chutakcode.wixsite.com/website"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fea44003ea7e9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lichutak.medium.com/?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": ""}, {"url": "https://lichutak.medium.com/?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "Chu-Tak Li"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4c07943b642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&user=Chu-Tak+Li&userId=f4c07943b642&source=post_page-f4c07943b642----ea44003ea7e9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea44003ea7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea44003ea7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "before"}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "previous posts"}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "previous post"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://medium.com/analytics-vidhya/review-high-resolution-image-inpainting-using-multi-scale-neural-patch-synthesis-4bbda21aa5bc", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "here"}, {"url": "https://medium.com/analytics-vidhya/review-high-resolution-image-inpainting-using-multi-scale-neural-patch-synthesis-4bbda21aa5bc", "anchor_text": "previous work"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "previous work"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://towardsdatascience.com/a-milestone-in-deep-image-inpainting-review-globally-and-locally-consistent-image-completion-505413c300df", "anchor_text": "encoder-decoder structure"}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "coarse-to-fine structure"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1810.08771.pdf", "anchor_text": "Image Inpainting via Generative Multi-column Convolutional Neural Networks"}, {"url": "https://medium.com/tag/image-inpainting?source=post_page-----ea44003ea7e9---------------image_inpainting-----------------", "anchor_text": "Image Inpainting"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----ea44003ea7e9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/image-processing?source=post_page-----ea44003ea7e9---------------image_processing-----------------", "anchor_text": "Image Processing"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----ea44003ea7e9---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/generative-adversarial?source=post_page-----ea44003ea7e9---------------generative_adversarial-----------------", "anchor_text": "Generative Adversarial"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea44003ea7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&user=Chu-Tak+Li&userId=f4c07943b642&source=-----ea44003ea7e9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea44003ea7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&user=Chu-Tak+Li&userId=f4c07943b642&source=-----ea44003ea7e9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea44003ea7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fea44003ea7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ea44003ea7e9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ea44003ea7e9--------------------------------", "anchor_text": ""}, {"url": "https://lichutak.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lichutak.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Chu-Tak Li"}, {"url": "https://lichutak.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "122 Followers"}, {"url": "https://chutakcode.wixsite.com/website", "anchor_text": "https://chutakcode.wixsite.com/website"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4c07943b642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&user=Chu-Tak+Li&userId=f4c07943b642&source=post_page-f4c07943b642--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd59b7e8b1294&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9&newsletterV3=f4c07943b642&newsletterV3Id=d59b7e8b1294&user=Chu-Tak+Li&userId=f4c07943b642&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}