{"url": "https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0", "time": 1683007194.801593, "path": "towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0/", "webpage": {"metadata": {"title": "Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models | by Roland Hewage | Towards Data Science", "h1": "Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models", "description": "Keras provides a set of deep learning models that are made available alongside pre-trained weights on ImageNet dataset. These models can be used for prediction, feature extraction, and fine-tuning\u2026"}, "outgoing_paragraph_urls": [{"url": "https://keras.io/applications/", "anchor_text": "Keras", "paragraph_index": 0}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet", "paragraph_index": 0}], "all_paragraphs": ["Keras provides a set of deep learning models that are made available alongside pre-trained weights on ImageNet dataset. These models can be used for prediction, feature extraction, and fine-tuning. Here I\u2019m going to discuss how to extract features, visualize filters and feature maps for the pretrained models VGG16 and VGG19 for a given image.", "Here we first import the VGG16 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG16 model. The numpy module is imported for array-processing. Then the VGG16 model is loaded with the pretrained weights for the imagenet dataset. VGG16 model is a series of convolutional layers followed by one or a few dense (or fully connected) layers. Include_top lets you select if you want the final dense layers or not. False indicates that the final dense layers are excluded when loading the model. From the input layer to the last max pooling layer (labeled by 7 x 7 x 512) is regarded as feature extraction part of the model, while the rest of the network is regarded as classification part of the model. After defining the model, we need to load the input image with the size expected by the model, in this case, 224\u00d7224. Next, the image PIL object needs to be converted to a NumPy array of pixel data and expanded from a 3D array to a 4D array with the dimensions of [samples, rows, cols, channels], where we only have one sample. The pixel values then need to be scaled appropriately for the VGG model. We are now ready to get the features.", "Here also we first import the VGG16 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG16 model. The numpy module is imported for array-processing. In addition the Model module is imported to design a new model that is a subset of the layers in the full VGG16 model. The model would have the same input layer as the original model, but the output would be the output of a given convolutional layer, which we know would be the activation of the layer or the feature map. Then the VGG16 model is loaded with the pretrained weights for the imagenet dataset. For example, after loading the VGG model, we can define a new model that outputs a feature map from the block4 pooling layer. After defining the model, we need to load the input image with the size expected by the model, in this case, 224\u00d7224. Next, the image PIL object needs to be converted to a NumPy array of pixel data and expanded from a 3D array to a 4D array with the dimensions of [samples, rows, cols, channels], where we only have one sample. The pixel values then need to be scaled appropriately for the VGG model. We are now ready to get the features.", "For example here we extract features of block4_pool layer.", "Here we first import the VGG19 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG19 model. The numpy module is imported for array-processing. Then the VGG19 model is loaded with the pretrained weights for the imagenet dataset. VGG19 model is a series of convolutional layers followed by one or a few dense (or fully connected) layers. Include_top lets you select if you want the final dense layers or not. False indicates that the final dense layers are excluded when loading the model. From the input layer to the last max pooling layer (labeled by 7 x 7 x 512) is regarded as feature extraction part of the model, while the rest of the network is regarded as classification part of the model. After defining the model, we need to load the input image with the size expected by the model, in this case, 224\u00d7224. Next, the image PIL object needs to be converted to a NumPy array of pixel data and expanded from a 3D array to a 4D array with the dimensions of [samples, rows, cols, channels], where we only have one sample. The pixel values then need to be scaled appropriately for the VGG model. We are now ready to get the features", "Here also we first import the VGG19 model from tensorflow keras. The image module is imported to preprocess the image object and the preprocess_input module is imported to scale pixel values appropriately for the VGG19 model. The numpy module is imported for array-processing. In addition the Model module is imported to design a new model that is a subset of the layers in the full VGG19 model. The model would have the same input layer as the original model, but the output would be the output of a given convolutional layer, which we know would be the activation of the layer or the feature map. Then the VGG19 model is loaded with the pretrained weights for the imagenet dataset. For example, after loading the VGG model, we can define a new model that outputs a feature map from the block4 pooling layer. After defining the model, we need to load the input image with the size expected by the model, in this case, 224\u00d7224. Next, the image PIL object needs to be converted to a NumPy array of pixel data and expanded from a 3D array to a 4D array with the dimensions of [samples, rows, cols, channels], where we only have one sample. The pixel values then need to be scaled appropriately for the VGG model. We are now ready to get the features.", "For example here we extract features of block4_pool layer.", "Filters are simply weights, yet because of the specialized two-dimensional structure of the filters, the weight values have a spatial relationship to each other and plotting each filter as a two-dimensional image is meaningful. Here we review the filters in the VGG16 model. Here we import the VGG19 model from tensorflow keras. We can access all of the layers of the model via the model.layers property. Each layer has a layer.name property, where the convolutional layers have a naming convolution like block#_conv#, where the \u2018#\u2018 is an integer. Therefore, we can check the name of each layer and skip any that don\u2019t contain the string \u2018conv\u2018. Each convolutional layer has two sets of weights. One is the block of filters and the other is the block of bias values. These are accessible via the layer.get_weights() function. We can retrieve these weights and then summarize their shape. The complete example of summarizing the model filters is given above and the results are shown below.", "All convolutional layers use 3\u00d73 filters, which are small and perhaps easy to interpret. An architectural concern with a convolutional neural network is that the depth of a filter must match the depth of the input for the filter (e.g. the number of channels). We can see that for the input image with three channels for red, green and blue, that each filter has a depth of three (here we are working with a channel-last format). We could visualize one filter as a plot with three images, one for each channel, or compress all three down to a single color image, or even just look at the first channel and assume the other channels will look the same.", "Here we retrieve weights from the second hidden layer of VGG16 model. The weight values will likely be small positive and negative values centered around 0.0. We can normalize their values to the range 0\u20131 to make them easy to visualize. We can enumerate the first six filters out of the 64 in the block and plot each of the three channels of each filter. We use the matplotlib library and plot each filter as a new row of subplots, and each filter channel or depth as a new column. Here we plot the first six filters from the first hidden convolutional layer in the VGG16 model.", "It creates a figure with six rows of three images, or 18 images, one row for each filter and one column for each channel. We can see that in some cases, the filter is the same across the channels (the first row), and in others, the filters differ (the last row). The dark squares indicate small or inhibitory weights and the light squares represent large weights. Using this intuition, we can see that the filters on the first row detect a gradient from light in the top left to dark in the bottom right.", "The activation maps, called feature maps, capture the result of applying the filters to input, such as the input image or another feature map. The idea of visualizing a feature map for a specific input image would be to understand what features of the input are detected or preserved in the feature maps. The expectation would be that the feature maps close to the input detect small or fine-grained detail, whereas feature maps close to the output of the model capture more general features. In order to explore the visualization of feature maps, we need input for the VGG16 model that can be used to create activations.", "We need a clearer idea of the shape of the feature maps output by each of the convolutional layers and the layer index number. So we enumerate all layers in the model and print the output size or feature map size for each convolutional layer as well as the layer index in the model.", "Here we design a new model that is a subset of the layers in the full VGG16 model. The model would have the same input layer as the original model, but the output would be the output of a given convolutional layer, which we know would be the activation of the layer or the feature map. After loading the VGG model, we can define a new model that outputs a feature map from the first convolutional layer. Making a prediction with this model will give the feature map for the first convolutional layer for a given provided input image. After defining the model, we need to load the input image with the size expected by the model, in this case, 224\u00d7224. Next, the image PIL object needs to be converted to a NumPy array of pixel data and expanded from a 3D array to a 4D array with the dimensions of [samples, rows, cols, channels], where we only have one sample. The pixel values then need to be scaled appropriately for the VGG model. We are now ready to get the feature map. We can do this easy by calling the model.predict() function and passing in the prepared single image. We know the result will be a feature map with 224x224x64. We can plot all 64 two-dimensional images as an 8\u00d78 square of images.", "Here we collect feature maps output from each block of the model in a single pass, then create an image of each. There are five main blocks in the image (e.g. block1, block2, etc.) that end in a pooling layer. The layer indexes of the last convolutional layer in each block are [2, 5, 9, 13, 17]. We can define a new model that has multiple outputs, one feature map output for each of the last convolutional layer in each block. Making a prediction with this new model will result in a list of feature maps. We know that the number of feature maps (e.g. depth or number of channels) in deeper layers is much more than 64, such as 256 or 512. Nevertheless, we can cap the number of feature maps visualized at 64 for consistency. Here we create five separate plots for each of the five blocks in the VGG16 model for our input image.", "Running the example results in five plots showing the feature maps from the five main blocks of the VGG16 model. We can see that the feature maps closer to the input of the model capture a lot of fine detail in the image and that as we progress deeper into the model, the feature maps show less and less detail. This pattern was to be expected, as the model abstracts the features from the image into more general concepts that can be used to make a classification. Although it is not clear from the final image that the model saw a car, we generally lose the ability to interpret these deeper feature maps.", "Hope you have gained some good knowledge about how to Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models. Stay tuned for more amazing articles.", "(Born to Code) | Software Engineer (Ecosystem Engineering) at WSO2 | Bachelor of Computer Science (Special) Degree Graduate at University of Ruhuna, Sri Lanka"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd2da6333edd0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://rolyhewage.medium.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Roland Hewage"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F710f77466d5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&user=Roland+Hewage&userId=710f77466d5e&source=post_page-710f77466d5e----d2da6333edd0---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2da6333edd0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&user=Roland+Hewage&userId=710f77466d5e&source=-----d2da6333edd0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2da6333edd0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&source=-----d2da6333edd0---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "http://www.cs.toronto.edu/~frossard/post/vgg16/", "anchor_text": "VGG16 Architecture"}, {"url": "https://miro.medium.com/max/2408/1*6U9FJ_se7SIuFKJRyPMHuA.png", "anchor_text": "VGG19 Architecture"}, {"url": "https://keras.io/applications/", "anchor_text": "Keras"}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d2da6333edd0---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----d2da6333edd0---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/vgg16?source=post_page-----d2da6333edd0---------------vgg16-----------------", "anchor_text": "Vgg16"}, {"url": "https://medium.com/tag/vgg19?source=post_page-----d2da6333edd0---------------vgg19-----------------", "anchor_text": "Vgg19"}, {"url": "https://medium.com/tag/feature-extraction?source=post_page-----d2da6333edd0---------------feature_extraction-----------------", "anchor_text": "Feature Extraction"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2da6333edd0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&user=Roland+Hewage&userId=710f77466d5e&source=-----d2da6333edd0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2da6333edd0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&user=Roland+Hewage&userId=710f77466d5e&source=-----d2da6333edd0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2da6333edd0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F710f77466d5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&user=Roland+Hewage&userId=710f77466d5e&source=post_page-710f77466d5e----d2da6333edd0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff8a43d7511c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&newsletterV3=710f77466d5e&newsletterV3Id=f8a43d7511c9&user=Roland+Hewage&userId=710f77466d5e&source=-----d2da6333edd0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Written by Roland Hewage"}, {"url": "https://rolyhewage.medium.com/followers?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "130 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F710f77466d5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&user=Roland+Hewage&userId=710f77466d5e&source=post_page-710f77466d5e----d2da6333edd0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff8a43d7511c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0&newsletterV3=710f77466d5e&newsletterV3Id=f8a43d7511c9&user=Roland+Hewage&userId=710f77466d5e&source=-----d2da6333edd0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/analyze-health-insurance-data-using-rstudio-85f1c1e37ec8?source=author_recirc-----d2da6333edd0----0---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=author_recirc-----d2da6333edd0----0---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=author_recirc-----d2da6333edd0----0---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Roland Hewage"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d2da6333edd0----0---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/analyze-health-insurance-data-using-rstudio-85f1c1e37ec8?source=author_recirc-----d2da6333edd0----0---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Analyze Health Insurance Data using RStudioLearn How to Analyze Health Insurance Data using RStudio"}, {"url": "https://towardsdatascience.com/analyze-health-insurance-data-using-rstudio-85f1c1e37ec8?source=author_recirc-----d2da6333edd0----0---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "\u00b712 min read\u00b7Sep 5, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F85f1c1e37ec8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-health-insurance-data-using-rstudio-85f1c1e37ec8&user=Roland+Hewage&userId=710f77466d5e&source=-----85f1c1e37ec8----0-----------------clap_footer----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/analyze-health-insurance-data-using-rstudio-85f1c1e37ec8?source=author_recirc-----d2da6333edd0----0---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F85f1c1e37ec8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-health-insurance-data-using-rstudio-85f1c1e37ec8&source=-----d2da6333edd0----0-----------------bookmark_preview----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2da6333edd0----1---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d2da6333edd0----1---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d2da6333edd0----1---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d2da6333edd0----1---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2da6333edd0----1---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2da6333edd0----1---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2da6333edd0----1---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----d2da6333edd0----1-----------------bookmark_preview----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2da6333edd0----2---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d2da6333edd0----2---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d2da6333edd0----2---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d2da6333edd0----2---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2da6333edd0----2---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2da6333edd0----2---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2da6333edd0----2---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d2da6333edd0----2-----------------bookmark_preview----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://faun.pub/step-by-step-guide-to-dockerize-a-node-js-express-application-cb6be4159cf1?source=author_recirc-----d2da6333edd0----3---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=author_recirc-----d2da6333edd0----3---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=author_recirc-----d2da6333edd0----3---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Roland Hewage"}, {"url": "https://faun.pub/?source=author_recirc-----d2da6333edd0----3---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "FAUN Publication"}, {"url": "https://faun.pub/step-by-step-guide-to-dockerize-a-node-js-express-application-cb6be4159cf1?source=author_recirc-----d2da6333edd0----3---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "Step by Step Guide to Dockerize a Node.js Express ApplicationI covered what Docker is in my \u201cWhat is Docker?\u201d blog. We also understood that the thing that eventually runs an application is called a\u2026"}, {"url": "https://faun.pub/step-by-step-guide-to-dockerize-a-node-js-express-application-cb6be4159cf1?source=author_recirc-----d2da6333edd0----3---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": "\u00b77 min read\u00b7Mar 24, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ffaun%2Fcb6be4159cf1&operation=register&redirect=https%3A%2F%2Ffaun.pub%2Fstep-by-step-guide-to-dockerize-a-node-js-express-application-cb6be4159cf1&user=Roland+Hewage&userId=710f77466d5e&source=-----cb6be4159cf1----3-----------------clap_footer----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://faun.pub/step-by-step-guide-to-dockerize-a-node-js-express-application-cb6be4159cf1?source=author_recirc-----d2da6333edd0----3---------------------07e411b3_5021_4fe5_bf23_f50a3682d80f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb6be4159cf1&operation=register&redirect=https%3A%2F%2Ffaun.pub%2Fstep-by-step-guide-to-dockerize-a-node-js-express-application-cb6be4159cf1&source=-----d2da6333edd0----3-----------------bookmark_preview----07e411b3_5021_4fe5_bf23_f50a3682d80f-------", "anchor_text": ""}, {"url": "https://rolyhewage.medium.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "See all from Roland Hewage"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----0-----------------clap_footer----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----d2da6333edd0----0-----------------bookmark_preview----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Conor O'Sullivan"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Augmenting Images for Deep LearningUsing Python to augment data by flipping, adjusting brightness, color jitter and random noise"}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "\u00b712 min read\u00b7Nov 17, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3f1ea92a891c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-images-for-deep-learning-3f1ea92a891c&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=-----3f1ea92a891c----1-----------------clap_footer----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f1ea92a891c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-images-for-deep-learning-3f1ea92a891c&source=-----d2da6333edd0----1-----------------bookmark_preview----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://kennethleungty.medium.com/?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://kennethleungty.medium.com/?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Kenneth Leung"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Practical Guide to Transfer Learning in TensorFlow for Multiclass Image ClassificationClearly-explained step-by-step tutorial for implementing transfer learning in image classification"}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "\u00b714 min read\u00b7Dec 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd35fab7b28c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0&user=Kenneth+Leung&userId=dcd08e36f2d0&source=-----d35fab7b28c0----0-----------------clap_footer----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----d2da6333edd0----0---------------------71842e25_0173_414c_b05b_450c75606635-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd35fab7b28c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0&source=-----d2da6333edd0----0-----------------bookmark_preview----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/object-detection-with-yolov7-a74fa1f03c7e?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://medium.com/@bert.gollnick?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://medium.com/@bert.gollnick?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Bert Gollnick"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/object-detection-with-yolov7-a74fa1f03c7e?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Create a Custom Object Detection Model with YOLOv7Train a model to detect face masks in real-time with the most powerful real-time algorithm YOLOv7"}, {"url": "https://medium.com/mlearning-ai/object-detection-with-yolov7-a74fa1f03c7e?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "\u00b75 min read\u00b7Dec 10, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Fa74fa1f03c7e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fobject-detection-with-yolov7-a74fa1f03c7e&user=Bert+Gollnick&userId=b6cf6dd84a57&source=-----a74fa1f03c7e----1-----------------clap_footer----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/object-detection-with-yolov7-a74fa1f03c7e?source=read_next_recirc-----d2da6333edd0----1---------------------71842e25_0173_414c_b05b_450c75606635-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa74fa1f03c7e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fobject-detection-with-yolov7-a74fa1f03c7e&source=-----d2da6333edd0----1-----------------bookmark_preview----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d2da6333edd0----2---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d2da6333edd0----2---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d2da6333edd0----2---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----d2da6333edd0----2---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d2da6333edd0----2---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d2da6333edd0----2---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----2-----------------clap_footer----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d2da6333edd0----2---------------------71842e25_0173_414c_b05b_450c75606635-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----d2da6333edd0----2-----------------bookmark_preview----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d2da6333edd0----3---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----d2da6333edd0----3---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----d2da6333edd0----3---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d2da6333edd0----3---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d2da6333edd0----3---------------------71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----3-----------------clap_footer----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d2da6333edd0----3---------------------71842e25_0173_414c_b05b_450c75606635-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----d2da6333edd0----3-----------------bookmark_preview----71842e25_0173_414c_b05b_450c75606635-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----d2da6333edd0--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}