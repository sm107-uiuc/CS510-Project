{"url": "https://towardsdatascience.com/the-chime-6-challenge-review-15f3cbf0062d", "time": 1683012356.9749272, "path": "towardsdatascience.com/the-chime-6-challenge-review-15f3cbf0062d/", "webpage": {"metadata": {"title": "The CHIME-6 Challenge Review. Let\u2019s discuss the highlights of the\u2026 | by Dmitry Obukhov | Towards Data Science", "h1": "The CHIME-6 Challenge Review", "description": "Not so long ago, there was a challenge for speech separation and recognition called CHIME-6. CHIME competitions have been held since 2011. The main distinguishing feature of these competitions is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://chimechallenge.github.io/chime6/index.html", "anchor_text": "CHIME-6", "paragraph_index": 0}, {"url": "https://chimechallenge.github.io/chime6/track1_software.html", "anchor_text": "software baselines", "paragraph_index": 3}, {"url": "https://chimechallenge.github.io/chime6/index.html", "anchor_text": "GitHub page", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/2004.09249.pdf", "anchor_text": "the overview", "paragraph_index": 4}, {"url": "http://www.kaldi-asr.org/", "anchor_text": "Kaldi", "paragraph_index": 10}, {"url": "https://chimechallenge.github.io/chime6/results.html#TOP", "anchor_text": "GitHub", "paragraph_index": 13}, {"url": "https://groups.uni-paderborn.de/nt/pubs/2018/INTERSPEECH_2019_Boeddeker_Slides.pdf", "anchor_text": "Guided Source Separation", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/2004.09249.pdf", "anchor_text": "officially referred", "paragraph_index": 16}, {"url": "https://arxiv.org/pdf/1905.12230.pdf", "anchor_text": "paper", "paragraph_index": 21}, {"url": "https://arxiv.org/pdf/1905.12230.pdfhttps://groups.uni-paderborn.de/nt/pubs/2018/INTERSPEECH_2019_Boeddeker_Slides.pdf", "anchor_text": "slides", "paragraph_index": 21}, {"url": "https://chimechallenge.github.io/chime2020-workshop/abstracts/CHiME_2020_abstract_du.pdf", "anchor_text": "paper", "paragraph_index": 24}, {"url": "https://chimechallenge.github.io/chime2020-workshop/abstracts/CHiME_2020_abstract_arora.pdf", "anchor_text": "paper", "paragraph_index": 29}, {"url": "https://arxiv.org/pdf/2002.06033.pdf", "anchor_text": "paper", "paragraph_index": 32}, {"url": "https://arxiv.org/pdf/2003.02405.pdf", "anchor_text": "paper", "paragraph_index": 36}, {"url": "https://arxiv.org/abs/2005.07272", "anchor_text": "TS-VAD model", "paragraph_index": 42}, {"url": "http://Dasha.AI", "anchor_text": "Dasha.AI", "paragraph_index": 45}], "all_paragraphs": ["Not so long ago, there was a challenge for speech separation and recognition called CHIME-6. CHIME competitions have been held since 2011. The main distinguishing feature of these competitions is that conversational speech recorded in everyday home environments on several devices simultaneously is used to train and evaluate participants\u2019 solutions.", "The data provided for the competition was recorded during the \u201chome parties\u201d of the four participants. These parties were recorded on 32 channels at the same time (six four-channel Microsoft Kinects in the room + two-channel microphones on each of the four speakers).", "There were 20 parties, all of them lasting 2\u20133 hours. The organizers have chosen some of them for testing:", "By the way, it was the same dataset that had been used in the previous CHIME-5 challenge. However, the organizers prepared several techniques to improve data quality (see the description of software baselines on GitHub, sections \u201cArray synchronization\u201d and \u201cSpeech enhancement\u201d).", "To find out more about the competition and data preparation here, visit its GitHub page or read the overview on Arxiv.org.", "This year there were two tracks:", "Track 1 \u2014 multiple-array speech recognition;Track 2 \u2014 multiple-array diarization and recognition.", "And for each track, there were two separate ranking categories:", "Ranking A \u2014 systems based on conventional acoustic modeling and official language modeling;", "Ranking B \u2014 all other systems, including systems based on the end-to-end ASR baseline or systems whose lexicon and/or language model have been modified.", "The organizers provided a baseline for participation, which includes a pipeline based on the Kaldi speech recognition toolkit.", "The main criterion for evaluating participants was the speech recognition metric \u2014 word error rate (WER). For the second track, two additional metrics were used \u2014 diarization error rate (DER) and Jaccard error rate (JER), which allow to evaluate the quality of the diarization task:", "In the tables below, you can see the competition results:", "You can access the links to the papers on GitHub.", "Here are a few curious things I\u2019d like to discuss about the challenge: don\u2019t want you to miss anything!", "In the previous CHiME-5 challenge, the Paderborn University team, who ranked 4th in Track 2, focused on a speech enhancement technique called Guided Source Separation (GSS). The results of the CHiME-5 competition have demonstrated that the technique improves other solutions.", "This year, the organizers officially referred to GSS in the sound improvement section and included this technique in the baseline of the first track.", "That is why many participants, including all the front runners, used GSS or a similar modification inspired by this idea.", "Here is how it works: you need to construct a Spatial Mixture Model (SMM), which allows to determine time-frequency masks for speakers (i.e., on what frequencies and at what time a given speaker was speaking). Training is performed using the EM algorithm with temporary annotations of speakers as initialization.", "Then, this block is integrated into the general speech enhancement pipeline. This pipeline includes the dereverberation technique (i.e., removing the echo effect from a signal, which occurs when sound is reflected from the walls) and beamforming (i.e., generating a single signal from several audio tracks).", "Since there were no speaker annotations for the second track, speech recognition alignments (time stamps of spoken phrases) were used to initialize the EM algorithm for training SMM.", "You can read more about the technique and its implementation results in the Hitachi and Paderborn University team\u2019s paper on Arxiv or take a look at their slides.", "The USTC team, who ranked 1st in Track 1 and 3rd in Track 2, improved the solution they presented at the CHIME-5 challenge. This is the same team that won the CHIME-5 contest. However, other participants did not use the techniques described in their solution.", "Inspired by the idea of GSS, USTC implemented its modification of the speech enhancement algorithm \u2014 IBF-SS.", "You can find out more in their paper.", "There were several evident weaknesses in the baseline that the organizers did not bother to hide: for example, using only one audio channel to build diarization or the lack of rescoring by the language model for ranking B. In baseline scripts, you can also find tips for improvement (for example, to add augmentation with noise from the CHIME-6 data to build x-vectors).", "The JHU team solution completely eliminates all these weaknesses: there no brand new super efficient techniques, but the participants went over all the problem areas of the baseline. In Track 2, they ranked 2nd.", "They explored multi-array processing techniques at each stage of the pipeline, such as multi-array GSS for enhancement, posterior fusion for speech activity detection, PLDA score fusion for diarization, and lattice combination for ASR. The GSS technique was described above. A good enough fusion technique, according to the JHU research, is simple max function.", "Besides, they integrated techniques such as online multi-channel WPE dereverberation and VB-HMM based overlap assignment to deal with challenges like background noise and overlapping speakers, respectively.", "More detailed description of the JHU solution can be found in their paper.", "I\u2018d like to highlight a few tricks that were used by the winners of the second track of the competition, the ITMO (STC) team:", "X-Vector is a speaker embedding, i.e a vector that contains speaker information. Such vectors are used in speaker recognition tasks. WRN x-vectors is an improvement of x-vectors through using the ResNet architecture and some other tricks. It has reduced DER so much that this technique alone would have been enough for the team to win the competition.", "You can read more about WRN x-vectors in the paper by the ITMO team.", "By default, the Kaldi diarization pipeline includes extracting x-vectors from audio, calculating PLDA scores and clustering audio using agglomerative hierarchical clustering (AHC).", "Now look at the PLDA component that used to build distances between speaker vectors. PLDA has a mathematical justification in calculating distances for I-Vectors. Put simply, it relies on the fact that I-Vectors contain information about the speaker and the channel, and when clustering, the only important thing for us is the speaker information. It also works nicely for X-Vectors.", "However, using cosine similarity instead of PLDA scores and spectral clustering with automatic selection of a threshold instead of AHC allowed the ITMO team to make another significant improvement in diarization.", "To find out more about spectral clustering with automatic selection of the binarization threshold, read this paper on Arxiv.org.", "The authors focus specifically on this technique in their work. TS-VAD is a novel approach that predicts an activity of each speaker on each time frame. The TS-VAD model uses acoustic features (e.g., MFCC) along with i-vectors for each speaker as inputs. Two versions of TS-VAD are provided: single-channel and multi-channel. The architecture of this model is presented below.", "Note that this network is tailored for dialogs of four participants, which is actually stipulated by the requirements of this challenge.", "The single-channel TS-VAD model was designed to predict speech probabilities for all speakers simultaneously. This model with four output layers was trained using a sum of binary cross-entropies as a loss function. Authors also found that it is essential to process each speaker by the same Speaker Detection (SD) 2-layer BLSTMP, and then combine SD outputs for all speakers by one more BLSTMP layer.", "The single-channel version of TS-VAD processes each channel separately. To process separate Kinect channels jointly, authors investigated the multi-channel TS-VAD model, which uses a combination of SD blocks outputs of the single TS-VAD model as an input. All the SD vectors for each speaker are passed through a 1-d convolutional layer and then combined by means of a simple attention mechanism. Combined outputs of attention for all speakers are passed through a single BLSTM layer and converted into a set of perframe probabilities of each speaker\u2019s presence/absence.", "Finally, to improve overall diarization performance, the ITMO team fused several single-channel and multi-channel TS-VAD models by computing a weighted average of their probability streams.", "You can learn more about the TS-VAD model on Arxiv.org.", "I hope this review has helped you get a better understanding of the CHiME-6 challenge. Maybe you\u2019ll find the tips and tricks I mentioned useful if you decide to take part in the upcoming contests. Feel free to reach out in case I missed something!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Researcher @ Dasha.AI, a voice-first conversational platform. I specialize in speech technologies."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F15f3cbf0062d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dmitry.obukhov_ML?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dmitry.obukhov_ML?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "Dmitry Obukhov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a0c11528869&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&user=Dmitry+Obukhov&userId=1a0c11528869&source=post_page-1a0c11528869----15f3cbf0062d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F15f3cbf0062d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F15f3cbf0062d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@allecgomes?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Allec Gomes"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://chimechallenge.github.io/chime6/index.html", "anchor_text": "CHIME-6"}, {"url": "https://chimechallenge.github.io/chime6/track1_software.html", "anchor_text": "software baselines"}, {"url": "https://chimechallenge.github.io/chime6/index.html", "anchor_text": "GitHub page"}, {"url": "https://arxiv.org/pdf/2004.09249.pdf", "anchor_text": "the overview"}, {"url": "http://www.kaldi-asr.org/", "anchor_text": "Kaldi"}, {"url": "https://chimechallenge.github.io/chime6/results.html#TOP", "anchor_text": "GitHub"}, {"url": "https://groups.uni-paderborn.de/nt/pubs/2018/INTERSPEECH_2019_Boeddeker_Slides.pdf", "anchor_text": "Guided Source Separation"}, {"url": "https://arxiv.org/pdf/2004.09249.pdf", "anchor_text": "officially referred"}, {"url": "https://arxiv.org/pdf/1905.12230.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1905.12230.pdfhttps://groups.uni-paderborn.de/nt/pubs/2018/INTERSPEECH_2019_Boeddeker_Slides.pdf", "anchor_text": "slides"}, {"url": "https://chimechallenge.github.io/chime2020-workshop/abstracts/CHiME_2020_abstract_du.pdf", "anchor_text": "paper"}, {"url": "https://chimechallenge.github.io/chime2020-workshop/abstracts/CHiME_2020_abstract_arora.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/2002.06033.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/2003.02405.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/abs/2005.07272", "anchor_text": "TS-VAD model"}, {"url": "https://medium.com/tag/speech-recognition?source=post_page-----15f3cbf0062d---------------speech_recognition-----------------", "anchor_text": "Speech Recognition"}, {"url": "https://medium.com/tag/chime?source=post_page-----15f3cbf0062d---------------chime-----------------", "anchor_text": "Chime"}, {"url": "https://medium.com/tag/speaker-diarization?source=post_page-----15f3cbf0062d---------------speaker_diarization-----------------", "anchor_text": "Speaker Diarization"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----15f3cbf0062d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----15f3cbf0062d---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F15f3cbf0062d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&user=Dmitry+Obukhov&userId=1a0c11528869&source=-----15f3cbf0062d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F15f3cbf0062d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&user=Dmitry+Obukhov&userId=1a0c11528869&source=-----15f3cbf0062d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F15f3cbf0062d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F15f3cbf0062d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----15f3cbf0062d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----15f3cbf0062d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dmitry.obukhov_ML?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dmitry.obukhov_ML?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dmitry Obukhov"}, {"url": "https://medium.com/@dmitry.obukhov_ML/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "47 Followers"}, {"url": "http://Dasha.AI", "anchor_text": "Dasha.AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a0c11528869&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&user=Dmitry+Obukhov&userId=1a0c11528869&source=post_page-1a0c11528869--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4bd982059919&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-chime-6-challenge-review-15f3cbf0062d&newsletterV3=1a0c11528869&newsletterV3Id=4bd982059919&user=Dmitry+Obukhov&userId=1a0c11528869&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}