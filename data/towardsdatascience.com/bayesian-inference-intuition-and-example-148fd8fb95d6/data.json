{"url": "https://towardsdatascience.com/bayesian-inference-intuition-and-example-148fd8fb95d6", "time": 1683002499.705451, "path": "towardsdatascience.com/bayesian-inference-intuition-and-example-148fd8fb95d6/", "webpage": {"metadata": {"title": "Bayesian Inference \u2014 Intuition and Example | by Ms Aerin | Towards Data Science", "h1": "Bayesian Inference \u2014 Intuition and Example", "description": "The core of Bayesian Inference is to combine two different distributions (likelihood and prior) into one \u201csmarter\u201d distribution (posterior). Posterior is \u201csmarter\u201d in the sense that the classic\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation", "anchor_text": "Maximum A Posteriori (MAP)", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/beta-distribution-intuition-examples-and-derivation-cf00f4db57af", "anchor_text": "Beta distribution", "paragraph_index": 18}, {"url": "https://towardsdatascience.com/pdf-is-not-a-probability-5a4b8a5d9531", "anchor_text": "Probability Density is NOT a probability.", "paragraph_index": 25}, {"url": "https://towardsdatascience.com/difference-between-batch-gradient-descent-and-stochastic-gradient-descent-1187f1291aa1", "anchor_text": "the Gradient Descent", "paragraph_index": 43}, {"url": "https://towardsdatascience.com/pdf-is-not-a-probability-5a4b8a5d9531", "anchor_text": "Read \u201cPDF is NOT a probability, while PMF IS a probability\u201d.", "paragraph_index": 44}, {"url": "https://automata88.medium.com/subscribe", "anchor_text": "https://automata88.medium.com/subscribe", "paragraph_index": 50}], "all_paragraphs": ["In one sentence: to update the probability as we gather more data.", "The core of Bayesian Inference is to combine two different distributions (likelihood and prior) into one \u201csmarter\u201d distribution (posterior). Posterior is \u201csmarter\u201d in the sense that the classic maximum likelihood estimation (MLE) doesn\u2019t take into account a prior. Once we calculate the posterior, we use it to find the \u201cbest\u201d parameters and the \u201cbest\u201d is in terms of maximizing the posterior probability, given the data. This process is called Maximum A Posteriori (MAP). The optimization used in MAP is the same as the one used in typical machine learning, such as gradient descent or Newton\u2019s method, etc.", "When I look at the famous Bayes rule, understanding the equation analytically is pretty easy. But how would you implement it with the data?", "Specifically, we will have a large number of data points X. How do we multiply the probability wrt X with the probability wrt \u03b8?", "Apparently, the art of Bayesian Inference lies in how you implement it.", "I have about 2,000 readers per day visiting my Medium blog. Some people clap after reading articles and some don\u2019t. I\u2019d like to make predictions about what percentage of people will engage and clap when I write a new blog post in the future.", "This kind of problem is widely applicable. Try to apply this to your own modeling work \u2014 the Click-Through Rate of an advertisement, the conversion rate of customers actually purchasing on your website, the percentage of people who would agree to go on a date with you, the survival chance for women with breast cancer, etc.", "Let\u2019s generate the data X. In real life, you don\u2019t have any control over X. This is what you are going to observe.", "The clapping data is binary. 1 indicates a clap and 0 means no clap.", "Step 1. [Prior] Choose a PDF to model your parameter \u03b8, aka the prior distribution P(\u03b8). This is your best guess about parameters before seeing the data X.", "Step 2. [Likelihood] Choose a PDF for P(X|\u03b8). Basically you are modeling how the data X will look like given the parameter \u03b8.", "Step 3. [Posterior] Calculate the posterior distribution P(\u03b8|X) and pick the \u03b8 that has the highest P(\u03b8|X).", "And the posterior becomes the new prior. Repeat step 3 as you get more data.", "The first step is to choose the PDF to model the parameter \u03b8.", "What does the parameter \u03b8 represent?", "Then, what kind of probability distributions should we use to model a probability?", "To represent a probability, there are a few conditions to meet. First, the domain should be ranged from 0 to 1. Second, it should be a continuous distribution.", "Then there are two well-known probability distributions that I can think of:", "Dirichlet is for multivariate and Beta is for univariate. We have only one thing to predict, which is a probability, so let\u2019s use the Beta distribution.", "(An interesting side note: It\u2019s easy to create an arbitrary distribution over (0,1). Just take any function that doesn\u2019t blow up anywhere between 0 and 1 and stays positive. Then, simply integrate it from 0 to 1 and divide the function with that result.)", "To use a Beta distribution, there are two parameters, \u03b1 & \u03b2, that we need to decide. You can think of \u03b1 as How many people clap (the number of successes) and \u03b2 as how many people don\u2019t clap (the number of failures). These parameters \u2014 how big or small \u03b1 & \u03b2 are \u2014 will determine the shape of the distribution.", "Let\u2019s say you have data from yesterday and observed 400 people clapped out of total 2,000 visitors.", "How would you write this in terms of the beta distribution?", "Let\u2019s plot the prior distribution with respect to all \u03b8 values.", "It spikes at 20% (400 claps / 2000 readers) as expected. Two thousand data points seem to produce a strong prior. If we use fewer datapoints, say, 100 readers, the curve will be much less spiky. Try it with \u03b1 = 20 & \u03b2 = 80.", "For those who are wondering how probability density can be greater than 1. \ud83d\udc49Probability Density is NOT a probability.", "Choose a probability model for P(X|\u03b8), the probability of seeing the data X given a particular parameter \u03b8. Likelihood is also called a sampling distribution. To me, the term \u201csampling distribution\u201d is much more intuitive than \u201clikelihood\u201d.", "To choose which probability distribution to use to model the sampling distribution, we need to first ask:", "What does our data X look like?", "We also have the total number of visitors (n) and we want the probability of clap (p).", "Ok, n & p\u2026 What do they scream to you?", "Binomial distribution with n & p.", "Is our prior assumption \u03b8 highly likely?", "Let\u2019s see the graph of P(X|\u03b8) for all possible \u03b8.", "Finally, let\u2019s answer the question we asked in the beginning:", "Specifically, we will have a large number of data points X. How do we multiply the probability wrt X with the probability wrt \u03b8?", "Even though there are thousands of data points, we can convert them into a single scalar \u2014 the likelihood P(X|\u03b8) \u2014 by plugging data into the model that you chose (in this example, the binomial distribution.)", "Then, we calculate P(\u03b8) & P(X|\u03b8) for a specific \u03b8 and multiply them together. If you do this for every possible \u03b8, you can pick the highest P(\u03b8) * P(X|\u03b8) among different \u03b8\u2019s.", "Your initial guess about parameters was P(\u03b8). Now you are upgrading a simple P(\u03b8) into something more informative \u2014 P(\u03b8|X) \u2014 as more data become available. P(\u03b8|X) is still the probability of \u03b8, just like P(\u03b8) is. However, P(\u03b8|X) is a smarter version of P(\u03b8).", "The code is worth a thousand words:", "When you look at the posterior graph (the 3rd one), notice it is where the likelihood shifted toward the prior. The clapping probability for the prior was 20%. The clapping probability for the data was given as 30%. Now, the posterior has its peak around 0.25%.", "Also, notice the width of the bell curves in prior/likelihood has shrunk in the posterior. Because we incorporated more information through sampling, the range of possible parameters is now narrower.", "The more data you gather, the graph of the posterior will look more like that of the likelihood and less like that of the prior. In other words, as you get more data, the original prior distribution matters less.", "Finally, we pick \u03b8 that gives the highest posterior computed by numerical optimization, such as the Gradient Descent or newton method. This whole iterative procedure is called Maximum A Posteriori estimation (MAP).", "Footnote: We calculated the prior by subtracting two stats.beta.cdf instead of using stats.beta.pdf because the likelihood stats.binom.pmf is a probability while stats.beta.pdf returns a density. Even if we use the density to calculate the posterior, it won\u2019t change the optimization result. However, if you want the units to match, converting a density into a probability is necessary. (Still not clear? Read \u201cPDF is NOT a probability, while PMF IS a probability\u201d.)", "Nope. You can still find the maximum without normalizing. However, if you want to compare posteriors from different models, or calculate the point estimates, you need to normalize it.", "4. MAP estimation can be seen as a regularized ML by incorporating more information through the prior.", "5. Are you familiar with maximum likelihood estimation (MLE), but not quite with maximum a posteriori (MAP)? MLE is just a special case of MAP with a uniform prior.", "6. I wrote \u201cPrior is your best guess about parameters *before* seeing the data\u201d, however, in practice, once we calculate the posterior, the posterior becomes the new prior until the new batch of data comes in. This way, we can iteratively update our prior and posterior. Markov Chain Monte Carlo sampling methods are based on this idea.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Engineer. Love teaching math concepts intuitively. Support my math writing: https://automata88.medium.com/subscribe"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F148fd8fb95d6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://automata88.medium.com/?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": ""}, {"url": "https://automata88.medium.com/?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "Ms Aerin"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d8994ad0efc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&user=Ms+Aerin&userId=1d8994ad0efc&source=post_page-1d8994ad0efc----148fd8fb95d6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F148fd8fb95d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F148fd8fb95d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation", "anchor_text": "Maximum A Posteriori (MAP)"}, {"url": "https://towardsdatascience.com/beta-distribution-intuition-examples-and-derivation-cf00f4db57af", "anchor_text": "Beta distribution"}, {"url": "https://towardsdatascience.com/pdf-is-not-a-probability-5a4b8a5d9531", "anchor_text": "Read \u201cPDF is NOT a probability\u201d"}, {"url": "https://towardsdatascience.com/pdf-is-not-a-probability-5a4b8a5d9531", "anchor_text": "Probability Density is NOT a probability."}, {"url": "https://towardsdatascience.com/difference-between-batch-gradient-descent-and-stochastic-gradient-descent-1187f1291aa1", "anchor_text": "the Gradient Descent"}, {"url": "https://towardsdatascience.com/pdf-is-not-a-probability-5a4b8a5d9531", "anchor_text": "Read \u201cPDF is NOT a probability, while PMF IS a probability\u201d."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----148fd8fb95d6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----148fd8fb95d6---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----148fd8fb95d6---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----148fd8fb95d6---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----148fd8fb95d6---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F148fd8fb95d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&user=Ms+Aerin&userId=1d8994ad0efc&source=-----148fd8fb95d6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F148fd8fb95d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&user=Ms+Aerin&userId=1d8994ad0efc&source=-----148fd8fb95d6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F148fd8fb95d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F148fd8fb95d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----148fd8fb95d6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----148fd8fb95d6--------------------------------", "anchor_text": ""}, {"url": "https://automata88.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://automata88.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ms Aerin"}, {"url": "https://automata88.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.98K Followers"}, {"url": "https://automata88.medium.com/subscribe", "anchor_text": "https://automata88.medium.com/subscribe"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d8994ad0efc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&user=Ms+Aerin&userId=1d8994ad0efc&source=post_page-1d8994ad0efc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3956b2925abd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-intuition-and-example-148fd8fb95d6&newsletterV3=1d8994ad0efc&newsletterV3Id=3956b2925abd&user=Ms+Aerin&userId=1d8994ad0efc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}