{"url": "https://towardsdatascience.com/the-complete-guide-to-decision-trees-17a874301448", "time": 1682997414.29698, "path": "towardsdatascience.com/the-complete-guide-to-decision-trees-17a874301448/", "webpage": {"metadata": {"title": "The Complete Guide to Decision Trees | by Marco Peixeiro | Towards Data Science", "h1": "The Complete Guide to Decision Trees", "description": "Tree-based methods can be used for regression or classification. They involve segmenting the prediction space into a number of simple regions. The set of splitting rules can be summarized in a tree\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/linear-regression-understanding-the-theory-7e53ac2831b5", "anchor_text": "linear regression", "paragraph_index": 1}, {"url": "https://becominghuman.ai/classification-part-1-intro-to-logistic-regression-f6258791d309", "anchor_text": "logistic regression", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/classification-part-2-linear-discriminant-analysis-ea60c45b9ee5", "anchor_text": "LDA", "paragraph_index": 1}, {"url": "https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber", "anchor_text": "YouTube channel", "paragraph_index": 3}, {"url": "https://github.com/marcopeix/ISL-Decision-Trees", "anchor_text": "here", "paragraph_index": 35}, {"url": "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra", "anchor_text": "here", "paragraph_index": 36}], "all_paragraphs": ["Tree-based methods can be used for regression or classification. They involve segmenting the prediction space into a number of simple regions. The set of splitting rules can be summarized in a tree, hence the name decision tree methods.", "A single decision tree is often not as performant as linear regression, logistic regression, LDA, etc. However, by introducing bagging, random forests, and boosting, it can result in dramatic improvements in prediction accuracy at the expense of some loss in interpretation.", "In this post, we introduce everything you need to know about decision trees, bagging, random forests, and boosting. It will be a long read, but it will be worth it!", "For hands-on video tutorials on machine learning, deep learning, and artificial intelligence, checkout my YouTube channel.", "Before getting to the theory, we need some basic terminology.", "Trees are drawn upside down. The final regions are termed leaves. The points inside the tree where a split occurs is an interval node. Finally, segments that connect nodes are branches.", "Each region is split to minimize the RSS. To do so, it takes a top-down greedy approach also called recursive binary splitting.", "Because all observations are in a single region before the first split.", "Because the best split occurs at a particular step, rather than looking ahead and making a split that will result in a better prediction in a future step.", "Mathematically, we define the pair of half-planes as:", "and we seek j and s to minimize:", "However, this may lead to overfitting. Pruning the tree will result in a smaller subtree that we can validate with cross-validation.", "A classification tree is very similar to a regression tree. However, we cannot use the mean value of the response, so we now predict the most commonly occurring class in a region. Of course, RSS cannot be used as a criterion. Instead, each split is done to minimize the classification error rate.", "The classification error rate is simply the fraction of training observations in a region that do not belong to the most common class.", "Unfortunately, this is not sensitive enough for tree-growing. In practice, two other methods are used.", "This is a measure of total variance across all classes. As you can see, the Gini index will be small if the proportion is close to 0 or 1, so it is a good measure of node purity.", "A similar rationale is applied to the other method called cross-entropy:", "Now that we have seen how a basic decision tree works, let\u2019s see how we can improve its performance!", "We know that bootstrap can compute the standard deviation of any quantity of interest. For decision trees, the variance is very high. Therefore, with bootstrap aggregation or bagging, we can reduce the variance and increase the performance of a decision tree.", "Bagging involves repeatedly taking samples from a dataset. This generates B different bootstrap training sets. Then, we train on all bootstrapped training sets to get a prediction for each set, and we average the predictions.", "Applying this to decision trees, it means that that we can construct a high number of trees which will have high variance and low bias. Then, we can average their predictions to reduce the variance to improve the performance of the decision trees.", "Random forests provide an improvement over bagged trees by way of a small tweak that decorrelates the trees.", "Like in bagging, multiple decision trees are built. However, at each split, a random sample of m predictors is chosen from all p predictors. The split is allowed to use only one of the m predictors, and typically:", "In other words, at each split, the algorithm is not allowed to consider a majority of the available predictors!", "Suppose that there is one very strong predictor in the dataset, along with other moderately strong predictors. Then, in the collection of bagged trees, they will all use this strong predictor in the top split. Consequently, all of the bagged trees will be very similar, and averaging their predictions will not reduce variance, since the predictions would be highly correlated.", "Random forests overcome this problem by forcing each split to only consider a subset of predictors which effectively decorrelates the trees.", "Of course, if m is equal to p, then it is just like bagging. Usually, the square root of p gives the best results as shown below.", "Boosting works in a similar way to bagging, but the trees are grown sequentially: each tree uses information from the previously grown trees.", "This means that the algorithm learns slowly. Each tree is fit to the residuals from the model rather than to the target variable. Hence, each tree is small and will slowly improve predictions in areas where it does not perform well.", "There are three tuning parameters in boosting:", "1. number of tree (B): unlike bagging and random forests, boosting can overfit if B is too large. Use cross-validation to choose the right amount of trees.", "2. shrinkage parameter (alpha): a small positive number that controls the learning rate of boosting. It is typically set to 0.01 or 0.001.", "3. number of splits in each tree (d): it controls the complexity of the boosted ensemble. Usually, a single split (d = 1) works well. It is also called the interaction depth.", "As you can see above, an interaction depth of 1 seems to give the best results.", "Now, let\u2019s apply what we have learned to predict breast cancer. Many datasets about breast cancer contain information about the tumor. However, I was lucky to find a dataset that contains routine blood tests information of patients with and without breast cancer. Potentially, if we can accurately predict if a patient has cancer, that patient could receive very early treatments, even before a tumor is noticeable!", "Of course, the dataset and full notebook are available here, and I strongly suggest that you code along.", "Before starting our work on Jupyter, we can gain information about the dataset here.", "First, you notice that the dataset is very small, with only 116 instances. This poses several challenges, because the decision trees might overfit the data, or our predictive model might not be the best, due to the lack of other observations. Yet, it is a good proof-of-concept that might demonstrate a real potential of predicting breast cancer from a simple blood test.", "The dataset contains only the following ten attributes:", "1. Age: age of the patient (years)", "3. Glucose: glucose concentration in blood (mg/dL)", "4. Insulin: insulin concentration in blood (microU/mL)", "5. HOMA: Homeostatic Model Assessment of Insulin Resistance (glucose multiplied by insulin)", "6. Leptin: concentration of leptin \u2014 the hormone of energy expenditure (ng/mL)", "7. Adiponectin: concentration of adiponectin \u2014 a protein regulating glucose levels (micro g/mL)", "8. Resistin: concentration of resistin \u2014 a protein secreted by adipose tissue (ng/mL)", "9. MCP.1: concentration of MCP-1 \u2014 a protein that recruits monocytes to the sites of inflammation due to tissue injury or inflammation (pg/dL)", "Now that we know what we will be working with, we can start by importing our usual libraries:", "Then, define the path to the dataset and let\u2019s preview it:", "Great! Now, because this is a classification problem, let\u2019s see if the classes are balanced:", "As you can see, there is almost the same number of patients and healthy controls.", "Now, it would be interesting to see the distribution and density of each feature for healthy people and patients. To do so, a violin plot is ideal. It shows both the density and distribution of a feature in a single plot. Let\u2019s have nine violin plots: one for each feature:", "Take time to review all the plots and try to find some differences between healthy controls and patients.", "Finally, let\u2019s check if we have missing values:", "You should see that none of the columns have missing values! We are now ready to start modelling!", "First, we need to encode the classes to 0 and 1:", "Now, 0 represents a healthy control, and 1 represents a patient.", "Then, we split the dataset into a training and test set:", "Before writing our models, we need to define the appropriate error metric. In this case, since it is a classification problem, we could use a confusion matrix and use the classification error. Let\u2019s write a helper function to plot the confusion matrix:", "Awesome! Now, let\u2019s implement a decision tree.", "Using scikit-learn, a decision tree is implemented very easily:", "You should get the following confusion matrix:", "As you can see, it misclassified three instances. Therefore, let\u2019s see if bagging, boosting or random forest can improve the performance of the tree.", "To implement a decision tree with bagging, we write the following:", "And you get the following confusion matrix:", "Amazing! The model classified correctly all instances in the test set! For the sake of getting more practice, let\u2019s also implement a random forest classifier and use boosting.", "Here, for the random forest classifier, we specify the number of trees we want. Let\u2019s go with 100:", "And you get this confusion matrix:", "Here, although only one instance was misclassified, the model in fact said that a patient was healthy, when in fact the person had cancer! This is a very undesirable situation.", "Again, only one instance was misclassified.", "This article covered a lot! You learned the underlying theory of tree-based methods, you learned how we can improve their performance and we implemented each algorithm in a project setting.", "I hope you found this article useful and that you will use it in a future project.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior data scientist | Author | Instructor. I write hands-on articles with a focus on practical skills."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F17a874301448&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----17a874301448--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----17a874301448--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@marcopeixeiro?source=post_page-----17a874301448--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=post_page-----17a874301448--------------------------------", "anchor_text": "Marco Peixeiro"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd----17a874301448---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F17a874301448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F17a874301448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/linear-regression-understanding-the-theory-7e53ac2831b5", "anchor_text": "linear regression"}, {"url": "https://becominghuman.ai/classification-part-1-intro-to-logistic-regression-f6258791d309", "anchor_text": "logistic regression"}, {"url": "https://towardsdatascience.com/classification-part-2-linear-discriminant-analysis-ea60c45b9ee5", "anchor_text": "LDA"}, {"url": "https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber", "anchor_text": "YouTube channel"}, {"url": "https://github.com/marcopeix/ISL-Decision-Trees", "anchor_text": "here"}, {"url": "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----17a874301448---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----17a874301448---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----17a874301448---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----17a874301448---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----17a874301448---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F17a874301448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----17a874301448---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F17a874301448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----17a874301448---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F17a874301448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----17a874301448--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F17a874301448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----17a874301448---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----17a874301448--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----17a874301448--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----17a874301448--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----17a874301448--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----17a874301448--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----17a874301448--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----17a874301448--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----17a874301448--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marco Peixeiro"}, {"url": "https://medium.com/@marcopeixeiro/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.6K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9835bccb3d51&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-decision-trees-17a874301448&newsletterV3=741c1c8fcfbd&newsletterV3Id=9835bccb3d51&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.manning.com/books/time-series-forecasting-in-python-book", "anchor_text": "Time Series Forecasting in Python2022"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}