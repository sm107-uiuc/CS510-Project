{"url": "https://towardsdatascience.com/active-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9", "time": 1683016706.990243, "path": "towardsdatascience.com/active-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9/", "webpage": {"metadata": {"title": "Active and Semi-Supervised machine learning: Oct 26 \u2014 Nov 13 | by Olga Petrova | Towards Data Science", "h1": "Active and Semi-Supervised machine learning: Oct 26 \u2014 Nov 13", "description": "One of my personal benefits from writing these bi-weekly newsletters is that it gives me a first-hand look at which research topics are gaining momentum \u2014 albeit, in academia (not to be confused with\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/tagged/active-learning-news", "anchor_text": "You can also find all of my Active Learning Newsletters to date here", "paragraph_index": 0}, {"url": "https://medium.com/scaleway-cloud/active-learning-part-1-the-theory-239b7a43ddb5?sk=8c9e99904ab4de20035f15a046948a54", "anchor_text": "Active Learning: the Theory", "paragraph_index": 1}, {"url": "https://medium.com/scaleway-cloud/active-learning-with-pytorch-dc6805956b0f?sk=fb5235fa27ac160c4056628da4f43b74", "anchor_text": "Active Learning with PyTorch", "paragraph_index": 1}, {"url": "http://snap.stanford.edu/grape/", "anchor_text": "open source their code", "paragraph_index": 9}, {"url": "https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf", "anchor_text": "GANs", "paragraph_index": 12}, {"url": "https://thispersondoesnotexist.com/", "anchor_text": "spookily realistic photos", "paragraph_index": 12}, {"url": "https://app.livestorm.co/scaleway-1/active-learning-ai-data-annotation-kairntech-experience", "anchor_text": "free webinar that I will be co-hosting with Kairntech", "paragraph_index": 16}, {"url": "http://www.olgapaints.net", "anchor_text": "www.olgapaints.net", "paragraph_index": 19}], "all_paragraphs": ["You can also find all of my Active Learning Newsletters to date here.", "One of my personal benefits from writing these bi-weekly newsletters is that it gives me a first-hand look at which research topics are gaining momentum \u2014 albeit, in academia (not to be confused with the industry, although the latter will likely catch up soon enough). The two subjects, that I am seeing more and more of, are graph-based machine learning and active learning. Since you are reading this newsletter, I presume that you don\u2019t need an introduction to active learning (but just in case you do, here are a couple of blog posts to get you started: Active Learning: the Theory and Active Learning with PyTorch). Graph-based machine learning is something that I have talked about in the previous issues of the newsletter, but let me repeat my mini-summary here for your convenience:", "Think of each datapoint that you have as a node of a graph. Let\u2019s say each node corresponds to a person\u2019s Facebook profile. We will draw edges between (i.e. connect) those nodes, that are friends with each other on Facebook. The nodes can, but do not have to, have features (e.g. the person\u2019s age, gender, self-described political views, and whether they own a cat). Now let\u2019s say you want to figure out whether a given person is likely to support the idea of a covid-imposed lockdown, or not. A binary classification task, in other words. (You can label those nodes that have explicitly voiced their lockdown support or disdain in their profile, and train off them.) If you did not want to do any of that fancy graph stuff, you could simply train a classifier with the features that your training data has. However, you hypothesize that a person who is friends with lots of lockdown-supporters is more likely to share those views than the person whose Facebook friend circle is decidedly against the stay-at-home orders. If only we could include this kind of relational information in our modeling\u2026 Wait, we actually can: as long as we use the graph (nodes + their connections to other nodes) instead of just nodes as an input to our model. This might sound strange, but in a way, you have already been doing it. Think of image classification, for instance: a 1024 x 1024 image can be thought of as a grid \u2014 a very boring graph, that happens to have a fixed size and the same topology everywhere except for the image boundary. Each node (pixel) has a set number of features (that define the pixel\u2019s color). Generalizing the familiar ML notions from a grid to a graph of arbitrary complexity is non-trivial, but can be done.", "Let\u2019s get back to what is new on the arXiv. You know how uncertainty sampling (prioritizing the data instances that the model is least sure about) has a tendency to pick up the outliers from the dataset? (This is why in practice you would normally want to query labels for the data that got assigned medium, rather than lowest, confidence scores by the model!) Now, in a non-graph-related setting, these lowest-confidence instances are outliers in feature space. Once we start dealing with graphs though, there is additional information added to the mix \u2014 namely, the structure of the graph, i.e how different nodes are connected. Roughly speaking, the fewer the connections, the less relational information we have about a given node. It follows that the uncertainty sampling approach will be biased to prioritize the sparsely-connected nodes. Just like outliers in the feature space, nodes with few connections are not, generally, the most useful ones for our purposes.", "To address this and other issues, the authors of Deep Active Graph Representation Learning use a combination of uncertainty sampling and a representativeness-based query strategy:", "Representativeness basically means prioritizing data instances that are representative of the data distribution. In practice, this comes down to two criteria: the degree of a node (i.e. the number of its nearest neighbours, with the higher degree nodes getting higher rankings to be queried) and the node\u2019s purity. Here purity refers to minimizing the number of noisy (erroneous) edges, and is estimated by the ratio of nearest neighbours belonging to the same class as the center node.", "A very cool way to apply graphs to a common problem of incomplete data is discussed in Handling Missing Data with Graph Representation Learning:", "Let us say you have some training samples (aka observations): O1, O2, and O3. Each of these can be assigned to one of two classes, y1 or y2. (In our example below, O3 is unlabelled.) These samples live in a four-dimensional space \u2014 meaning, they are described by four features, F1, F2, F3, and F4. If you look at the table on the upper left of the figure below, you will see that some observations are missing values for certain features.", "The first thing we do is that we say that our three observations are nodes (pretty standard), and so are our four features (not so standard). Note: not the values that features have for a given node, but the actual features. We then connect all the observation nodes to all the feature nodes. This creates a bipartite graph \u2014 bipartite just means that there are two kinds of nodes (e.g. O and F), and all nearest neighbours of O nodes are F nodes, and vice versa. We assign the value that observation Oi has for feature Fj to the <ij> edge that connects these two nodes (why not).", "The feature imputation task can now be formulated at the edge level of the graph. The downstream label prediction (the task that we ultimately care about) then follows at the observation node level. The authors argue that this way of dealing with missing data is superior to the common imputation methods, and, importantly, open source their code.", "Automatic speech recognition (ASR, also known as speech-to-text) is a technology that many of us make use of semi-regularly \u2014 namely, whenever we feel like talking to Google assistant, Siri or Alexa. Training fully supervised deep ASR models requires manually transcribing large quantities of audio data, an error-prone and expensive process. On the other hand, unannotated audio files are abundant, making this domain a prime candidate for semi-supervised machine learning. Promising results have been achieved with self-training \u2014 a relatively simple bootstrapping approach where a model is trained on labelled data, then the model\u2019s high confidence predictions are [pseudo-]labelled automatically, and the model is re-trained. What if we decided to keep multiple predictions for each unlabelled audio sequence that we pseudo-label? Indeed, the authors of Semi-Supervised Speech Recognition via Graph-based Temporal Classification show that this approach works better than the self-training baseline:", "Here is a practical one: some of your labellers are good (and expensive), while others are weak (but cheap). See how you can keep the model\u2019s performance at an acceptable level while combining the two in a cost-effective way:", "Remember GANs? The Discriminator + Generator duo that is capable of generating spookily realistic photos? Conditional GANs are a variation that generates data with, well, conditions. This could be a class label, fed as input in addition to the noise vector that one would use for a vanilla unsupervised GAN. It could also be something more interesting, like a semantic map:", "Semantic maps are a pricy kind of data annotation to carry out. Fortunately, the creators of S2cGAN managed to get away with as few as 5 (yes, five!) labeled map-photo pairs and 29K unpaired images, by training their GAN in a semi-supervised manner:", "I like the title of the next preprint: To BERT or Not to BERT, that is the question. This question arises because while training a contextual embedding like BERT on unsupervised (or rather, self-supervised) language modeling works great for many a downstream task, it is incredibly expensive computationally. Not to mention the environmental cost! \ud83d\ude31 Can we achieve similar performance via semi-supervised learning if we use the unlabelled data in a task-specific (as in, specific to the downstream task), rather than a task-agnostic (generic language modeling pre-training) way? Yes, we can!", "On the other hand, train BERT once, and you\u2019ll always have a trained BERT, whereas a task-specific model has to be trained for, well, every specific task. Still, a good result to know!", "On a more interactive note, I would like to invite you to a free webinar that I will be co-hosting with Kairntech, a french NLP startup, on December 17th (17h30 CET). We will start with a beginner-friendly introduction to active learning, and talk about how Kairntech uses it for real-world NLP data annotation use cases.", "See you back here with the next dose of the latest active learning research in a couple of weeks!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Former quantum physicist & current techie who also creates art with stories behind it. Based in Paris, France. \ud83c\udf10 www.olgapaints.net"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F35f11a03e6c9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@OlgaPaints?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@OlgaPaints?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "Olga Petrova"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3ec417445414&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&user=Olga+Petrova&userId=3ec417445414&source=post_page-3ec417445414----35f11a03e6c9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35f11a03e6c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35f11a03e6c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/active-learning-news", "anchor_text": "Active Learning Newsletter"}, {"url": "https://towardsdatascience.com/active-and-semi-supervised-machine-learning-oct-12-23-6bfe5470253d", "anchor_text": "Active and Semi-Supervised machine learning: Oct 12\u201323A selection of the latest arXiv preprints concerning active (and occasionally semi- or weakly-supervised) deep learningtowardsdatascience.com"}, {"url": "https://towardsdatascience.com/tagged/active-learning-news", "anchor_text": "You can also find all of my Active Learning Newsletters to date here"}, {"url": "https://unsplash.com/@jmuniz?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Joel Muniz"}, {"url": "https://unsplash.com/s/photos/reading?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://medium.com/scaleway-cloud/active-learning-part-1-the-theory-239b7a43ddb5?sk=8c9e99904ab4de20035f15a046948a54", "anchor_text": "Active Learning: the Theory"}, {"url": "https://medium.com/scaleway-cloud/active-learning-with-pytorch-dc6805956b0f?sk=fb5235fa27ac160c4056628da4f43b74", "anchor_text": "Active Learning with PyTorch"}, {"url": "https://arxiv.org/abs/2010.16091", "anchor_text": "Deep Active Graph Representation LearningGraph neural networks (GNNs) aim to learn graph representations that preserve both attributive and structural\u2026arxiv.org"}, {"url": "https://arxiv.org/abs/2010.16418", "anchor_text": "Handling Missing Data with Graph Representation LearningMachine learning with missing data has been approached in two different ways, including feature imputation where\u2026arxiv.org"}, {"url": "https://arxiv.org/abs/2010.16418", "anchor_text": "https://arxiv.org/abs/2010.16418"}, {"url": "http://snap.stanford.edu/grape/", "anchor_text": "open source their code"}, {"url": "https://arxiv.org/abs/2010.15653", "anchor_text": "Semi-Supervised Speech Recognition via Graph-based Temporal ClassificationSemi-supervised learning has demonstrated promising results in automatic speech recognition (ASR) by self-training\u2026arxiv.org"}, {"url": "https://arxiv.org/abs/2010.14149", "anchor_text": "Active Learning for Noisy Data Streams Using Weak and Strong LabelersLabeling data correctly is an expensive and challenging task in machine learning, especially for on-line data streams\u2026arxiv.org"}, {"url": "https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf", "anchor_text": "GANs"}, {"url": "https://thispersondoesnotexist.com/", "anchor_text": "spookily realistic photos"}, {"url": "https://arxiv.org/abs/2010.12622", "anchor_text": "https://arxiv.org/abs/2010.12622"}, {"url": "https://arxiv.org/abs/2010.12622", "anchor_text": "S2cGAN: Semi-Supervised Training of Conditional GANs with Fewer LabelsGenerative adversarial networks (GANs) have been remarkably successful in learning complex high dimensional real word\u2026arxiv.org"}, {"url": "https://giphy.com/gifs/obama-barack-obama-election-night-2008-l0ErOholJjSmFlMFG", "anchor_text": "NBC News via giphy.com"}, {"url": "https://arxiv.org/abs/2010.14042", "anchor_text": "To BERT or Not to BERT: Comparing Task-specific and Task-agnostic Semi-Supervised Approaches for\u2026Leveraging large amounts of unlabeled data using Transformer-like architectures, like BERT, has gained popularity in\u2026arxiv.org"}, {"url": "https://app.livestorm.co/scaleway-1/active-learning-ai-data-annotation-kairntech-experience", "anchor_text": "free webinar that I will be co-hosting with Kairntech"}, {"url": "https://medium.com/tag/ai?source=post_page-----35f11a03e6c9---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----35f11a03e6c9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----35f11a03e6c9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----35f11a03e6c9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/active-learning-news?source=post_page-----35f11a03e6c9---------------active_learning_news-----------------", "anchor_text": "Active Learning News"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35f11a03e6c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&user=Olga+Petrova&userId=3ec417445414&source=-----35f11a03e6c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35f11a03e6c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&user=Olga+Petrova&userId=3ec417445414&source=-----35f11a03e6c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35f11a03e6c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F35f11a03e6c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----35f11a03e6c9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----35f11a03e6c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@OlgaPaints?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@OlgaPaints?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Olga Petrova"}, {"url": "https://medium.com/@OlgaPaints/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "104 Followers"}, {"url": "http://www.olgapaints.net", "anchor_text": "www.olgapaints.net"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3ec417445414&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&user=Olga+Petrova&userId=3ec417445414&source=post_page-3ec417445414--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F21863272452a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Factive-and-semi-supervised-machine-learning-oct-26-nov-13-35f11a03e6c9&newsletterV3=3ec417445414&newsletterV3Id=21863272452a&user=Olga+Petrova&userId=3ec417445414&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}