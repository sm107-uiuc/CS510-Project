{"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02", "time": 1682997211.001827, "path": "towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02/", "webpage": {"metadata": {"title": "All about Categorical Variable Encoding | by Baijayanta Roy | Towards Data Science", "h1": "All about Categorical Variable Encoding", "description": "Most of the Machine learning algorithms can not handle categorical variables unless we convert them to numerical values. Many algorithm\u2019s performances vary based on how Categorical variables are\u2026"}, "outgoing_paragraph_urls": [{"url": "https://baijayanta.medium.com/membership", "anchor_text": "https://baijayanta.medium.com/membership", "paragraph_index": 65}], "all_paragraphs": ["Most of the Machine learning algorithms can not handle categorical variables unless we convert them to numerical values. Many algorithm\u2019s performances vary based on how Categorical variables are encoded.", "Categorical variables can be divided into two categories: Nominal (No particular order) and Ordinal (some ordered).", "Few examples as below for the Nominal variable:", "There are many ways we can encode these categorical variables as numbers and use them in an algorithm. I will cover most of them, from basic to more advanced ones, in this post. I will be comprising these encoding:", "1) One Hot Encoding2) Label Encoding3) Ordinal Encoding4) Helmert Encoding5) Binary Encoding6) Frequency Encoding7) Mean Encoding8) Weight of Evidence Encoding9) Probability Ratio Encoding10) Hashing Encoding11) Backward Difference Encoding12) Leave One Out Encoding13) James-Stein Encoding14) M-estimator Encoding (updated)", "For explanation, I will use this data frame, which has two independent variables or features(Temperature and Color) and one label (Target). It also has Rec-No, which is a sequence number of the record. There is a total of 10 records in this data frame. Python code would look as below.", "We will use Pandas and Scikit-learn and category_encoders (Scikit-learn contribution library) to show different encoding methods in Python.", "In this method, we map each category to a vector that contains 1 and 0, denoting the presence or absence of the feature. The number of vectors depends on the number of categories for features. This method produces many columns that slow down the learning significantly if the number of the category is very high for the feature. Pandas has get_dummies function, which is quite easy to use. The sample data-frame code would be as below:", "Scikit-learn has OneHotEncoder for this purpose, but it does not create an additional feature column (another code is needed, as shown in the below code sample).", "One Hot Encoding is very popular. We can represent all categories by N-1 (N= No of Category) as sufficient to encode the one that is not included. Usually, for Regression, we use N-1 (drop first or last column of One Hot Coded new feature ). Still, for classification, the recommendation is to use all N columns without as most of the tree-based algorithm builds a tree based on all available variables. One hot encoding with N-1 binary variables should be used in linear Regression to ensure the correct number of degrees of freedom (N-1). The linear Regression has access to all of the features as it is being trained and therefore examines the whole set of dummy variables altogether. This means that N-1 binary variables give complete information about (represent completely) the original categorical variable to the linear Regression. This approach can be adopted for any machine learning algorithm that looks at ALL the features simultaneously during training\u2014for example, support vector machines and neural networks as well as clustering algorithms.", "We will never consider that additional label in tree-based methods if we drop. Thus, if we use the categorical variables in a tree-based learning algorithm, it is good practice to encode it into N binary variables and don\u2019t drop.", "In this encoding, each category is assigned a value from 1 through N (where N is the number of categories for the feature. One major issue with this approach is there is no relation or order between these classes, but the algorithm might consider them as some order or some relationship. In below example it may look like (Cold<Hot<Very Hot<Warm\u2026.0 < 1 < 2 < 3 ) .Scikit-learn code for the data-frame as follows:", "Pandas factorize also perform the same function.", "We do Ordinal encoding to ensure the encoding of variables retains the ordinal nature of the variable. This is reasonable only for ordinal variables, as I mentioned at the beginning of this article. This encoding looks almost similar to Label Encoding but slightly different as Label coding would not consider whether the variable is ordinal or not, and it will assign a sequence of integers", "If we consider the temperature scale as the order, then the ordinal value should from cold to \u201cVery Hot. \u201c Ordinal encoding will assign values as ( Cold(1) <Warm(2)<Hot(3)<\u201dVery Hot(4)). Usually, Ordinal Encoding is done starting from 1.", "Refer to this code using Pandas, where first, we need to assign the original order of the variable through a dictionary. Then we can map each row for the variable as per the dictionary.", "Though it\u2019s very straightforward, it requires coding to tell ordinal values and the actual mapping from text to an integer as per the order.", "In this encoding, the mean of the dependent variable for a level is compared to the mean of the dependent variable over all previous levels.", "The version in category_encoders is sometimes referred to as Reverse Helmert Coding. The mean of the dependent variable for a level is compared to the mean of the dependent variable over all previous levels. Hence, the name \u2018reverse\u2019 is used to differentiate from forward Helmert coding.", "Binary encoding converts a category into binary digits. Each binary digit creates one feature column. If there are n unique categories, then binary encoding results in the only log(base 2)\u207f features. In this example, we have four features; thus, the binary encoded features will be three features. Compared to One Hot Encoding, this will require fewer feature columns (for 100 categories, One Hot Encoding will have 100 features, while for Binary encoding, we will need just seven features).", "For Binary encoding, one has to follow the following steps:", "Refer to the below diagram for better intuition.", "We will use the category_encoders package for this, and the function name is BinaryEncoder.", "It is a way to utilize the frequency of the categories as labels. In the cases where the frequency is related somewhat to the target variable, it helps the model understand and assign the weight in direct and inverse proportion, depending on the nature of the data. Three-step for this :", "Pandas code can be constructed as below:", "Mean Encoding or Target Encoding is one viral encoding approach followed by Kagglers. There are many variations of this. Here I will cover the basic version and smoothing version. Mean encoding is similar to label encoding, except here labels are correlated directly with the target. For example, in mean target encoding for each category in the feature label is decided with the mean value of the target variable on training data. This encoding method brings out the relation between similar categories, but the connections are bounded within the categories and target itself. The advantages of the mean target encoding are that it does not affect the volume of the data and helps in faster learning. Usually, Mean encoding is notorious for over-fitting; thus, a regularization with cross-validation or some other approach is a must on most occasions. Mean encoding approach is as below:", "2. Group by the categorical variable and obtain aggregated sum over the \u201cTarget\u201d variable. (total number of 1\u2019s for each category in \u2018Temperature\u2019)", "3. Group by the categorical variable and obtain aggregated count over \u201cTarget\u201d variable", "4. Divide the step 2 / step 3 results and join it back with the train.", "Sample code for the data frame:", "Mean encoding can embody the target in the label, whereas label encoding does not correlate with the target. In the case of many features, mean encoding could prove to be a much simpler alternative. Mean encoding tends to group the classes, whereas the grouping is random in label encoding.", "There are many variations of this target encoding in practice, like smoothing. Smoothing can implement as below:", "Weight of Evidence (WoE) measures the \u201cstrength\u201d of a grouping technique to separate good and bad. This method was developed primarily to build a predictive model to evaluate the risk of loan default in the credit and financial industry. Weight of evidence (WOE) measures how much the evidence supports or undermines a hypothesis.", "WoE will be 0 if the P(Goods) / P(Bads) = 1. That is, if the outcome is random for that group. If P(Bads) > P(Goods) the odds ratio will be < 1 and the WoE will be < 0; if, on the other hand, P(Goods) > P(Bads) in a group, then WoE > 0.", "WoE is well suited for Logistic Regression because the Logit transformation is simply the log of the odds, i.e., ln(P(Goods)/P(Bads)). Therefore, by using WoE-coded predictors in Logistic Regression, the predictors are prepared and coded to the same scale. The parameters in the linear logistic regression equation can be directly compared.", "The WoE transformation has (at least) three advantage:1) It can transform an independent variable to establish a monotonic relationship to the dependent variable. It does more than this \u2014 to secure a monotonic relationship it would be enough to \u201crecode\u201d it to any ordered measure (for example 1,2,3,4\u2026), but the WoE transformation orders the categories on a \u201clogistic\u201d scale which is natural for Logistic Regression2) For variables with too many (sparsely populated) discrete values, these can be grouped into categories (densely populated), and the WoE can be used to express information for the whole category3) The (univariate) effect of each category on the dependent variable can be compared across categories and variables because WoE is a standardized value (for example, you can compare WoE of married people to WoE of manual workers)", "It also has (at least) three drawbacks: 1) Loss of information (variation) due to binning to a few categories 2) It is a \u201cunivariate\u201d measure, so it does not take into account the correlation between independent variables 3) It is easy to manipulate (over-fit) the effect of variables according to how categories are created", "Below code, snippets explain how one can build code to calculate WoE.", "Once we calculate WoE for each group, we can map back this to Data-frame.", "Probability Ratio Encoding is similar to Weight Of Evidence(WoE), with the only difference is the only ratio of good and bad probability is used. For each label, we calculate the mean of target=1, that is, the probability of being 1 ( P(1) ), and also the probability of the target=0 ( P(0) ). And then, we calculate the ratio P(1)/P(0) and replace the labels with that ratio. We need to add a minimal value with P(0) to avoid any divide-by-zero scenarios where for any particular category, there is no target=0.", "Hashing converts categorical variables to a higher dimensional space of integers, where the distance between two vectors of categorical variables is approximately maintained by the transformed numerical dimensional space. With Hashing, the number of dimensions will be far less than the number of dimensions with encoding like One Hot Encoding. This method is advantageous when the cardinality of categorical is very high.", "This encoding is widely used where in production when a category changes very frequently say in the case of an e-commerce site product category keeps on changing as new products are added at regular intervals.", "(Sample Code \u2014 I Will update in a future version of this article)", "In backward difference coding, the mean of the dependent variable for a level is compared with the mean of the dependent variable for the prior level. This type of coding may be useful for a nominal or an ordinal variable.", "This technique falls under the contrast coding system for categorical features. A feature of K categories, or levels, usually enters a regression as a sequence of K-1 dummy variables.", "(Sample Code \u2014 Will be updated in a future version of this article)", "This is very similar to target encoding but excludes the current row\u2019s target when calculating the mean target for a level to reduce outliers.", "(Sample Code \u2014 Will be updated in a future version of this article)", "For feature value, the James-Stein estimator returns a weighted average of:", "The James-Stein encoder shrinks the average toward the overall average. It is a target-based encoder. James-Stein estimator has, however, one practical limitation \u2014 it was defined only for normal distributions.", "(Sample Code \u2014 I Will update in a future version of this article)", "M-estimator encoding can be used in categorical encoding as a way to handle outliers or rare categories in a dataset. In this context, it can be used as a way to handle a class imbalance in a categorical variable. The idea is to assign a weight to each category based on its deviation from the overall class frequency. This weight is then used to adjust the encoding of the categorical variable, giving more importance to under-represented categories.", "For example, suppose you have a categorical variable with 3 categories A, B, and C, and you want to encode it using one-hot encoding. The standard one-hot encoding will assign the same weight to each category. However, if category A is significantly under-represented compared to B and C, you should give it more weight in the encoding. In this case, you can use M-estimator encoding, which assigns weights to each category based on a weight function chosen to address the class imbalance.", "It is worth noting that M-estimator encoding is just one of the many methods that can be used to handle a class imbalance in categorical variables, and it may not be the best method in every situation. Whether or not to use it, and how to use it, depends on the specific problem and dataset you are working with.", "In this example, the weight variable is the weight assigned to each category based on the deviation from the mean frequency. The encoded_temperature variable is the weighted encoding of the Temperature category, calculated as the sum of the weights for each category and normalized to sum 1.", "Thermometer Encoder is used to represent categorical variables as numerical values, specifically for ordinal variables where the categories have an inherent order.", "The encoding works by creating a binary representation of each category and concatenating the binary values to form a new numerical variable. The number of binary digits used in the representation depends on the number of categories. For each category, the first digit is set to 1 if the category is present, and the rest of the digits are set to 0.", "For example, if there are 5 categories A, B, C, D, and E, a thermometer encoding could be represented as 5 binary variables:", "This encoding represents the order of the categories in a more intuitive way than one-hot encoding and captures the inherent relationship between categories. It can be useful in scenarios where the model needs to understand the ordinal relationship between categories. Let\u2019s use our color category to explain this with the Pandas code.", "I received many queries related to using or how one can treat the test data when there is no target. I am adding a Faq section here, which I hope would assist.", "Faq 01: Which method should I use?", "Answer: There is no single method that works for every problem or dataset. You may have to try a few to see, which gives a better result. The general guideline is to refer to the cheat sheet shown at the end of the article.", "Faq 02: How do I create categorical encoding for a situation like a target encoding as, in test data, there won\u2019t be any target value?", "Answer: We need to use the mapping values created at the time of training. This process is the same as scaling or normalization, where we use the train data to scale or normalize the test data. Then map and use the same value in testing time pre-processing. We can even create a dictionary for each category and mapped the value and then use the dictionary at testing time. Here I am using the mean encoding to explain this.", "It is essential to understand that all these encodings do not work well in all situations or for every dataset for all machine learning models. Data Scientists still need to experiment and find out which works best for their specific case. If test data has different classes, some of these methods won\u2019t work as features won\u2019t be similar. There are few benchmark publications by research communities, but it\u2019s not conclusive which works best. My recommendation will be to try each of these with the smaller datasets and then decide where to focus on tuning the encoding process. You can use the below cheat-sheet as a guiding tool.", "For only $5/month, get unlimited access to the most inspiring and uplifting content\u2026 Click on the link below to become a Medium member and support my writing. Thank you!https://baijayanta.medium.com/membership", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science | Machine Learning | Deep Learning | Artificial Intelligence | Quantum Computing"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F305f3361fd02&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----305f3361fd02--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----305f3361fd02--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://baijayanta.medium.com/?source=post_page-----305f3361fd02--------------------------------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=post_page-----305f3361fd02--------------------------------", "anchor_text": "Baijayanta Roy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F583a83b12a79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&user=Baijayanta+Roy&userId=583a83b12a79&source=post_page-583a83b12a79----305f3361fd02---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://blog.featurelabs.com/encode-smarter/", "anchor_text": "Source"}, {"url": "http://www.linkedin.com/in/baijayantaroy", "anchor_text": "LinkedIn"}, {"url": "https://baijayanta.medium.com/membership", "anchor_text": "https://baijayanta.medium.com/membership"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----305f3361fd02---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----305f3361fd02---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----305f3361fd02---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/programming?source=post_page-----305f3361fd02---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data?source=post_page-----305f3361fd02---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&user=Baijayanta+Roy&userId=583a83b12a79&source=-----305f3361fd02---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&user=Baijayanta+Roy&userId=583a83b12a79&source=-----305f3361fd02---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----305f3361fd02--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----305f3361fd02---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----305f3361fd02--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----305f3361fd02--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----305f3361fd02--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----305f3361fd02--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----305f3361fd02--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----305f3361fd02--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----305f3361fd02--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----305f3361fd02--------------------------------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Baijayanta Roy"}, {"url": "https://baijayanta.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.3K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F583a83b12a79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&user=Baijayanta+Roy&userId=583a83b12a79&source=post_page-583a83b12a79--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff205a028dace&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&newsletterV3=583a83b12a79&newsletterV3Id=f205a028dace&user=Baijayanta+Roy&userId=583a83b12a79&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}