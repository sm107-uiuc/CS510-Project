{"url": "https://towardsdatascience.com/which-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88", "time": 1683003651.760938, "path": "towardsdatascience.com/which-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88/", "webpage": {"metadata": {"title": "Which bin do I need to put out? Scraping websites with Python and Selenium | by Phil Gorman | Towards Data Science", "h1": "Which bin do I need to put out? Scraping websites with Python and Selenium", "description": "In a previous post, I demonstrated an example of scraping the Hansard website for information. This was a relatively simple example, as Hansard serves up all the data the webpage provides as soon as\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/scraping-hansard-with-python-and-beautifulsoup-f2887f0bc937", "anchor_text": "a previous post", "paragraph_index": 0}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "anchor_text": "BeautifulSoup", "paragraph_index": 0}, {"url": "https://selenium.dev/", "anchor_text": "Selenium", "paragraph_index": 2}, {"url": "https://chromedriver.chromium.org/downloads", "anchor_text": "which can be found here", "paragraph_index": 5}], "all_paragraphs": ["In a previous post, I demonstrated an example of scraping the Hansard website for information. This was a relatively simple example, as Hansard serves up all the data the webpage provides as soon as the page is loaded. All the text that can appear on the page, whether immediately served up in paragraphs, or hidden and only revealed when a button is pressed \u2014 all of it is already there in the page source, ready to be picked up by a package like BeautifulSoup.", "In the example I\u2019m about to show you, the data we need is not readily available in the page\u2019s source code. It is loaded dynamically on the server-side, once I have inputted some information into a form. In this case, we cannot just use BeautifulSoup (BS4), as there is nothing there for BS4 to scrape. We need to interact with the page in some way first, before the information appears for us to scrape.", "This is where Selenium comes into play. Selenium is a Python package that automates actions in a browser. Selenium will open up a browser window, can navigate to a website, click on elements on the page and enter text into input elements. It can even interact with elements on a page in iframes, something which BeautifulSoup also struggles with. We can use Selenium to execute actions on a webpage, making new information appear on that page and then scrape that new information.", "For this example, I will find the most vital of all information \u2014 which bin needs to be put out on a given week. We alternate between general waste and recycling in my town and I forget which one I need to put out every single week. I also completely lose track when there\u2019s a bank holiday.", "These are the packages I used", "I also had to download a webdriver. This is an executable file for either Firefox or Google Chrome, that Selenium can access and open. Selenium uses the webdriver as the browser to control. I downloaded Google Chrome\u2019s webdriver, which can be found here.", "In the code above, I pass Selenium the file location for the webdriver, so it can open up a browser window. I then pass it the URL of the website I want to access \u2014 in this case a horrendous URL for my council\u2019s webpage for bin collections.", "As you can see from the image above, we have a page with a form field, asking for my address or postcode. Selenium is able to click elements on a page and enter text into input fields.", "I hit a snag with scraping this page using Selenium and it confused me for a while \u2014 I was selecting the id of the element I wanted to interact with, but I was getting an error saying it couldn\u2019t be found. This is because the form on the page is not part of the page itself, it is embedded as an iframe. Thankfully, Selenium can interact with embedded iframes using the \u201cswitch_to.frame()\u201d function.", "Now I have the right frame of the page selected, I need to click the text box and type in my address.", "I first create a variable to hold my address, as I\u2019ll need to use it again later. Then I use the Selenium function \u201cfind_element_by_id\u201d to find the text input box on the page, and click on it to put the cursor in the box. After that I use \u201cfind_element_by_id\u201d again, but then rather than using click, I use \u201csend_keys\u201d to type the address inside that box.", "Having gone through the process of looking up my bin day manually beforehand, I know that once a valid address is in the box, the address picker dropdown box appears automatically, so I don\u2019t need to click or interact with the page any more at this point. However, I do need to tell the script to wait for a few seconds whilst the dropdown box loads.", "Once the dropdown box has loaded, I need to select the address from the list. There are only two items in this dropdown \u2014 the address I want to select and the default \u201cSelect\u2026\u201d value. Not helpful for web scraping, but easy enough to work around.", "First I assign the dropdown box list a variable name, addresslist. I then use a for loop to look at the text of each option in the list and find out if it starts with the text of the address I typed in the box above (\u201c22 Burch Road\u201d). I use startswith because the addresses in the dropdown list also have the town and county following the road name. If the address is found, Selenium selects the address using the \u201cclick()\u201d command.", "I then use another wait period, this time even longer, because the bin collection tables take a long time to load.", "We finally have our results loaded, so now we can scrape this table to pull out the days of the week and which bins go out on those days.", "I find the element id of the table, then print the text of that element to the terminal.", "In future posts, I will show how to output this type of information, scraped from a website, into emails or Telegram messages, but for now, I will leave it here.", "This is a very simple example of how Selenium can be used, but it could easily be extended to scraping multiple pages, scraping pages that require multiple clicks through to the information you need or getting information out of pages made up of multiple iframes.", "As always, if you think there is a way this could have been better executed, please let me know in the comments. I\u2019m still learning, so any feedback is welcome.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Librarian and data enthusiast. I like helping people find what they're looking for on and off the internet."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc59738cdb88&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c59738cdb88--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c59738cdb88--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@philbgorman?source=post_page-----c59738cdb88--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@philbgorman?source=post_page-----c59738cdb88--------------------------------", "anchor_text": "Phil Gorman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb66f4963edea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&user=Phil+Gorman&userId=b66f4963edea&source=post_page-b66f4963edea----c59738cdb88---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc59738cdb88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc59738cdb88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/scraping-hansard-with-python-and-beautifulsoup-f2887f0bc937", "anchor_text": "a previous post"}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "anchor_text": "BeautifulSoup"}, {"url": "https://selenium.dev/", "anchor_text": "Selenium"}, {"url": "https://chromedriver.chromium.org/downloads", "anchor_text": "which can be found here"}, {"url": "https://my.gravesham.gov.uk/en/AchieveForms/?form_uri=sandbox-publish://AF-Process-22218d5c-c6d6-492f-b627-c713771126be/AF-Stage-905e87c1-144b-4a72-8932-5518ddd3e618/definition.json&redirectlink=%2Fen&cancelRedirectLink=%2Fen&consentMessage=yes#_ga=2.209993814.256753923.1580820371-471535357.1579531399'", "anchor_text": "https://my.gravesham.gov.uk/en/AchieveForms/?form_uri=sandbox-publish://AF-Process-22218d5c-c6d6-492f-b627-c713771126be/AF-Stage-905e87c1-144b-4a72-8932-5518ddd3e618/definition.json&redirectlink=%2Fen&cancelRedirectLink=%2Fen&consentMessage=yes#_ga=2.209993814.256753923.1580820371-471535357.1579531399'"}, {"url": "https://medium.com/tag/programming?source=post_page-----c59738cdb88---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/python?source=post_page-----c59738cdb88---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/selenium?source=post_page-----c59738cdb88---------------selenium-----------------", "anchor_text": "Selenium"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c59738cdb88---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----c59738cdb88---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc59738cdb88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&user=Phil+Gorman&userId=b66f4963edea&source=-----c59738cdb88---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc59738cdb88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&user=Phil+Gorman&userId=b66f4963edea&source=-----c59738cdb88---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc59738cdb88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c59738cdb88--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc59738cdb88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c59738cdb88---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c59738cdb88--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c59738cdb88--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c59738cdb88--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c59738cdb88--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c59738cdb88--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c59738cdb88--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c59738cdb88--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c59738cdb88--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@philbgorman?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@philbgorman?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Phil Gorman"}, {"url": "https://medium.com/@philbgorman/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "117 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb66f4963edea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&user=Phil+Gorman&userId=b66f4963edea&source=post_page-b66f4963edea--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff4c8b1b7708c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-bin-do-i-need-to-put-out-scraping-websites-with-python-and-selenium-c59738cdb88&newsletterV3=b66f4963edea&newsletterV3Id=f4c8b1b7708c&user=Phil+Gorman&userId=b66f4963edea&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}