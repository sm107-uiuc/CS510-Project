{"url": "https://towardsdatascience.com/common-practices-part-4-70c08fce3588", "time": 1683010942.8347552, "path": "towardsdatascience.com/common-practices-part-4-70c08fce3588/", "webpage": {"metadata": {"title": "Common Practices \u2014 Part 4. Performance Evaluation | by Andreas Maier | Towards Data Science", "h1": "Common Practices \u2014 Part 4", "description": "In this blog post, we discuss how to evaluate models for two and multi-class problems. We also look into statistical testing and significance."}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/common-practices-part-3-f4853b0ac977", "anchor_text": "Previous Lecture", "paragraph_index": 1}, {"url": "https://youtu.be/lua5KI8fpAo", "anchor_text": "Watch this Video", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258", "anchor_text": "Top Level", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/architectures-part-1-62c686f500c3", "anchor_text": "Next Lecture", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "anchor_text": "receiver operating characteristic (ROC) curves", "paragraph_index": 4}, {"url": "https://medium.com/@akmaier", "anchor_text": "more essays here", "paragraph_index": 11}, {"url": "https://lme.tf.fau.de/teaching/free-deep-learning-resources/", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Deep", "paragraph_index": 11}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Learning", "paragraph_index": 11}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Lecture", "paragraph_index": 11}, {"url": "https://www.youtube.com/c/AndreasMaierTV", "anchor_text": "YouTube", "paragraph_index": 11}, {"url": "https://twitter.com/maier_ak", "anchor_text": "Twitter", "paragraph_index": 11}, {"url": "https://www.facebook.com/andreas.maier.31337", "anchor_text": "Facebook", "paragraph_index": 11}, {"url": "https://www.linkedin.com/in/andreas-maier-a6870b1a6/", "anchor_text": "LinkedIn", "paragraph_index": 11}, {"url": "https://creativecommons.org/licenses/by/4.0/deed.de", "anchor_text": "Creative Commons 4.0 Attribution License", "paragraph_index": 11}], "all_paragraphs": ["These are the lecture notes for FAU\u2019s YouTube Lecture \u201cDeep Learning\u201d. This is a full transcript of the lecture video & matching slides. We hope, you enjoy this as much as the videos. Of course, this transcript was created with deep learning techniques largely automatically and only minor manual modifications were performed. If you spot mistakes, please let us know!", "Previous Lecture / Watch this Video / Top Level / Next Lecture", "Welcome everybody to the next part of deep learning! Today, we want to finish talking about common practices, and in particular, we want to have a look at the evaluation. Of course, we need to evaluate the performance of the models that we\u2019ve trained so far. Now, we have set up the training, set hyperparameters, and configured all of this. Now, we want to evaluate the generalization performance on previously unseen data. This means the test data and it\u2019s time to open the vault.", "Remember \u201cOf all things the measure is man\u201d. So, data is annotated and labeled by humans and during training, all labels are assumed to be correct. But of course, to err is human. This means we may have ambiguous data. The ideal situation that you actually want to have for your data is that it has been annotated by multiple human voters. Then you can take the mean or a majority vote. There\u2019s also a very nice paper by Stefan Steidl from 2005. It introduces an entropy-based measure that takes into account the confusions of human reference labelers. This is very useful in situations where you have unclear labels. In particular, in emotion recognition, this is a problem as also humans confuse sometimes classes like angry versus annoyed while they are not very likely to confuse \u201cangry\u201d versus \u201chappy\u201d as this is a very clear distinction. There are different degrees of happiness. Sometimes you\u2019re just a little bit happy. In these cases, it is really difficult to differentiate happy from neutral. This is also hard for humans. In prototypes, if you have for example actors playing, you get emotion recognition rates way over 90%. If you have real data emotion and if you have emotions as they occur in daily life, it\u2019s much harder to predict. This can then also be seen in the labels and in the distribution of the labels. If you have a prototype, all of the raters will agree that the observation is clearly this particular class. If you have nuances and not so clear emotions, you will see that also our raters will have a less peaked or even a uniform distribution over the labels because they also can\u2019t assess the specific sample. So, mistakes by the classifier are obviously less severe if the same class is also confused by humans. Exactly this is considered in Steidl\u2019s entropy-based measure.", "Now, if we look into performance measures, you want to take into account the typical classification measures. They are typically built around the false negatives, the true negatives, the true positives, and the false positives. From that for binary classification problems, you can then compute true and false positive rates. This typically then leads to numbers like the accuracy that is the number of true positives plus true negatives over the number of positives and negatives. Then, there is the precision or positive predictive value that is computed as the number of true positives over the number of true positives plus false positives. There\u2019s the so-called recall that is defined as the true positives over the true positives plus the false negatives. Specificity or true negative value is given as the true negatives over the true negatives plus the false positives. The F1 score is an intermediate way of mixing these measures. You have the true positive value times the true negative value divided over the sum of two positive and true negative value. I typically recommend the receiver operating characteristic (ROC) curves because all of the measures that you\u2019ve seen above, they are dependent on thresholds. If you have the ROC curves, you essentially evaluate your classifier for all different thresholds. This then gives you an analysis of how well it performs in different scenarios.", "Furthermore, there are performance measures in multi-class classification. These are adapted versions of the measures above. The top-K error is the probability of the true class label not being in the K estimates with the highest prediction score. Common realizations are the top-1 and top-5 error. ImageNet, for example, usually uses the top-5 error. If you really want to understand what\u2019s going on in multi-class classification, I recommend looking at confusion matrices. Confusion matrices are useful for let\u2019s say 10 to 15 classes. If you have a thousand classes, confusion matrices don\u2019t make any sense anymore. Still, you can gain a lot of understanding of what\u2019s happening if you look at confusion matrices in cases with fewer classes.", "Now, sometimes you have very few data. So, in these cases, you may want to choose cross-validation. In k-fold cross-validation, you split your data into k folds, and then you use k \u2014 1 folds as training data and test on Fold k. Then, you repeat it k times. This way, you have seen in the evaluation data all of the data but you trained on independent data because you held it out at the time of training. It\u2019s rather uncommon in deep learning because it implies very long training times. You have to repeat the entire training K times which is really hard if you train for like seven days. If you have sevenfold cross-validation, you know you can do the math, it will take really long. If you use it for hyperparameter estimation, you have to nest it. Don\u2019t perform cross-validation just on all of your data, select the hyperparameters, and then go ahead with the same data in testing. This will give you optimistic results. You should always make sure that if you select parameters you hold out the test data where you want to test on so there\u2019s techniques for nesting cross-validation into cross-validation but then it will also become computationally very expensive so that\u2019s even worse if you want to nest the cross-validation one thing that you have to keep in mind is that the variance of the results is typically underestimated because the training grants are not independent also pay attention that you may introduce additional bias by incorporating the architecture selection and hyperparameter selection so this should be done on different data and it\u2019s very difficult if you\u2019re working with cross-validation even without cross-validation training is a highly stochastic process therefore you may want to retrain your network multiple times with different initializations if you pick random initializations for example and then report the standard deviation just to make sure how well your training actually performs.", "Now, you want to compare different classifiers. The question is: \u201cIs my new method with 91.5% accuracy better than the state-of-the-art with 90.9%?\u201d Of course, training a system is a stochastic process. So, just comparing those two numbers will yield biased results. The actual question that you have to ask is: \u201cIs there a significant difference between the classifiers?\u201d This means that you need to run the training for each method multiple times. Only then you can, for example, use a t-test to see whether the distribution of the results is significantly different (see link section). The t-test compares two normally distributed data sets with equal variance. Then, you can determine that the means are significantly different with respect to a significance level \u03b1 which is the level of randomness. Quite frequently you find in literature like 5% or 1% significance level. So you have a significant difference if the chance of this observation being random is less than 5% or 1%.", "Now be careful if you train multiple models on the same data. If you ask the same data a couple of times, you actually have to correct your significance computation. This is called the Bonferroni correction. If we compare multiple classifiers, this will introduce multiple comparisons and then you have to correct for this. If you had n tests with significance level \u03b1, then the total risk is n times \u03b1. So, to reach the total significance level of \u03b1, the adjusted \u03b1\u2019 would be \u03b1 over n for each individual test. So, the more tests you run on the same data, the more you have to divide by. Of course, this assumes independence between the tests and it\u2019s a kind of pessimistic estimation of significance. But you want to be pessimistic in this case just to make sure that you are not reporting something that has been produced by chance. Just because you test often enough and your testing is a random process, there may be a very good result showing up just by chance. More accurate, but incredibly time-consuming would be permutation tests, and believe me, you probably want to go with the Bonferroni correction instead. Permuting everything will take even longer than the cross-validation approach that we\u2019ve seen previously.", "Okay so let\u2019s summarize what we\u2019ve seen before: You check your implementation before training, the gradient initialization, monitor the training process continuously, the training, the validation losses, the weights, and the activations. Stick to established architectures before reinventing the wheel. Experiment with little data and keep your evaluation data safe until the evaluation. Decay the learning rate over time. Do a random search, not a grid search for hyperparameters. Perform model ensembling for better performance, and when you check your comparison, of course, you want to go for significance tests to make sure that you are not reporting a random observation.", "So next time on deep learning, we actually want to look at the evolution of neural network architectures. So from deep networks to even deeper networks. We want to have a look at sparse and dense connections and we\u2019ll introduce a lot of common names, things you hear all over the place, LeNet, GoogLeNet, ResNet, and so on. So we will learn about many interesting state-of-the-art approaches in this next series of lecture videos. So, thank you very much for listening and see you in the next video!", "If you liked this post, you can find more essays here, more educational material on Machine Learning here, or have a look at our Deep LearningLecture. I would also appreciate a follow on YouTube, Twitter, Facebook, or LinkedIn in case you want to be informed about more essays, videos, and research in the future. This article is released under the Creative Commons 4.0 Attribution License and can be reprinted and modified if referenced.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I do research in Machine Learning. My positions include being Prof @FAU_Germany, President @DataDonors, and Board Member for Science & Technology @TimeMachineEU"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F70c08fce3588&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----70c08fce3588--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70c08fce3588--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://akmaier.medium.com/?source=post_page-----70c08fce3588--------------------------------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=post_page-----70c08fce3588--------------------------------", "anchor_text": "Andreas Maier"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1444918afee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&user=Andreas+Maier&userId=b1444918afee&source=post_page-b1444918afee----70c08fce3588---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70c08fce3588&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70c08fce3588&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/fau-lecture-notes", "anchor_text": "FAU LECTURE NOTES"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning"}, {"url": "https://towardsdatascience.com/common-practices-part-3-f4853b0ac977", "anchor_text": "Previous Lecture"}, {"url": "https://youtu.be/lua5KI8fpAo", "anchor_text": "Watch this Video"}, {"url": "https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258", "anchor_text": "Top Level"}, {"url": "https://towardsdatascience.com/architectures-part-1-62c686f500c3", "anchor_text": "Next Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "anchor_text": "receiver operating characteristic (ROC) curves"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://medium.com/@akmaier", "anchor_text": "more essays here"}, {"url": "https://lme.tf.fau.de/teaching/free-deep-learning-resources/", "anchor_text": "here"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Deep"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Learning"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Lecture"}, {"url": "https://www.youtube.com/c/AndreasMaierTV", "anchor_text": "YouTube"}, {"url": "https://twitter.com/maier_ak", "anchor_text": "Twitter"}, {"url": "https://www.facebook.com/andreas.maier.31337", "anchor_text": "Facebook"}, {"url": "https://www.linkedin.com/in/andreas-maier-a6870b1a6/", "anchor_text": "LinkedIn"}, {"url": "https://creativecommons.org/licenses/by/4.0/deed.de", "anchor_text": "Creative Commons 4.0 Attribution License"}, {"url": "https://www.usablestats.com/calcs/2samplet&summary=1", "anchor_text": "Online t-test"}, {"url": "http://peaks.informatik.uni-erlangen.de/cgi-bin/significance.cgi", "anchor_text": "Online test for comparing recognition rates"}, {"url": "http://peaks.informatik.uni-erlangen.de/cgi-bin/usignificance.cgi", "anchor_text": "Online test to compare correlations"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----70c08fce3588---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----70c08fce3588---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/fau-lecture-notes?source=post_page-----70c08fce3588---------------fau_lecture_notes-----------------", "anchor_text": "Fau Lecture Notes"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----70c08fce3588---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----70c08fce3588---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "http://creativecommons.org/licenses/by/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70c08fce3588&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&user=Andreas+Maier&userId=b1444918afee&source=-----70c08fce3588---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70c08fce3588&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&user=Andreas+Maier&userId=b1444918afee&source=-----70c08fce3588---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70c08fce3588&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70c08fce3588--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F70c08fce3588&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----70c08fce3588---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----70c08fce3588--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----70c08fce3588--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----70c08fce3588--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----70c08fce3588--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----70c08fce3588--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----70c08fce3588--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----70c08fce3588--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----70c08fce3588--------------------------------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andreas Maier"}, {"url": "https://akmaier.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1444918afee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&user=Andreas+Maier&userId=b1444918afee&source=post_page-b1444918afee--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa5f0dee142a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcommon-practices-part-4-70c08fce3588&newsletterV3=b1444918afee&newsletterV3Id=a5f0dee142a2&user=Andreas+Maier&userId=b1444918afee&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}