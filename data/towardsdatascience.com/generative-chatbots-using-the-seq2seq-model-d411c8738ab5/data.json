{"url": "https://towardsdatascience.com/generative-chatbots-using-the-seq2seq-model-d411c8738ab5", "time": 1683007733.913249, "path": "towardsdatascience.com/generative-chatbots-using-the-seq2seq-model-d411c8738ab5/", "webpage": {"metadata": {"title": "Generative chatbots using the seq2seq model! | by Dhruvil Shah | Towards Data Science", "h1": "Generative chatbots using the seq2seq model!", "description": "The below article shows how to create closed domain chatbots with the help of Machine learning classifier. In the above article, the responses were fixed and the machine learning helped to select the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c", "anchor_text": "teacher forcing", "paragraph_index": 4}, {"url": "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html", "anchor_text": "seq2seq", "paragraph_index": 4}, {"url": "http://www.kaggle.com", "anchor_text": "Kaggle", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c", "anchor_text": "teacher forcing", "paragraph_index": 12}, {"url": "https://stackoverflow.com/questions/54235845/what-exactly-is-timestep-in-an-lstm-model", "anchor_text": "timestep", "paragraph_index": 12}, {"url": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/", "anchor_text": "here", "paragraph_index": 15}, {"url": "https://github.com/jackfrost1411/Generative-chatbot", "anchor_text": "here", "paragraph_index": 26}, {"url": "https://www.linkedin.com/in/dhruvilshah28/", "anchor_text": "here", "paragraph_index": 26}, {"url": "http://LinkedIn.com/in/dhruvilshah28", "anchor_text": "LinkedIn.com/in/dhruvilshah28", "paragraph_index": 32}], "all_paragraphs": ["A chatbot is a software that provides a real conversational experience to the user. There are closed domain chatbots and open domain (generative) chatbots. Closed domain chatbot is a chatbot that responses with predefined texts. A generative chatbot generates a response as the name implies.", "The below article shows how to create closed domain chatbots with the help of Machine learning classifier.", "In the above article, the responses were fixed and the machine learning helped to select the correct response given in the user\u2019s question. But here, we are not going to select from pre-defined responses but instead, we will generate a response based on the training corpus. We are going to use the encoder-decoder (seq2seq) model for this approach.", "The seq2seq model also called the encoder-decoder model uses Long Short Term Memory- LSTM for text generation from the training corpus. The seq2seq model is also useful in machine translation applications. What does the seq2seq or encoder-decoder model do in simple words? It predicts a word given in the user input and then each of the next words is predicted using the probability of likelihood of that word to occur. In building our Generative chatbot we will use this approach for text generation given in the user input.", "The encoder outputs a final state vector (memory) which becomes the initial state for the decoder. We use a method called teacher forcing to train the decoder which enables it to predict the following words in a target sequence given in the previous words. As shown above, states are passed through the encoder to each layer of the decoder. \u2018Hi,\u2019, \u2018how\u2019, \u2018are\u2019, and \u2018you\u2019 are called input tokens while \u2018I\u2019, \u2018am\u2019, and \u2018fine\u2019 are called target tokens. The likelihood of token \u2018am\u2019 depends on the previous words and the encoder states. We are adding \u2018<END>\u2019 token to let our decoder know when to stop. You can learn more about the seq2seq model here.", "Let\u2019s start building our generative chatbot from scratch! The first task we will have to do is preprocess our dataset.", "The dataset we are going to use is collected from Kaggle. You can find it below. It contains human responses and bot responses. There are 2363 entries for each.", "First, we will have to clean our corpus with the help of Regular Expressions. Then, we will need to make pairs like human response-bot response so that we can train our seq2seq model. We will do these tasks as shown below.", "After creating pairs we can also shuffle those before training. Our pairs will look like this now:", "Here, \u2018hi\u2019 is input sequence, and \u2018hi there how are you\u2019 is a target sequence. We will have to create separate lists for input sequences and target sequences and we will also need to create lists for unique tokens (input tokens and target tokens) in our dataset. For target sequences, we will add \u2018<START>\u2019 at the beginning of the sequence and \u2018<END>\u2019 at the end of the sequence so that our model knows where to start and end text generation. We will do this as shown below.", "Note: We are only taking the first 400 pairs to keep things simple but as a result, we will get very low accuracy.", "We have unique input tokens and target tokens for our dataset. Now we will create an input features dictionary that will store our input tokens as key-value pairs, the word being the key and value is the index. Similarly, for target tokens, we will create a target features dictionary. Features dictionary will help us encode our sentences into one-hot vectors. After all, computers only understand the numbers. To decode the sentences we will need to create the reverse features dictionary that stores index as a key and word as a value.", "To train our seq2seq model we will use three matrices of one-hot vectors, Encoder input data, Decoder input data, and Decoder output data. The reason we are using two matrices for the Decoder is a method called teacher forcing which is used by the seq2seq model while training. What is the idea behind this? We have an input token from the previous timestep to help the model train for the current target token. Let\u2019s create these matrices.", "To get a clear understanding of how the dimensions of encoder_input_data works see the below figure. The decoder_input_data and decoder_target_data similarly have the dimensions.", "Our encoder model requires an input layer which defines a matrix for holding the one-hot vectors and an LSTM layer with some number of hidden states. Decoder model structure is almost the same as encoder\u2019s but here we pass in the state data along with the decoder inputs.", "You can learn more about how to code the encoder-decoder model here as a full explanation of it is out of scope for this article.", "Now we will create our seq2seq model and train it with encoder and decoder data as shown below.", "Here, we are using rmsprop as an optimizer and categorical_crossentropy as our loss function. We call the .fit() method by giving the encoder and decoder input data (X/input) and decoder target data (Y/label). After training finishes, we get training accuracy of around 20%. The reason for this lower accuracy is that we used only 400 pairs of the dataset. If trained on a larger dataset, greater accuracy can be achieved.", "Now, to handle an input that the model has not seen we will need a model that decodes step-by-step instead of using teacher forcing because the model we created only works when the target sequence is known. In the Generative chatbot application, we will not know what the generated response will be for input the user passes in. For doing this, we will have to build a seq2seq model in individual pieces. Let\u2019s first build an encoder model with encoder inputs and encoder output states. We will do this with the help of the previously trained model.", "Next, we will need to create placeholders for decoder input states as we do not know what we need to decode or what hidden state we will get.", "Now we will create new decoder states and outputs with the help of decoder LSTM and Dense layer that we trained earlier.", "Finally, we have the decoder input layer, the final states from the encoder, the decoder outputs from the Dense layer of the decoder, and decoder output states which is the memory during the network from one word to the next. We can bring this all together now and set up the decoder model as shown below.", "At last, we will create a function that accepts our text inputs and generates a response using encoder and decoder that we created. In the function below, we pass in the NumPy matrix that represents our text sentence and we get the generated response back from it. I have added comments for almost every line of code for you to understand it quickly. What happens in the below function is this: 1.) We retrieve output states from the encoder 2.) We pass in the output states to the decoder (which is our initial hidden state of the decoder) to decode the sentence word by word 3.) Update the hidden state of decoder after decoding each word so that we can use previously decoded words to help decode new ones", "We will stop once we encounter \u2018<END>\u2019 token that we added to target sequences in our preprocessing task or we hit the maximum length of the sequence.", "Let\u2019s create a class that contains methods required for running a chatbot.", "All methods are self-explanatory in the above code. Below is the final output for our Generative chatbot!", "You can find all of the code above here on GitHub and find me here on LinkedIn.", "Here we used a very small dataset and got an accuracy of around 20%. In the future for a larger dataset, the model might give better accuracy. The limitation of using this approach for creating chatbots is that we need a very large dataset to give the best responses to the user as we can see in the above output that chatbot does not give the right responses in some cases because of a smaller dataset.", "A similar task we can do with the above-shown approach is Machine Translation. The below article shows how we can use the seq2seq model to perform Machine Translation.", "Closed domain architecture focuses on response selection from a set of predefined responses when the open domain architecture enables us to perform boundless text generation. Closed domain systems use intent classification, entity identification, and response selection. But for an open domain chatbot, intent classification is harder and an immense number of intents are likely. Rather than selecting full responses, the open domain or generative model generates the response word by word, allowing for new combinations of language.", "In industries, some companies use the closed domain chatbots to ensure that the user always receives the right response from the predefined ones. The Natural Language Processing- NLP domain is developing and training neural networks for approximating the approach the human brain takes towards language processing. This deep learning strategy allows computers to handle human language much more efficiently.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science Enthusiast | Full Stack Developer | LinkedIn.com/in/dhruvilshah28"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd411c8738ab5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dhruvilshah28?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dhruvilshah28?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "Dhruvil Shah"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0cd54e8f51c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&user=Dhruvil+Shah&userId=e0cd54e8f51c&source=post_page-e0cd54e8f51c----d411c8738ab5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd411c8738ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd411c8738ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@neonbrand?utm_source=medium&utm_medium=referral", "anchor_text": "NeONBRAND"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/a-naive-bayes-approach-towards-creating-closed-domain-chatbots-f93e7ac33358", "anchor_text": "A Naive Bayes approach towards creating closed domain Chatbots!There is an easy and efficient approach for creating a closed domain chatbot that uses the Naive Bayes classifier.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c", "anchor_text": "teacher forcing"}, {"url": "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html", "anchor_text": "seq2seq"}, {"url": "http://www.kaggle.com", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/eibriel/rdany-conversations", "anchor_text": "\u2018rDany\u2019 Chat157 chats & 6300+ messages with a (fake) virtual companionwww.kaggle.com"}, {"url": "https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c", "anchor_text": "teacher forcing"}, {"url": "https://stackoverflow.com/questions/54235845/what-exactly-is-timestep-in-an-lstm-model", "anchor_text": "timestep"}, {"url": "https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/", "anchor_text": "here"}, {"url": "https://github.com/jackfrost1411/Generative-chatbot", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/dhruvilshah28/", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/machine-translation-with-the-seq2seq-model-different-approaches-f078081aaa37", "anchor_text": "Machine translation with the seq2seq model: Different approachesDiscussing the two different approaches for machine translation using the seq2seq model.towardsdatascience.com"}, {"url": "https://unsplash.com/@hauntedeyes?utm_source=medium&utm_medium=referral", "anchor_text": "Lukas"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d411c8738ab5---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d411c8738ab5---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/chatbots?source=post_page-----d411c8738ab5---------------chatbots-----------------", "anchor_text": "Chatbots"}, {"url": "https://medium.com/tag/python?source=post_page-----d411c8738ab5---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/nlp?source=post_page-----d411c8738ab5---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd411c8738ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&user=Dhruvil+Shah&userId=e0cd54e8f51c&source=-----d411c8738ab5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd411c8738ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&user=Dhruvil+Shah&userId=e0cd54e8f51c&source=-----d411c8738ab5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd411c8738ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd411c8738ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d411c8738ab5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d411c8738ab5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d411c8738ab5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d411c8738ab5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dhruvilshah28?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dhruvilshah28?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dhruvil Shah"}, {"url": "https://medium.com/@dhruvilshah28/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "172 Followers"}, {"url": "http://LinkedIn.com/in/dhruvilshah28", "anchor_text": "LinkedIn.com/in/dhruvilshah28"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0cd54e8f51c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&user=Dhruvil+Shah&userId=e0cd54e8f51c&source=post_page-e0cd54e8f51c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2bf065f3ed8b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-chatbots-using-the-seq2seq-model-d411c8738ab5&newsletterV3=e0cd54e8f51c&newsletterV3Id=2bf065f3ed8b&user=Dhruvil+Shah&userId=e0cd54e8f51c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}