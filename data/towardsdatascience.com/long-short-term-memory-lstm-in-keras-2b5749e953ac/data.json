{"url": "https://towardsdatascience.com/long-short-term-memory-lstm-in-keras-2b5749e953ac", "time": 1683005738.093738, "path": "towardsdatascience.com/long-short-term-memory-lstm-in-keras-2b5749e953ac/", "webpage": {"metadata": {"title": "Long Short Term Memory (LSTM) In Keras | by Ritesh Ranjan | Towards Data Science", "h1": "Long Short Term Memory (LSTM) In Keras", "description": "In this article, we will first focus on unidirectional and bidirectional LSTMs. I will explain all the steps right from preparing data for training and defining the LSTM model. In this article, I\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/snap/amazon-fine-food-reviews", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://github.com/riteshranjan110/MediumBlogsCode/blob/master/LSTMblog1.ipynb", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://www.linkedin.com/in/riteshranjan11055/", "anchor_text": "https://www.linkedin.com/in/riteshranjan11055/", "paragraph_index": 17}], "all_paragraphs": ["In this article, we will first focus on unidirectional and bidirectional LSTMs. I will explain all the steps right from preparing data for training and defining the LSTM model. In this article, I will explain only the sequential model. In this article, I will use LSTMs to do sentiment analysis of amazon fine food reviews. So let's get started.", "In this section, you will learn how to vectorize the data and pass it as input to the architecture. I will take an example so that you can learn to give input based on your dataset. Here I will take the amazon reviews dataset to show how to vectorize your data. You can download the dataset from here.", "Before moving forward first let us see the data and do some data cleaning. First, we will load the .csv file using the pandas library. We will take those reviews whose rating is not equal to 3 stars as the 3-star rated review is neutral. Below is the code to do the same.", "Now we will do standard data preprocessing by removing HTML tags, stopwords, and duplicates. You can see the details here. After cleaning the dataset we will have two columns. One will contain reviews and the other will contains labels 1 or 0. 1 means positive review and 0 means negative review.", "Now the next step is to vectorize the data. We will vectorize the data using the tokenizer class of the Keras module. This assigns every unique word an integer number. So now each word will be identified by an integer number. Below is the code that exactly does this.", "Every word should be represented by a vector so that model can understand them. There are two ways: one is using a pre-trained word embeddings such as word2vec and glove, the other is to train your own word embedding for your dataset. We can do this by using the Embedding layer of Keras module while training our deep learning model. Embedding layer takes vocabulary size, dimension of word vector and the input length of each review. Here we will keep dimension to 32. Then each word will be represented by a vector of length 32 after training is done. We have already fixed the max length of reviews to 150. Below is the code to define the embedding layer.", "You can see that the Embedding layer is the first layer of the model. We must specify the below three arguments.", "In this section, we will define the model. In our architecture, we will use two layers of the LSTM each of 128 units one stacked on the other. Normal LSTM is 3 to 4 times slower compared to CuDNNLSTM. Therefore if you are training on GPU then train using CuDNNLSTM. You will see that magically the training speed will increase 3 to 4 times. Below is the code to define the architecture.", "If you want to use stacked layers of LSTMs then use return_sequences=True before passing input to the next LSTM layer. For the last LSTM layer, there is no need to use return_sequences=True. You can change the number of units used. Here e have used 128, you can use what suits your case. You can vary these values and keep the best value. You can also try other activation functions and see which fives the best performance, and then you can select the best one. You can also try to stack more layers and check the improvement is there or not.", "In this section, we will train the model that we defined above. We can train the model using \u2018model.fit\u2019 method. This takes the following arguments:", "The following code does what has been mentioned above.", "With this architecture, we got an accuracy of 83% on the test dataset. Using bidirectional LSTMs instead of unidirectional LSTMs gave us an accuracy of 92%. Below is the code for using bidirectional LSTMs.", "Now the question is what is the intuition behind using bidirectional LSTMs. In unidirectional LSTM we encode a word by just looking at the words that are on the left side of that word. In bidirectional LSTM we encode a word by looking at the words that are on the left and right side of that word. It is very obvious that we can encode a word better if we observe the words on the left and right sides as well. Right?", "This we can see with the results that we have got. Using bidirectional improved accuracy of our model from 83% to 92%, and this is a significant jump.", "I hope this will help you to start working with LSTMs. I will provide the link to the jupyter notebook for further reference. You can view the notebook here.", "If you have any doubts do let me know.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Enthusiast. Writer in Towards Data Science, Analytics Vidhya, and AI In Plain English. LinkedIn: https://www.linkedin.com/in/riteshranjan11055/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2b5749e953ac&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://riteshk981.medium.com/?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": ""}, {"url": "https://riteshk981.medium.com/?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "Ritesh Ranjan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb6b2556387fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&user=Ritesh+Ranjan&userId=b6b2556387fc&source=post_page-b6b2556387fc----2b5749e953ac---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b5749e953ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b5749e953ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/snap/amazon-fine-food-reviews", "anchor_text": "here"}, {"url": "https://github.com/riteshranjan110/MediumBlogsCode/blob/master/LSTMblog1.ipynb", "anchor_text": "here"}, {"url": "https://keras.io/getting-started/sequential-model-guide/", "anchor_text": "https://keras.io/getting-started/sequential-model-guide/"}, {"url": "http://www.bioinf.jku.at/publications/older/2604.pdf", "anchor_text": "http://www.bioinf.jku.at/publications/older/2604.pdf"}, {"url": "https://keras.io/callbacks/", "anchor_text": "https://keras.io/callbacks/"}, {"url": "https://keras.io/layers/recurrent/", "anchor_text": "https://keras.io/layers/recurrent/"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----2b5749e953ac---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2b5749e953ac---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/technology?source=post_page-----2b5749e953ac---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/lstm?source=post_page-----2b5749e953ac---------------lstm-----------------", "anchor_text": "Lstm"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2b5749e953ac---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2b5749e953ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&user=Ritesh+Ranjan&userId=b6b2556387fc&source=-----2b5749e953ac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2b5749e953ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&user=Ritesh+Ranjan&userId=b6b2556387fc&source=-----2b5749e953ac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b5749e953ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2b5749e953ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2b5749e953ac---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2b5749e953ac--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2b5749e953ac--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2b5749e953ac--------------------------------", "anchor_text": ""}, {"url": "https://riteshk981.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://riteshk981.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ritesh Ranjan"}, {"url": "https://riteshk981.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "68 Followers"}, {"url": "https://www.linkedin.com/in/riteshranjan11055/", "anchor_text": "https://www.linkedin.com/in/riteshranjan11055/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb6b2556387fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&user=Ritesh+Ranjan&userId=b6b2556387fc&source=post_page-b6b2556387fc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fad539cca55bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flong-short-term-memory-lstm-in-keras-2b5749e953ac&newsletterV3=b6b2556387fc&newsletterV3Id=ad539cca55bd&user=Ritesh+Ranjan&userId=b6b2556387fc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}