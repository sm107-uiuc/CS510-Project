{"url": "https://towardsdatascience.com/simple-ocr-with-tesseract-a4341e4564b6", "time": 1683010747.0167491, "path": "towardsdatascience.com/simple-ocr-with-tesseract-a4341e4564b6/", "webpage": {"metadata": {"title": "Simple OCR with Tesseract. How to train Tesseract to read your\u2026 | by Andreas M M | Towards Data Science", "h1": "Simple OCR with Tesseract", "description": "In this article, I want to share with you how to build a simple OCR using Tesseract, \u201can optical character recognition engine for various operating systems\u201d. Tesseract itself is free software\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["In this article, I want to share with you how to build a simple OCR using Tesseract, \u201can optical character recognition engine for various operating systems\u201d. Tesseract itself is free software, originally developed by Hewlett-Packard until 2006 when Google took over the development. It is arguably the best out of the box OCR engine until today, with support for more than 100 languages. It\u2019s one of the most popular OCR engines, as it\u2019s easy to install and use.", "Now, suppose that you were given a task by your boss to be able to convert the below picture into a machine language, or in simpler words, \u201cBuild an OCR model to be able to read these fonts in some pictures!\u201d. \u201cAlright, no problemo,\u201d you said, but suddenly your supervisor said to you \u201cAnd I want it done today, in the next 3\u20135 hours.\u201d", "\u201cWelp, How am I able to build an OCR model that fast?\u201d you said to yourself. But don\u2019t you worry, that is what the Tesseract is for! First thing first, you have to install it on your computer.", "After you are successfully installing Tesseract on your computer, open command prompt for windows or terminal if you are using Ubuntu, and then run:", "Where file_0.png is the filename of the above picture. We want Tesseract to read any words it found in the above image. You should see these outputs in your terminal :", "Oh no! It seems like Tesseract cannot read the words in the above picture perfectly. Seems like it misread some character, probably because the font in the image was unique and strange. Luckily, you can train your Tesseract so it can read your font easily. Just follow my steps!", "Disclaimer, as stated in the Tesseract\u2019s wiki, it is recommended to use the default \u201clanguage\u201d which was already trained on so many data for tesseract, and train your own language for the very last resort (means, that you should try to preprocess the image, thresholding and other image preprocessing method before jumping to training). This was because Tesseract itself is quite accurate on generally clean images, and it\u2019s quite difficult to make Tesseract\u2019s training prediction more accurate, EXCEPT if your font is quite different and unique (like in our cases) or if you try to read some demonic language.", "To train your font, first, you need to :", "After you have prepared all the installation steps above, you are ready to train your Tesseract. Tesseract use \u201clanguage\u201d as its model for OCR. There are many default languages, like eng (English), ind (Indonesian), and so on. We try to create a new language for Tesseract to be able to predict our Font, by creating some training data consisting of random numbers using our Font. There are 2 ways to do just that. First, if you have a collection of images consisting of just your fonts, then you can use that or, the second way, that is to type any number (or character) you want on word using your font, and use snipping tools (windows) or shift key + PrintScreen (Ubuntu) to capture and save it on a folder.", "In my experience, 10\u201315 data was enough to produce an accurate (subjectively) model which is sufficiently accurate for both clean and some noisy images. Note that you should try to create as balanced data as possible, and as close as real case as possible. If you want to predict some images with a blue background, red font, then you should create training data with a blue background and red font.", "In general, the training step of Tesseract is :", "After you are done creating some data, open the jTessBoxEditor. At the top bar, go to \u201cTools\u201d \u2192 \u201cMerge Tiff\u201d (or you can just use shortcut Ctrl + M ). Go to the folder where you have saved your training images. Change the filter to PNG (or any extension your images have), select all images, and click \u201cOk\u201d. Then in the selection panel, type in font_name.font.exp0 where font_name is any name you want (this will be the name for your own new Tesseract\u2019s language).", "Open terminal, navigate to the folder where you saved your training images and .tiff file. As we now have the training data, how do we get the training label? Afraid not, you should not label each image manually, as we can use Tesseract and jTessBoxEditor to aid us. In the terminal, run below command :", "Wait, why suddenly there are psm and oem? What will happen when I type the command above? If you run :", "You will see that psm means Page Segmentation Modes, meaning how the tesseract treats the image. If you want the tesseract to treat each image it sees as a single word, you can choose psm 8. In our case, as our images in .tiff file are a collection of single-line text, we choose psm 6. As for OEM, it means Ocr Engine Modes, as for tesseract there are legacy engine that works by recognizing character patterns, or using Neural Nets and LTSM engines (if you want to use LTSM, install tesseract version> 4.0.0 ).", "Using the above command, we want the tesseract to produce the bounding boxes and the prediction of each image in the .tiff file and save it to font_name.font.exp0.box text file. In case you didn\u2019t know, the.tiff file that we produced earlier contains your training images segmented by \u201cpage\u201d. By using the above command, it will produce a .box file containing a prediction, and bounding box of each word in the .tiff file. with the name font_name.font.exp0.box", "Now open jTessBoxEditor, navigate to the box editor tab, and click open and select the .tiff file. You should see that each image on each page has its bounding boxes and prediction. Your job now is to fix each bounding box and its char prediction in the .box file. (yes, this is the dullest part)", "After you have created the already fixed .box file and .tiff file. Create a new text document contains", "Save it as font_properties into the same folder as the .tiff file and .box file. Now you are ready to begin the training process! (finally). Inside the folder, you should have all these files:", "Now run this command on the terminal :", "If you meet an error, you might need to use tesseract.exe, unicharset_extractor.exe, and cntraining.exe (for windows users). You will see some outputs in your terminal, and most importantly in the shapeclustering part. If your training images contain all the necessary characters, you will see that the Number of Shapes = {Number of class that you want}. For example, if I want to train the tesseract to be able to read the digits number correctly, then the Number of shapes equals to 10 (which is 0,1,2,3 ,\u2026 , 9).", "If your number of shapes does not equal to the number of class that you want, you should go back to create training data, and try to create cleaner data", "If you have done everything correctly, you will see 4 major files in your folder. shapetable, normproto, intemp, and pffmtable. Rename those files into font_name.shapetable, font_name.normproto, font_name.intemp, font_name.pffmtable.", "After you run all the command above, you will see these files in your folder", "And you are done! Yep, because we use a small amount of data, the training itself doesn\u2019t take hours, just seconds or maybe minutes. Compared to if you have to train a deep learning model (probably using an object detection model) from scratch, it\u2019s much much faster. Now, the next time you run the Tesseract, you could specify your new trained language by using", "Remember that using the default language before, the result of the above picture using the default Tesseract engine was 40293847 S565647386e2e91L0. Using our new trained language, the result was", "As you can see the result was much more accurate. Yay! With just a few training data and a relatively short amount of time, you have created an OCR model capable to read unique and strange font!", "To further check the model\u2019s result, you can create another .tiff file by using another image or by using the previous .tiff file. Open terminal and again, run :", "Now open jTessBoxEditor \u2192 box editor \u2192 open and select your .tiff file. Check if your model give more accurate prediction than the previous one. You should see that the prediction improved a lot.", "\u201cBut Is Tesseract the only way to go if you want an out of the box and fast OCR engine?\u201d you may ask. Well of course not, there are a ton of OCR API providers out there if you are willing to take out some cash. In my honest opinion, Tesseract is good if your images are really-really clean (for example, a word document, a cashier bill, and so on. If your images data contains many noises, you can use thresholding to differentiate the background and the noise from the font itself. In my experience, using as little as 10\u201320 data, Tesseract was able to compete even with the state of the art object detection model like Faster R-CNN which was trained using a lot more data (with a lot of augmentation as well). BUT if your images data have some noises (random dots, dirty mark) with the same color of your font, Tesseract will not be able to predict your images correctly. I say you should use Tesseract if you want to build OCR model as fast as possible, or you have a limited amount of training data.", "One of the main weaknesses (well I think) of the Tesseract is that it is quite unstable. I could get a different result by just using a larger crop of the same image. Also for some reason, if I use more than 50 data, the Tesseract performs worse. Well, I\u2019m also still learning myself. If you find some mistakes or misconceptions in this article, feel free to contact me. Thank you for reading, Happy Learning!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI Researcher at Astra Digital. Deep Learning, and Computer Vision enthusiast"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa4341e4564b6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@andreasmmadjiah?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andreasmmadjiah?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "Andreas M M"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe2c1e15056a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&user=Andreas+M+M&userId=be2c1e15056a&source=post_page-be2c1e15056a----a4341e4564b6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4341e4564b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4341e4564b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/angel-kun-50012/", "anchor_text": "Angel-Kun"}, {"url": "https://pixabay.com/photos/future-eye-robot-eye-machine-175620/", "anchor_text": "Pixabay"}, {"url": "https://github.com/UB-Mannheim/tesseract/wiki", "anchor_text": "https://github.com/UB-Mannheim/tesseract/wiki"}, {"url": "https://www.java.com/en/download/", "anchor_text": "https://www.java.com/en/download/"}, {"url": "https://sourceforge.net/projects/vietocr/files/jTessBoxEditor/", "anchor_text": "https://sourceforge.net/projects/vietocr/files/jTessBoxEditor"}, {"url": "https://github.com/tesseract-ocr/tesseract", "anchor_text": "tesseract-ocr/tesseractThis package contains an OCR engine \u2014 libtesseract and a command line program \u2014 tesseract. Tesseract 4 adds a new\u2026github.com"}, {"url": "https://github.com/nguyenq/jTessBoxEditor", "anchor_text": "nguyenq/jTessBoxEditorA box editor and trainer for Tesseract OCR, providing editing of box data of both Tesseract 2.0x and 3.0x formats and\u2026github.com"}, {"url": "https://medium.com/@gaopengbai0121/training-your-tesseract-on-windows-10-df6756946d4f", "anchor_text": "Training your tesseract on windows 10Tesseract, an open-source OCR (Optical Character Recognition) engine developed by Google Labs and maintained by Google\u2026medium.com"}, {"url": "https://github.com/tesseract-ocr/tessdoc", "anchor_text": "tesseract-ocr/tessdocTesseract documentation. Contribute to tesseract-ocr/tessdoc development by creating an account on GitHub.github.com"}, {"url": "https://medium.com/@latifvardar/how-does-tesseract-ocr-work-with-python-a6bccf85a002", "anchor_text": "How does Tesseract-OCR work with Python?This article is a guide for you to recognize characters from images using Tesseract OCR, OpenCV and Python.medium.com"}, {"url": "https://medium.com/better-programming/beginners-guide-to-tesseract-ocr-using-python-10ecbb426c3d", "anchor_text": "A Beginner\u2019s Guide to Tesseract OCROptical character recognition with Tesseract and Pythonmedium.com"}, {"url": "https://nanonets.com/blog/ocr-with-tesseract/#installingtesseract?&utm_source=nanonets.com/blog/&utm_medium=blog&utm_content=%5BTutorial%5D%20OCR%20in%20Python%20with%20Tesseract,%20OpenCV%20and%20Pytesseract", "anchor_text": "[Tutorial] OCR in Python with Tesseract, OpenCV and PytesseractOCR = Optical Character Recognition. In other words, OCR systems transform a two-dimensional image of text, that could\u2026nanonets.com"}, {"url": "https://medium.com/tag/tesseract?source=post_page-----a4341e4564b6---------------tesseract-----------------", "anchor_text": "Tesseract"}, {"url": "https://medium.com/tag/ocr?source=post_page-----a4341e4564b6---------------ocr-----------------", "anchor_text": "Ocr"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----a4341e4564b6---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a4341e4564b6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/machine-intelligence?source=post_page-----a4341e4564b6---------------machine_intelligence-----------------", "anchor_text": "Machine Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4341e4564b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&user=Andreas+M+M&userId=be2c1e15056a&source=-----a4341e4564b6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4341e4564b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&user=Andreas+M+M&userId=be2c1e15056a&source=-----a4341e4564b6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4341e4564b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa4341e4564b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a4341e4564b6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a4341e4564b6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a4341e4564b6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a4341e4564b6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andreasmmadjiah?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andreasmmadjiah?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andreas M M"}, {"url": "https://medium.com/@andreasmmadjiah/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "25 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe2c1e15056a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&user=Andreas+M+M&userId=be2c1e15056a&source=post_page-be2c1e15056a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F589e24712b9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimple-ocr-with-tesseract-a4341e4564b6&newsletterV3=be2c1e15056a&newsletterV3Id=589e24712b9c&user=Andreas+M+M&userId=be2c1e15056a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}