{"url": "https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30", "time": 1683002572.186719, "path": "towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30/", "webpage": {"metadata": {"title": "SHAP Values Explained Exactly How You Wished Someone Explained to You | by Samuele Mazzanti | Towards Data Science", "h1": "SHAP Values Explained Exactly How You Wished Someone Explained to You", "description": "SHAP \u2014 which stands for SHapley Additive exPlanations \u2014 is probably the state of the art in Machine Learning explainability. This algorithm was first published in 2017 by Lundberg and Lee (here is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1705.07874", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/black-box-models-are-actually-more-explainable-than-a-logistic-regression-f263c22795d", "anchor_text": "Black-Box models are actually more explainable than a Logistic Regression", "paragraph_index": 3}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP library for Python", "paragraph_index": 3}, {"url": "https://arxiv.org/abs/1705.07874", "anchor_text": "article", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Power_set", "anchor_text": "power set", "paragraph_index": 11}, {"url": "https://arxiv.org/abs/1705.07874", "anchor_text": "article", "paragraph_index": 34}, {"url": "https://towardsdatascience.com/black-box-models-are-actually-more-explainable-than-a-logistic-regression-f263c22795d", "anchor_text": "here", "paragraph_index": 37}, {"url": "https://github.com/slundberg/shap", "anchor_text": "the one by Slundberg", "paragraph_index": 39}], "all_paragraphs": ["SHAP \u2014 which stands for SHapley Additive exPlanations \u2014 is probably the state of the art in Machine Learning explainability. This algorithm was first published in 2017 by Lundberg and Lee (here is the original paper) and it is a brilliant way to reverse-engineer the output of any predictive algorithm.", "In a nutshell, SHAP values are used whenever you have a complex model (could be a gradient boosting, a neural network, or anything that takes some features as input and produces some predictions as output) and you want to understand what decisions the model is making.", "Predictive models answer the \u201chow much\u201d. SHAP answers the \u201cwhy\u201d.", "In a previous post (Black-Box models are actually more explainable than a Logistic Regression) we used SHAP to understand why a gradient boosting model was suggesting that a Titanic passenger was more or less likely to survive. In other words, we used SHAP to demystify a black-box model. But, so far, we exploited the SHAP library for Python without worrying too much about how it works.", "Ironically enough, we used SHAP as a black-box itself!", "However, understanding the idea behind the calculation of SHAP values is crucial to make sense of their outcome. This is why, in this post, we will go through the theoretical foundation of SHapley Additive exPlanations described in the article by Slundberg and Lee, and see why SHAP values are computed the way they are computed.", "SHAP values are based on Shapley values, a concept coming from game theory. But game theory needs at least two things: a game and some players. How does this apply to machine learning explainability? Imagine that we have a predictive model, then:", "What Shapley does is quantifying the contribution that each player brings to the game. What SHAP does is quantifying the contribution that each feature brings to the prediction made by the model.", "It is important to stress that what we called a \u201cgame\u201d concerns a single observation. One game: one observation. Indeed, SHAP is about local interpretability of a predictive model.", "By way of example, we will imagine a machine learning model (let\u2019s say a linear regression, but it could be any other machine learning algorithm) that predicts the income of a person knowing age, gender and job of the person.", "Shapley values are based on the idea that the outcome of each possible combination (or coalition) of players should be considered to determine the importance of a single player. In our case, this corresponds to each possible combination of f features (f going from 0 to F, F being the number of all features available, in our example 3).", "In math, this is called a \u201cpower set\u201d and can be represented as a tree.", "Each node represents a coalition of features. Each edge represents the inclusion of a feature not present in the previous coalition.", "We know from math that the cardinality of a power set is 2 ^ n, where n is the number of elements of the original set. Indeed, in our case, we have 2 ^ F = 2 ^ 3 = 8 possible coalitions of features.", "Now, SHAP requires to train a distinct predictive model for each distinct coalition in the power set, meaning 2 ^ F models. Of course, these models are completely equivalent to each other for what concerns their hyperparameters and their training data (which is the full dataset). The only thing that changes is the set of features included in the model.", "Let us imagine that we have already trained our 8 linear regression models on the same training data. We can then take a new observation (let us call it x\u2080) and see what the 8 different models predict for the same observation x\u2080.", "Here, each node represents a model. But what do edges represent?", "As seen above, two nodes connected by an edge differ for just one feature, in the sense that the bottom one has exactly the same features of the upper one plus an additional feature that the upper one did not have. Therefore, the gap between the predictions of two connected nodes can be imputed to the effect of that additional feature. This is called \u201cmarginal contribution\u201d of a feature.", "Therefore, each edge represents the marginal contribution brought by a feature to a model.", "Imagine that we are in node 1, which is the model with no features. This model will simply predict the average income of all the training observations (50k $). If we move to node 2, which is a model with just one feature (Age), the prediction for x\u2080 is now 40k $. This means that knowing the age of x\u2080 has lowered our prediction by 10k $.", "Thus, the marginal contribution brought by Age to the model containing only Age as a feature is -10k $. In formula:", "Of course, to obtain the overall effect of Age on the final model (i.e. the SHAP value of Age for x\u2080) it is necessary to consider the marginal contribution of Age in all the models where Age is present. In our tree representation, this means to consider all the edges connecting two nodes such that:", "In the following figure, such edges have been highlighted in red.", "All these marginal contributions are then aggregated through a weighted average. In formula:", "But how do we determine the weights of the edges (i.e. of the marginal contiributions of Age in the 4 models)?", "Therefore, (keeping in mind that they should sum to 1) the solution is:", "Looking at the figure above, can you guess the pattern for determining weights in a general framework?", "Spoiler: the weight of an edge is the reciprocal of the total number of edges in the same \u201crow\u201d. Or, equivalently, the weight of a marginal contribution to a f-feature-model is the reciprocal of the number of possible marginal contributions to all the f-feature-models.", "Is there a formula to calculate this? It is straightforward, actually.", "Each f-feature-model has f marginal contributions (one per feature), so it is enough to count the number of possible f-feature-models and to multiply it by f. Thus, the problem boils down to counting the number of possible f-feature-models, given f and knowing that the total number of feature is F. This is simply the definition of binomial coefficient.", "Putting things together, we have that the number of all the marginal contributions of all the f-feature-models \u2014 in other words, the number of edges in each \u201crow\u201d \u2014 is:", "It is enough to take the reciprocal of this and we have the weight of a marginal contribution to a f-feature-model.", "This is exemplified in the figure below:", "Now, we have all the elements required for calculating the SHAP value of Age for x\u2080:", "We have built the formula for calculating the SHAP value of Age in a 3-feature-model. Generalizing to any feature and any F, we obtain the formula reported in the article by Slundberg and Lee:", "Applied on our example, the formula yields:", "Summing them up gives +33k $, which is exactly the difference between the output of the full model (83k $) and the output of the dummy model with no features (50k $).", "This is a fundamental characteristic of SHAP values: summing the SHAP values of each feature of a given observation yields the difference between the prediction of the model and the null model (or its logistic function, as we have seen here). This is actually the reason for their name: SHapley Additive exPlanations.", "As seen above, the original SHAP formula requires to train 2 ^ F models. For a model with just 50 features, this would mean to train 1e15 models! Indeed, as F increases, the formula seen above becomes inapplicable soon.", "However, libraries such as the one by Slundberg employ some brilliant approximations and samplings (I will treat the topic in a follow-up post) that make the job feasible.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Lead Data Scientist | Striving for simplicity."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fab81cc69ef30&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mazzanti.sam?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mazzanti.sam?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "Samuele Mazzanti"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe16f3bb86e03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=post_page-e16f3bb86e03----ab81cc69ef30---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fab81cc69ef30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fab81cc69ef30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1705.07874", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/black-box-models-are-actually-more-explainable-than-a-logistic-regression-f263c22795d", "anchor_text": "Black-Box models are actually more explainable than a Logistic Regression"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP library for Python"}, {"url": "https://arxiv.org/abs/1705.07874", "anchor_text": "article"}, {"url": "https://en.wikipedia.org/wiki/Power_set", "anchor_text": "power set"}, {"url": "https://arxiv.org/abs/1705.07874", "anchor_text": "article"}, {"url": "https://towardsdatascience.com/black-box-models-are-actually-more-explainable-than-a-logistic-regression-f263c22795d", "anchor_text": "here"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "the one by Slundberg"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ab81cc69ef30---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/shap?source=post_page-----ab81cc69ef30---------------shap-----------------", "anchor_text": "Shap"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----ab81cc69ef30---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/explainability?source=post_page-----ab81cc69ef30---------------explainability-----------------", "anchor_text": "Explainability"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----ab81cc69ef30---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fab81cc69ef30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=-----ab81cc69ef30---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fab81cc69ef30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=-----ab81cc69ef30---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fab81cc69ef30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fab81cc69ef30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ab81cc69ef30---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ab81cc69ef30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mazzanti.sam?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mazzanti.sam?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Samuele Mazzanti"}, {"url": "https://medium.com/@mazzanti.sam/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe16f3bb86e03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=post_page-e16f3bb86e03--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fce90f5bea5f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fshap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30&newsletterV3=e16f3bb86e03&newsletterV3Id=ce90f5bea5f9&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}