{"url": "https://towardsdatascience.com/the-maths-behind-back-propagation-cf6714736abf", "time": 1683005013.905628, "path": "towardsdatascience.com/the-maths-behind-back-propagation-cf6714736abf/", "webpage": {"metadata": {"title": "The Maths behind Back Propagation | by Shane De Silva | Towards Data Science", "h1": "The Maths behind Back Propagation", "description": "The high-level explanation of how back propagation (BP) works is fairly straightforward for most people to understand conceptually. Looking at the image above is enough to scare all but the most\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/a-beginners-guide-to-neural-nets-5cf4050117cb", "anchor_text": "previous article", "paragraph_index": 4}, {"url": "https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/a/chain-rule-review", "anchor_text": "chain rule", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e", "anchor_text": "(e^-z/(1+e^-z)\u00b2)", "paragraph_index": 15}, {"url": "https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/", "anchor_text": "ReLU activation function", "paragraph_index": 16}], "all_paragraphs": ["The high-level explanation of how back propagation (BP) works is fairly straightforward for most people to understand conceptually.", "What is more intimidating is exactly how we calculate those gradients.", "Looking at the image above is enough to scare all but the most quantitatively minded people amongst us away from this area of Deep Learning. Especially with all the high-level libraries out there (e.g. Keras) it is tempting to never look into how BP actually works. However, understanding how BP works will help you to understand many of the techniques used to improve the performance of vanilla NNs. Furthermore, understanding BP will give you a great foundation to attack the fancier and more exotic deep learning architectures out there as they pretty much all use it under the hood.", "I truly believe that most people can understand what is presented above as it is nothing more than high school maths dressed up in some fancy notation to keep track of the millions of parameters in a NN. We just need to break it down into its components and then translate those into English so that we understand what those equations are trying to express.", "In this article, I will shed light on the equations driving BP-the miracle algorithm driving much of deep learning. Before continuing further I assume the reader has knowledge of how a NN is trained. Specifically, understanding of the forward and backpropagation phases of a NN at a high level is assumed. If any of that sounded foreign then I direct you to my previous article in which I explain exactly that.", "In what follows I am continuing with the example from my previous post of recognising handwritten digits. So let\u2019s get on with it.", "As with most problems, we can make a lot of progress by simplifying the scenario. So instead of the usual mess of neurons and layers connected to everything in every-which-way let us first consider a simple 1\u20131\u20131 network.", "Fig. 1 shows such a network where the green, blue, and red neuron represent the input, hidden, and output neuron respectively. We call the activation of the final neuron a^(L) , and the activation of the neuron in the previous layer a^(L \u2014 1) where L is the number of layers in our network (in this case L = 3). Similarly, define the weight and bias between layer (L-1) and L as w^(L-1) and b^(L-1).", "Imagine we have put a 1 pixel image of a 9 (just humour me, clearly this is impossible) through the forward propagation phase of our NN and this output neuron corresponds to the digit 9. The desired output is 1. But our NN gives us a random value like 0.68. We will use mean squared error as our cost function. The cost for one training example, C, is then simply (0.68\u20131)\u00b2.", "So now we want to calculate the gradient of our cost C w.r.t the weight connecting the neurons in layer L to layer L-1. To see how we would do this we can unfold the last layer of the network.", "Fig. 2 shows how each of the terms that contribute to the activation of the final layer a^(L) and hence contribute to the cost C. To get the weighted sum, z^(L) for the final layer, we multiply the activation from layer (L-1) by the weight connecting the two layers, w^(L-1). Then we add a bias term, b^(L-1). Finally we put that weighted sum through a nonlinear function, \u03c3(z^(L)) , to calculate a^(L).", "Now we want to know how much does C change if we change w^(L-1). In other words we want to calculate dC/dw^(L-1). To do this we can use something that all of us are taught at secondary school: the chain rule.", "From fig. 4 you can see the path through which the weight w^(L-1) affects C. w^(L-1) contributes to the weighted sum z^(L), which is used to calculate the activation a^(L), which is itself directly used to calculate C. So by taking the derivative w.r.t the appropriate terms we can construct an equation for the gradient of C w.r.t the weight w^(L-1).", "Using the equations for z^(L) and a^(L) from fig. 3 in the chain rule gives", "The first of the three terms on the left-hand side of fig. 5 is the gradient of C w.r.t a^(L). Since we are using MSE, (a^(L)-y)\u00b2, as our cost function the gradient is 2(a^(L)-y).", "The second term is the gradient of the activation of the final layer w.r.t the weighted sum of the final layer. This is just the derivative of the nonlinear function that we are using so we denote it \u03c3\u2019. For example, if we used the sigmoid as our nonlinear function (1/(1+e^-z )), then the derivative would evaluate to (e^-z/(1+e^-z)\u00b2).", "[NOTE: This is why it is important to select a nonlinear function that is differentiable everywhere, otherwise you cannot propagate (calculate) your gradients, although there are caveats to this like the ReLU activation function]", "The last term is the derivative of the weighted sum w.r.t the weight connecting the layers (L-1) and L. From fig. 3 this is simply equal to the activation of the layer (L-1).", "We also want to know how our cost function would change if we changed the bias term, b^(L-1). So can construct a similar unfolded graph as in fig. 4 but for the bias term.", "The only term that has changed in the chain rule is the first one where now the derivative of the weighted sum of the final layer is taken w.r.t the bias.", "As before, we go through and calculate the value of each of the terms needed for the chain rule.", "Great, so now the NN can use these equations in the weight update equation to work out what values to set w^(L-1) and b(L-1) to for the next training round.", "Even though the NN has no direct control over a^(L-1) it will be shown in a second that we will need it when we consider going further into the network so let\u2019s repeat the above process but for a^(L-1).", "Again, we follow the path back to a^(L-1) and construct the chain rule that links how a change to a^(L-1) affects C.", "As before, we just replace the first term in the chain rule. Then we calculate the three terms to obtain", "If you have kept up until this point, you have done the majority of the work! Just a little bit more and you\u2019ll have pretty much all the equations.", "Now let\u2019s consider finding out what happens to C if we change a weight in layer (L-2). As before, we can draw an unfolded graph to illustrate how w^(L-2) indirectly affects C.", "Construct the appropriate chain rule expression that links how a change in w^(L-2) affects the cost function C", "From fig. 12 you can see the path connecting w^(L-2) to C. So we use the partial derivative of all the terms in the path in the chain rule. But we just worked out an expression for how a change in a^(L-1) affects C (see fig. 10). So we replace the last three partial derivatives with a single partial derivative because we already have an expression for it.", "The first two terms are very similar to before, but now we just replace the minus 1 from the superscripts in fig. 5 . Doing this allows us to obtain the following expression for the gradient of C w.r.t the weight w^(L-2).", "You can see that if we had a deeper network with a layer even further back, the expression for this would call the gradient dC/da^(L-2), and the one before that would call dC/da^(L-3), etc. Therefore, by calculating the derivative of C w.r.t. the activation at each layer we can recursively calculate the gradient of C w.r.t. any weight or bias in the network. This process is called back propagation because you are literally propagating the gradient back from the final layer.", "If you\u2019ve gotten this far then you\u2019ll be happy to hear that the above is 90% of back-propagation. We just performed all of the above for the simple case of a 1\u20131\u20131 network. To generalise it to a network of arbitrary size just means we have to add some summations and some more indices to keep track of which neuron in a layer each term corresponds to. But the equations we just derived take the exact same form.", "Now let\u2019s consider how we must modify the equations from above to apply to a general network with many neurons in each layer rather than just one.", "Fig. 14 shows such a network where there is L layers, and layer L has N_L neurons. For instance if N_L=5 then there is 5 neurons in the final layer and if N_3 = 7 that means that layer 3 has 7 neurons. Also shown is one of the weights connecting neurons in different layers. As before it has a superscript to denote which layer it corresponds to and also has a subscript to show which neuron in each layer it connects. For example, the weight in the figure w_21 connects neuron 1 in layer L-1 to neuron 2 in layer L.", "[NOTE: I am only going to consider how the equations for the weights change as it will be the same procedure for the bias equations.]", "Let\u2019s first see how the terms for forward propagation change between the 1\u20131\u20131 case and the general case for the cost, weighted sum, and activation for the final layer.", "In the 1\u20131\u20131 case, the cost function only depended on the value of a single neuron in the output layer. But now in the more general case, we have N_L neurons in the final layer. In our example of digit recognition N_L=10 \u2014 one neuron for each digit. So we need to sum the squared error of each of the neurons in the final layer. Lastly, because we are using mean squared error as our cost function we divide by the number of neurons in the layer.", "For the weighted sum in the general case, there is now contributions from all the neurons in the previous layer (L-1) \u2014 this is the sum over k. Furthermore, because there is multiple neurons in a layer we have to make sure we specify which one we are referring to so we add the subscript j to the account for this. As always, this is easiest to understand with a diagram and a simplified example where both the final and the penultimate layer has 3 neurons as in fig. 16.", "So if we consider what terms contribute to the weighted sum of the second neuron in the final layer we see that each of the activations in the previous layer contribute. They are multiplied by a weight which connects them to the second neuron in the final layer so we give the weight a subscript with the two numbers corresponding to those two neurons. You also add a single bias term to the weighted sum (not shown).", "Finally, the third term in fig. 15 does not change so you put this weighted sum through a nonlinear function to obtain the activation of the neuron. The only thing we do again is add a subscript so show which neuron in a layer we are referring to. For example, a\u2081^(L) is the activation of the first neuron in the final layer (top right neuron in fig. 16), and likewise a\u2083^(L) is the activation of the third neuron in the final layer (bottom right in fig. 16).", "Great, we have adjusted the terms to work out all the activations and eventually the cost to use in forward propagation. Now we need to do the same for the gradients to use in back propagation.", "As before, I will state the result first and then we will see the reasons for the adjustments.", "The gradient of C w.r.t the weight from the (L-1) layer doesn\u2019t change much except we add a subscript as we did in the adjustment of the forward propagation equations.", "The term that does change is the gradient of C w.r.t the activation of the previous layer. The reasoning is much the same as before when we adjusted the weighted sum equation and is clearer with a diagram and simplified 3\u20133\u20133 network.", "Fig. 18 shows how the activation from a single neuron in the (L-1) layer now affects all activations of the final layer. All these activations are then summed over to calculate the cost C. Therefore, in this example, changing a\u2081^(L-1) will affect all N_L neurons in the next layer, which will affect the cost. This is why the gradient is now a sum over the neurons in the next layer to account for all the channels that will be affected by a change to this activation value.", "The key thing is that it is exactly the same form as before, we just introduce summations and subscripts to account for multiple neurons per layer.", "Finally, we go one layer further back into this network and ask, what happens if I change a weight in layer (L-2)?", "Let\u2019s first consider which terms we expect to be affected by changing the weight connecting the first neuron in layer (L-2) to the first neuron in layer (L-1). Another diagram to the rescue!", "Changing the weight between the first neurons in layers (L-2) and (L-1) changes the activation of the first neuron in layer (L-1). But, as we just saw above, this now affects the cost through N_L channels since it is connected to all neurons in the final layer. So we expect that the gradient of C w.r.t this weight will contain a sum over these N_L channels.", "Fig. 20 shows the adjusted equation for the derivative of the cost function w.r.t. a weight in layer (L-2). If we do as we did before, and just adjust the expression from the 1\u20131\u20131 case with subscripts if may not seem like we have included these N_L channels.", "BUT, if we now input our expression from fig. 17 above for that last derivative on the right-side of fig. 20 we indeed see that the N_L channels is already included in this expression.", "We now follow exactly the same procedure as before whereby to work out the gradient of C w.r.t any weight in the network we just recursively find the gradient of the cost function w.r.t. all of the activations between the cost and the weight of interest. In other words, we back propagate the gradient calculations all the way back to the weight of interest.", "The same procedure is followed to get the gradient of C w.r.t. any of the biases in the network.", "Congratulations if you managed to understand all of that in one read. If this is the first time you are looking at these equations they will definitely seem very confusing with all the sub- and superscripts to keep hold of. But by looking at the network and following the channels through which a term will affect C you can reason where summations should occur. This then makes the equations look a lot less intimidating.", "The best thing is, because each gradient further back in the network depends on gradient terms after it in the network, you don\u2019t need to construct ridiculously long chain rule expressions as you already have the expressions you need from the previous layers.", "In this article we started off by using the simple 1\u20131\u20131 network to derive the general form of the equations for back propagation. This was a matter of unfolding the network to see explicitly the path from terms in the network to the cost function and then constructing the appropriate chain rule expression. Once we had this we could simply calculate exactly what these expressions would be. Then we saw how terms in the layer (L-1) depended on terms in layer L. Thus we could propagate our calculations back through the network by continually chaining terms from later layers together.", "Finally, we moved to the general case of a network with multiple and a variable amount of neurons per layer. The difference between the simple case and this one was:", "Don\u2019t get me wrong, the equations that underpin back-propagation are not easy to understand at first glance (or second, third, fourth, etc). But the actual mathematical tools that they represent are just derivatives and additions. The rest of it is just fancy book-keeping.", "I hope you enjoyed looking into the equations of the black box. See you in the next article.", "PhD student interested in the application of statistical learning, DS, ML, and DL to real world problems"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcf6714736abf&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@shanedesilva?source=post_page-----cf6714736abf--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Shane De Silva"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb843df4e54f4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&user=Shane+De+Silva&userId=b843df4e54f4&source=post_page-b843df4e54f4----cf6714736abf---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcf6714736abf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&user=Shane+De+Silva&userId=b843df4e54f4&source=-----cf6714736abf---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf6714736abf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&source=-----cf6714736abf---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-beginners-guide-to-neural-nets-5cf4050117cb", "anchor_text": "previous article"}, {"url": "https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/a/chain-rule-review", "anchor_text": "chain rule"}, {"url": "https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e", "anchor_text": "(e^-z/(1+e^-z)\u00b2)"}, {"url": "https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/", "anchor_text": "ReLU activation function"}, {"url": "https://giphy.com/gifs/reaction-spoilers-outlander-LSNqpYqGRqwrS", "anchor_text": "https://giphy.com/gifs/reaction-spoilers-outlander-LSNqpYqGRqwrS"}, {"url": "https://tenor.com/vemb.gif", "anchor_text": "https://tenor.com/vemb.gif"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----cf6714736abf---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----cf6714736abf---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/backpropagation?source=post_page-----cf6714736abf---------------backpropagation-----------------", "anchor_text": "Backpropagation"}, {"url": "https://medium.com/tag/data-science?source=post_page-----cf6714736abf---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----cf6714736abf---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcf6714736abf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&user=Shane+De+Silva&userId=b843df4e54f4&source=-----cf6714736abf---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcf6714736abf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&user=Shane+De+Silva&userId=b843df4e54f4&source=-----cf6714736abf---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf6714736abf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=post_page-----cf6714736abf--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb843df4e54f4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&user=Shane+De+Silva&userId=b843df4e54f4&source=post_page-b843df4e54f4----cf6714736abf---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7b227aa56f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&newsletterV3=b843df4e54f4&newsletterV3Id=e7b227aa56f&user=Shane+De+Silva&userId=b843df4e54f4&source=-----cf6714736abf---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Written by Shane De Silva"}, {"url": "https://medium.com/@shanedesilva/followers?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "163 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb843df4e54f4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&user=Shane+De+Silva&userId=b843df4e54f4&source=post_page-b843df4e54f4----cf6714736abf---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7b227aa56f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-maths-behind-back-propagation-cf6714736abf&newsletterV3=b843df4e54f4&newsletterV3Id=e7b227aa56f&user=Shane+De+Silva&userId=b843df4e54f4&source=-----cf6714736abf---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/diy-apache-spark-docker-bb4f11c10d24?source=author_recirc-----cf6714736abf----0---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=author_recirc-----cf6714736abf----0---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=author_recirc-----cf6714736abf----0---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Shane De Silva"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cf6714736abf----0---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/diy-apache-spark-docker-bb4f11c10d24?source=author_recirc-----cf6714736abf----0---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "DIY: Apache Spark & DockerSet up a Spark cluster in Docker from scratch"}, {"url": "https://towardsdatascience.com/diy-apache-spark-docker-bb4f11c10d24?source=author_recirc-----cf6714736abf----0---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "\u00b716 min read\u00b7May 7, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb4f11c10d24&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdiy-apache-spark-docker-bb4f11c10d24&user=Shane+De+Silva&userId=b843df4e54f4&source=-----bb4f11c10d24----0-----------------clap_footer----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/diy-apache-spark-docker-bb4f11c10d24?source=author_recirc-----cf6714736abf----0---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb4f11c10d24&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdiy-apache-spark-docker-bb4f11c10d24&source=-----cf6714736abf----0-----------------bookmark_preview----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cf6714736abf----1---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----cf6714736abf----1---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----cf6714736abf----1---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cf6714736abf----1---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cf6714736abf----1---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cf6714736abf----1---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----cf6714736abf----1---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----cf6714736abf----1-----------------bookmark_preview----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cf6714736abf----2---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----cf6714736abf----2---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----cf6714736abf----2---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cf6714736abf----2---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cf6714736abf----2---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cf6714736abf----2---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----cf6714736abf----2---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----cf6714736abf----2-----------------bookmark_preview----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-beginners-guide-to-neural-nets-5cf4050117cb?source=author_recirc-----cf6714736abf----3---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=author_recirc-----cf6714736abf----3---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=author_recirc-----cf6714736abf----3---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Shane De Silva"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----cf6714736abf----3---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/a-beginners-guide-to-neural-nets-5cf4050117cb?source=author_recirc-----cf6714736abf----3---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "A Beginners Guide to Neural NetsA dive into the \u2018black box\u2019"}, {"url": "https://towardsdatascience.com/a-beginners-guide-to-neural-nets-5cf4050117cb?source=author_recirc-----cf6714736abf----3---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": "\u00b712 min read\u00b7Mar 20, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5cf4050117cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-neural-nets-5cf4050117cb&user=Shane+De+Silva&userId=b843df4e54f4&source=-----5cf4050117cb----3-----------------clap_footer----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-beginners-guide-to-neural-nets-5cf4050117cb?source=author_recirc-----cf6714736abf----3---------------------b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cf4050117cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-neural-nets-5cf4050117cb&source=-----cf6714736abf----3-----------------bookmark_preview----b7d0e1d1_f12c_411c_9b89_0eea1a285d9b-------", "anchor_text": ""}, {"url": "https://medium.com/@shanedesilva?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "See all from Shane De Silva"}, {"url": "https://towardsdatascience.com/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----cf6714736abf----0-----------------bookmark_preview----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----1-----------------clap_footer----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----cf6714736abf----1-----------------bookmark_preview----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Rukshan Pramoditha"}, {"url": "https://medium.com/data-science-365?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Data Science 365"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Determining the Right Batch Size for a Neural Network to Get Better and Faster ResultsGuidelines for choosing the right batch size to maintain optimal training speed and accuracy while saving computer resources"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "\u00b74 min read\u00b7Sep 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-365%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----7a8662830f15----0-----------------clap_footer----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----cf6714736abf----0---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&source=-----cf6714736abf----0-----------------bookmark_preview----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----cf6714736abf----1---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----cf6714736abf----1-----------------bookmark_preview----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cf6714736abf----2---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----cf6714736abf----2---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----cf6714736abf----2---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----cf6714736abf----2---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cf6714736abf----2---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cf6714736abf----2---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----2-----------------clap_footer----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----cf6714736abf----2---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----cf6714736abf----2-----------------bookmark_preview----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----cf6714736abf----3---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://medium.com/@iamleonie?source=read_next_recirc-----cf6714736abf----3---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://medium.com/@iamleonie?source=read_next_recirc-----cf6714736abf----3---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Leonie Monigatti"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----cf6714736abf----3---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----cf6714736abf----3---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "A Visual Guide to Learning Rate Schedulers in PyTorchLR decay and annealing strategies for Deep Learning in Python"}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----cf6714736abf----3---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": "\u00b79 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24bbb262c863&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863&user=Leonie+Monigatti&userId=3a38da70d8dc&source=-----24bbb262c863----3-----------------clap_footer----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----cf6714736abf----3---------------------bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24bbb262c863&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863&source=-----cf6714736abf----3-----------------bookmark_preview----bd5f69c6_652e_4e8a_9e8f_cc1bb021d96e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cf6714736abf--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----cf6714736abf--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}