{"url": "https://towardsdatascience.com/zipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e", "time": 1683007992.08642, "path": "towardsdatascience.com/zipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e/", "webpage": {"metadata": {"title": "Zipping and Submitting PySpark Jobs in EMR Through Lambda Functions | Towards Data Science", "h1": "Zipping and Submitting PySpark Jobs in EMR Through Lambda Functions", "description": "I assume that you are already familiar with AWS Cloud platform, especially with Lambda and EMR services. I assume that you already have an EMR cluster running and know how to set up a lambda\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["I assume that you are already familiar with AWS Cloud platform, especially with Lambda and EMR services. I assume that you already have an EMR cluster running and know how to set up a lambda function. This article covers an end-to-end topic of creating a PySpark project and submitting it to EMR. At the end, this article results in a PySpark project called pyspark-seed that is ready to be cloned and further developed on top of it.", "My go to IDE for Python projects is PyCharm. Jupyter Notebook is always there for quick checks. To build the Python virtual environment I will go with venv. Venv is simple and comes preinstalled with your Python interpreter. For Python I will go with version 3.7; for PySpark I will go with version 2.4.5. A continuous integration configuration file is provided and is ready to get executed via GitLab Runner. I do also host the source code of this pyspark-seed project in GitHub due to larger community.", "Before even creating the project let us discuss about the deployment! Yes, deployment happens the last but its importance should be discussed at the beginning of the project. Why? Because most of the times, the way how you deploy the project affects the project structure and code organisation.", "In a PySpark project, you can deploy stand-alone scripts or you can deploy packed/zipped projects. Deploy stand-alone scripts if you have few simple jobs that do not share functionality among each other. Deploy a packed/zipped project when you have multiple jobs that share functionality among each other.", "When packing spark jobs written in Java or Scala you create a single jar file. If packed correctly, submitting this single jar file in EMR will run the job successfully. To submit a PySpark project in EMR you need to have two things:", "I have created a Python project called pyspark-seed. The structure of the project is as follows:", "I use venv to create the isolated Python environment. Python binaries inside this environment are identical to the ones in the Python you used to create this environment. Modules installed in this virtual environment are independent from the ones installed in your local/system Python. To create a Python environment, type the following commands in your project root directory (ie. /pyspark-seed).", "The first command creates a Python environment. This will make a directory named venv in your project structure. The second command will activate the Python environment created. The last command will run setup.py and install/setup the project.", "This file\u2019s responsibility is to properly setup your Python project. You can specify the name of your project, version, provide a description of your project, author name, packages and much more. A simple setup.py is as follows:", "Specifying the project version in __version__ variable, allows you to access it during CI and use it to generate a path, where you will store artefacts (i.e. seed_module and main.py) in s3. Accessing this variable is as simple as:", "A CI pipeline for a PySpark project usually has three base stages: build, test, and deploy.", "Python 3.7-stretch is used as base image. This version is required if you want to install PySpark and run PySpark tests during the test phase. This pipeline is linear. Every stage runs after the previous one finishes successfully. Stages build and test run automatically whereas deploy should be triggered manually for the deployment to happen. AWS credentials are stored as environment variables in GitLab. When storing artifacts in s3, we always overwrite the latest path content, with the latest changes.", "Every job should be written in a separate Python file. To keep things simple, every job should have one single function called process that receives at least spark_session, input_path and output_path as parameters. These parameters, the job name we want to run and other, are specified in the lambda function discussed at the next section. A simple template of a job is shown below.", "AWS Lambda is a serverless service. You can schedule lambda code runs through AWS CloudWatch, trigger code runs as response to an event or even trigger lambda functions on-demand through API calls. A lambda function that submits jobs to EMR is presented below. This lambda function runs in Python 3.7.", "I have defined main_path and modules_path that by default point at the latest version of the artefact. Arguments specific to your main function are passed in spark-submit after the main_path. I prefer setting all parameters in a dictionary, cast dictionary to string, and pass this whole string as a single parameter to the main. When received this string dictionary, i use ast module, to extract the dictionary out of it.", "This dictionary of parameters then is passed to run.py function, which sets up the spark session with configs provided and runs the job stated in parameters.", "Consider a use case where a single data file (size~3GB) is dumped in s3 raw data bucket every 20 min. Consider that an event listener is set to this bucket properties. This event listener listens for all object creation events. If an object is uploaded in this bucket, the listener catches it and triggers the target lambda function. This lambda function gets the object path from the event message, provides the job parameters, and submits a job in EMR. The following diagram shows this workflow from the beginning to the end.", "In this article, I have described the process of starting a PySpark project, creating a CI configuration file, deploy artifacts in S3 and submitting jobs in EMR through Lambda Functions. Most of the advice provided are taken directly from my personal experience using PySpark in production and research done. I have hosted the source code for this pyspark-seed project in Github. Lots of other details can be learned by exploring this repository yourself. Feel free to clone it and make it better.", "Of course that many aspect of this project can be done differently. I intended to provide this seed project as a starting point that can furthermore be developed. All questions, feedback and critiques are welcomed. I believe in the world where critiques drive change.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A Software Crafter on Daily Basis."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F46a58a496d9e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dardanx?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dardanx?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "Dardan Xhymshiti"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd5b24517a0ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&user=Dardan+Xhymshiti&userId=d5b24517a0ed&source=post_page-d5b24517a0ed----46a58a496d9e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46a58a496d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46a58a496d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@dnevozhai?utm_source=medium&utm_medium=referral", "anchor_text": "Denys Nevozhai"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://gitignore.io/", "anchor_text": "gitignore.io"}, {"url": "https://github.com/dardanxhymshiti/pyspark-seed", "anchor_text": "dardanxhymshiti/pyspark-seedContribute to dardanxhymshiti/pyspark-seed development by creating an account on GitHub.github.com"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----46a58a496d9e---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----46a58a496d9e---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/aws?source=post_page-----46a58a496d9e---------------aws-----------------", "anchor_text": "AWS"}, {"url": "https://medium.com/tag/serverless?source=post_page-----46a58a496d9e---------------serverless-----------------", "anchor_text": "Serverless"}, {"url": "https://medium.com/tag/big-data?source=post_page-----46a58a496d9e---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46a58a496d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&user=Dardan+Xhymshiti&userId=d5b24517a0ed&source=-----46a58a496d9e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46a58a496d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&user=Dardan+Xhymshiti&userId=d5b24517a0ed&source=-----46a58a496d9e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46a58a496d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F46a58a496d9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----46a58a496d9e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----46a58a496d9e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----46a58a496d9e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----46a58a496d9e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dardanx?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dardanx?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dardan Xhymshiti"}, {"url": "https://medium.com/@dardanx/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "173 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd5b24517a0ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&user=Dardan+Xhymshiti&userId=d5b24517a0ed&source=post_page-d5b24517a0ed--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2325acc43cb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzipping-and-submitting-pyspark-jobs-in-emr-through-lambda-functions-46a58a496d9e&newsletterV3=d5b24517a0ed&newsletterV3Id=2325acc43cb8&user=Dardan+Xhymshiti&userId=d5b24517a0ed&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}