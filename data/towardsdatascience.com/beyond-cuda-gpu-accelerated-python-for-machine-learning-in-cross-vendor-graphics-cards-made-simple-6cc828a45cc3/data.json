{"url": "https://towardsdatascience.com/beyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3", "time": 1683016386.751422, "path": "towardsdatascience.com/beyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3/", "webpage": {"metadata": {"title": "Beyond CUDA: GPU Accelerated Python for Machine Learning on Cross-Vendor Graphics Cards Made Simple | by Alejandro Saucedo | Towards Data Science", "h1": "Beyond CUDA: GPU Accelerated Python for Machine Learning on Cross-Vendor Graphics Cards Made Simple", "description": "Machine learning algorithms \u2014 together with many other advanced data processing paradigms \u2014 fit incredibly well to the parallel-architecture that GPU computing offers. This has driven massive growth\u2026"}, "outgoing_paragraph_urls": [{"url": "https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm.html", "anchor_text": "model parallelism", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Data_parallelism", "anchor_text": "data parallelism", "paragraph_index": 0}, {"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute Python framework", "paragraph_index": 1}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "main repository,", "paragraph_index": 3}, {"url": "https://github.com/EthicalML/vulkan-kompute/tree/master/examples/python", "anchor_text": "this link", "paragraph_index": 3}, {"url": "https://www.khronos.org/", "anchor_text": "Khronos Group", "paragraph_index": 5}, {"url": "https://github.com/tensorflow/tensorflow", "anchor_text": "Tensorflow", "paragraph_index": 6}, {"url": "https://github.com/pytorch/pytorch", "anchor_text": "Pytorch", "paragraph_index": 6}, {"url": "https://github.com/Tencent/ncnn", "anchor_text": "NCNN", "paragraph_index": 6}, {"url": "https://github.com/alibaba/MNN", "anchor_text": "MNN", "paragraph_index": 6}, {"url": "https://github.com/EthicalML/vulkan-kompute#vulkan-kompute", "anchor_text": "The Kompute Python package", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units", "anchor_text": "GPGPU framework", "paragraph_index": 8}, {"url": "https://github.com/EthicalML/vulkan-kompute/tree/master/examples/python", "anchor_text": "provided in the repository", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc", "anchor_text": "this other tutorial", "paragraph_index": 15}, {"url": "https://www.khronos.org/opengl/wiki/SPIR-V", "anchor_text": "SPIR-V is the intermediate representation", "paragraph_index": 25}], "all_paragraphs": ["Machine learning algorithms \u2014 together with many other advanced data processing paradigms \u2014 fit incredibly well to the parallel-architecture that GPU computing offers. This has driven massive growth in the advancement and adoption of graphics cards for accelerated computing in recent years. This has also driven exciting research around techniques that optimize towards concurrency, such as model parallelism and data parallelism.", "In this article you\u2019ll learn how to write your own GPU accelerated algorithms in Python, which you will be able to run on virtually any GPU hardware \u2014 including non-NVIDIA GPUs. We\u2019ll introduce core concepts and show how you can get started with the Kompute Python framework with only a handful of lines of code.", "First we will be building a simple GPU Accelerated Python script that will multiply two arrays in parallel which this will introduce the fundamentals of GPU processing. We will then write a Logistic Regression algorithm from scratch on the GPU. Below are the core topics that we will cover, together with the respective resource links:", "Only basic programming experience is required for anyone reading this article, no knowledge of GPU computing is required. You can find the full code in the main repository, and we also created an online Google Colab Notebook where you\u2019ll be able to run the example with a GPU for free \u2014 you can find it in this link.", "There are two parts to the Python framework we will be using today, both which are in the name itself \u2014the Vulkan SDK, and Kompute.", "The Vulkan SDK is an Open Source project led by the Khronos Group, a consortium consisting of numerous tech companies that have come together to work towards defining and advancing the open standards for mobile and desktop media (and compute) technologies.", "A large number of high profile (and new) machine learning frameworks such as Google\u2019s Tensorflow, Facebook\u2019s Pytorch, Tencent\u2019s NCNN, Alibaba\u2019s MNN \u2014between others \u2014 have been adopting Vulkan as their core cross-vendor GPU computing SDK. This is primarily to enable the frameworks for cross platform and cross vendor graphics card support.", "As you can imagine, the Vulkan SDK provides very low-level C / C++ access to GPUs, which allows for very specialized optimizations. This is a great asset for GPU computing\u2014 the main disadvantage is the verbosity involved, requiring 500\u20132000+ lines of C++ code to only get the base boilerplate required to even start writing the application logic. This can result in expensive developer cycles and errors that can lead to larger problems. This was one of the main motivations for us to start the Kompute project.", "The Kompute Python package is built on top of the Vulkan SDK through optimized C++ bindings, which exposes Vulkan\u2019s core computing capabilities. Kompute is the Python GPGPU framework that we will be using in this tutorial to build the GPU Accelerated machine learning algorithms.", "In order for us to start using the Kompute Python Package we will need to install its required dependencies. The package is available in Pypi, which means we can install it with pip install. You will however require the following key components installed on your machine before being able to use it:", "Once you have these dependencies installed, you can simply run:", "You should now see a success message confirming that the Kompute Python package has been installed. You can try it out yourself in the Google Colab Notebook provided in the repository, which you can set up with a GPU.", "To build our first simple array-multiplication GPU computing application using Kompute, we will write a simple python program that will do the following:", "The full Python code required is quite minimal, so we are able to show the full script below. We\u2019ll break down each of the sections in more detail.", "First, we\u2019ll create our Kompute Manager, which is in charge of creating and managing all the underlying Vulkan resources.", "As you can see, here we are initializing our Kompute Manager, which by default creates all the base Vulkan resources on Device 0 (in my case it\u2019s an NVIDIA card, and Device 1 is my integrated graphics card). For more advanced use-cases it\u2019s also possible to provide the underlying GPU queues that you\u2019d like to load \u2014 in this other tutorial we show how this can lead to significant speedups, but this is outside of scope of this article.", "We will now create the Kompute Tensors that will be used for input and output. These will hold the data required which will be mapped into the GPU to perform this simple multiplication.", "When the tensors are created, the data is only initialized in the local CPU memory (aka RAM), but in order to use it in the GPU we\u2019ll have to map the data into the GPU memory.", "Now that we have our Tensors created with local data, we will map the data into the GPU. For this we will use the eval_tensor_create_def, which will initialize the underlying Vulkan buffer and GPU memory, and perform the respective mapping into the GPU.", "Now that we\u2019ve initialized the necessary Kompute Tensor components and they are mapped in GPU memory, we can add the Kompute Algorithm that will be executed in the GPU. This is referred to as the \u201cshader\u201d code, which we build using the pyshader library. You can see the full shader code below, and we\u2019ll break down each of the section below.", "The GPU shader code can be defined as a Python function with the decorator @ps.python2shader , and the parameters in this case include the variables that we\u2019ll be using. This includes the Tensor inputs and outputs that we\u2019ll be processing \u2014 the parameter format is the following:", "In this case we are using Tensors with float values, which inherently would be equivalent to the ps.Array value, with ps.f32 float values as elements.", "The first parameter index is of type GlobalInvocationId , and provides the shader with the current index location in the execution GPU dispatch structure. This is what allows us to know what index in the parallel execution loop we are currently running, which is what we extract from the component i = index.x \u2014 the reason why here we select x is because the execution index can be defined as a vec3 component, where there would be execution indices for inedx.x , index.y and index.z .", "The final component is the actual equation used, which in this case is a simple multiplication of the first and second parameter, and stored in the output (third) parameter.", "In order to run the shader above we will use the eval_algo_data_def function. The parameters required for this Kompute Operation includes the Tensors to bind into the GPU instructions, as well as the GPU shader code that we defined in the Python function above.", "It\u2019s worth mentioning that Kompute allows the user to also pass the shader as a raw glsl string, or alternatively a file path to a SPIR-V binary or raw glsl/hlsl file. For context, SPIR-V is the intermediate representation that GPUs can use to process relevant operations.", "Once the algorithm runs successfully, the result data will now be we held in the GPU memory of our output tensor. We can now use the function eval_tensor_sync_local_def to sync the Tensor GPU memory into the local tensor.", "Finally, we can print the output data of our tensor.", "When you run this, you will see the values of your output tensor printed. That\u2019s it, you\u2019ve written your first Kompute!", "Although it may not seem obvious, the above introduced some intuition around core concepts and design thinking in GPU computing, whilst still abstracting a couple of the more in-depth concepts. In the following sections we will be providing more concrete terminology and at the end we\u2019ll also outline a set of articles to dive into if you\u2019re interested to learn more.", "Now we\u2019ll look into the more advanced GPU compute use-case, specifically implementing the \u201chello world of machine learning\u201d: logistic regression. Before we cover the implementation we will provide some intuition on the concepts and the terminology that we\u2019ll be using throughout the following sections.", "In machine learning we always have two stages, training and inference. In the diagram below you can see the two simplified flows. At the top is the training flow, where you identify some data, extract some features, and train a model until you are happy with the accuracy. Once you have a trained model, you persist the model \u201cweights\u201d and deploy the model into the second workflow, where the model would perform inference on unseen data.", "In this case we will have an input dataset X , where each element is a pair xi and xj . Our input data will be the following:", "With this input data, the expected target value Y to be predicted will be the following:", "Our core objective in machine learning is to learn using this training data to find the function (and parameters) that will allow us to predict values Y from new \u201cpreviously unseen\u201d inputs.", "It\u2019s worth noting that the predicted values will be defined as \u0177 , which are specifically the values computed with our \u201cprediction\u201d function, distinct to the \u201ctrue\u201d or \u201cactual\u201d values of Y that we defined above.", "The functions that we will be using for logistic regression will be the following:", "And the parameters that we\u2019ll be looking to learn with our machine learning algorithm are:", "There is also the surrounding function \u03c3 which is the sigmoid function. This function forces our input to be closer to 0 or 1, which could be intuitively seen as the probability of our prediction to be \u201ctrue\u201d or \u201cfalse\u201d, and is defined as following:", "This is now the prediction/inference function that will allow us to process predictions from new data points. If we say for example that we have a new unseen set of inputs X = { (0, 1) }, and we assume that the learned parameters were W = (1, 1), b = 0 after running our machine learning algorithm through our training data (which we\u2019ll do later on), then we\u2019ll be able to run this through our prediction function by substituting the values as follows:", "In this case the prediction is 0.73..., which would be a positive prediction. This of course is just to demonstrate what our inference function will look like once we learn the parameters W and b.", "The way that we will be learning the parameters is by performing a prediction, calculating the error, and then re-adjusting the weights accordingly. The method used to \u201cre-adjust\u201d the weights based on the \u201cprediction error\u201d will be done by leveraging gradient descent. This will be repeated multiple times to find more accurate parameters.", "For this we will need to use the derivatives of each of the formulas. The first one, which is the derivative of our linear mapping function z is using the partial derivatives of the variables w, z and b. First, the partial derivative \u2202z:", "Where the variables are defined as follows:", "Similarly the derivatives for w and b respectively are the following:", "In this case m is the total number of input elements.", "We will now be able to re-adjust the parameters using the above as follows:", "In this case \u03b8 is the learning rate, which as the name suggests controls the ratio by which the parameters will be modified on each iteration. Intuitively, the smaller, the more iterations it will be required for the algorithm to converge, however if the learning rate is too big, it will overshoot, leading to never being able to converge (from the image above you can imagine it will keep bouncing from side to side never reaching the bottom).", "In order for us to calculate loss, we will be using the log loss function, known also as cross-entropy loss function. This function is defined as follows:", "The function itself is set up such that the larger the difference between the predicted class and the expected class, the larger the error (you can see how much it punishes if the predicted class is on the complete different label).", "The loss function will provide us an idea of the improvement of our algorithm across iterations.", "Finally, one of the most important points here will be the intuition behind how we can leverage the parallel architecture of the GPU to optimize computation. In this case, we\u2019ll be able to do it by processing multiple input parameters at the same time, referred to as a micro-batch, and then re-adjusting the parameters in batch. This is known as data-parallelization, and is one of many techniques available. In the next section we will see how this is implemented, namely passing a mini-batch of inputs, storing the weights, and then re-adjusting them before the next iteration.", "Note: In this post we won\u2019t delve into much detail, nor best practices on machine learning, however at the end of the article we will be listing a broad range of sources for people interested to take their machine learning (or GPU compute) knowledge to the next level.", "Now that we have covered some of the core concepts, we will be able to learn about the implementation.", "First we will start with the GPU compute shader, which is the code that will be executed in the GPU. The full shader is outlined below, and we\u2019ll be breaking down each section in detail to explain what each part is doing.", "First we define all input parameters that are analogous to the input and output components we mentioned in the previous sections.", "If you remember, at the end of the last section we mentioned how we will be leveraging the concept of micro-batches in order to use the parallel architecture of GPU processing. What this means in practice, is that we will be passing multiple instances of X to the GPU to process at a time, instead of expecting the GPU to process it one by one. This is why we see that above we have an array for xi, xj, y, wOuti, wOutj, andbOut respectively.", "We also receive the constant M, which will be the total number of elements \u2014 if you remember this parameter will be used for the calculation of the derivatives. We will also see how these parameters are actually passed into the shader from the Python Kompute side.", "Now that we have all the input and output parameters defined, we can start defining the core logic, which will contain the implementation of our machine learning training algorithm.", "We will need to keep track of the current index of the global invocation. Since the GPU executes in parallel, each of these runs will be running directly in parallel, so this allows the current execution to consistently keep track of what iteration index is currently being executed.", "We now can start preparing all the variables that we\u2019ll be using throughout the algorithms. All our inputs are buffer arrays, so we\u2019ll want to store them in vec2 and float32 variables.", "In this case we\u2019re basically making explicit the variables that are being used for the current \u201cthread run\u201d. The GPU architecture consists of slightly more nuanced execution structures that involve thread blocks, memory access limitations, etc \u2014 however we won\u2019t be covering these in this article.", "Now we get into the more fun part \u2014 implementing the inference / predict logic. Below we will implement the inference logic to calculate \u0177, which involves both the linear mapping function, as well as the sigmoid function which we defined above.", "Now that we have y_hat, we can now use it to calculate the derivatives (\u2202z, \u2202w and \u2202b), which in this case are the derivative of the currently-executed index input element.", "Using the expected prediction output and the calculated prediction output we are now able to compute the loss for the current iteration. As covered above, we are using the log loss (cross entropy) function to calculate the loss.", "Finally we are able to pass all respective calculated metrics to our output buffers. This will allow us to re-adjust for the next iteration.", "We\u2019ve now finished the shader that will enable us to train a Logistic Regression algorithm in the GPU \u2014we will now cover the rest of the logic that will call this shader and orchestrate the machine learning training and inference. The full script is outlined below, and you can also try it in the Google Colab notebook with a GPU.", "We will be using a few more advanced components from Kompute, which can be more intuitively visualised in the diagram below.", "At the core of Kompute are Kompute \u201cSequences\u201d and \u201cOperations\u201d, which are used for GPU actions. A Kompute Section can record and execute a batch of Kompute Operations for more efficient processing. In this example we will be leveraging Sequences to manage more efficient execution of the machine learning processing.", "Similar to the example above, we will be will setting up the following steps:", "As you can see this is more involved than the simpler example we used above. In this case we will use the Kompute Sequence instead of the Kompute Manager directly, as we want to have deeper control on the commands that can be recorded to send in batch to the GPU. We will discuss this in more detail as we cover each of the steps. Let\u2019s get started.", "We will be creating the Kompute Manager with the device 0 explicitly defined \u2014 you can define another device as required.", "Now we\u2019ll be creating all the tensors required. In this sub-section you will notice that we will be referencing all the buffers/arrays that are being used in the shader. We\u2019ll also cover how the order in the parameters passed relates to the way data is bound into the shaders so it\u2019s accessible.", "We also store them in a list params for easier access:", "The Kompute Tensor initialisation is quite standard so we\u2019ll be able to do this step directly through the manager as we did in the simple array multiplication example previously.", "In this section we will want to clear the previous recordings of the Kompute Sequence and begin recording a set of sequences. You will notice that unlike the previous section, in this case we won\u2019t be running the eval() straight away as we\u2019ll have to first record the operations.", "You will also notice that we will be recording three types of Kompute Operations through separate functions:", "Now that we have the command recorded, we can start running executions of these pre-loaded commands. In this case, we will be running the execution of a micro-batch iteration, followed by updating the parameters locally, so they are used in the following iteration.", "We now have a trained logistic regression model, or at least we\u2019ve been able to optimize its respective function to identify suitable parameters. We are now able to print these parameters and use the parameters for inference in unseen datasets.", "You are able to find this entire example in the example repository, which you\u2019ll be able to run and extend.", "Congratulations, you\u2019ve made it all the way to the end! Although there was a broad range of topics covered in this post, there is a massive amount of concepts that were skimmed through. These include the underlying Vulkan concepts, GPU computing fundamentals, machine learning best practices, and more advanced Kompute concepts. Luckily, there are a broad range of resources online to expand your knowledge on each of these. Some links I recommend as further reading include the following:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Chief Scientist @ The Institute for Ethical AI & Machine learning | Engineering Director @ Seldon | Member at Large @ ACM | Building the future of production ML"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6cc828a45cc3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278----6cc828a45cc3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cc828a45cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cc828a45cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm.html", "anchor_text": "model parallelism"}, {"url": "https://en.wikipedia.org/wiki/Data_parallelism", "anchor_text": "data parallelism"}, {"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute Python framework"}, {"url": "https://pypi.org/project/kp/", "anchor_text": "Kompute python package"}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/master/python/test/test_array_multiplication.py", "anchor_text": "Array Multiplication Example"}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/master/python/test/test_logistic_regression.py", "anchor_text": "Logistic Regression Example"}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "main repository,"}, {"url": "https://github.com/EthicalML/vulkan-kompute/tree/master/examples/python", "anchor_text": "this link"}, {"url": "https://streamhpc.com/blog/2017-05-04/what-is-khronos-as-of-today/", "anchor_text": "StreamHPC"}, {"url": "https://www.khronos.org/", "anchor_text": "Khronos Group"}, {"url": "https://github.com/tensorflow/tensorflow", "anchor_text": "Tensorflow"}, {"url": "https://github.com/pytorch/pytorch", "anchor_text": "Pytorch"}, {"url": "https://github.com/Tencent/ncnn", "anchor_text": "NCNN"}, {"url": "https://github.com/alibaba/MNN", "anchor_text": "MNN"}, {"url": "https://github.com/EthicalML/vulkan-kompute#vulkan-kompute", "anchor_text": "The Kompute Python package"}, {"url": "https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units", "anchor_text": "GPGPU framework"}, {"url": "https://ethicalml.github.io/vulkan-kompute/", "anchor_text": "Documentation"}, {"url": "https://tulip.labri.fr/TulipDrupal/?q=node/1081", "anchor_text": "Windows"}, {"url": "https://vitux.com/how-to-install-cmake-on-ubuntu-18-04/", "anchor_text": "Linux (Ubuntu)"}, {"url": "https://stackoverflow.com/a/59825656/1889253", "anchor_text": "Mac"}, {"url": "https://vulkan.lunarg.com/sdk/home", "anchor_text": "official website"}, {"url": "https://github.com/EthicalML/vulkan-kompute/tree/master/examples/python", "anchor_text": "provided in the repository"}, {"url": "https://towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc", "anchor_text": "this other tutorial"}, {"url": "https://www.khronos.org/opengl/wiki/SPIR-V", "anchor_text": "SPIR-V is the intermediate representation"}, {"url": "https://www.datasciencecentral.com/profiles/blogs/why-logistic-regression-should-be-the-last-thing-you-learn-when-b", "anchor_text": "DS Central"}, {"url": "https://mi-academy.com/2018/10/04/the-history-of-gradient-descent/", "anchor_text": "ML Academy"}, {"url": "https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/", "anchor_text": "from ML Mastery"}, {"url": "https://ethicalml.github.io/vulkan-kompute/overview/reference.html", "anchor_text": "Architecture Design"}, {"url": "https://kompute.cc/", "anchor_text": "Kompute Documentation"}, {"url": "https://ethical.institute/mle.html", "anchor_text": "The Machine Learning Engineer Newsletter"}, {"url": "https://github.com/EthicalML/awesome-production-machine-learning/", "anchor_text": "Awesome Production Machine Learning"}, {"url": "https://www.fast.ai/2018/09/26/ml-launch/", "anchor_text": "Introduction to ML for Coders course"}, {"url": "https://medium.com/tag/python?source=post_page-----6cc828a45cc3---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6cc828a45cc3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/gpu?source=post_page-----6cc828a45cc3---------------gpu-----------------", "anchor_text": "Gpu"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----6cc828a45cc3---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/kompute?source=post_page-----6cc828a45cc3---------------kompute-----------------", "anchor_text": "Kompute"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cc828a45cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&user=Alejandro+Saucedo&userId=32de426f7278&source=-----6cc828a45cc3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cc828a45cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&user=Alejandro+Saucedo&userId=32de426f7278&source=-----6cc828a45cc3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cc828a45cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6cc828a45cc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6cc828a45cc3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6cc828a45cc3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/@AxSaucedo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "616 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1b4684c4c42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3&newsletterV3=32de426f7278&newsletterV3Id=b1b4684c4c42&user=Alejandro+Saucedo&userId=32de426f7278&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}