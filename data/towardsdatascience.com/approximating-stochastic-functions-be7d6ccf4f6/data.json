{"url": "https://towardsdatascience.com/approximating-stochastic-functions-be7d6ccf4f6", "time": 1683016460.161469, "path": "towardsdatascience.com/approximating-stochastic-functions-be7d6ccf4f6/", "webpage": {"metadata": {"title": "Approximating stochastic functions | by Nicolas Arroyo Duran | Towards Data Science", "h1": "Approximating stochastic functions", "description": "Neural networks are universal function approximators. Which means that having enough hidden neurons a neural network can be used to approximate any continuous function. Real world data, however\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/narroyo1/sffnn", "anchor_text": "github.com/narroyo1/sffnn", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Universal_approximation_theorem", "anchor_text": "universal function approximators", "paragraph_index": 1}, {"url": "https://www.kaggle.com/usdot/flight-delays", "anchor_text": "2015 Flight Delays and Cancellations", "paragraph_index": 1}, {"url": "https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/", "anchor_text": "Logistic Regression with Maximum Likelihood Estimation", "paragraph_index": 3}, {"url": "https://narroyo1.github.io/sffnn/#goal-2", "anchor_text": "Goal 2", "paragraph_index": 27}, {"url": "https://narroyo1.github.io/sffnn/#goal-1", "anchor_text": "Goal 1", "paragraph_index": 30}, {"url": "https://en.wikipedia.org/wiki/Earth_mover%27s_distance", "anchor_text": "wikipedia.org", "paragraph_index": 49}, {"url": "https://en.wikipedia.org/wiki/Earth_mover%27s_distance", "anchor_text": "EMD", "paragraph_index": 50}, {"url": "https://narroyo1.github.io/sffnn/#goal-1", "anchor_text": "Goal 1", "paragraph_index": 52}, {"url": "https://narroyo1.github.io/sffnn/#goal-2", "anchor_text": "Goal 2", "paragraph_index": 59}, {"url": "http://lib.stat.cmu.edu/datasets/houses.zip", "anchor_text": "California housing dataset", "paragraph_index": 71}], "all_paragraphs": ["You can reproduce the experiments in this article by cloning github.com/narroyo1/sffnn", "Neural networks are universal function approximators. Which means that having enough hidden neurons a neural network can be used to approximate any continuous function. Real world data, however, often has noise that in some cases makes producing a single deterministic value prediction insufficient. Take for example the dataset in Fig. 1a, it shows the relation between the departure delay and the arrival delay for flights out of JFK International Airport over a period of one year (Subset of 2015 Flight Delays and Cancellations).", "Fig. 1a also shows the prediction of a fully trained neural network that does a good job of approximating the mean value and does provide information about the trend of the dataset. However, it does not help answer questions like given a departure delay, what is the maximum expected arrival in X% of the flights? or given a departure delay, what is the probability that the arrival delay will be longer than Y? or even more interesting, write a model that samples arrival delay values for given departure delays with the same distribution as the real thing.", "There are methods to solve this problem, for example, assuming the model in Fig 1a estimates the mean, the standard deviation for the entire data set can be calculated and with those parameters you can produce the expected normal distribution. And if the variance is not constant, that is if the variance changes across the input space, you could use Logistic Regression with Maximum Likelihood Estimation which in a nutshell trains a model that predicts the parameters for a specific distribution function (for example the mean and the standard deviation of the normal or gaussian distribution) at a given input. The problem is that it relies on beforehand knowledge of the dataset distribution, which might be difficult in some cases or too irregular to match a known distribution.", "In the case of the departure to arrival delays dataset, we can observe from the plot that the distribution appears to be similar to the normal distribution, so it makes sense to build a Maximum Likelihood Estimation model trying to calculate the parameters of a normal distribution. Fig 1b shows a plot of a fully trained model showing the mean, the mean plus/minus the standard deviation and the mean plus/minus twice the standard deviation. The error of this model is of 2.48% which is quite good. However, the dataset\u2019s distribution is not perfectly normal, you can see that the upper tail is slightly longer than the lower tail in addition to other imperfections, which is why the accuracy is not better.", "This article presents a generic approach to training probabilistic machine learning models that will produce distributions that adapt to the real data with any distribution it may have, even branching distributions or distributions that change form across the input space.", "Given that the function producing the data has a specific distribution Y at input x \u2208 X we can define the target function, or the function we actually want to approximate, as y \u223c Y\u2093. We want to create an algorithm capable of sampling an arbitrary number of data points from Y\u2093 for any given x \u2208 X.", "To do this we introduce a secondary input z that can be sampled from a uniformly distributed space Z by the algorithm and fed to a deterministic function f such that P(Z \u2264 z) = P(Y\u2093 \u2264f(x, z)).", "Or put another way, we want a deterministic function that for any given input x, maps a random (but uniform) variable Z to a dependent random variable Y\u2093.", "The proposed model to approximate Y\u2093 is an ordinary feed forward neural network that in addition to an input x takes an input z that can be sampled from Z.", "At every point x \u2208 X we want our model f(x, z \u223c Z) to approximate the Y\u2093 distribution to an arbitrary precision. Let\u2019s picture f(x, z \u223c Z) and Y\u2093 as 2-dimensional (in the case where X and Z are both 1-dimensional) pieces of fabric, they can stretch and shrink in different measures at different regions, decreasing or increasing their densities respectively. We want a mechanism that stretches and shrinks f(x, z \u223c Z) in a way that matches the shrinks and stretches in Y\u2093.", "In Fig 2 we can see how the trained model output stretches and shrinks little by little on each epoch until it matches target function.", "Going on with the stretching and shrinking piece of fabric analogy, we want to put \u201cpins\u201d into an overlaying fabric (our model) so that we can superimpose it over the underlying fabric (the target data set) that we are trying to match. We will put these pins into fixed points in the overlaying fabric but we will move them to different places of the underlying fabric as we train the model. At first we will pin them to random places on the underlying fabric. As we observe the position of the pins on the underlying fabric relative to the overlaying fabric we will move them slightly upwards or downwards to improve the overlaying fabric\u2019s match on the underlying fabric. Every pin will affect its surroundings in the fabric proportionally to distance from the pin.", "We\u2019ll start by putting 1 pin at a fixed position in any given longitude of the overlaying fabric and at the midpoint latitude across the fabric\u2019s height. We\u2019ll then make many observations in the underlying fabric at the same longitude, that is we will randomly pick several locations at the vertical line that goes through the selected pin location.", "For every observed point, we\u2019ll move the pin position on the underlying fabric (keeping the same fixed position on the overlaying fabric) a small predefined distance downwards if the observed point is below its current position, and we\u2019ll move it upwards if it is above it. This means that if there are more observed points above the pin\u2019s position in the underlying fabric the total movement will be upwards and vice versa if there are more observed points below it. If we repeat this process enough times, the pin\u2019s position in the underlying fabric will settle in a place that divides the observed points by half, that is the same amount of observed points are above it as below it.", "Why do we move the pin a predefined distance up or down instead of a distance proportional to the observed point? The reason is that we are not interested in matching the observed point. Since the target dataset is stochastic, matching a random observation is pointless. The interesting information we get from the observed points is whether or not the pin divides them by half (or by another specific ratio)", "Fig 3 shows how the pin comes to a stable position dividing all data points in half because the amount of movement for every observation is equal for data points above and data points below. If the predefined distance of movement for observations above is different from the predefined distance of movement for observations below then the pin would settle in a position dividing the data points by a different ratio (different than half). For example, let\u2019s try having 2 pins instead of 1, the first one will move 1 distance for observations above it and 0.5 distance for observations below, the second one will do the opposite. After enough iterations the first one should settle at a position that divides the data points by 1/3 above and 2/3 below while the second pin will divide by 2/3 above and 1/3 below. This means we\u2019ll have 1/3 above the first pin, 1/3 between both pins and 1/3 below the second pin like Fig 4 shows.", "If a pin divides the observed data points in 2 groups of sizes a and b and after training its fixed position settles in the underlying fabric in the a/(a+b) latitude from the top, we have a single point mapping between the 2 fabrics, that is at this longitude the densities above and below the pin are equal in both pieces of fabric. We can extrapolate this concept and use as many pins as we want in order to create a finer mapping between the 2 pieces of fabric.", "We\u2019ll start by selecting a fixed set of points in Z of size S that we will call z-samples. We can define this set as:", "The predictive model will be defined as:", "Here x will be any input tuple from the input domain, z will be a sample from uniform random variable Z and \u03b8 is the internal state of the model, or the weight matrix.", "Then we define the prediction error for any input x for a specific z \u2208 Z as:", "That is, the difference between the real data cumulative probability distribution and the predicted cumulative probability distribution.", "Now we can define our training goals as:", "In other words, we want that for every z\u2019 in z\u209b\u2090\u2098\u209a\u2097\u2091\u209b and across the entire X input space the absolute error |E(z\u2019)| is minimized. This first goal gives us an approximate discrete finite mapping between the z-samples set and Y\u2093. Even if it doesn\u2019t say anything about all the points z\u0302 in Z that are not in z\u209b\u2090\u2098\u209a\u2097\u2091\u209b.", "This second goal gives us that for any given x in X, f is a monotonically increasing function in Z.", "Both of these goals will be tested empirically during the testing step of the training algorithm.", "For any point z \u223c Z and with z\u2019 and z\u2019\u2019 being the z-samples that are immediately smaller and greater respectively, and assuming Goal 2 is met we have:", "and replacing the prediction error we have:", "And if we substract P(Z \u2264 z) from every term we have:", "Assuming Goal 1 is met we know that E(z\u2019) and E(z\u2019\u2019) are small numbers which leaves P(Z \u2264 z\u2019) \u2014 P(Z \u2264 z) and P(Z \u2264 z\u2019\u2019) \u2014 P(Z \u2264 z) as the dominant factors. The distance between any z and its neighboring z-samples can be minimized by increasing the number of z-samples or S. In other words the maximum error of f can be arbitrarily minimized by a sufficiently large S.", "For any given x in X and any z\u2019 in z\u209b\u2090\u2098\u209a\u2097\u2091\u209b we want f to satisfy P(Y\u2093 \u2264 f(x, z\u2019)) = P(Z \u2264 z\u2019). For this purpose we\u2019ll assume that we count with a sufficiently representative set of samples in Y\u2093 or y\u209c\u1d63\u2090\u1d62\u2099 \u223c Y\u2093.", "For a given x \u2208 X and having z\u2019 as the midpoint in Z (i.e. z\u2019 \u2208 Z s.t. Pr(z\u2019 \u2264 Z) = 0.5) we could simply train f to change the value of f(x, z\u2019) a constant movement number M greater for every training example y \u2208 y\u209c\u1d63\u2090\u1d62\u2099 that was greater than f(x, z\u2019) itself and the same constant number smaller for every training example that was smaller (remember the 2 pieces of fabric and the pins analogy). This would cause after enough iterations for the value of f(x,z\u2019) to settle in a position that divides in half all training examples when the total movement equals 0.", "If instead of being Z\u2019s midpoint P(Z \u2264 z\u2019) \u2260 0.5 then the constant numbers of movement for greater and smaller samples have to be different.", "Let\u2019s say that a is the distance between z\u2019 and the smallest number in Z or Z\u2098\u1d62\u2099, and b the distance between z\u2019 and Z\u2098\u2090\u2093.", "Since a represents the amount of training examples we hope to find smaller than z\u2019 and b the amount of training examples greater than z\u2019 we need 2 scalars \u03b1 and \u03b2 to satisfy the following equations:", "These movement scalars will be the multipliers to be used with the constant movement M on every observed point smaller and greater than z\u2019 respectively. This first equation assures that the total movement when z\u2019 is situated at Z\u2098\u1d62\u2099 + a or Z\u2098\u2090\u2093 \u2014 b will be 0.", "This second equation normalizes the scalars so that the total movement for all z in z\u209b\u2090\u2098\u209a\u2097\u2091\u209b have the same total movement.", "This logic, however, breaks at the edges, that is when a z-sample is equal to Z\u2098\u1d62\u2099 or Z\u2098\u2090\u2093. At these values either a or b is 0 and if either of them is 0 then one of \u03b1 or \u03b2 is undefined.", "As a or b approach 0 \u03b1 or \u03b2 tend to infinity, one might be tempted to replace this with a large number, but that would not be practical because a large distance multiplier would dominate the training and minimize the movement of other z\u209b\u2090\u2098\u209a\u2097\u2091\u209b.", "Also as one of \u03b1 or \u03b2 tend to infinity the other one becomes a small number that is also impractical but for a different reason. The z\u209b\u2090\u2098\u209a\u2097\u2091\u209b at the edges are supposed to map to the edges of Y\u2093 and any quantity of movement into the opposite direction will result in Z\u2098\u1d62\u2099 or Z\u2098\u2090\u2093 mapping to a greater or smaller point in Y\u2093 respectively. For this reason the \u03b1 and \u03b2 for the z\u209b\u2090\u2098\u209a\u2097\u2091\u209b at the edges (i.e. z[0] and z[S]) will be assigned a value of 0 for the one that pushes inward and a predefined hyperparameter C \u2208 [0, 1] that can be adjusted to the model.", "In order to train the neural network the z-samples, the set size S is chosen depending on the desired accuracy and compute available. Having decided that, Z must be defined. That is, the number of dimensions and its range must be chosen. Given Z and the training level we can create the z-samples set.", "First we select a batch of data from the training data with size n, for every data point in the batch, we evaluate the current model on every z-sample. This gives us the prediction matrix:", "For every data point (x\u1d62, y\u1d62) in the batch, we take the output value y\u1d62 and compare it with every value of its corresponding row in the prediction matrix (i.e. [f(x\u1d62, z\u2080), f(x\u1d62, z\u2081), \u2026, f(x\u1d62, z\u2088)]). After determining if y\u1d62 is greater or smaller than each predicted value, we produce 2 values for every element in the matrix:", "The scalar will be \u03b1[z-sample] if y\u1d62 is smaller than the prediction and \u03b2[z-sample] if y\u1d62 is greater.", "The target value is the prediction itself plus the preselected movement constant M multiplied by -1 if y\u1d62 is smaller than the prediction and 1 if y\u1d62 is greater. You can think of target values as the \u201cwhere we want the prediction to be\u201d value.", "After calculating these 2 values we are ready to assemble the matrix to be used during backpropagation.", "We pass the prediction matrix results in a addition to this matrix to a Weighted Mean Squared Error loss function (WMSE). The loss function will look like this:", "The Mean Squared Error (MSE) loss function works to train the model using backpropagation and target values, but testing the model requires a different approach. Since both f(x, Z) and Y\u2093 are random variables, measuring the differences between their samplings is pointless. Because of this, the success of the model will be measured in 2 ways:", "In statistics, the earth mover\u2019s distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved. wikipedia.org", "Using EMD we can obtain an indicator of how similar Y\u2093 and f(x, Z) are. It can be calculated by comparing every x, y data point in the test data and prediction data sets and finding way to transform one into the other that requires the smallest total movement. What the EMD number tells us is the average amount of distance to transform every point in the predictions data set to the test data set.", "On the example below, you can see that the mean EMD is ~3.9 on a data set with a thickness of roughly 100. Because of the random nature of the data sets the EMD cannot be used as a literal error indicator, but it can be used as a progress indicator, that is to tell if the model improves with training.", "Ideally, to test Goal 1 (i.e. \u2200 x \u2208 X \u2227 \u2200 z\u2019 \u2208 z\u209b\u2090\u2098\u209a\u2097\u2091\u209b: arg min |E(z\u2019)|) we would evaluate f for a given x and on every z-sample and then compare it to an arbitrary number of test data points having the same x. We would then proceed to count for every z-sample the number of test data points smaller than it. With a vector of smaller than counts (i.e. P(Y\u2093 \u2264 f(x, z\u2019))) we could proceed to compare it with the canonical counts for every z-sample (i.e. P(Z \u2264 z\u2019)) and measure the error. However in real life data sets this is not possible. Real life data sets will not likely have an arbitrary number of data points having the same x (they will unlikely even have 2 data points with the same x) which means that we need to use a vicinity in x (values X that are close to an x) to test the goal.", "We start by creating an ordering (an array of indices) O = {o\u2080, o\u2081, \u2026, o[m]} that sorts all the elements in X\u209c\u2091\u209b\u209c (the x inputs in the test data set). Then we select a substring of the array O\u2019 = {o\u1d62, o\u1d62\u208a\u2081, \u2026, o\u2c7c}.", "Now we can evaluate f for every x[o\u2019] \u2223 o\u2019 \u2208 O\u2019 on every z-sample which gives us the matrix:", "We then proceed to compare each row with the outputs y[o\u2019] \u2223 o\u2019 \u2208 O\u2019", "and create smaller than counts (i.e. P(Y\u2093 \u2264 f(x, z))) which we can then compare with the canonical counts for every z-sample (i.e. P(Z \u2264 z)) to measure the error in the selected substring.", "We will create a number of such substrings and call each error the local vicinity error located at the central element of the substring.", "On the example below you can see that the goal 1 mean error is ~1.6%, this can be used as an error indicator for the model.", "In order to test Goal 2 \u2200 x \u2208 X \u2227 \u2200 z\u2080, z\u2081 \u2208 Z s.t. z\u2080 < z\u2081: f(x, z\u2080) < f(x, z\u2081) we select some random points in X and a set of random points in Z, we run them in our model and get result matrix:", "From here it is trivial to check that each row is monotonically increasing. To increase the quality of the check we can increment the sizes of the test point set in X and the test point set in Z.", "Now we can go back to the departure delays to arrival delays dataset, below you can see the MLE approach (Fig 7a) and the approach introduced in this article (Fig 7b) side by side. As we saw before the MLE approach fails to capture the small imperfections obtaining a goal 1 error of 2.48% while the generic approach does a much better job with a 0.018% goal 1 error.", "The following are various experiments done on different datasets.", "Let\u2019s start with a simple example. The function x\u00b2 with added gaussian noise. On the left panel you can see the training evolving over the course of 180 epochs. On the top left corner of this panel you can see the goal 1 error localized over X, at the end of the training you can see that the highest local error is around 2% and the global error is around 0.5%. On the top right corner of the same panel you can see the local Earth Mover\u2019s Distance (EMD). On the bottom left corner you can see a plot of the original test dataset (in blue) and the z-samples (in orange), you can see how they progressively conform to the test data. On the bottom right you can see a plot of the original test dataset (in blue) and random predictions (with z \u223c Z), you can see as the predicted results progressively represent the test data.", "On the right panel, you can see a plot of the global goal 1 error (above) and global EMD values (below) as they change over the course of the training.", "This one is a bit more complicated. An order 3 polynomial with added truncated gaussian noise (that is a normal distribution clipped at specific points).", "This one is quite more interesting. 2 mirroring sin(x) functions with gaussian noise scaled by sin(x) itself.", "Notice how the model succeeds to represent the areas in the middle with lower densities.", "This one experiments with branching paths. It starts with simple gaussian noise around 0, then starts splitting it with equal probabilities over the course of various segments.", "Despite the distribution not being continuous, the model does a reasonably good job of approximating it.", "The next example has 2 dimensions of input. X\u2080 (the first dimension) is x\u00b2 and X\u2081 (the second dimension) is x\u00b3 with added absolute gaussian noise. The display is slightly different, for the sake of space the z-samples plot is omitted. As you can see there is a panel per dimension and as always an additional panel for goal 1 error and EMD error histories.", "This experiment uses real data instead of generated one which proves the model\u2019s effectivity on real data. It is the classic California housing dataset. It has information from the 1990 California census with 8 input dimensions (Median Income, House Age, etc \u2026). Below you can see the plots of each dimension.", "The method presented allows to approximate the distributions of stochastic data sets to an arbitrary precision. The model is simple, fast to train and can be implemented with a vanilla feedforward neural network. Its ability to approximate any distribution across an input space makes it a valuable tool for any task that requires prediction.", "Senior Software Engineer @ Bloomberg LP | Computer Scientist | Artificial Intelligence enthusiast | Opinions are my own"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbe7d6ccf4f6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://medium.com/@nicolas.arroyo.duran?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nicolas.arroyo.duran?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Nicolas Arroyo Duran"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffafde8b402f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=post_page-fafde8b402f0----be7d6ccf4f6---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbe7d6ccf4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=-----be7d6ccf4f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbe7d6ccf4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&source=-----be7d6ccf4f6---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://github.com/narroyo1/sffnn", "anchor_text": "github.com/narroyo1/sffnn"}, {"url": "https://en.wikipedia.org/wiki/Universal_approximation_theorem", "anchor_text": "universal function approximators"}, {"url": "https://www.kaggle.com/usdot/flight-delays", "anchor_text": "2015 Flight Delays and Cancellations"}, {"url": "https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/", "anchor_text": "Logistic Regression with Maximum Likelihood Estimation"}, {"url": "https://narroyo1.github.io/sffnn/#goal-2", "anchor_text": "Goal 2"}, {"url": "https://narroyo1.github.io/sffnn/#goal-1", "anchor_text": "Goal 1"}, {"url": "https://narroyo1.github.io/sffnn/#goal-1", "anchor_text": "Goal 1"}, {"url": "https://en.wikipedia.org/wiki/Earth_mover%27s_distance", "anchor_text": "wikipedia.org"}, {"url": "https://en.wikipedia.org/wiki/Earth_mover%27s_distance", "anchor_text": "EMD"}, {"url": "https://narroyo1.github.io/sffnn/#goal-1", "anchor_text": "Goal 1"}, {"url": "https://narroyo1.github.io/sffnn/#goal-2", "anchor_text": "Goal 2"}, {"url": "http://lib.stat.cmu.edu/datasets/houses.zip", "anchor_text": "California housing dataset"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----be7d6ccf4f6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----be7d6ccf4f6---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/stochastic-process?source=post_page-----be7d6ccf4f6---------------stochastic_process-----------------", "anchor_text": "Stochastic Process"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----be7d6ccf4f6---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----be7d6ccf4f6---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbe7d6ccf4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=-----be7d6ccf4f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbe7d6ccf4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=-----be7d6ccf4f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbe7d6ccf4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@nicolas.arroyo.duran?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffafde8b402f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=post_page-fafde8b402f0----be7d6ccf4f6---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Ffafde8b402f0%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=-----be7d6ccf4f6---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@nicolas.arroyo.duran?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Written by Nicolas Arroyo Duran"}, {"url": "https://medium.com/@nicolas.arroyo.duran/followers?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "12 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffafde8b402f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=post_page-fafde8b402f0----be7d6ccf4f6---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Ffafde8b402f0%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapproximating-stochastic-functions-be7d6ccf4f6&user=Nicolas+Arroyo+Duran&userId=fafde8b402f0&source=-----be7d6ccf4f6---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----be7d6ccf4f6----0---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----be7d6ccf4f6----0---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----be7d6ccf4f6----0---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----be7d6ccf4f6----0---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----be7d6ccf4f6----0---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----be7d6ccf4f6----0---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----0-----------------clap_footer----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----be7d6ccf4f6----0---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----be7d6ccf4f6----0-----------------bookmark_preview----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----be7d6ccf4f6----1---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----be7d6ccf4f6----1---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----be7d6ccf4f6----1---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----be7d6ccf4f6----1---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----be7d6ccf4f6----1---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----be7d6ccf4f6----1---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----1-----------------clap_footer----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----be7d6ccf4f6----1---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----be7d6ccf4f6----1-----------------bookmark_preview----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----be7d6ccf4f6----2---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----be7d6ccf4f6----2---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----be7d6ccf4f6----2---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----be7d6ccf4f6----2---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----be7d6ccf4f6----2---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----be7d6ccf4f6----2---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----be7d6ccf4f6----2---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----be7d6ccf4f6----2-----------------bookmark_preview----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----be7d6ccf4f6----3---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=author_recirc-----be7d6ccf4f6----3---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=author_recirc-----be7d6ccf4f6----3---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Nikos Kafritsas"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----be7d6ccf4f6----3---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----be7d6ccf4f6----3---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "Time-Series Forecasting: Deep Learning vs Statistics \u2014 Who Wins?A comprehensive guide on the ultimate dilemma"}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----be7d6ccf4f6----3---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": "\u00b714 min read\u00b7Apr 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc568389d02df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df&user=Nikos+Kafritsas&userId=bec849d9e1d2&source=-----c568389d02df----3-----------------clap_footer----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----be7d6ccf4f6----3---------------------62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc568389d02df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df&source=-----be7d6ccf4f6----3-----------------bookmark_preview----62ffd1d2_6bb8_4873_90f0_5b879b3aeb87-------", "anchor_text": ""}, {"url": "https://medium.com/@nicolas.arroyo.duran?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "See all from Nicolas Arroyo Duran"}, {"url": "https://towardsdatascience.com/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----be7d6ccf4f6----0-----------------bookmark_preview----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----be7d6ccf4f6----1-----------------bookmark_preview----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----be7d6ccf4f6----0---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----be7d6ccf4f6----0-----------------bookmark_preview----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Aleid ter Weel"}, {"url": "https://medium.com/better-advice?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Better Advice"}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "10 Things To Do In The Evening Instead Of Watching NetflixDevice-free habits to increase your productivity and happiness."}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "\u00b75 min read\u00b7Feb 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-advice%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&user=Aleid+ter+Weel&userId=6ffe087f07e5&source=-----4e270e9dd6b9----1-----------------clap_footer----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----be7d6ccf4f6----1---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "204"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&source=-----be7d6ccf4f6----1-----------------bookmark_preview----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----be7d6ccf4f6----2---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----be7d6ccf4f6----2---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----be7d6ccf4f6----2---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----be7d6ccf4f6----2---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----be7d6ccf4f6----2---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Understanding NeRFsA massive breakthrough in scene representation"}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----be7d6ccf4f6----2---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "\u00b711 min read\u00b73 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----2a082e13c6eb----2-----------------clap_footer----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----be7d6ccf4f6----2---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&source=-----be7d6ccf4f6----2-----------------bookmark_preview----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----be7d6ccf4f6----3---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----be7d6ccf4f6----3---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----be7d6ccf4f6----3---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----be7d6ccf4f6----3---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----be7d6ccf4f6----3---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----be7d6ccf4f6----3---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----3-----------------clap_footer----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----be7d6ccf4f6----3---------------------f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----be7d6ccf4f6----3-----------------bookmark_preview----f36b2171_5f65_4060_8a6c_cfd42cb2eeb2-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----be7d6ccf4f6--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}