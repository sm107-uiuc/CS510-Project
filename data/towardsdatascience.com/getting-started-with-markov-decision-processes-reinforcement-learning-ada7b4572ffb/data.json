{"url": "https://towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb", "time": 1682993766.607032, "path": "towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb/", "webpage": {"metadata": {"title": "Getting Started with Markov Decision Processes: Reinforcement Learning | by Ryan Wong | Towards Data Science", "h1": "Getting Started with Markov Decision Processes: Reinforcement Learning", "description": "In this blog post I will be explaining the concepts required to understand how to solve problems with Reinforcement Learning. This series of blog posts contain a summary of concepts explained in\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html", "anchor_text": "Introduction to Reinforcement Learning", "paragraph_index": 0}], "all_paragraphs": ["In this blog post I will be explaining the concepts required to understand how to solve problems with Reinforcement Learning. This series of blog posts contain a summary of concepts explained in Introduction to Reinforcement Learning by David Silver.", "So far we have learnt the components required to set up a reinforcement learning problem at a very high level. We will now look into more detail of formally describing an environment for reinforcement learning. In this post, we will look at a fully observable environment and how to formally describe the environment as Markov decision processes (MDPs).", "If we can solve for Markov Decision Processes then we can solve a whole bunch of Reinforcement Learning problems.", "The MDPs need to satisfy the Markov Property.", "Markov Property: requires that \u201cthe future is independent of the past given the present\u201d.", "Property: Our state S\u209c is Markov if and only if:", "Simply this means that the state S\u209c captures all the relevant information from the history. S\u2081, S\u2082, \u2026, S\u209c\u208b\u2081 can be discarded and we still get the same state transition probability to the next state S\u209c\u208a\u2081.", "State Transition Probability: The state transition probability tells us, given we are in state s what the probability the next state s\u2019 will occur.", "We can also define all state transitions in terms of a State Transition Matrix P, where each row tells us the transition probabilities from one state to all possible successor states.", "The first and most simplest MDP is a Markov process.", "Markov Process / Markov Chain: A sequence of random states S\u2081, S\u2082, \u2026 with the Markov property.", "Below is an illustration of a Markov Chain were each node represents a state with a probability of transitioning from one state to the next, where Stop represents a terminal state.", "We can take a sample episode to go through the chain and end up at the terminal state. An example sample episode would be to go from Stage1 to Stage2 to Win to Stop. Below is a representation of a few sample episodes:", "- S1 S2 Win Stop- S1 S2 Teleport S2 Win Stop- S1 Pause S1 S2 Win Stop", "The above Markov Chain has the following Transition Probability Matrix:", "For each of the states the sum of the transition probabilities for that state equals 1.", "In the above Markov Chain we did not have a value associated with being in a state to achieve a goal. A Markov Reward Process is a Markov chain with reward values.", "Our goal is to maximise the return. The return G\u209c is the total discount reward from time-step t.", "The discount factor \u03b3 is a value (that can be chosen) between 0 and 1. If gamma is closer 0 it leads to short sighted evaluation, while a value closer to 1 favours far sighted evaluation.", "Note: Since in a Markov Reward Process we have no actions to take, G\u209c is calculated by going through a random sample sequence.", "State Value Function v(s): gives the long-term value of state s. It is the expected return starting from state s", "How we can view this is by saying going from state s and going through various samples from state s what is our expected return. We want to prefer states which gives more total reward.", "The value function can be decomposed into two parts:", "We can define a new equation to calculate the state-value function using the state-value function and return function above:", "Alternatively this can be written in a matrix form:", "Using this equation we can calculate the state values for each state. Since we have a simple model above with the \u201cstate-values for MRP with \u03b3=1\u201d we can calculate the state values using a simultaneous equations using the updated state-value function.", "Solving the above equation is simple for a small MRPs but becomes highly complex for larger numbers. In order to solve for large MRPs we require other techniques such as Dynamic Programming, Monte-Carlo evaluation and Temporal-Difference learning which will be discussed in a later blog.", "A Markov Decision Process is an extension to a Markov Reward Process as it contains decisions that an agent must make. All states in the environment are Markov.", "In a Markov Decision Process we now have more control over which states we go to. An example in the below MDP if we choose to take the action Teleport we will end up back in state Stage2 40% of the time and Stage1 60% of the time. Other state transitions occur with 100% probability when selecting the corresponding actions such as taking the Action Advance2 from Stage2 will take us to Win.", "A policy \u03c0 is a distribution over actions given states. It fully defines the behaviour of an agent. MDP policies depend on the current state and not the history.", "Polices give the mappings from one state to the next. If I am in state s, it maps from that state the probability of taking each action. Example if we have the policy \u03c0(Chores|Stage1)=100%, this means the agent will take the action Chores 100% of the time when in state Stage1.", "Since we take actions there are different expectations depending on how we behave.", "The state-value function v_\u03c0(s) of an MDP is the expected return starting from state s, and then following policy \u03c0.", "State-value function tells us how good is it to be in state s by following policy \u03c0.", "The action-value function q_\u03c0(s,a) is the expected return starting from state s, taking action a, and then following policy \u03c0.", "Action-value function tells us how good is it to take a particular action from a particular state. Gives us an idea on what action we should take at states", "The value functions can also be written in the form of a Bellman Expectation Equation as follows:", "In all of the above equations we are using a given policy to follow, which may not be the optimal actions to take. The key goal in reinforcement learning is to find the optimal policy which will maximise our return.", "The optimal state-value function v\u2217(s) is the maximum value function over all policies. It tells us the maximum possible reward you can extract from the system.", "The optimal action-value function q\u2217(s,a) is the maximum action-value function over all policies. It tells us what is the maximum possible reward you can extract from the system starting at state s and taking action a.", "If you know q\u2217 then you know the right action to take and behave optimally in the MDP and therefore solving the MDP.", "q\u2217(s,a) tells which actions to take to behave optimally.", "An optimal policy can be found by maximising over q\u2217(s, a):", "The Bellman Optimality Equation is non-linear which makes it difficult to solve. In a later blog, I will discuss iterative solutions to solving this equation with various techniques such as Value Iteration, Policy Iteration, Q-Learning and Sarsa.", "If you enjoyed this post and want to see more don\u2019t forget follow and/or leave a clap."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fada7b4572ffb&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@taggatle?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Ryan Wong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c034a2353ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&user=Ryan+Wong&userId=8c034a2353ca&source=post_page-8c034a2353ca----ada7b4572ffb---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fada7b4572ffb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&user=Ryan+Wong&userId=8c034a2353ca&source=-----ada7b4572ffb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fada7b4572ffb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&source=-----ada7b4572ffb---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html", "anchor_text": "Introduction to Reinforcement Learning"}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d", "anchor_text": "1"}, {"url": "https://medium.com/@taggatle/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c", "anchor_text": "3"}, {"url": "https://towardsdatascience.com/model-free-prediction-reinforcement-learning-507297e8e2ad", "anchor_text": "4"}, {"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MDP.pdf", "anchor_text": "UCL Course on RL \u2014 Lecture 2"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ada7b4572ffb---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ada7b4572ffb---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----ada7b4572ffb---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ada7b4572ffb---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fada7b4572ffb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&user=Ryan+Wong&userId=8c034a2353ca&source=-----ada7b4572ffb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fada7b4572ffb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&user=Ryan+Wong&userId=8c034a2353ca&source=-----ada7b4572ffb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fada7b4572ffb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c034a2353ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&user=Ryan+Wong&userId=8c034a2353ca&source=post_page-8c034a2353ca----ada7b4572ffb---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F87d33b7279c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&newsletterV3=8c034a2353ca&newsletterV3Id=87d33b7279c4&user=Ryan+Wong&userId=8c034a2353ca&source=-----ada7b4572ffb---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Written by Ryan Wong"}, {"url": "https://medium.com/@taggatle/followers?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "347 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c034a2353ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&user=Ryan+Wong&userId=8c034a2353ca&source=post_page-8c034a2353ca----ada7b4572ffb---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F87d33b7279c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&newsletterV3=8c034a2353ca&newsletterV3Id=87d33b7279c4&user=Ryan+Wong&userId=8c034a2353ca&source=-----ada7b4572ffb---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c?source=author_recirc-----ada7b4572ffb----0---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ada7b4572ffb----0---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ada7b4572ffb----0---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Ryan Wong"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ada7b4572ffb----0---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c?source=author_recirc-----ada7b4572ffb----0---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Planning by Dynamic Programming: Reinforcement LearningPart 3: Explaining the concepts of the Dynamic Programming, Policy Evaluation, Policy Iteration and Value Iteration"}, {"url": "https://towardsdatascience.com/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c?source=author_recirc-----ada7b4572ffb----0---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "6 min read\u00b7Nov 24, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed4924bbaa4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&user=Ryan+Wong&userId=8c034a2353ca&source=-----ed4924bbaa4c----0-----------------clap_footer----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c?source=author_recirc-----ada7b4572ffb----0---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed4924bbaa4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&source=-----ada7b4572ffb----0-----------------bookmark_preview----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ada7b4572ffb----1---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ada7b4572ffb----1---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ada7b4572ffb----1---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ada7b4572ffb----1---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ada7b4572ffb----1---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ada7b4572ffb----1---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ada7b4572ffb----1---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----ada7b4572ffb----1-----------------bookmark_preview----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ada7b4572ffb----2---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ada7b4572ffb----2---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ada7b4572ffb----2---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ada7b4572ffb----2---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ada7b4572ffb----2---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ada7b4572ffb----2---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ada7b4572ffb----2---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----ada7b4572ffb----2-----------------bookmark_preview----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ada7b4572ffb----3---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ada7b4572ffb----3---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ada7b4572ffb----3---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Ryan Wong"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ada7b4572ffb----3---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ada7b4572ffb----3---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "Reinforcement Learning: An Introduction to the Concepts, Applications and CodePart 1: An introduction to reinforcement learning, explaining common terms, concepts and applications."}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ada7b4572ffb----3---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": "5 min read\u00b7Sep 23, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fced6fbfd882d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d&user=Ryan+Wong&userId=8c034a2353ca&source=-----ced6fbfd882d----3-----------------clap_footer----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ada7b4572ffb----3---------------------3af87bdc_e827_4356_b4bb_fd9365510dbd-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fced6fbfd882d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d&source=-----ada7b4572ffb----3-----------------bookmark_preview----3af87bdc_e827_4356_b4bb_fd9365510dbd-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "See all from Ryan Wong"}, {"url": "https://towardsdatascience.com/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----ada7b4572ffb----0-----------------bookmark_preview----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----ada7b4572ffb----1-----------------bookmark_preview----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----0-----------------clap_footer----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ada7b4572ffb----0---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----ada7b4572ffb----0-----------------bookmark_preview----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-rl-what-is-it-and-how-does-it-work-1962cf6db103?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://solclover.com/?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://solclover.com/?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Saul Dobilas"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/reinforcement-learning-rl-what-is-it-and-how-does-it-work-1962cf6db103?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Reinforcement Learning (RL) \u2014 What Is It and How Does It Work?A gentle introduction to Reinforcement Learning with a clear explanation of concepts and terminology"}, {"url": "https://towardsdatascience.com/reinforcement-learning-rl-what-is-it-and-how-does-it-work-1962cf6db103?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "\u00b78 min read\u00b7Sep 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1962cf6db103&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-rl-what-is-it-and-how-does-it-work-1962cf6db103&user=Saul+Dobilas&userId=f77accd417be&source=-----1962cf6db103----1-----------------clap_footer----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-rl-what-is-it-and-how-does-it-work-1962cf6db103?source=read_next_recirc-----ada7b4572ffb----1---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1962cf6db103&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-rl-what-is-it-and-how-does-it-work-1962cf6db103&source=-----ada7b4572ffb----1-----------------bookmark_preview----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----ada7b4572ffb----2---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://rahulbhadani.medium.com/?source=read_next_recirc-----ada7b4572ffb----2---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://rahulbhadani.medium.com/?source=read_next_recirc-----ada7b4572ffb----2---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Rahul Bhadani"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ada7b4572ffb----2---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----ada7b4572ffb----2---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Foundational RL: Solving Markov Decision ProcessRoad to Reinforcement Learning"}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----ada7b4572ffb----2---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "\u00b711 min read\u00b7Dec 12, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd90b7e134c0b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffoundational-rl-solving-markov-decision-process-d90b7e134c0b&user=Rahul+Bhadani&userId=5d4d67138803&source=-----d90b7e134c0b----2-----------------clap_footer----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----ada7b4572ffb----2---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd90b7e134c0b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffoundational-rl-solving-markov-decision-process-d90b7e134c0b&source=-----ada7b4572ffb----2-----------------bookmark_preview----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----ada7b4572ffb----3---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----ada7b4572ffb----3---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----ada7b4572ffb----3---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "Bruce Yang ByFinTech"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----ada7b4572ffb----3---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----ada7b4572ffb----3---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement LearningNeurIPS 2022 Datasets and Benchmarks."}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----ada7b4572ffb----3---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": "\u00b79 min read\u00b7Nov 13, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F7af8e747c4bd&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffinrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd&user=Bruce+Yang+ByFinTech&userId=a878fc45fb3f&source=-----7af8e747c4bd----3-----------------clap_footer----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----ada7b4572ffb----3---------------------397ce41b_9bf6_4b30_9245_801e63c5f857-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7af8e747c4bd&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffinrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd&source=-----ada7b4572ffb----3-----------------bookmark_preview----397ce41b_9bf6_4b30_9245_801e63c5f857-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----ada7b4572ffb--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}