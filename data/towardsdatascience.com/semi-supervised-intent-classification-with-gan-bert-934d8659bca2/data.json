{"url": "https://towardsdatascience.com/semi-supervised-intent-classification-with-gan-bert-934d8659bca2", "time": 1683012637.622803, "path": "towardsdatascience.com/semi-supervised-intent-classification-with-gan-bert-934d8659bca2/", "webpage": {"metadata": {"title": "Semi-supervised Intent Classification with GAN-BERT | by Louis Owen | Towards Data Science", "h1": "Semi-supervised Intent Classification with GAN-BERT", "description": "Starting from that simple question, I start to do research in order to answer that question. After spending several hours, I ended up with GAN-BERT. What is GAN-BERT? What experiment that I did using\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.aclweb.org/anthology/D19-1131.pdf", "anchor_text": "CLINC150 Dataset", "paragraph_index": 1}, {"url": "https://github.com/google-research/bert", "anchor_text": "BERT or Bidirectional Encoder Representations from Transformers", "paragraph_index": 2}, {"url": "https://www.aclweb.org/anthology/2020.acl-main.191.pdf", "anchor_text": "\u201cGAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples\u201d", "paragraph_index": 4}, {"url": "http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf", "anchor_text": "SS-GAN", "paragraph_index": 4}, {"url": "https://www.aclweb.org/anthology/D19-1131.pdf", "anchor_text": "CLINC150", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/2003.04807.pdf", "anchor_text": "paper", "paragraph_index": 16}, {"url": "https://github.com/louisowen6/GAN_BERT_CLINC150", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://www.itb.ac.id/", "anchor_text": "Institut Teknologi Bandung", "paragraph_index": 18}, {"url": "https://www.linkedin.com/company/traveloka-com/", "anchor_text": "Traveloka", "paragraph_index": 19}, {"url": "https://www.linkedin.com/company/pt--tokopedia/", "anchor_text": "Tokopedia", "paragraph_index": 19}, {"url": "https://www.linkedin.com/company/doitglotech/", "anchor_text": "Do-it", "paragraph_index": 19}, {"url": "https://www.linkedin.com/company/qluesmartcity/", "anchor_text": "Qlue Smart City", "paragraph_index": 19}, {"url": "https://www.linkedin.com/company/the-world-bank/", "anchor_text": "The World Bank", "paragraph_index": 19}, {"url": "http://louisowen6.github.io/", "anchor_text": "Louis\u2019 website", "paragraph_index": 20}, {"url": "https://www.linkedin.com/in/louisowen/", "anchor_text": "LinkedIn", "paragraph_index": 20}, {"url": "http://Yellow.ai", "anchor_text": "Yellow.ai", "paragraph_index": 22}], "all_paragraphs": ["Is it possible to do text-classification with 150 target classes using only 10 labelled samples for each class but still get a good performance?", "Starting from that simple question, I start to do research in order to answer that question. After spending several hours, I ended up with GAN-BERT. What is GAN-BERT? What experiment that I did using GAN-BERT? In this article, I will try to give a brief introduction of GAN-BERT and also the implementation of it for Intent Classification using CLINC150 Dataset.", "In Natural Language Processing (NLP) field, BERT or Bidirectional Encoder Representations from Transformers is a well-known technique based on Transformers architecture to do a wide range of tasks, including text classification. However, this technique can perform well when there is \u2018enough\u2019 labelled training data to be exploited while obtaining labelled data is time-consuming and a costly process. The potential solution for this is using a semi-supervised learning approach.", "Semi-supervised learning is an approach in machine learning field which combines both labelled and unlabelled data during training. The goal is the same as the supervised learning approach, that is to predict the target variable given the data with several features. This approach is crucial when we have not so many labelled data while our model needs a lot of training data to perform well.", "Recently in July 2020, a paper named \u201cGAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples\u201d, try to extend the fine-tuning of BERT-like architectures with unlabeled data in a generative adversarial setting. In high-level, they try to enrich the BERT fine-tuning process with an SS-GAN (Semi-supervised GAN) perspective.", "\u201cIn this paper, we extend the BERT training with unlabeled data in a generative adversarial setting. In particular, we enrich the BERT fine-tuning process with an SS-GAN perspective, in the so-called GAN-BERT model\u201d", "This architecture combines the power of BERT and SS-GAN to do the text classification. The generator produces \u201cfake\u201d examples by taking the input of a 100-dimensional noise vector drawn from Gaussian Distribution. The discriminator is an MLP on top of BERT which receives the input vector either a fake vector generated by the generator or the vector from the real data generated by BERT. The final layer of the discriminator is a softmax layer which outputs the k+1 dimension vector of logits, where k is the number of classes in the dataset. Here, the real data is divided into 2, they are labelled (L) and unlabelled (U) data.", "The discriminator aims to classify whether the input is a real instance or not. If it predicts the input as a real instance, then it has to predict which class the input belongs to.", "The training process tries to optimize two competing losses, they are discriminator loss and generator loss. The discriminator loss is the summation of 2 other losses: supervised and unsupervised loss. Supervised loss measures the error in assigning the wrong class to a real example among the original k categories, while unsupervised loss measures the error in incorrectly recognizing a real (unlabeled) example as fake and not recognizing a fake example. The generator loss is also the result of summation from 2 other losses: feature matching and unsupervised loss. Feature matching loss aims to make sure that the generator should produce examples whose intermediate representations provided in input to the discriminator are very similar to the real ones, while unsupervised loss measures the error induced by fake examples correctly identified by the discriminator.", "During training, the samples in each class are replicated in the factor of log(2|U|/|L|), to guarantees the presence of some labelled instances in each batch to avoid divergences due to the unsupervised component of the adversarial training. During inference process, the generator is discarded from the architecture while retaining the rest.", "This means that there is no additional cost at inference time with respect to the standard BERT model.", "In this experiment, CLINC150 dataset is used. This dataset consists of 150 intent classes over 10 domains. There are 4 variants of data provided: full, small, imbalance, and OOS+, where the full variant is used here. For each intent, there are 100 training utterances, 20 validation, and 30 testing utterances. Actually this data also provides the Out-of-scope (OOS) in addition to the 150 intent In-scope classes. However, in this experiment, I only focus on In-scope class prediction.", "Since the actual CLINC150 dataset is not built for semi-supervised learning settings, here I try to experiment with 6 variants of training data. The training data is split into the labelled and unlabelled set for each variant. The first variant consists of 10% labelled and 90% unlabelled dataset. Since the total number of utterances in training data is 100, so for the first variant there are 10 utterances for the labelled set and 90 utterances for the unlabelled set.", "I use the exact same parameters settings for all training data variants. The only difference is the number of training epochs. I use 20, 18, 16, 14, 12, 10 number of epochs for the first until the last variants, respectively.", "The results on CLINC150 paper shows that by utilizing BERT, they got 96.2% accuracy on the test dataset. Using the same test dataset here are the results of GAN-BERT across 6 variations of training data.", "We can see that GAN-BERT able to gives a reasonable performance even using only 10 labelled utterances in each intent during the training process. The performance of GAN-BERT increase as the number of labelled utterances increase. The performance of the fourth, fifth, and sixth variant is similar to each other. This shows that even only using 60% labelled training data, the performance of GAN-BERT is similar to the model that is trained using 80% or even 90% of labelled training data.", "GAN-BERT has great potential in semi-supervised learning for the multi-text classification task. It performs well given only limited labelled training data. However, this is only one of the approaches to handle limited labelled training data in the text-classification task. There is also another approach called few-shot text classification. If you are interested more, you can read this paper which also uses CLINC150 as their training data.", "You can find all of the codes used in this article here.", "Louis Owen is a Data Science enthusiast who always hungry for new knowledge. He pursued a Mathematics major at one of the top university in Indonesia, Institut Teknologi Bandung, under the full final-year scholarship.", "Louis has experienced as an analytics/machine learning intern in various field of industry, including OTA (Traveloka), e-Commerce (Tokopedia), FinTech (Do-it), Smart City App (Qlue Smart City) and currently as a Data Science Consultant at The World Bank.", "Check out Louis\u2019 website to know more about him! Lastly, if you have any queries or any topics to be discussed, please reach out to Louis via LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "NLP Engineer at Yellow.ai | Former Data Science Consultant at The World Bank & AI Research Engineer at Bukalapak"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F934d8659bca2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----934d8659bca2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----934d8659bca2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://louisowen6.medium.com/?source=post_page-----934d8659bca2--------------------------------", "anchor_text": ""}, {"url": "https://louisowen6.medium.com/?source=post_page-----934d8659bca2--------------------------------", "anchor_text": "Louis Owen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa05d4a2c510d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&user=Louis+Owen&userId=a05d4a2c510d&source=post_page-a05d4a2c510d----934d8659bca2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F934d8659bca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F934d8659bca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.aclweb.org/anthology/2020.acl-main.191.pdf", "anchor_text": "GAN-BERT: Generative Adversarial Learning for Robust Text Classification"}, {"url": "https://www.aclweb.org/anthology/D19-1131.pdf", "anchor_text": "CLINC150 Dataset"}, {"url": "https://github.com/google-research/bert", "anchor_text": "BERT or Bidirectional Encoder Representations from Transformers"}, {"url": "https://www.aclweb.org/anthology/2020.acl-main.191.pdf", "anchor_text": "\u201cGAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples\u201d"}, {"url": "http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf", "anchor_text": "SS-GAN"}, {"url": "https://www.aclweb.org/anthology/2020.acl-main.191.pdf", "anchor_text": "GAN-BERT: Generative Adversarial Learning for Robust Text Classification"}, {"url": "https://unsplash.com/@acfb5071?utm_source=medium&utm_medium=referral", "anchor_text": "Keith Johnston"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.aclweb.org/anthology/D19-1131.pdf", "anchor_text": "CLINC150"}, {"url": "https://arxiv.org/pdf/2003.04807.pdf", "anchor_text": "paper"}, {"url": "https://github.com/louisowen6/GAN_BERT_CLINC150", "anchor_text": "here"}, {"url": "https://www.itb.ac.id/", "anchor_text": "Institut Teknologi Bandung"}, {"url": "https://www.linkedin.com/company/traveloka-com/", "anchor_text": "Traveloka"}, {"url": "https://www.linkedin.com/company/pt--tokopedia/", "anchor_text": "Tokopedia"}, {"url": "https://www.linkedin.com/company/doitglotech/", "anchor_text": "Do-it"}, {"url": "https://www.linkedin.com/company/qluesmartcity/", "anchor_text": "Qlue Smart City"}, {"url": "https://www.linkedin.com/company/the-world-bank/", "anchor_text": "The World Bank"}, {"url": "http://louisowen6.github.io/", "anchor_text": "Louis\u2019 website"}, {"url": "https://www.linkedin.com/in/louisowen/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/data-science?source=post_page-----934d8659bca2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----934d8659bca2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----934d8659bca2---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/text-classification?source=post_page-----934d8659bca2---------------text_classification-----------------", "anchor_text": "Text Classification"}, {"url": "https://medium.com/tag/nlp?source=post_page-----934d8659bca2---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F934d8659bca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&user=Louis+Owen&userId=a05d4a2c510d&source=-----934d8659bca2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F934d8659bca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&user=Louis+Owen&userId=a05d4a2c510d&source=-----934d8659bca2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F934d8659bca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----934d8659bca2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F934d8659bca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----934d8659bca2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----934d8659bca2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----934d8659bca2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----934d8659bca2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----934d8659bca2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----934d8659bca2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----934d8659bca2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----934d8659bca2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----934d8659bca2--------------------------------", "anchor_text": ""}, {"url": "https://louisowen6.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://louisowen6.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Louis Owen"}, {"url": "https://louisowen6.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "282 Followers"}, {"url": "http://Yellow.ai", "anchor_text": "Yellow.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa05d4a2c510d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&user=Louis+Owen&userId=a05d4a2c510d&source=post_page-a05d4a2c510d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6ae66b798f0b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemi-supervised-intent-classification-with-gan-bert-934d8659bca2&newsletterV3=a05d4a2c510d&newsletterV3Id=6ae66b798f0b&user=Louis+Owen&userId=a05d4a2c510d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}