{"url": "https://towardsdatascience.com/embracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca", "time": 1683005510.478912, "path": "towardsdatascience.com/embracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca/", "webpage": {"metadata": {"title": "Embracing Bayesian A/B Test Measurement (and Ditching P Values) | Towards Data Science", "h1": "Exploring Bayesian A/B Test Measurement as an Alternative to P Values", "description": "(This is the second in a 2-part series on A/B testing. Part 1 walked through a process for weighing all your options when designing a new test and can be found here. This post picks up the example in\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/streamlining-design-and-maximizing-success-for-agile-test-and-learn-443156d9b2f1", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://www.countbayesie.com/blog/2019/6/12/logistic-regression-from-bayes-theorem", "anchor_text": "this great overview", "paragraph_index": 23}, {"url": "http://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf", "anchor_text": "rstanarm tutorial", "paragraph_index": 23}, {"url": "https://mc-stan.org/rstanarm/articles/rstanarm.html", "anchor_text": "Stan", "paragraph_index": 24}, {"url": "https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html", "anchor_text": "rstanarm vignette", "paragraph_index": 31}, {"url": "https://github.com/peifern/bayesian_regression", "anchor_text": "GitHub", "paragraph_index": 56}, {"url": "https://www.linkedin.com/in/curtbergmann/", "anchor_text": "Curt Bergmann", "paragraph_index": 57}], "all_paragraphs": ["(This is the second in a 2-part series on A/B testing. Part 1 walked through a process for weighing all your options when designing a new test and can be found here. This post picks up the example in the test measurement phase, demonstrating an approach using Bayesian analysis in R.)", "If you\u2019re like me, your inbox is inundated every day with emails. Many are work-related, a few are from friends and family (including the off-color forward from Grandma) and a lot (maybe too many) are marketing emails from companies vying for your business.", "They might seem like a nuisance, but let\u2019s be honest, every once in awhile our interest is piqued and we\u2019ll open one. Sometimes we\u2019ll even go to the company\u2019s site and buy something. This magical moment is captured by the company and counted as a conversion, and the money we spend is attributed to the email campaign.", "Conversion rates vary by industry and content type but are generally fairly low \u2014 under 5%. That might not seem like much, but if you\u2019re sending an email to an entire subscriber list, even a 1% conversion rate can yield a significant ROI. Say you\u2019re an online retailer and you send an email out to 1 million customers who bought Men\u2019s apparel last year. If only 1% of them convert with an average spend of $50, you\u2019re attributing $500,000 in revenue to a single email campaign!", "As a Towards Data Science reader, you\u2019re probably familiar with the concept of Bayesian analysis. Bayes\u2019 Theorem aims to use information about one event to understand another. Loosely speaking, an embrace of Bayes is an embrace of probability. Applying Bayesian inference for the purposes of A/B test measurement means we\u2019ll determine the probability that A is different from B.", "For a while now there has been a debate (sometimes heated, usually pragmatic) between the Frequentist and Bayesian approaches to statistical learning. Spoiler alert: At the end of the day, your data has one story to tell, and you can reach the same conclusions in a few different ways. This article focuses on the Bayesian approach, highlighting some of the differences compared to Frequentist methods. Ultimately, there are certain aspects of Bayesian inference that I have found valuable in practice. Namely, Bayesian inference provides:", "In this article we\u2019ll measure A/B test results using a traditional Frequentist approach and a Bayesian approach and end with the difference in expected revenue of A over B. We will show that both approaches lead to similar results, and expound on the nuances of the Bayesian technique and resulting interpretations.", "Let\u2019s set the stage. Our business partners have designed and executed a new email marketing campaign testing two different types of email content focused on Men\u2019s Suits. Out of 4,000 test customers, 2,000 were sent an email promoting a new line of dress shirts by an up-and-coming designer, while the other 2,000 were sent an email promoting a similar line of dress shirts by an in-house brand. We\u2019ll call the up-and-coming designer email Designer and the in-house email In-House.", "It\u2019s been 7 days since the email went out and we have our results. 88 customers who received Designer content made a purchase and spent $168.34 on average, while 72 customers who received In-House content made a purchase and spent $152.88 on average (and we received bounce backs from 3 customers).", "Designer looks like the clear winner, right? Maybe so, but as good data scientists, we have to make sure the difference is statistically significant and not just a result of randomness in our data.", "We\u2019ll start with a traditional measurement approach. This can be done through t-tests comparing means and variances of the two samples or by fitting regression models and investigating the independent variable coefficients. I use the regression approach here because I like having the flexibility to add additional variables to control for (e.g. day email was sent, customer location, etc) and it makes for a better apples-to-apples comparison with the Bayesian approach, which also uses regression.", "We start by exploring Conversion rates alone, fitting a logistic regression model to our data to see if Group (our predictor) has a statistically significant relationship to Conversion (our outcome). Our null hypothesis is that there is no relationship between Group and Conversion, and we\u2019ll use a standard P-value threshold of 0.05 to either confirm or reject this hypothesis.", "P >= 0.05 \u2192 Fail to reject null (we cannot conclude a relationship between Conversion and Group)", "P < 0.05 \u2192 Reject the null (we conclude a relationship does exist between Group and Conversion)", "First, we fit a logistic regression on the data to model conversion rates.", "Note that the predictor is \u201cgroupIn-House\u201d which just means the regression turned our binary predictor (Group) into a dummy variable which takes the value of 1 for In-House content and 0 for Designer content.", "Our results summary shows that the estimated coefficient for our predictor is negative in both models, indicating that customers who received In-House content have a lower conversion rate than those who received Designer content. However, the p-value of the coefficient is 0.199 is above our 0.05 threshold, meaning we failed to reject our null hypothesis and thus cannot conclude that the email content had an effect on Conversion. In fact, the p-value is a measure of probability. It means that, under conditions of the null hypothesis that there is no difference between variants, we would expect to see our data X% of the time. In this case, if there was truly no difference, our data would naturally occur ~20% of the time. While not a slam-dunk, it does indicate that there might be some underlying difference.", "What we really want to test, however, is the total effect on revenues, which means we need to compare spend. We\u2019ll fit a linear regression model on Spend.", "With a p-value of 0.0797, the data is telling us that there is only an 8% chance we would see our spend data if there was no relationship. I should note that the p-values we see assume we wanted a two-tailed test. Since the original data summary indicated that Designer would outperform In-House, we could reinterpret the p-value for a one-tailed test roughly by dividing it by two. That would further reduce 8% to 4%. Not bad at all, there\u2019s clearly some difference.", "Looking at the coefficient on our independent \u2018groupIn-House\u2019 variable, we see -1.90, indicating that, on average, the In-House content results in $1.90 less revenue per send than Designer.", "So what have we learned? If there was no difference in our variants, our data would only occur 8% of the time (4% if we\u2019re using a less-conservative one-tailed test), thus, we\u2019re pretty confident that there is a difference between our two variants. And, with $1.90 on the table for each email sent on an audience of ~1 million customers, we could be looking at an extra $1.9 million in revenues! We don\u2019t want to miss an opportunity like that without really analyzing our results.", "Switching from a Frequentist to a Bayesian approach means thinking about our data in terms of probabilities. Rather than a \u2018yes\u2019 or \u2018no\u2019 answer to the hypothesis about the relationship between Group and Conversion, we test by generating the probability that our outcomes in one Group are consistently different from the other.", "In a nutshell, Bayesian regression uses the traditional underlying regression formula, but instead of returning a point estimate for the input coefficients \u03b2i, it generates a distribution for the intercept, input coefficients, and error term.", "This is known as the posterior distribution and is generated using previous knowledge of the data (\u2018priors\u2019) combined with the observed results. (If you want to better understand the theory behind Bayesian logistic regression, check out this great overview by Will Kurt or this rstanarm tutorial)", "We\u2019ll use the four steps of Bayesian analysis outlined by Stan to get a better understanding of our results:", "The Four Steps of Bayesian Analysis:", "1. Specify a joint distribution for the outcome(s) and all the unknowns, which typically takes the form of a marginal prior distribution for the unknowns multiplied by a likelihood for the outcome(s) conditional on the unknowns. This joint distribution is proportional to a posterior distribution of the unknowns conditional on the observed data", "2. Draw from posterior distribution using Markov Chain Monte Carlo (MCMC).", "3. Evaluate how well the model fits the data and possibly revise the model.", "4. Draw from the posterior predictive distribution of the outcome(s) given interesting values of the predictors in order to visualize how a manipulation of a predictor affects (a function of) the outcome(s).", "We\u2019ll use Rstan \u2014 the R interface to Stan \u2014 to specify our posterior distribution, draw samples using MCMC, and evaluate model fit. Specifically, we use the rstanarm package.", "First off, what are our priors? Let\u2019s assume we\u2019re on a newly formed team that has no previous knowledge of test results. This means we have no prior belief about what our conversion rate or spend should be. Rstanarm handles this nicely by using weakly informative priors by default. The default priors for the intercept and input coefficients are assumed to be normal distributions, and Rstanarm adjusts the scales according to the data. More detail about priors and their implementation can be found in the rstanarm vignette. We\u2019ll check in later to see how rstanarm has (or has not) adjusted the default priors.", "Next we need to specify a few key details in the modeling stage. Since our outcome is a conversion rate (0 or 1), we\u2019ll use the binomial distribution with a logit link function. We\u2019ll set chains = 4 so that we can run 4 different Markov chains and ensure that the resulting samples all converge on the same parameter estimates. We then set the number of iterations at 4,000, with a warmup of 2,000. This means each chain has 2,000 iterations to train and adjust the priors (if needed), and with 4 chains we end up with a healthy 8,000 record sample drawn from the posterior.", "A quick check of the summary stats looks good. Rhat is very close to 1 for all parameters, indicating that the model successfully converged on a posterior distribution for each one. We also see the effective sample size for each parameter is relatively high, well above 10% of sample size (8,000). Additionally, looking at the trace plots we see each of the 4 chains converged around the same parameter estimates for both the intercept and our Group coefficient. Notice that the weakly-informative default priors did not change.", "The output from training our model is a set of 8,000 values sampled from the posterior distribution. We have samples for the intercept and the coefficient on our single predictor Group. Just like before, the model has turned our predictor into a dummy variable In_House_Flag_conv.", "Because our predictor is a dummy variable where In-House = 1 and Designer = 0, we can compare the Designer content against the In-House content by looking at just the sampled coefficients of our predictor In_House_Flag_conv (the right-hand column above).", "A negative value for the coefficient indicates In-House had a lower conversion rate than Designer, and a positive value indicates the opposite. The probability that Designer outperforms In-House is simply the proportion of draws where In_House_Flag_conv < 0.", "We see that In_House_Flag_conv was negative 90% of the time, therefore the probability of Designer content yielding a higher conversion rate than B is 90%. In other words, if we ran this test 100 times, we would expect more conversions from Designer content 90 times out of 100.", "For the visual learners, it may help to plot the posterior distribution to see how different the two Groups really are.", "From a marketing perspective, Designer content is a pretty clear winner. There\u2019s no inherent difference in cost to produce and send emails with A content, so the decision to go with Designer over In-House seems like a no-brainer. But conversion rate is only half of the picture\u2026", "Because we\u2019re in business to make money, we also want to know how much customers actually spend when they convert. The different email content may inspire different purchase behaviors, which we\u2019ll need to factor in when we present the total expected value of our campaign to our stakeholders.", "We\u2019ll use the same sequence as above, fit the model (specify our posterior distribution), draw samples using MCMC, and evaluate model fit. The only real tweaks here are switching our response variable to spend and the distribution family to gaussian to accommodate our continuous, normally distributed response variable.", "Again the summary stats look good. Rhat = 1 for all parameters, the effective sample size for each parameter is high, and the trace plots show that all chains converged around the same parameter estimates for the intercept, our Group coefficient and the sigma error term.", "Using the same process as before, we\u2019ll compare Designer vs. In-House using our dummy variable, this time named In_House_Flag_spend. We take the proportion of In_House_Flag_spend < 0 across our 8,000 samples to get the probability that Designer outperformed In-House.", "Sure enough, customers receiving Designer content spent more than those receiving In-House content 92% of the time. Now let\u2019s see what that translates to in dollars.", "So our Designer customers spent about $15.55 more on average than In-House customers when they shop from the email. Now we have two pieces of strong evidence showing that Designer content drives a higher conversion rate and spends more when they convert. Now let\u2019s combine the two signals to see what the difference in total value is between the two.", "We can calculate total value by combining the random samples from our conversion and spend posterior distributions. The total value of a campaign is given by the percent of customers who convert multiplied by the total amount they spend. So, using our posterior samples, we simply multiply the conversion coefficients by the spend coefficients for each Group and compare.", "We\u2019ll start by looking at the probability that the total value of our Designer customers is greater than the total value of our In-House customers. In R, it looks something like this:", "We have a 96% probability that Designer has a higher total value than In-House. This is a pretty strong sign that the Designer content is truly worth more to the business.", "Now that we have a very strong probability, the question is how much is the expected difference in revenue? We can combine the Conversion and Spend samples and calculate the average difference in total value between the two Groups. This will tell us how much extra revenue we can expect for each customer we send the email to.", "From our combined posterior distributions we calculate a difference in total value of $1.89 in favor of Group B. This means that on average, we would expect $1.89 more revenue per send using Designer content vs. In-House content. Not bad considering we can roll this out to 1 million subscribers over the year!", "And finally, we can visualize these distributions using ggplot.", "Notice that the mean for Designer is just shy of 7.5 and the mean for In-House is about 5.5, right on the nose of ~1.89.", "In this article, we walked through a comparison of Frequentist and Bayesian analysis for A/B test measurement. Overall, Frequentist and Bayesian approaches brought us to roughly the same conclusions, with slightly different interpretations.", "Analyzing the results demonstrated a clear advantage of running Designer content over In-House content, culminating in an extra $1.89 in revenue per email sent. With our 1 million qualifying email subscribers, this translates to $1.89 million in additional annual revenue by choosing the right content.", "Note: I revised the original article to reflect a more apples-to-apples comparison between Frequentist and Bayesian methods. A reader brought up the observation that in many A/B test scenarios, the p-value derived from a one-tailed t-test of means is equivalent to the Bayesian inferred probability of A being greater than B. This updated version shows that both approaches arrive at roughly the same numerical results and general confidence in those results.", "You can download the full code from my GitHub", "Thanks to Curt Bergmann for introducing me to this technique and providing guidance as I learned.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "NYC-based data scientist and NCSU alum"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9e444df379ca&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e444df379ca--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e444df379ca--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nate.peifer?source=post_page-----9e444df379ca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nate.peifer?source=post_page-----9e444df379ca--------------------------------", "anchor_text": "Nate Peifer"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F289127324dd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&user=Nate+Peifer&userId=289127324dd1&source=post_page-289127324dd1----9e444df379ca---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e444df379ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e444df379ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@firmbee?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "William Iven"}, {"url": "https://unsplash.com/s/photos/measurement?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/streamlining-design-and-maximizing-success-for-agile-test-and-learn-443156d9b2f1", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/intro-to-bayesian-statistics-5056b43d248d", "anchor_text": "Pranav Prathvikumar"}, {"url": "https://www.countbayesie.com/blog/2019/6/12/logistic-regression-from-bayes-theorem", "anchor_text": "this great overview"}, {"url": "http://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf", "anchor_text": "rstanarm tutorial"}, {"url": "https://mc-stan.org/rstanarm/articles/rstanarm.html", "anchor_text": "Stan"}, {"url": "https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html", "anchor_text": "rstanarm vignette"}, {"url": "https://github.com/peifern/bayesian_regression", "anchor_text": "GitHub"}, {"url": "https://www.linkedin.com/in/curtbergmann/", "anchor_text": "Curt Bergmann"}, {"url": "https://medium.com/tag/r?source=post_page-----9e444df379ca---------------r-----------------", "anchor_text": "R"}, {"url": "https://medium.com/tag/a-b-testing?source=post_page-----9e444df379ca---------------a_b_testing-----------------", "anchor_text": "A B Testing"}, {"url": "https://medium.com/tag/bayesian-inference?source=post_page-----9e444df379ca---------------bayesian_inference-----------------", "anchor_text": "Bayesian Inference"}, {"url": "https://medium.com/tag/measurement?source=post_page-----9e444df379ca---------------measurement-----------------", "anchor_text": "Measurement"}, {"url": "https://medium.com/tag/marketing?source=post_page-----9e444df379ca---------------marketing-----------------", "anchor_text": "Marketing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e444df379ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&user=Nate+Peifer&userId=289127324dd1&source=-----9e444df379ca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e444df379ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&user=Nate+Peifer&userId=289127324dd1&source=-----9e444df379ca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e444df379ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e444df379ca--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9e444df379ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9e444df379ca---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e444df379ca--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9e444df379ca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9e444df379ca--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9e444df379ca--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9e444df379ca--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9e444df379ca--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9e444df379ca--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9e444df379ca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nate.peifer?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nate.peifer?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nate Peifer"}, {"url": "https://medium.com/@nate.peifer/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "24 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F289127324dd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&user=Nate+Peifer&userId=289127324dd1&source=post_page-289127324dd1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F58e6b586ac4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fembracing-bayesian-a-b-test-measurement-and-ditching-p-values-9e444df379ca&newsletterV3=289127324dd1&newsletterV3Id=58e6b586ac4e&user=Nate+Peifer&userId=289127324dd1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}