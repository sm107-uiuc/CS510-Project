{"url": "https://towardsdatascience.com/bootstrapping-vs-permutation-testing-a30237795970", "time": 1683016237.2452831, "path": "towardsdatascience.com/bootstrapping-vs-permutation-testing-a30237795970/", "webpage": {"metadata": {"title": "Bootstrapping vs. Permutation Testing | by Yevgeniy (Gene) Mishchenko | Towards Data Science", "h1": "Bootstrapping vs. Permutation Testing", "description": "The main goal of this article is to theoretically and experimentally compare the two resampling methods and then draw some conclusions on when each one should be used, in the scenarios when\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.data.gov/", "anchor_text": "https://www.data.gov/", "paragraph_index": 3}, {"url": "https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html", "anchor_text": "here", "paragraph_index": 8}], "all_paragraphs": ["The main goal of this article is to theoretically and experimentally compare the two resampling methods and then draw some conclusions on when each one should be used, in the scenarios when technically there is room for using either one. What prompted me to write this article is what I perceived to be the lack of freely available clear guidelines on this subject at the beginner level. In some learning materials I even encountered the statement that we can use either one, without any further explanations.", "Main sections of the article:1. As an introduction to bootstrapping, we will calculate confidence intervals and test some hypotheses analytically and then solve the same problems non-parametrically using the bootstrap method.2. As an introduction to permutation testing (also called significance testing), we will test a hypothesis using a permutation test on the same data as in Section 1.3. We will develop a slightly more elaborate example, design a couple of hypothesis tests and compare the bootstrap distributions and the permutation distributions of replicated statistics side-by-side for each test.", "We invited some of our best friends over: NumPy, SciPy and Matplotlib\u2026 Pandas will take a day off, since the data sets that we will use are rather simple.", "For the first part we will be using the 2008 US presidential election results from the \u201cswing states\u201d of PA and OH, specifically, the % of voters who voted for the Democrats within each county in a given state (source: https://www.data.gov/).", "For this section and for the next section of the note we will be using the same data and the same statistic for the consistency of examples \u2014 the difference between PA and OH mean voting percentages.", "Let\u2019s look at the mean, median, SD and sample size for each state, as well as the histograms:", "Conclusion: the distributions don\u2019t look perfectly Normal, but they are probably close enough for testing the parametric (analytical) solutions, and they are slightly positively skewed (the means are larger than the medians, the tails are longer on the right/positive side).", "(assuming the Normal distributions of the populations)", "First, let\u2019s find the lower and the upper critical values (LCV and UCV) using the Normal sample distribution (the z-scores with alpha/2 to the left and alpha/2 to the right correspondingly). In Python this can be done by using the scipy.stats.norm.ppf() method that takes the AUC to the left (i.e. the percentile rank) as input and returns the Z-score corresponding to the percentile rank provided.NOTE 1: This is the inverse of the scipy.stats.norm.cdf() method that takes a Z-score and returns the corresponding percentile rank. These are the two most frequently used Python methods for this kind of analysis, but here is the SciPy tutorial for additional information.NOTE 2: If instead of the Normal distribution we wanted to use the Student\u2019s t distribution, we would use the scipy.stats.t class and its methods, which take the degrees of freedom as an additional agrument.", "Great! Now we don\u2019t need to carry around these silly lookup tables\u2026Next, we need the standard error (SE) for the difference of the means.The formula is: sqrt(std(sample_1)^2 / len(sample_1) + std(sample_2)^2 / len(sample_2))", "Finally, we need the empirical difference of the means:", "Now we are ready to calculate the confidence interval analytically:", "Conclusion:We estimate with 90% confidence that the true difference between the mean votes for PA and for OH is between -1.449 and 3.766(assuming approximately Normal distributions of the samples)This result was verified using an online CI calculator that uses the Student's t distribution and the result was very close to ours, but a little wider, as expected: (-1.4676, 3.7876)", "Bootstrapping, and resampling methods in general, are very powerful because they make fewer assumptions about the population distributions (there is no normality constraint, for example), there are typically no formulas involved and the calculations are relatively simple.", "First, we need to calculate a large number of bootstrap replicates of the test statistic.", "Let\u2019s define a reusable function that we can utilize for producing the bootstrap replicates of a test statistic, calling some base statistical function (pre-defined or user-defined) that operates on each sample.NOTE that we are NOT mixing the data from different samples before resampling and calculating each replicate.", "Generate the BS replicates for our task:", "It\u2019s always a good idea to check the distribution of the test statistic replicates visually:", "Now we can apply the np.percentile() function to this large set of generated BS replicates in order to get the upper and the lower limits of the confidence interval in one step. For the lower limit calculation we provide alpha/2 as the second argument to the function and for the upper limit calculation we provide the complement of alpha/2, since the function expects the cumulative percentile rank as the second argument.The confidence interval derived using percentile calculations is called the Bootstrap Percentile Confidence Interval:", "NOTE: if (and only if) the BS replicates distribution appears to be Normal and centered around the true parameter value (the bias is small), we can use the following formula to calculate the Bootstrap t Confidence Interval:BS_stat_mean +/- t * SE", "Conclusion:The result is quite close to the analytical one (-1.449, 3.766), but here we didn't make any assumptions about the distributions of the samples.", "First, we will be testing the hypothesis that the true difference between the population means is 0. The test conditions are:", "Let\u2019s use the Z-value method.We need to calculate the Z-value for the hypothesized difference of the means. The formula is:Zc = [(sample_mean_1 - sample_mean_2) - (hyp_difference)] / SEThe critical Z-values are the same as in calculating the confidence interval above: -1.645 and 1.645.SE (Standard Error) can be re-used as well from calulating the CI: 1.585.The hypothesized difference between the means is 0.", "So we get the following for the calculated Z-score (Zc):", "Conclusion: fail to reject (FTR) the null hypothesis at the 90% confidence level, since the calculated Z-value of 0.731 is well between the critical values of -1.645 and 1.645.Intuitively, it makes sense because the standard deviations of both samples are quite large relatively to the mean values (21% and 22% respectively) and several times larger than the empirical difference of the means.", "NOTE: the right tail p-value (AUC to the right) associated with this Z score for the normal distribution is 0.23239.The two-tailed p-value is the double of that: 0.465.So, if we wanted to use the p-value method analytically, it also would have resulted in the FTR decision because this p-value is much larger than the sum of our rejection regions at the tails (0.05 each), defined by our total significance level of 10%.", "The main advantage of using the bootstrap method over the analytical method when comparing two groups is that under the BS method there is no Normality restriction for the populations. Also, we are not restricted here to just the comparison of the means.", "The basic process of generating the bootstrapped test statistic replicates is the same as in the above section on CI (also without mixing the sample populations, and sampling with replacement), so we will use the same function:", "The additional important step (when compared to finding a CI) is centering the distribution of the replicates around the hypothesized mean:", "Let\u2019s make sure that our final set of BS replicates is in order (centered around the hypothesized mean and the BS version of the Standard Error is close to the analytical one):", "Looks good\u2026 now we can get the percentile rank of the empirical difference of the means within this set of BS replicates:(scipy.stats.percentileofscore() is the inverse of np.percentile())", "We need to interpret this result very carefully now, depending on what kind of test we are conducting, in order to get the p-value:", "So our p-value here for the two-tail test that we are conducting is:", "Conclusion: fail to reject (FTR) the null hypothesis at the 90% confidence level because the p-value is much larger than the significance of 0.10.", "Here we will be testing the hypothesis that the true difference between the PA and OH means is less than or equal to -2.0 (in other words, it was expected that the mean voting percentage for OH is at least 2.0 larger than for PA).", "NOTE: when stating this one-tailed hypothesis we are keeping the same order of the means as in the above examples for illustrative purposes, even though the more natural way to state this inequality would be \u201cOH mean \u2014 PA mean >= 2\u201d.", "Ho : (mean PA voting %) \u2014 (mean OH voting %) <= -2Ha : (mean PA voting %) \u2014 (mean OH voting %) > -2CL : 90%Direction : right-tailed (since the Ho rejection region that corresponds to our Ha is on the right)", "We need to calculate the Z-value for the hypothesized difference of the means. The formula is:Zc = [(sample_mean_1 - sample_mean_2) - (hyp_difference)] / SESE (Standard Error) can be re-used from calulating the CI, which is 1.585.The difference between the hypothesized means is -2.We assume the Normal distributions of the populations.So we get the following for the calculated Z-score (Zc):", "If using the Z-value method, we need to calculate the upper critical z-value for the right-tail alpha of 0.10, which can be compared directly to the calculated Z-score:", "If using the P-value method, we need to find the right-tail p-value associated with the calculated Z-score.First, we calcualte the AUC on the left:", "Since we are looking for the p-value under the right tail, we need to subtract this from 1:(if we were conducting a left-tailed test, we would take this AUC value as-is)", "Conclusion: reject the null hypothesis because:", "The basic process of generating the bootstrap replicates is the same as before:", "The additional important step (when compared to finding a CI) is centering the distribution of the replicates around the hypothesized mean:", "Let\u2019s make sure that our population of BS replicates is centered around the hypothesized mean and the BS version of the Standard Error is close to the analytical result:", "Looks good\u2026 now we can get the percentile rank of the empirical difference of the means within this set of BS replicates:", "INTERPRETATION:Since this is the right-tailed test, the p-value is the AUC to the right (which is pretty close to the analytical result of 0.0232).And since we are conducting a one-tailed test, we can compare this value to the significance level directly.", "Conclusion: reject the null hypothesis because the p-value is smaller than the significance of 0.10.", "Permutation tests are used to determine whether an observed effect could reasonably be ascribed to the randomness introduced in selecting the sample(s). If not, we have the evidence that the effect observed in the sample(s) reflects an effect that is present in the population(s). Permutation tests are very popular in the controlled settings like clinical studies, where a group that receives some treatment needs to be compared to the control group that does not receive any treatment.", "When permutation tests can be used:", "Basically, we can perform PT when there are two sets of data and the null hypothesis states that some observed effect between them is observed by accident.", "When permutation tests should be used instead of bootstrap tests:", "In two-sample test settings, we can choose between a bootstrap test and a permutation test. Even though a test statistic for a two-sample permutation test may be chosen to be the same as for a two-sample bootstrap test (e.g. the difference between the sample means), the underlying nature of the tests is quite different: a permutation test really looks at whether the two samples can hypothetically come from the same population using a certain narrow statistic, while a bootstrap test looks specifically at the statistic itself, so a permutation test is a \u201cdeeper\u201d, more general comparison than a bootstrap test, BUT (beware!) the test statistic may not show it, depending on how you design it and how well it captures the actual differences between the samples.", "In summary, permutation tests should be used for:", "Just in order to introduce the process itself, let\u2019s use the same two-sample scenario that we used to test the difference between the population means using the bootstrap test (BT):", "Ho : the underlying distributions are the same (means AND other features)Ha : mean(PA voting %) \u2014 mean(OH voting %) != 0CL : 90 %Direction : two-tailed (our alternative hypothesis does not suggest a direction and we need to identify ALL the hypothesized values of the test statistic that are as extreme or more extreme than the empirical value \u2014 on both tails, regardless of signs).", "NOTE: The test statistic and the alternative hypothesis here are the same as for the bootstrap test that we conducted, but the null hypothesis has to remain very general just due to the nature of the process of test statistic replication via permutation (we will shortly see why). The logic here is that once there is enough evidence to accept a rather specific alternative hypothesis, we can reject a very general null hypothesis, which is the conjunction of many things, including the opposite of the alternative hypothesis. Using a legal analogy, in a criminal case it may take only one line of very specific evidence out of plethora of all available evidence to break the very general presumption of innocence. Unlike in the legal setting, however, in permutation testing we are frequently not interested in the null hypothesis itself (unless the actual test goal is knowing whether the populations are identical). So the focus shifts to the alternative hypothesis.", "Let\u2019s define a reusable function that we can utilize for producing the permutation replicates of a test statistic, calling some base statistical function (pre-defined or user-defined) that operates on each sample.", "Now let\u2019s generate the set of permutation replicates:", "Let\u2019s take a brief look at the hypothesized distribution of the difference of the means. It should be centered around zero and should be approximately normal.", "Now we need to get the p-value from both tails associated with the empirical difference of the means using this distribution.NOTE that while the permutation distribution should be relatively symmetrical in most cases because of the Central Limit Theorem, as a good practice it is better to get the AUC under both tails directly.There are a couple of technical ways to do it:", "Conclusion: FTR (keep) the null hypothesis that the distributions of the voting percentages in favor of Democrats by county for PA and for OH are the same, since the resulting p-value is larger than the significance of 0.10.", "It\u2019s probably worth noting that the p-value here turned out to be slightly larger than when comparing the means using the analytical method and the bootstrap method (0.465)... The samples are similar, so it is hard to tell whether this difference in results really means anything, but in general the larger p-value is a stronger basis for keeping the null hypothesis.", "Since there is some overlap between the situations when bootstrapping can be used and the situations when permutation can be used, let\u2019s experimentally compare the corresponding populations of the replicated test statistics, so we understand the implications of using them better.Each comparison will consist of the following hypothesis testing workflow, partially conducted:", "(1) State the high-level business objectives and how the research that we are conducting relates to them. Be as specific as possible when stating the business objectives and the current research goals in their context.(2) Define the statistics that may help us reach the research goals (here we will assume that these samples are the only data sets that we get, but normally this phase includes an iterative process of data discovery, EDA and/or new data collection setup, as necessary and as feasible).(3) Design the statistical inference tasks that use the above statistics to meet the above research goals. Create as many tasks as necessary of any kind necessary. The items below need to be stated for each hypothesis test:", "Step (1) often may seem trivial and unnecessary, but it is required to choose the statistics and to design the tests correctly.Steps (1) and (2) will be shared among the bootstrap and the permutation tests in our comparison.We won\u2019t be performing step (4) \u2014 actually conducting the tests \u2014 so we won\u2019t need to define the confidence intervals.", "We will focus on comparing the two distributions of the test statistic replicates and the corresponding p-values for:", "Research goals: this is an imaginary controlled study of the effects of a new teaching methodology on the grades of college students. It is integrated directly into the development and testing process of the new teaching methodology. We are tasked to look specifically at the effectiveness of the new methodology, as measured by the students\u2019 test scores. The study\u2019s conclusions will be used, along with other considerations, in making the decision on whether to switch to the new teaching methodology for the subject.Study setup: there is a randomly composed \u201ctreatment\u201d group that receives the new kind of instruction during one semester and there is a randomly composed \u201ccontrol\u201d group that receives the traditional instruction for the same subject. Each group consists of 100 students. The instructors who teach the subject must teach both groups of students, so that the instruction-side human factor is taken out of the equation as much as possible. The mid-term and the final exams are identical for both groups of students.The data collected for each group are the per-student averages of the mid-term and of the final exam scores on the 0\u2013100 scale.", "Conclusion: It appears that the the average score improved by about 2 points, and there are many more A and B students in the treatment group relative to the control group, but something is going on on the low end as well \u2014 more students are failing (score < 70) and with larger margins.So we can see both the potential positive effects and the potential negative effects that we can test for in this example.", "Let\u2019s assume here that the only business objective that we care about is the imrovement of average learning results among all students.Test statistic: we consider any statistically significant positive difference of the mean test score between the treatment group and the control group of students to be the proof that the business objectives are being met.", "Ho : mean(treatment group score) \u2014 mean(control group score) = 0Ha : mean(treatment group score) \u2014 mean(control group score) > 0Direction : right-tailed", "Ho : the student scores distributions are the same (including the means)Ha : mean(treatment group score) \u2014 mean(control group score) > 0Direction : right-tailed", "First, let\u2019s generate and plot the two replicate distributions:", "Not a huge difference between the distributions, with the permutation replicates distributed slightly wider (for larger sample sizes this difference between the distributions is smaller, and for smaller sample sizes the difference is more substantial).", "Now let\u2019s look at the p-values. Since we are conducting a right-tailed test, the p-value is the complement of the percentile rank of the observed value:", "Conclusion: the permutation method adds more randomness to the testing process than bootstrapping (this difference is more obvious when the samples are smaller), so we get a more conservative answer. This is why permutation testing is a better choice for categorical hypothesis testing.In this specific example, if our significance level were set at 10%, the choice of the method would make the critical difference, since the p-values fall on the different sides of it (and this is also why we should always determine a significance level before implementing a test \u2014 so we are not tempted to back-solve).", "Now, let\u2019s say that in terms of business objectives, the university management cares not only about the average learning outcomes, but also about the dropout and failure rates of students (keeping these rates as low as possible, of course).Assuming that the research goals, study setup and data collected stay the same with this new information all the way from the top, what can we do to meet the research goals?", "Well, given this artificial data set, there is nothing we can do to measure the drop-out rate (or the course completion rate), but in real life the test scores of the students who complete the course would be complemented with this kind of information\u2026 So let\u2019s focus on analyzing just the test scores on the low end of the spectrum.", "The \u201cbase\u201d statistic for each data set that we may want to consider is the average score below the lower quartile. So the test statistic will be the difference between the base statistic for the treatment group and the base statistic for the control group. Just like the difference of the mean test scores, it\u2019s a positive measure, meaning that if it has a positive sign, it\u2019s good for business, and vice versa.Let\u2019s define a function for calculating the base statistic that we can pass to the boot_diff and the perm_diff functions:", "Now let\u2019s test it on the treatment sample and on the control sample\u2026", "The average drop of 5 points from the control sample to the treatment sample\u2026 This should be interesting\u2026 Let\u2019s set up our tests.", "Ho : mean(lowest quarter of the treatment group scores) \u2014 mean(lowest quarter of the control group scores) >= 0Ha : mean(lowest quarter of the treatment group scores) \u2014 mean(lowest quarter of the control group scores) < 0Direction : left-tailed", "Ho : the student scores distributions are the same (including the means of the lowest quarters of scores)Ha : mean(lowest quarter of the treatment group scores) \u2014 mean(lowest quarter of the control group scores) < 0Direction : left-tailed", "NOTE: we are intentionally setting the direction of the alternative hypothesis in the direction of the preliminary discovery that we made during the EDA\u2026 Otherwise, the permutation test will not be very useful in the case of the FTR outcome (failure to reject the null hypothesis) because the null hypothesis is so general (and it has to remain such in PT). It\u2019s perfectly normal in the research process to have to keep the null hypothesis after the first test and then to try constructing a different test to \u201cbreak it\u201d, but if we have a \u201chunch\u201d based on the EDA and we think we can do it in one test, why not do it?In bootstrap tests we don\u2019t have this restriction \u2014 the null hypothesis can be defined at the same level as the alternative hypothesis and be the mirror opposite, so the direction of the test becomes arbitrary.Also, as a reminder, aside from this restriction on the null hypothesis in permutation testing, the alternative hypothesis in permutation tests also has a restriction \u2014 the replicated statistic that measures some difference between the hypothesized data sets has to be centered around 0, because the directionality is lost in the process.Bootstrap tests don\u2019t have these restrictions on Ho and Ha, this is why for the quantitative testing of confirmed/expected effects bootstrapping is a natural choice.", "Again, the permutation replicates appear to be distributed slightly wider.", "Now let\u2019s look at the p-values. Since we are conducting a left-tailed test, the p-value in each case is the percentile rank of the observed value:", "Conclusion: for this use case the difference between the replicate distributions is even more obvious than for the difference of the means, with the permutation method producing a wider distribution of the test statistic and yielding a larger p-value, which serves as a more conservative null hypothesis rejection criterion.", "Bootstrapping is a more general method that is not limited to the scenarios with two sets of data, not limited to hypothesis testing and less restricted in terms of the null and the alternative hypotheses. It should be used for estimating the confidence intervals and for the quantitative hypothesis testing of known effects.", "Permutation testing can be used in the settings with two data sets (two samples, matched pairs, or two variables in one sample) and it should be used when we are interested in confirming the presence (or the absence) of a certain effect that is observable between the two data sets.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist and knowledge engineer by day, post-positivist and knowledge advocate by night."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa30237795970&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a30237795970--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a30237795970--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@gene.mishchenko?source=post_page-----a30237795970--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gene.mishchenko?source=post_page-----a30237795970--------------------------------", "anchor_text": "Yevgeniy (Gene) Mishchenko"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2ddfd36d656a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&user=Yevgeniy+%28Gene%29+Mishchenko&userId=2ddfd36d656a&source=post_page-2ddfd36d656a----a30237795970---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa30237795970&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa30237795970&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://www.data.gov/", "anchor_text": "https://www.data.gov/"}, {"url": "https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html", "anchor_text": "here"}, {"url": "https://medium.com/tag/hypothesis-testing?source=post_page-----a30237795970---------------hypothesis_testing-----------------", "anchor_text": "Hypothesis Testing"}, {"url": "https://medium.com/tag/bootstrapping?source=post_page-----a30237795970---------------bootstrapping-----------------", "anchor_text": "Bootstrapping"}, {"url": "https://medium.com/tag/permutations?source=post_page-----a30237795970---------------permutations-----------------", "anchor_text": "Permutations"}, {"url": "https://medium.com/tag/confidence-interval?source=post_page-----a30237795970---------------confidence_interval-----------------", "anchor_text": "Confidence Interval"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----a30237795970---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa30237795970&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&user=Yevgeniy+%28Gene%29+Mishchenko&userId=2ddfd36d656a&source=-----a30237795970---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa30237795970&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&user=Yevgeniy+%28Gene%29+Mishchenko&userId=2ddfd36d656a&source=-----a30237795970---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa30237795970&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a30237795970--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa30237795970&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a30237795970---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a30237795970--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a30237795970--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a30237795970--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a30237795970--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a30237795970--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a30237795970--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a30237795970--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a30237795970--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gene.mishchenko?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gene.mishchenko?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yevgeniy (Gene) Mishchenko"}, {"url": "https://medium.com/@gene.mishchenko/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "12 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2ddfd36d656a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&user=Yevgeniy+%28Gene%29+Mishchenko&userId=2ddfd36d656a&source=post_page-2ddfd36d656a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F2ddfd36d656a%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbootstrapping-vs-permutation-testing-a30237795970&user=Yevgeniy+%28Gene%29+Mishchenko&userId=2ddfd36d656a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}