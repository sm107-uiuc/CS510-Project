{"url": "https://towardsdatascience.com/ultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91", "time": 1683016353.17308, "path": "towardsdatascience.com/ultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91/", "webpage": {"metadata": {"title": "Ultimate Guide to Reinforcement Learning Part 1 \u2014 Creating a Game | by Daniel Brummerloh | Towards Data Science", "h1": "Ultimate Guide to Reinforcement Learning Part 1 \u2014 Creating a Game", "description": "The complete code of the environment, the training and the rollout can be found on GitHub: https://github.com/danuo/rocket-meister/ This is the first part of the series. We will implement the game\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/danuo/rocket-meister/", "anchor_text": "https://github.com/danuo/rocket-meister/", "paragraph_index": 0}, {"url": "https://www.pygame.org/docs/ref/draw.html", "anchor_text": "Pygame documentary", "paragraph_index": 13}], "all_paragraphs": ["The complete code of the environment, the training and the rollout can be found on GitHub: https://github.com/danuo/rocket-meister/", "Part 1 \u2014 Creation of a playable environment with Pygame", "Part 2 \u2014Training a Neural Network with Reinforced Learning", "This is the first part of the series. We will implement the game logic, acquire user input data for the controls and implement rendering to make it possible for humans to play the game. For this, we will be using a popular python package called Pygame.", "As the model we are going to train is relatively small, the training can be performed on a consumer level desktop CPU in a reasonable amount time (less than a day). You do not need a powerful GPU or access to a cloud computing network. The python packages used in this guide are listed below:", "In the context of reinforced learning, an environment can be seen as an interactive problem, that needs to be solved in the best way possible.", "To quantify the success, a reward function is defined within the environment. The agent can see the so called observations that give information about the current state of the environment. It can then take a specific action, which will return the observation and the scalar reward of the next environment\u2019s state. The agent\u2019s goal is to maximize the sum of rewards achieved in a limited number of steps.", "From a technical standpoint, there are many different ways build an environment. The best way though, is to adopt the structure defined in the gym package. The gym package is a collection of ready to use environments providing a de facto standard API for reinforced learning. All gym environments share the same names for functions and variables, which makes the environment and the agent easily interchangeable. To adopt the gym structure, we will make our environment a sub-class of the gym.Env class. The fundamental and mandatory elements of the class are shown below:", "Most of these functions and variables will be discussed in more depth later on. Here is a small summary with the most important items lisetd first:", "As seen in the video, we want to control a rocket which can be accelerated forwards/backwards (action 1) and rotated left/right (action 2). Thus, we define the actions as a linear vector of the size 2.", "The values of each array cell are continuous and must be in the range of [-1,1]. The corresponding gym space is defined in the following line of code:", "Pygame is a Python library designed for the creation of simple games. Key features are 2d-rendering capabilities, user input acquisition and options for audio output. The following section will cover a very basic Pygame implementation with the bare minimum features. If you are more ambitious, you can consider implementing features such as dynamic frame rate or dynamic resolution.", "To render in Pygame, we need to create a window (also called surface) to draw the visual output on.", "Next, we can queue draw calls for the created window. You can find an overview of the available draw calls in the Pygame documentary. We will implement a couple of exemplary draw calls in a new function that we add to our CustomEnv class. The function is called render() and looks as follows:", "After the draw calls are made, the window needs to be updated and actually rendered with the pygame.display.update() command.", "Now it\u2019s time to throw it all together by creating a render loop routine that can keep our environment running. We initialize Pygame with pygame.init() Then we create a clock object, that can maintain a static frame rate in combination with tick(fps). We create a window of the size 1000*500 pixels for the visual output. Then we start a while loop that will perform step() and render() once before one frame is generated with update(). Obviously, this render loop only makes sense, if the render() actually reflects the changes induced by step().", "Pygame offers two ways to acquire user input data from the keyboard:", "Next, we will implement the kinematics of the rocket. While we use a simple approach for the rotation, the translational movement will have inertia. Mathematically, the rocket\u2019s trajectory is the solution of the Equation of Motion and is smooth. The position cannot jump, but needs to change continuously instead.", "Since we are fine with an approximate solution, we can calculate the trajectory using a time discretization with the Euler Forward Method. A simple and minimal 2-d implementation is shown in the following code:", "Now we incorporate everything (gamelogic, input and rendering) into our previously defined CustomEnv class. We will also move everything related to Pygame into the render() and a separate init() function. This way, we can execute Machine Learning routines with step() and reset() without loading the heavier Pygame package. If the environment is loaded for the AI-training, the rendering is not needed and the performance can be increased.", "Here is the above code running with some keyboard inputs:", "For now, we will be using a manually created static level. Creating one can be a tedious task. We will use Matplotlib to make our live a little bit easier. With the plt.ginput() function, coordinates can be captured by clicking inside the figure.", "These coordinates will be printed into the console, from where you can copy them into your code. A little reformatting should make it possible to include them into our environment, for example by storing them in numpy array as seen in rocket_gym.py.", "Let\u2019s assume we have the level boundary stored as an array of the size n*4, each line holding the points of one segment:", "If two lines intersect can be checked by the following function. If the lines intersect, coordinates of the intersecting point are returned. If there is no intersection, None is returned.", "Now, we can apply the formula to our problem. We do this by checking, if any of the environment boundaries intersect with the movement vector", "In the second part, we will discuss and implement the observations and rewards that are returned by the environment. After that, the actual training is conducted. Have a read over here:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F956f1f2b0a91&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@d.brummerloh?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@d.brummerloh?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "Daniel Brummerloh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F947fdd60d7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&user=Daniel+Brummerloh&userId=947fdd60d7c3&source=post_page-947fdd60d7c3----956f1f2b0a91---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F956f1f2b0a91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F956f1f2b0a91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://github.com/danuo/rocket-meister/", "anchor_text": "https://github.com/danuo/rocket-meister/"}, {"url": "https://medium.com/@d.brummerloh/ultimate-guide-for-ai-game-creation-part-2-training-e252108dfbd1", "anchor_text": "https://medium.com/@d.brummerloh/ultimate-guide-for-ai-game-creation-part-2-training-e252108dfbd1"}, {"url": "http://gym.openai.com/docs/#spaces", "anchor_text": "documentation"}, {"url": "https://github.com/openai/gym/tree/master/gym/spaces", "anchor_text": "gym GitHub"}, {"url": "https://www.pygame.org/docs/ref/draw.html", "anchor_text": "Pygame documentary"}, {"url": "https://www.pygame.org/docs/ref/key.html", "anchor_text": "Pygame documentation"}, {"url": "https://medium.com/@d.brummerloh/ultimate-guide-for-ai-game-creation-part-2-training-e252108dfbd1", "anchor_text": "https://medium.com/@d.brummerloh/ultimate-guide-for-ai-game-creation-part-2-training-e252108dfbd1"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----956f1f2b0a91---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----956f1f2b0a91---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----956f1f2b0a91---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/pygame?source=post_page-----956f1f2b0a91---------------pygame-----------------", "anchor_text": "Pygame"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----956f1f2b0a91---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F956f1f2b0a91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&user=Daniel+Brummerloh&userId=947fdd60d7c3&source=-----956f1f2b0a91---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F956f1f2b0a91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&user=Daniel+Brummerloh&userId=947fdd60d7c3&source=-----956f1f2b0a91---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F956f1f2b0a91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F956f1f2b0a91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----956f1f2b0a91---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----956f1f2b0a91--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@d.brummerloh?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@d.brummerloh?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Daniel Brummerloh"}, {"url": "https://medium.com/@d.brummerloh/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "25 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F947fdd60d7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&user=Daniel+Brummerloh&userId=947fdd60d7c3&source=post_page-947fdd60d7c3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3b7af2004bb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91&newsletterV3=947fdd60d7c3&newsletterV3Id=3b7af2004bb9&user=Daniel+Brummerloh&userId=947fdd60d7c3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}