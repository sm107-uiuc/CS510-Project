{"url": "https://towardsdatascience.com/a-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc", "time": 1683005463.698096, "path": "towardsdatascience.com/a-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc/", "webpage": {"metadata": {"title": "A Quick Guide to Tokenization and Phrase Matching using spaCy | NLP | Part 2 | by Ashutosh Tripathi | Towards Data Science", "h1": "A Quick Guide to Tokenization and Phrase Matching using spaCy | NLP | Part 2", "description": "\u201c spaCy\u201d is designed specifically for production use. It helps you build applications that process and \u201cunderstand\u201d large volumes of text. It can be used to build information extraction or natural\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Reaganomics", "anchor_text": "https://en.wikipedia.org/wiki/Reaganomics", "paragraph_index": 38}, {"url": "https://ashutoshtripathi.com/2020/04/06/guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy/", "anchor_text": "http://ashutoshtripathi.com", "paragraph_index": 43}], "all_paragraphs": ["\u201c spaCy\u201d is designed specifically for production use. It helps you build applications that process and \u201cunderstand\u201d large volumes of text. It can be used to build information extraction or natural language understanding systems or to pre-process text for deep learning. In this article, you will learn about Tokenization, Lemmatization, Stop Words and Phrase Matching operations using spaCy.", "This is article 2 in the spaCy Series. In my last article, I have explained about spaCy Installation and basic operations. If you are new to this, I would suggest starting from article 1 for a better understanding.", "Tokenization is the first step in text processing task. Tokenization is not only breaking the text into components, pieces like words, punctuation etc known as tokens. However, it is more than that. spaCy do the intelligent Tokenizer which internally identifies whether a \u201c.\u201d is punctuation and separate it into token or it is part of an abbreviation like \u201cU.S.\u201d and do not separate it.", "spaCy applies rules specific to the Language type. Let\u2019s understand with an example.", "If there\u2019s a match, the rule is applied and the Tokenizer continues its loop, starting with the newly split substrings. This way, spaCy can split complex, nested tokens like combinations of abbreviations and multiple punctuation marks.", "Notice that tokens are pieces of the original text. Tokens are the basic building blocks of a Doc object \u2014 everything that helps us understand the meaning of the text is derived from tokens and their relationship to one another.", "Note that the exclamation points, comma are assigned their own tokens. However point, colon present in email address and website URL are not isolated. Hence both the email address and website are preserved.", "Here the distance unit and dollar sign are assigned their own tokens, however, the dollar amount is preserved, point in amount is not isolated.", "Punctuation that exists as part of a known abbreviation will be kept as part of the token.", "Here the abbreviations for \u201cSaint\u201d and \u201cUnited States\u201d are both preserved. Mean point next to St. is not separated as a token. Same in the U.S.", "Using len() function, you can count the number of tokens in a document.", "Vocab objects contain a full library of items!", "see all doc objects are created from the English language model, which we have loaded in the beginning using", "Hence vocab len will be the same.", "Note spaCy do not have stemming. Due to the reason that Lemmatization is seen as more informative than stemming.", "Creating a Function to find and print Lemma in a more structured way.", "Here we\u2019re using an f-string to format the printed text by setting minimum field widths and adding a left-align to the lemma hash value.", "Note that the lemma of saw is see, lemma of mice is mouse, mice is the plural form of mouse, and see eighteen is a number, not an expanded form of eight and this is detected while computing lemmas hence it has kept eighteen as untouched.", "Here the lemma of meeting is determined by its Part of Speech tag.", "for first meeting which is a verb it has calculated lemma as meet. and for second meeting which is a Noun, and it has calculated lemma as meeting itself.", "That is where we can see that spaCy take care of the part of speech while calculating the Lemmas.", "Note that Lemmatization does not reduce words to their most basic synonym \u2014 that is, enormous doesn't become big and automobile doesn't become car.", "You can print the total number of stop words using the len() function.", "There may be times when you wish to add a stop word to the default set. Perhaps you decide that 'btw' (common shorthand for \"by the way\") should be considered a stop word.", "Alternatively, you may decide that 'without' should not be considered a stop word.", "In this section, we will identify and label specific phrases that match patterns we can define ourselves.", "You can match on any part of the token including text and annotations, and you can add multiple patterns to the same matcher.", "In literature, the phrase \u2018united states\u2019 might appear as one word or two, with or without a hyphen. In this section we\u2019ll develop a matcher named \u2018unitedstates\u2019 that finds all three:", "* Remember that single spaces are not tokenized, so they don\u2019t count as punctuation.Once we define our patterns, we pass them into matcher with the name 'unitedstates', and set callbacks to None", "To make you understand I have written the United States differently like \u201cUnited States\u201d, \u201cUnitedStates\u201d, \u201cUnited-States\u201d and \u201cUnited-States\u201d", "You can make token rules optional by passing an 'OP':'*' argument. This lets us streamline our patterns list:", "This found both two-word patterns, with and without the hyphen!", "The following quantifiers can be passed to the 'OP' key:", "Suppose we have another word as \u201cSolar Power\u201d in some sentence. Now, If we want to match on both \u2018solar power\u2019 and \u2018solar powered\u2019, it might be tempting to look for the lemma of \u2018powered\u2019 and expect it to be \u2018power\u2019. This is not always the case! The lemma of the adjective \u2018powered\u2019 is still \u2018powered\u2019:", "The matcher found the first occurrence because the lemmatizer treated \u2018Solar-powered\u2019 as a verb, but not the second as it considered it an adjective.For this case it may be better to set explicit token patterns.", "Besides lemmas, there are a variety of token attributes we can use to determine matching rules:", "You can pass an empty dictionary {} as a wildcard to represent any token. For example, you might want to retrieve hashtags without knowing what might follow the # character:", "In the above section, we used token patterns to perform rule-based matching. An alternative \u2014 and often more efficient \u2014 method is to match on terminology lists. In this case, we use PhraseMatcher to create a Doc object from a list of phrases and pass that into matcher instead.", "For this exercise, we\u2019re going to import a Wikipedia article on ReaganomicsSource: https://en.wikipedia.org/wiki/Reaganomics", "The first four matches are where these terms are used in the definition of Reaganomics:", "There are a few ways to fetch the text surrounding a match. The simplest is to grab a slice of tokens from the doc that is wider than the match:", "This is all about text pre-processing operations which include Tokenization, Lemmatization, Stop Words and Phrase Matching. Hope you enjoyed the post.", "If you have any feedback to improve the content or any thought please write in the comment section below. Your comments are very valuable.", "Originally published at http://ashutoshtripathi.com on April 6, 2020.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb29b407adbfc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ashutoshtr.medium.com/?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": ""}, {"url": "https://ashutoshtr.medium.com/?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "Ashutosh Tripathi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2e643aea4066&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&user=Ashutosh+Tripathi&userId=2e643aea4066&source=post_page-2e643aea4066----b29b407adbfc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb29b407adbfc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb29b407adbfc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://ashutoshtripathi.com/2020/04/02/spacy-installation-and-basic-operations-nlp-text-processing-library/", "anchor_text": "spaCy-installation-and-basic-operations-nlp-text-processing-library/"}, {"url": "https://en.wikipedia.org/wiki/Reaganomics", "anchor_text": "https://en.wikipedia.org/wiki/Reaganomics"}, {"url": "https://ashutoshtripathi.com/2020/04/02/spacy-installation-and-basic-operations-nlp-text-processing-library/", "anchor_text": "Spacy Installation and Basic Operations | NLP Text Processing Library | Part 1"}, {"url": "https://ashutoshtripathi.com/2020/04/13/parts-of-speech-tagging-and-dependency-parsing-using-spacy-nlp/", "anchor_text": "Parts of Speech Tagging and Dependency Parsing using spaCy | NLP | Part 3"}, {"url": "https://ashutoshtripathi.com/2020/04/27/named-entity-recognition-ner-using-spacy-nlp-part-4/", "anchor_text": "Named Entity Recognition NER using spaCy | NLP | Part 4"}, {"url": "https://ashutoshtripathi.com/2020/05/04/how-to-perform-sentence-segmentation-or-sentence-tokenization-using-spacy-nlp-series-part-5/", "anchor_text": "How to Perform Sentence Segmentation or Sentence Tokenization using spaCy | NLP Series | Part 5"}, {"url": "https://ashutoshtripathi.com/2020/09/02/numerical-feature-extraction-from-text-nlp-series-part-6/", "anchor_text": "Numerical Feature Extraction from Text | NLP series | Part 6"}, {"url": "https://ashutoshtripathi.com/2020/09/04/word2vec-and-semantic-similarity-using-spacy-nlp-spacy-series-part-7/", "anchor_text": "Word2Vec and Semantic Similarity using spacy | NLP spacy Series | Part 7"}, {"url": "https://spacy.io/usage/spacy-101", "anchor_text": "https://spacy.io/usage/spacy-101"}, {"url": "https://www.udemy.com/course/nlp-natural-language-processing-with-python/", "anchor_text": "https://www.udemy.com/course/nlp-natural-language-processing-with-python/"}, {"url": "https://ashutoshtripathi.com/2020/04/06/guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy/", "anchor_text": "http://ashutoshtripathi.com"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----b29b407adbfc---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----b29b407adbfc---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/spacy?source=post_page-----b29b407adbfc---------------spacy-----------------", "anchor_text": "Spacy"}, {"url": "https://medium.com/tag/text-preprocessing?source=post_page-----b29b407adbfc---------------text_preprocessing-----------------", "anchor_text": "Text Preprocessing"}, {"url": "https://medium.com/tag/enetworkai?source=post_page-----b29b407adbfc---------------enetworkai-----------------", "anchor_text": "Enetworkai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb29b407adbfc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&user=Ashutosh+Tripathi&userId=2e643aea4066&source=-----b29b407adbfc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb29b407adbfc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&user=Ashutosh+Tripathi&userId=2e643aea4066&source=-----b29b407adbfc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb29b407adbfc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb29b407adbfc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b29b407adbfc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b29b407adbfc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b29b407adbfc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b29b407adbfc--------------------------------", "anchor_text": ""}, {"url": "https://ashutoshtr.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ashutoshtr.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ashutosh Tripathi"}, {"url": "https://ashutoshtr.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "317 Followers"}, {"url": "http://www.ashutoshtripathi.com", "anchor_text": "www.ashutoshtripathi.com"}, {"url": "https://www.youtube.com/c/AshutoshTripathi_AI", "anchor_text": "https://www.youtube.com/c/AshutoshTripathi_AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2e643aea4066&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&user=Ashutosh+Tripathi&userId=2e643aea4066&source=post_page-2e643aea4066--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F52a197d8682e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc&newsletterV3=2e643aea4066&newsletterV3Id=52a197d8682e&user=Ashutosh+Tripathi&userId=2e643aea4066&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}