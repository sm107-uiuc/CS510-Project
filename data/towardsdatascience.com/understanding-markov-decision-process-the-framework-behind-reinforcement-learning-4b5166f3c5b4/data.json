{"url": "https://towardsdatascience.com/understanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4", "time": 1683015822.822149, "path": "towardsdatascience.com/understanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4/", "webpage": {"metadata": {"title": "Understanding Markov Decision Process: The Framework Behind Reinforcement Learning | by Bima Putra Pratama | Towards Data Science", "h1": "Understanding Markov Decision Process: The Framework Behind Reinforcement Learning", "description": "This article describes the important term of the Markov Decision Process. This outlines the concept in friendly and less mathematic ways."}, "outgoing_paragraph_urls": [{"url": "https://www.itb.ac.id/", "anchor_text": "Institut Teknologi Bandung", "paragraph_index": 29}, {"url": "https://www.unsw.com/", "anchor_text": "University of New South Wales", "paragraph_index": 29}, {"url": "https://www.linkedin.com/in/bpratama/", "anchor_text": "LinkedIn", "paragraph_index": 30}], "all_paragraphs": ["Continue our journey to know Reinforcement Learning in a fun way with AWS and Jakarta Machine Learning. We have discussed AWS Deep Racer and the basics of Reinforcement Learning (RL) in the first article. For you who haven't read this article or want to reread it, don't worry. You can find it again here:", "Now, in this article, we will discuss how to formulate the RL problems. To do that, we need to understand the Markov Decision Process or well known as MDP.", "MDP is a framework that can be used to formulate the RL problems mathematically. Almost all RL problems can be modeled as MDP with states, actions, transition probability, and the reward function.", "So, why we need to care about MDP? Because with the MDP, an agent can get an optimal policy for maximum rewards over time, and we will get optimum results.", "Okay, Let's get started. To get a better understanding of MDP, we need to learn about the components of MDP first.", "The future depends only on the present and not on the past.", "That statement summarises the principle of Markov Property. On the other hand, the term Markov Property refers to the memoryless property of a stochastic \u2014 or randomly determined \u2014 a process in probability theory and statistics.", "As an example, let say you own a restaurant and manage the raw material inventory. You check the inventory each week and use the result to order the raw material for next week. This condition implies that you only consider the stock this week to predict next week's requirement without bothering last week's stock level.", "The Markov Chain consists of a sequence of states that follow the Markov property. This Markov Chain actually is the probabilistic model that depends on the current state to predict the next state.", "To understand Markov Property and Markov Chain, we will use weather prediction as an example. If the current state is cloudy, then the next state could be rainy or windy. In the middle of the first state to the next state, there is a probability that we called transition probability.", "From the image above, when the current state is cloudy, 70% of the next state will be rainy, or 30% will be windy. If the current state is windy, there is a 100% possibility the next state will be rainy. Then, when the state is Rainy, there is an 80% probability that the next state will keep rainy, and there are 20% will be changed to cloudy. We can show these states and transition probability into a table or a matrix as below:", "As a wrap, we can say that the Markov chain consists of a set of states along with their transition probabilities.", "The Markov Reward Process (MRP) is an extension of the Markov chain with an additional reward function. So, it consists of states, a transition probability, and a reward function.", "This reward function gives us the reward that we get from each state. This function will tell us the reward we obtain in the state cloudy, the reward we obtain in the state of windy, and the rainy state. This reward also can be a positive or negative value.", "Up to this point, we have already seen about Markov Property, Markov Chain, and Markov Reward Process. These become the basics of the Markov Decision Process (MDP). In the Markov Decision Process, we have action as additional from the Markov Reward Process.", "Let\u2019s describe this MDP by a miner who wants to get a diamond in a grid maze. In this scenario, a miner could move within the grid to get the diamonds.", "With this scenario, we can describe that MDP consists of:", "There are also several terminologies that we need to understand in MDP.", "Action space is an action that an agent can take to achieve the goal. In our miner example, the action space is moving up, down, left, and right. This action space can be categories into two types. The first is a discrete action space, and the second is a continuous action space.", "In MDP, agent behavior is defined as a policy. This policy tells the agent what action to perform in each state. In the beginning, we need to initialize a random policy. Then the agent will continue to learn, and the optimal policy results from iterations, where the agent performs good actions in each state, which maximizes the cumulative reward.", "This policy can be classified into two types:", "One episode is actions taken by the agent from the initial state and reaches the final state or termination state. For example, the journey from the current state into finally get the diamond. The miner movement is D > A > B > C > F > I.", "In reinforcement learning, we aim to maximize the cumulative reward in an episode. This reward is the sum of reward the agent receives instead of the reward agent receives from the current state (immediate reward). This cumulative reward is also called as returns.", "The agent can maximize the return by performing correct action in each state. It will be guided by the optimal policy to achieve this correct action.", "In the process of maximizing reward, we need to consider the importance of immediate and future rewards. Thus, the discount factor comes to action. This discount factor deciding how much importance we give to future rewards and immediate rewards.", "The value of the discount factor ranges from 0 to 1. A small value (close to 0) gives more importance to immediate rewards than to future rewards. On the other hand, high value (close to 1) gives more importance to future rewards than immediate rewards.", "For example, in the race, our main goal is to complete the lap. Then we need to give more importance to future rewards than the immediate rewards. So, we need to use a discount factor close to 1.", "Up to this point, we already cover what Markov Property, Markov Chain, Markov Reward Process, and Markov Decision Process is. This includes the important terminologies in MDP like Action Space, Policy, Episode, Returns, and Discount Factor.", "In summary, Reinforcement Learning can be represented as an MDP with states, actions, transition probability, and the reward function.", "Bima is a Data Scientist who always eager to expand his knowledge and skills. He was graduated as a Mining Engineer at Institut Teknologi Bandung and University of New South Wales. Then he began his Data Science journey through various online courses from HardvardX, IBM, Udacity, etc. Currently, he is making impacts together with DANA Indonesia in building a cashless society in Indonesia.", "If you have any queries or any topics to be discussed, please reach out to Bima via LinkedIn.", "Former Mine Engineer who passionate about data and became Data Scientist"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4b5166f3c5b4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@bima.putra1?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Bima Putra Pratama"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31f83028bd26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&user=Bima+Putra+Pratama&userId=31f83028bd26&source=post_page-31f83028bd26----4b5166f3c5b4---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b5166f3c5b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&user=Bima+Putra+Pratama&userId=31f83028bd26&source=-----4b5166f3c5b4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b5166f3c5b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&source=-----4b5166f3c5b4---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@alschim?utm_source=medium&utm_medium=referral", "anchor_text": "Alexander Schimmeck"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/aws-deepracer-the-fun-way-of-learning-reinforcement-learning-c961cde9ce8b", "anchor_text": "AWS DeepRacer: The fun way of Learning Reinforcement LearningWelcome to the AWS DeepRacer journeytowardsdatascience.com"}, {"url": "https://unsplash.com/@j?utm_source=medium&utm_medium=referral", "anchor_text": "Jeremy Cai"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://inst.eecs.berkeley.edu/~cs188/sp20/", "anchor_text": "CS 188: Introduction to Artificial Intelligence, Spring 2020This course will introduce the basic ideas and techniques underlying the design of intelligent computer systems. A\u2026inst.eecs.berkeley.edu"}, {"url": "https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da", "anchor_text": "Introduction to Reinforcement Learning: Markov-Decision ProcessIn a typical Reinforcement Learning (RL) problem, there is a learner and a decision-maker called agent and the\u2026towardsdatascience.com"}, {"url": "https://en.wikipedia.org/wiki/Markov_property", "anchor_text": "Markov propertyIn probability theory and statistics, the term Markov property refers to the memoryless property of a stochastic\u2026en.wikipedia.org"}, {"url": "https://en.wikipedia.org/wiki/Markov_chain", "anchor_text": "Markov chainA Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event\u2026en.wikipedia.org."}, {"url": "https://en.wikipedia.org/wiki/Markov_decision_process", "anchor_text": "Markov decision processIn mathematics, a Markov decision process ( MDP) is a discrete-time stochastic control process. It provides a\u2026en.wikipedia.org"}, {"url": "https://www.itb.ac.id/", "anchor_text": "Institut Teknologi Bandung"}, {"url": "https://www.unsw.com/", "anchor_text": "University of New South Wales"}, {"url": "https://www.linkedin.com/in/bpratama/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----4b5166f3c5b4---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/markov-decision-process?source=post_page-----4b5166f3c5b4---------------markov_decision_process-----------------", "anchor_text": "Markov Decision Process"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4b5166f3c5b4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----4b5166f3c5b4---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deepracer?source=post_page-----4b5166f3c5b4---------------deepracer-----------------", "anchor_text": "Deepracer"}, {"url": "http://creativecommons.org/licenses/by/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b5166f3c5b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&user=Bima+Putra+Pratama&userId=31f83028bd26&source=-----4b5166f3c5b4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b5166f3c5b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&user=Bima+Putra+Pratama&userId=31f83028bd26&source=-----4b5166f3c5b4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b5166f3c5b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31f83028bd26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&user=Bima+Putra+Pratama&userId=31f83028bd26&source=post_page-31f83028bd26----4b5166f3c5b4---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5e80780eb492&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&newsletterV3=31f83028bd26&newsletterV3Id=5e80780eb492&user=Bima+Putra+Pratama&userId=31f83028bd26&source=-----4b5166f3c5b4---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Written by Bima Putra Pratama"}, {"url": "https://medium.com/@bima.putra1/followers?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "257 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31f83028bd26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&user=Bima+Putra+Pratama&userId=31f83028bd26&source=post_page-31f83028bd26----4b5166f3c5b4---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5e80780eb492&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-markov-decision-process-the-framework-behind-reinforcement-learning-4b5166f3c5b4&newsletterV3=31f83028bd26&newsletterV3Id=5e80780eb492&user=Bima+Putra+Pratama&userId=31f83028bd26&source=-----4b5166f3c5b4---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-make-sankey-diagram-in-tableau-f5f8730e5962?source=author_recirc-----4b5166f3c5b4----0---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=author_recirc-----4b5166f3c5b4----0---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=author_recirc-----4b5166f3c5b4----0---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Bima Putra Pratama"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----4b5166f3c5b4----0---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-make-sankey-diagram-in-tableau-f5f8730e5962?source=author_recirc-----4b5166f3c5b4----0---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "How to Make Sankey Diagram in TableauSankey Diagram is a chart that we can use to visualize the flow of one measure over multiple dimensions."}, {"url": "https://towardsdatascience.com/how-to-make-sankey-diagram-in-tableau-f5f8730e5962?source=author_recirc-----4b5166f3c5b4----0---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "\u00b76 min read\u00b7May 7, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff5f8730e5962&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-sankey-diagram-in-tableau-f5f8730e5962&user=Bima+Putra+Pratama&userId=31f83028bd26&source=-----f5f8730e5962----0-----------------clap_footer----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-make-sankey-diagram-in-tableau-f5f8730e5962?source=author_recirc-----4b5166f3c5b4----0---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff5f8730e5962&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-sankey-diagram-in-tableau-f5f8730e5962&source=-----4b5166f3c5b4----0-----------------bookmark_preview----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4b5166f3c5b4----1---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----4b5166f3c5b4----1---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----4b5166f3c5b4----1---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----4b5166f3c5b4----1---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4b5166f3c5b4----1---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4b5166f3c5b4----1---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4b5166f3c5b4----1---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----4b5166f3c5b4----1-----------------bookmark_preview----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4b5166f3c5b4----2---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----4b5166f3c5b4----2---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----4b5166f3c5b4----2---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----4b5166f3c5b4----2---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4b5166f3c5b4----2---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4b5166f3c5b4----2---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4b5166f3c5b4----2---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----4b5166f3c5b4----2-----------------bookmark_preview----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/tabpy-combining-python-and-tableau-511b10da8175?source=author_recirc-----4b5166f3c5b4----3---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=author_recirc-----4b5166f3c5b4----3---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=author_recirc-----4b5166f3c5b4----3---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Bima Putra Pratama"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----4b5166f3c5b4----3---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/tabpy-combining-python-and-tableau-511b10da8175?source=author_recirc-----4b5166f3c5b4----3---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "TabPy: Combining Python and TableauGetting started to start using Python in Tableau"}, {"url": "https://towardsdatascience.com/tabpy-combining-python-and-tableau-511b10da8175?source=author_recirc-----4b5166f3c5b4----3---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": "\u00b75 min read\u00b7Oct 13, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F511b10da8175&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabpy-combining-python-and-tableau-511b10da8175&user=Bima+Putra+Pratama&userId=31f83028bd26&source=-----511b10da8175----3-----------------clap_footer----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/tabpy-combining-python-and-tableau-511b10da8175?source=author_recirc-----4b5166f3c5b4----3---------------------d54f7939_b99b_466a_a78e_85d4e8b8071e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F511b10da8175&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabpy-combining-python-and-tableau-511b10da8175&source=-----4b5166f3c5b4----3-----------------bookmark_preview----d54f7939_b99b_466a_a78e_85d4e8b8071e-------", "anchor_text": ""}, {"url": "https://medium.com/@bima.putra1?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "See all from Bima Putra Pratama"}, {"url": "https://towardsdatascience.com/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----4b5166f3c5b4----0-----------------bookmark_preview----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----4b5166f3c5b4----1-----------------bookmark_preview----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/codex/ai-anyone-can-understand-part-5-the-exploration-exploitation-trade-off-f4871d717649?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/codex?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "CodeX"}, {"url": "https://medium.com/codex/ai-anyone-can-understand-part-5-the-exploration-exploitation-trade-off-f4871d717649?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "AI Anyone Can Understand: Part 5 \u2014 The Exploration-Exploitation Trade-OffMake sure you check out the rest of the AI Anyone Can Understand Series"}, {"url": "https://medium.com/codex/ai-anyone-can-understand-part-5-the-exploration-exploitation-trade-off-f4871d717649?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "\u00b76 min read\u00b7Dec 20, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcodex%2Ff4871d717649&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fai-anyone-can-understand-part-5-the-exploration-exploitation-trade-off-f4871d717649&user=Andrew+Austin&userId=42d388912d13&source=-----f4871d717649----0-----------------clap_footer----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/codex/ai-anyone-can-understand-part-5-the-exploration-exploitation-trade-off-f4871d717649?source=read_next_recirc-----4b5166f3c5b4----0---------------------20f2729a_2f60_47d9_b738_db419c54b351-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4871d717649&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fai-anyone-can-understand-part-5-the-exploration-exploitation-trade-off-f4871d717649&source=-----4b5166f3c5b4----0-----------------bookmark_preview----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----1-----------------clap_footer----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----4b5166f3c5b4----1---------------------20f2729a_2f60_47d9_b738_db419c54b351-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----4b5166f3c5b4----1-----------------bookmark_preview----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----4b5166f3c5b4----2---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----4b5166f3c5b4----2---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----4b5166f3c5b4----2---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----4b5166f3c5b4----2---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----4b5166f3c5b4----2---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----2-----------------clap_footer----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----4b5166f3c5b4----2---------------------20f2729a_2f60_47d9_b738_db419c54b351-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----4b5166f3c5b4----2-----------------bookmark_preview----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----4b5166f3c5b4----3---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----4b5166f3c5b4----3---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----4b5166f3c5b4----3---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----4b5166f3c5b4----3---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----4b5166f3c5b4----3---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "Trust Region Policy Optimization (TRPO) ExplainedThe Reinforcement Learning algorithm TRPO builds upon natural policy gradient algorithms, ensuring updates remain within \u2018trustworthy\u2019\u2026"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----4b5166f3c5b4----3---------------------20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": "\u00b712 min read\u00b7Oct 12, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----4b56bd206fc2----3-----------------clap_footer----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----4b5166f3c5b4----3---------------------20f2729a_2f60_47d9_b738_db419c54b351-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&source=-----4b5166f3c5b4----3-----------------bookmark_preview----20f2729a_2f60_47d9_b738_db419c54b351-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----4b5166f3c5b4--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}