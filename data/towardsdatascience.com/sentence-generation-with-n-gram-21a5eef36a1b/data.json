{"url": "https://towardsdatascience.com/sentence-generation-with-n-gram-21a5eef36a1b", "time": 1683001149.643221, "path": "towardsdatascience.com/sentence-generation-with-n-gram-21a5eef36a1b/", "webpage": {"metadata": {"title": "Language Model Concept behind Word Suggestion Feature | by Vitou Phy | Towards Data Science", "h1": "Language Model Concept behind Word Suggestion Feature", "description": "N-gram is one of the simple ways to do language modeling. It is useful for word suggestion task, auto-complete, sentence generation and many more."}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Language_model", "anchor_text": "language modeling", "paragraph_index": 1}, {"url": "https://web.stanford.edu/~jurafsky/slp3/3.pdf", "anchor_text": "this", "paragraph_index": 22}, {"url": "https://www.kaggle.com/gulsahdemiryurek/harry-potter-dataset", "anchor_text": "Harry Potter and the Sorcerer\u2019s Stone Movie Script", "paragraph_index": 23}, {"url": "https://www.kaggle.com/ruka96/sentence-generation-with-n-gram?scriptVersionId=22881807", "anchor_text": "this kernel", "paragraph_index": 23}], "all_paragraphs": ["You may have seen word suggestion feature on your smartphone. As you type in one word, the keyboard understands what you are typing and suggests the next relevant word. If you select the suggested word, it will then suggest another one, and another and another until you end up having these funny sentences.", "This is a simple concept, known as language modeling. So what language modeling does is it reads the written text and it attempts to assign probability to the next word. Let\u2019s look at an example.", "Intuitively, suppose we have 100 words to be considered for the next word, language model takes previous word into consideration and give probability to those 100 words. Then, it can give top 3 options to the users as part of word suggestion feature. Now, let\u2019s give a formal definition to LM.", "Commonly, language model is known as a way to give probability to a sentence.", "But wait! Isn\u2019t earlier we mentioned LM assign probability to the next word? Let\u2019s break down the equation above to investigate this further.", "As you can see in Equation 1, LM not only can assign probability to the next word given but also can give the probability to the whole sentence. Then, the LM can understand which sentence might sound good and which might not.", "Awesome, right? But what\u2019s under the hood of such awesome function? There are many ways to create this language model. In this post, we will explore a simple method, called n-gram.", "One key idea is ngram looks only at n words at a time. Let\u2019s work with the example \u201cthe cat sat on the mat\u201d.", "Suppose n=2 (also known as bigram), it will try to predict the second word based on the first one. For example:", "The same thing goes with n=3. For the words \u201cthe cat sat\u201d, trigram knows \u201csat\u201d comes after \u201cthe cat\u201d. I guess you get the idea.", "This concept is scalable to n words (n-gram). So, how does ngram know all of these pattern? It\u2019s probability theory.", "For simplicity, we will look the case of bigram. From the example above, we know that \u201ccat\u201d comes after \u201cthe\u201d, which can be denoted as P(cat | the).", "P(cat | the) : the probability that the next word is \u201ccat\u201d given the word \u201cthe\u201d.", "To compute this probability, simply use this the formula below.", "where c(the cat) is number of occurrence of \u201cthe cat\u201d in the entire corpus. The same goes for c(the). Intuitively, this equation says that: Among all of the words \u201cthe\u201d, how many of them are followed by \u201ccat\u201d? And voila, now we have P(cat | the).", "Bigram is simple and quite powerful but there are many cases it will fail to perform. For instance:", "In the beginning of the sentence, the model sees \u201cthe\u201d followed by \u201ccat\u201d. If we use bigram and rely only on one previous word, it is very difficult to guess that the underline word is \u201cmat\u201d since it probably generates \u201ccat\u201d again. Fortunately, trigram or 4-gram can resolve this issue. i.e. If we see \u201csat on the\u201d, it is more likely that the next word is \u201cmat\u201d.", "However, that does not mean the longer sequence we consider, the better the prediction. For 6-gram, for instance, it might not be very common to see the exact \u201cthe cat sat on the\u201d. Thus, it is not very efficient.", "Most of the time, bigram and trigram are the common choices.", "There are also times where your dataset is small and 3-gram fails to recognize some exact words; thus, resulting in the probability of 0. That would make your entire 3-gram implementation not that useful anymore.", "Easily you can do a simple if-else, and use 2-gram in case 3-gram fails. Or use 1-gram in the case of 2-gram fails. There is called, back-off.", "Another technique, interpolation, is considering different ngrams at the same time. The idea is to give weight (\u03bb) to your n-gram so your 3-gram model can also look at the value of 2-gram and 1-gram. i.e.", "Config the weight manually until you feel it\u2019s right. You can also use some automatic method, but we won\u2019t go over that in this post. You can refer to this for further info on how to properly set these weights.", "Now let\u2019s try to use this LM to generate a sentence based on random initial word. For this task, we will use Harry Potter and the Sorcerer\u2019s Stone Movie Script to train our ngram. For the code below, you can find on this kernel as well.", "Then, we can count the frequency of unigram, bigram and trigram. This will be used later to compute probability.", "Now that we can the count of the n-gram, we can compute its probability. We will use linear interpolation of 0.01, 0.4, and 0.5 respectively for 1-gram, 2-gram and 3-gram.", "Let\u2019s attempt to generate 20 words. The initial will be randomized, and choose the best next word.", "So, how will this perform? Below are the results of each generation.", "N-gram is a simple yet powerful technique to do language modeling by just looking at 2 to 3 words. It is quite practical in many applications, for instance, word suggestion on mobile device, thanks to its easy and fast in computation. N-gram, however, is not robust when it comes to generating long sentence where the current word depends on the very first word in the sentence. This long term dependency is more suitable for the model like neural network, but that is a topic for later post.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F21a5eef36a1b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@phyvitou?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@phyvitou?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "Vitou Phy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F81157f79faae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&user=Vitou+Phy&userId=81157f79faae&source=post_page-81157f79faae----21a5eef36a1b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21a5eef36a1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21a5eef36a1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@dearseymour?utm_source=medium&utm_medium=referral", "anchor_text": "Ksenia Makagonova"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Language_model", "anchor_text": "language modeling"}, {"url": "https://web.stanford.edu/~jurafsky/slp3/3.pdf", "anchor_text": "this"}, {"url": "https://www.kaggle.com/gulsahdemiryurek/harry-potter-dataset", "anchor_text": "Harry Potter and the Sorcerer\u2019s Stone Movie Script"}, {"url": "https://www.kaggle.com/ruka96/sentence-generation-with-n-gram?scriptVersionId=22881807", "anchor_text": "this kernel"}, {"url": "https://web.stanford.edu/~jurafsky/slp3/3.pdf", "anchor_text": "https://web.stanford.edu/~jurafsky/slp3/3.pdf"}, {"url": "https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9", "anchor_text": "https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9"}, {"url": "http://www.cs.umd.edu/class/fall2018/cmsc470/slides/slides_10.pdf", "anchor_text": "http://www.cs.umd.edu/class/fall2018/cmsc470/slides/slides_10.pdf"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----21a5eef36a1b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/language-model?source=post_page-----21a5eef36a1b---------------language_model-----------------", "anchor_text": "Language Model"}, {"url": "https://medium.com/tag/nlp?source=post_page-----21a5eef36a1b---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----21a5eef36a1b---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/generation?source=post_page-----21a5eef36a1b---------------generation-----------------", "anchor_text": "Generation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F21a5eef36a1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&user=Vitou+Phy&userId=81157f79faae&source=-----21a5eef36a1b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F21a5eef36a1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&user=Vitou+Phy&userId=81157f79faae&source=-----21a5eef36a1b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21a5eef36a1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F21a5eef36a1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----21a5eef36a1b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----21a5eef36a1b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@phyvitou?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@phyvitou?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Vitou Phy"}, {"url": "https://medium.com/@phyvitou/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "82 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F81157f79faae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&user=Vitou+Phy&userId=81157f79faae&source=post_page-81157f79faae--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7c7adf70813c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-generation-with-n-gram-21a5eef36a1b&newsletterV3=81157f79faae&newsletterV3Id=7c7adf70813c&user=Vitou+Phy&userId=81157f79faae&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}