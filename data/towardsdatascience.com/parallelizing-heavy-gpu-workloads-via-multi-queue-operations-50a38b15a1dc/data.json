{"url": "https://towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc", "time": 1683015337.6494, "path": "towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc/", "webpage": {"metadata": {"title": "Parallelizing GPU-intensive Workloads via Multi-Queue Operations using Kompute & Vulkan | by Alejandro Saucedo | Towards Data Science", "h1": "Parallelizing GPU-intensive Workloads via Multi-Queue Operations using Kompute & Vulkan", "description": "Achieving 2x+ speed improvements on large GPU-intensive workloads by leveraging multi-queue operation parallelism using Vulkan and Vulkan Kompute"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1802.09941", "anchor_text": "extremely useful for highly parallelizable data processing use-cases", "paragraph_index": 0}, {"url": "http://cs149.stanford.edu/fall19/lecture/gpuarch/", "anchor_text": "the processing architecture graphics cards provide", "paragraph_index": 0}, {"url": "https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm", "anchor_text": "model parallelism", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Data_parallelism", "anchor_text": "data parallelism", "paragraph_index": 1}, {"url": "https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf", "anchor_text": "page 19 in this document", "paragraph_index": 3}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "Kompute framework", "paragraph_index": 4}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/0b221c9ebd3c8d7c8a81ef2ce80627c9460ec9c2/test/TestAsyncOperations.cpp#L10", "anchor_text": "full code in this file", "paragraph_index": 5}, {"url": "https://github.com/EthicalML/vulkan-kompute#build-overview", "anchor_text": "main Kompute repository build section", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Vulkan_(API)", "anchor_text": "The Vulkan SDK", "paragraph_index": 6}, {"url": "https://www.khronos.org/", "anchor_text": "Khronos Group", "paragraph_index": 6}, {"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units", "anchor_text": "GPGPU computing framework", "paragraph_index": 7}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/1053cde1f0d27799f0d7dbd8043919656498f8bf/test/TestAsyncOperations.cpp#L8", "anchor_text": "runnable code in this file", "paragraph_index": 16}, {"url": "http://vulkan.gpuinfo.org/displayreport.php?id=9700", "anchor_text": "NVIDIA 1650 video card", "paragraph_index": 30}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/0b221c9ebd3c8d7c8a81ef2ce80627c9460ec9c2/test/TestAsyncOperations.cpp#L10", "anchor_text": "the full suite", "paragraph_index": 40}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "main Kompute repository", "paragraph_index": 40}], "all_paragraphs": ["GPUs have proven extremely useful for highly parallelizable data processing use-cases. The computational paradigms found in machine learning & deep learning for example fit extremely well to the processing architecture graphics cards provide.", "However, when it comes to multiple GPU workloads, one would assume that these would be processed concurrently, but this is not the case. Whilst a single GPU compute workload is parallelized across the numerous GPU cores, multiple workloads are run one by one sequentially. That is of course until recent improvements in graphics card architectures which are now enabling for hardware parallelization across multiple workloads. This can be achieved by submitting the workloads to different underlying physical GPU \u201cqueue families\u201d that support concurrency. Practical tecniques in machine learning that would benefit from this include model parallelism and data parallelism.", "In this example we will show how we can achieve a 2x performance improvement on a synchronous example by simply submitting multiple workloads across two queue families, resulting in these workloads running in parallel.", "This is an important optimization technique, as recent announcements outlined in NVIDIA\u2019s Ampere GA10x architecture specifications page 19 in this document will enable for 3x performance improvements (i.e. concurrency across one graphics queue and two compute queues), making it clear that this trend will only continue to bring further optimization improvements in this area.", "We will be implementing this using Vulkan and the Kompute framework. More specifically we will cover:", "You can find the full code in this file \u2014 instructions on how to run the full suite using CMAKE can be found in the main Kompute repository build section.", "The Vulkan SDK is an Open Source project led by the Khronos Group, which enables for highly optimized cross-vendor/cross-platform GPU processing.", "Kompute is a framework built on top of the Vulkan SDK which abstracts the thousands of lines of boilerplate code required, introducing best practices that expose Vulkan\u2019s core computing capabilities. Kompute is the GPGPU computing framework that we will be using in this tutorial to build the core asynchronous and parallel code implementation.", "Before diving into the code, it is important to disambiguate two concepts \u2014 asynchronous workload submission and parallel workload processing.", "The way parallel workloads are submitted for processing when using the Vulkan SDK through GPU Queues. This can be visualised in the simplified Vulkan Architecture diagram (pipeline and descriptor components were left out for simplicity).", "Asynchronous processing encompasses the ability for the CPU host side to be able to do other work whilst the GPU is processing the workload. \u201cOther work\u201d can include calling other C++ functions, or even submitting further workloads to the same or other GPU queues. When the CPU wants to check whether the GPU workload is finished, it can use a Vulkan \u201cFence\u201d which is basically a semaphore resource that allows the CPU to be notified when a GPU workload finishes.", "It is important to note that when multiple workloads are submitted to the same queue, even if these are done from multiple C++ threads, the expected execution ordering will still be sequential \u2014 at least as of today\u2019s GPU architectures.", "Parallel workload processing consists of the concurrent execution of two or more workloads by the GPU. More specifically, if you had two GPU tasks that would take 10 seconds each to process, the theoretical parallel execution would still take 10 seconds for both as they would be carried out at the same time.", "In order for parallel workload processing to be achieved, this is something that first and foremost has to be supported by the underlying GPU. The reason why this is important is because even if you were to submit workloads across different GPU queues, the processing may still be done sequentially by the underlying hardware based on its limitations.", "We will now take a look at the code that we will be using throughout this article. This first version of the code will be the sequential flow \u2014 we will be able to then convert it into asynchronous code, and finally into parallel code. We will basically be running a workload where we will be doing the following:", "For measuring time we will be using <chrono> from the standard library. We will be mainly using it to calculate the difference across a start and end time retrieved with std::chrono::high_resolution_clock::now() as follows:", "You can find the runnable code in this file, which is part of the Kompute test suite.", "First we have to create the Kompute Manager, which performs all the required memory management and creates all required Vulkan resources. By default the Kompute Manager will pick GPU Device 0, but you are able to pass the specific device index you would prefer to initialise with, and if preferred you can pass your Vulkan resources if you already have a Vulkan application.", "We will now be able to create a set of Kompute Tensors. We first initialise the data in the CPU Host, consisting of an array of zeros with length of 10. We will be using two tensors as we\u2019ll be running two algorithm executions. We will be able to check these Kompute Tensors at the end to confirm that the execution has been successful.", "We are now able to copy the host data of the Kompute Tensors into the GPU Device memory.", "This is an important step as by default the Kompute Tensors use device-only-visible memory which means that a GPU operation will need to copy it with a staging tensor.", "Kompute allows us to create the buffer and GPU memory block, as well as performing a copy with a staging buffer through the kp::OpTensorCreate operation.", "The compute shader that we create has a relatively large loop to simulate an \u201cexpensive computation\u201d. It basically performs a unit addition for 100000000 iterations and adds the result to the input Tensor.", "Now we are able to submit the compute shader for execution through the kp::OpAlgoBase operation. This basically allows us to perform a submission of the shader with the respective tensor. This initial implementation runs the execution synchronously, so it will first run the execution of the shader with tensorA, and then the execution of the same shader with tensorB.", "Finally we want to retrieve the results from the GPU device memory into the CPU host memory so we can access it from C++. For this we can use the kp::OpTensorSync operation.", "Finally we can just check that both resulting kp::Tensor contain the expected value of 100000000.", "The steps that we will need to extend for asynchronous submission in this case are quite minimal. The only thing we need to do is to substitute the evalOpDefault function for the evalOpAsyncDefault function, and then using the evalOpAwaitDefault(<timeInNanoSecs>) to wait until the job is finished. This basically would look as follows:", "As you can see we are able to submit two tasks for processing asynchronously, and then wait until they are finished with the Await function.", "It\u2019s worth pointing out that every time we call evalOpAsyncDefault it creates a new managed sequence, and evalOpAwaitDefault only waits for the most recent default sequence. This means that in the snippet above, we are only waiting for the second asynchronous operation. This isn\u2019t a problem for our example, but this could introduce bugs if we\u2019re now aware. The proper way to do this is with explicitly created \u201cnamed sequences\u201d \u2014 we will do this in the next section.", "Now that we know we are able to execute multiple workloads asynchronously, we are able to extend this to leverage the multiple queues in the GPU to achieve parallel execution of workloads.", "In order to show a useful example, we will dive into how this would be achieved in an NVIDIA 1650 video card. You are able to try this yourself by checking the device report of your video card \u2014 namely on the queue families and parallel processing capabilities available.", "The NVIDIA 1650 GPU has 3 queue families. Using G for GRAPHICS, T for TRANSFER and C for COMPUTE capabilities, the NVIDIA 1650 has a G+T+C family in familyIndex 0with 16 queues, a T family on familyIndex 1 with 2 queues, and a T+C family on familyIndex 2 with 8 queues.", "As of today (October 2020), NVIDIA does not support parallel processing of workloads when work is submitted across multiple queues within the same family. However it supports parallelizing when workloads are submitted across queue families. This means that workloads between graphics and compute family queues can be parallelized \u2014 we will be using this knowledge in our implementation.", "So far we have been submitting all GPU workloads to a single queue, namely the GRAPHICS familyIndex 0 using the underlying queue index 0. In our case using the GPU 1650, we will be able to achieve parallel processing if we submit workloads across the GRAPHICS family and the COMPUTE family. The diagram below should provide an intuition on what we will be doing.", "In order for us to do this, we will need to modify three key things:", "We will dive into each of these three points.", "When initialising a manager we are able to pass an array containing the queues that we would like to fetch. In this case, we only fetch one graphics queue and one compute queue, however, based on the hardware specs of the NVIDIA 1650, we would be able to request up to 16 graphics queues (familyIndex 0), 2 transfer queues (familyIndex 1), and 8 compute queues (familyIndex 2).", "Now we are able to explicitly initialise two managed sequences, each allocated to a different queue, referencing the index of the array we passed in the previous step.", "Now we are able to run operations submitting to each respective queue. In this case both of the GPU workloads are submitted in parallel.", "When running the code provided above, we can see a 2x speed improvement in execution time thanks to the parallel family queue submission of workload. You can also see that if we were to submit to extra queues from the GRAPHICS or COMPUTE queues, we would not see any further speed improvements as intra-queue parallelization is not supported in this NVIDIA 1650 card.", "You can find the full code and run it in this file \u2014 instructions on how to run the full suite using CMAKE can be found in the main Kompute repository.", "This is a particularly important result, as based on the recent announcement from NVIDIA coming together with the release of their 300x video cards, there are improvements via the Ampere GA10x architecture that allows for two compute workloads simultaneously. Relative to the example above, this means that we could see a 3x improvement if we were to use one GRAPHICS queue and two COMPUTE queue (together with the extra performance using the TRANSFER queue for transfer operations).", "Congratulations, you\u2019ve made it all the way to the end! Although there was a broad range of topics covered in this post, there is a massive amount of concepts that were skimmed through. These include the underlying Vulkan concepts, GPU computing fundamentals, and more advanced Kompute concepts. Luckily, there are resources online to expand your knowledge on each of these. Here are some links I recommend for further reading:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Chief Scientist @ The Institute for Ethical AI & Machine learning | Engineering Director @ Seldon | Member at Large @ ACM | Building the future of production ML"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F50a38b15a1dc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278----50a38b15a1dc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F50a38b15a1dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F50a38b15a1dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1802.09941", "anchor_text": "extremely useful for highly parallelizable data processing use-cases"}, {"url": "http://cs149.stanford.edu/fall19/lecture/gpuarch/", "anchor_text": "the processing architecture graphics cards provide"}, {"url": "https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm", "anchor_text": "model parallelism"}, {"url": "https://en.wikipedia.org/wiki/Data_parallelism", "anchor_text": "data parallelism"}, {"url": "https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf", "anchor_text": "page 19 in this document"}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "Kompute framework"}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/0b221c9ebd3c8d7c8a81ef2ce80627c9460ec9c2/test/TestAsyncOperations.cpp#L10", "anchor_text": "full code in this file"}, {"url": "https://github.com/EthicalML/vulkan-kompute#build-overview", "anchor_text": "main Kompute repository build section"}, {"url": "https://streamhpc.com/blog/2017-05-04/what-is-khronos-as-of-today/", "anchor_text": "StreamHPC"}, {"url": "https://en.wikipedia.org/wiki/Vulkan_(API)", "anchor_text": "The Vulkan SDK"}, {"url": "https://www.khronos.org/", "anchor_text": "Khronos Group"}, {"url": "https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute", "anchor_text": "Kompute"}, {"url": "https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units", "anchor_text": "GPGPU computing framework"}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "Kompute Repo"}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/1053cde1f0d27799f0d7dbd8043919656498f8bf/test/TestAsyncOperations.cpp#L8", "anchor_text": "runnable code in this file"}, {"url": "http://cs149.stanford.edu/fall19/lecture/gpuarch/slide_038", "anchor_text": "2019 Slides"}, {"url": "http://vulkan.gpuinfo.org/displayreport.php?id=9700", "anchor_text": "NVIDIA 1650 video card"}, {"url": "https://github.com/EthicalML/vulkan-kompute/blob/0b221c9ebd3c8d7c8a81ef2ce80627c9460ec9c2/test/TestAsyncOperations.cpp#L10", "anchor_text": "the full suite"}, {"url": "https://github.com/EthicalML/vulkan-kompute", "anchor_text": "main Kompute repository"}, {"url": "https://towardsdatascience.com/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a", "anchor_text": "Machine Learning in Mobile & Cross-Vendor GPUs Made Simple With Kompute & Vulkan"}, {"url": "https://axsaucedo.github.io/vulkan-kompute/", "anchor_text": "Kompute Documentation"}, {"url": "https://towardsdatascience.com/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a", "anchor_text": "Machine Learning in Mobile & Cross-Vendor GPUs Made Simple With Kompute & Vulkan"}, {"url": "https://towardsdatascience.com/gpu-accelerated-machine-learning-in-your-mobile-applications-using-the-android-ndk-vulkan-kompute-1e9da37b7617", "anchor_text": "Supercharging your Mobile Apps with GPU Accelerated Machine Learning using the Android NDK & Kompute"}, {"url": "https://towardsdatascience.com/supercharging-game-development-with-gpu-accelerated-ml-using-vulkan-kompute-the-godot-game-engine-4e75a84ea9f0", "anchor_text": "GPU Accelerated ML using the Godot Engine and Kompute"}, {"url": "https://vulkan-tutorial.com/", "anchor_text": "Vulkan SDK Tutorial"}, {"url": "https://medium.com/tag/parallel-computing?source=post_page-----50a38b15a1dc---------------parallel_computing-----------------", "anchor_text": "Parallel Computing"}, {"url": "https://medium.com/tag/gpu?source=post_page-----50a38b15a1dc---------------gpu-----------------", "anchor_text": "Gpu"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----50a38b15a1dc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/vulkan?source=post_page-----50a38b15a1dc---------------vulkan-----------------", "anchor_text": "Vulkan"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----50a38b15a1dc---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F50a38b15a1dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&user=Alejandro+Saucedo&userId=32de426f7278&source=-----50a38b15a1dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F50a38b15a1dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&user=Alejandro+Saucedo&userId=32de426f7278&source=-----50a38b15a1dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F50a38b15a1dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F50a38b15a1dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----50a38b15a1dc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----50a38b15a1dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AxSaucedo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alejandro Saucedo"}, {"url": "https://medium.com/@AxSaucedo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "616 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32de426f7278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&user=Alejandro+Saucedo&userId=32de426f7278&source=post_page-32de426f7278--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1b4684c4c42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc&newsletterV3=32de426f7278&newsletterV3Id=b1b4684c4c42&user=Alejandro+Saucedo&userId=32de426f7278&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}