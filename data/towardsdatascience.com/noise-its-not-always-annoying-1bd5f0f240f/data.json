{"url": "https://towardsdatascience.com/noise-its-not-always-annoying-1bd5f0f240f", "time": 1683002996.307263, "path": "towardsdatascience.com/noise-its-not-always-annoying-1bd5f0f240f/", "webpage": {"metadata": {"title": "Regularization Method: Noise for improving Deep Learning models | by Alex Diaz | Towards Data Science", "h1": "Regularization Method: Noise for improving Deep Learning models", "description": "One of the first concepts you learn when you begin to study neural networks is the meaning of overfitting and underfitting. Sometimes, it is a challenge to train a model that generalizes your data\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690", "anchor_text": "overfitting and underfitting", "paragraph_index": 0}, {"url": "https://github.com/alejandrods/Noise-Regularization-Method-Neural-Network", "anchor_text": "GitHub", "paragraph_index": 3}, {"url": "https://books.google.es/books?id=Np9SDQAAQBAJ&pg=PA107&lpg=PA107&dq=The+central+challenge+in+machine+learning+is+that+our+algorithm+must+perform+well+on+...&source=bl&ots=kROllLy-_Z&sig=ACfU3U1FzdT_Vg1GkcsBupzbmt8YHWQvhw&hl=es&sa=X&ved=2ahUKEwiph6T22YfnAhW9DWMBHVkNDkgQ6AEwAHoECAwQAQ#v=onepage&q=The%20central%20challenge%20in%20machine%20learning%20is%20that%20our%20algorithm%20must%20perform%20well%20on%20...&f=false", "anchor_text": "generalization", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a", "anchor_text": "Regularization", "paragraph_index": 8}, {"url": "https://pdfs.semanticscholar.org/d79b/a428e1cf1b8aa5d320a93166315bb30b4765.pdf", "anchor_text": "One hypothesis of the above observation is that relaxing consistency introduces stochastic noise into training process", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Gaussian_noise", "anchor_text": "Gaussian Noise", "paragraph_index": 23}], "all_paragraphs": ["One of the first concepts you learn when you begin to study neural networks is the meaning of overfitting and underfitting. Sometimes, it is a challenge to train a model that generalizes your data perfectly, especially when you have a small dataset because:", "To acquire more data is a very expensive and arduous task. However, sometimes you can apply some techniques (regularization methods) to obtain a better performance of your model.", "In this article, we are focusing on the use of noise as a regularizing method in a neural network. This technique not only reduces overfitting, but it can also lead to faster optimization of our model and better overall performance.", "You can find the entire code in my GitHub! :)", "The objectives of this article are the following:", "It is a challenge to train a machine learning model that will perform well on previously unseen inputs, not just those on which our model was trained. This feature is called generalization, performs well on unobserved inputs. There are some methods like train-test split or cross-validation to measure how well generalize our model.", "We can classify the performance of the model in 3 cases:", "It is more likely to face overfitting models in our problems thus, it is important to monitor the performance during training to detect if it has overfitting. It is common to plot the evolution of accuracy and loss during the training to detect usual patterns.", "Regularization is to modify our learning algorithm to reduce its generalization error but not its training error. The most common regularization methods in neural networks are:", "These methods are popular in neural networks and most of them have been proven to reduce overfitting. However, the effect of noise on deep learning models has never been systematically studied, nor is the underlying reason for the improved accuracy. One hypothesis of the above observation is that relaxing consistency introduces stochastic noise into training process. This implicitly mitigates the overfitting of the model and generalizes the model better to classify test data.", "We want to understand the effect of using noise as a regularization method in a neural network with overfitting and we have decided to use a binary classification problem to explain this. Therefore we are going to generate a binary dataset applying sklearn, specifically make_circles which generates 2 two-dimensional concentric circles. The parameters are:", "We need to evaluate the performance of our network to see if we have overfitting and thus, we need to split our data to generate another dataset x_test for testing. We have split our data into train_set (30%) and test_set (70%).", "As we need to force overfitting, we have chosen a small size (30%) for our train set because we want to create a neural network that doesn\u2019t generalize our data and has a higher error rate on the test dataset.", "We can plot the distribution of X_train and X_test:", "We have selected this type of data, called circle data, because these classes are not linearly separable (we can not split our data using a line). For this reason, we need a neural network to address this nonlinear problem.", "As we need to find overfitting in our model to study the effect of the noise as a regularizing method, we have only generated 100 samples. This is a small size sample to train a neural network and it enables us to overfit the training.", "To study how noise influences our training, we have trained a basic Neural Network as a baseline. We have defined a Multilayer Perceptron (MLP) to address our binary classification problem.", "The first layer is a hidden layer that uses 400 nodes and the relu activation function. In the output layer, we have used a sigmoid because we want to predict class values of 0 or 1. We use binary_crossentropy as loss (proper for binary classifications) and adam as optimizer.", "We train the neural network for 5000 epochs and we use X_test and y_test as validation_data.", "We have plotted a graph to represent the accuracy and loss on train and test set. It can be observed that our neural network has overfitting because this graph has the expected shape of an overfit model, test accuracy increases to a point and then begins to decrease again. At the same time, loss is divergent.", "We can observe that the accuracy for the train set is about train_acc=1 and for the test set is about test_acc=0.5857. It shows better performance on the training set than in the test dataset; this can be a sign for overfitting.", "Now, we are going to add noise using the Gaussian Noise Layer from Keras and compare the results. This layer applies additive zero-centered Gaussian noise, which is useful to mitigate overfitting. Gaussian Noise (GS) is a natural choice as a corruption process for real-valued inputs.", "This regularization layer is only active at training time.", "Gaussian Noise is statistical noise having a Probability Density Function (PDF) equal to that of the normal distribution. It is also known as the Gaussian Distribution. The probability density function \ud835\udc5d of a Gaussian random variable \ud835\udc67 is given by:", "where \ud835\udc67 represents the grey level, \ud835\udf07 the mean value and \ud835\udf0e the standard deviation. To sum up, the values that the noise can take on are Gaussian-distributed.", "To understand the meaning of Gaussian Noise, imagine that we have an image and we have plotted 2 Probability Density Functions. If we observe the red PDF: the mean value of the noise will be -2. So, on average, 2 would be subtracted from all pixels of the image. However, if we observe the orange PDF, the mean value is 3. So on average, 3 would be added to all pixels. For instance, if we take this image and we apply Gaussian Noise:", "We can check the histogram for each image to appreciate the effect of applying Gaussian Noise:", "Although we have explained the Gaussian Noise with images, the method of applying Gaussian Noise as regularization methods in Keras applies the same theory.", "Adding noise increases the size of our training dataset. When we are training a neural network, random noise is added to each training sample and this is a form of data augmentation. Furthermore, when we use noise, we are increasing the randomness of our data and the model is less capable to learn from training samples since they are changing each iteration. Consequently, the neural network learns more general features and has lower generalization errors.", "When we apply noise, we are creating new samples in the vicinity of the training samples and thus, the distribution of the input data is smoothed. This allows the neural network to learn from our data much more easily.", "We will add a Gaussian Noise layer as the input layer and we are going to analyze if this helps to improve generalization performance. When we add noise we are creating more samples and making the data distribution smoother.", "It can be seen on the line graph that noise causes the accuracy and loss of the model to jump around due to the points with noise that we have introduced in the training and that conflict with the points of the training data set. We have used std=0.1 as input noise and which might be a little bit high.", "With the use of noise as a regularization method in the input layer, we have decreased the overfitting in our model, furthermore, we have improved the test_accuracy=0.642.", "Now, we are going to try to create a Hidden Layer with Gaussian Noise. This has to be done before the activation function is applied. We will use a standard deviation of 0.1, again, chosen arbitrarily.", "In this case, it can be seen that train_accuracy remains constant, although we have managed to increase the test_accuracy=0.671. It seems that adding noise to our model allows improving the training of the neural network and is useful to mitigate overfitting.", "We have combined the 2 previous examples to study the performance of our model by adding an input layer noise and a hidden layer noise at the same time. We will use a standard deviation of 0.1, again, chosen arbitrarily.", "Once again, it can be seen that with the use of noise as input_layer and hidden_layer, at the same time, we have reduced the overfitting in our model. Additionally, it has increased the test_accuracy=0.6857 and it seems that Gaussian Noise as a regularization method allows the model to better generalize our data.", "Applying noise, we are creating new samples in the vicinity of the training samples and thus, the distribution of the input data is smoothed.", "We are going to develop a grid search to find out the exact amount of noise and the nodes in the hidden layer that allow us to get the best performing model.", "We will use the Neural Network with a Hidden Layer Noise as an example for the grid search. We need to create a function with the model to search for the best value for noise.", "We have created a dictionary called grid_values that contains the range of values for each parameter of the model. Finally, we insert our model create_model() in the wrapper called KerasClassifier which implements the Scikit-Learn classifier interface.", "We can see that the best results were achieved with a network with 300 neurons in the hidden layer and with noise_amount=0.001 with an accuracy of about 83%.", "We can improve this experiment of adding noise as regularization method with the next ideas:", "Suggestions and reviews are welcome. Follow me and thank you for reading! :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1bd5f0f240f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@alejandrods?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alejandrods?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "Alex Diaz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3b43171da13b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&user=Alex+Diaz&userId=3b43171da13b&source=post_page-3b43171da13b----1bd5f0f240f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1bd5f0f240f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1bd5f0f240f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690", "anchor_text": "overfitting and underfitting"}, {"url": "https://github.com/alejandrods/Noise-Regularization-Method-Neural-Network", "anchor_text": "GitHub"}, {"url": "https://books.google.es/books?id=Np9SDQAAQBAJ&pg=PA107&lpg=PA107&dq=The+central+challenge+in+machine+learning+is+that+our+algorithm+must+perform+well+on+...&source=bl&ots=kROllLy-_Z&sig=ACfU3U1FzdT_Vg1GkcsBupzbmt8YHWQvhw&hl=es&sa=X&ved=2ahUKEwiph6T22YfnAhW9DWMBHVkNDkgQ6AEwAHoECAwQAQ#v=onepage&q=The%20central%20challenge%20in%20machine%20learning%20is%20that%20our%20algorithm%20must%20perform%20well%20on%20...&f=false", "anchor_text": "generalization"}, {"url": "https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a", "anchor_text": "Regularization"}, {"url": "https://medium.com/konvergen/understanding-dropout-ddb60c9f98aa", "anchor_text": "Dropout"}, {"url": "https://medium.com/swlh/early-stopping-in-polynomial-regression-d1183bd363a7", "anchor_text": "Early Stopping"}, {"url": "https://arxiv.org/abs/1207.0580", "anchor_text": "Weight Constraint"}, {"url": "https://pdfs.semanticscholar.org/d79b/a428e1cf1b8aa5d320a93166315bb30b4765.pdf", "anchor_text": "Noise"}, {"url": "https://pdfs.semanticscholar.org/d79b/a428e1cf1b8aa5d320a93166315bb30b4765.pdf", "anchor_text": "One hypothesis of the above observation is that relaxing consistency introduces stochastic noise into training process"}, {"url": "https://en.wikipedia.org/wiki/Gaussian_noise", "anchor_text": "Gaussian Noise"}, {"url": "https://medium.com/tag/programming?source=post_page-----1bd5f0f240f---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1bd5f0f240f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1bd5f0f240f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----1bd5f0f240f---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----1bd5f0f240f---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1bd5f0f240f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&user=Alex+Diaz&userId=3b43171da13b&source=-----1bd5f0f240f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1bd5f0f240f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&user=Alex+Diaz&userId=3b43171da13b&source=-----1bd5f0f240f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1bd5f0f240f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1bd5f0f240f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1bd5f0f240f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1bd5f0f240f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alejandrods?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alejandrods?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alex Diaz"}, {"url": "https://medium.com/@alejandrods/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "128 Followers"}, {"url": "https://medium.com/@immune_technology_institute", "anchor_text": "https://medium.com/@immune_technology_institute"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3b43171da13b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&user=Alex+Diaz&userId=3b43171da13b&source=post_page-3b43171da13b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb9a177424e1e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnoise-its-not-always-annoying-1bd5f0f240f&newsletterV3=3b43171da13b&newsletterV3Id=b9a177424e1e&user=Alex+Diaz&userId=3b43171da13b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}