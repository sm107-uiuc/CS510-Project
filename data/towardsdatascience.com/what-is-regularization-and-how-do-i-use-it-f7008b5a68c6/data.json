{"url": "https://towardsdatascience.com/what-is-regularization-and-how-do-i-use-it-f7008b5a68c6", "time": 1683009752.559215, "path": "towardsdatascience.com/what-is-regularization-and-how-do-i-use-it-f7008b5a68c6/", "webpage": {"metadata": {"title": "Regularization with Ridge, Lasso, and Elastic Net Regressions | by Blake Samaha | Towards Data Science", "h1": "Regularization with Ridge, Lasso, and Elastic Net Regressions", "description": "Learn what is Regularization and Over/underfitting a model looks like. A basic guide to understanding Ridge, Lasso, and Elastic Net regression techniques."}, "outgoing_paragraph_urls": [{"url": "https://github.com/bsamaha/Blog-Post-Ridge-and-Lasso", "anchor_text": "Click this link to view the GitHub repository containing the notebook for this blog post.", "paragraph_index": 1}, {"url": "https://www.mathsisfun.com/algebra/degree-expression.html", "anchor_text": "how to determine the degree of a polynomial function please refer to this website", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Residual_sum_of_squares", "anchor_text": "RSS", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Mean_squared_error", "anchor_text": "MSE", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Root-mean-square_deviation", "anchor_text": "RMSE", "paragraph_index": 12}, {"url": "https://medium.com/swlh/my-guide-to-understanding-the-assumptions-of-ordinary-least-squares-regressions-b180f81801a4", "anchor_text": "If you need a refresher on the assumptions of an OLS model please check out my previous blog post.", "paragraph_index": 15}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html?highlight=elastic%20net#sklearn.linear_model.ElasticNet", "anchor_text": "sci-kit learn\u2019s documentation.", "paragraph_index": 24}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch#sklearn.model_selection.GridSearchCV", "anchor_text": "Sci-kit learn\u2019s GridSearchCV", "paragraph_index": 26}, {"url": "https://github.com/bsamaha/dsc-mod-2-project-v2-1-onl01-dtsc-ft-041320.git", "anchor_text": "my GitHub repository", "paragraph_index": 36}], "all_paragraphs": ["You have trained a regression model and your R\u00b2 comes back and it looks good \u2014 almost like it is too good. Of course, the next logical step is to see how the test data set fares. Spoiler alert: it will not have near the success of the training set.", "This is a quite common phenomenon referred to as \u201coverfitting\u201d. Overfitting has a polar opposite called underfitting. In technical terms, overfitting means the model you built has more parameters than the data can justify. Click this link to view the GitHub repository containing the notebook for this blog post.", "Working with computers has a way of disconnecting us from reality and overfitting/underfitting models is the proof. For example, in construction, computer aided design (CAD) enables drafters to draw extreme tolerances such as 0.001 inches for example. If you draw a plan telling an excavator to dig a trench 34.963 inches deep, can you really expect heavy machinery to have that kind of precision? Can you expect a carpenter in the field to cut lumber to .001 inches? I can tell you from experience that it will not happen. The trench will be about 36 inches deep (3 feet) and the board will probably be rounded to the nearest 1/8 inch or if you\u2019re lucky 1/16 inch. This is a real-world example of overfitting a computer model\u2019s calculations that happens all the time.", "A real-world example of underfitting would be a gas oven that only has 2 input settings, max heat, and off. It would be nearly impossible to cook anything thorough as your output of food would either be burnt to a crisp or still raw!", "You may be asking what does all this have to do with regularization? The answer is everything. Adding the right amount of bias to a model can help make more accurate predictions by desensitizing it to some of the noise in the training data.", "In the plots above the blue dots are sample data points taken from the real-world. The distance those samples are from the yellow line, \u201cTrue Function\u201d, is called the \u201cnoise\u201d of the data. The distance of the sample points to the blue line is referred to as the \u201cerror\u201d of our model.", "The underfit model\u2019s predictions do not explain the sample data of the true function at all. The true function is more complex than a simple linear equation with a degree of 1. If you need a refresher on how to determine the degree of a polynomial function please refer to this website.", "A good analogy for this model would be like answering \u201cC\u201d for every question on a multiple-choice test. Sure, you may get lucky on a couple of questions, but you will get the vast majority wrong.", "The overfit model\u2019s prediction line describes the true function almost perfectly \u2014 and then some. This model\u2019s prediction output is a super complex 15th-degree polynomial function. As the complexity (degree) of a model increases the model begins to care less about the error of its predictions and more about predicting the value of the training data it was given. Take time to trace along the overfit model\u2019s prediction line and see how far it travels away from the true function.", "Continuing our exam analogy, the overfitted model found the answer key to our exam and memorized that key. What will happen when we give the model an exam it didn\u2019t have the answer key for? Most likely it will fail miserably.", "The proper fit model is in the Goldilocks zone. It is not too simple nor too complicated. This model still has complexity being an 8th-degree polynomial function, but this model does a good job of seeing through the noise in the sample data. This allows the model to vastly reduce the error from the overfitted model and more accurately predict the values of the true function. This Goldilocks zone of model fit is what we are attempting to achieve with regularization.", "Ridge and Lasso regressions techniques expand on simple linear regression. Let\u2019s review what OLS regressions a bit before moving on:", "A cost function measures the difference of the model output to the actual data. There are multiple cost functions for linear regression such as RSS, MSE, and RMSE. In the example above the cost function is RSS (y_actual \u2014 y_predicted)\u00b2. The predicted value can be substituted with the equation of your regression line. Your feature coefficients, also known as slope, are (m\u2c7c). These feature coefficients are the object we are manipulating with our regularization techniques.", "Note: I use the terms predictors and features synonymously throughout this post. A predictor is an independent variable (x variable) used in the model. If you were building a BMI estimator, height would most likely be one of your predictors.", "When building a model, no matter the type, it is imperative you perform proper data cleaning and exploration techniques to completely understand your data. All of the regularization techniques in this blog apply a penalty based on the predictor\u2019s coefficients. This means you must standardize your data before applying these algorithms.", "The assumptions of these techniques depend on the type of model you apply the regularization technique to. If you need a refresher on the assumptions of an OLS model please check out my previous blog post.", "Ridge regression is a small extension of the OLS cost function where it adds a penalty to the model as the complexity of the model increases. The more predictors(m\u2c7c) you have in your data set the higher the R\u00b2 value, and the higher the chance your model will overfit to your data. Ridge regression is often referred to as L2 norm regularization.", "Keep in mind that the goal is to minimize the cost function, so the larger the penalty term (\u03bb * sum(m\u2c7c\u00b2)) the worse the model will perform. This function penalizes your model for having too many or too large predictors. The objective of Ridge regression is to reduce the effect of these predictors to decrease the chance of overfitting your data. If we were to set \u03bb = 0 then this would be a normal OLS regression.", "The most common use of Ridge regression is to be preemptive in addressing overfitting concerns. Ridge regression is a good tool for handling multicollinearity when you must keep all your predictors. It addresses the collinearity by shrinking the magnitude of the predictors \u2014 but never eliminates them.", "Ridge regression works well if there are many predictors of about the same magnitude. This means all predictors have similar power to predict the target value.", "When looking at the equation below and thinking to yourself \u201cthat looks almost identical to Ridge regression.\u201d Well, you\u2019re right for the most part. Lasso differs from Ridge regression by summing the absolute value of the predictors (m\u2c7c) instead of summing the squared values.", "Lasso is an acronym that stands for \u201cLeast Absolute Shrinkage and Selection Operator.\u201d Due to the penalty term not being squared, some values can reach 0. When a predictor coefficient (m\u2c7c) reaches 0 that predictor does not affect the model.", "Lasso is great for multi-collinearity due to its feature selection properties. One of the most effective ways to address the collinearity of two predictor variables is to cut one. Yet, the removal does come at a cost. There may be instances where a collection of variables are collinear, and still provide value to making estimations. Lasso will arbitrarily choose one predictor to carry on and it will drop the other.", "Lasso tends to do well if there are few significant predictors and the magnitudes of the others are close to zero. Another way of saying, a few variables are much better predictors of the target value than the other predictors.", "So, what if I don\u2019t want to choose? What if I don\u2019t know what I want or need? Elastic Net regression was created as a critique of Lasso regression. While it helps in feature selection, sometimes you don\u2019t want to remove features aggressively. As you may have guessed, Elastic Net is a combination of both Lasso and Ridge regressions. Since we have an idea of how the Ridge and Lasso regressions act, I will not go into details. Please refer to sci-kit learn\u2019s documentation.", "As you can see in the picture above there are now two \u03bb terms. \u03bb\u2081 is the \u201calpha\u201d value for the Lasso part of the regression and \u03bb\u2082 is the \u201calpha\u201d value for the Ridge regression equation. When using sci-kit learn\u2019s Elastic Net regression the alpha term is a ratio of \u03bb\u2081:\u03bb\u2082. When setting the ratio = 0 it acts as a Ridge regression, and when the ratio = 1 it acts as a Lasso regression. Any value between 0 and 1 is a combination of Ridge and Lasso regression.", "Now the fun begins! I am going to assume you already know how to build a basic linear model. If not, you will see how in the corresponding notebook for this blog. Using Lasso and Ridge regressions are very similar \u2014 except for the \u201calpha value\u201d. Sci-kit learn\u2019s GridSearchCV searches a range of values to find the optimal value for your hyperparameters.", "Below is the code I used to build the resultant graph pictured below. This model was created using Sci-Kit Learn\u2019s Boston Housing data set.", "Notice how the optimal alpha value is 0.0106 and not 0. This proves that adding this bit of alpha produced a higher cross-validation score than a pure linear regression did. It is easy to see in this chart that as the alpha value increases the CV score approaches and hits 0.", "The above image is to show that at a value of 1 the Lasso regression removed 8 of the features leaving 5 out of a total 13 predictors left. The predictive strength of the model decreased as features were removed, but the model is much more simple now. This gives a bit of insight into the power of good feature selection.", "Once again, like the Lasso regression here is the code and the following graph is produced.", "Unlike the Lasso regression, we can see here how the value is approaching 0 as the alpha value increases. If you wish, in the GitHub notebook you can go increase the alpha value and see that it will never reach 0.", "In the Ridge regression graph, we see that with an alpha value of 2.97 our model has a better performance than it did at a value of 0. Remember that an alpha value of 0 is equal to a normal regression. This proves that the right amount of bias can improve your model and prevent overfitting!", "That\u2019s it! You can now use your optimized alpha value to run the regression of your choice. Here is a quick summary of what we have discussed:", "What is Regularization: Techniques for combating overfitting and improving training.", "When do I use Regularization: Lasso \u2014 Few significant predictors and the magnitudes of the others are close to zero Ridge regression \u2014 Ridge regression works well if there are many large predictors of about the same value. Elastic Net \u2014 Mixture of both Ridge and Lasso", "Thank you for taking the time to read my blog. The notebook is available in full detail at my GitHub repository. If you have any questions or have constructive criticism, please feel free to reach out to me!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a data junkie working to kick my addiction to MS Excel with Python."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff7008b5a68c6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://buh-lah-kay.medium.com/?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": ""}, {"url": "https://buh-lah-kay.medium.com/?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "Blake Samaha"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8301b2223791&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&user=Blake+Samaha&userId=8301b2223791&source=post_page-8301b2223791----f7008b5a68c6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7008b5a68c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7008b5a68c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/bsamaha/Blog-Post-Ridge-and-Lasso", "anchor_text": "Click this link to view the GitHub repository containing the notebook for this blog post."}, {"url": "https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html", "anchor_text": ""}, {"url": "https://docs.scipy.org/doc/numpy/reference/generated/numpy.cos.html#numpy.cos", "anchor_text": "np.cos"}, {"url": "https://docs.scipy.org/doc/numpy/reference/constants.html#numpy.pi", "anchor_text": "np.pi"}, {"url": "https://www.mathsisfun.com/algebra/degree-expression.html", "anchor_text": "how to determine the degree of a polynomial function please refer to this website"}, {"url": "https://en.wikipedia.org/wiki/Residual_sum_of_squares", "anchor_text": "RSS"}, {"url": "https://en.wikipedia.org/wiki/Mean_squared_error", "anchor_text": "MSE"}, {"url": "https://en.wikipedia.org/wiki/Root-mean-square_deviation", "anchor_text": "RMSE"}, {"url": "https://medium.com/swlh/my-guide-to-understanding-the-assumptions-of-ordinary-least-squares-regressions-b180f81801a4", "anchor_text": "If you need a refresher on the assumptions of an OLS model please check out my previous blog post."}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html?highlight=elastic%20net#sklearn.linear_model.ElasticNet", "anchor_text": "sci-kit learn\u2019s documentation."}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch#sklearn.model_selection.GridSearchCV", "anchor_text": "Sci-kit learn\u2019s GridSearchCV"}, {"url": "https://github.com/bsamaha/dsc-mod-2-project-v2-1-onl01-dtsc-ft-041320.git", "anchor_text": "my GitHub repository"}, {"url": "http://www.linkedin.com/in/blake-samaha-54a9bbaa", "anchor_text": "www.linkedin.com/in/blake-samaha-54a9bbaa"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f7008b5a68c6---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f7008b5a68c6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/regularization?source=post_page-----f7008b5a68c6---------------regularization-----------------", "anchor_text": "Regularization"}, {"url": "https://medium.com/tag/regression?source=post_page-----f7008b5a68c6---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f7008b5a68c6---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7008b5a68c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&user=Blake+Samaha&userId=8301b2223791&source=-----f7008b5a68c6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7008b5a68c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&user=Blake+Samaha&userId=8301b2223791&source=-----f7008b5a68c6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7008b5a68c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff7008b5a68c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f7008b5a68c6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f7008b5a68c6--------------------------------", "anchor_text": ""}, {"url": "https://buh-lah-kay.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://buh-lah-kay.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blake Samaha"}, {"url": "https://buh-lah-kay.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "104 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8301b2223791&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&user=Blake+Samaha&userId=8301b2223791&source=post_page-8301b2223791--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbe63cc83975&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-regularization-and-how-do-i-use-it-f7008b5a68c6&newsletterV3=8301b2223791&newsletterV3Id=be63cc83975&user=Blake+Samaha&userId=8301b2223791&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}