{"url": "https://towardsdatascience.com/web-scraping-with-selenium-d7b6d8d3265a", "time": 1683011941.038284, "path": "towardsdatascience.com/web-scraping-with-selenium-d7b6d8d3265a/", "webpage": {"metadata": {"title": "Web Scraping with Selenium. This is the third part of a 4 part\u2026 | by Karthikeyan P | Towards Data Science", "h1": "Web Scraping with Selenium", "description": "This is the third part of a 4 part tutorial series on web scraping using Scrapy and Selenium."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/web-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd", "anchor_text": "Part 1: Web scraping with Scrapy: Theoretical Understanding", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/web-scraping-with-scrapy-practical-understanding-2fbdae337a3b", "anchor_text": "Part 2: Web scraping with Scrapy: Practical Understanding", "paragraph_index": 5}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1", "anchor_text": "Part 4: Web scraping with Selenium & Scrapy", "paragraph_index": 6}, {"url": "https://www.selenium.dev/documentation/en/getting_started_with_webdriver/browsers/", "anchor_text": "5 Web Browsers.", "paragraph_index": 8}, {"url": "https://sites.google.com/a/chromium.org/chromedriver/", "anchor_text": "site.", "paragraph_index": 9}, {"url": "https://github.com/mozilla/geckodriver/", "anchor_text": "Firefox", "paragraph_index": 10}, {"url": "https://openaq.org/", "anchor_text": "OpenAQ", "paragraph_index": 15}, {"url": "https://openaq.org/robots.txt", "anchor_text": "robots.txt", "paragraph_index": 15}, {"url": "http://openaq.org.", "anchor_text": "http://openaq.org.", "paragraph_index": 16}, {"url": "https://blissair.com/what-is-pm-2-5.htm", "anchor_text": "link.", "paragraph_index": 16}, {"url": "http://openaq.org", "anchor_text": "http://openaq.org", "paragraph_index": 17}, {"url": "https://openaq.org/#/locations", "anchor_text": "https://openaq.org/#/locations", "paragraph_index": 18}, {"url": "http://openaq.org", "anchor_text": "http://openaq.org", "paragraph_index": 22}, {"url": "https://github.com/karthikn2789/Selenium-Project", "anchor_text": "GitHub repository", "paragraph_index": 23}, {"url": "https://openaq.org/#/countries", "anchor_text": "https://openaq.org/#/countries", "paragraph_index": 24}, {"url": "https://github.com/karthikn2789/Selenium-Project", "anchor_text": "repository", "paragraph_index": 31}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1", "anchor_text": "next tutorial", "paragraph_index": 31}], "all_paragraphs": ["Selenium is a portable framework for testing web applications. It is open-source software released under the Apache License 2.0 that runs on Windows, Linux and macOS. Despite serving its major purpose, Selenium is also used as a web scraping tool. Without delving into the components of Selenium, we shall focus on a single component that is useful for web scraping, WebDriver. Selenium WebDriver provides us with an ability to control a web browser through a programming interface to create and execute test cases.", "In our case, we shall be using it for scraping data from websites. Selenium comes in handy when websites display content dynamically i.e. use JavaScripts to render content. Even though Scrapy is a powerful web scraping framework, it becomes useless with these dynamic websites. My goal for this tutorial is to make you familiarize with Selenium and carry out some basic web scraping using it.", "Let us start by installing selenium and a webdriver. WebDrivers support 7 Programming Languages: Python, Java, C#, Ruby, PHP, .Net and Perl. The examples in this manual are with Python language. There are tutorials available on the internet with other languages.", "This is the third part of a 4 part tutorial series on web scraping using Scrapy and Selenium. The other parts can be found at", "Part 1: Web scraping with Scrapy: Theoretical Understanding", "Part 2: Web scraping with Scrapy: Practical Understanding", "Part 4: Web scraping with Selenium & Scrapy", "Installing Selenium on any Linux OS is easy. Just execute the following command in a terminal and Selenium would be installed automatically.", "Selenium officially has WebDrivers for 5 Web Browsers. Here, we shall see the installation of WebDriver for two of the most widely used browsers: Chrome and Firefox.", "First, we need to download the latest stable version of chromedriver from Chrome\u2019s official site. It would be a zip file. All we need to do is extract it and put it in the executable path.", "Installing geckodriver for Firefox is even simpler since it is maintained by Firefox itself. All we need to do is execute the following line in a terminal and you are ready to play around with selenium and geckodriver.", "There are two examples with increasing levels of complexity. First one would be a simpler webpage opening and typing into textboxes and pressing key(s). This example is to showcase how a webpage can be controlled through Selenium using a program. The second one would be a more complex web scraping example involving mouse scrolling, mouse button clicks and navigating to other pages. The goal here is to make you feel confident to start web scraping with Selenium.", "Let us try out a simple automation task using Selenium and chromedriver as our training wheel exercise. For this, we would try to log into a Facebook account and we are not performing any kind of data scraping. I am assuming that you have some knowledge of identifying HTML tags used in a webpage using the browser\u2019s developer tools. The following is a piece of python code that opens up a new Chrome browser, opens the Facebook main page, enters a username, password and clicks Login button.", "After executing this python code, your Facebook homepage would open in a new Chrome browser window. Let us examine how this became possible.", "IMPORTANT NOTE:Any instance created in a program should be closed at the end of the program or after its purpose is served. So, whenever we are creating a webdriver instance, it has to be terminated using driver.quit(). If we do not terminate the opened instances, it starts to use up RAM, which may impact the machine's performance and slow it down. In the above example, this termination process has been commented out to show the output in a browser window. And, if terminated, the browser window would also be closed and the reader would not be able to see the output.", "This is a more complex example. OpenAQ is a non-profit organization that collects and shares air quality data that are open and can be accessed in many ways. This is evident from the site\u2019s robots.txt.", "Our goal here is to collect data on PM2.5 readings from all the countries listed on http://openaq.org. PM2.5 are the particulate matter (PM) that have a diameter lesser than 2.5 micrometres, which is way smaller than the diameter of a human hair. If the reader is interested in knowing more about PM2.5, please follow this link.", "The reason for choosing Selenium over Scrapy is that http://openaq.org uses React JS to render data. If it were static webpages, Scrapy would scrape the data efficiently. To scrape data, we first need to analyze the website, manually navigate the pages and note down the user interaction steps required to extract data.", "It is always better to scrape with as few webpage navigations as possible. The website has a webpage https://openaq.org/#/locations which could be used as a starting point for scraping.", "The filter locations option on the left-side panel is used to filter out PM2.5 data for each country. The Results on the right-side panel show cards that open a new page when clicked to display PM2.5 and other data.", "A sample page containing PM2.5 data is shown below. From this page, we can extract PM2.5 values, location, city, country, date and time of recording PM2.5 value using XPATH or CSS.", "Similarly, the left-side panel can be used to filter out and collect URLs of all the locations that contain PM2.5 data. The following are the actions that we performed manually to collect the data.", "Based on the manual steps performed, data collection from http://openaq.org is broken down to 3 steps.", "Now that we have the steps needed, let us start to code. The example is divided into 3 functions, each performing the task corresponding to the aforementioned 3 steps. The python code for this example can be found in my GitHub repository.", "Instead of using OpenAQ locations webpage, there is https://openaq.org/#/countries webpage, which displays all the countries at once. It is easier to extract country names from this page.", "Let us understand how the code works. As always, the first step is to instantiate the webdriver. Here, instead of opening a new browser window, the webdriver is instantiated as a headless one. This way, a new browser window will not be opened and the burden on RAM would be reduced. The second step is to open the webpage containing the list of countries. The concept of wait is used in the above code.", "The third step is to extract the country names using the tag with class name \u201ccard__title\u201d. Finally, the country names are written to a JSON file for persistence. Below is a glimpse of the JSON file.", "The next step after getting the list of countries is to get the URLs of every location that records PM2.5 data. To do this, we need to open the OpenAQ locations webpage and make use of the left-side panel to filter out countries and PM2.5 data. Once it is filtered, the right-side panel would be populated with cards to individual locations that record PM2.5 data. We extract the URLs corresponding to each of these cards and eventually write them to a file that would be used in the next step of extracting PM2.5 data. Some countries have more than 20 locations that record PM2.5 data. For example, Australia has 162 locations, Belgium has 69 locations, China has 1602 locations. For these countries, the right-side panel on locations webpage is subdivided into pages. It is highly imperative that we navigate through these pages and collect URLs of all the locations. The code below has a while TRUE: loop that performs this exact task of page navigation.", "It is always a good practice to log the output of programs that tend to run longer than 5 minutes. For this purpose, the above code makes use of logzero. The output JSON file containing the URLs looks like this.", "The process of getting PM2.5 data from the individual location is a straight forward web scraping task of identifying the HTML tag containing the data and extracting it with text processing. The same happens in the code provided below. The code extracts the country, city, location, PM2.5 value, URL of the location, date and time of recording PM2.5 value. Since there are over 5000 URLs to be opened, there would be a problem with RAM usage unless the RAM installed is over 64GB. To make this program to run on machines with minimum 8GB of RAM, the webdriver is terminated and re-instantiated every 200 URLs.", "The outcome of the program looks as shown below. The program has extracted PM2.5 values from 4114 individual locations. Imagine opening these individual webpages and manually extracting the data. It is times like this makes us appreciate the use of web scraping programs or bots, in general.", "I hope this tutorial has given you the confidence to start web scraping with Selenium. The complete code of the example is available in my GitHub repository. In the next tutorial, I shall show you how to integrate Selenium with Scrapy.", "Till then, Good Luck. Stay safe and happy learning.!", "Data Science & Machine Learning Aficionado | Tech Geek | Writing to share the joy of learning"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd7b6d8d3265a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@karthikn2789?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Karthikeyan P"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33836712ab7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&user=Karthikeyan+P&userId=33836712ab7a&source=post_page-33836712ab7a----d7b6d8d3265a---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd7b6d8d3265a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&user=Karthikeyan+P&userId=33836712ab7a&source=-----d7b6d8d3265a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd7b6d8d3265a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&source=-----d7b6d8d3265a---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@cgower?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Christopher Gower"}, {"url": "https://unsplash.com/s/photos/coding?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/web-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd", "anchor_text": "Part 1: Web scraping with Scrapy: Theoretical Understanding"}, {"url": "https://towardsdatascience.com/web-scraping-with-scrapy-practical-understanding-2fbdae337a3b", "anchor_text": "Part 2: Web scraping with Scrapy: Practical Understanding"}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1", "anchor_text": "Part 4: Web scraping with Selenium & Scrapy"}, {"url": "https://www.selenium.dev/documentation/en/getting_started_with_webdriver/browsers/", "anchor_text": "5 Web Browsers."}, {"url": "https://sites.google.com/a/chromium.org/chromedriver/", "anchor_text": "site."}, {"url": "https://chromedriver.storage.googleapis.com/83.0.4103.39/chromedriver_linux64.zip", "anchor_text": "https://chromedriver.storage.googleapis.com/83.0.4103.39/chromedriver_linux64.zip"}, {"url": "https://github.com/mozilla/geckodriver/", "anchor_text": "Firefox"}, {"url": "https://www.facebook.com", "anchor_text": "Facebook"}, {"url": "https://openaq.org/", "anchor_text": "OpenAQ"}, {"url": "https://openaq.org/robots.txt", "anchor_text": "robots.txt"}, {"url": "http://openaq.org.", "anchor_text": "http://openaq.org."}, {"url": "https://blissair.com/what-is-pm-2-5.htm", "anchor_text": "link."}, {"url": "http://openaq.org", "anchor_text": "http://openaq.org"}, {"url": "http://openaq.org", "anchor_text": "http://openaq.org"}, {"url": "https://openaq.org/#/locations", "anchor_text": "https://openaq.org/#/locations"}, {"url": "https://openaq.org/#/locations", "anchor_text": "https://openaq.org/#/locations"}, {"url": "https://openaq.org/#/locations", "anchor_text": "https://openaq.org/#/locations"}, {"url": "https://openaq.org", "anchor_text": "https://openaq.org"}, {"url": "https://openaq.org/#/locations", "anchor_text": "https://openaq.org/#/locations"}, {"url": "http://openaq.org", "anchor_text": "http://openaq.org"}, {"url": "https://github.com/karthikn2789/Selenium-Project", "anchor_text": "GitHub repository"}, {"url": "https://openaq.org/#/countries", "anchor_text": "https://openaq.org/#/countries"}, {"url": "https://openaq.org/#/countries", "anchor_text": "https://openaq.org/#/countries"}, {"url": "https://github.com/karthikn2789/Selenium-Project", "anchor_text": "repository"}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1", "anchor_text": "next tutorial"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----d7b6d8d3265a---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/tag/selenium?source=post_page-----d7b6d8d3265a---------------selenium-----------------", "anchor_text": "Selenium"}, {"url": "https://medium.com/tag/python?source=post_page-----d7b6d8d3265a---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/web-scraping-series?source=post_page-----d7b6d8d3265a---------------web_scraping_series-----------------", "anchor_text": "Web Scraping Series"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd7b6d8d3265a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&user=Karthikeyan+P&userId=33836712ab7a&source=-----d7b6d8d3265a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd7b6d8d3265a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&user=Karthikeyan+P&userId=33836712ab7a&source=-----d7b6d8d3265a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd7b6d8d3265a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33836712ab7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&user=Karthikeyan+P&userId=33836712ab7a&source=post_page-33836712ab7a----d7b6d8d3265a---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2ef23ab79d68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&newsletterV3=33836712ab7a&newsletterV3Id=2ef23ab79d68&user=Karthikeyan+P&userId=33836712ab7a&source=-----d7b6d8d3265a---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Written by Karthikeyan P"}, {"url": "https://medium.com/@karthikn2789/followers?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "89 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33836712ab7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&user=Karthikeyan+P&userId=33836712ab7a&source=post_page-33836712ab7a----d7b6d8d3265a---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2ef23ab79d68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-selenium-d7b6d8d3265a&newsletterV3=33836712ab7a&newsletterV3Id=2ef23ab79d68&user=Karthikeyan+P&userId=33836712ab7a&source=-----d7b6d8d3265a---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1?source=author_recirc-----d7b6d8d3265a----0---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=author_recirc-----d7b6d8d3265a----0---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=author_recirc-----d7b6d8d3265a----0---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Karthikeyan P"}, {"url": "https://medium.com/swlh?source=author_recirc-----d7b6d8d3265a----0---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "The Startup"}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1?source=author_recirc-----d7b6d8d3265a----0---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Web Scraping With Selenium & ScrapyThis is the final part of a 4 part tutorial series on web scraping using Scrapy and Selenium."}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1?source=author_recirc-----d7b6d8d3265a----0---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "\u00b711 min read\u00b7Aug 6, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fswlh%2F9d9c2e9d83b1&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fweb-scraping-with-selenium-scrapy-9d9c2e9d83b1&user=Karthikeyan+P&userId=33836712ab7a&source=-----9d9c2e9d83b1----0-----------------clap_footer----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1?source=author_recirc-----d7b6d8d3265a----0---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d9c2e9d83b1&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fweb-scraping-with-selenium-scrapy-9d9c2e9d83b1&source=-----d7b6d8d3265a----0-----------------bookmark_preview----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b6d8d3265a----1---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d7b6d8d3265a----1---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d7b6d8d3265a----1---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d7b6d8d3265a----1---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b6d8d3265a----1---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b6d8d3265a----1---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b6d8d3265a----1---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----d7b6d8d3265a----1-----------------bookmark_preview----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----d7b6d8d3265a----2---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----d7b6d8d3265a----2---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----d7b6d8d3265a----2---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d7b6d8d3265a----2---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----d7b6d8d3265a----2---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----d7b6d8d3265a----2---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----d7b6d8d3265a----2---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----d7b6d8d3265a----2-----------------bookmark_preview----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/web-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd?source=author_recirc-----d7b6d8d3265a----3---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=author_recirc-----d7b6d8d3265a----3---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=author_recirc-----d7b6d8d3265a----3---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Karthikeyan P"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d7b6d8d3265a----3---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/web-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd?source=author_recirc-----d7b6d8d3265a----3---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "Web scraping with Scrapy: Theoretical UnderstandingThis is the first part of a 4 part tutorial series on web scraping using Scrapy and Selenium."}, {"url": "https://towardsdatascience.com/web-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd?source=author_recirc-----d7b6d8d3265a----3---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": "\u00b712 min read\u00b7Jul 31, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff8639a25d9cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd&user=Karthikeyan+P&userId=33836712ab7a&source=-----f8639a25d9cd----3-----------------clap_footer----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/web-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd?source=author_recirc-----d7b6d8d3265a----3---------------------a8c12704_3fa3_4288_a1d3_47df90d657d8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8639a25d9cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd&source=-----d7b6d8d3265a----3-----------------bookmark_preview----a8c12704_3fa3_4288_a1d3_47df90d657d8-------", "anchor_text": ""}, {"url": "https://medium.com/@karthikn2789?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "See all from Karthikeyan P"}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@molixnu/avoiding-bot-detection-with-selenium-python-bypassing-puzzle-captcha-using-a-cookie-based-dd1e95965b37?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@molixnu?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@molixnu?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Mikel Molinuevo"}, {"url": "https://medium.com/@molixnu/avoiding-bot-detection-with-selenium-python-bypassing-puzzle-captcha-using-a-cookie-based-dd1e95965b37?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Avoiding bot detection with Selenium (Python): Bypassing Puzzle Captcha using a cookie-based\u2026Web scraping is a good way to gather data from the Internet. However, some pages are willing to protect themselves from bot traffic. This\u2026"}, {"url": "https://medium.com/@molixnu/avoiding-bot-detection-with-selenium-python-bypassing-puzzle-captcha-using-a-cookie-based-dd1e95965b37?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "5 min read\u00b7Dec 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fdd1e95965b37&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40molixnu%2Favoiding-bot-detection-with-selenium-python-bypassing-puzzle-captcha-using-a-cookie-based-dd1e95965b37&user=Mikel+Molinuevo&userId=8f1a2715f78&source=-----dd1e95965b37----0-----------------clap_footer----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@molixnu/avoiding-bot-detection-with-selenium-python-bypassing-puzzle-captcha-using-a-cookie-based-dd1e95965b37?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd1e95965b37&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40molixnu%2Favoiding-bot-detection-with-selenium-python-bypassing-puzzle-captcha-using-a-cookie-based-dd1e95965b37&source=-----d7b6d8d3265a----0-----------------bookmark_preview----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@zenrows/web-scraping-in-python-avoid-detection-like-a-ninja-69bf688aba9a?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@zenrows?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@zenrows?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "ZenRows"}, {"url": "https://medium.com/@zenrows/web-scraping-in-python-avoid-detection-like-a-ninja-69bf688aba9a?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Web Scraping in Python: Avoid Detection Like a NinjaScraping should be about extracting content from HTML. It sounds simple but has many obstacles. The first one is to obtain the said HTML\u2026"}, {"url": "https://medium.com/@zenrows/web-scraping-in-python-avoid-detection-like-a-ninja-69bf688aba9a?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "13 min read\u00b7Apr 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F69bf688aba9a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40zenrows%2Fweb-scraping-in-python-avoid-detection-like-a-ninja-69bf688aba9a&user=ZenRows&userId=7f9b47ce47de&source=-----69bf688aba9a----1-----------------clap_footer----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@zenrows/web-scraping-in-python-avoid-detection-like-a-ninja-69bf688aba9a?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69bf688aba9a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40zenrows%2Fweb-scraping-in-python-avoid-detection-like-a-ninja-69bf688aba9a&source=-----d7b6d8d3265a----1-----------------bookmark_preview----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@sreejaec/design-patterns-for-selenium-webdriver-automation-b276a55d42c7?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@sreejaec?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@sreejaec?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Sreeja Erattuthody Chandrasekharan"}, {"url": "https://medium.com/@sreejaec/design-patterns-for-selenium-webdriver-automation-b276a55d42c7?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Design Patterns for Selenium WebDriver AutomationDesign patterns are the best solutions and practices to the software architecture which is evolved over time by many industry experts while\u2026"}, {"url": "https://medium.com/@sreejaec/design-patterns-for-selenium-webdriver-automation-b276a55d42c7?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "4 min read\u00b7Feb 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fb276a55d42c7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sreejaec%2Fdesign-patterns-for-selenium-webdriver-automation-b276a55d42c7&user=Sreeja+Erattuthody+Chandrasekharan&userId=99a74d962db9&source=-----b276a55d42c7----0-----------------clap_footer----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@sreejaec/design-patterns-for-selenium-webdriver-automation-b276a55d42c7?source=read_next_recirc-----d7b6d8d3265a----0---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb276a55d42c7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sreejaec%2Fdesign-patterns-for-selenium-webdriver-automation-b276a55d42c7&source=-----d7b6d8d3265a----0-----------------bookmark_preview----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/pick-your-optimal-flight-instantly-using-web-scraping-insightful-power-bi-viz-9ff47d5980e5?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@johnleungTJ?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@johnleungTJ?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "John Leung"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/pick-your-optimal-flight-instantly-using-web-scraping-insightful-power-bi-viz-9ff47d5980e5?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Pick Your Optimal Flight Instantly \u2014 Using Web Scraping & Power BI VizStep-by-step guide on leveraging Python web scraping & Power BI visualization tricks to pick your optimal flight without decision fatigue"}, {"url": "https://medium.com/geekculture/pick-your-optimal-flight-instantly-using-web-scraping-insightful-power-bi-viz-9ff47d5980e5?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "\u00b710 min read\u00b7Dec 18, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2F9ff47d5980e5&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fpick-your-optimal-flight-instantly-using-web-scraping-insightful-power-bi-viz-9ff47d5980e5&user=John+Leung&userId=6125e8835d3b&source=-----9ff47d5980e5----1-----------------clap_footer----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/pick-your-optimal-flight-instantly-using-web-scraping-insightful-power-bi-viz-9ff47d5980e5?source=read_next_recirc-----d7b6d8d3265a----1---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9ff47d5980e5&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fpick-your-optimal-flight-instantly-using-web-scraping-insightful-power-bi-viz-9ff47d5980e5&source=-----d7b6d8d3265a----1-----------------bookmark_preview----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@gnrnoguz/scraping-dynamic-pages-with-python-overcoming-challenges-with-beautiful-soup-and-selenium-7f6a770f5121?source=read_next_recirc-----d7b6d8d3265a----2---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@gnrnoguz?source=read_next_recirc-----d7b6d8d3265a----2---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@gnrnoguz?source=read_next_recirc-----d7b6d8d3265a----2---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Oguz Guneren"}, {"url": "https://medium.com/@gnrnoguz/scraping-dynamic-pages-with-python-overcoming-challenges-with-beautiful-soup-and-selenium-7f6a770f5121?source=read_next_recirc-----d7b6d8d3265a----2---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Scraping Dynamic Pages with Python: Overcoming Challenges with Beautiful Soup and SeleniumDuring my internship as a Data Scientist Intern, I was assigned a web scraping project that required me to extract extensive product\u2026"}, {"url": "https://medium.com/@gnrnoguz/scraping-dynamic-pages-with-python-overcoming-challenges-with-beautiful-soup-and-selenium-7f6a770f5121?source=read_next_recirc-----d7b6d8d3265a----2---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "3 min read\u00b7Mar 18"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7f6a770f5121&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40gnrnoguz%2Fscraping-dynamic-pages-with-python-overcoming-challenges-with-beautiful-soup-and-selenium-7f6a770f5121&user=Oguz+Guneren&userId=9e024a032a87&source=-----7f6a770f5121----2-----------------clap_footer----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/@gnrnoguz/scraping-dynamic-pages-with-python-overcoming-challenges-with-beautiful-soup-and-selenium-7f6a770f5121?source=read_next_recirc-----d7b6d8d3265a----2---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7f6a770f5121&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40gnrnoguz%2Fscraping-dynamic-pages-with-python-overcoming-challenges-with-beautiful-soup-and-selenium-7f6a770f5121&source=-----d7b6d8d3265a----2-----------------bookmark_preview----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://trading-data-analysis.pro/web-scraping-nasdaq-718dab33853e?source=read_next_recirc-----d7b6d8d3265a----3---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://scrapingking.medium.com/?source=read_next_recirc-----d7b6d8d3265a----3---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://scrapingking.medium.com/?source=read_next_recirc-----d7b6d8d3265a----3---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Scrapingdog"}, {"url": "https://trading-data-analysis.pro/?source=read_next_recirc-----d7b6d8d3265a----3---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Trading Data Analysis"}, {"url": "https://trading-data-analysis.pro/web-scraping-nasdaq-718dab33853e?source=read_next_recirc-----d7b6d8d3265a----3---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "Web Scraping NasdaqEverybody is aware of what Nasdaq is. Basically, it is a marketplace for buying and selling stocks. It was the first online stock exchange\u2026"}, {"url": "https://trading-data-analysis.pro/web-scraping-nasdaq-718dab33853e?source=read_next_recirc-----d7b6d8d3265a----3---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": "9 min read\u00b7Nov 4, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftrading-data-analysis%2F718dab33853e&operation=register&redirect=https%3A%2F%2Ftrading-data-analysis.pro%2Fweb-scraping-nasdaq-718dab33853e&user=Scrapingdog&userId=b830e47d1608&source=-----718dab33853e----3-----------------clap_footer----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://trading-data-analysis.pro/web-scraping-nasdaq-718dab33853e?source=read_next_recirc-----d7b6d8d3265a----3---------------------1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F718dab33853e&operation=register&redirect=https%3A%2F%2Ftrading-data-analysis.pro%2Fweb-scraping-nasdaq-718dab33853e&source=-----d7b6d8d3265a----3-----------------bookmark_preview----1aa9c1bb_cfab_4b82_bf11_3a7ee891073d-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----d7b6d8d3265a--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}