{"url": "https://towardsdatascience.com/hyperparameter-tuning-with-keras-tuner-283474fbfbe", "time": 1683006595.966845, "path": "towardsdatascience.com/hyperparameter-tuning-with-keras-tuner-283474fbfbe/", "webpage": {"metadata": {"title": "Hyperparameter Tuning with Keras Tuner | by Cedric Conol | Towards Data Science", "h1": "Hyperparameter Tuning with Keras Tuner", "description": "In this article, we\u2019ll review techniques data scientists use to create models that work great and win competitions. Getting the most out of our models means choosing the optimal hyperparameters for\u2026"}, "outgoing_paragraph_urls": [{"url": "https://keras-team.github.io/keras-tuner/", "anchor_text": "keras tuner", "paragraph_index": 2}, {"url": "https://keras.io/datasets/", "anchor_text": "list", "paragraph_index": 3}, {"url": "https://keras-team.github.io/keras-tuner/documentation/hyperparameters/", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://keras-team.github.io/keras-tuner/documentation/tuners/", "anchor_text": "Tuners", "paragraph_index": 14}, {"url": "http://jmlr.org/papers/v18/16-558.html", "anchor_text": "Li et. al", "paragraph_index": 18}, {"url": "https://github.com/cedricconol/keras-tuner-demo", "anchor_text": "repo", "paragraph_index": 22}, {"url": "http://Texthero.org", "anchor_text": "Texthero.org", "paragraph_index": 25}, {"url": "https://www.linkedin.com/in/conolcedric", "anchor_text": "https://www.linkedin.com/in/conolcedric", "paragraph_index": 25}], "all_paragraphs": ["Great data scientists do not settle with \u201cokay\u201d, they go beyond to achieve the extraordinary.", "In this article, we\u2019ll review techniques data scientists use to create models that work great and win competitions. Getting the most out of our models means choosing the optimal hyperparameters for our learning algorithm. This task is known as hyperparameter optimization or hyperparameter tuning. This is especially strenuous in deep learning as neural networks are full of hyperparameters. I\u2019ll assume that you are already familiar with common data science concepts like regression and mean squared error (MSE) metric and have experience building model using tensorflow and keras.", "To demonstrate hyperparameter tuning methods, we\u2019ll use keras tuner library to tune a regression model on the Boston housing price dataset. This dataset contains 13 attributes with 404 and 102 training and testing samples respectively. We\u2019ll use tensorflow as keras backend so make sure you have tensorflow installed on your machines. I\u2019m using tensorflow version \u20182.1.0\u2019 and kerastuner version \u20181.0.1\u2019. Tensorflow 2.0.x comes up with keras so you don\u2019t need to install keras separately if you have version 2.0.x. You can check the version you have using the code below:", "Boston housing price regression dataset can be downloaded directly using keras. Here\u2019s a list of datasets that comes with keras. To load the dataset, run the following codes.", "Note that if this is the first time you are using this dataset within keras, it will download the dataset from an external source.", "This is the regression model I\u2019ll use in this demo. The code below shows how the model was built without any tuning.", "This model has a MSE of around 434. I have set the random seed in numpy and tensorflow to 42 to get reproducible results. Despite doing so, I still get slightly different results every time I run the code. Let me know in the comments what else I missed make this reproducible.", "To start tuning the model in keras tuner, let\u2019s define a hypermodel first. Hypermodel is a keras tuner class that lets you define the model with a searchable space and build it.", "Create a class that inherits from kerastuner.HyperModel, like so:", "This is the same model we built earlier, except that for every hyperparameter, we defined a search space. You may have noticed hp.Int, hp.Float, and hp.Choice, these are used to define a search space for a hyperparameter that accepts an integer, float and a category respectively. A complete list of hyperparameter methods can be found here. \u2018hp\u2019 is an alias for Keras Tuner\u2019s HyperParameters class.", "Hyperparameter such as the number of units in a dense layer accepts an integer, hence, hp.Int is used to define a range of integers to try. Similarly, the dropout rate accepts a float value so hp.Float is used. Both hp.Int and hp.Float requires a name, minimum value and maximum value, while the step size and default value is optional.", "The hp.Int search space below is named, \u201cunits\u201d, and will have values from 8 to 64 in multiples of 4, and a default value of 8. hp. Float is used similarly as hp.Int but accepts float values.", "hp.Choice is used to define a categorical hyperparameter such as the activation function. The search space below, named \u201cdense_activation\u201d, will choose between \u201crelu\u201d, \u201ctanh\u201d, and \u201csigmoid\u201d functions, with a default value set to \u201crelu\u201d.", "Let\u2019s instantiate a hypermodel object. Input shape varies per dataset and the problem you are trying to solve.", "As the name suggests, this hyperparameter tuning method randomly tries a combination of hyperparameters from a given search space. To use this method in keras tuner, let\u2019s define a tuner using one of the available Tuners. Here\u2019s a full list of Tuners.", "Run the random search tuner using the search method.", "Select the best combination of hyperparameters the tuner had tried and evaluate.", "Random search\u2019s MSE is 53.48, a very big improvement from not performing any tuning at all.", "Hyperband is based on the algorithm by Li et. al. It optimizes random search method through adaptive resource allocation and early-stopping. Hyperband first runs random hyperparameter configurations for one iteration or two, then selects which configurations perform well, then continues tuning the best performers.", "The resulting MSE is 395.19 which is a lot worse when compared to random search but a little bit better than not tuning at all.", "Bayesian optimization is a probabilistic model that maps the hyperparameters to a probability score on the objective function. Unlike Random Search and Hyperband models, Bayesian Optimization keeps track of its past evaluation results and uses it to build the probability model.", "Best model MSE tuned using Bayesian optimization is 46.47, better than the first two tuners we have tried.", "We were able to show that indeed, tuning helps us get the most out of our models. Discussed here are just 3 of the many methods of hyperparameter tuning. When trying out the codes above, we may get slightly different results, for some reason, despite setting numpy, tensorflow, and keras tuner random seeds, results per iteration still differ slightly. The notebook is uploaded in my github repo.", "Furthermore, tuners can also be tuned! Yes, you read that right, tuning the tuners. Tuners accept values such as max_trials and execution per trial and are can, therefore, be tuned as well. Try changing these parameters and see if you get further improvements.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "NLP | Texthero.org | Data @ Lamudi https://www.linkedin.com/in/conolcedric"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F283474fbfbe&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----283474fbfbe--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----283474fbfbe--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@conolcedric?source=post_page-----283474fbfbe--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@conolcedric?source=post_page-----283474fbfbe--------------------------------", "anchor_text": "Cedric Conol"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F81f6802d94b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&user=Cedric+Conol&userId=81f6802d94b4&source=post_page-81f6802d94b4----283474fbfbe---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F283474fbfbe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F283474fbfbe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@willyin?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "yinka adeoti"}, {"url": "https://unsplash.com/s/photos/knobs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://keras-team.github.io/keras-tuner/", "anchor_text": "keras tuner"}, {"url": "https://keras.io/datasets/", "anchor_text": "list"}, {"url": "https://keras-team.github.io/keras-tuner/documentation/hyperparameters/", "anchor_text": "here"}, {"url": "https://keras-team.github.io/keras-tuner/documentation/tuners/", "anchor_text": "Tuners"}, {"url": "http://jmlr.org/papers/v18/16-558.html", "anchor_text": "Li et. al"}, {"url": "https://github.com/cedricconol/keras-tuner-demo", "anchor_text": "repo"}, {"url": "https://keras-team.github.io/keras-tuner/", "anchor_text": "https://keras-team.github.io/keras-tuner/"}, {"url": "https://arxiv.org/abs/1603.06560", "anchor_text": "https://arxiv.org/abs/1603.06560"}, {"url": "https://medium.com/tag/hyperparameter-tuning?source=post_page-----283474fbfbe---------------hyperparameter_tuning-----------------", "anchor_text": "Hyperparameter Tuning"}, {"url": "https://medium.com/tag/keras?source=post_page-----283474fbfbe---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----283474fbfbe---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----283474fbfbe---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----283474fbfbe---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F283474fbfbe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&user=Cedric+Conol&userId=81f6802d94b4&source=-----283474fbfbe---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F283474fbfbe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&user=Cedric+Conol&userId=81f6802d94b4&source=-----283474fbfbe---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F283474fbfbe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----283474fbfbe--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F283474fbfbe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----283474fbfbe---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----283474fbfbe--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----283474fbfbe--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----283474fbfbe--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----283474fbfbe--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----283474fbfbe--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----283474fbfbe--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----283474fbfbe--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----283474fbfbe--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@conolcedric?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@conolcedric?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Cedric Conol"}, {"url": "https://medium.com/@conolcedric/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "30 Followers"}, {"url": "http://Texthero.org", "anchor_text": "Texthero.org"}, {"url": "https://www.linkedin.com/in/conolcedric", "anchor_text": "https://www.linkedin.com/in/conolcedric"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F81f6802d94b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&user=Cedric+Conol&userId=81f6802d94b4&source=post_page-81f6802d94b4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4464285b81c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-with-keras-tuner-283474fbfbe&newsletterV3=81f6802d94b4&newsletterV3Id=4464285b81c6&user=Cedric+Conol&userId=81f6802d94b4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}