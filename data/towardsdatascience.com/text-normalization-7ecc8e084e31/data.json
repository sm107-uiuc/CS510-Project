{"url": "https://towardsdatascience.com/text-normalization-7ecc8e084e31", "time": 1683005317.623729, "path": "towardsdatascience.com/text-normalization-7ecc8e084e31/", "webpage": {"metadata": {"title": "Text Normalization. Why, what and how. | by Tiago Duque | Towards Data Science", "h1": "Text Normalization", "description": "In the last few articles we spent some time explaining and implementing some of the most important preprocessing techniques in NLP. However, we played too little with real text situations. Now it is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@tfduque/dissecting-natural-language-processing-layer-by-layer-an-introductory-overview-d11cfff4f329", "anchor_text": "last few articles", "paragraph_index": 0}, {"url": "https://medium.com/analytics-vidhya/tokenization-building-a-tokenizer-and-a-sentencizer-c19a00393c19", "anchor_text": "Tokenization", "paragraph_index": 1}, {"url": "https://medium.com/analytics-vidhya/building-a-stemmer-492e9a128e84", "anchor_text": "Sentencizing", "paragraph_index": 1}, {"url": "https://medium.com/analytics-vidhya/how-to-build-a-lemmatizer-7aeff7a1208c", "anchor_text": "Lemmatization", "paragraph_index": 1}, {"url": "https://gist.githubusercontent.com/Sirsirious/8be85ad68bc03feba15aa4c7c12311eb/raw/ae47f298d46deb7906a552a66ba77f75455d61ec/censored_data_corona.txt", "anchor_text": "here", "paragraph_index": 26}, {"url": "https://pypi.org/project/better-profanity/", "anchor_text": "better-profanity", "paragraph_index": 26}, {"url": "https://medium.com/analytics-vidhya/how-to-build-a-lemmatizer-7aeff7a1208c", "anchor_text": "lemmatization", "paragraph_index": 29}, {"url": "https://blog.bioturing.com/2018/05/22/how-to-compare-box-plots/", "anchor_text": "Boxplot", "paragraph_index": 42}, {"url": "https://tfduque.medium.com/how-to-turn-text-into-features-478b57632e99", "anchor_text": "how can we turn text into features for Machine Learning Algorithms", "paragraph_index": 47}], "all_paragraphs": ["In the last few articles we spent some time explaining and implementing some of the most important preprocessing techniques in NLP. However, we played too little with real text situations. Now it is the time to work a little with that.", "We talked about Text Normalization in the article about stemming. However, stemming is not the most important (and even used) task in Text Normalization. We also went on into some other Normalization techniques earlier, such as Tokenization, Sentencizing and Lemmatization. But there are other small tasks used to do this important preprocessing step that are going to be discussed in this article.", "Keep in mind that there is no \u201ccorrect\u201d set or list of normalization tasks that work for all situations. In fact, as we dive deeper in NLP, more and more we get to know that NLP is not as general as one may think. While there are many interesting general purpose toolboxes and premade pipelines, the more precise systems are the ones tailored to the context.", "Therefore, take the list of normalization steps presented in this article as not hard rules, but instead as guidelines for doing text Normalization. It is also important to point out that, in some rare cases, you might not want to normalize the input \u2014 these cases are those where more variation and wrongness is important or vital (consider a test correction algorithm, for example).", "Lets start of by defining clearly where we want to get with the use of normalization techniques. Natural language, as a human resource, tends to follow the inherent nature of its creator randomness. This means that, as we \u201cproduce\u201d natural language, we imprint our random states to it. Computers are not so good at dealing with randomness (although this is being minimized with the use of Machine Learning Algorithms).", "When we normalize a natural language resource, we attempt to reduce the randomness in it, bringing it closer to a predefined \u201cstandard\u201d. This helps into reducing the amount of different information that the computer has to deal, and therefore improves efficiency.", "When we normalize a natural language resource, we attempt to reduce the randomness in it", "In that article about Stemming, I mentioned that normalization attempts to bring things closer to the \u2018normal distribution\u2019. That\u2019s true in a sense where when we normalize a natural language input, we\u2019re looking to make things \u2018behave as expected\u2019, in a \u2018good\u2019 and \u2018predictable\u2019 shape, like the probabilities distributions that follow the Normal Distribution.", "Mathematics aside, we can discuss about the benefits of having normalized inputs into our NLP systems.", "First of all, by reducing the variations, we have less input variables to treat and deal with, improving overall performance and avoiding false negatives (imagine the case of a software log line that would trigger a warning if there wasn\u2019t a typo in it). This is very true for expert systems and for Information Retrieval tasks (imagine if Google\u2019s search engine only matched the exact words that you typed!).", "Second, especially when talking about machine learning algorithms, normalization reduces the dimensionality of the input, if we\u2019re using plain old structures like Bags of Words or TF-IDF dicts; or lowers the amount of processing needed for creating embeddings.", "Third, normalization helps to deal with code-breaking inputs before they are passed to our decision making NLP algorithm. In this case, we ensure that our inputs will follow a \u201ccontract\u201d before being treated.", "Finally, if done correctly, normalization is very important in granting reliable extraction of statistics from our natural language inputs \u2014 as in other areas (such as time series analysis), normalization is an important step into the hands of a NLP Data Scientist/Analyst/Engineer.", "That is an important question. When doing text normalization, we should know exactly what do we want to normalize and why. Also, the purpose of the input helps shaping the steps we\u2019re going to apply to normalize our input. There are two things that we are interested in normalizing the most:", "In practice, we can do normalization over these two aspects by breaking into simpler problems. Here\u2019s a list of the most common ones:", "\u2192 Removal of duplicate whitespaces and punctuation.", "\u2192 Accent removal (if your data includes diacritical marks from \u2018foreign\u2019 languages \u2014 this helps to reduce errors related to encoding type).", "\u2192 Capital letter removal (often, working with lowercase words deliver better results. In some cases, however, capital letters are very important to extract information, like names and locations).", "\u2192 Removal or substitution of special characters/emojis (e.g.: remove hashtags).", "\u2192 Normalize date formats, social security numbers or other data that have a standard format.", "\u2192 Spell correction (one could say that a word can be misspelled infinite ways, so spell corrections reduce the vocabulary variation by \u201ccorrecting\u201d) \u2014 this is very important if you\u2019re dealing with open user inputs, such as tweets, IMs and emails.", "\u2192 Removal of gender/time/grade variation with Stemming or Lemmatization.", "\u2192 Substitution of rare words for more common synonyms.", "\u2192 Stop word removal (more a dimensionality reduction technique than a normalization technique, but let us leave it here for the sake of mentioning it).", "For this article, I\u2019ll discuss the implementation of just a few of them.", "To choose which normalization steps we\u2019re going to use, we need a specific task. For this article, we\u2019ll suppose that we want to extract the sentiment of a set of 3000 tweets for the #COVIDIOTS hashtag, extracted during the end of March 2020, to know how people was behaving regarding to the pandemic of COVID-19 around the world.", "I went ahead and got these tweets, which can be downloaded here. I also went on to censor the text for curses using this nifty tool named better-profanity, which can be added to your normalization pipeline, if you want . They also do not contain the person who wrote the content.", "However, I did not went on with the effort of removing names or checking for any political position, fakes, etc, inside each tweet, since this is not the purpose of this article and could take another entire article on its own (about automated censoring).", "What I want to make clear is that I do not take responsibility for the content of the tweets, since they were consciously made publicly available by their authors on the moment the decided to post their words on the twitter. I just batch downloaded the tweets. That considered, let us continue (below is the link for a nice article that teaches how to mine tweets using python).", "For this case in particular, we want to apply the following steps: Removal of duplicate white space and punctuation; substitution of contractions; spell correction. Also, we\u2019ve already discussed lemmatization . So, we\u2019re using it.", "After we\u2019re through the code part, we\u2019ll analyse the results of applying the mentioned normalization steps statistically.", "One import thing about normalization is that the order of the functions matter. We could say that Normalization is a pipeline within the NLP preprocessing pipeline. If we\u2019re not careful, we can remove information that is important for future steps (such as removing stopwords before lemmatizing).", "We could even divide these steps into two consecutive groups: \u201cpre tokenization steps\u201d (for steps that modify sentence structure) and \u201cpost tokenization steps\u201d (for steps that only modify individual tokens), to avoid duplicating tokenization steps. However, for the sake of simplicity, we\u2019re using a simple .split() function.", "After we\u2019ve parsed our tweets into a list of strings, we can start creating the functions. Btw, I\u2019m using this nifty module called tqdm around the lists so we have nice progress bars once we apply the normalization process. Here are the needed imports:", "Finally, we join all steps in a \u201cpipeline\u201d function:", "So, you might be wondering: what are the results of applying these tasks? I\u2019ve run a few counting functions and plotted some charts to help in explaining, but I have to be clear about one thing: numbers are not the best way to express the importance of text normalization.", "Rather, Text normalization plays its role the best when applied to downstream NLP applications by improving efficiency, accuracy and other relevant scores. I\u2019ll point to some benefits that we can clearly see by statistics.", "First, we can clearly see a reduction in the total number of distinct tokens. In this specific case, we reduced the number of tokens by about 32%.", "Now, a bigger difference happens in the number of common tokens. These tokens are those which correspond to about 80% of all tokens. Usually, we have a range of about 10\u201320% of tokens that make the gross 80% of the text.", "By applying normalization, we reduced the number of most common tokens by 69%! That is a lot! This also means that any machine learning technique that we plug this data to will be able to generalize better.", "Now, one important thing about text normalization is that, for it to be useful, the normalized text has to retain default Natural Language structure. We can see that by the data distribution itself. One example is that, if done properly, sentences will not be much smaller or bigger after normalization.", "This is presented in the following histograms, that shows that, although we have less 1-sized sentences and more 2-sized sentences after normalization, the rest of the distribution follows the structure of the unnormalized data (also, note that our curve tends to be slightly closer to the Normal distribution curve).", "Another tool that help us to visualize this is the Boxplot. It shows how our data is distributed, including means, quartiles and outliers. In summary, we want our median line to be the same (or as close) as that of our unnormalized data. We also want that our box (the distribution of most of our data) remains in a similar place. If we are able to increase the size of the box, this means that we have more data cluttered around the median than before normalization (which is good). Also, we want to reduce outliers (those dots that are outside the range of our whiskers).", "If you want to learn how I achieved these results, while at the same time being able to access and run all the code I mentioned above, check the following Colab Notebook:", "In this article, I expect to have been able to explain what is Text Normalization, Why should we do it and How to do it. Also, I attempted to present some proof that it works (without presenting its benefits, yet).", "If you\u2019ve been following along with the series and is asking yourself about the set of tools that I\u2019m developing and if I added normalization to it, the answer is yes! I just didn\u2019t use it here to make it simpler to explain. But in short, I added functionalities that allow (most) of the mentioned normalization steps to be applied directly to our Document or Sentence structures (and use our tokenization tools that we developed earlier).", "You can see where I\u2019m at by looking at the state of the following commit:", "Now that we have many tools, we have to start applying them. But before, how can we turn text into features for Machine Learning Algorithms? This is the topic of the next article!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A Data Scientist passionate about data and text. Trying to understand and clearly explain all important nuances of Natural Language Processing."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7ecc8e084e31&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tfduque.medium.com/?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": ""}, {"url": "https://tfduque.medium.com/?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "Tiago Duque"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff6698b3e89e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&user=Tiago+Duque&userId=f6698b3e89e3&source=post_page-f6698b3e89e3----7ecc8e084e31---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ecc8e084e31&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ecc8e084e31&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/cxoR55-bels", "anchor_text": "Markus Winkler from Unsplash"}, {"url": "https://medium.com/@tfduque/dissecting-natural-language-processing-layer-by-layer-an-introductory-overview-d11cfff4f329", "anchor_text": "last few articles"}, {"url": "https://medium.com/analytics-vidhya/tokenization-building-a-tokenizer-and-a-sentencizer-c19a00393c19", "anchor_text": "Tokenization"}, {"url": "https://medium.com/analytics-vidhya/building-a-stemmer-492e9a128e84", "anchor_text": "Sentencizing"}, {"url": "https://medium.com/analytics-vidhya/how-to-build-a-lemmatizer-7aeff7a1208c", "anchor_text": "Lemmatization"}, {"url": "https://pt.wikipedia.org/wiki/Distribui%C3%A7%C3%A3o_normal#/media/Ficheiro:Normal_Distribution_PDF.svg", "anchor_text": "Wikipedia"}, {"url": "https://www.aoc.gov/explore-capitol-campus/blog/two-thumbs-taking-edge", "anchor_text": "Architect of the Capitol"}, {"url": "https://gist.githubusercontent.com/Sirsirious/8be85ad68bc03feba15aa4c7c12311eb/raw/ae47f298d46deb7906a552a66ba77f75455d61ec/censored_data_corona.txt", "anchor_text": "here"}, {"url": "https://pypi.org/project/better-profanity/", "anchor_text": "better-profanity"}, {"url": "https://www.earthdatascience.org/courses/earth-analytics-python/using-apis-natural-language-processing-twitter/get-and-use-twitter-data-in-python/", "anchor_text": "Get and Work With Twitter Data in Python Using TweepyAfter completing this tutorial, you will be able to: Connect to the twitter RESTful API to access twitter data with\u2026www.earthdatascience.org"}, {"url": "https://medium.com/analytics-vidhya/how-to-build-a-lemmatizer-7aeff7a1208c", "anchor_text": "lemmatization"}, {"url": "https://br.pinterest.com/pin/456833955944489156/", "anchor_text": "Pattama Pon"}, {"url": "https://gist.githubusercontent.com/Sirsirious/c70400176a4532899a483e06d72cf99e/raw/e46fa7620c4f378f5bf39608b45cddad7ff447a4/english_contractions.json", "anchor_text": "here"}, {"url": "https://pypi.org/project/symspellpy/", "anchor_text": "symspellpy"}, {"url": "https://medium.com/@thomasdecaux/build-a-spell-checker-with-word2vec-data-with-python-5438a9343afd", "anchor_text": "train a deep learning model to spell correction based on context"}, {"url": "https://blog.bioturing.com/2018/05/22/how-to-compare-box-plots/", "anchor_text": "Boxplot"}, {"url": "https://colab.research.google.com/drive/1U_C_4wAtlWQdaA84yVwHUCdkvQWEd7r9", "anchor_text": "Google ColaboratoryNLP Series \u2014 Text Normalizationcolab.research.google.com"}, {"url": "https://github.com/Sirsirious/NLPTools/tree/1c2e3efd740f1ede57d316d8f4edf18cce295103", "anchor_text": "Sirsirious/NLPToolsA set of NLP tools created during my medium NLP Explanation series. - Sirsirious/NLPToolsgithub.com"}, {"url": "https://tfduque.medium.com/how-to-turn-text-into-features-478b57632e99", "anchor_text": "how can we turn text into features for Machine Learning Algorithms"}, {"url": "http://mlwiki.org/index.php/Text_Normalization", "anchor_text": "Text NormalizationIt's a part of NLP Pipeline for preprocessing text data normalization = applying some linguistic models to tokens of\u2026mlwiki.org"}, {"url": "https://www.aclweb.org/anthology/W18-3902/", "anchor_text": "Encoder-Decoder Methods for Text NormalizationAbstract Text normalization is the task of mapping non-canonical language, typical of speech transcription and\u2026www.aclweb.org"}, {"url": "https://medium.com/tag/nlp?source=post_page-----7ecc8e084e31---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7ecc8e084e31---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/normalization?source=post_page-----7ecc8e084e31---------------normalization-----------------", "anchor_text": "Normalization"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----7ecc8e084e31---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/statistics?source=post_page-----7ecc8e084e31---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7ecc8e084e31&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&user=Tiago+Duque&userId=f6698b3e89e3&source=-----7ecc8e084e31---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7ecc8e084e31&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&user=Tiago+Duque&userId=f6698b3e89e3&source=-----7ecc8e084e31---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ecc8e084e31&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7ecc8e084e31&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7ecc8e084e31---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7ecc8e084e31--------------------------------", "anchor_text": ""}, {"url": "https://tfduque.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tfduque.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tiago Duque"}, {"url": "https://tfduque.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "225 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff6698b3e89e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&user=Tiago+Duque&userId=f6698b3e89e3&source=post_page-f6698b3e89e3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbb155ace8381&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-normalization-7ecc8e084e31&newsletterV3=f6698b3e89e3&newsletterV3Id=bb155ace8381&user=Tiago+Duque&userId=f6698b3e89e3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}