{"url": "https://towardsdatascience.com/how-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac", "time": 1683006634.65612, "path": "towardsdatascience.com/how-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac/", "webpage": {"metadata": {"title": "Building domain specific dataset or corpora from Wikipedia for ML | Towards Data Science", "h1": "How to Build your own Domain-Focused Datasets or Corpora from Wikipedia", "description": "Wikipedia is a great platform for creating rich datasets or corpora because it has natural language content as well as semantically structured database called the DBpedia."}, "outgoing_paragraph_urls": [{"url": "https://www.wikipedia.org/", "anchor_text": "Wikipedia", "paragraph_index": 0}, {"url": "https://wiki.dbpedia.org/", "anchor_text": "DBpedia", "paragraph_index": 1}, {"url": "https://pypi.org/project/beautifulsoup4/", "anchor_text": "Beautiful Soup", "paragraph_index": 4}, {"url": "https://pypi.org/project/wikipedia/", "anchor_text": "pypi link", "paragraph_index": 4}, {"url": "https://github.com/royn5618/Corpus_Builder_Wikipedia", "anchor_text": "Link to GitHub Repository", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/N-Triples", "anchor_text": "N-Triples format", "paragraph_index": 10}, {"url": "https://www.w3.org/RDF/", "anchor_text": "RDF graph", "paragraph_index": 10}, {"url": "https://www.w3.org/TR/rdf-sparql-query/", "anchor_text": "SPARQL", "paragraph_index": 14}, {"url": "https://dbpedia.org/sparql", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://pypi.org/project/SPARQLWrapper/", "anchor_text": "SPARQLWrapper", "paragraph_index": 18}, {"url": "https://dbpedia.org/sparql", "anchor_text": "https://dbpedia.org/sparql", "paragraph_index": 18}, {"url": "https://github.com/royn5618/DBPedia-Data-Scraping-using-Python", "anchor_text": "Link to GitHub Repository", "paragraph_index": 20}], "all_paragraphs": ["Wikipedia is the 21st century\u2019s most-trusted and crowd-sourced digital wealth of information which we refer to for answers to questions, in case of any doubt, to know the plot of web series, to find biodata of the casts of a movie, to know more about the great leaders of the world or the disasters that shook the earth, to learn about the past and what the future holds for us.", "Wikipedia is a great platform for creating rich datasets or corpora because it has natural language content as well as semantically structured database called the DBpedia.", "This blog discusses two simple, fast and light-weight approaches to curate domain-specific datasets or build coropra from Wikipedia for training machine learning models.", "So, let us take a look at how this wealth of knowledge can be your next project\u2019s input data.", "This is what you must already be familiar with \u2014 web scraping. Alongside Beautiful Soup, Wikipedia has its own scraping library now (pypi link).", "Below is a simple program that uses wikipedia, the python library, to scrape contents.", "The limitation of this approach is that tables are not scraped what-so-ever.", "The following is an example code which extracts tables from wikipedia page using MediaWikiAPI and Beautifulsoup:", "I have have created a composite code to scrape Wikipedia pages using Wikipedia, MediaWikiAPI and Beautiful Soup. This code scrapes pages that is retrieved as response of the search term, which is basically the topic or domain you are interested. To go a level deeper, this code also gets the related links from all the search response pages and scrapes their contents as well.", "Link to GitHub Repository for scraping Wikipedia content using Wikipedia.", "DBpedia is created by extracting entities and their relations from the Wikipedia Project and stored in N-Triples format. In other words, DBpedia is an RDF graph database. The specialty of these databases is that they store data along with retaining the embedded semantic relationship.", "For example: \u201cMy name is Nabanita and I am from India. I reside in Ireland.\u201d", "An N-triples database would treat this information about you as:", "In general terms, this format is also known as:", "SPARQL is the RDF database query language. The syntax is quite different from other traditional query languages but the objectives are fairly similar and hence, quite readable.", "Objective: To get details of athletes on wikipedia like \u2014 birth date, name and country. Also, I want the names to be in English. Additionally, country is an optional variable, i.e. I want the athlete\u2019s information even if \u201ccountry\u201d is empty. Birth date and name are mandatory.", "All prefixes are the standard definitions or RDF vocabulary already in place. Treat them as imports. In the main query, we select distinct athletes (?a) which is the subject; the date of birth (?dob), name (?name) and country (?c) which are the objects. Inside \u201cWHERE\u201d, the first line indicates that \u2014 select the subject which is a type (represented by a or rdfs:type) dbo:Athelete. rdfs:type or a and dbo:athlete are predefined vocabularies. The \u2018;\u2019 is use to keep using the selected subject, i.e. \u2018?a\u2019. Further, we select the dbo:birthDate (predefined vocabulary) and the value/object will be retrieved as \u201c?dob\u201d and the same for foaf:name ?name. In \u201cOPTIONAL\u201d, we select the country of the same subject (?a) using vocabulary dbo:country as the predicate but we say that it is optional. In other words, retrieve the result even though dbo:county does not have an associated value . The last line \u201cFILTER\u201d, filters the language based on the variable \u201c?name\u201d and specifies that it should be in English. If language is not specified, then SPARQL would retrieve objects of different languages. So, unless that is desired to address a specific objective, we will have duplicate data which is unrequired.", "The output looks somewhat like this image (when limited to 2). You can try and execute your own SPARQL queries here . A great advantage of using SPARQL is that you can choose a variety of response types including HTML, JSON and csv file formats.", "Python has a wrapper around the SPARQL service called SPARQLWrapper. This can be used to query through the SPARQL endpoint at https://dbpedia.org/sparql and retrieve results. In this case, I have retrieved a json object and normalized to a pandas dataframe.", "To scrape all athlete\u2019s data from Wikipedia, I had created a repository which executes a slightly enhanced version of this example query.", "Link to GitHub Repository for querying DBpedia using SPARQLWrapper.", "To conclude, these are the two ways in which we can scrape or query wikipedia contents and create", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist @ EY (UK & Ireland) | Education Lead @ Women in AI Ireland | \u2764 NLP"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3eb35d78baac&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nroy0110.medium.com/?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": ""}, {"url": "https://nroy0110.medium.com/?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "Nabanita Roy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd36a8b28c928&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&user=Nabanita+Roy&userId=d36a8b28c928&source=post_page-d36a8b28c928----3eb35d78baac---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3eb35d78baac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3eb35d78baac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@fragilejames?utm_source=medium&utm_medium=referral", "anchor_text": "James L.W"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.wikipedia.org/", "anchor_text": "Wikipedia"}, {"url": "https://wiki.dbpedia.org/", "anchor_text": "DBpedia"}, {"url": "https://pypi.org/project/beautifulsoup4/", "anchor_text": "Beautiful Soup"}, {"url": "https://pypi.org/project/wikipedia/", "anchor_text": "pypi link"}, {"url": "https://pypi.org/project/beautifulsoup4/", "anchor_text": "Beautifulsoup"}, {"url": "https://pypi.org/project/mediawikiapi/", "anchor_text": "MediaWikiAPI"}, {"url": "https://github.com/royn5618/Corpus_Builder_Wikipedia", "anchor_text": "Link to GitHub Repository"}, {"url": "https://en.wikipedia.org/wiki/N-Triples", "anchor_text": "N-Triples format"}, {"url": "https://www.w3.org/RDF/", "anchor_text": "RDF graph"}, {"url": "https://www.w3.org/TR/rdf-sparql-query/", "anchor_text": "SPARQL"}, {"url": "https://dbpedia.org/sparql", "anchor_text": "here"}, {"url": "https://pypi.org/project/SPARQLWrapper/", "anchor_text": "SPARQLWrapper"}, {"url": "https://dbpedia.org/sparql", "anchor_text": "https://dbpedia.org/sparql"}, {"url": "https://github.com/royn5618/DBPedia-Data-Scraping-using-Python", "anchor_text": "Link to GitHub Repository"}, {"url": "https://www.cambridgesemantics.com/blog/semantic-university/learn-rdf/", "anchor_text": "Learn RDFIntroduction This set of lessons is an introduction to RDF, the core data model of the Semantic Web and the foundation\u2026www.cambridgesemantics.com"}, {"url": "https://www.ontotext.com/knowledgehub/fundamentals/what-is-rdf/", "anchor_text": "What is RDF? Making Data Triple Their PowerRDF stands for Resource Description Framework and is a standard for data interchange, developed and agreed upon by W3C\u2026www.ontotext.com"}, {"url": "https://medium.com/tag/python?source=post_page-----3eb35d78baac---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/wikipedia?source=post_page-----3eb35d78baac---------------wikipedia-----------------", "anchor_text": "Wikipedia"}, {"url": "https://medium.com/tag/dbpedia?source=post_page-----3eb35d78baac---------------dbpedia-----------------", "anchor_text": "Dbpedia"}, {"url": "https://medium.com/tag/sparql?source=post_page-----3eb35d78baac---------------sparql-----------------", "anchor_text": "Sparql"}, {"url": "https://medium.com/tag/corpora?source=post_page-----3eb35d78baac---------------corpora-----------------", "anchor_text": "Corpora"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3eb35d78baac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&user=Nabanita+Roy&userId=d36a8b28c928&source=-----3eb35d78baac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3eb35d78baac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&user=Nabanita+Roy&userId=d36a8b28c928&source=-----3eb35d78baac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3eb35d78baac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3eb35d78baac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3eb35d78baac---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3eb35d78baac--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3eb35d78baac--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3eb35d78baac--------------------------------", "anchor_text": ""}, {"url": "https://nroy0110.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nroy0110.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nabanita Roy"}, {"url": "https://nroy0110.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "222 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd36a8b28c928&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&user=Nabanita+Roy&userId=d36a8b28c928&source=post_page-d36a8b28c928--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa0eba44b2636&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-your-own-datasets-or-corpora-from-wikipedia-3eb35d78baac&newsletterV3=d36a8b28c928&newsletterV3Id=a0eba44b2636&user=Nabanita+Roy&userId=d36a8b28c928&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}