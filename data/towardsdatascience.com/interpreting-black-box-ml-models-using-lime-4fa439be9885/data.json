{"url": "https://towardsdatascience.com/interpreting-black-box-ml-models-using-lime-4fa439be9885", "time": 1683015269.5485802, "path": "towardsdatascience.com/interpreting-black-box-ml-models-using-lime-4fa439be9885/", "webpage": {"metadata": {"title": "Interpreting Black-Box ML Models using LIME | by Travis Tang | Towards Data Science", "h1": "Interpreting Black-Box ML Models using LIME", "description": "It is almost trite at this point for anyone to espouse the potential of machine learning in the medical field. There are a plethora of examples to support this claim \u2014 one would be Microsoft\u2019s use of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.microsoft.com/en-us/research/project/medical-image-analysis/", "anchor_text": "make an accurate cancer diagnosis", "paragraph_index": 0}, {"url": "https://builders.intel.com/docs/aibuilders/using-ai-in-medical-imaging-to-improve-accuracy-and-efficiency.pdf", "anchor_text": "AI algorithms has drastically improved the accuracy of such diagnoses.", "paragraph_index": 0}, {"url": "https://www.getfilecloud.com/blog/2018/06/top-5-limitations-of-machine-learning-in-an-enterprise-setting/#.X4LV64tS9EY", "anchor_text": "difficult, if not impossible, to interpret.", "paragraph_index": 1}, {"url": "https://bdtechtalks.com/2020/07/27/black-box-ai-models/", "anchor_text": "deep neural network", "paragraph_index": 1}, {"url": "https://insightsimaging.springeropen.com/articles/10.1186/s13244-019-0798-3", "anchor_text": "only 55.4% of the clinicians", "paragraph_index": 2}, {"url": "https://christophm.github.io/interpretable-ml-book/agnostic.html", "anchor_text": "many solutions out there", "paragraph_index": 5}, {"url": "https://arxiv.org/pdf/1602.04938.pdf", "anchor_text": "paper by Ribeiro et al [2]", "paragraph_index": 6}, {"url": "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)", "anchor_text": "Wisconsin Breast Cancer Data Set", "paragraph_index": 14}, {"url": "https://github.com/marcotcr/lime/blob/master/CONTRIBUTING.md", "anchor_text": "too slow to be useful", "paragraph_index": 29}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME\u2019s Github page", "paragraph_index": 29}, {"url": "https://towardsdatascience.com/what-makes-a-wine-good-ea370601a8e4", "anchor_text": "Partial Dependence Plot to explain a black-box model.", "paragraph_index": 30}, {"url": "https://doi.org/10.1186/s13244-019-0798-3", "anchor_text": "Impact of artificial intelligence on radiology: a EuroAIM survey among members of the European Society of Radiology", "paragraph_index": 32}, {"url": "http://dx.doi.org/10.1145/2939672.2939778", "anchor_text": "\u2018Why Should I Trust You?\u2019 Explining the Predictions of Any Clasifier", "paragraph_index": 33}, {"url": "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)", "anchor_text": "Wisconsin Breast Cancer Database", "paragraph_index": 34}, {"url": "http://linkedin.com/in/travistang", "anchor_text": "linkedin.com/in/travistang", "paragraph_index": 36}], "all_paragraphs": ["It is almost trite at this point for anyone to espouse the potential of machine learning in the medical field. There are a plethora of examples to support this claim \u2014 one would be Microsoft\u2019s use of medical imaging data in helping clinicians and radiologists make an accurate cancer diagnosis. Simultaneously, the development of sophisticated AI algorithms has drastically improved the accuracy of such diagnoses. Undoubtedly, such amazing applications of medical data and one has all the good reasons to be excited about its benefits.", "However, such cutting-edge algorithms are black boxes that might be difficult, if not impossible, to interpret. One example of a black-box model is the deep neural network, where a single decision is made after the input data passes through millions of neurons in the network. Such black-box models do not allow clinicians to verify the models\u2019 diagnosis with their prior knowledge and experiences, making the model-based diagnosis less trustworthy.", "In fact, a recent survey of radiologists in Europe paints a realistic picture of the use of black-box models in radiology. The survey shows that only 55.4% of the clinicians think that patients will not accept purely AI-based application without the supervision of a physician. [1]", "The next question is this: if AI cannot fully replace the role of physicians, then how can AI help physicians in providing an accurate diagnosis?", "That prompted me to explore existing solutions that help explain machine learning models. In general, machine learning models can be divided into models that are explainable and models that are not. To put it loosely, models that are explainable provide outputs that correlate with the importance of each input feature. Examples of such models include linear regression, logistic regression, decision trees and decision rules, among others. On the other hand, neural networks form the bulk of models that are not explainable.", "There are many solutions out there that can help with providing an explanation for black-box models. Such solutions include the Shapley values, the Partial Dependence Plot and the Local Interpretable Model Agnostic Explanations (LIME) which are popular among machine learning practitioners. Today, I will be focusing on LIME.", "According to the LIME paper by Ribeiro et al [2], the goal of LIME is to \u2018identify an interpretable model over the interpretable representation that is locally faithful to the classifier\u2019. In other words, LIME is able to explain the classification result of one particular point. LIME also works for all kinds of models, making it model-agnostic.", "That sounds like a lot to understand. Let\u2019s break it down step-by-step. Imagine we have the following toy data set with two features. Each data point is associated with a ground truth label (positive or negative).", "As can be seen from the data points, a linear classifier will not be able to identify the boundaries that separate the positive and negative labels. Thus, we can train a non-linear model, say a neural network, to classify these points. If the model is well-trained, it is able to predict that a new data point that falls in the dark grey area to be positive, while another new data point that falls in the light grey area to be negative.", "Now, we are curious about the decision made by the model on a particular data point (coloured purple). We ask ourselves, why is this particular point predicted to be negative by the neural network?", "We can use LIME to answer that question. LIME first identifies random points from the original data set and assigns weights to each data point according to their distances to the purple point of interest. The nearer the sampled data point is to the point of interest, the more important it is to LIME. (In the picture, a larger dot indicates a heavier weight assigned to the data point.)", "Using these points of different weights, LIME presents an explanation that has the highest interpretability and local fidelity.", "Using this set of criteria, LIME identifies the purple line as the learned explanation for the point of interest. We see that the purple line is able to explain the neural network\u2019s decision boundary close to the data point of interest, but is unable to explain its decision boundary farther away. In other words, the learned explanation has high local fidelity but low global fidelity.", "Let\u2019s see LIME in action: now, I will focus on the use of LIME in explaining a machine learning model trained using the Wisconsin breast cancer data.", "The Wisconsin Breast Cancer Data Set [3], published by UCI in 1992, contains 699 data points. Each data point representing a cell sample which can either be malignant or benign. Each sample is also given a number 1 to 10 for the following characteristics.", "Let\u2019s attempt to understand the meaning of these features. The following illustrations show the difference between benign and malignant cells, using features of the data set.", "From this illustration, we see that the higher the value of each feature, the more likely it is for the cell to be malignant.", "Now that we understand what the data means, let\u2019s get to coding! We first read the data, and clean the data by removing incomplete data points and reformatting the class column.", "After removing the incomplete data, we briefly explore the data. By plotting the distribution of the class of the cell sample (malignant or benign), we find that we have more cell samples which are benign (class 0) than benign (class 1).", "By visualizing the histograms of each of the features, we find that most features have a mode of 1 or 2, except ClumpThickness and BlandChromatin whose distributions are more evenly spread out from 1 to 10. This indicates that ClumpThickness and BlandChromatin might be weaker predictors of the class.", "Then, the data set is split into typical train-validation-test sets in a ratio of 80%-10%-10%, and a K-Nearest Neighbour model is built using Sklearn. After some hyperparameter tuning (not shown), a model with k=10 is found to perform well in the evaluation stage \u2014 it has an F1-score of 0.9655. The code block is shown below.", "A Kaggle connoisseur might say that this result is great and that we can conclude the project here. However, one should be skeptical about the model\u2019s decisions, even if the model performs well in evaluation. Thus, we use LIME to explain the decision made by the KNN model on this data set. This verifies the validity of the model by checking if the decisions made fit our intuition.", "Here, I have picked 3 points to illustrate how LIME can be used.", "Here, we have a data point that is actually malignant and is predicted to be malignant. On the left panel, we see that the KNN model has predicted this point to have close to 100% probability to be malignant. In the middle, we observe that LIME is able to explain this prediction using each feature of the data point of interest, in order of importance. According to LIME,", "Overall, considering all the features of the sample (on the right panel), the sample is predicted to be malignant.", "These four observations fit our intuition and our knowledge of cancer cells. Knowing this, we are more confident that the model is making predictions correctly as per our intuition. Let\u2019s look at another sample.", "Here, we have a cell sample that is predicted to be benign and is actually benign. LIME explains why this is the case by citing (among other reasons)", "Again, these fit our intuition of why the cell is benign.", "In the final example, we see that the model is unable to make a prediction of whether the cell is benign or malignant with high confidence. Can you see why this is the case using LIME\u2019s explanation?", "LIME\u2019s usefulness extends beyond tabular data to text and images, making it incredibly versatile. However, there is still work to be done. For instance, the author of the paper contends that the current algorithm, when applied to images, is too slow to be useful. Nevertheless, LIME is still incredibly useful in bridging the gap between the usefulness and the intractability of black-box models. If you\u2019d like to start using LIME, a great starting point would be LIME\u2019s Github page.", "If you are interested about Machine Learning Interpretability, be sure to check my article that focuses on using Partial Dependence Plot to explain a black-box model.", "Feel free to reach out to me by LinkedIn for any feedback. Thank you for your time!", "[1] Codari, M., Melazzini, L., Morozov, S.P. et al., Impact of artificial intelligence on radiology: a EuroAIM survey among members of the European Society of Radiology (2019), Insights into Imaging", "[2] M. Ribeiro, S. Singh and C. Guestrin, \u2018Why Should I Trust You?\u2019 Explining the Predictions of Any Clasifier (2016), KDD", "[3] Dr. William H. Wolberg, Wisconsin Breast Cancer Database (1991), University of Wisconsin Hospitals, Madison", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Self-taught data scientist | 20k+ followers on LinkedIn linkedin.com/in/travistang"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4fa439be9885&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa439be9885--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa439be9885--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://travis-tang.medium.com/?source=post_page-----4fa439be9885--------------------------------", "anchor_text": ""}, {"url": "https://travis-tang.medium.com/?source=post_page-----4fa439be9885--------------------------------", "anchor_text": "Travis Tang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F169b6a57c01e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&user=Travis+Tang&userId=169b6a57c01e&source=post_page-169b6a57c01e----4fa439be9885---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fa439be9885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fa439be9885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/Model-Interpretability", "anchor_text": "Model Interpretability"}, {"url": "https://unsplash.com/@nci?utm_source=medium&utm_medium=referral", "anchor_text": "National Cancer Institute"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.microsoft.com/en-us/research/project/medical-image-analysis/", "anchor_text": "make an accurate cancer diagnosis"}, {"url": "https://builders.intel.com/docs/aibuilders/using-ai-in-medical-imaging-to-improve-accuracy-and-efficiency.pdf", "anchor_text": "AI algorithms has drastically improved the accuracy of such diagnoses."}, {"url": "https://www.getfilecloud.com/blog/2018/06/top-5-limitations-of-machine-learning-in-an-enterprise-setting/#.X4LV64tS9EY", "anchor_text": "difficult, if not impossible, to interpret."}, {"url": "https://bdtechtalks.com/2020/07/27/black-box-ai-models/", "anchor_text": "deep neural network"}, {"url": "https://insightsimaging.springeropen.com/articles/10.1186/s13244-019-0798-3", "anchor_text": "only 55.4% of the clinicians"}, {"url": "https://christophm.github.io/interpretable-ml-book/agnostic.html", "anchor_text": "many solutions out there"}, {"url": "https://arxiv.org/pdf/1602.04938.pdf", "anchor_text": "paper by Ribeiro et al [2]"}, {"url": "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)", "anchor_text": "Wisconsin Breast Cancer Data Set"}, {"url": "https://github.com/marcotcr/lime/blob/master/CONTRIBUTING.md", "anchor_text": "too slow to be useful"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME\u2019s Github page"}, {"url": "https://towardsdatascience.com/what-makes-a-wine-good-ea370601a8e4", "anchor_text": "Partial Dependence Plot to explain a black-box model."}, {"url": "https://www.linkedin.com/in/voon-hao-tang/", "anchor_text": "Travis Tang | LinkedInData Analyst at Gojek"}, {"url": "https://doi.org/10.1186/s13244-019-0798-3", "anchor_text": "Impact of artificial intelligence on radiology: a EuroAIM survey among members of the European Society of Radiology"}, {"url": "http://dx.doi.org/10.1145/2939672.2939778", "anchor_text": "\u2018Why Should I Trust You?\u2019 Explining the Predictions of Any Clasifier"}, {"url": "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)", "anchor_text": "Wisconsin Breast Cancer Database"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4fa439be9885---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4fa439be9885---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/interpretability?source=post_page-----4fa439be9885---------------interpretability-----------------", "anchor_text": "Interpretability"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----4fa439be9885---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/model-interpretability?source=post_page-----4fa439be9885---------------model_interpretability-----------------", "anchor_text": "Model Interpretability"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4fa439be9885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&user=Travis+Tang&userId=169b6a57c01e&source=-----4fa439be9885---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4fa439be9885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&user=Travis+Tang&userId=169b6a57c01e&source=-----4fa439be9885---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fa439be9885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa439be9885--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4fa439be9885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4fa439be9885---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa439be9885--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4fa439be9885--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4fa439be9885--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4fa439be9885--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4fa439be9885--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4fa439be9885--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4fa439be9885--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4fa439be9885--------------------------------", "anchor_text": ""}, {"url": "https://travis-tang.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://travis-tang.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Travis Tang"}, {"url": "https://travis-tang.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "http://linkedin.com/in/travistang", "anchor_text": "linkedin.com/in/travistang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F169b6a57c01e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&user=Travis+Tang&userId=169b6a57c01e&source=post_page-169b6a57c01e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F71f383dd749b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-black-box-ml-models-using-lime-4fa439be9885&newsletterV3=169b6a57c01e&newsletterV3Id=71f383dd749b&user=Travis+Tang&userId=169b6a57c01e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}