{"url": "https://towardsdatascience.com/how-to-synchronize-elasticsearch-with-mysql-ed32fc57b339", "time": 1683016346.2134871, "path": "towardsdatascience.com/how-to-synchronize-elasticsearch-with-mysql-ed32fc57b339/", "webpage": {"metadata": {"title": "How to synchronize Elasticsearch with MySQL | by Redouane Achouri | Towards Data Science", "h1": "How to synchronize Elasticsearch with MySQL", "description": "Using Logstash to create a data pipe linking Elasticsearch to MySQL in order to build an index from scratch and to replicate any changes occurring on the database records into Elasticsearch"}, "outgoing_paragraph_urls": [{"url": "https://lucene.apache.org/core/", "anchor_text": "Lucene search engine", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Inverted_index", "anchor_text": "inverted document index", "paragraph_index": 3}, {"url": "https://www.elastic.co/what-is/elk-stack", "anchor_text": "ELK stack", "paragraph_index": 5}, {"url": "https://www.goodreads.com/", "anchor_text": "Goodreads", "paragraph_index": 9}, {"url": "https://www.kaggle.com/jealousleopard/goodreadsbooks", "anchor_text": "found on Kaggle", "paragraph_index": 9}, {"url": "https://docs.docker.com/compose/", "anchor_text": "docker-compose", "paragraph_index": 11}, {"url": "https://github.com/redouane-dev/sync-elasticsearch-mysql", "anchor_text": "sync-elasticsearch-mysql", "paragraph_index": 12}, {"url": "https://github.com/redouane-dev/sync-elasticsearch-mysql/tree/main/data", "anchor_text": "project repository", "paragraph_index": 14}, {"url": "https://dev.mysql.com/downloads/connector/j/", "anchor_text": "this address", "paragraph_index": 25}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-action", "anchor_text": "see docs", "paragraph_index": 37}, {"url": "https://en.wikipedia.org/wiki/International_Standard_Book_Number", "anchor_text": "ISBN is an internationally unique ID for books", "paragraph_index": 37}, {"url": "https://docs.docker.com/compose/compose-file/#volumes", "anchor_text": "official Docker Compose documentation", "paragraph_index": 42}, {"url": "http://localhost:5601/app/monitoring#/elasticsearch/indices", "anchor_text": "this link for example", "paragraph_index": 45}, {"url": "https://github.com/jmettraux/rufus-scheduler", "anchor_text": "Rufus Scheduler", "paragraph_index": 53}, {"url": "https://crontab.guru/", "anchor_text": "crontab.guru", "paragraph_index": 54}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html#plugins-inputs-jdbc-last_run_metadata_path", "anchor_text": "documentation here", "paragraph_index": 55}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-action", "anchor_text": "use the \u201cupsert\u201d action", "paragraph_index": 56}, {"url": "http://www.redouaneachouri.com", "anchor_text": "www.redouaneachouri.com", "paragraph_index": 69}], "all_paragraphs": ["A common scenario for tech companies is to start building their core business functionalities around one or more databases, and then start connecting services to those databases to perform searches on text data, such as searching for a street name in the user addresses column of a users table, or searching for book titles and author names in the catalog of a library.", "So far everything is fine. The company keeps growing and acquires more and more customers. But then searches start to become slower and slower, which tends to irritate their customers and makes it hard to convince new prospects to buy in.", "Looking under the hood, the engineers realize that MySQL\u2019s FULLTEXT indexes are not ideal for text look-ups on large datasets, and in order to scale up their operations, the engineers decide to move on to a more dedicated and battle-tested text search engine.", "Enters Elasticsearch and its underlying Lucene search engine. Elasticsearch indexes data using an inverted document index, and this results in a blazing-fast full-text search.", "A new challenge then comes in: How to get the data that is in a MySQL database into an Elasticsearch index, and how to keep the latter synchronized with the former?", "The modern data plumber\u2019s toolkit contains a plethora of software for any data manipulation task. In this article, we\u2019ll focus on Logstash from the ELK stack in order to periodically fetch data from MySQL, and mirror it on Elasticsearch. This will take into consideration any changes on the MySQL data records, such as create , update , and delete , and have the same replicated on Elasticsearch documents.", "The problem we are trying to solve here \u2014 sending data periodically from MySQL to Elasticsearch for syncing the two \u2014 can be solved with a Shell or Python script ran by a cron job or any job scheduler, BUT this would deprive us from the benefits otherwise acquired by configuring Logstash and its plugin-based setup:", "We will cover two scenarios in the following steps:", "Imagine you are opening an online library where avid readers can search your catalog of books to find their next reading. Your catalog contains millions of titles, ranging from scientific literature volumes to pamphlets about exotic adventures.", "We will create an initial database table books with a few thousands of records with book titles, authors, ISBN and publication date. We\u2019ll use the Goodreads book catalog that can be found on Kaggle. This initial table will serve prototyping the use case (1) Building an index from scratch.", "We will create triggers on the table books that will populate a journal table books_journal with all changes on the books table (e.g. create , update , delete ). This means that whenever a record on the books table is created, updated, or deleted, this action will be recorded on the books_journal table, and the same action will be done on the corresponding Elasticsearch document. This will serve prototyping the use case (2) Incremental update of the Elasticsearch index.", "We\u2019ll prototype and test the above concepts by defining a micro-services architecture using docker-compose.", "Full source code can be found on GitHub at sync-elasticsearch-mysql.", "2. Setup a MySQL database: Create a directory data/ where we\u2019ll store MySQL dump files with the pre-cleaned books data for the books table, as well as the triggers for the books table (on create, update, and delete), and a new_arrivals table with books we will add to our catalog to simulate new records, and the table books_journal .", "You can find these dump files in the project repository. Please copy them to the data/ directory so that the MySQL container will add them to the books database during the startup process.", "Note that storing usernames and passwords in plain text in your source code is not advised. The above is done for the sake of prototyping this project only and is not in any case a recommended practice.", "To start MySQL and check that data has been added successfully, from you project\u2019s directory run on a terminal:", "To show the triggers with a JSON-like formatting, use command:", "Now that we have our database properly set up, we can move on to the meat and potatoes of this project.", "3. Setup Elasticsearch and Kibana: To setup Elasticsearch (without indexing any document yet), add this to your docker-compose.yaml file:", "Note that the volumes definition is recommended in order to mount the Elasticsearch index data from the docker volume to your directory file system.", "To get Elasticsearch and Kibana started, run the following from your project directory:", "Let\u2019s check if there is any index in our Elasticsearch node so far:", "If Kibana is up and running, you\u2019ll see a list of indices used for metrics and visualization, but nothing related to our books yet \u2014 and if Kibana hasn\u2019t been started, the list of indices will be empty.", "4. Setup Logstash to pipe data from MySQL to Elasticsearch:", "To connect Logstash to MySQL, we will use the official JDBC driver available at this address.", "Let\u2019s create a Dockerfile (named Dockerfile-logstash in the same directory) to pull a Logstash image, download the JDBC connector, and start a Logstash container. Add these lines to your Dockerfile:", "Then add the following snippet to your docker-compose.yaml file:", "Logstash uses defined pipelines to know where to get data from, how to filter it, and where should it go. We will define two pipelines: one for creating an Elasticsearch index from scratch (first scenario), and one for incremental updates on changes to the database records (second scenario).", "Please check documentation for an explanation of each of the fields used in the pipeline definition:", "4.a. First Scenario \u2014 Creating an Elasticsearch index from scratch:", "In your project directory, create a volumes folder (if not already created) then create a directory to host our Logstash configuration:", "Then in this config directory, create a file pipelines.yml containing:", "We then create a folder pipeline to host our pipelines definitions:", "and there create a file from-scratch.conf with the following content:", "We define where to find the JDBC connector in jdbc_driver_library , setup where to find MySQL in jdbc_connection_string , instruct the plugin to run from scratch in clean_run , and we define where to find the SQL statement to fetch and format the data records in statement_filepath .", "The filter basically removes extra fields added by the plugin.", "In the output, we define where to find the Elasticsearch host, set the name of the index to books (can be a new or an existing index), define which action to perform (can be index , create , update , delete \u2014 see docs), and setup which field will serve as a unique ID in the books index \u2014 ISBN is an internationally unique ID for books.", "To add the SQL query referenced by statement_filepath , let\u2019s create a folder queries :", "Then add file from-scratch.sql with as little as:", "to get our index built with all the records available so far in our books table. Note that the query should NOT end with a semi-colon (;).", "Now to mount the configuration files and definitions created above, add the following to your docker-compose.yaml file:", "Note that volumes directives are a way to tell Docker to mount a directory or file inside the container (right hand side of the :) onto a directory or file on your machine or server (left hand side of the :). Checkout the official Docker Compose documentation on volumes.", "In order to test the implementation for this first scenario, run on your terminal:", "If the run is successful, you will see a message similar to Logstash shut down and the container will exit with error code 0.", "Now head to Kibana on you browser (to this link for example) and let\u2019s start playing around to see if we have a books index and how we can search for books.", "In the Dev Tools panel, you can run custom queries to fetch documents by field value. For example, let\u2019s search for books with the word \u201cmagic\u201d in their title. Paste this query on the Dev Tools console:", "4.b. Second Scenario \u2014 Replicating changes on the database records to Elasticsearch:", "Most of the configuring and tweaking has been done in the previous part. We will simply add another pipeline that will take charge of the incremental update (replication).", "In the file volumes/logstash/config/pipelines.yml, add these two line:", "In the same file, you may want to comment out the two previous lines related to the \u201cfrom-scratch\u201d part (first scenario) in order to instruct Logstash to run this incremental pipeline only.", "Let\u2019s create a file incremental.conf in the directory volumes/logstash/pipeline/ with the following content:", "We see a few extra parameters compared to the previous pipeline definition.", "The schedule parameter has a cron-like syntax (with a resolution down to the second when adding one more value the left), and uses the Rufus Scheduler behind the scene. Here we instruct Logstash to run this pipeline every 5 seconds with */5 * * * * * .", "The website crontab.guru can help you read crontab expressions.", "During each periodic run, the parameter tracking_column instructs Logstash to store the journal_id value of the last record fetched and store it somewhere on the filesystem (See documentation here for last_run_metadata_path ). In the following run, Logstash will fetch records starting from journal_id + 1 , where journal_id is the value stored in the current run.", "In the filter section, when the database action type is \u201ccreate\u201d or \u201cupdate\u201d, we set the Elasticsearch action to \u201cindex\u201d so that new documents get indexed, and existing documents get re-indexed to update their value. Another approach to avoid re-indexing existing documents is to write a custom \u201cupdate\u201d script and to use the \u201cupsert\u201d action. For \u201cdelete\u201d actions, the document on Elasticsearch gets deleted.", "Let\u2019s create and populate the file incremental.sql in directory volumes/logstash/config/queries/ with this query:", "Let\u2019s have a look at the table books.new_arrival . It contains books that just got delivered to us and we didn\u2019t have time to add them to our main books.books table.", "As we can see, none of the books in that table are in our Elasticsearch index. Let\u2019s try with the 3 book in the table above \u201cThe Rocky Road to Romance (Elsie Hawkins #4)\u201d, ISBN 9780060598891:", "Now let\u2019s transfer that book from the new arrivals table to our main books table:", "Running the same search on Elasticsearch, we are happy to see that the document is now available:", "Let\u2019s test with an update of the same ISBN:", "\u2026and a delete of the same ISBN:", "We managed to get a proof of concept up and running in a short amount of time of how to index data into Elasticsearch from a MySQL database, and how to keep Elasticsearch in sync with the database.", "The technologies we used are a gold standard in the industry and many businesses rely on them daily to serve their customer, and it\u2019s very likely that many have encountered or will encounter the same problem we solved in this project.", "Shoot me a message! I am on these social platforms:", "If you find this post helpful, feel free to share it and follow to get my latest articles!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Curious about engineering and tech, I build projects based on my inspirations and needs around #webapps #devops #aws www.redouaneachouri.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fed32fc57b339&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@redouane.achouri?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@redouane.achouri?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "Redouane Achouri"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe058a5afdc88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&user=Redouane+Achouri&userId=e058a5afdc88&source=post_page-e058a5afdc88----ed32fc57b339---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed32fc57b339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed32fc57b339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/redouane-dev/sync-elasticsearch-mysql", "anchor_text": "sync-elasticsearch-mysql"}, {"url": "https://unsplash.com/@seb?utm_source=medium&utm_medium=referral", "anchor_text": "S\u00e9bastien Jermer"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://lucene.apache.org/core/", "anchor_text": "Lucene search engine"}, {"url": "https://en.wikipedia.org/wiki/Inverted_index", "anchor_text": "inverted document index"}, {"url": "https://www.elastic.co/what-is/elk-stack", "anchor_text": "ELK stack"}, {"url": "https://www.elastic.co/guide/en/logstash/current/input-plugins.html", "anchor_text": "Logstash can ingest data from many sources,"}, {"url": "https://www.elastic.co/guide/en/logstash/current/filter-plugins.html", "anchor_text": "parse, transform, and filter data on the fly"}, {"url": "https://www.elastic.co/guide/en/logstash/current/output-plugins.html", "anchor_text": "many output destinations available"}, {"url": "https://www.goodreads.com/", "anchor_text": "Goodreads"}, {"url": "https://www.kaggle.com/jealousleopard/goodreadsbooks", "anchor_text": "found on Kaggle"}, {"url": "https://docs.docker.com/compose/", "anchor_text": "docker-compose"}, {"url": "https://docs.docker.com/get-docker/", "anchor_text": "Install Docker"}, {"url": "https://docs.docker.com/compose/install/", "anchor_text": "Docker Compose"}, {"url": "https://github.com/redouane-dev/sync-elasticsearch-mysql", "anchor_text": "sync-elasticsearch-mysql"}, {"url": "https://github.com/redouane-dev/sync-elasticsearch-mysql/tree/main/data", "anchor_text": "project repository"}, {"url": "http://elasticsearch:9200", "anchor_text": "http://elasticsearch:9200"}, {"url": "https://dev.mysql.com/downloads/connector/j/", "anchor_text": "this address"}, {"url": "https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.22.tar.gz", "anchor_text": "https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.22.tar.gz"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html", "anchor_text": "JDBC Input Plugin"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate-remove_field", "anchor_text": "Mutate"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate-remove_field", "anchor_text": "remove_field"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html", "anchor_text": "Elasticsearch Output Plugin"}, {"url": "http://twitter.com/version", "anchor_text": "@version"}, {"url": "http://twitter.com/timestamp", "anchor_text": "@timestamp"}, {"url": "http://elasticsearch:9200", "anchor_text": "http://elasticsearch:9200"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-action", "anchor_text": "see docs"}, {"url": "https://en.wikipedia.org/wiki/International_Standard_Book_Number", "anchor_text": "ISBN is an internationally unique ID for books"}, {"url": "https://docs.docker.com/compose/compose-file/#volumes", "anchor_text": "official Docker Compose documentation"}, {"url": "http://localhost:5601/app/monitoring#/elasticsearch/indices", "anchor_text": "this link for example"}, {"url": "https://media.giphy.com/media/5pUxc9KypDZSkGRRXe/giphy.gif", "anchor_text": "Giphy"}, {"url": "http://twitter.com/metadata", "anchor_text": "@metadata"}, {"url": "http://twitter.com/metadata", "anchor_text": "@metadata"}, {"url": "http://twitter.com/version", "anchor_text": "@version"}, {"url": "http://twitter.com/timestamp", "anchor_text": "@timestamp"}, {"url": "http://elasticsearch:9200", "anchor_text": "http://elasticsearch:9200"}, {"url": "http://twitter.com/metadata", "anchor_text": "@metadata"}, {"url": "https://github.com/jmettraux/rufus-scheduler", "anchor_text": "Rufus Scheduler"}, {"url": "https://crontab.guru/", "anchor_text": "crontab.guru"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html#plugins-inputs-jdbc-last_run_metadata_path", "anchor_text": "documentation here"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-action", "anchor_text": "use the \u201cupsert\u201d action"}, {"url": "https://media.giphy.com/media/WKdPOVCG5LPaM/giphy.gif", "anchor_text": "Giphy"}, {"url": "https://twitter.com/redouaneoachour", "anchor_text": "https://twitter.com/redouaneoachour"}, {"url": "https://www.linkedin.com/in/redouane-achouri/", "anchor_text": "https://www.linkedin.com/in/redouane-achouri/"}, {"url": "https://github.com/redouane-dev", "anchor_text": "https://github.com/redouane-dev"}, {"url": "https://nlp.stanford.edu/IR-book/html/htmledition/a-first-take-at-building-an-inverted-index-1.html", "anchor_text": "A first take at building an inverted index"}, {"url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/documents-indices.html", "anchor_text": "Data in: documents and indices"}, {"url": "https://www.elastic.co/blog/how-to-keep-elasticsearch-synchronized-with-a-relational-database-using-logstash", "anchor_text": "How to keep Elasticsearch synchronized with a relational database using Logstash and JDBC"}, {"url": "https://www.kaggle.com/jealousleopard/goodreadsbooks", "anchor_text": "Goodreads-books"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html", "anchor_text": "Logstash JDBC input plugin"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html", "anchor_text": "Logstash Mutate filter plugin"}, {"url": "https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html", "anchor_text": "Logstash Elasticsearch output plugin"}, {"url": "https://medium.com/tag/elasticsearch?source=post_page-----ed32fc57b339---------------elasticsearch-----------------", "anchor_text": "Elasticsearch"}, {"url": "https://medium.com/tag/mysql?source=post_page-----ed32fc57b339---------------mysql-----------------", "anchor_text": "MySQL"}, {"url": "https://medium.com/tag/logstash?source=post_page-----ed32fc57b339---------------logstash-----------------", "anchor_text": "Logstash"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----ed32fc57b339---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ed32fc57b339---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed32fc57b339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&user=Redouane+Achouri&userId=e058a5afdc88&source=-----ed32fc57b339---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed32fc57b339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&user=Redouane+Achouri&userId=e058a5afdc88&source=-----ed32fc57b339---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed32fc57b339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fed32fc57b339&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ed32fc57b339---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ed32fc57b339--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ed32fc57b339--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ed32fc57b339--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@redouane.achouri?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@redouane.achouri?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Redouane Achouri"}, {"url": "https://medium.com/@redouane.achouri/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "66 Followers"}, {"url": "http://www.redouaneachouri.com", "anchor_text": "www.redouaneachouri.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe058a5afdc88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&user=Redouane+Achouri&userId=e058a5afdc88&source=post_page-e058a5afdc88--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe299b4e3079f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-synchronize-elasticsearch-with-mysql-ed32fc57b339&newsletterV3=e058a5afdc88&newsletterV3Id=e299b4e3079f&user=Redouane+Achouri&userId=e058a5afdc88&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}