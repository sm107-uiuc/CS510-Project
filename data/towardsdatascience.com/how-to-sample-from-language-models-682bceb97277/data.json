{"url": "https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277", "time": 1682996380.0782158, "path": "towardsdatascience.com/how-to-sample-from-language-models-682bceb97277/", "webpage": {"metadata": {"title": "How to sample from language models | by Ben Mann | Towards Data Science", "h1": "How to sample from language models", "description": "Causal language models like GPT-2 are trained to predict the probability of the next word given some context. For example, given \u201cI ate a delicious hot ___\u201d, the model may predict \u201cdog\u201d with 80%\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1904.09751", "anchor_text": "The Curious Case of Neural Text Degeneration", "paragraph_index": 1}, {"url": "https://colab.research.google.com/drive/1yeLM1LoaEqTAS6D_Op9_L2pLA06uUGW1", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://duet.li", "anchor_text": "https://duet.li", "paragraph_index": 14}, {"url": "https://colab.research.google.com/drive/1BBJPKYsgheHcCH0JAqLZ49UXHDk4XzX7", "anchor_text": "colab notebook", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1810.06640", "anchor_text": "Adversarial Text Generation without Reinforcement Learning", "paragraph_index": 18}, {"url": "https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-2-rl-1bc18a2b8c60", "anchor_text": "RL-based idea", "paragraph_index": 18}, {"url": "https://medium.com/u/5511064b4364?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Yaroslav Bulatov", "paragraph_index": 19}], "all_paragraphs": ["Causal language models like GPT-2 are trained to predict the probability of the next word given some context. For example, given \u201cI ate a delicious hot ___\u201d, the model may predict \u201cdog\u201d with 80% probability, \u201cpancake\u201d 5% probability, etc. The cool thing about this structure is they can be used to generate sequences of arbitrary length. I can give the model \u201cI ate,\u201d sample a token from the resulting distribution to get \u201cI ate a\u201d, then put that through the model again to get another distribution and resulting token. Repeat as long as we like. It turns out that this generation often either gets stuck in repetitive loops or forgets the subject and goes off topic. Why is this happening, and how might we better sample to generate more human-like text?", "This post is a summary and exploration of The Curious Case of Neural Text Degeneration by Holtzman et al 2019. I found it one of the most thorough and readable papers I\u2019ve read in recent memory, so please check it out if this post piques your interest!", "If we always sample the the most likely word, the standard language model training objective causes us to get stuck in loops like \u201cI don\u2019t know. I don\u2019t know. I don\u2019t know.\u201d This is unnatural, but most of the model\u2019s attention in modern language models is only on the most recent few tokens. Instead, popular sampling methods for generation are based on sampling from the distribution. But sampling also runs into a problem: if we have 50K possible choices, even if the bottom 25K tokens are each extremely unlikely, in aggregate they might have for example 30% of the probability mass. This means with each sample, we have a 1 in 3 chance of completely derailing our \u201ctrain of thought.\u201d Because of the short context mentioned earlier, this will cause an unrecoverable error cascade as each next word depends heavily on this recent wrong word.", "To combat sampling from the tail, the most popular methods are temperature and top k sampling.", "Temperature sampling is inspired by statistical thermodynamics, where high temperature means low energy states are more likely encountered. In probability models, logits play the role of energy and we can implement temperature sampling by dividing logits by the temperature before feeding them into softmax and obtaining our sampling probabilities. For example:", "Lower temperatures make the model increasingly confident in its top choices, while temperatures greater than 1 decrease confidence. 0 temperature is equivalent to argmax/max likelihood, while infinite temperature corresponds to a uniform sampling.", "Top k sampling means sorting by probability and zero-ing out the probabilities for anything below the k\u2019th token. It appears to improve quality by removing the tail and making it less likely to go off topic. But in some cases, there really are many words we could sample from reasonably (broad distribution below), and in some cases there aren\u2019t (narrow distribution below).", "To address this problem, the authors propose top p sampling, aka nucleus sampling, in which we compute the cumulative distribution and cut off as soon as the CDF exceeds P. In the broad distribution example above, it may take the top 100 tokens to exceed top_p = .9. In the narrow distribution, we may already exceed top_p = .9 with just \u201chot\u201d and \u201cwarm\u201d in our sample distribution. In this way, we still avoid sampling egregiously wrong tokens, but preserve variety when the highest scoring tokens have low confidence.", "Why doesn\u2019t maximum likelihood sampling work? In the training process, there\u2019s never a chance to see compounding errors. The model is trained to predict the next token based on a human-generated context. If it gets one token wrong by generating a bad distribution, the next token uses the \u201ccorrect\u201d human generated context independent of the last prediction. During generation it is forced to complete its own automatically-generated context, a setting it has not considered during training.", "Here are samples using top_k=40 and context \u201cI ate a delicious\u201d", "And here are samples using top_p=0.9 and same \u201cI ate a delicious\u201d context:", "Try it yourself here! You can enable GPU in Runtime > Change runtime type and get big batches for no additional runtime.", "I found it challenging to determine which of these samples is more human-like. For this reason I designed an experiment to determine top_k and top_p empirically.", "Our goal is to use top_k and top_p to maximize the probability of choosing the actual next word we\u2019ve held out. When searching for the optimal k and p values, it\u2019s actually easy to determine analytically for a given sample. For k, we find the sorted index where the \u201cgolden\u201d token occurred. For p, we find the CDF of the golden token. For example, if the context is \u201cI ate a delicious hot\u201d and the actual word is \u201cdog\u201d, but the model\u2019s predicted distribution had \u201cpancake\u201d as most likely, we\u2019d search down the probabilities until we found \u201cdog\u201d at index 3. At index 1, the CDF might be 62%. At index 3, the CDF might be something like 86%, so we\u2019ll record that as our optimal p.", "Across many examples, we can compute a histogram of optimal p and k values and compute summary statistics on them. I tested on a random section of Wikipedia with a context length of 15. This is much shorter than what the model was trained on (1024), but common for settings like https://duet.li or chat bots.", "Feel free to try it yourself in my colab notebook.", "If the model were being evaluated on its training set, it would be optimal to choose top_k = 1. But since the model is slightly out of domain, the most likely token sometimes appears further down the list. In addition, we have a 50K token vocabulary. In many datasets, we\u2019ll never see all the tokens, but the model isn\u2019t sure of that. By zero-ing out much of the probability mass using top_p or top_k, we incorporate our prior to never choose these never-seen-even-in-training tokens.", "That said, this search for k and p is still in the context of the model\u2019s view of the world and as such it\u2019s only a bandaid. What we really want is to fix training.", "I\u2019ve also started to think about changing the training objective to better match the generation task. For example, could we train some kind of discriminator to punish the model when it generates whole sequences that don\u2019t look human? It\u2019s not straightforward how to apply a GAN architecture to non-continuous domains. I came upon Adversarial Text Generation without Reinforcement Learning and an RL-based idea, but it seems these have not yet become mainstream. I think it\u2019d be interesting to apply these ideas to the big transformers that have swept state of the art in the last few months.", "Thanks to Yaroslav Bulatov for feedback and edits", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software engineer, tinkerer, aspiring mad scientist"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F682bceb97277&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----682bceb97277--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://8enmann.medium.com/?source=post_page-----682bceb97277--------------------------------", "anchor_text": ""}, {"url": "https://8enmann.medium.com/?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Ben Mann"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33ebef5d1079&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&user=Ben+Mann&userId=33ebef5d1079&source=post_page-33ebef5d1079----682bceb97277---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F682bceb97277&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F682bceb97277&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1904.09751", "anchor_text": "The Curious Case of Neural Text Degeneration"}, {"url": "https://colab.research.google.com/drive/1yeLM1LoaEqTAS6D_Op9_L2pLA06uUGW1", "anchor_text": "here"}, {"url": "https://duet.li", "anchor_text": "https://duet.li"}, {"url": "https://colab.research.google.com/drive/1BBJPKYsgheHcCH0JAqLZ49UXHDk4XzX7", "anchor_text": "colab notebook"}, {"url": "https://arxiv.org/abs/1810.06640", "anchor_text": "Adversarial Text Generation without Reinforcement Learning"}, {"url": "https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-2-rl-1bc18a2b8c60", "anchor_text": "RL-based idea"}, {"url": "https://medium.com/u/5511064b4364?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Yaroslav Bulatov"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----682bceb97277---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----682bceb97277---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/data-science?source=post_page-----682bceb97277---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----682bceb97277---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----682bceb97277---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F682bceb97277&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&user=Ben+Mann&userId=33ebef5d1079&source=-----682bceb97277---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F682bceb97277&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&user=Ben+Mann&userId=33ebef5d1079&source=-----682bceb97277---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F682bceb97277&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----682bceb97277--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F682bceb97277&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----682bceb97277---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----682bceb97277--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----682bceb97277--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----682bceb97277--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----682bceb97277--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----682bceb97277--------------------------------", "anchor_text": ""}, {"url": "https://8enmann.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://8enmann.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ben Mann"}, {"url": "https://8enmann.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "950 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33ebef5d1079&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&user=Ben+Mann&userId=33ebef5d1079&source=post_page-33ebef5d1079--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F869b10d3566e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-sample-from-language-models-682bceb97277&newsletterV3=33ebef5d1079&newsletterV3Id=869b10d3566e&user=Ben+Mann&userId=33ebef5d1079&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}