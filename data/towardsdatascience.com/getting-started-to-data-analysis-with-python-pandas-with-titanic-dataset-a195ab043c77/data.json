{"url": "https://towardsdatascience.com/getting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77", "time": 1682995727.330623, "path": "towardsdatascience.com/getting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77/", "webpage": {"metadata": {"title": "Getting started with Data Analysis with Python Pandas | by Sukru Yavuz | Towards Data Science", "h1": "Getting started with Data Analysis with Python Pandas", "description": "In this article, I will focus on importing datasets, dealing with missing values, changing data types, filtering, sorting, selecting specific column(s), dealing with duplicate values, dropping and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html", "anchor_text": "Ref-2", "paragraph_index": 17}, {"url": "https://www.linkedin.com/in/sukruyavuz/", "anchor_text": "https://www.linkedin.com/in/sukruyavuz/", "paragraph_index": 58}], "all_paragraphs": ["In this article, I will focus on importing datasets, dealing with missing values, changing data types, filtering, sorting, selecting specific column(s), dealing with duplicate values, dropping and adding rows and columns, counting values, counting unique values.", "During my graduation project, I have dealt with a lot of Data Pre-processing stuff without using any libraries. I have just used if statements and for loops. It literally killed me. After I started to learn Pandas, I decided to write this article to help students and beginners to get start with it. I will do my best to introduce you with Pandas\u2019 some of the most useful capabilities in the stage of Exploratory Data Analysis. Let\u2019s start with the definition of Python Pandas.", "Pandas is a software library written for the Python programming language for data manipulation and analysis.", "We are going to use the famous Titanic Dataset which is available on Kaggle. To download and work on it, click here. After you click on the given link, you have to click on \u201cDownload all\u201d. If you can\u2019t find the download button, it is shown below.", "The website might direct you to the competition tab, all you have to do is click on \u201cJoin Competition\u201d. After that, you will be able to download the dataset.", "The common shortcut of Pandas is pd. Instead of writing \u201cpandas.\u201d we can write \u201cpd.\u201d now. So, there is a dot after \u201cpd\u201d which is used to call a method from Pandas library.", "To read a dataset, we are going to use read_csv.", "After you run the code above, nothing will appear. So you have to write df to see your data. But instead of seeing all the data, we are going to use the \u201c.head()\u201d method to see the first five elements of the data. Before you run the read_csv code, you can write df.head() below. So it\u2019s going to be like this:", "Inside the parentheses, we can write the number of elements that we want to see. If we leave it blank, it will show the first five elements. If we write 25 inside of the parentheses, it will show the first 25 elements of the dataframe.", "There is also a method to see the see last n number of elements. The method is called .tail().", "The same rule is also applied here. If we leave the parentheses blank, it will be set as 5, if we write 25 inside of the parentheses, it will show the last 25 elements of the dataframe.", "To sum up, these methods return the top and bottom of the dataframe. The default number of rows is set to 5. But, you can change it by writing number of rows that you want to see inside the parentheses.", "Let\u2019s assume that you don\u2019t want all of the columns in your CSV file. You just want 3 of them and you want to get rid of them at the begining. How to do that? Good news! There is a really easy way to do that. We are going to use usecols argument to specify the column names that we want to work with. Let\u2019s work with just PassengerId, Survived, Pclass columns.", "It was just an example. We are going to work with whole data.", "After we load our dataset with read_csv, we would like to get some information about the columns. To do that, we are going to use .describe() and .info()", "This method is used to get a summary of numeric values in your dataset. It calculates the mean, standard deviation, minimum value, maximum value, 1st percentile, 2nd percentile, 3rd percentile of the columns with numeric values. It also counts the number of variables in the dataset. So, we will be able to see if there are missing values in columns.", "We can see that count of Age column is 714, mean is 29.6, standard deviation is 14.52 and so on. Thanks to count, we can understand that there are some missing values in this column. We will deal with them later.", "This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. (Ref-2)", "We can also see the data types of columns with .dtypes", "There is a column in our dataframe which represents the price of the ticket that passengers bought. Let\u2019s assume that we want to see lowest ticket price. To do that, we have to use .sort_values() method. It doesn\u2019t matter if the column that you want to sort is string or numeric. If it includes letters, it will sort in alphabetical order.", "We used .head() method to see only first 10 of the results after sorting. We can see that the lowest \u201cFare\u201d values are 0. What if we want to see the highest fare? All we have to do is use the .tail() method. No, just kidding. We have to set the ascending argument as False. But using .tail() is an alternative :P.", "Thanks to that, we can see the highest fares paid by passengers. If we want to save the sorted version of the dataframe, there are two alternatives. One is the old way, which is", "The other way is using the inplace argument. If we set this argument as True, it will write over it.", "After the execution of the code above, we will use the .head() method to check the new version of our DataFrame.", "We are going to sort the \u201cCabin\u201d column. There are lots of missing (NaN) values in this column. How can we deal with them? Thankfully, there is an argument which is called na_position which helps us to set a position for the NaN values in the dataset.", "By using .tail(20), we can see the last 20 elements of the dataset. If we look at Cabin column, we can see that all of the values are NaN.", "To sum up, we learned to read csv files with .read_csv method(with and without selecting specific columns), used .head() and .tail() to see elements in the top and at the bottom, got information about dataset with .describe() and .info(), sorted columns which include string or numeric values (with and without NaN values)", "Knowing how many unique variables are there in a column, or the occurence of each item in a column might be very useful in some cases. Let\u2019s count the number of male and female passengers with .value_counts()", "To count the occurence of a variable, we have to select the column first. You can select a column with two different ways:", "Since .value_counts() is a method, all we have to do is appending this method to the code above. It will look like this:", "If we want to see number of unique records in a dataset or in a column, we have to use .nunique() method.", "We can also count the unique records with .nunique() for a column. All we have to do is add the column name.", "If you want to see number of unique records for more than one column, you have to add one more square bracket.", "We checked the data types of the columns in Titanic dataset. We saw that the type of Embarked column is object. After counting the unique values in Embarked column with .unique(), we can see that there are 3 unique values in that column. So we can consider that the data type should be categorical. To change the datatype of that column the code below must be executed:", "The comparison sign in Python is == (double equal sign). So you should double check whether you used 2 equal signs. If you use just one equal sign, you might ruin your data. Let\u2019s assume that I want to see if the \u201cEmbarked\u201d column is equal to \u201cC\u201d. The true version of the comparison is:", "If I write the code like this", "It will set all the values as \u201cC\u201d in the Embarked column.", "What if we dont want to see just Trues and Falses? What if we want to see all information of those whose Embarked is C? To do that:", "If we write it like that, pandas will understand that we want to see those rows that have True value. The output is:", "Another way to do that might be:", "If we want to filter our data in vice versa:", "It is going to show the rows that their Embarked column is not \u201cC\u201d. The output is", "We are going to use AND and OR operator to filter with more than one condition. Let\u2019s assume that we want to see the passengers whose Fare is smaller than 100 and who are female. We are going to create 2 new masks to complete that.", "Let\u2019s do another example with OR operator. We are going to use | sign to do that. Let\u2019s see the passengers whose fare is more than 500 or older than 70.", "One of the most common problems in data science is missing values. To detect them, there is a beautiful method which is called .isnull(). With this method, we can get a boolean series (True or False). As we did before, by masking the condition, we can extract the values which are null. For example", "With this code, we are saying that \u201cShow me the passengers whose cabin is unknown\u201d. The output is:", "Instead of using this method on a column, it can be used on whole dataset too. If we want to count of the null values of all columns in a dataframe, we just have to write code below", "There are lots of dealing ways with missing values but in this article, we are going to use \u201cignore the tuple\u201d and \u201cfill it with median\u201d. We are going to ignore the \u201cCabin\u201d column since %70 of that column is missing. And we are going to fill the missing Ages with median value of that column.", "To drop the \u201cCabin\u201d column, we have to execute the code below.", "We used .drop method to drop Cabin column. There is a 2 argument above. In the labels argument, we have to specify the column names that we want to drop, in the axis argument, we specified that we drop it column-wise.", "If you want to drop more than one column, all you have to do is add it in the square brackets. For example:", "We are dropping cabin column and name column at the same time. As I mentioned before, If we knew that we won\u2019t use these columns, we would have usecols argument of .read_csv method to get rid of that columns at the beginning.", "To fill missing values in a dataframe, there is a method called .fillna().", "Let\u2019s assume that we have lots of missing values in a column and we want to fill them with 0. All we have to do is write the code below", "We can fill it with a specific value too. Let\u2019s give an example on Titanic dataset", "But instead of filling with \u201cUnknown\u201d to fill the missing values in the Age column, we are going to use the median of that column. To do that:", "If we want to fill the missing values with mean or something else, all we have to do is change the method at the end. After executing this code, we should check if there is still null values in the Age column.", "If you have any questions, don\u2019t hesitate to ask. Your comments are much appreciated.", "You can contact me via LinkedIn: https://www.linkedin.com/in/sukruyavuz/", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa195ab043c77&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a195ab043c77--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a195ab043c77--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sukruyavuz96?source=post_page-----a195ab043c77--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sukruyavuz96?source=post_page-----a195ab043c77--------------------------------", "anchor_text": "Sukru Yavuz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4f2532b72757&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&user=Sukru+Yavuz&userId=4f2532b72757&source=post_page-4f2532b72757----a195ab043c77---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa195ab043c77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa195ab043c77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Pandas_(software)", "anchor_text": "Ref-1"}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "here"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html", "anchor_text": "Ref-2"}, {"url": "https://www.linkedin.com/in/sukruyavuz/", "anchor_text": "https://www.linkedin.com/in/sukruyavuz/"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a195ab043c77---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----a195ab043c77---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/pandas?source=post_page-----a195ab043c77---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/pandas-dataframe?source=post_page-----a195ab043c77---------------pandas_dataframe-----------------", "anchor_text": "Pandas Dataframe"}, {"url": "https://medium.com/tag/exploratory-data-analysis?source=post_page-----a195ab043c77---------------exploratory_data_analysis-----------------", "anchor_text": "Exploratory Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa195ab043c77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&user=Sukru+Yavuz&userId=4f2532b72757&source=-----a195ab043c77---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa195ab043c77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&user=Sukru+Yavuz&userId=4f2532b72757&source=-----a195ab043c77---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa195ab043c77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a195ab043c77--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa195ab043c77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a195ab043c77---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a195ab043c77--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a195ab043c77--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a195ab043c77--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a195ab043c77--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a195ab043c77--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a195ab043c77--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a195ab043c77--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a195ab043c77--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sukruyavuz96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sukruyavuz96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sukru Yavuz"}, {"url": "https://medium.com/@sukruyavuz96/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "56 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4f2532b72757&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&user=Sukru+Yavuz&userId=4f2532b72757&source=post_page-4f2532b72757--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff87fb037d921&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-to-data-analysis-with-python-pandas-with-titanic-dataset-a195ab043c77&newsletterV3=4f2532b72757&newsletterV3Id=f87fb037d921&user=Sukru+Yavuz&userId=4f2532b72757&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}