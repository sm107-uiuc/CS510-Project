{"url": "https://towardsdatascience.com/math-of-q-learning-python-code-5dcbdc49b6f6", "time": 1682994096.7770722, "path": "towardsdatascience.com/math-of-q-learning-python-code-5dcbdc49b6f6/", "webpage": {"metadata": {"title": "Math of Q-Learning \u2014 Python. Understand where the Bellman equation\u2026 | by Omar Aflak | Towards Data Science", "h1": "Math of Q-Learning \u2014 Python", "description": "Understand where the Bellman equation comes from."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Q-Learning is a type of Reinforcement Learning which is a type of Machine Learning. Reinforcement learning has been used lately (typically) to teach an AI to play a game (Google DeepMind Atari, etc). Our goal is to understand a simple version of Reinforcement learning called Q-Learning, and write a program that will learn how to play a simple \u201cgame\u201d. Let\u2019s dive in!", "A Markov chain is a mathematical model that experiences transition of states with probabilistic rules.", "Here we have two states E and A, and the probabilities of going from one state to another (e.g. 70% chance of going to state A, starting from state E).", "A Markov Decision Process (MDP) is an extension of the Markov chain and it is used to model more complex environments. In this extension, we add the possibility to make a choice at every state which is called an action. We also add a reward which is a feedback from the environment for going from one state to another taking one action.", "In the image above, we are in the initial state don\u2019t understand, where we have two possible actions, study and don\u2019t study. For the study action, we may end up in different states according to a probabilistic rule. This is what we call a stochastic environment (random), in the sense that for one same action taken in the same state, we might have different results (understand and don\u2019t understand).", "In reinforcement learning, this is how we model a game or environment, and our goal will be to maximize the reward we get from that environment.", "The reward is the feedback from the environment that tells us how good we are doing. It can be the number of coins you grab in a game for example. Our goal is to maximize the total reward. Therefore, we need to write it down.", "This is the total reward we can get starting at some point t in time.", "For example, if we use the MDP presented above. We\u2019re initially in the state don\u2019t understand, we take the study action which takes us randomly to don\u2019t understand. Therefore we experienced the reward r(t+1)=-1. Now we can decide to take another action which will give r(t+2) and so on. The total reward is the sum of all the immediate rewards we get for taking actions in the environment.", "Defining the reward this way leads to two major problems :", "One way to fix up these problems is to use a decreasing factor for future rewards.", "Setting \u03b3=1 takes us back to the first expression where every reward is equally important. Setting \u03b3=0 results in only looking for the immediate reward (always acting for the optimal next step). Setting \u03b3 between 0 and 1 is a compromise to look more for immediate reward but still account for future rewards.", "We can rewrite that expression in a recursive manner, that will come handy later on.", "A policy is a function that tells what action to take when in a certain state. This function is usually denoted \u03c0(s,a) and yields the probability of taking action a in state s. We want to find the policy that maximizes the reward function.", "If we get back to the previous MDP for example, the policy can tell you the probability of taking action study when you\u2019re in the state don\u2019t understand.", "Moreover, because this is a probability distribution, the sum over all the possible actions must be equal to 1.", "We are going to start playing around with some equations, and for that we need to introduce new notations.", "This is the expected immediate reward for going from state s to state s\u2019 through action a.", "This is the transition probability of going from state s to state s\u2019 through action a.", "Two so-called \u201cvalue functions\u201d exist. The state value function, and the action value function. These functions are a way to measure the \u201cvalue\u201d, or how good some state is, or how good some action is, respectively.", "The value of a state is the expected total reward we can get starting from that state. It depends on the policy which tells how to take decisions.", "The value of an action taken in some state is the expected total reward we can get, starting from that state and taking that action. It also depends on the policy.", "Now that we are settled with notations we can finally start playing around with the math! Looking at the following diagram during the calculation can help you understand.", "We will start by expanding the state value function. The expected operator is linear.", "Next, we can expand the action value function.", "This form of the Q-Value is very generic. It handles stochastic environments, but we could write it in a deterministic one. Meaning, whenever you take an action you always end up in the same next state and receive the same reward. In that case, we simply do not need to make a weighted sum with probabilities, and the equation becomes:", "Where s\u2019 is the state you end up in for taking action a in state s. Written, more formally, this is:", "You probably already came across greedy policy reading on the internet. A greedy policy is a policy where you always choose the optimal next step.", "In a greedy policy context, we can write a relation between the state value and the action value functions.", "Therefore, plugging this into the previous equation, we get the Q-Value of a (state, action) pair in a deterministic environment, following a greedy policy.", "And this is the Bellman equation in the Q-Learning context ! It tells that the value of an action a in some state s is the immediate reward you get for taking that action, to which you add the maximum expected reward you can get in the next state.", "It actually makes sens when you think about it.", "Here, if you only look at the immediate reward, you surely choose to go left. Unfortunately, the game ends after and you cannot get more points.", "If you add the maximum expected reward of the next state, then you will most probably go to the right since the maximum expected reward of S1 is equal to zero and the maximum expected reward of S2 is probably higher than 10\u20135=5.", "You can also tweak \u03b3 to specify how important are the next rewards.", "Here is a simple environment which consists of a 5-by-5 grid. A treasure (T) is placed at the bottom right corner of the grid. The agent (O) starts at the top left corner of the grid.", "The agent needs to get to the treasure using the 4 available actions : left, right, up, down.", "If the agent takes an action that leads him directly to T, he gets a reward of 1, otherwise a reward of 0.", "The code is well commented and it is simply what we just discussed. Now the interesting part, the Q-Learning algorithm !", "I almost commented every single line of this code, so hopefully, it will be easy to understand!", "Put both of the above files in the same directory, and run :", "Around the epoch number 40, the agent should have learned to get to the treasure using one of the shortest paths (8 steps).", "We have seen how to derive statistical formulas to find the Bellman equation and used it to teach an AI how to play a simple game. Notice that in this game, the number of possible states is finite (the number of different cells you might end up in), which is why building a Q-Table (a table of values that approaches the real value of the Q function for discrete values) is still manageable. What about a graphical game, such as Flappy Bird, Mario Bros, or Call Of Duty ? Every frame displayed by the game can be considered as a different state. In that case it\u2019s impossible to build a Q-Table, and what we do instead is use a neural network who\u2019s goal will be to learn the Q function. That neural network will typically take as input the current state of the game, and output the best possible action to take in that state. This is known as Deep Q Learning and is exactly how AIs such as Deep Blue or Alpha Go managed to beat world champions at Chess or Go."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5dcbdc49b6f6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://omaraflak.medium.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Omar Aflak"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc215fdc67eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&user=Omar+Aflak&userId=c215fdc67eb&source=post_page-c215fdc67eb----5dcbdc49b6f6---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5dcbdc49b6f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&user=Omar+Aflak&userId=c215fdc67eb&source=-----5dcbdc49b6f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5dcbdc49b6f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&source=-----5dcbdc49b6f6---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@brett_jordan?utm_source=medium&utm_medium=referral", "anchor_text": "Brett Jordan"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5dcbdc49b6f6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----5dcbdc49b6f6---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----5dcbdc49b6f6---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----5dcbdc49b6f6---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/python?source=post_page-----5dcbdc49b6f6---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5dcbdc49b6f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&user=Omar+Aflak&userId=c215fdc67eb&source=-----5dcbdc49b6f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5dcbdc49b6f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&user=Omar+Aflak&userId=c215fdc67eb&source=-----5dcbdc49b6f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5dcbdc49b6f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc215fdc67eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&user=Omar+Aflak&userId=c215fdc67eb&source=post_page-c215fdc67eb----5dcbdc49b6f6---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb98d8ad5cb06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&newsletterV3=c215fdc67eb&newsletterV3Id=b98d8ad5cb06&user=Omar+Aflak&userId=c215fdc67eb&source=-----5dcbdc49b6f6---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Written by Omar Aflak"}, {"url": "https://omaraflak.medium.com/followers?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "497 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc215fdc67eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&user=Omar+Aflak&userId=c215fdc67eb&source=post_page-c215fdc67eb----5dcbdc49b6f6---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb98d8ad5cb06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-of-q-learning-python-code-5dcbdc49b6f6&newsletterV3=c215fdc67eb&newsletterV3Id=b98d8ad5cb06&user=Omar+Aflak&userId=c215fdc67eb&source=-----5dcbdc49b6f6---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65?source=author_recirc-----5dcbdc49b6f6----0---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=author_recirc-----5dcbdc49b6f6----0---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=author_recirc-----5dcbdc49b6f6----0---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Omar Aflak"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5dcbdc49b6f6----0---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65?source=author_recirc-----5dcbdc49b6f6----0---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Neural Network from scratch in PythonMake your own machine learning library."}, {"url": "https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65?source=author_recirc-----5dcbdc49b6f6----0---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "10 min read\u00b7Nov 15, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6da9f29ce65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-neural-network-from-scratch-in-python-d6da9f29ce65&user=Omar+Aflak&userId=c215fdc67eb&source=-----d6da9f29ce65----0-----------------clap_footer----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65?source=author_recirc-----5dcbdc49b6f6----0---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "33"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6da9f29ce65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmath-neural-network-from-scratch-in-python-d6da9f29ce65&source=-----5dcbdc49b6f6----0-----------------bookmark_preview----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5dcbdc49b6f6----1---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----5dcbdc49b6f6----1---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----5dcbdc49b6f6----1---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5dcbdc49b6f6----1---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5dcbdc49b6f6----1---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5dcbdc49b6f6----1---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5dcbdc49b6f6----1---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----5dcbdc49b6f6----1-----------------bookmark_preview----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5dcbdc49b6f6----2---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----5dcbdc49b6f6----2---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----5dcbdc49b6f6----2---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5dcbdc49b6f6----2---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5dcbdc49b6f6----2---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5dcbdc49b6f6----2---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5dcbdc49b6f6----2---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----5dcbdc49b6f6----2-----------------bookmark_preview----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/ray-tracing-from-scratch-in-python-41670e6a96f9?source=author_recirc-----5dcbdc49b6f6----3---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=author_recirc-----5dcbdc49b6f6----3---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=author_recirc-----5dcbdc49b6f6----3---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Omar Aflak"}, {"url": "https://medium.com/swlh?source=author_recirc-----5dcbdc49b6f6----3---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "The Startup"}, {"url": "https://medium.com/swlh/ray-tracing-from-scratch-in-python-41670e6a96f9?source=author_recirc-----5dcbdc49b6f6----3---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "Ray Tracing From Scratch in PythonCreate a computer-generated image using the Ray Tracing algorithm coded from scratch in Python."}, {"url": "https://medium.com/swlh/ray-tracing-from-scratch-in-python-41670e6a96f9?source=author_recirc-----5dcbdc49b6f6----3---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": "\u00b716 min read\u00b7Jul 26, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fswlh%2F41670e6a96f9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fray-tracing-from-scratch-in-python-41670e6a96f9&user=Omar+Aflak&userId=c215fdc67eb&source=-----41670e6a96f9----3-----------------clap_footer----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/ray-tracing-from-scratch-in-python-41670e6a96f9?source=author_recirc-----5dcbdc49b6f6----3---------------------d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41670e6a96f9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fray-tracing-from-scratch-in-python-41670e6a96f9&source=-----5dcbdc49b6f6----3-----------------bookmark_preview----d2e8694c_2c22_4ca7_853b_bb08177c1ef7-------", "anchor_text": ""}, {"url": "https://omaraflak.medium.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "See all from Omar Aflak"}, {"url": "https://towardsdatascience.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://eligijus-bujokas.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://eligijus-bujokas.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Eligijus Bujokas"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "The Values of Actions in Reinforcement Learning using Q-learningThe Q-learning algorithm implemented from scratch in Python"}, {"url": "https://towardsdatascience.com/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "\u00b710 min read\u00b7Feb 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb4b03be5c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81&user=Eligijus+Bujokas&userId=d61597e07b4d&source=-----cb4b03be5c81----0-----------------clap_footer----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb4b03be5c81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81&source=-----5dcbdc49b6f6----0-----------------bookmark_preview----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://eligijus-bujokas.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://eligijus-bujokas.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Eligijus Bujokas"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "First Steps in the World Of Reinforcement Learning using PythonOriginal Python implementation of how to find the best places to be in one of the fundamental worlds of reinforcement learning \u2014 the grid\u2026"}, {"url": "https://towardsdatascience.com/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "\u00b715 min read\u00b7Jan 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb843b76538e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3&user=Eligijus+Bujokas&userId=d61597e07b4d&source=-----b843b76538e3----1-----------------clap_footer----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb843b76538e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffirst-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3&source=-----5dcbdc49b6f6----1-----------------bookmark_preview----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----5dcbdc49b6f6----0---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----5dcbdc49b6f6----0-----------------bookmark_preview----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/feature-importance-with-deep-neural-network-for-cryptocurrencies-f06191e2d562?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Bruce Yang ByFinTech"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/feature-importance-with-deep-neural-network-for-cryptocurrencies-f06191e2d562?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Feature Importance with Deep Neural Network for CryptocurrenciesA FinRL-Meta Tutorial for NeurIPS 2022 Datasets and Benchmarks"}, {"url": "https://medium.datadriveninvestor.com/feature-importance-with-deep-neural-network-for-cryptocurrencies-f06191e2d562?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "\u00b710 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2Ff06191e2d562&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffeature-importance-with-deep-neural-network-for-cryptocurrencies-f06191e2d562&user=Bruce+Yang+ByFinTech&userId=a878fc45fb3f&source=-----f06191e2d562----1-----------------clap_footer----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/feature-importance-with-deep-neural-network-for-cryptocurrencies-f06191e2d562?source=read_next_recirc-----5dcbdc49b6f6----1---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff06191e2d562&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffeature-importance-with-deep-neural-network-for-cryptocurrencies-f06191e2d562&source=-----5dcbdc49b6f6----1-----------------bookmark_preview----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----5dcbdc49b6f6----2---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----2---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----5dcbdc49b6f6----2---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Bruce Yang ByFinTech"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----5dcbdc49b6f6----2---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----5dcbdc49b6f6----2---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement LearningNeurIPS 2022 Datasets and Benchmarks."}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----5dcbdc49b6f6----2---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "\u00b79 min read\u00b7Nov 13, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F7af8e747c4bd&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffinrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd&user=Bruce+Yang+ByFinTech&userId=a878fc45fb3f&source=-----7af8e747c4bd----2-----------------clap_footer----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----5dcbdc49b6f6----2---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7af8e747c4bd&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffinrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd&source=-----5dcbdc49b6f6----2-----------------bookmark_preview----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----5dcbdc49b6f6----3---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----5dcbdc49b6f6----3---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----5dcbdc49b6f6----3---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----5dcbdc49b6f6----3---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----5dcbdc49b6f6----3---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----3-----------------clap_footer----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----5dcbdc49b6f6----3---------------------7fdf37c8_65a8_4e69_bd9c_95041f06e028-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----5dcbdc49b6f6----3-----------------bookmark_preview----7fdf37c8_65a8_4e69_bd9c_95041f06e028-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----5dcbdc49b6f6--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}