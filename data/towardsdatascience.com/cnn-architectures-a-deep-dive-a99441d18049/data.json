{"url": "https://towardsdatascience.com/cnn-architectures-a-deep-dive-a99441d18049", "time": 1683000143.86586, "path": "towardsdatascience.com/cnn-architectures-a-deep-dive-a99441d18049/", "webpage": {"metadata": {"title": "CNN Architectures, a Deep-dive. Implementing every popular CNN\u2026 | by Sai Kumar Basaveswara | Towards Data Science", "h1": "CNN Architectures, a Deep-dive", "description": "In Deep Learning, a Convolutional Neural Network(CNN) is a class of deep neural networks, most commonly applied to analyzing visual imagery. Convolutional Neural Networks are state of the art models\u2026"}, "outgoing_paragraph_urls": [{"url": "https://gist.github.com/kumararduino/9d55e7d76a2435784a49114aff4579a8", "anchor_text": "gist", "paragraph_index": 27}], "all_paragraphs": ["In Deep Learning, a Convolutional Neural Network(CNN) is a class of deep neural networks, most commonly applied to analyzing visual imagery. Convolutional Neural Networks are state of the art models for Image Classification, Segmentation, Object Detection and many other image processing tasks. In order to get started into the field of Image Processing or to improve the prediction accuracy of the custom CNN models, the knowledge of some of the famous CNN architectures will keep us reach the pace in this competitive and ravenous world. Ergo, in this post I will be covering a few famous CNN architectures. I mainly stress on how to implement them in Keras in general i.e., making custom models with the idealogy and structure of those architectures.", "In this post, I will be covering the following architectures:", "VGG Net is a plain and straight forward CNN architecture among all other. Thought it looks simple, it do outperform many complex architectures. It is the 1st runner-up in ImageNet Challenge in 2014. As shown above, there are totally 6 VGGNet Architectures. Among them, VGG-16 and VGG-19 are popular.", "The idea of VGG architectures is quite simple. we have to stack the convolutional layers with increasing filter sizes. i.e., if layer-1 has 16 filters, then layer-2 must have 16 or more filters.", "Another noteworthy point is that in every VGG architecture, all filters are of size 3*3. The idea here is that, two 3*3 filters almost cover the are of what a 5*5 filter would cover and also two 3*3 filters are cheaper than one 5*5 filter(cheaper in the sense of total no. of multiplications to be performed).", "Lets create a custom VGG Net with 6 convolutional layers in Keras.", "The above code will create a simple VGG Network with six convolutional layers. After every Convolutional layer, I added a Dropout layer to reduce overfitting and MaxPooling layer after every pair of Convolutional layers for Dimensionality Reduction.", "The problem with VGG is that this naive architecture is not good for deeper networks, as the deeper the network goes, it is more prone to Vanishing Gradients Problem. More training and also more parameters have to be tuned in deeper VGG architectures.", "However, VGG Nets are handy for transfer learning and small classification tasks.", "Residual Networks are the first deeper networks to be won on the ImageNet Challenge. The ResNet used at ImageNet in 2015 has 152 layers. Until then, the idea of training such deeper networks is a dream. ResNet however achieved an error rate of 3.57% (top-5 error rate).", "The success recipe of ResNet for training such a deep(152 layers) network is that, it has residual connections. In VGG, every layer is connected to its previous layer, from which it is getting its inputs. This makes sure that upon propagation from layer to layer, more and more useful features are carried and less important features are dropped out. This is not the best way since the latter layers cannot see what the former layers have seen. ResNet addresses this problem by connecting not just the previous layer to the current layer but also a layer behind the previous layer. By incorporating this, now each layer can see more than just its previous layer\u2019s observations.", "There are many variants of ResNets. The core idea is, let us consider x as an output of some Conv2D layer. Add few Conv2D layers to x and then add the output to x and send this as input to the next layer.", "Training of such a deep Residual Networks is possible by using BatchNormalisation layers after every Convolutional Layer. Batch Normalisation layers will boost the values of weights and hence higher learning rates can be used while training, which will help train faster and also can minimize Vanishing Gradient problem.", "Lets convert the notion of ResNet into a snippet of code, which can be arbitrary to achieve the architecture we desire.", "The above function takes arguments as follows:", "And the process is, it connects the input layer to a Conv2D layer having filters specified in our function calling and then attaches a BatchNormalization layer, upon which a ReLU Activation layer is added, and then another Conv2D layer is stacked. Now, this stacked output is added with the initial input, but the initial input is transformed by passing it through a Conv2D layer of given filters. This step is done to match the output sizes of both the layers that are going to be added. Then, if we prefer having a MaxPooling2D layer, we add that and also if any Dropout value is given, then a Dropout layer is also added and then finally one more BatchNormalization layer and Activation layer are added and then this final layer is returned by our res_layer function.", "Now that we have created our res_layer, lets create a custom resnet.", "The above code created a simple ResNet model. The res_layer function is used to simplify the process of stacking multiple layers and adding them multiple times, which makes our code readable and manageable.", "The advantage of ResNet is that we can train deeper networks with this architecture.", "In ResNet, we added the stacked layer along with its input layer. In DenseNet, for a given layer, all other layers preceding to it are concatenated and given as input to the current layer. With such an arrangement, we can use smaller filter counts and also, this will minimize the vanishing gradient problem as all layers are directly connected to the output, gradients can be calculated directly from the output for each layer.", "Similar to res_layer function, lets develop a function for dense_layer.", "Now that we have defined our function, lets create some custom layer_configs.", "Now, lets create a custom DenseNet.", "DenseNet have much more intermediate connections when compared to ResNet. Also, we can use smaller filter counts in Dense layers and is good for smaller models.", "Inception means going deeper. In ResNet, we created deeper networks. The idea of Inception Net is to make the network wider. This can be done by parallel connection of multiple layers having different filters, and then finally concatenating all of those parallel paths to pass to next layers.", "We can do that by writing the inception_layer function, which can create an inception_layer of arbitrary configurations.", "Let us see a demo layer_configs list to get the idea.", "Now that we have created a inception_layer function, lets create a custom Inception Net. The layer_configs for different layers in this example can be found in this gist.", "Finally, lets create a custom Inception Net.", "There are many variants of Inception Nets. The differences among them are:", "Using our inception_layer function, we can customize all above types of InceptionNet architectures by writing our layer_configs accordingly.", "InceptionNets are preferable as they are not just deeper, but also wider and we can stack many such layers and still the output params to be trained are less when compared to all other architectures.", "Xception Net is an improvisation of InceptionNet in terms of computational efficiency. Xception means Extreme Inception. The Xception architecture presented in the image above is more like a ResNet rather than an InceptionNet. Xception Net outperforms Inception Net v3.", "The difference between Inception Net and Xception Net is that, in Inception Net normal convolutional operations are performed whereas in Xception Net, Depthwise Separable Convolutional operations are performed. Depthwise Separable Convolutions are different from normal convolutions in a way that, in normal Conv2D layer, for an input of (32, 32, 3) image we can use any number of filters in the Conv layer. Each of those filters will be operated over all three channels and the output is the sum of all corresponding values. But in Depthwise separable convolutions, each channel have only one kernel to do convolution. Hence, by performing Depthwise Separable Convolutions, we can reduce the computational complexity as every kernel is of two dimensional only and is convoluting only over one channel. In Keras, we can implement this by using DepthwiseConv2D layer.", "Lets create a simple Xception Net architecture.", "The above is a simpler implementation of Xception Net architecture. We can use XceptionNet in low power devices as there are less compuations in the Conv layer and also is accuracy is pretty similar when compared to a normal convolution layer.", "The main idea behind this article is to get familiar with state-of-the-art CNN architectures by actually creating them. This will build and improve our intuition and understanding about CNN\u2019s and how to and when to use them.There are many other popular CNN architectures. They appear more or less similar to the above architectures with added functionalities.", "For example, let us take MobileNet. It performs Depthwise Separable Convolutions rather than normal convolutions. This makes it more suitable for using it in low power devices and for models with faster responses.", "To wrap up everything, I prefer using custom architectures like these in smaller classification tasks with decent dataset sizes and moves to Transfer Learning in case of smaller datasets. When speed of response is concerned, we move for smaller models. Also, by using Ensemble methods, we can get pretty good accuracy with custom architectures.", "The articles and papers that helped me do this are:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa99441d18049&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a99441d18049--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a99441d18049--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://bvpsk.medium.com/?source=post_page-----a99441d18049--------------------------------", "anchor_text": ""}, {"url": "https://bvpsk.medium.com/?source=post_page-----a99441d18049--------------------------------", "anchor_text": "Sai Kumar Basaveswara"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb09b4681785f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&user=Sai+Kumar+Basaveswara&userId=b09b4681785f&source=post_page-b09b4681785f----a99441d18049---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa99441d18049&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa99441d18049&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://miro.medium.com/max/2800/0*pkrso8DZa0m6IAcJ.png", "anchor_text": "Image Sources"}, {"url": "https://miro.medium.com/max/2244/1*_1DEx3bHlnBApCWWQ0HgcQ.png", "anchor_text": "Image Source"}, {"url": "https://gist.github.com/kumararduino/ab4e3ffad6bd5fe9088f1d532b70f985", "anchor_text": "Snippet Source"}, {"url": "https://miro.medium.com/max/2800/0*pkrso8DZa0m6IAcJ.png", "anchor_text": "Image Source"}, {"url": "https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRC5NE6iebgG2L1gELx_FMVB1GtHMvDCZD6Z3zX32Fmg3fhZ_qs", "anchor_text": "Image Source"}, {"url": "https://gist.github.com/kumararduino/bed23d471fbb3132959fc6143e43c77a", "anchor_text": "Snippet Source"}, {"url": "https://gist.github.com/kumararduino/1699d6342926139bd83764124a48367c", "anchor_text": "Snippet Source"}, {"url": "https://arxiv.org/pdf/1608.06993v3.pdf", "anchor_text": "Image Source"}, {"url": "https://gist.github.com/kumararduino/2e2a1c90b7c1fc9989959a8e3f541876", "anchor_text": "Snippet Source"}, {"url": "https://gist.github.com/kumararduino/2ce1e463c567f07ffe32f93336dd6c02", "anchor_text": "Snippet Source"}, {"url": "https://gist.github.com/kumararduino/e0a666f2140b723745fd6d3da4f99fd0", "anchor_text": "Snippet Source"}, {"url": "https://gist.github.com/kumararduino/d3ea68366ec852d55f76d77a5b1495b7", "anchor_text": "Snippet Source"}, {"url": "https://miro.medium.com/max/2434/1*_rCyzi7fQzc_Q1gCqSLM1g.png", "anchor_text": "Image Source"}, {"url": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQksprDAKDmbIva8RfIyfN3pn2YBF1Y25v9PsvnqzPNaB6awYP2hA", "anchor_text": "Image Source"}, {"url": "https://gist.github.com/kumararduino/12e0cc146f17e7d40bc8c58aa6767c0d", "anchor_text": "Snippet Source"}, {"url": "https://gist.github.com/kumararduino/05d218d2cd30acbdd868f18446c7ee50", "anchor_text": "Snippet Source"}, {"url": "https://gist.github.com/kumararduino/9d55e7d76a2435784a49114aff4579a8", "anchor_text": "gist"}, {"url": "https://gist.github.com/kumararduino/4b0ae1f0fa0c913fe4aa1a2bbef89bff", "anchor_text": "Snippet Source"}, {"url": "http://zpascal.net/cvpr2017/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf", "anchor_text": "Image Source."}, {"url": "https://gist.github.com/kumararduino/4d71456d3c6960ac8597be416cb41079", "anchor_text": "Snippet Source"}, {"url": "https://arxiv.org/pdf/1409.4842v1.pdf", "anchor_text": "https://arxiv.org/pdf/1409.4842v1.pdf"}, {"url": "https://arxiv.org/pdf/1608.06993v3.pdf", "anchor_text": "https://arxiv.org/pdf/1608.06993v3.pdf"}, {"url": "https://towardsdatascience.com/densenet-2810936aeebb", "anchor_text": "https://towardsdatascience.com/densenet-2810936aeebb"}, {"url": "http://zpascal.net/cvpr2017/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf", "anchor_text": "http://zpascal.net/cvpr2017/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a99441d18049---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----a99441d18049---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----a99441d18049---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/cnn?source=post_page-----a99441d18049---------------cnn-----------------", "anchor_text": "Cnn"}, {"url": "https://medium.com/tag/ai?source=post_page-----a99441d18049---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa99441d18049&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&user=Sai+Kumar+Basaveswara&userId=b09b4681785f&source=-----a99441d18049---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa99441d18049&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&user=Sai+Kumar+Basaveswara&userId=b09b4681785f&source=-----a99441d18049---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa99441d18049&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a99441d18049--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa99441d18049&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a99441d18049---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a99441d18049--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a99441d18049--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a99441d18049--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a99441d18049--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a99441d18049--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a99441d18049--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a99441d18049--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a99441d18049--------------------------------", "anchor_text": ""}, {"url": "https://bvpsk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://bvpsk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sai Kumar Basaveswara"}, {"url": "https://bvpsk.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "45 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb09b4681785f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&user=Sai+Kumar+Basaveswara&userId=b09b4681785f&source=post_page-b09b4681785f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1914f5ec456d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcnn-architectures-a-deep-dive-a99441d18049&newsletterV3=b09b4681785f&newsletterV3Id=1914f5ec456d&user=Sai+Kumar+Basaveswara&userId=b09b4681785f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}