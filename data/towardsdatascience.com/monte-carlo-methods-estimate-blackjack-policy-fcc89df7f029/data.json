{"url": "https://towardsdatascience.com/monte-carlo-methods-estimate-blackjack-policy-fcc89df7f029", "time": 1682996484.372534, "path": "towardsdatascience.com/monte-carlo-methods-estimate-blackjack-policy-fcc89df7f029/", "webpage": {"metadata": {"title": "Reinforcement Learning \u2014 Estimating Blackjack Policy | by Jeremy Zhang | Towards Data Science", "h1": "Reinforcement Learning \u2014 Estimating Blackjack Policy", "description": "We have been discussing several reinforcement learning problems, within each we are trying to get the optimal policy by keep playing the game and update our estimates. In essence, we estimate the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Monte_Carlo_method", "anchor_text": "Monte Carlo Method", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Blackjack", "anchor_text": "blackjack", "paragraph_index": 4}, {"url": "https://github.com/MJeremy2017/RL/blob/master/BlackJack/blackjack_mc.py", "anchor_text": "full code here", "paragraph_index": 8}, {"url": "https://github.com/MJeremy2017/RL/blob/master/BlackJack/blackjack_mc.py", "anchor_text": "full code here", "paragraph_index": 22}, {"url": "https://github.com/MJeremy2017/RL/blob/master/BlackJack/blackjack_mc.py", "anchor_text": "full code here", "paragraph_index": 26}], "all_paragraphs": ["We have been discussing several reinforcement learning problems, within each we are trying to get the optimal policy by keep playing the game and update our estimates. In essence, we estimate the (state, value) pair or (state, action, value) pair and based on the estimates we generate policy by taking the action that gives the highest value. But this is not the only way to do it.", "In this paragraph, I will introduce Monte Carlo Method, which is another way to estimate the value of a state, or value of a policy. The Monte Carlo Method involves a wide broad of methods, but all follows the same principal \u2014 sampling. The idea is straightforward and intuitive, if you are not sure of the value of a state, just do sampling, which is keep visiting that state and averaging over the reward that got from simulated actions by interacting with the environment.", "\u201cMonte Carlo methods are ways of solving the reinforcement learning problem based on averaging sample returns.\u201d \u2014 Sutton, Reinforcement Learning an Introduction", "To get a better understanding on how to leverage Monte Carlo Methods on reinforcement learning, let us dive into an example which comes from Sutton\u2019s book.", "The game we are playing today is the widely known casino card game of blackjack, and our goal is to estimate a policy using sampling. Following is a brief description of the rules:", "The game begins with two cards dealt to both dealer and player. One of the dealer\u2019s cards is face up and the other is face down. If the player has 21 immediately (an ace and a 10-card), it is called a natural. He then wins unless the dealer also has a natural, in which case the game is a draw. If the player does not have a natural, then he can request additional cards, one by one (hits), until he either stops (sticks) or exceeds 21 (goes bust). If he goes bust, he loses; if he sticks, then it becomes the dealer\u2019s turn. The dealer hits or sticks according to a fixed strategy without choice: he sticks on any sum of 17 or greater, and hits otherwise. If the dealer goes bust, then the player wins; otherwise, the outcome\u2014win, lose, or draw\u2014is determined by whose final sum is closer to 21.If the player holds an ace that he could count as 11 without going bust, then the ace is said to be usable.", "Our policy is to stick if the our card\u2019s sum is 20 or 21, and to his otherwise. To find the state-value function for this policy by a Monte Carlo approach, we will simulate many blackjack games using the policy and averages the returns following each state.", "The key point is that a dealer\u2019s policy is fixed, sticking at sum \u2265 17, and we are going to simulate many blackjack games to measure the policy sticking at sum \u2265 20.", "To implement our simulation, let us first be clear about the states. The states in blackjack that we need to consider about include firstly, player\u2019s card sum, which ranges from 12\u201321(we exclude sum lower than 12 as in those scenarios we would always hit), secondly, dealer\u2019s showing card, as it potentially indicates the dealer\u2019s final card value, and lastly, player\u2019s usable ace, which is also a factor that would slightly affect our wining chance. So add up in total we have 10(from 12 to 21) * 10(from 1 to 10) * 2(true or false) = 200 states.(full code here)", "As our goal is to estimate the states\u2019 value under our fixed policy, we will need to have a (state, value) dict to record all the states and number of winnings along our game simulation, and also a player_states to track the states of each game.", "The player_win and player_draw are used to track the total wining of the game.", "The fundamental mechanism that required is to randomly give a card to each side, in which case we assume that we have infinite card.", "Our dealer policy is to hit when card value less than 17 and stand when 17 or above. The function will be able to return a new value based on the action chosen and be able to tell if the game is ended.", "This function can be called recursively until reaches its end as its returns is the same as inputs. We keep track of the usable ace, when current value is less than 10, the ace will always be taken as 11, otherwise 1; When current value is over 21 and the dealer has usable ace on hand, then the usable ace will be taken as 1, total value is subtracted by 10 accordingly, and the usable ace indicator will be set to false .", "The implementation is exactly the same as dealer policy except that player stands at 20 or above in this setting.", "At the end of each game, credit will be given to the winner by adding one to the state that leads to wining.", "The player_states is a list that records all the states until game ends, and the credit is only given to the last state that with card value between 12 and 21, that is to say, if we have a card sum of 15, and take the action HIT, getting a card of value 7, which ends with total sum of 22, then 15 will be taken as the last state instead of 22.", "Besides counting state_value , number of player winning and drawing is also counted, which will be used to measure the overall goodness of this policy.", "With all the above preparation, we are good to run the simulation! The whole process is similar to general value iteration stuff, but except backpropagating the reward at the end of the game, we update the estimates of state, value pair by what we defined in _giveCredit function.", "At the beginning of the game, dealer is given 2 cards, and we assume the first card is being shown. Then to the player\u2019s turn, only card value between 12 and 21 is included in the states, since it is meaningless to include value 22 or above in the states, as these values can not lead to a wining, thus needless to be counted.", "And finally at the end of the game, states that not yet exist in the player_state_value dict will be initialised to 0, and game will be credited by _giveCredit .", "We ran our simulation by 10000 rounds and plotted the estimates of state, value:", "The z column of reward is the number of wining of that state. As expected, when a player has value 20 or 21, which is at the rear of the plot, one is more likely to win. In overall, this HIT20 policy gives us 30.6% of wining, 24.37% drawing and 45.03% of losing against dealer\u2019s HIT17, obviously this is a policy that leads to more losing than winning in casino.(full code here)", "Let\u2019s also have a look at how usable ace leads to the nuances of game playing:", "The result from Sutton\u2019s book is clearer, in which he raised the question: why the frontmost values with usable ace are slightly higher than that without usable ace? I guess usable ace does increase the chance of wining in that a player with usable ace has greater chance to hit, as even the value crosses above 21, he is still able to continue by making the usable ace non-usable.", "To conclude, we together explored using MC method to evaluate a given policy. The idea of sampling of MC method can be generalised to many game playing scenarios, so if you reach a state and don\u2019t know where to go or what action to take, just sampling!", "Please check out full code here, and you are welcomed to contribute and raise issues!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Hmm\u2026I am a data scientist looking to catch up the tide\u2026"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffcc89df7f029&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://meatba11.medium.com/?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----fcc89df7f029---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffcc89df7f029&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffcc89df7f029&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Monte_Carlo_method", "anchor_text": "Monte Carlo Method"}, {"url": "https://en.wikipedia.org/wiki/Blackjack", "anchor_text": "blackjack"}, {"url": "https://github.com/MJeremy2017/RL/blob/master/BlackJack/blackjack_mc.py", "anchor_text": "full code here"}, {"url": "https://github.com/MJeremy2017/RL/blob/master/BlackJack/blackjack_mc.py", "anchor_text": "full code here"}, {"url": "https://github.com/MJeremy2017/RL/blob/master/BlackJack/blackjack_mc.py", "anchor_text": "full code here"}, {"url": "http://incompleteideas.net/book/the-book-2nd.html", "anchor_text": "http://incompleteideas.net/book/the-book-2nd.html"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----fcc89df7f029---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/monte-carlo-method?source=post_page-----fcc89df7f029---------------monte_carlo_method-----------------", "anchor_text": "Monte Carlo Method"}, {"url": "https://medium.com/tag/python3?source=post_page-----fcc89df7f029---------------python3-----------------", "anchor_text": "Python3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffcc89df7f029&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----fcc89df7f029---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffcc89df7f029&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----fcc89df7f029---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffcc89df7f029&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffcc89df7f029&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fcc89df7f029---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fcc89df7f029--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fcc89df7f029--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fcc89df7f029--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://meatba11.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcdbd8b83c584&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-methods-estimate-blackjack-policy-fcc89df7f029&newsletterV3=f37783fc8c26&newsletterV3Id=cdbd8b83c584&user=Jeremy+Zhang&userId=f37783fc8c26&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}