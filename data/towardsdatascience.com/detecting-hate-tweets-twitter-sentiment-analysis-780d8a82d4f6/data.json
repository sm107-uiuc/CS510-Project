{"url": "https://towardsdatascience.com/detecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6", "time": 1683002348.980711, "path": "towardsdatascience.com/detecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6/", "webpage": {"metadata": {"title": "Detecting Hate tweets \u2014 Twitter Sentiment Analysis | by Vedant Kshirsagar | Towards Data Science", "h1": "Detecting Hate tweets \u2014 Twitter Sentiment Analysis", "description": "Contributors: Vedant Kshirsagar, Adwait Toro, Sushrut Shendre, Sneha Lakshmikanthaiah, Rishab Ballekere Narayana Gowda, Tanvir Brar, Chavi Singal Toxic online content has become a major issue in\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Contributors: Vedant Kshirsagar, Adwait Toro, Sushrut Shendre, Sneha Lakshmikanthaiah, Rishab Ballekere Narayana Gowda, Tanvir Brar, Chavi Singal", "All of our code can be found on our GitHub", "Toxic online content has become a major issue in today\u2019s world due to an exponential increase in the use of the internet by people of different cultures and educational backgrounds. Differentiating hate speech and offensive language is a key challenge in the automatic detection of toxic text content. In this report, we propose an approach to automatically classify tweets on Twitter into two classes: hate speech and non-hate speech. Using the Twitter dataset, we perform experiments by leveraging bag of words and the term frequency-inverse document frequency (TFIDF) values to multiple machine learning models. We perform comparative analysis of the models considering both of these approaches. After tuning the model giving the best results, we achieved an accuracy of 89% and a recall of 84% upon applying the Logistic Regression model. We also create a module using flask which serves as a real time application of our model.", "Our goal is to classify tweets into two categories, hate speech or non-hate speech. Our project analyzed a dataset CSV file from Kaggle containing 31,935 tweets. The dataset was heavily skewed with 93% of tweets or 29,695 tweets containing non-hate labeled Twitter data and 7% or 2,240 tweets containing hate-labeled Twitter data. The first step of building our model was to balance the number of hate and non-hate tweets. Our data preprocessing step involved 2 approaches, Bag of words and Term Frequency Inverse Document Frequency (TFIDF).", "The bag-of-words approach is a simplified representation used in natural language processing and information retrieval. In this approach, a text such as a sentence or a document is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.", "TFIDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection. It is used as a weighting factor in searches of information retrieval, text mining, and user modeling.", "Before we input this data into various algorithms, we have to clean it as the tweets contain many different tenses, grammatical errors, unknown symbols, hashtags, and Greek characters.", "We tackle this problem by employing lemmatization, stemming, removal of stop words, and omissions. Lemmatization removes the inflectional endings of words and returns the word to the base or dictionary form of it itself. Stemming is similar to lemmatization in that it reduces the inflected or derived words to their word stem. A stop word is a commonly used word, such as \u201cthe\u201d, \u201ca\u201d, \u201can\u201d, \u201cin\u201d, that we programmed to ignore as it holds no importance. The last step is to omit any foreign characters and Greek symbols.", "The inspiration to explore this topic came from both the increase in the instances of hate speech and hate speech awareness. According to the New York Times, \u201cPersonal attacks motivated by bias or prejudice reached a 16-year high in 2018, with a significant upswing in violence against Latinos outpacing a drop-in assault targeting Muslims and Arab-Americans.\u201d This rise can also be attributed to the rise of digital social media platforms which facilitate the spread of hate speech. Majority (59.6%) of all hate crime incidents involve race and ethnicity bias. The next highest bias was religion which accounted for 18.7% of all incidents. Our research validated these results when we observed that the most commonly occurring negative words in hate tweets were related to race or religion. These instances of vitriol can subconsciously incite hatred in our society, particularly in the minds of our impressionable younger generations. According to public research, 22% of respondents say they feel less safe in their community because of online hate speech and over 85% support setting up a task force to monitor cyber bullying. The issue has become so widespread now that the first lady of the United States, Melania Trump, has made it her main goal to combat cyberbullying and hate speech online. As the statistics show, not enough is being done to reduce the spread of hate speech.", "A word cloud is created to get an idea of the most common words utilized in tweets. This was done for both categories of hate and non-hate tweets. Next, we created a bar graph to visualize the utilization frequencies between the most common words in both the positive as well as the negative sentiment.", "As discussed earlier, the data we have is imbalanced. We have a total of 31935 rows out of which the hate tweets comprise only 7% of the total tweets. Modelling on an imbalanced dataset is not ideal since the model won\u2019t be able to learn what pieces of text or information causes the tweet to be classified as a hate tweet.", "If we train a model on imbalanced data, the results will be misleading. In such datasets, due to lack of learning, the model would simply predict each tweet as a good tweet. In this case, in spite of having a high accuracy, it is not actually doing a good job of classification since it is unable to classify the hate tweets accurately.", "In simpler words, even when the model predicts all tweets as non-hate, it will still be accurate 93 percent of the time.", "Therefore, we perform strategic sampling and separate the data into a temporary set and test set. Note that since we have performed strategic sampling, the ratio of good tweets to hate tweets is 93:7 for both the temporary and test datasets.", "On the temporary data, we first tried to perform up sampling of hate tweets using SMOTE (Synthetic Minority Oversampling Technique). Since the SMOTE packages don\u2019t work directly for textual data, we wrote our own code for it. The process is as follows:", "We created a corpus of all the unique words present in hate tweets of the temporary dataset. Once we had a matrix containing all possible words in hate tweets, we created a blank new dataset and started filling it with new hate tweets. These new tweets were synthesized by selecting words at random from the corpus. The lengths of these new tweets were determined on the basis of the lengths of the tweets from which the corpus was formed.", "We then repeated this process multiple times until the number of hate tweets in this synthetic data was equal to the number of non-hate tweets we had in our temporary data. However, when we employed the Bag of Words approach for feature generation, the number of features went up to 100,000. Due to an extremely high number of features, we faced hardware and processing power limitation and hence had to discard the SMOTE oversampling method.", "As it was not possible to up-sample hate tweets to balance the data, we decided to down-sample non-hate tweets to make it even. We took a subset of only the non-hate tweets from the temporary dataset. From this subset, we selected n random tweets, where n is the number of hate tweets in the temporary data. We then joined this with the subset of hate tweets in the temporary data. This dataset is now the training data that we use for our feature generation and modelling purposes.", "The test data is still in a 93:7 ratio of good tweets to hate tweets as we did not perform any sampling on it. Sampling was not performed as real world data comes in this ratio.", "We have looked at two major approaches for feature generation: Bag of Words (BOW) and Term Frequency Inverse Document Frequency (TFIDF).", "2. Term Frequency Inverse Document Frequency", "A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, such as with machine learning algorithms.", "It is called a \u201cbag\u201d of words because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document. The intuition is that documents are similar if they have similar content. Further, from the content alone we can learn something about the meaning of the document.", "The objective is to turn each document of free text into a vector that we can use as input or output for a machine learning model. Because we know the vocabulary has 10 words, we can use a fixed-length document representation of 10, with one position in the vector to score each word. The simplest scoring method is to mark the presence of words as a Boolean value, 0 for absent, 1 for present.", "Using the arbitrary ordering of words listed above in our vocabulary, we can step through the first document (\u201cIt was the best of times \u201c) and convert it into a binary vector.", "The scoring of the document would look as follows:", "As a binary vector, this would look as follows:", "The other three documents would look as follows:", "If your dataset is small and context is domain specific, BoW may work better than Word Embedding. Context is very domain specific which means that you cannot find corresponding Vector from pre-trained word embedding models (GloVe, fastText etc.)", "TF*IDF is an information retrieval technique that weighs a term\u2019s frequency (TF) and its inverse document frequency (IDF). Each word or term has its respective TF and IDF score. The product of the TF and IDF scores of a term is called the TF*IDF weight of that term.", "Put simply, the higher the TF*IDF score (weight), the rarer the term and vice versa.", "The TF*IDF algorithm is used to weigh a keyword in any content and assign the importance to that keyword based on the number of times it appears in the document. More importantly, it checks how relevant the keyword is throughout the web, which is referred to as corpus.", "For a term t in a document d, the weight Wt, d of term t in document d is given by:", "\u25cf TFt, d is the number of occurrences of t in document d.", "\u25cf DFt is the number of documents containing the term t.", "\u25cf N is the total number of documents in the corpus.", "How is TF*IDF calculated? The TF (term frequency) of a word is the frequency of a word (i.e. number of times it appears) in a document. When you know it, you\u2019re able to see if you\u2019re using a term too much or too little.", "For example, when a 100-word document contains the term \u201ccat\u201d 12 times, the TF for the word \u2018cat\u2019 is", "The IDF (inverse document frequency) of a word is the measure of how significant that term is in the whole corpus.", "Languages we speak and write are made up of several words often derived from one another and can contain words which don\u2019t add meaning or context. In order to clean the data, we implemented 5 approaches.", "For both the Bag of words and TFIDF, we run 5 classification algorithms, namely Logistic Regression, Naive Bayes, Decision Tree, Random Forest and Gradient Boosting. Furthermore, we also perform dimensionality reduction in both the approaches and again run these 5 algorithms.", "We implement the Bag of Words for feature generation, on our training dataset. In this approach, we try to find the probability that a tweet is a hate tweet or not, given the presence of certain words and their frequency in the tweet.", "Our training data is a total of 4480 tweets which generates a corpus of 12566 unique words. After implementing the Bag of Words feature engineering, the result is a dataframe containing 4480 rows and 12566 columns, where each column corresponds to a unique word. We then concatenate the label as a column.", "Upon running the classification algorithms, the following results were obtained:", "To better visualize these results, we plot the following cluster column chart.", "We now debate over the reasoning of having accuracy and recall as our metrics and how they\u2019ll help us choose our champion model. At a first glance, gradient boosting seems to be the best model due to its highest accuracy. But as discussed in data architecture, our test data contains a 93:7 ratio for good tweets to hate tweets. Thus, having high accuracy may not be the best metric. We hence take into consideration recall, which is the proportion of hate tweets we are able to correctly identify. If this metric is high, it would correspond to a high number of hate tweets being classified as hate tweets and thus achieving our objective. If we look exclusively at recall, Naive Bayes seems to be the best model. However, another factor to be considered is that all the tweets we capture as hate tweets will be forwarded to an operations team which would review each of these tweets individually. Therefore, having a large number of false positives will mean that the analysts will have to unnecessarily scrutinize a higher number of tweets which are actually non hate tweets. This will lead to inefficiencies in the utilization of time, resources and personnel. Our recommendation is to have a high recall while at the same time ensuring that the number of false positives are kept to a minimum. It would be ideal to move forward with models which are giving high scores for both accuracy and recall. Thus, we select logistic regression and random forest as the champion models.", "ii) Term Frequency Inverse Document Frequency (TFIDF)", "There are certain words which are considered as slang or abusive words, but are so common that people use them a lot in their daily lives. So, if there is a tweet containing these words, it may not actually be intended as a hate tweet. To draw the line between whether a slang/abusive word is intended as hate or not, we tried the TFIDF approach since it allocates a low weightage to such words. So, instead of the Bag of Words model where we have a count of how many times that word occurred in the tweet, this will have a TFIDF weight instead. After running the algorithms, we obtain the following results.", "Again, logistic regression and random forests give us the best results for accuracy as well as recall.", "iii) Bag of Words for 1000 most frequent words", "Since the number of features was equal to the number of unique words, and hence, enormous (12566), we hypothesized that the two models we have discussed so far could be overfitting. Therefore, we try to reduce the dimensionality by taking the 1000 most frequent words (and hence variables). After this variable selection, we implement the classification algorithms again. We do this for both Bag of Words as well as TFIDF. The results obtained are tabulated and plotted as follows:", "iv) TF-IDF for 1000 most frequent words", "The results obtained after running the models with reduced dimensions were consistent with those without dimensionality reduction. Gradient Boosting again gives a high accuracy, naive bayes a good recall and logistic regression and random forest give the best results for both of these metrics.", "However, there are no significant improvements for these models. While the metrics improve for some algorithms, they depreciate for others and the amount by which they improve/reduce is negligible.", "Lastly, we look at the ROC curves. Following is the curve for the Bag of Words approach (all words):", "The following table shows the Area under the curve (AUC) for the various algorithms", "Now, let us look at the ROC curves and AUC table for the TFIDF approach (all words)", "As we can see, logistic regression gives us the best AUC. Also, if we look at its ROC curve, we can see that it covers the False Positive Rate (FPR) and True Positive Rate (TPR) area equally. Compare this to Naive Bayes which shows a poor false positive performance, which was also evident by its accuracy score earlier. Similarly, gradient boosting has a poor true positive performance which was evident by its low recall score.", "In addition, logistic regression is straightforward in nature, i.e. the model can be explained with the help of a simple exponential equation, and its coefficients can be visualized and compared. Therefore, we recommend logistic regression as the best model for our case.", "After all the data cleaning, feature engineering and modeling, we decided to deploy the model to yield something useful from this project. The main objective of this project was to develop a system that can detect the hate tweets so that Twitter could take appropriate actions and reduce the causes of social bullying. Thus, we deployed our machine learning model using Flask technology.", "Below is a snapshot of the website: -", "The website was built using HTML and CSS wherein a person can enter a tweet given in the text box on the website.", "Consider 2 use cases of our proposed model: -", "1 \u2014 The user enters a positive tweet and then correctly gets classified as a positive tweet.", "2 \u2014 The user enters a hate tweet and then correctly gets classified as a hate tweet.", "Politics, race and sexual tweets form a major chunk of hate tweets.", "Results obtained when we played around with an imbalanced data set were inaccurate. The model predicts new data to belong to the major class in the training set due to the skewed nature of the train data.", "The weighted accuracy of a classifier is not the only metric to be looked at while evaluating the performance of the model. Business context plays a vital role as well.", "A challenge faced by automatic hate speech detection systems is the changing of attitudes towards topics over time and historical context. For example, in the following excerpt:", "\u201c\u2026The merciless Indian Savages, whose known rule of warfare, is an undistinguished destruction of all ages, sexes and conditions\u2026\u201d", "Intuition suggests that this is hate speech; it refers to Native Americans as \u201cmerciless Indian savages\u201d and dehumanizes them by suggesting that they are inferior. Indeed, the text satisfies conditions used in most definitions of hate speech. However, this text is actually a quote from the Declaration of Independence. Given the historical context of the text, the user who posted it may not have intended the hate speech result, but instead meant to quote the historical document for other purposes. This shows that user intent and context play an important role in hate speech identification.", "As another example, consider the phrase \u201cthe Nazi organization was great.\u201d This would be considered hate speech because it shows support for a hate group. However, \u201cthe Nazi\u2019s organization was great\u201d isn\u2019t supporting their ideals but instead commenting on how well the group was organized. In some contexts, this might not be considered hate speech, e.g., if the author was comparing organizational effectiveness over time. The difference in these two phrases is subtle but could be enough to make the difference between hate speech or not.", "Another remaining challenge is that automatic hate speech detection is a closed-loop system; individuals are aware that it is happening, and actively try to evade detection. Users who desire to spread the hateful messages quickly find ways to circumvent these measures by, for instance, posting the content as images containing the text, rather than the text itself. Although optical character recognition can be employed to solve the particular problem, this further demonstrates the difficulty of hate speech detection going forward. It will be a constant battle between those trying to spread hateful content and those trying to block it.", "As hate speech continues to be a societal problem, the need for automatic hate speech detection systems becomes more apparent. In this report, we proposed a solution to the detection of hate speech and offensive language on Twitter through machine learning using Bag of Words and TF IDF values. We performed comparative analysis of Logistic Regression, Naive Bayes, Decision Tree, Random Forest and Gradient Boosting on various sets of feature values and model parameters. The results showed that Logistic Regression performs comparatively better with the TF IDF approach.", "We presented the current problems for this task and our system that achieves reasonable accuracy (89%) as well as recall (84%). Given all the challenges that remain, there is a need for more research on this problem, including both technical and practical matters.", "[2] A. Gaydhani, V. Doma, S. Kendre and L. Bhagwat, \u201cDetecting Hate Speech and Offensive Language on Twitter using Machine Learning: An N-gram and TF IDF based approach\u201d.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F780d8a82d4f6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@vedantkshirsagar?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vedantkshirsagar?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "Vedant Kshirsagar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff38d5d3269ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&user=Vedant+Kshirsagar&userId=f38d5d3269ce&source=post_page-f38d5d3269ce----780d8a82d4f6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F780d8a82d4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F780d8a82d4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/vedant-95/Twitter-Hate-Speech-Detection", "anchor_text": "https://github.com/vedant-95/Twitter-Hate-Speech-Detection"}, {"url": "https://www.kaggle.com/vkrahul/twitter-hate-speech", "anchor_text": "https://www.kaggle.com/vkrahul/twitter-hate-speech"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6701757/", "anchor_text": "ncbi.nlm.nih.gov/pmc/articles/PMC6701757/"}, {"url": "https://www.nytimes.com/2019/11/12/us/hate-crimes-fbi-report.html", "anchor_text": "https://www.nytimes.com/2019/11/12/us/hate-crimes-fbi-report.html"}, {"url": "https://www.dailyprincetonian.com/article/2018/10/hate-speech-deserves-a-second-look", "anchor_text": "https://www.dailyprincetonian.com/article/2018/10/hate-speech-deserves-a-second-look"}, {"url": "https://medium.com/tag/data-science?source=post_page-----780d8a82d4f6---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/sentiment-analysis?source=post_page-----780d8a82d4f6---------------sentiment_analysis-----------------", "anchor_text": "Sentiment Analysis"}, {"url": "https://medium.com/tag/twitter?source=post_page-----780d8a82d4f6---------------twitter-----------------", "anchor_text": "Twitter"}, {"url": "https://medium.com/tag/hate-speech?source=post_page-----780d8a82d4f6---------------hate_speech-----------------", "anchor_text": "Hate Speech"}, {"url": "https://medium.com/tag/nlp?source=post_page-----780d8a82d4f6---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F780d8a82d4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&user=Vedant+Kshirsagar&userId=f38d5d3269ce&source=-----780d8a82d4f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F780d8a82d4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&user=Vedant+Kshirsagar&userId=f38d5d3269ce&source=-----780d8a82d4f6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F780d8a82d4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F780d8a82d4f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----780d8a82d4f6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----780d8a82d4f6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vedantkshirsagar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vedantkshirsagar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Vedant Kshirsagar"}, {"url": "https://medium.com/@vedantkshirsagar/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "37 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff38d5d3269ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&user=Vedant+Kshirsagar&userId=f38d5d3269ce&source=post_page-f38d5d3269ce--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Ff38d5d3269ce%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6&user=Vedant+Kshirsagar&userId=f38d5d3269ce&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}