{"url": "https://towardsdatascience.com/an-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03", "time": 1682993543.8479779, "path": "towardsdatascience.com/an-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03/", "webpage": {"metadata": {"title": "An Advanced Example of the Tensorflow Estimator Class | by Tijmen Verhulsdonck | Towards Data Science", "h1": "An Advanced Example of the Tensorflow Estimator Class", "description": "Estimators were introduced in version 1.3 of the Tensorflow API, and are used to abstract and simplify training, evaluation and prediction. If you haven\u2019t worked with Estimators before I suggest to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/learning-machine-learning/introduction-to-tensorflow-estimators-part-1-39f9eb666bc7", "anchor_text": "article", "paragraph_index": 0}, {"url": "https://github.com/Timen/squeezenext-tensorflow", "anchor_text": "SqueezeNext-Tensorflow", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/1803.10615.pdf", "anchor_text": "SqueezeNext", "paragraph_index": 3}, {"url": "https://github.com/amirgholami/SqueezeNext", "anchor_text": "caffe", "paragraph_index": 3}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/train.py", "anchor_text": "train.py", "paragraph_index": 8}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data/Dataset", "anchor_text": "Dataset class", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Extract,_transform,_load", "anchor_text": "E.T.L", "paragraph_index": 12}, {"url": "https://www.tensorflow.org/guide/datasets", "anchor_text": "write-up", "paragraph_index": 12}, {"url": "https://www.tensorflow.org/performance/performance_guide", "anchor_text": "performance", "paragraph_index": 12}, {"url": "https://www.tensorflow.org/performance/datasets_performance", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://github.com/tensorflow/models/tree/master/research/inception/inception/data", "anchor_text": "repo", "paragraph_index": 16}, {"url": "https://www.tensorflow.org/performance/performance_guide", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer", "anchor_text": "AdamOptimizer", "paragraph_index": 27}, {"url": "https://www.tensorflow.org/guide/estimators", "anchor_text": "tutorials", "paragraph_index": 31}, {"url": "https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/train/Scaffold", "anchor_text": "scaffold", "paragraph_index": 33}, {"url": "https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/estimator/WarmStartSettings", "anchor_text": "\u201cWarmStartSettings\u201d", "paragraph_index": 35}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook", "anchor_text": "SessionRunHook", "paragraph_index": 36}, {"url": "https://en.wikipedia.org/wiki/Hooking", "anchor_text": "hooking", "paragraph_index": 36}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook", "anchor_text": "here", "paragraph_index": 37}, {"url": "https://github.com/Timen/squeezenext-tensorflow", "anchor_text": "github repo", "paragraph_index": 43}], "all_paragraphs": ["Estimators were introduced in version 1.3 of the Tensorflow API, and are used to abstract and simplify training, evaluation and prediction. If you haven\u2019t worked with Estimators before I suggest to start by reading this article and get some familiarity as I won\u2019t be covering all of the basics when using estimators. Instead I hope to demystify and clarify some aspects more detailed aspects of using Estimators and switching to Estimators from an existing code-base.", "Anyone who has been working with Tensorflow for a long time will know that it used to be a lot more time consuming to setup and use Tensorflow as it is today. Today there are numerous libraries that simplify development such as slim, tflearn and more. These often reduced the code needed to define a network from multiple files and classes to a single function. They also simplified managing the training and evaluation, and to a small extend data preparation and loading. The Estimator class of Tensorflow does not change anything about the network definition but it simplifies and abstracts managing training, evaluation and prediction. It stands out from the other libraries due to it\u2019s low level optimizations, useful abstractions and support from the core Tensorflow dev team.", "That is the long story, in short Estimators are faster to run and to implement, simpler (once you get used to them) and well supported.", "This article will break down some of the features of the Estimators, using examples from a GitHub project of mine SqueezeNext-Tensorflow. The network implemented in the project is from a paper released in 2018 called \u201cSqueezeNext\u201d. This network is very lightweight and fast due to a novel approach to separable convolutions. The researchers released a caffe version but to facilitate experimentation using the available Tensorflow libraries I recreated the algorithm from the paper in Tensorflow.", "The article is setup using the following structure:", "In order to setup the Estimator for a certain training and evaluation roster it\u2019s good to first understand how the Estimator setup works. To construct an instance of the Estimator class you can use the following call:", "In this call \u201cmodel_dir\u201d is the path to the folder where the Estimator should store and load checkpoints and event files. The \u201cmodel_fn\u201d parameter is a function that consumes the features, labels, mode and params in the following order:", "The Estimator will always supply those parameters when it executes the model function for training, evaluation or prediction. The features parameter contains a dictionary of tensors with the features that you want to feed to your network, the labels parameter contains a dictionary of tensors with the labels you want to use for training. These two parameters are generated by the input fn which will be explained later. The third parameter mode describes whether the \u201cmodel_fn\u201d is being called for training, evaluation or prediction. The final parameter params is a simple dictionary that can contain python variables and such that can be used during network definition (think total steps for learning rate schedule etc.).", "Now that the Estimator object is initialized it can be used to start training and evaluating the network. Below is an excerpt of train.py which implements the above instructions to create an Estimator object after which it starts training and evaluating.", "This snippet of code first sets up the config dictionary for the params, and uses it together with the \u201cmodel_fn\u201d to construct an Estimator Object. It then creates a \u201cTrainSpec\u201d with an \u201cinput_fn\u201d and the \u201cmax_steps\u201d the model should train for. A similar thing is done to create the \u201cEvalSpec\u201d where the \u201csteps\u201d are the number of steps of each evaluation, and \u201cthrottle_secs\u201d defines the interval in seconds between each evaluation. The \u201ctf.estimator.train_and_evaluate\u201d is used to start the training and evaluation roster using the Estimator object, \u201cTrainSpec\u201d and \u201cEvalSpec\u201d. Finally an evaluation is explicitly called once more after the training finishes.", "In my opinion the best things about Estimators, is that you can combine them easily with the Dataset class. Before the Estimator and Dataset class combination it was hard to prefetch and process examples on the CPU asynchronously from the GPU. Prefetching and processing on the CPU would in theory make sure there would be a batch of examples ready in memory any time the GPU was done processing the previous batch, in practice this was easier said then done. The problem with just assigning the fetch and process step to CPU is that unless it is done in parallel with the model processing on the GPU, the GPU still has to wait for the CPU to fetch the data from the storage disk and process it before it can start processing the next batch. For a long time queuerunners, asynchronous prefetching using python threads and other solutions were suggested, and in my experience none of them ever worked flawlessly and efficiently.", "But using the Estimator class and combining it with the Dataset class is very easy, clean and works in parallel with the GPU. It allows the CPU to fetch, preprocess and que batches of examples such that there is always a new batch ready for the GPU. Using this method I have seen the utilization of a GPU stay close to 100% during training and global steps per second for small models(<10MB) increase 4 fold.", "The Tensorflow Dataset class is designed as an E.T.L. process, which stands for Extract, Transform and Load. These steps will be defined soon, but this guide will only explain how to use tfrecords in combination with the Dataset class. For other formats (csv, numpy etc.) this page has a good write-up, however I suggest using tfrecords as they offer better performance and are easier to integrate with a Tensorflow development pipeline.", "The whole E.T.L. process can be implemented using the Dataset class in only 7 lines of code as shown below. It might look complicated at first but read on for a detailed explanation of each lines functionality.", "The first step in a Dataset input pipeline is to load the data from the tfrecords into memory. This starts with making a list of tfrecords available using a glob pattern e.g. \u201c./Datasets/train-*.tfrecords\u201d and the list_files function of the Dataset class. The parallel_interleave function is applied to the list of files, which ensures parallel extraction of the data as explained here. Finally a merged shuffle and repeat function is used to prefetch a certain number of examples from the tfrecords and shuffle them. The repeat ensures that there are always examples available by repeating from the start once the last example of every tfrecord is read.", "Now that the data is available in memory the next step is to transform it, preferably into something that does not need any further processing in order to be fed to the neural network input. A call to the dataset\u2019s map function is required to do this as shown below, where \u201cmap_func\u201d is the function applied to every individual example on the CPU and \u201cnum_parallel_calls\u201d the number of parallel invocations of the \u201cmap_func\u201d to use.", "In this case the \u201cmap_func\u201d is the parse function shown below, this function processes an example from the tfrecords (created using this repo) and outputs a tuple of dictionaries containing tensors representing the features and labels respectively. Note the use of a lambda function to pass python variables separately from the example to the parse function, as the example is unparsed data from the tfrecord and provided by the Dataset class.", "Keep in mind that this parse function only processes one example at the time as show by the tf.parse_single_example call, but does so a number of times in parallel. To prevent running into any CPU bottlenecks it is important to keep the parse function fast, some tips on how to do this can be found here. All the individually processed examples are then batched and ready for processing.", "The final step of the ETL process is loading the batched examples onto the accelerator (GPU) ready for processing. In the Dataset class this is achieved by prefetching, which is done by calling the prefetch function of the dataset.", "Prefetching uncouples the producer (Dataset object on CPU) from the consumer (GPU), this allows them to run in parallel for increased throughput.", "Once the whole E.T.L. process is fully defined and implemented, the \u201cinput_fn\u201d can be created by initializing the iterator and grabbing the next example using the following line:", "This input function is used by the Estimator as an input for the model function.", "A quick reminder, the model function the estimator invokes during training, evaluation and prediction, should accept the following arguments as explained earlier:", "The features and labels are in this case supplied by the Dataset class, the params are mostly for hyper parameters used during network initialization, but the mode (of type \u201ctf.estimator.ModeKeys\u201d) dictates what action the model is going to be performing. Each mode is used to setup the model for that specific purpose, the available modes are prediction, training and evaluation.", "The different modes can be used by calling the respective functions (shown above) of an Estimator Object namely; \u201cpredict\u201d, \u201ctrain\u201d and \u201cevaluate\u201d. The code-path of every mode has to return an \u201cEstimatorSpec\u201d with the required fields for that mode, e.g. when the mode is predict, it has to return an \u201cEstimatorSpec\u201d that includes the predictions field:", "The most basic mode is the prediction mode \u201ctf.estimator.ModeKeys.PREDICT\u201d, which as the name suggests is used to do predictions on data using the Estimator object. In this mode the \u201cEstimatorSpec\u201d expects a dictionary of tensors which will be executed and the results of which will be made available as numpy values to python.", "In this excerpt you can see the predictions dictionary setup to generate classical image classification results. The if statement ensures that this code path is only executed when the predict function of an Estimator object is executed. The dictionary of tensors is passed to the \u201cEstimatorSpec\u201d as the predictions argument together with the mode. It is smart to define the prediction code-path first as it is the simplest, and since most of the code is used for training and evaluation as-well it can show problems early on.", "To train a model in the \u201ctf.estimator.ModeKeys.TRAIN\u201d mode it is necessary to create a so called \u201ctrain_op\u201d, this op is a tensor that when executed performs the back propagation to update the model. Simply put it is the minimize function of an optimizer such as the AdamOptimizer. The \u201ctrain_op\u201d and the scalar loss tensor are the minimum required arguments to create an \u201cEstimatorSpec\u201d for training. Below you can see an example of this being done.", "Note the non-required arguments \u201ctraining_hooks\u201d and \u201cscaffold\u201d, these will be further explained later but in short they are used to add functionality to the setup and tear-down of a model and training session.", "The final mode that needs a code-path in the model function is \u201ctf.estimator.ModeKeys.EVAL\u201d. The most important thing in order to perform an eval is the the metrics dictionary, this should be structured as a dictionary of tuples, where the first element of the tuple is a tensor containing the actual metric value and the second element is the tensor that updates the metric value. The update operation is necessary to ensure a reliable metric calculation over the whole validation set. Since it will often be impossible to evaluate the whole validation set in one batch, multiple batches have to be used. To prevent noise in the metric value due to per batch differences, the update operation is used to keep a running average (or gather all results) over all batches. This setup ensures the metric value is calculated over the whole validation set and not a single batch.", "In the example above only the \u201closs\u201d and \u201ceval_metric_ops\u201d are required arguments, the third argument \u201cevaluation_hooks\u201d is used to execute \u201ctf.summary\u201d operations as they are not automatically executed when running the Estimators evaluate function. In this example the \u201cevaluation_hooks\u201d are used to store images from the validation set to display using a Tensorboard. To achieve this a \u201cSummarySaverHook\u201d with the same output directory as the \u201cmodel_dir\u201d is initialized with a \u201ctf.summary.image\u201d operation and passed (encapsulated in an iterable) to the \u201cEstimatorSpec\u201d.", "Now that I explained the advantages of using the Estimator class and how to use it, I hope you are excited to start using Estimators for your Tensorflow projects. However switching to Estimators from an existing code-base is not necessarily straightforward. As the Estimator class abstracts away most of the initialization and execution during training, any custom initialization and execution loops can no longer be an implementation using \u201ctf.Session\u201d and \u201csess.run()\u201d. This could be a reason for someone with a large code-base not to transition to the Estimator class, as there is no easy and straightforward transition path. While this article is not a transition guide, I will clarify some of the new procedures for initialization and execution. This will hopefully fill in some of the gaps left by the official tutorials.", "The main tools to influence the initialization and execution loop are the \u201cScaffold\u201d object and the \u201cSessionRunHook\u201d object. The \u201cScaffold\u201d is used for custom first time initialization of a model and can only be used to construct an \u201cEstimatorSpec\u201d in training mode. The \u201cSessionRunHook\u201d on the other hand can be used to construct an \u201cEstimatorSpec\u201d for each execution mode and is used each time train, evaluate or predict is called. Both the \u201cScaffold\u201d and \u201cSessionRunHook\u201d provide certain functions that the Estimator class calls during use. Below you can see a timeline showing which function is called and when during the initialization and training process. This also shows that the Estimator under the hood still uses \u201ctf.Session\u201d and \u201csess.run\u201d.", "A scaffold can be passed as the scaffold argument when constructing the \u201cEstimatorSpec\u201d for training. In a scaffold you can specify a number of different operations to be called during various stages of initialization. However for now we will focus on the \u201cinit_fn\u201d argument as the others are more for distributed settings which this series will not cover. The \u201cinit_fn\u201d is called after graph finalization but before the \u201csess.run\u201d is called for the first time, it is only used once and thus perfect for custom variable initialization. A good example of this is if you want to finetune using a pretrained network and want to be selective about which variables to restore.", "Above you can see an example of this implemented, the function checks for the existence of the fine-tune checkpoint and creates an initializer function using slim that filters on the \u201cscope_name\u201d variable. This function is then encapsulated in the function format that the Estimator expects which consumes the \u201cScaffold\u201d object itself and a \u201ctf.Session\u201d object. Inside the \u201cinit_fn\u201d the session is used to run the \u201cinitializer_fn\u201d.", "This \u201cinit_fn\u201d can then be passed as an argument to construct a \u201cScaffold\u201d object, as show above. This \u201cScaffold\u201d object is used to construct the \u201cEstimatorSpec\u201d for the train mode. While this is a relatively simple example (and can also be achieved with \u201cWarmStartSettings\u201d), it can be easily expanded for more advanced onetime initialization functionality.", "As shown in the timeline earlier the \u201cSessionRunHook\u201d class can be used to alter certain parts of the training, evaluation or prediction loop. This is done using a concept known as hooking, I will not go into to much detail on what hooking is exactly as in this case it is pretty self explanatory. But using a \u201cSessionRunHook\u201d is slightly different from using a scaffold. Instead of initializing the \u201cSessionRunHook\u201d object with one or more functions as arguments it is used as a super class. It is then possible to overwrite the methods \u201cbegin\u201d, \u201cafter_create_session\u201d, \u201cbefore_run\u201d, \u201cafter_run\u201d and \u201cend\u201d, to extend functionality. Below an excerpt showing how to overwrite the \u201cbegin\u201d function is shown.", "Keep in mind that the \u201cbegin\u201d function does not get any arguments but each hook is slightly different, please refer here to check what arguments are passed to which function. Now one can create a \u201cSessionRunHook\u201d with the extended begin method by calling:", "This object can then be used when constructing an \u201cEstimatorSpec\u201d for training, evaluating and predicting by passing it to the respective arguments \u201ctraining_hooks\u201d, \u201cevaluation_hooks\u201d and \u201cprediction_hooks\u201d. Note that each arguments ends with hooks, and they expect an iterable of one or multiple hooks so always encapsulate your hooks in an iterable.", "Training and evaluation have extensively been covered, but prediction has not yet been fully explained. This is mostly because prediction is the easiest of the the 3 (train,eval,predict) Estimator modes, but there are still some pitfalls one can run into. I explained earlier how to setup an \u201cEstimatorSpec\u201d for prediction, but not how to use it. Below is a small example showing how to use an Estimator for prediction.", "For prediction it does not make sense to make/use tfrecords, so instead the \u201cnumpy_input_fn\u201d is used. To the \u201cx\u201d argument a dictionary of numpy arrays is passed containing the features, in this case an image.", "Note: Depending on whether or not you are preprocess images in the \u201cinput_fn\u201d during training, you would need to perform the same preprocessing here, either in numpy before passing to the \u201cnumpy_input_fn\u201d or in Tensorflow.", "With the numpy input function setup, a simple call to predict is enough to create a prediction. The \u201cpredictions\u201d variable in the example above will not actually contain the result yet, instead it is an object of the generator class, to get the actual result you need to iterate over the it. This iteration will start the Tensorflow execution and produce the actual result.", "I hope I was able to demystify some of the not so documented features of tensorflow Estimators and fill in the gaps left by the official tutorials. All the code in this post comes from this github repo, so please head over there for an example of Estimators used in combination with the Datasets class. If you have any more questions please leave them here, I\u2019ll try my best to answer them.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I enjoy making computers understand the world through images/video in real-time."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc9ffba3bff03&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@tijmenlv?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tijmenlv?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "Tijmen Verhulsdonck"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb2c086e7a2cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&user=Tijmen+Verhulsdonck&userId=b2c086e7a2cc&source=post_page-b2c086e7a2cc----c9ffba3bff03---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9ffba3bff03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9ffba3bff03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/learning-machine-learning/introduction-to-tensorflow-estimators-part-1-39f9eb666bc7", "anchor_text": "article"}, {"url": "https://github.com/Timen/squeezenext-tensorflow", "anchor_text": "SqueezeNext-Tensorflow"}, {"url": "https://arxiv.org/pdf/1803.10615.pdf", "anchor_text": "SqueezeNext"}, {"url": "https://github.com/amirgholami/SqueezeNext", "anchor_text": "caffe"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/train.py", "anchor_text": "train.py"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/train.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/train.py"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data/Dataset", "anchor_text": "Dataset class"}, {"url": "https://en.wikipedia.org/wiki/Extract,_transform,_load", "anchor_text": "E.T.L"}, {"url": "https://www.tensorflow.org/guide/datasets", "anchor_text": "write-up"}, {"url": "https://www.tensorflow.org/performance/performance_guide", "anchor_text": "performance"}, {"url": "http://blog.appliedinformaticsinc.com/etl-extract-transform-and-load-process-concept/", "anchor_text": "http://blog.appliedinformaticsinc.com/etl-extract-transform-and-load-process-concept/"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/dataloader.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/dataloader.py"}, {"url": "https://www.tensorflow.org/performance/datasets_performance", "anchor_text": "here"}, {"url": "https://github.com/tensorflow/models/tree/master/research/inception/inception/data", "anchor_text": "repo"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/dataloader.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/dataloader.py"}, {"url": "https://www.tensorflow.org/performance/performance_guide", "anchor_text": "here"}, {"url": "https://k-d-w.org/blog/103/denoising-autoencoder-as-tensorflow-estimator", "anchor_text": "https://k-d-w.org/blog/103/denoising-autoencoder-as-tensorflow-estimator"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/squeezenext_model.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/squeezenext_model.py"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer", "anchor_text": "AdamOptimizer"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/squeezenext_model.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/squeezenext_model.py"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/squeezenext_model.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/squeezenext_model.py"}, {"url": "https://www.tensorflow.org/guide/estimators", "anchor_text": "tutorials"}, {"url": "https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/train/Scaffold", "anchor_text": "scaffold"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/tools/fine_tune.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/tools/fine_tune.py"}, {"url": "https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/estimator/WarmStartSettings", "anchor_text": "\u201cWarmStartSettings\u201d"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook", "anchor_text": "SessionRunHook"}, {"url": "https://en.wikipedia.org/wiki/Hooking", "anchor_text": "hooking"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/tools/stats.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/tools/stats.py"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook", "anchor_text": "here"}, {"url": "https://github.com/Timen/squeezenext-tensorflow/blob/master/predict.py", "anchor_text": "https://github.com/Timen/squeezenext-tensorflow/blob/master/predict.py"}, {"url": "https://github.com/Timen/squeezenext-tensorflow", "anchor_text": "github repo"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c9ffba3bff03---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----c9ffba3bff03---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/estimators?source=post_page-----c9ffba3bff03---------------estimators-----------------", "anchor_text": "Estimators"}, {"url": "https://medium.com/tag/squeezenext?source=post_page-----c9ffba3bff03---------------squeezenext-----------------", "anchor_text": "Squeezenext"}, {"url": "https://medium.com/tag/software-engineering?source=post_page-----c9ffba3bff03---------------software_engineering-----------------", "anchor_text": "Software Engineering"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc9ffba3bff03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&user=Tijmen+Verhulsdonck&userId=b2c086e7a2cc&source=-----c9ffba3bff03---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc9ffba3bff03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&user=Tijmen+Verhulsdonck&userId=b2c086e7a2cc&source=-----c9ffba3bff03---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9ffba3bff03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc9ffba3bff03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c9ffba3bff03---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c9ffba3bff03--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tijmenlv?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tijmenlv?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tijmen Verhulsdonck"}, {"url": "https://medium.com/@tijmenlv/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "92 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb2c086e7a2cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&user=Tijmen+Verhulsdonck&userId=b2c086e7a2cc&source=post_page-b2c086e7a2cc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fb2c086e7a2cc%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03&user=Tijmen+Verhulsdonck&userId=b2c086e7a2cc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}