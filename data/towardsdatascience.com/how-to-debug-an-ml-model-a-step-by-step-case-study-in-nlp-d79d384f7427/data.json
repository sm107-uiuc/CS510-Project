{"url": "https://towardsdatascience.com/how-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427", "time": 1683009703.059135, "path": "towardsdatascience.com/how-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427/", "webpage": {"metadata": {"title": "How to Debug a ML Model: A Step-by-Step Case Study in NLP | by Yada Pruksachatkun | Towards Data Science", "h1": "How to Debug a ML Model: A Step-by-Step Case Study in NLP", "description": "Not to worry! This article will go through the debugging process of a pretty subtle (and not so subtle) series of bugs, and how we fixed them, with a case study to walk you through the lessons. If\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270", "anchor_text": "masked language modeling", "paragraph_index": 1}, {"url": "http://jiant.info", "anchor_text": "jiant", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a", "anchor_text": "transfer learning and multitask learning,", "paragraph_index": 1}, {"url": "https://medium.com/towards-artificial-intelligence/a-robustly-optimized-bert-pretraining-approach-f6b6e537e6a6", "anchor_text": "RoBERTa model.", "paragraph_index": 1}, {"url": "https://github.com/google-research/bert/blob/master/create_pretraining_data.py", "anchor_text": "original implementation", "paragraph_index": 4}, {"url": "https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py", "anchor_text": "Huggingface implementatio", "paragraph_index": 4}, {"url": "https://huggingface.co/transformers/model_doc/bert.html#bertformaskedlm", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://github.com/allenai/allennlp/blob/master/allennlp/data/vocabulary.py#L97", "anchor_text": "utomatically inserts", "paragraph_index": 17}, {"url": "https://github.com/nyu-mll/jiant/blob/master/jiant/tasks/lm.py#L323", "anchor_text": "t here!", "paragraph_index": 24}], "all_paragraphs": ["Not to worry! This article will go through the debugging process of a pretty subtle (and not so subtle) series of bugs, and how we fixed them, with a case study to walk you through the lessons. If you would like to just see a bulleted list of tips, scroll down to the end!", "In order to do that, let me take you back a few months, to when we (my research collaborator Phu and I) were first implementing masked language modeling into jiant, which is an opensource NLP framework, with the goal of doing multi task training on a RoBERTa model. If this sounds like an alien language to you, I would first suggest you look into this article on transfer learning and multitask learning, and this article about the RoBERTa model.", "Masked language modeling is one of the pretraining objectives in BERT, RoBERTa, and many BERT-style variants. It consists of an input-noising objective, where given a text, the model has to predict 15% of the tokens given the context. To make things harder, these predicted tokens are 80% of the time replaced by \u201c[MASK]\u201d, 10% by another random token, and 10% is the correct, unreplaced token.", "For example, the model will be shown the below", "We first looked into if other people had implemented MLM before, and found the original implementation by Google, and a Pytorch implementation by AllenNLP. We used mostly all of the Huggingface implementation (which has been moved since, since it seems like the file that used to be there no longer exists) for the forward function. Following the RoBERTa paper, we dynamically masked the batch at each time step. Furthermore, Huggingface exposes the pretrained MLM head here, which we utilized as below.", "Thus, the MLM flow in our code became the below:", "Load MLM data -> Preprocess and index data -> Load model -> In each step of the model training, we:", "2. Compute NLL loss for each masked token", "The jiant framework uses primarily AllenNLP for vocabulary creation and indexing, as well as instance and dataset management.", "We first tested with a toy dataset of 100 dataset examples to make sure the loading was correct with AllenNLP. After we went through some pretty explicit bugs, such as some label type mismatch with AllenNLP, we came upon a bigger bug.", "After making sure our preprocessing code worked with AllenNLP, we found a strange bug.", "This was because the code we copy-pasted from Huggingface was written with an older version of Python, and in the Pytorch you needed to use .byte() instead of bool() .", "Thus, we simply changed one line, from", "Now, finally, we were able to run a forward function without erroring out! After a few minutes of celebration, we got to work verifying more subtle bugs. We first tested the correctness of our implementation by calling model.eval() and running the model through the MLM forward functions. Since the model, in this case RoBERTa-large, has been pretrained with MLM, we would expect it to do very well on MLM. That was not the case, and we were getting very high losses.", "It became clear why: the predictions were always 2 off from the gold labels. For example, if the token \u201ctail\u201d was assigned index 25, the label for \u201cdog wagged its [MASK] when it saw the treat\u201d and \u201c[MASK]\u201d would be 25, but the prediction would be 27.", "We only discovered this after hitting this error.", "This error meant that the prediction space was larger than the number of classes.", "After a lot of pdb tracing, we realized that we weren\u2019t using AllenNLP tag/label namespace. In AllenNLP, you can keep track of all the vocabularies you need in an AllenNLP Vocabulary object using namespaces such as the label namespace and input namespace. We found that AllenNLP vocabulary object automatically inserts @@PADDING@@ and @@UNKOWN@@ tokens to index 0 and 1 for all namespaces except for label namespaces (which are all those ending in \u201c_tag\u201d or \u201c_labels.\u201d Since we did not use the label namespace, our indices were being shifted forward by two, and the prediction space (defined by the label vocabulary size) was larger by 2! After finding this out, we renamed the label index and this particular threat was curbed.", "By this point, we had thought we had caught all or most of the bugs, and that MLM was working correctly. However, while the model was getting low perplexity now, a week later, while looking through the code with a third person, we found another hidden bug.", "Somewhere buried in a separate part of the code, which we had written a few months back, we had shifted the inputs of any Transformer-based model back by 2, since AllenNLP shifted it forward by 2. Thus, essentially the model was seeing gibberish, since it was seeing whatever vocabulary tokens were two indices away from the correct inputs\u2019 indices.", "We ended up reversing a previous fix for a previous bug and not using the label namespace for inputs, since everything was shifted back by 2 anyhow. and simply making sure that the dynamically generated mask_idx is shifted forward by 2 before being fed into the model. In order to fix the previous error with mismatch between prediction and label space sizes, we made the number of labels the size of the pretrained model\u2019s tokenizer, since that includes all of the vocabulary that that model was pretrained on.", "After many countless hours debugging and running preliminary experiments, we were finally out of bugs. Phew!", "So just as a recap of things we did to make sure the code was bug free, and to also recap the types of bugs we saw, here\u2019s a nifty list.", "And there you have it, a debugging case study and some lessons. We\u2019re all on a journey to get better at debugging together, and I know that I\u2019m far from an expert at model debugging, but hopefully this post was helpful for you! Special thanks to Phu Mon Htut for editing this post.", "If you\u2019d like to see the final implementation, check it out here!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Graduate Student @ NYU CDS, previously @Facebook @MIT Media Lab @FinExploration. I write about machine learning and life. \u0e04\u0e19\u0e40\u0e0a\u0e35\u0e22\u0e07\u0e43\u0e2b\u0e21\u0e48"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd79d384f7427&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d79d384f7427--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d79d384f7427--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@yadapruksachatkun?source=post_page-----d79d384f7427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yadapruksachatkun?source=post_page-----d79d384f7427--------------------------------", "anchor_text": "Yada Pruksachatkun"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7703426e09ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&user=Yada+Pruksachatkun&userId=7703426e09ed&source=post_page-7703426e09ed----d79d384f7427---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd79d384f7427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd79d384f7427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/StockSnap-894430/", "anchor_text": "StockSnap"}, {"url": "https://pixabay.com/users/Free-Photos-242387/", "anchor_text": "Free-Photo"}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270", "anchor_text": "masked language modeling"}, {"url": "http://jiant.info", "anchor_text": "jiant"}, {"url": "https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a", "anchor_text": "transfer learning and multitask learning,"}, {"url": "https://medium.com/towards-artificial-intelligence/a-robustly-optimized-bert-pretraining-approach-f6b6e537e6a6", "anchor_text": "RoBERTa model."}, {"url": "https://github.com/google-research/bert/blob/master/create_pretraining_data.py", "anchor_text": "original implementation"}, {"url": "https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py", "anchor_text": "Huggingface implementatio"}, {"url": "https://huggingface.co/transformers/model_doc/bert.html#bertformaskedlm", "anchor_text": "here"}, {"url": "https://github.com/allenai/allennlp/blob/master/allennlp/data/vocabulary.py#L97", "anchor_text": "utomatically inserts"}, {"url": "https://github.com/nyu-mll/jiant/blob/master/jiant/tasks/lm.py#L323", "anchor_text": "t here!"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d79d384f7427---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d79d384f7427---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----d79d384f7427---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/technology?source=post_page-----d79d384f7427---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/nlp?source=post_page-----d79d384f7427---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd79d384f7427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&user=Yada+Pruksachatkun&userId=7703426e09ed&source=-----d79d384f7427---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd79d384f7427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&user=Yada+Pruksachatkun&userId=7703426e09ed&source=-----d79d384f7427---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd79d384f7427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d79d384f7427--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd79d384f7427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d79d384f7427---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d79d384f7427--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d79d384f7427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d79d384f7427--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d79d384f7427--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d79d384f7427--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d79d384f7427--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d79d384f7427--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d79d384f7427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yadapruksachatkun?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yadapruksachatkun?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yada Pruksachatkun"}, {"url": "https://medium.com/@yadapruksachatkun/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "241 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7703426e09ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&user=Yada+Pruksachatkun&userId=7703426e09ed&source=post_page-7703426e09ed--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5918775dd734&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-debug-an-ml-model-a-step-by-step-case-study-in-nlp-d79d384f7427&newsletterV3=7703426e09ed&newsletterV3Id=5918775dd734&user=Yada+Pruksachatkun&userId=7703426e09ed&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}