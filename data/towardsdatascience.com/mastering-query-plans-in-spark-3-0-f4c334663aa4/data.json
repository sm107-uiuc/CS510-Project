{"url": "https://towardsdatascience.com/mastering-query-plans-in-spark-3-0-f4c334663aa4", "time": 1683010256.5746481, "path": "towardsdatascience.com/mastering-query-plans-in-spark-3-0-f4c334663aa4/", "webpage": {"metadata": {"title": "Mastering Query Plans in Spark 3.0 | by David Vrba | Towards Data Science", "h1": "Mastering Query Plans in Spark 3.0", "description": "In Spark SQL the query plan is the entry point for understanding the details about the query execution. It carries lots of useful information and provides insights about how the query will be\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/should-i-repartition-836f7842298c", "anchor_text": "article", "paragraph_index": 19}, {"url": "https://towardsdatascience.com/about-joins-in-spark-3-0-1e0ea083ea86", "anchor_text": "article", "paragraph_index": 20}], "all_paragraphs": ["In Spark SQL the query plan is the entry point for understanding the details about the query execution. It carries lots of useful information and provides insights about how the query will be executed. This is very important especially in heavy workloads or whenever the execution takes to long and becomes costly. Based on the information from the query plan we may find out what is not efficient and decide to rewrite part of the query to achieve better performance.", "For someone not familiar with query plans, at first sight, the information may look a bit cryptic. It has a structure of a tree and each node represents an operator that provides some basic details about the execution. The official Spark documentation which is otherwise nicely written and very informative becomes insufficient when it comes to execution plans. The motivation for this article is to provide some familiarity with the physical plans, we will take a tour of some of the most frequently used operators and explain what information they provide and how it can be interpreted.", "The theory presented here is based mostly on the study of the Spark source code and on the practical experience with running and optimizing Spark queries on daily basis.", "For the sake of simplicity let\u2019s consider a query in which we apply a filter, carry out an aggregation, and join with another DataFrame:", "You can think about the data in this example in such a way that usersDF is a set of users that are asking questions that are represented by questionsDF. The questions are partitioned by the year column which is a year when the question was asked. In the query, we are interested in questions asked in 2019 and for each user, we want to know how many questions he/she asked. Also for each user, we want to have some additional information in the output, that is why we join with the usersDF after the aggregation.", "There are two basic ways how to see the physical plan. The first one is by calling explain function on a DataFrame which shows a textual representation of the plan:", "There have been some improvements in Spark 3.0 in this regard and the explain function now takes a new argument mode. The value of this argument can be one of the following: formatted, cost, codegen. Using the formatted mode converts the query plan to a better organized output (here only part of the plan is displayed):", "So in the formatted plan, you can see the \u201cnaked\u201d tree which has only the names of the operators with a number in parenthesis. Below the tree, there is then a detailed description of each operator referenced by the number. The cost mode will show besides the physical plan also the optimized logical plan with the statistics for each operator so you can see what are the estimates for the data size at different steps of execution. Finally, the codegen mode shows the generated java code that will be executed.", "The second option to see the plan is going to the SQL tab in Spark UI where are lists of all running and finished queries. By clicking on your query you will see the graphical representation of the physical plan. In the picture below I combined the graphical representation with the formatted textual tree to see how they correspond to each other:", "The difference here is that the graphical representation has the leaf nodes on the top and the root is at the bottom, while the textual tree is upside down.", "In the graphical representation of the physical plan, you can see that the operators are grouped into big blue rectangles. These big rectangles correspond to codegen stages. It is an optimization feature, which takes place in the phase of physical planning. There is a rule called CollapseCodegenStages which is responsible for that and the idea is to take operators that support code generation and collapse it together to speed-up the execution by eliminating virtual function calls. Not all operators support code generation, so some operators (for instance Exchange) are not part of the big rectangles. In our example, there are three codegen stages that correspond to three big rectangles and in the formatted plan output, you can see the id of the codegen stage in the brackets at the operator. Also from the tree, you can tell if an operator supports the codegen or not because there is an asterisk with corresponding stage codegen id in the parenthesis if the codegen is supported.", "Let\u2019s now briefly describe how to interpret each of the operators in our query plan.", "The Scan parquet operator represents reading the data from a parquet file format. From the detailed information, you can directly see what columns will be selected from the source. Even though we do not select specific fields in our query, there is a ColumnPruning rule in the optimizer that will be applied and it makes sure that only those columns that are actually needed will be selected from the source. We can also see here two types of filters: PartitionFilters and PushedFilters. The PartitionFilters are filters that are applied on columns by which the datasource is partitioned in the file system. These are very important because they allow for skipping the data that we don\u2019t need. It is always good to check whether the filters are propagated here correctly. The idea behind this is to read as little data as possible since the I/O is expensive. In Spark 2.4 there was also a field partitionCount which was the number of partitions that are actually scanned, but this field is no longer present in Spark 3.0.", "The PushedFilters are on the other hand filters on fields that can be pushed directly to parquet files and they can be useful if the parquet file is sorted by these filtered columns because in that case, we can leverage the internal parquet structure for data skipping as well. The parquet file is composed of row groups and the footer of the file contains metadata about each of these row groups. This metadata contains also statistical information such as min and max value for each row group and based on this information Spark can decide whether it will read the row group or not.", "The Filter operator is quite intuitive to understand, it simply represents the filtering condition. What may not be so obvious is how the operator was created because very often it doesn\u2019t directly correspond to the filtering condition used in the query. The reason for that is that all the filters are first processed by the Catalyst optimizer which may modify and relocate them. There are several rules applied to the logical filters before they are converted to a physical operator. Let\u2019s list a couple of the rules here:", "This operator simply represents what columns will be projected (selected). Each time we call select, withColumn, or drop transformations on a DataFrame, Spark will add the Project operator to the logical plan which is then converted to its counterpart in the physical plan. Again there are some optimization rules applied to it before it is converted:", "The Exchange operator represents shuffle, which is a physical data movement on the cluster. This operation is considered to be quite expensive because it moves the data over the network. The information in the query plan contains also details about how the data will be repartitioned. In our example, it is hashpartitioning(user_id, 200) as you can see below:", "This means that the data will be repartitioned according to the user_id column into 200 partitions and all rows with the same value of user_id will belong to the same partition and will be located on the same executor. To make sure that exactly 200 partitions are created, Spark will always compute the hash of the user_id and then will compute positive modulo 200. The consequence of this is that more different user_ids will be located in the same partition. And what can also happen is that some partitions can become empty. There are other types of partitioning worth to mention:", "This operator represents data aggregation. It usually comes in pair of two operators which may or may not be divided by an Exchange as you can see here:", "To understand better the logic behind the Exchange in these situations you can check my previous article about data distribution in Spark SQL where I describe it in detail. The reason for having two HashAggregate operators is that the first one does a partial aggregation, which aggregates separately each partition on each executor. In our example, you can see in the Functions field that it says partial_count(1). The final merge of the partial results follows in the second HashAggregate. The operator also has the Keys field which shows the columns by which the data is grouped. The Results field shows the columns that are available after the aggregation.", "The BroadcastHashJoin (BHJ) is an operator that represents a specific joining algorithm. Apart from this one, there are also other joining algorithms available in Spark such as SortMergeJoin or ShuffleHashJoin and to read more about them you can check my other article about joins in Spark 3.0. The BHJ always comes in a pair with BroadcastExchange which is an operator that represents the broadcasted shuffle \u2014 the data will be collected to the driver and then send over to each executor where it will be available for the join.", "This is a new operator introduced in Spark 3.0 and it is used as a transition between columnar and row execution.", "The physical plans in Spark SQL are composed of operators that carry useful information about the execution. Having a proper understanding of each operator may help to get insights about the execution and by analyzing the plan we may discover what is not optimal and possibly try to fix it.", "In this article, we described a set of operators that are frequently used in Spark physical plans. The set is by no means complete but we tried to focus on operators that are commonly used and very likely to be present in plans of basic analytical queries.", "Senior ML Engineer at Sociabakers and Apache Spark trainer and consultant. I lecture Spark trainings, workshops and give public talks related to Spark."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff4c334663aa4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@vrba.dave?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "David Vrba"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7f216c64e33&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&user=David+Vrba&userId=b7f216c64e33&source=post_page-b7f216c64e33----f4c334663aa4---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff4c334663aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&user=David+Vrba&userId=b7f216c64e33&source=-----f4c334663aa4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4c334663aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&source=-----f4c334663aa4---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/should-i-repartition-836f7842298c", "anchor_text": "article"}, {"url": "https://towardsdatascience.com/about-joins-in-spark-3-0-1e0ea083ea86", "anchor_text": "article"}, {"url": "https://medium.com/tag/spark-sql?source=post_page-----f4c334663aa4---------------spark_sql-----------------", "anchor_text": "Spark Sql"}, {"url": "https://medium.com/tag/apache-spark?source=post_page-----f4c334663aa4---------------apache_spark-----------------", "anchor_text": "Apache Spark"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----f4c334663aa4---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f4c334663aa4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/query-optimization?source=post_page-----f4c334663aa4---------------query_optimization-----------------", "anchor_text": "Query Optimization"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff4c334663aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&user=David+Vrba&userId=b7f216c64e33&source=-----f4c334663aa4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff4c334663aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&user=David+Vrba&userId=b7f216c64e33&source=-----f4c334663aa4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4c334663aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7f216c64e33&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&user=David+Vrba&userId=b7f216c64e33&source=post_page-b7f216c64e33----f4c334663aa4---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F83cdb92c0d8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&newsletterV3=b7f216c64e33&newsletterV3Id=83cdb92c0d8c&user=David+Vrba&userId=b7f216c64e33&source=-----f4c334663aa4---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Written by David Vrba"}, {"url": "https://medium.com/@vrba.dave/followers?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "2K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7f216c64e33&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&user=David+Vrba&userId=b7f216c64e33&source=post_page-b7f216c64e33----f4c334663aa4---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F83cdb92c0d8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-query-plans-in-spark-3-0-f4c334663aa4&newsletterV3=b7f216c64e33&newsletterV3Id=83cdb92c0d8c&user=David+Vrba&userId=b7f216c64e33&source=-----f4c334663aa4---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34?source=author_recirc-----f4c334663aa4----0---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=author_recirc-----f4c334663aa4----0---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=author_recirc-----f4c334663aa4----0---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "David Vrba"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f4c334663aa4----0---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34?source=author_recirc-----f4c334663aa4----0---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Best practices for caching in Spark SQLDeep dive into data persistence in Spark."}, {"url": "https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34?source=author_recirc-----f4c334663aa4----0---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "\u00b710 min read\u00b7Jul 20, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&user=David+Vrba&userId=b7f216c64e33&source=-----b22fb0f02d34----0-----------------clap_footer----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34?source=author_recirc-----f4c334663aa4----0---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb22fb0f02d34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-caching-in-spark-sql-b22fb0f02d34&source=-----f4c334663aa4----0-----------------bookmark_preview----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f4c334663aa4----1---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f4c334663aa4----1---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f4c334663aa4----1---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f4c334663aa4----1---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f4c334663aa4----1---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f4c334663aa4----1---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f4c334663aa4----1---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----f4c334663aa4----1-----------------bookmark_preview----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f4c334663aa4----2---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f4c334663aa4----2---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f4c334663aa4----2---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f4c334663aa4----2---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f4c334663aa4----2---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f4c334663aa4----2---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f4c334663aa4----2---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----f4c334663aa4----2-----------------bookmark_preview----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/best-practices-for-bucketing-in-spark-sql-ea9f23f7dd53?source=author_recirc-----f4c334663aa4----3---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=author_recirc-----f4c334663aa4----3---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=author_recirc-----f4c334663aa4----3---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "David Vrba"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f4c334663aa4----3---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/best-practices-for-bucketing-in-spark-sql-ea9f23f7dd53?source=author_recirc-----f4c334663aa4----3---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "Best Practices for Bucketing in Spark SQLThe ultimate guide to bucketing in Spark."}, {"url": "https://towardsdatascience.com/best-practices-for-bucketing-in-spark-sql-ea9f23f7dd53?source=author_recirc-----f4c334663aa4----3---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": "\u00b721 min read\u00b7Apr 25, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea9f23f7dd53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-bucketing-in-spark-sql-ea9f23f7dd53&user=David+Vrba&userId=b7f216c64e33&source=-----ea9f23f7dd53----3-----------------clap_footer----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/best-practices-for-bucketing-in-spark-sql-ea9f23f7dd53?source=author_recirc-----f4c334663aa4----3---------------------67f3b5bb_5895_4034_bd90_4b957f9ddadb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea9f23f7dd53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-bucketing-in-spark-sql-ea9f23f7dd53&source=-----f4c334663aa4----3-----------------bookmark_preview----67f3b5bb_5895_4034_bd90_4b957f9ddadb-------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "See all from David Vrba"}, {"url": "https://towardsdatascience.com/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Pier Paolo Ippolito"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Apache Spark Optimization TechniquesA review of some of the most common Spark performance problems and how to address them"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=-----fa7f20a9a2cf----0-----------------clap_footer----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&source=-----f4c334663aa4----0-----------------bookmark_preview----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----f4c334663aa4----1-----------------bookmark_preview----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://julianwest155.medium.com/?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://julianwest155.medium.com/?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Julian West"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Unit testing PySpark code using PytestWhen it comes to writing unit-tests for PySpark pipelines, writing focussed, fast, isolated and concise tests can be a challenge."}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "\u00b710 min read\u00b7Jan 16"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb5ab2fd54415&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funit-testing-pyspark-code-using-pytest-b5ab2fd54415&user=Julian+West&userId=257ac04bf615&source=-----b5ab2fd54415----0-----------------clap_footer----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----f4c334663aa4----0---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5ab2fd54415&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funit-testing-pyspark-code-using-pytest-b5ab2fd54415&source=-----f4c334663aa4----0-----------------bookmark_preview----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/building-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://medium.com/@vrba.dave?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "David Vrba"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/building-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Building a Data Lake on PB scale with Apache SparkHow we deal with Big Data at Emplifi"}, {"url": "https://towardsdatascience.com/building-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "\u00b715 min read\u00b7Jan 26"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1622d7073d46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46&user=David+Vrba&userId=b7f216c64e33&source=-----1622d7073d46----1-----------------clap_footer----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/building-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46?source=read_next_recirc-----f4c334663aa4----1---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1622d7073d46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-data-lake-on-pb-scale-with-apache-spark-1622d7073d46&source=-----f4c334663aa4----1-----------------bookmark_preview----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----f4c334663aa4----2---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----f4c334663aa4----2---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----f4c334663aa4----2---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Anuj Syal"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----f4c334663aa4----2---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----f4c334663aa4----2---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "12 Must-Have Skills to become a Data EngineerThe Essential Skills for a Successful Data Engineering Career"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----f4c334663aa4----2---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "\u00b78 min read\u00b7Jan 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&user=Anuj+Syal&userId=df3997c527b4&source=-----35b100dbee0a----2-----------------clap_footer----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----f4c334663aa4----2---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&source=-----f4c334663aa4----2-----------------bookmark_preview----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://medium.com/data-engineering-space/interested-in-becoming-a-data-engineer-a-glimpse-of-the-data-engineering-career-a7b35e68f5ba?source=read_next_recirc-----f4c334663aa4----3---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://chengzhizhao.medium.com/?source=read_next_recirc-----f4c334663aa4----3---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://chengzhizhao.medium.com/?source=read_next_recirc-----f4c334663aa4----3---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Chengzhi Zhao"}, {"url": "https://medium.com/data-engineering-space?source=read_next_recirc-----f4c334663aa4----3---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Data Engineering Space"}, {"url": "https://medium.com/data-engineering-space/interested-in-becoming-a-data-engineer-a-glimpse-of-the-data-engineering-career-a7b35e68f5ba?source=read_next_recirc-----f4c334663aa4----3---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "Interested in Becoming a Data Engineer? A Glimpse of the Data Engineering CareerHow to Get Data Engineering Opportunity in 2023"}, {"url": "https://medium.com/data-engineering-space/interested-in-becoming-a-data-engineer-a-glimpse-of-the-data-engineering-career-a7b35e68f5ba?source=read_next_recirc-----f4c334663aa4----3---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": "\u00b76 min read\u00b7Jan 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-engineering-space%2Fa7b35e68f5ba&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-engineering-space%2Finterested-in-becoming-a-data-engineer-a-glimpse-of-the-data-engineering-career-a7b35e68f5ba&user=Chengzhi+Zhao&userId=f956c63a9571&source=-----a7b35e68f5ba----3-----------------clap_footer----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://medium.com/data-engineering-space/interested-in-becoming-a-data-engineer-a-glimpse-of-the-data-engineering-career-a7b35e68f5ba?source=read_next_recirc-----f4c334663aa4----3---------------------a079ead5_a4f2_4d7e_9524_d280df2cb307-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7b35e68f5ba&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-engineering-space%2Finterested-in-becoming-a-data-engineer-a-glimpse-of-the-data-engineering-career-a7b35e68f5ba&source=-----f4c334663aa4----3-----------------bookmark_preview----a079ead5_a4f2_4d7e_9524_d280df2cb307-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----f4c334663aa4--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}