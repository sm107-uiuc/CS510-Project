{"url": "https://towardsdatascience.com/generating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320", "time": 1682996979.338933, "path": "towardsdatascience.com/generating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320/", "webpage": {"metadata": {"title": "Generating optical flow using NVIDIA flownet2-pytorch implementation | by Mark Gituma | Towards Data Science", "h1": "Generating optical flow using NVIDIA flownet2-pytorch implementation", "description": "This blog was originally published in blog.dancelogue.com. In a previous post, an introduction to optical flow was conducted, as well an overview of it\u2019s architecture based on the FlowNet 2.o paper\u2026"}, "outgoing_paragraph_urls": [{"url": "https://blog.dancelogue.com/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/", "anchor_text": "blog.dancelogue.com", "paragraph_index": 0}, {"url": "https://blog.dancelogue.com/what-is-optical-flow-and-why-does-it-matter/", "anchor_text": "post", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1612.01925", "anchor_text": "FlowNet 2.o paper", "paragraph_index": 0}, {"url": "https://github.com/dancelogue/flownet2-pytorch", "anchor_text": "fork", "paragraph_index": 0}, {"url": "https://github.com/NVIDIA/flownet2-pytorch", "anchor_text": "NVIDIA flownet2-pytorch", "paragraph_index": 0}, {"url": "https://github.com/dancelogue/flownet2-pytorch", "anchor_text": "Dancelogue linked repo", "paragraph_index": 0}, {"url": "https://github.com/NVIDIA/nvidia-docker", "anchor_text": "nvidia-docke", "paragraph_index": 3}, {"url": "https://github.com/dancelogue/flownet2-pytorch", "anchor_text": "https://github.com/dancelogue/flownet2-pytorch", "paragraph_index": 7}, {"url": "https://dancelogue.s3.amazonaws.com/open_source/datasets/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/000835.flo", "anchor_text": "link", "paragraph_index": 15}, {"url": "http://vision.middlebury.edu/flow/code/flow-code/README.txt", "anchor_text": "http://vision.middlebury.edu/flow/code/flow-code/README.txt", "paragraph_index": 18}, {"url": "https://github.com/georgegach/flowiz/blob/master/flowiz/flowiz.py#L25", "anchor_text": "https://github.com/georgegach/flowiz/blob/master/flowiz/flowiz.p", "paragraph_index": 19}, {"url": "https://github.com/georgegach/flowiz", "anchor_text": "https://github.com/georgegach/flowiz", "paragraph_index": 23}, {"url": "https://blog.dancelogue.com/what-is-optical-flow-and-why-does-it-matter/", "anchor_text": "previous blog", "paragraph_index": 25}, {"url": "https://github.com/dancelogue/flownet2-pytorch/blob/master/datasets.py#L320", "anchor_text": "codebase", "paragraph_index": 31}, {"url": "https://github.com/georgegach/flow2image", "anchor_text": "flowviz repository", "paragraph_index": 33}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark", "paragraph_index": 38}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark", "paragraph_index": 39}], "all_paragraphs": ["This blog was originally published in blog.dancelogue.com. In a previous post, an introduction to optical flow was conducted, as well an overview of it\u2019s architecture based on the FlowNet 2.o paper. This blog will focus in going deeper into optical flow, which will be done by generating optical flow files both from the standard Sintel data and a custom dance video. It will be conducted using a fork of the NVIDIA flownet2-pytorch code base which can be found in the Dancelogue linked repo.", "The goal of this blog is to:", "The flownet2-pytorch implementation has been designed to work with a GPU. Unfortunately, it means if you don\u2019t have access to one it will not be possible to follow this blog completely. In order to mitigate this problem, sample data generated by the model is provided and allows the reader to follow through with the rest of the blog.", "The rest of this tutorial is conducted using ubuntu 18.04 with a NVIDIA GEFORCE GTX 1080 Ti GPU. Docker is required and must be GPU enabled which can be done using the the nvidia-docker package.", "Here is a list of all the code and data required so as to follow through with the blog (downloading the data has been automated so the reader doesn\u2019t have to do it manually, please see the Getting Started section):", "The memory space requirements required to follow through with this blog is approximately 32 GB. The reason for this will be explained later on.", "As mentioned, a fork of the original flownet2-pytorch was created, and it\u2019s because at the time of the writing of this blog, the original repository had issues when building and running the docker image e.g. python package version issues, c libraries compile issues etc. The updates include:", "With this in mind, let\u2019s get started. The first thing is to clone the dancelogue fork of the original repository from https://github.com/dancelogue/flownet2-pytorch. Then run the docker script using the following command:", "It should take a few minutes to set up, after which, it should change the terminal context to the docker session.", "The next thing is to download the relevant datasets, all the required data for the initial setup can be achieved by running the following command within the docker context:", "This downloads the FlowNet2_checkpoint.pth.tar model weights to the models folder, as well as the MPI-Sintel data to the datasets folder. This is required in order to follow the instructions for the inference example as indicated in the flownet2-pytorch getting started guide. The custom dance video is also downloaded as well as a sample optical flow .flo file.", "The rest of the commands in this blog have been automated and can be run by the following:", "The command to run the original inference example is as follows:", "However based on the fork, this has modified to:", "Running the above command saves the generated optical flow files into the datasets/sintel/output/inference/run.epoch-0-flow-field folder. The generated optical flow files have the extension .flo which are the flow fields representations.", "Now that the optical flow files have been generated, it\u2019s time to analyze the structure in order get a better understanding of the result, as well as convert them to the flow field color coding scheme. The sample flow file used in this section can be downloaded from the following link.", "Loading an optical flow file into numpy is a fairly trivial process, which can be conducted as follows:", "The above syntax is based on python3, where the file is loaded into a buffer and then fed into numpy. The next thing is trying to understand the basic features of the flow file which is achieved by the print statement. Assuming you are following with the sample flow file that was provided, the print statement should output(786435,). The implication is that for each flow file, it contains a single array with 786453 elements in the array. The memory footprint of a single flow file is approximately 15.7 MB, which even though looks trivial, increases quite quickly especially when looking at video with thousands of frames.", "Before proceeding further we need to look at the optical flow specification as defined in http://vision.middlebury.edu/flow/code/flow-code/README.txt. What we care about is the following:", "Based on the above specification, the following code will allow us to read the flow file correctly (borrowed from https://github.com/georgegach/flowiz/blob/master/flowiz/flowiz.py).", "Based on the optical flow format specification, hopefully the above code should make more sense about what\u2019s happening i.e. we get the tag, then the width, followed by height. The output of the print statement is tag 202021.25 width 1024 height 384. From the given specification we can see that the tag matches the sanity check value, the width of the flow file is 1024 and the height is 384. Note, it is important to have the correct order when reading the file buffer and loading it into numpy, this is due to the way the files are read in python (bytes are read sequentially) otherwise the tag, height and width can get mixed up. Now that we have the width and the height, we can read the rest of the optical flow data and resize into a shape that's more familiar, which is done using the np.resize method.", "A quick way to understand how the flow vectors have been resized is to print them to the terminal, this is done by running the following code:", "As we expect the shape of the new representation implies a height of 384, a width of 1024 and has a displacement vector consisting of 2 values. Focusing on the pixel at location 0, 0 we can see the displacement vector at that point seems to be pointing to the left and to the bottom i.e. the bottom left quadrant of an x, y plot, which means we expect the color code for this location to be a light blue or even a green color based on the color coding scheme given below.", "There are quite a few open source code bases written to visualize optical flow files. The one chosen for this purpose can be found in the github repository https://github.com/georgegach/flowiz. The reason for this is that it allows the generation of video clips from the color coding scheme which will be useful at a later stage. Assuming the docker context provided at the beginning of this tutorial is used, the following command can be used to generate color coded image files of the optical flow.", "This takes the optical flow files and generates image files where the displacement vector is color coded as shown below.", "In order to understand the color coding scheme, please view the previous blog on optical flow. At position 0, 0 i.e. the bottom right portion of the image, we can indeed see a light blue color and is what we expected from the displacement vector, i.e. it is the color for a vector pointing to the left and bottom.", "In this section, we will use a dance video, and generate optical flow files from it. The dance video is:", "It consists of a dance choreography class in a real world setting.", "As the flownet code base takes in images, the first thing we need to do is to convert the videos into frames, which can be done by the following command using ffmpeg.", "It will output the frames in an ordered sequence within the frames folder, the order is important as the flownet algorithm uses adjacent images to calculate the optical flow between the images. The generated frames occupy 1.7 GB of memory whereas the video is only 11.7 MB, each frame is about 2 MB.", "The optical flow representations can be generated by running the following command.", "This is similar to the inference model we ran with the sintel dataset where the differences are in the --inference_dataset argument which changes to ImagesFromFolder and as defined in the codebase. The --inference_dataset_root is the path to the generated video frames. The generated optical flow files occupy 14.6 GB of memory, this is because each optical flow file is approximately 15.7 MB for this example.", "The command to generate the color coding scheme is:", "This makes use of the flowviz repository as well as ffmpeg. Not only does it generate the optical flow color encodings as .png files, but the -v -r 30 parameter generates videos from the image files at 30 fps. The generated color coding frames occupy 422 MB of memory which includes a 8.7 MB video file which has the name 000000.flo.mp4 if you are following through this blog.", "The generated video representation of the optical flow is as follows:", "The gist of the choreography can be seen from the generated video, the different colors indicate the direction of motion. However, it can be seen there is a lot of background noise especially around the central dancers despite no apparent motion in the video. Unfortunately, it is not clear why this is the case.", "When running the flownet algorithm, one needs to be aware of the size implications, a 11.7 MB video for example, generates a 1.7 GB file of individual frames when extracted. However when generating optical flow this becomes a 14.6 GB file containing all the optical flow representations. This is because each optical flow file occupies about 15.7 MB in memory, however each image frame occupies 2 MB of memory (for the case of the examples provided). Thus when running optical flow algorithms one needs to be aware of the computation requirements vs space tradeoff. This trade off will impact the architecture when building deep learning systems for video, meaning either generate optical flow files as needed (i.e. lazily) at the cost of computation time or generate all the required formats and representations before hand and save them to the file system at the cost of storage space.", "We have seen how to generate optical flow files using a fork of NVIDIA\u2019s flownet2-pytorch implementation, as well as have had an overview understanding of optical flow files. The next blog will cover how to use the optical flow representations to understand video content and will be focusing on 2 stream networks.", "If you have any questions or anything needs clarification, you can book a time with me on https://mbele.io/mark", "Ask me anything or request a 10 minute video call on https://mbele.io/mark"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd7b0ae6f8320&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://markgituma.medium.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Mark Gituma"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe69ad71e0901&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&user=Mark+Gituma&userId=e69ad71e0901&source=post_page-e69ad71e0901----d7b0ae6f8320---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd7b0ae6f8320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&user=Mark+Gituma&userId=e69ad71e0901&source=-----d7b0ae6f8320---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd7b0ae6f8320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&source=-----d7b0ae6f8320---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://blog.dancelogue.com/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/", "anchor_text": "blog.dancelogue.com"}, {"url": "https://blog.dancelogue.com/what-is-optical-flow-and-why-does-it-matter/", "anchor_text": "post"}, {"url": "https://arxiv.org/abs/1612.01925", "anchor_text": "FlowNet 2.o paper"}, {"url": "https://github.com/dancelogue/flownet2-pytorch", "anchor_text": "fork"}, {"url": "https://github.com/NVIDIA/flownet2-pytorch", "anchor_text": "NVIDIA flownet2-pytorch"}, {"url": "https://github.com/dancelogue/flownet2-pytorch", "anchor_text": "Dancelogue linked repo"}, {"url": "https://github.com/NVIDIA/nvidia-docker", "anchor_text": "nvidia-docke"}, {"url": "https://github.com/dancelogue/flownet2-pytorch", "anchor_text": "repo"}, {"url": "http://files.is.tue.mpg.de/sintel/MPI-Sintel-complete.zip", "anchor_text": "link"}, {"url": "https://dancelogue.s3.amazonaws.com/open_source/datasets/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/000835.flo", "anchor_text": "sample optical flow"}, {"url": "https://dancelogue.s3.amazonaws.com/open_source/datasets/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/000835.flo.png", "anchor_text": "color coding scheme"}, {"url": "https://dancelogue.s3.amazonaws.com/open_source/datasets/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/sample-video.mp4", "anchor_text": "dance video"}, {"url": "https://dancelogue.s3.amazonaws.com/open_source/datasets/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/sample-optical-flow-video.mp4", "anchor_text": "optical flow video representation"}, {"url": "https://github.com/NVIDIA/vid2vid", "anchor_text": "vid2vid"}, {"url": "https://github.com/dancelogue/flownet2-pytorch", "anchor_text": "https://github.com/dancelogue/flownet2-pytorch"}, {"url": "https://blog.dancelogue.com/what-is-optical-flow-and-why-does-it-matter/", "anchor_text": "previous blog"}, {"url": "https://github.com/dancelogue/flownet2-pytorch/blob/master/datasets.py", "anchor_text": "https://github.com/dancelogue/flownet2-pytorch/blob/master/datasets.py"}, {"url": "https://dancelogue.s3.amazonaws.com/open_source/datasets/generating-optical-flow-using-flownet-for-human-action-deep-learning-algorithms/000835.flo", "anchor_text": "link"}, {"url": "http://vision.middlebury.edu/flow/code/flow-code/README.txt", "anchor_text": "http://vision.middlebury.edu/flow/code/flow-code/README.txt"}, {"url": "https://github.com/georgegach/flowiz/blob/master/flowiz/flowiz.py#L25", "anchor_text": "https://github.com/georgegach/flowiz/blob/master/flowiz/flowiz.p"}, {"url": "https://github.com/georgegach/flowiz", "anchor_text": "https://github.com/georgegach/flowiz"}, {"url": "https://blog.dancelogue.com/what-is-optical-flow-and-why-does-it-matter/", "anchor_text": "previous blog"}, {"url": "https://github.com/dancelogue/flownet2-pytorch/blob/master/datasets.py#L320", "anchor_text": "codebase"}, {"url": "https://github.com/georgegach/flow2image", "anchor_text": "flowviz repository"}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark"}, {"url": "https://blog.dancelogue.com/what-is-optical-flow-and-why-does-it-matter/", "anchor_text": "https://blog.dancelogue.com/what-is-optical-flow-and-why-does-it-matter/"}, {"url": "https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/", "anchor_text": "https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/"}, {"url": "https://stackoverflow.com/questions/28013200/reading-middlebury-flow-files-with-python-bytes-array-numpy", "anchor_text": "https://stackoverflow.com/questions/28013200/reading-middlebury-flow-files-with-python-bytes-array-numpy"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d7b0ae6f8320---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/optical-flow?source=post_page-----d7b0ae6f8320---------------optical_flow-----------------", "anchor_text": "Optical Flow"}, {"url": "https://medium.com/tag/dance?source=post_page-----d7b0ae6f8320---------------dance-----------------", "anchor_text": "Dance"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----d7b0ae6f8320---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/video-classification?source=post_page-----d7b0ae6f8320---------------video_classification-----------------", "anchor_text": "Video Classification"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd7b0ae6f8320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&user=Mark+Gituma&userId=e69ad71e0901&source=-----d7b0ae6f8320---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd7b0ae6f8320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&user=Mark+Gituma&userId=e69ad71e0901&source=-----d7b0ae6f8320---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd7b0ae6f8320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe69ad71e0901&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&user=Mark+Gituma&userId=e69ad71e0901&source=post_page-e69ad71e0901----d7b0ae6f8320---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe0d223f0a4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&newsletterV3=e69ad71e0901&newsletterV3Id=e0d223f0a4b3&user=Mark+Gituma&userId=e69ad71e0901&source=-----d7b0ae6f8320---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Written by Mark Gituma"}, {"url": "https://markgituma.medium.com/followers?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "469 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe69ad71e0901&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&user=Mark+Gituma&userId=e69ad71e0901&source=post_page-e69ad71e0901----d7b0ae6f8320---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe0d223f0a4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320&newsletterV3=e69ad71e0901&newsletterV3Id=e0d223f0a4b3&user=Mark+Gituma&userId=e69ad71e0901&source=-----d7b0ae6f8320---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/swlh/what-is-optical-flow-and-why-does-it-matter-in-deep-learning-b3278bb205b5?source=author_recirc-----d7b0ae6f8320----0---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=author_recirc-----d7b0ae6f8320----0---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=author_recirc-----d7b0ae6f8320----0---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Mark Gituma"}, {"url": "https://medium.com/swlh?source=author_recirc-----d7b0ae6f8320----0---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "The Startup"}, {"url": "https://medium.com/swlh/what-is-optical-flow-and-why-does-it-matter-in-deep-learning-b3278bb205b5?source=author_recirc-----d7b0ae6f8320----0---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "What is Optical Flow and why does it matter in deep learningDancelogue (https://dancelogue.com/) is an AI first company whose main objective is to understand and classify human movement in dance. To\u2026"}, {"url": "https://medium.com/swlh/what-is-optical-flow-and-why-does-it-matter-in-deep-learning-b3278bb205b5?source=author_recirc-----d7b0ae6f8320----0---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "\u00b712 min read\u00b7Jun 20, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fswlh%2Fb3278bb205b5&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fwhat-is-optical-flow-and-why-does-it-matter-in-deep-learning-b3278bb205b5&user=Mark+Gituma&userId=e69ad71e0901&source=-----b3278bb205b5----0-----------------clap_footer----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/what-is-optical-flow-and-why-does-it-matter-in-deep-learning-b3278bb205b5?source=author_recirc-----d7b0ae6f8320----0---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb3278bb205b5&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fwhat-is-optical-flow-and-why-does-it-matter-in-deep-learning-b3278bb205b5&source=-----d7b0ae6f8320----0-----------------bookmark_preview----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b0ae6f8320----1---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d7b0ae6f8320----1---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d7b0ae6f8320----1---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d7b0ae6f8320----1---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b0ae6f8320----1---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b0ae6f8320----1---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d7b0ae6f8320----1---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----d7b0ae6f8320----1-----------------bookmark_preview----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d7b0ae6f8320----2---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d7b0ae6f8320----2---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d7b0ae6f8320----2---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d7b0ae6f8320----2---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d7b0ae6f8320----2---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d7b0ae6f8320----2---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d7b0ae6f8320----2---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d7b0ae6f8320----2-----------------bookmark_preview----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/kubernetes-local-to-production-with-django-3-postgres-with-migrations-on-minikube-31f2baa8926e?source=author_recirc-----d7b0ae6f8320----3---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=author_recirc-----d7b0ae6f8320----3---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=author_recirc-----d7b0ae6f8320----3---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Mark Gituma"}, {"url": "https://markgituma.medium.com/kubernetes-local-to-production-with-django-3-postgres-with-migrations-on-minikube-31f2baa8926e?source=author_recirc-----d7b0ae6f8320----3---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "Kubernetes, Local to Production with Django: 3 - Postgres with Migrations on MinikubeSo far, we have created and deployed a basic Django app to the minikube Kubernetes cluster. However, to experience the true power of\u2026"}, {"url": "https://markgituma.medium.com/kubernetes-local-to-production-with-django-3-postgres-with-migrations-on-minikube-31f2baa8926e?source=author_recirc-----d7b0ae6f8320----3---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": "12 min read\u00b7Jan 15, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F31f2baa8926e&operation=register&redirect=https%3A%2F%2Fmarkgituma.medium.com%2Fkubernetes-local-to-production-with-django-3-postgres-with-migrations-on-minikube-31f2baa8926e&user=Mark+Gituma&userId=e69ad71e0901&source=-----31f2baa8926e----3-----------------clap_footer----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/kubernetes-local-to-production-with-django-3-postgres-with-migrations-on-minikube-31f2baa8926e?source=author_recirc-----d7b0ae6f8320----3---------------------ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F31f2baa8926e&operation=register&redirect=https%3A%2F%2Fmarkgituma.medium.com%2Fkubernetes-local-to-production-with-django-3-postgres-with-migrations-on-minikube-31f2baa8926e&source=-----d7b0ae6f8320----3-----------------bookmark_preview----ff1456bc_6f0b_4e39_9670_adc3922b7a6f-------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "See all from Mark Gituma"}, {"url": "https://towardsdatascience.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----d7b0ae6f8320----0-----------------bookmark_preview----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----d7b0ae6f8320----1-----------------bookmark_preview----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d7b0ae6f8320----0---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----d7b0ae6f8320----0-----------------bookmark_preview----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://tnmthai.medium.com/training-pytorch-models-on-a-mac-m1-and-m2-92d02c50b872?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://tnmthai.medium.com/?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://tnmthai.medium.com/?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Thai Tran"}, {"url": "https://tnmthai.medium.com/training-pytorch-models-on-a-mac-m1-and-m2-92d02c50b872?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Training PyTorch models on a Mac M1 and M2Metal acceleration"}, {"url": "https://tnmthai.medium.com/training-pytorch-models-on-a-mac-m1-and-m2-92d02c50b872?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "\u00b78 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F92d02c50b872&operation=register&redirect=https%3A%2F%2Ftnmthai.medium.com%2Ftraining-pytorch-models-on-a-mac-m1-and-m2-92d02c50b872&user=Thai+Tran&userId=bb8b875b3e65&source=-----92d02c50b872----1-----------------clap_footer----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://tnmthai.medium.com/training-pytorch-models-on-a-mac-m1-and-m2-92d02c50b872?source=read_next_recirc-----d7b0ae6f8320----1---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F92d02c50b872&operation=register&redirect=https%3A%2F%2Ftnmthai.medium.com%2Ftraining-pytorch-models-on-a-mac-m1-and-m2-92d02c50b872&source=-----d7b0ae6f8320----1-----------------bookmark_preview----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d7b0ae6f8320----2---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----d7b0ae6f8320----2---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----d7b0ae6f8320----2---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d7b0ae6f8320----2---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d7b0ae6f8320----2---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d7b0ae6f8320----2---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----2-----------------clap_footer----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d7b0ae6f8320----2---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----d7b0ae6f8320----2-----------------bookmark_preview----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----d7b0ae6f8320----3---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin?source=read_next_recirc-----d7b0ae6f8320----3---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin?source=read_next_recirc-----d7b0ae6f8320----3---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "Nitin Kishore"}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----d7b0ae6f8320----3---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "How to solve CUDA Out of Memory error**Freeze frame, scratch that record and cue \u2014 \u2018The Who\u2019 intro**"}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----d7b0ae6f8320----3---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": "\u00b77 min read\u00b7Nov 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F850bb247cfb2&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40snk.nitin%2Fhow-to-solve-cuda-out-of-memory-error-850bb247cfb2&user=Nitin+Kishore&userId=ef6a1cf849e2&source=-----850bb247cfb2----3-----------------clap_footer----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----d7b0ae6f8320----3---------------------4525ad0c_116b_4d36_9d08_6753ca13156f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F850bb247cfb2&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40snk.nitin%2Fhow-to-solve-cuda-out-of-memory-error-850bb247cfb2&source=-----d7b0ae6f8320----3-----------------bookmark_preview----4525ad0c_116b_4d36_9d08_6753ca13156f-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----d7b0ae6f8320--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}