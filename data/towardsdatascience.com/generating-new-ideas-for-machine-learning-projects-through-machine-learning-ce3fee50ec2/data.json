{"url": "https://towardsdatascience.com/generating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2", "time": 1682994295.81927, "path": "towardsdatascience.com/generating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2/", "webpage": {"metadata": {"title": "Generating New Ideas for Machine Learning Projects Through Machine Learning | by Paras Chopra | Towards Data Science", "h1": "Generating New Ideas for Machine Learning Projects Through Machine Learning", "description": "Why RNNs fail on small corpus of text and how transfer learning addresses those failures. Generating style-specific text from a small corpus of 2.5k sentences using a pre-trained language model."}, "outgoing_paragraph_urls": [{"url": "http://cs229.stanford.edu/projects.html", "anchor_text": "CS229 Machine Learning course", "paragraph_index": 3}, {"url": "https://medium.com/artists-and-machine-intelligence/neural-nets-for-generating-music-f46dffac21c0", "anchor_text": "generating music", "paragraph_index": 5}, {"url": "https://amoudgl.github.io/blog/funnybot/", "anchor_text": "jokes", "paragraph_index": 5}, {"url": "https://pubs.acs.org/doi/full/10.1021/acscentsci.7b00512", "anchor_text": "molecules", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec", "paragraph_index": 12}, {"url": "https://www.reddit.com/r/MachineLearning/comments/a4ihvd/d_how_to_do_text_generation_from_a_small_dataset/", "anchor_text": "the thread", "paragraph_index": 12}, {"url": "https://nips2018creativity.github.io/doc/Transfer%20Learning%20for%20Style-Specific%20Text%20Generation.pdf", "anchor_text": "Transfer Learning for Style-Specific Text Generation", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/ImageNet", "anchor_text": "ImageNet dataset", "paragraph_index": 14}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT", "paragraph_index": 19}, {"url": "https://arxiv.org/abs/1801.06146", "anchor_text": "ULMFit", "paragraph_index": 19}, {"url": "https://www.reddit.com/r/MachineLearning/comments/a4ihvd/d_how_to_do_text_generation_from_a_small_dataset/", "anchor_text": "Reddit thread", "paragraph_index": 22}, {"url": "https://course.fast.ai/lessons/lesson10.html", "anchor_text": "lesson on classifying IMDB reviews", "paragraph_index": 22}, {"url": "https://docs.fast.ai/text.html", "anchor_text": "FastAI library\u2019s documentation", "paragraph_index": 22}, {"url": "https://github.com/paraschopra/generating-text-small-corpus/", "anchor_text": "this repository", "paragraph_index": 23}, {"url": "https://docs.fast.ai/text.html", "anchor_text": "astAI text module\u2019s documentation", "paragraph_index": 23}, {"url": "https://github.com/salesforce/awd-lstm-lm", "anchor_text": "3-layer AWD-LSTM model", "paragraph_index": 24}, {"url": "https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/", "anchor_text": "Wikipedia articles", "paragraph_index": 24}, {"url": "https://activeintellect.wordpress.com/nietzsche-chaos-and-the-dancing-star/", "anchor_text": "dancing star", "paragraph_index": 33}, {"url": "http://cs229.stanford.edu/projects.html", "anchor_text": "Stanford\u2019s CS229 class had submitted", "paragraph_index": 35}, {"url": "https://github.com/paraschopra/generating-text-small-corpus/", "anchor_text": "my repository", "paragraph_index": 35}, {"url": "https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd", "anchor_text": "Bayesian Neural Networks", "paragraph_index": 45}, {"url": "https://medium.com/u/75f7ca12ae5c?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Nirant Kasliwal", "paragraph_index": 46}, {"url": "https://twitter.com/paraschopra", "anchor_text": "https://twitter.com/paraschopra", "paragraph_index": 47}, {"url": "http://InvertedPassion.com", "anchor_text": "InvertedPassion.com", "paragraph_index": 49}], "all_paragraphs": ["Let\u2019s do a quick Turing Test. Below, you\u2019ll see ten machine learning project ideas. Five of them are generated by a human and five of them are generated by a neural network. Your task is to tell them apart.", "Ready? (Don\u2019t overthink. Just go with your gut).", "Seen the list? Take note of the five ideas that you think a neural network generated, and the five that a human generated.", "Answer: all the odd-numbered ideas are titles of final projects done by Stanford\u2019s CS229 Machine Learning course, and all even numbered ideas were generated by a neural network trained on that dataset.", "Yes, scroll up and take a look at the list again, compare your notes and then we\u2019ll dive into details on how these ideas were generated. How accurate were you? (Tell in the comments!)", "The motivation for this project was for me to learn using a recurrent neural network (RNN) to generate quotes similar to my favorite philosophers and thinkers. I had seen many other people generating music, jokes and even molecules using RNNs. I was pumped to do the same, but for philosophy.", "From the web, I had collected about ~5000 quotes from thinkers like Camus, Nietzsche, Wittgenstein, Feynman, David Hume, Stephen Hawking, and James Carse.", "What skipped my eye completely was that the projects that I took as inspiration usually had a dataset that went into millions and all I had with myself was 5000 sentences. Naively and blindly, I marched on and failed repeatedly in getting my artificial philosopher to work. Finally, after three failed experiments I got it to work, which I followed up by building a generator for machine learning ideas.", "Here\u2019s the first failed experiment I did with RNNs:", "After so many failed attempts, I was VERY frustrated that my artificial philosopher will always remain a pipe dream.", "My conclusion from these failed attempts was that the culprit was the small text corpus.", "Perhaps 5000 quotes were not enough to generate similar quotes of good quality?", "So, as my next experiment, I wanted to try pre-existing word embeddings such as word2vec rather than forcing the network to learn the embeddings from scratch. But, before doing that, I decided to take advice on Reddit\u2019s machine learning subreddit. On the thread that I started, someone pointed me to a poster accepted into 2018 NeurIPS conference titled: \u201cTransfer Learning for Style-Specific Text Generation\u201d. I followed ideas from that paper and they worked like a charm.", "Transfer learning is a simple but powerful idea. It means using an existing model that\u2019s trained on a very large dataset as a starting point and tweaking it to work well on your domain-specific dataset.", "In the computer vision community, transfer learning has been used for long. The idea is to use a publicly available model such as VGG that was trained on the ImageNet dataset with 14 million images across 20,000 categories and use activations of its last layer as the input to an additional task-specific layer. The additional layer is then trained specifically on your small, domain-specific dataset for prediction, classification or any other task.", "The surprising beauty of using pre-trained models is that you for free, you get to use all the concepts that the pre-trained model has learned across millions of images across hundreds of hours of training.", "A pre-trained model is compressed knowledge.", "These pre-learned concepts and activations enable you to predict and classify on your small, domain-specific dataset. This magic happens due to the fact that all \u201cnatural\u201d datasets share similar characteristics. Most images share many characteristics: from primitive concepts of shapes, lines and edges to high-level concepts such as textures and effect of light and shadows.", "Without pre-trained models, you\u2019d have to learn all these concepts from scratch and your dataset may not contain enough examples to do that. With a pre-trained model, you go straight to learning what\u2019s important and different in your domain / problem and not bothering about common things found across datasets.", "Recently, transfer learning has started cropping up in NLP and exciting possibilities have opened up. There\u2019s Google\u2019s massive BERT model and then there\u2019s ULMFit.", "These language models are trained on publicly available textual corpus (such as parliamentary records, Wikipedia, etc) and implicitly encode knowledge of English. Hence, they enable machine learning tasks such as classification and prediction on text even when your dataset is very small.", "And that\u2019s precisely what I wanted! My dataset of quotes was small (~5k) and my objective was to generate new quotes with a style similar to those of my favorite thinkers.", "For generating style-specific text from my small corpus, I followed the paper linked from the Reddit thread and that led me to FastAI\u2019s lesson on classifying IMDB reviews using a pre-trained model. The lesson was about classification but as I was going through FastAI library\u2019s documentation, I discovered that even generating text is made trivial thanks to helper functions in the library.", "My code and dataset is present in this repository. You\u2019ll require PyTorch v1, FastAI v1 and Pandas. Note that my code is literally a copy-paste from FastAI text module\u2019s documentation. They\u2019ve made it that easy to use pre-trained models.", "What pre-trained model do we use? It\u2019s a 3-layer AWD-LSTM model developed by Salesforce\u2019s research team that\u2019s trained on 100 million tokens from Wikipedia articles. I encourage you to read more details on this specific model but a key benefit of using pre-trained models is that you can get away by not understanding the underlying details. Just like you\u2019ll most likely not care about how Pytorch and Numpy work under the hood, you can also afford to not care how AWD-LSTM works under the hood.", "This level of abstraction provided by pre-trained models is truly revolutionary.", "Now, anyone can assemble a state of the art deep learning model in their respective domain without requiring months and years of effort. (But it pays to know the details when you\u2019re not getting results)", "When I ran my model, I literally couldn\u2019t believe what came out of it. In excitement, I tweeted about it:", "My network said: \u201cIn the world there is no man who is not a slave\u201d and this sounded so too-good-to-be-true that I first checked whether it was simply repeating a memorized quote from the dataset. When I didn\u2019t find it, I googled the exact phrase to see if this idea has been expressed before. Lo-and-behold, I didn\u2019t find it on Google too.", "Here is a run with 100 quotes generated by the neural network. These are not modified by me in any way. I\u2019ve literally copy-pasted these from my notebook. (I\u2019m bolding the ones which are intriguing and possibly unique).", "You must have seen equally impressive generated text in other articles. But I think what\u2019s impressive here is the quality of generated text given that my training set was extremely small (5k sentences). This is only possible using a pre-trained model.", "It may not seem like much but I think an idea like \u201cthe limits of my language are always your limits\u201d seems like something the language philosopher Ludwig Wittgenstein might have said. In fact, when you Google this phrase, you find no exact results but Google recommends checking the Wikipedia article on Wittgenstein.", "In reality, Wittgenstein had said: \u201cThe limits of my language mean the limits of my world\u201d and our model has smartly (and in a grammatically accurate fashion) changed it to something new.", "Similarly, the generated quote \u201cthe present man has a reason to be able to give birth to a dancing star\u201d is reminiscent of Nietzsche because he has mentioned \u201cdancing star\u201d in his books but he never said it in context of the present man. I may be reading too much into it, but to me, the generated quote represents the idea that we\u2019ve become so technologically advanced that we can give rise to really complicated machinery (like a dancing star) and we\u2019ve become so competitive that we have a reason to do that. (Is my neural network warning us of the potential dangers of AI and the inevitability of it?)", "Remember that my corpus for philosophy quotes was ~5000 sentences. I wondered how this approach will perform if I were to give it an even smaller corpus.", "I decided that generating machine learning ideas would be fun. To my knowledge, nobody else so far has tried doing that. So I collected titles of all the machine learning projects that students at Stanford\u2019s CS229 class had submitted from the year 2004 to 2017. The dataset includes 2500 ideas comprising of five to seven words each. The dataset and the corresponding notebook are available in my repository. (Note: I don\u2019t own the copyright to ideas. It\u2019s collected merely for research and exploration)", "The project seemed exciting but my main worry was that the domain of machine learning project ideas is very narrow and contained niche and technical terms. I thought the model will mostly spit out memorized ideas, the same as the ones in the dataset.", "However, to my surprise, it generated some very novel ideas (in bold, followed by my commentary):", "If you want unfiltered output from the model, here are 100 ideas that it generated. I\u2019ve not modified anything (just bolding the ones I think are interesting and novel).", "I haven\u2019t checked thoroughly, but random checks tell me that most of the generated ideas are unique. I think the reason why the generated text isn\u2019t memorized from training corpus is because we\u2019re using a pre-trained model. The pre-trained language model was trained on Wikipedia and hence it has strong opinions on how concepts and words are related even before seeing training data.", "For a model that\u2019s initialized randomly, the easiest way to reduce training data is to remember the training corpus. This results in over-fitting. However, for a pre-trained model, if the network tries to learn the training corpus, it can only do that if it first forgets previously learned weights. And since that leads to a higher error, the easier way is to accommodate training corpus within the context of earlier learned weights. Hence, the network is forced to generalize and generates grammatically correct sentences (thanks to pre-training on Wikipedia) but using domain-specific concepts and words (thanks to your dataset).", "Before pre-trained models were available, you needed a huge corpus of text to do anything meaning. Now, even a small dataset is enough to do interesting things. Let me know in comments what project ideas come to your mind that could use a small text corpus along with a pre-trained model.", "Some ideas to get your neurons firing:", "Also, it\u2019ll be super cool if you end up implementing a machine learning project idea generated by my model (or the one contained in this post). You\u2019ll be part of the world\u2019s first project that a machine has thought of which a human implements!", "Thanks for reading so far. Let me know your thoughts and questions in comments.", "PS: Check out my previous hands-on tutorial on Bayesian Neural Networks", "Thanks Nirant Kasliwal for reviewing the draft of this post and giving helpful suggestions.", "I regularly tweet on AI, deep learning, startups, science and philosophy. Follow me on https://twitter.com/paraschopra", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Founder and Chairman of @Wingify. Writes on InvertedPassion.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fce3fee50ec2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@paraschopra?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@paraschopra?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Paras Chopra"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce4d7f282c52&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&user=Paras+Chopra&userId=ce4d7f282c52&source=post_page-ce4d7f282c52----ce3fee50ec2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce3fee50ec2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce3fee50ec2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/en/drum-drummer-instrument-music-1299129/", "anchor_text": "Pixabay"}, {"url": "http://cs229.stanford.edu/projects.html", "anchor_text": "CS229 Machine Learning course"}, {"url": "https://medium.com/artists-and-machine-intelligence/neural-nets-for-generating-music-f46dffac21c0", "anchor_text": "generating music"}, {"url": "https://amoudgl.github.io/blog/funnybot/", "anchor_text": "jokes"}, {"url": "https://pubs.acs.org/doi/full/10.1021/acscentsci.7b00512", "anchor_text": "molecules"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "character-level language model"}, {"url": "https://arxiv.org/abs/1706.01399", "anchor_text": "papers"}, {"url": "https://pixabay.com/en/frustrated-sad-stress-depressed-man-1169941/", "anchor_text": "Pixabay"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec"}, {"url": "https://www.reddit.com/r/MachineLearning/comments/a4ihvd/d_how_to_do_text_generation_from_a_small_dataset/", "anchor_text": "the thread"}, {"url": "https://nips2018creativity.github.io/doc/Transfer%20Learning%20for%20Style-Specific%20Text%20Generation.pdf", "anchor_text": "Transfer Learning for Style-Specific Text Generation"}, {"url": "https://software.intel.com/en-us/articles/use-transfer-learning-for-efficient-deep-learning-training-on-intel-xeon-processors", "anchor_text": "Intel\u2019s developer website"}, {"url": "https://en.wikipedia.org/wiki/ImageNet", "anchor_text": "ImageNet dataset"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT"}, {"url": "https://arxiv.org/abs/1801.06146", "anchor_text": "ULMFit"}, {"url": "https://www.reddit.com/r/MachineLearning/comments/a4ihvd/d_how_to_do_text_generation_from_a_small_dataset/", "anchor_text": "Reddit thread"}, {"url": "https://course.fast.ai/lessons/lesson10.html", "anchor_text": "lesson on classifying IMDB reviews"}, {"url": "https://docs.fast.ai/text.html", "anchor_text": "FastAI library\u2019s documentation"}, {"url": "https://github.com/paraschopra/generating-text-small-corpus/", "anchor_text": "this repository"}, {"url": "https://docs.fast.ai/text.html", "anchor_text": "astAI text module\u2019s documentation"}, {"url": "https://github.com/salesforce/awd-lstm-lm", "anchor_text": "3-layer AWD-LSTM model"}, {"url": "https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/", "anchor_text": "Wikipedia articles"}, {"url": "https://pixabay.com/en/photos/philosopher/?", "anchor_text": "Pixabay"}, {"url": "https://activeintellect.wordpress.com/nietzsche-chaos-and-the-dancing-star/", "anchor_text": "dancing star"}, {"url": "http://cs229.stanford.edu/projects.html", "anchor_text": "Stanford\u2019s CS229 class had submitted"}, {"url": "https://github.com/paraschopra/generating-text-small-corpus/", "anchor_text": "my repository"}, {"url": "https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd", "anchor_text": "Bayesian Neural Networks"}, {"url": "https://medium.com/u/75f7ca12ae5c?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Nirant Kasliwal"}, {"url": "https://twitter.com/paraschopra", "anchor_text": "https://twitter.com/paraschopra"}, {"url": "https://twitter.com/paraschopra", "anchor_text": "Paras Chopra (@paraschopra) | TwitterThe latest Tweets from Paras Chopra (@paraschopra). Founder and Chairman of @Wingify | Writes on\u2026twitter.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ce3fee50ec2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/transfer-learning?source=post_page-----ce3fee50ec2---------------transfer_learning-----------------", "anchor_text": "Transfer Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----ce3fee50ec2---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----ce3fee50ec2---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----ce3fee50ec2---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce3fee50ec2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&user=Paras+Chopra&userId=ce4d7f282c52&source=-----ce3fee50ec2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce3fee50ec2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&user=Paras+Chopra&userId=ce4d7f282c52&source=-----ce3fee50ec2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce3fee50ec2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fce3fee50ec2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ce3fee50ec2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ce3fee50ec2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@paraschopra?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@paraschopra?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Paras Chopra"}, {"url": "https://medium.com/@paraschopra/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.1K Followers"}, {"url": "http://InvertedPassion.com", "anchor_text": "InvertedPassion.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce4d7f282c52&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&user=Paras+Chopra&userId=ce4d7f282c52&source=post_page-ce4d7f282c52--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7ce94dbae53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-new-ideas-for-machine-learning-projects-through-machine-learning-ce3fee50ec2&newsletterV3=ce4d7f282c52&newsletterV3Id=e7ce94dbae53&user=Paras+Chopra&userId=ce4d7f282c52&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}