{"url": "https://towardsdatascience.com/dont-automate-all-the-boring-stuff-84d493ecc135", "time": 1683006335.1240819, "path": "towardsdatascience.com/dont-automate-all-the-boring-stuff-84d493ecc135/", "webpage": {"metadata": {"title": "Don\u2019t automate all the boring stuff | by Byron Dolon | Towards Data Science", "h1": "Don\u2019t automate all the boring stuff", "description": "A look at when it's worth automating a process and when you should just crank out the work, even if it is boring."}, "outgoing_paragraph_urls": [{"url": "https://panlasangpinoy.com/", "anchor_text": "Panlasang Pinoy", "paragraph_index": 2}], "all_paragraphs": ["I tend to get caught up trying to automate stuff.", "Learning and implementing new things is a lot of fun. Especially as someone new to coding, it feels like making your computer perform magic. But sometimes, automating stuff is unnecessary and counterproductive.", "As a personal project, I decided to get all the recipes from the Filipino recipe site \u201cPanlasang Pinoy\u201d. I wanted the final product to be an Excel spreadsheet that aggregated all recipe data from the site. That way, I would have a file on my computer for every time I wanted to cook something new.", "Manually getting a couple thousand recipes would have been an impossible task. Instead, I wanted to try using Scrapy, a Python library for web scraping. I looked through the documentation and thought I could whip something up in a couple of hours.", "After brushing up on my HTML, learning about xpath selectors and learning what \u201cyield\u201d does, I ran my first spider. I was greeted with an error. After a bit of debugging, I realized I missed out on a couple required variable assignments. 15 minutes later, my spider ran without error and extracted every recipe to an Excel file.", "My end goal was simple, which is why it only took a couple hours to go from nothing to a \u201cfinal product\u201d. Despite being simple, the file was easy to use and served as a basic compilation of food. After a bit of formatting on Excel, I posted the data onto the \u201cSubtle Filipino Traits\u201d group on Facebook.", "This quick project was an opportunity for me to achieve a task that needed automation. While learning to code, a lot of the advice I\u2019ve read is to build your own projects. One suggestion was to look at everything you do and try to automate each task, even if you didn\u2019t need to. That way, you\u2019d improve your knowledge with a \u201clearn by doing\u201d approach. In this case, I couldn\u2019t have even completed my project without writing code. That justified the hours spent learning to set up and deploy a spider.", "Automating everything may be great for learning, but it may not be the most efficient way to get results.", "Recently, I wanted to track how the Amsterdam Exchange index (AEX) is performing during the COVID-19 induced quarantine.", "My end goal for this project was a Tableau dashboard of KPIs and visualizations with three categories of data:", "These three categories of data exist on a variety of sources on the web. My goal was to create a dashboard to understand the situation as quickly as possible. As such, my priority was to analyze data and not to spend too much time collecting it. The project didn\u2019t need a custom-written spider, but I thought my experience would help with data collection for this project.", "Here\u2019s how my data collection went:", "On the \u201cHistorical Data\u201d tab for AEX, all the price information is available via the \u201cDownload Data\u201d button. At this point, I didn\u2019t even bother trying to inspect HTML because I didn\u2019t need to. I just set the date filters and hit download. Then, I directly connected that Excel output into Tableau.", "By now, everyone\u2019s probably seen the John Hopkins CSSE dashboard of COVID-19 stats.", "On a whim, I searched for \u201cGithub\u201d on that page and found their repository. I clicked through that repository to try and find another Excel file with all the Corona cases. I landed on another repository where someone had converted the raw data from John Hopkins into a csv.", "I downloaded that csv, checked to make sure the data was all there and then loaded it into Tableau.", "I saved this one for last because I knew it would take me the longest time to figure out. I started by checking regular news sites and typing \u201cAEX\u201d and \u201cCorona\u201d as keywords. Most of the content from those searches didn\u2019t look like they could explain the AEX index trend. Next, I thought to use company press releases and quarterly reports.", "There are 25 companies included in the AEX index. I didn\u2019t want to go to each website, click through it until I found their \u201cmedia\u201d page and then copy paste whatever I found there into an Excel sheet. As a test, I tried doing one site and it took about five minutes. Some quick mental math led me to conclude that I definitely did not want to spend 2.08 hours copy pasting stuff.", "After that, I went on the Euronext (stock exchange) website and clicked on one of the companies in the index. I found that company main page had a \u201cRegulated News\u201d tab showing recent press releases.", "The main site relied on JavaScript to load parts of its site. As Scrapy can\u2019t parse JavaScript sites, I couldn\u2019t write a spider to crawl the whole site\u00b9. However, when I clicked on the press releases tab for each company, the site I was redirected to didn\u2019t have any JavaScript! Also, only one sub-string in the URL needed to be changed to access any company on the Euronext site.", "With that, I thought I could write a quick spider to get all the necessary press releases for each company.", "So I got started. I set up a virtual environment, installed Scrapy and tested to see if the servers would block me from scraping. I initialized a base spider template and then opened up my browser to inspect the site.", "The HTML formatting looked fine at first, but then I realized there a couple issues:", "These issues may not seem very difficult, but I\u2019m a complete novice at web scraping (and coding in general).", "I knew I could put in the time to learn more about scraping and eventually resolve the complications. However, because of my limited knowledge, I couldn\u2019t estimate how much time it would take to both get up to speed on scraping and actually write the spider. I had already spent two hours testing and finding these issues. I stepped away for a bit to clear my head.", "When I came back, I opened the press release tab of a random company, copied the news table and pasted it to an empty Excel file. It took me about ten seconds. I did some quick mental math (full disclosure that\u2019s me opening a calculator) part two and I realized that it would take me 4.16 minutes to do all 25 companies.", "I\u2019d gotten so caught up in trying to figure out how to automate the process that I forgot the goal of my project. This wasn\u2019t supposed to be an exercise in learning web scraping. My goal was to transform raw data to key insights as quickly as possible.", "I was tempted to override that and go forward with the scraping, as I\u2019d already committed a lot of time to it. Thankfully, my brain went:", "\u201cBYRON, WE LEARNED ABOUT SUNK COSTS. LET IT GO\u201d.", "10 minutes later, I had copy pasted all the press releases from the Euronext site for every company in the AEX index. So it wasn\u2019t quite 4 minutes, as I needed an extra 6 to do a bit of processing on the copy pasted data. Once that as done, I loaded that Excel file into Tableau and was finally ready to start making some graphs.", "Time it could have taken to complete: 10 minutes.", "My brain right now is already screaming:", "\u201cBUT BYRON, WHAT ABOUT SCALE? DON\u2019T YOU WANT TO SCALE THIS PROJECT EVENTUALLY? WHY AREN\u2019T YOU MAKING IT SCALABLE?\u201d", "The answer is yes. At some point, I do want to make the dashboard on Tableau have real-time data, but that wasn\u2019t why I set out to do this. The goal of the project was to basically to make some graphs. This exercise was a quick and dirty way for me to brush up on Tableau and learn about what was happening to the AEX index.", "Whipping up graphs went a lot quicker than collecting the data, as I had already learned to use Tableau. I didn\u2019t need to look up the niche things like synchronizing axes, writing LOD expressions and blending data sources.", "When I finished, I had a single dashboard that combined all three data sets. From one page, I could quickly get a basic understanding of how events affected stock prices. I could also see if there was any correlation between COVID-19 cases and the AEX index over time.", "What I learned from this is sometimes, you don\u2019t really need to automate what you\u2019re trying to do. It would have been great if I had real time updates for each category of data. In fact, that\u2019s what I\u2019m going to do next. But that wasn\u2019t necessary for a proof of concept project, which is what this exercise was.", "I had a bunch of early success with automation. I scheduled emails, processed RSS feeds and used Pandas to analyze data, all within a couple months of learning Python. Because of this, I got a little obsessed with trying to apply automation everywhere. I learned the hard way that the process of developing an automated solution might get in the way of actually doing work.", "Copy pasting from a website was kind of like taking the easy way out, even though the easy way was mind-numbingly boring.", "\u201cI set up an advanced scraper that populated a relational database in the cloud which then connects to a Tableau dashboard.\u201d", "sounds a lot sexier than this:", "\u201cI copied some stuff from a website and pasted it to Excel. Then I put it on Tableau.\u201d", "Here\u2019s the thing: sexy wasn\u2019t the goal.", "I could have saved myself an hour if I wasn\u2019t trying to be sexy. I didn\u2019t need to be sexy to finish a proof of concept dashboard.", "SO after 1944 words (thanks for making it this far), my big takeaway is twofold:", "Sidenote\u00b9: Scrapy can parse JS if you integrate Splash or Selenium, but I haven\u2019t learned to do that yet. This was something I hadn\u2019t even touched yet, which is why I didn\u2019t even think to try and do it. The task of scraping regular (no JS) sites was already somewhat familiar. That\u2019s why I had a valid conundrum of whether to automate the data collection.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Medium has become a place to store my \u201chow to do tech stuff\u201d type guides. Come check out my notes on data-related shenanigans!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F84d493ecc135&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----84d493ecc135--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----84d493ecc135--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://byrondolon.medium.com/?source=post_page-----84d493ecc135--------------------------------", "anchor_text": ""}, {"url": "https://byrondolon.medium.com/?source=post_page-----84d493ecc135--------------------------------", "anchor_text": "Byron Dolon"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b5d063df5dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&user=Byron+Dolon&userId=6b5d063df5dd&source=post_page-6b5d063df5dd----84d493ecc135---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F84d493ecc135&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F84d493ecc135&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@vincentvanzalinge?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Vincent van Zalinge"}, {"url": "https://unsplash.com/s/photos/boring?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://panlasangpinoy.com/", "anchor_text": "Panlasang Pinoy"}, {"url": "https://panlasangpinoy.com/", "anchor_text": "https://panlasangpinoy.com/"}, {"url": "https://finance.yahoo.com/quote/%5EAEX/history?p=%5EAEX", "anchor_text": "https://finance.yahoo.com/quote/%5EAEX/history?p=%5EAEX"}, {"url": "https://coronavirus.jhu.edu/map.html", "anchor_text": "https://coronavirus.jhu.edu/map.html"}, {"url": "https://l.facebook.com/l.php?u=https%3A%2F%2Fgithub.com%2FRamiKrispin%2Fcoronavirus-csv%3Ffbclid%3DIwAR3hWL8q3GbgcBXtnjttoPfhwvJ2mo5i_HOx7lEKckNQc1SCVYbtk5pcN0s&h=AT2CYb01SYBto4JRtEF8r5iPNbNU94aLhUOMnUejK4lGrpAWYrsH4C1GLjrFSnUxu6ovCQcEKMH7NmPoy4n5YWjsdKcEHGcZWOcm5oDoVlmpZTq3PAV-JQ6JXMT9DMKqoWY5xsog", "anchor_text": "https://github.com/RamiKrispin/coronavirus-csv"}, {"url": "https://live.euronext.com/en/product/equities/NL0011540547-XAMS", "anchor_text": "https://live.euronext.com/en/product/equities/NL0011540547-XAMS"}, {"url": "https://live.euronext.com/listview/company-press-release/NL0011540547", "anchor_text": "https://live.euronext.com/listview/company-press-release/NL0011540547"}, {"url": "https://unsplash.com/@pawel_czerwinski?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Pawe\u0142 Czerwi\u0144ski"}, {"url": "https://unsplash.com/s/photos/fish?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://xkcd.com/1319/", "anchor_text": "https://xkcd.com/1319/"}, {"url": "https://medium.com/tag/python?source=post_page-----84d493ecc135---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/automation?source=post_page-----84d493ecc135---------------automation-----------------", "anchor_text": "Automation"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----84d493ecc135---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----84d493ecc135---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----84d493ecc135---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F84d493ecc135&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&user=Byron+Dolon&userId=6b5d063df5dd&source=-----84d493ecc135---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F84d493ecc135&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&user=Byron+Dolon&userId=6b5d063df5dd&source=-----84d493ecc135---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F84d493ecc135&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----84d493ecc135--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F84d493ecc135&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----84d493ecc135---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----84d493ecc135--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----84d493ecc135--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----84d493ecc135--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----84d493ecc135--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----84d493ecc135--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----84d493ecc135--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----84d493ecc135--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----84d493ecc135--------------------------------", "anchor_text": ""}, {"url": "https://byrondolon.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://byrondolon.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Byron Dolon"}, {"url": "https://byrondolon.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b5d063df5dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&user=Byron+Dolon&userId=6b5d063df5dd&source=post_page-6b5d063df5dd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb2ea4b269407&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-automate-all-the-boring-stuff-84d493ecc135&newsletterV3=6b5d063df5dd&newsletterV3Id=b2ea4b269407&user=Byron+Dolon&userId=6b5d063df5dd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}