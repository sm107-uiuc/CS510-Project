{"url": "https://towardsdatascience.com/tutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd", "time": 1682996999.878073, "path": "towardsdatascience.com/tutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd/", "webpage": {"metadata": {"title": "Tutorial: From The Hypothesis To The Analysis With Web Scraping | by Benedikt Droste | Towards Data Science", "h1": "Tutorial: From The Hypothesis To The Analysis With Web Scraping", "description": "Often people have interesting ideas for analysis and then find that there is no freely available data to answer the question. An interesting way to get needed data is web scraping. There is a lot of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/money-makes-the-world-go-round-and-thus-also-the-soccer-847bb5350535", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/money-makes-the-world-go-round-and-thus-also-the-soccer-847bb5350535", "anchor_text": "here", "paragraph_index": 28}, {"url": "https://medium.com/@droste.benedikt/membership", "anchor_text": "If you enjoy Medium and Towards Data Science and didn\u2019t sign up yet, feel free to use my referral link to join the community.", "paragraph_index": 29}, {"url": "https://www.linkedin.com/in/benedikt-droste-893b1b189/", "anchor_text": "https://www.linkedin.com/in/benedikt-droste-893b1b189/", "paragraph_index": 31}], "all_paragraphs": ["Often people have interesting ideas for analysis and then find that there is no freely available data to answer the question. An interesting way to get needed data is web scraping. There is a lot of data on the internet, but they are not available in such a way that they can be analyzed in a structured way. Often, tutorials start with reading the data and end with saving it. In this tutorial, I would like to take a different path. I would like to take you on the journey of a real-world Data-Science project. We start with our idea: we scrape, clean up and transform the data and answer our question with the scraped data set. A much more detailed analysis without the scraping part can be found here.", "Recently, the national and international competitions of the 2018/2019 season ended in soccer. Traditionally, in the summer break the transfer window opens and the clubs compete for the best players in the market. It is striking that again and again the same clubs spend new record sums for their stars. Real Madrid alone invested 135 million in Eden Hazard. Therefore, I wanted to pursue the question of how strong the squad value and the sporting success are related. Will there be other champions than Barcelona and Real Madrid in the next few years? What about the other leagues? My hypothesis is that a higher squad value also leads to higher success. So I had an idea for an interesting analysis, but no data. However, I knew that there are databases for squad values \u200b\u200bin the web. So let\u2019s get some data first!", "There are different packages for web scraping. Two of the best known libraries are certainly Scrapy and BeautifulSoup. Scrapy is a powerful framework built on an asynchronous networking library, which makes it very performant. It also has many features to avoid typical scraping problems. These include, for example, redirections, retrying requests, avoiding to overload the servers, etc. Due to the complexity, however, the learning curve for Scrapy is also significantly higher than for BeautifulSoup. This library is primarily used for parsing and extracting data from HTML. All exceptions and problems that arise when scraping must be identified by the programmer and taken into account in the coding. However, this has the advantage that the user actually has to deal with the matter here and learn the Webscraping from the ground up. Therefore, we will use BeautifulSoup here.", "The required data can be found on transfermarkt.com[1]. For example, in Figure 1, you can see the squad values \u200b\u200bfor the German Bundesliga in the 2018/2019 season. On the same page you will find a table with the results of the current season: placement, goal difference and points. If we take the trouble to scrape the data, we should extract all the information we need for further analysis.", "When it comes to web scraping, we are usually interested in a section of the page from which we would like to selectively extract information. In our example, we first want to extract the contents of the two tables (Figure 1). To do this, we identify the HTML tags that enclose our elements. Each browser offers the possibility to identify the HTML tags. In this example I am using Google Chrome (Figure 2). First, you click with a right click in the area, which contains the necessary data. Then you click Inspect and it opens a menu on the right. If you move the mouse over each row in the menu, the site highlights the areas associated with the HTML code (Figure 3).", "So the first table is in the HTML-elementtable with the class name items . Therein, there are the elements thead, tfood and tbody, which in turn contain further elements. The essential contents are found in tbody, which contains tr elements for each row of the table. We do not need more information in a first step. Hence, we first import the required modules:", "Then we assign the URL to a variable and set a header that serves to simulate a real user. Otherwise, some pages block the request directly. We will use the module requests to call up the URL and load the contents. Then we will parse the content of the requests object with BeautifulSoup to extract the content we need:", "The soup element now contains the parsed page. From the soup element we are able to extract the desired table:", "Now we can save every single row of the table in a list:", "By typing len(row) we find out that there is a total of 20 elements. The 18 teams of the Bundesliga, the header and footer. With row[2] we should find Bayern Munich:", "Now we have the data of the first club. In the red-marked areas in figure 4, we have the name, the size of the squad, the average age, the number of foreigners, the total market value and the average market value. But how do we get the data into a reasonable form to analyze it? To do this, we first have to remove all the HTML code with the suffix .text. Row[2].text gives us the information more readable:", "That looks a lot better, but now we have all the information in one variable. Thus, we divide the rows with findAll['td'] by columns so we can address each single cell and save it. Now, analogous to the lines, we can also address the individual columns or combine both:", "Now we have everything to read the whole table with a loop:", "We are able to create a DataFrame from the lists. We always skip the first line, as we have scraped the header we do not need.", "Of course we do not go to all that trouble to read only one table. We will be reading out the top 10 leagues [2] over a period of seven years. Then we have a solid database to do our calculations. First of all, we create a dictionary for each league, in which we store the data for every single season:", "Then we create a list with the URL for each league. Can you still remember the Bayern-URL for the 2018/2019 season?", "In the list we only deposit:", "We add the year using a loop. In this way, we can write a flexible script for our project. The complete list for the top 10 leagues looks like this:", "Now we need a nested loop. The outermost loop iterates over the list with the League URLs and the inner loop iterates over the years 2012 through 2018:", "As a result, we have ten dictionaries with each season from 2012 to 2018 for each league. First, we will combine all seasons for each league and then unite all the leagues into one data set. The question arises as to why we did not directly collect everything in one data set, if we combine them all together in the end anyway. I have included try and except blocks in the scraping part to avoid errors if there is no data for a year or league available. Thus, we still get the largest possible amount of data and data quality. First, we connect each season for each league, deposit the respective country in the individual data sets and then merge all leagues:", "Let\u2019s take a look at three selected clubs:", "The data looks good so far, but we have no numbers, though strings at Total value \u200b\u200band Average value. In Figure 5, we see the additions Mill. \u20ac, Th. \u20ac and Bill. \u20ac in each cell. We have to remove these before we can convert the columns \u200b\u200binto float. In the Age column, the delimiter is still a comma instead of a dot. We also have to clean up this column:", "Then we can convert all columns to float:", "For safety, we save the data set once:", "After scraping and cleaning the data, we have a clean data set to check our hypothesis. First let\u2019s take a look at the evolution of the average squad values with the following code:", "We see that the average squad values \u200b\u200bkeep increasing. The teams invest across all leagues, so in total, more in their teams. Now let\u2019s see how much the two variables correlate with each other:", "The correlation coefficient is 0.664, this means that we have a strong positive correlation. The correlation does not say anything about causality. We assume that higher squads values \u200b\u200balso lead to greater sporting success. We will do a regression to see how strong the influence of the squad values \u200b\u200bis on the number of points scored:", "The adjusted R is 0.569. This means that the squad value explains 56,9% of the variance of the points. The result is statistically significant and for every million Euros, the number of points scored increases by 0.2029 on average.", "In this article, we first developed a hypothesis and then identified a database on the Web. We looked at the basics of web scraping and developed a script based on a specific problem with which we can read the data of the website purposefully. Then we prepared and cleaned up the data to form the basis for our analysis. Using basic statistical methodology, we checked our hypothesis. The correlation between squad value and athletic success is significant. Furthermore the influence of the squad value on the scores is very high. A much more detailed analysis can be found here.", "If you enjoy Medium and Towards Data Science and didn\u2019t sign up yet, feel free to use my referral link to join the community.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Analyst in a management consultancy | Interested in data science, web scraping & storytelling | https://www.linkedin.com/in/benedikt-droste-893b1b189/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F98ac3c774bd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@droste.benedikt?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@droste.benedikt?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "Benedikt Droste"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93813b47e030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&user=Benedikt+Droste&userId=93813b47e030&source=post_page-93813b47e030----98ac3c774bd---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F98ac3c774bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F98ac3c774bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/money-makes-the-world-go-round-and-thus-also-the-soccer-847bb5350535", "anchor_text": "here"}, {"url": "https://www.transfermarkt.com/bundesliga/startseite/wettbewerb/L1/plus/?saison_id=2018'", "anchor_text": "https://www.transfermarkt.com/bundesliga/startseite/wettbewerb/L1/plus/?saison_id=2018'"}, {"url": "https://www.transfermarkt.com/bundesliga/startseite/wettbewerb/L1/plus/?saison_id=", "anchor_text": "https://www.transfermarkt.com/bundesliga/startseite/wettbewerb/L1/plus/?saison_id="}, {"url": "https://towardsdatascience.com/money-makes-the-world-go-round-and-thus-also-the-soccer-847bb5350535", "anchor_text": "here"}, {"url": "https://github.com/bd317/tutorial_scraping", "anchor_text": "https://github.com/bd317/tutorial_scraping"}, {"url": "https://github.com/bd317/tutorial_scraping/blob/master/Soccer_Scrape_Tutorial_Part_1%20(1).ipynb", "anchor_text": "https://github.com/bd317/tutorial_scraping/blob/master/Soccer_Scrape_Tutorial_Part_1%20(1).ipynb"}, {"url": "https://github.com/bd317/tutorial_scraping/blob/master/Soccer_Scrape_Tutorial_Part_2.ipynb", "anchor_text": "https://github.com/bd317/tutorial_scraping/blob/master/Soccer_Scrape_Tutorial_Part_2.ipynb"}, {"url": "https://www.transfermarkt.com/", "anchor_text": "https://www.transfermarkt.com"}, {"url": "https://www.uefa.com/memberassociations/uefarankings/country/#/yr/2019", "anchor_text": "https://www.uefa.com/memberassociations/uefarankings/country/#/yr/2019"}, {"url": "https://medium.com/@droste.benedikt/membership", "anchor_text": "If you enjoy Medium and Towards Data Science and didn\u2019t sign up yet, feel free to use my referral link to join the community."}, {"url": "https://medium.com/tag/data-science?source=post_page-----98ac3c774bd---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----98ac3c774bd---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/tag/analytics?source=post_page-----98ac3c774bd---------------analytics-----------------", "anchor_text": "Analytics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F98ac3c774bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&user=Benedikt+Droste&userId=93813b47e030&source=-----98ac3c774bd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F98ac3c774bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&user=Benedikt+Droste&userId=93813b47e030&source=-----98ac3c774bd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F98ac3c774bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F98ac3c774bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----98ac3c774bd---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----98ac3c774bd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----98ac3c774bd--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----98ac3c774bd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@droste.benedikt?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@droste.benedikt?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Benedikt Droste"}, {"url": "https://medium.com/@droste.benedikt/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "971 Followers"}, {"url": "https://www.linkedin.com/in/benedikt-droste-893b1b189/", "anchor_text": "https://www.linkedin.com/in/benedikt-droste-893b1b189/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93813b47e030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&user=Benedikt+Droste&userId=93813b47e030&source=post_page-93813b47e030--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe545585931c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftutorial-from-the-hypothesis-to-the-analysis-with-web-scraping-98ac3c774bd&newsletterV3=93813b47e030&newsletterV3Id=e545585931c&user=Benedikt+Droste&userId=93813b47e030&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}