{"url": "https://towardsdatascience.com/reinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2", "time": 1683002661.506295, "path": "towardsdatascience.com/reinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2/", "webpage": {"metadata": {"title": "Reinforcement Learning in a few lines of code | by Maarten Grootendorst | Towards Data Science", "h1": "Reinforcement Learning in a few lines of code", "description": "Reinforcement learning has seen major improvements over the last year with state-of-the-art methods coming out on a bi-monthly basis. We have seen AlphaGo beat world champion Go player Ke Jie\u2026"}, "outgoing_paragraph_urls": [{"url": "https://deepmind.com/alphago-china", "anchor_text": "Ke Jie", "paragraph_index": 0}, {"url": "https://www.youtube.com/watch?v=kopoLzvh5jY&feature=youtu.be", "anchor_text": "Hide and Seek", "paragraph_index": 0}, {"url": "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii", "anchor_text": "Starcraft", "paragraph_index": 0}, {"url": "https://simoninithomas.github.io/Deep_reinforcement_learning_Course/", "anchor_text": "this", "paragraph_index": 2}, {"url": "https://github.com/dennybritz/reinforcement-learning", "anchor_text": "this", "paragraph_index": 2}, {"url": "http://gym.openai.com/envs/#classic_control", "anchor_text": "this", "paragraph_index": 10}, {"url": "https://github.com/openai/gym/issues/1726", "anchor_text": "this", "paragraph_index": 11}, {"url": "https://github.com/openai/retro", "anchor_text": "Retro", "paragraph_index": 12}, {"url": "https://simoninithomas.github.io/Deep_reinforcement_learning_Course/", "anchor_text": "this", "paragraph_index": 21}, {"url": "https://github.com/dennybritz/reinforcement-learning", "anchor_text": "this", "paragraph_index": 21}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "Stable Baselines", "paragraph_index": 22}, {"url": "https://github.com/openai/baselines/", "anchor_text": "Baselines", "paragraph_index": 22}, {"url": "https://openai.com/blog/openai-baselines-ppo/", "anchor_text": "PPO2", "paragraph_index": 24}, {"url": "https://www.linkedin.com/in/mgrootendorst/", "anchor_text": "LinkedIn", "paragraph_index": 34}, {"url": "http://www.linkedin.com/in/mgrootendorst/", "anchor_text": "www.linkedin.com/in/mgrootendorst/", "paragraph_index": 36}], "all_paragraphs": ["Reinforcement learning has seen major improvements over the last year with state-of-the-art methods coming out on a bi-monthly basis. We have seen AlphaGo beat world champion Go player Ke Jie, Multi-Agents play Hide and Seek, and even AlphaStar competitively hold its own in Starcraft.", "Implementing these algorithms can be quite challenging as it requires a good understanding of both Deep Learning and Reinforcement Learning. The purpose of this article is to give you a quick start using some neat packages such that you can easily start with Reinforcement Learning.", "For in-depth tutorials on how to implement SOTA Deep Reinforcement Learning algorithms, please see this and this. They are highly recommended!", "Before we can start implementing these algorithms we first need to create an environment to work in, namely the games. It is important for the algorithm to understand what is action and observation space. For that, we will go into several packages that can be used for selecting interesting environments.", "Gym is a toolkit for developing and comparing reinforcement learning algorithms. It is typically used for experimentation and research purposes as it provides a simple to use interface for working with environments.", "Simply install the package with: pip install gym. After doing so, you can create an environment using the following code:", "In the CartPole environment, you are tasked with preventing a pole, attached by an un-actuated joint to a cart, from falling over.", "The env variable contains information about the environment (the game). To understand what the action space is of CartPole, simply run env.action_space which will yield Discrete(2). This means that there are two discrete actions possible. To view the observation space you run env.observation_spacewhich yields Box(4). This box represents theCartesian product of n (4) closed intervals.", "To render the game, run the following piece of code:", "We can see that the cart is constantly failing if we choose to take random actions. Eventually, the goal will be to run a Reinforcement Learning algorithm that will learn how to solve this problem.", "For a full list of environments in Gym, please see this.", "NOTE: If you have a problem running the atari games, please see this.", "Another option for creating interesting environments is to use Retro. This package is developed by OpenAI and allows you to use ROMS to emulate games such as Airstriker-Genesis.", "Simply install the package with pip install gym-retro. Then, we can create and view environments with:", "Again, to render the game, run the following piece of code:", "To install ROMS you need to find the corresponding .sha files and then run:", "NOTE: For a full list of readily available environments, run retro.data.list_games().", "A typical problem with Reinforcement Learning is that the resulting algorithms often work very well with specific environments, but fail to learn any generalizable skills. For example, what if we were to change how a game looks or how the enemy responds?", "To solve this problem OpenAI developed a package called Procgen, which allows creating procedurally-generated environments. We can use this package to measure how quickly a Reinforcement Learning Agent learns generalizable skills.", "This will generate a single level on which the algorithm can be trained. There are several options available to procedurally generate many different versions of the same environment:", "Now, it is finally time for the actual Reinforcement Learning. Although there are many packages available that can be used to train the algorithms, I will be mostly going into Stable Baselines due to their solid implementations.", "Note that I will not be explaining how the RL-algorithms actually work in this post as that would require an entirely new post in itself. For an overview of state-of-the-art algorithms such as PPO, SAC, and TD3 please see this or this.", "Stable Baselines (SB) is based upon OpenAI Baselines and is meant to make it easier for the research community and industry to replicate, refine, and identify new ideas. They improved upon on Baselines to make a more stable and simple tool that allows beginners to experiment with Reinforcement Learning without being buried in implementation details.", "SB is often used due to its easy and quick application of state-of-the-art Reinforcement Learning Algorithms. Moreover, only a few lines of code are necessary to create and train RL-models.", "Installation can simply be done with: pip install stable-baselines. Then, to create and learn an RL-model, for example, PPO2, we run the following lines of code:", "There are a few things that might need some explanation:", "In order to apply this model to the CartPole example, we need to wrap our environment in a Dummy to make it available to SB. The full example of training PPO2 on the CartPole environment is then as follows:", "As we can see in the image above, in only 50,000 steps PPO2 has managed to find out a way to keep the pole stable. This required only a few lines of code and a couple of minutes of processing!", "If you want to apply this to Procgen or Retro, make sure to select a policy that allows for a Convolution-based network as the observation space is likely to be the image of the current state of the environment.", "Finally, the CartPole example is an extremely simple one which makes it possible to train it only 50,000 steps. Most other environments typically take tens of millions of steps before showing significant improvements.", "NOTE: The authors of Stable Baselines warn beginners to get a good understanding when it comes to Reinforcement Learning before using the package in productions. There are many crucial components of Reinforcement Learning that if any of them go wrong, the algorithm will fail and likely leaves very little explanation.", "There are several other packages that are frequently used to apply RL-algorithms:", "Reinforcement Learning can be a tricky subject as it is difficult to debug if and when something is going wrong in your code. Hopefully, this post helped you get started with Reinforcement Learning.", "All code can be found in:", "If you are, like me, passionate about AI, Data Science or Psychology, please feel free to add me on LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Psychologist. Passionate about anything AI-related! Get in touch: www.linkedin.com/in/mgrootendorst/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd6c8af1e0fd2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@maartengrootendorst?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maartengrootendorst?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "Maarten Grootendorst"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22405c3b2875&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&user=Maarten+Grootendorst&userId=22405c3b2875&source=post_page-22405c3b2875----d6c8af1e0fd2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6c8af1e0fd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6c8af1e0fd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://deepmind.com/alphago-china", "anchor_text": "Ke Jie"}, {"url": "https://www.youtube.com/watch?v=kopoLzvh5jY&feature=youtu.be", "anchor_text": "Hide and Seek"}, {"url": "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii", "anchor_text": "Starcraft"}, {"url": "https://simoninithomas.github.io/Deep_reinforcement_learning_Course/", "anchor_text": "this"}, {"url": "https://github.com/dennybritz/reinforcement-learning", "anchor_text": "this"}, {"url": "http://gym.openai.com/envs/#classic_control", "anchor_text": "this"}, {"url": "https://github.com/openai/gym/issues/1726", "anchor_text": "this"}, {"url": "https://github.com/openai/retro", "anchor_text": "Retro"}, {"url": "https://simoninithomas.github.io/Deep_reinforcement_learning_Course/", "anchor_text": "this"}, {"url": "https://github.com/dennybritz/reinforcement-learning", "anchor_text": "this"}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "Stable Baselines"}, {"url": "https://github.com/openai/baselines/", "anchor_text": "Baselines"}, {"url": "https://openai.com/blog/openai-baselines-ppo/", "anchor_text": "PPO2"}, {"url": "https://github.com/tensorflow/agents", "anchor_text": "TF-Agents"}, {"url": "https://github.com/seungeunrho/minimalRL", "anchor_text": "MinimalRL"}, {"url": "https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch", "anchor_text": "DeepRL"}, {"url": "https://github.com/Unity-Technologies/ml-agents", "anchor_text": "MlAgents"}, {"url": "https://github.com/MaartenGr/ReinforcementLearning", "anchor_text": "MaartenGr/ReinforcementLearningCreate state-of-the-art reinforcement learning algorithms on dynamic environments using Stable-baselines, Gym, Retro, and Procgen.github.com"}, {"url": "https://www.linkedin.com/in/mgrootendorst/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d6c8af1e0fd2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----d6c8af1e0fd2---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d6c8af1e0fd2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----d6c8af1e0fd2---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/openai?source=post_page-----d6c8af1e0fd2---------------openai-----------------", "anchor_text": "OpenAI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6c8af1e0fd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&user=Maarten+Grootendorst&userId=22405c3b2875&source=-----d6c8af1e0fd2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6c8af1e0fd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&user=Maarten+Grootendorst&userId=22405c3b2875&source=-----d6c8af1e0fd2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6c8af1e0fd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd6c8af1e0fd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d6c8af1e0fd2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d6c8af1e0fd2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maartengrootendorst?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maartengrootendorst?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Maarten Grootendorst"}, {"url": "https://medium.com/@maartengrootendorst/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4.5K Followers"}, {"url": "http://www.linkedin.com/in/mgrootendorst/", "anchor_text": "www.linkedin.com/in/mgrootendorst/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22405c3b2875&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&user=Maarten+Grootendorst&userId=22405c3b2875&source=post_page-22405c3b2875--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb052d90faf55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2&newsletterV3=22405c3b2875&newsletterV3Id=b052d90faf55&user=Maarten+Grootendorst&userId=22405c3b2875&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}