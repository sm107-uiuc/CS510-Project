{"url": "https://towardsdatascience.com/comprehending-principal-component-analysis-9e820094ed44", "time": 1683006119.930235, "path": "towardsdatascience.com/comprehending-principal-component-analysis-9e820094ed44/", "webpage": {"metadata": {"title": "Comprehending Principal Component Analysis | by Ashu Prasad | Towards Data Science", "h1": "Comprehending Principal Component Analysis", "description": "Analysis of complex data often involves dealing with a multi dimensional dataset. Most of the time, there\u2019s a lot of noise in the data and one has to navigate through this noise identify useful\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/ashuprasad/", "anchor_text": "https://www.linkedin.com/in/ashuprasad/", "paragraph_index": 70}], "all_paragraphs": ["Analysis of complex data often involves dealing with a multi dimensional dataset. Most of the time, there\u2019s a lot of noise in the data and one has to navigate through this noise identify useful information or signal. Further, it is an arduous task to visualize data that tends to exceed the three dimensional space.", "Principal Component Analysis (PCA) is a technique of reducing dimensionality of our dataset while retaining meaningful variation in the data. This method ensures that the complexity of data is reduced without compromising on the information extracted from data. This is known as \u2018Dimensionality Reduction\u2019.", "Typically, features with a lot of variance tend to contain meaningful information. Predictive algorithms attempt to learn these variations and consequently are able to identify patterns in the data. Thus features having a high variance is a basic requirement for building accurate predictive models. PCA can capture these variations in data and can facilitate predictive algorithms to furnish good results.", "PCA is also able to generate features that are independent of each other. This is particularly significant in identifying uncorrelated data. While building a predictive model, it is advisable to select features which are independent of each other to avoid multicollinearity.", "Multicollinearity occurs when we have features in our dataset that are correlated with each other. The idea when selecting features is to have a set of independent features through which the value of a dependent feature or target variable can be predicted. If we have features that are correlated, a slight variation in one feature might begin to affect other features and consequently lead to reduced precision of our model.", "Another reason for using PCA is to reduce the number of features that we select for our predictive model. The more number of features we select, the more our model will grow in complexity and the more the model will begin to overfit the data. Overfitting can lead to excellent model performance on our training set but considerable poor performance on our test set. The idea behind using PCA is to retain the information in our dataset while also reducing the model complexity.", "To understand Principal Component Analysis, let\u2019s take an example of a mouse and genes dataset.", "Let\u2019s consider plotting a graph taking only one feature from our dataset. We are taking that feature to be \u2018Gene_1\u2019. Considering that we have only one feature, we\u2019ll be having only a single dimension in our graph.", "Now, let\u2019s take two features to plot our graph, namely \u2018Gene_1\u2019 and \u2018Gene_2\u2019. In this case, we\u2019ll be dealing with two dimensions.", "Continuing with the same trend, let\u2019s now take three features into consideration, \u2018Gene_1\u2019, \u2018Gene_2\u2019 and \u2018Gene_3\u2019. Now, we\u2019ll be having a three dimensional plot.", "Note: The samples of data that are larger in value for \u2018Gene_3\u2019 are smaller in size as they\u2019ll be located away from the origin, while those smaller in value will be nearer the origin.", "Now, if we want to plot a graph with a fourth feature, a four dimensional plot is required which is not possible to draw.", "Principal Component Analysis (PCA) can take these four or more dimensional data and can squeeze them in a two dimensional plot which can make it easier for us to analyze.", "Let\u2019s try to understand how this is possible\u2026", "Let\u2019s revert back to our previous two dimensional plot to gain an intuition behind it.", "The point in the middle denoted by \u2018X\u2019 represents the center of the data. Once we are aware of the center, we try to shift the plot such that the center coincides with the origin of the axis.", "We then pass a line through the origin and project the data points onto it.", "In order for the line passing through the origin to be a best fit line on the data, we need to minimize the projected length of the data onto the line (The thin black lines). This can also be achieved by maximizing the distance of the projected points of the data from the origin (The red lines).", "To understand this concept of minimization and maximization, let\u2019s build an intuition.", "As we try to get a line that better fits our data, the length of the projected lines (The thin black lines) gradually decreases while the length of the distance of the projected points from the origin (The red lines) gradually increases.", "Let\u2019s assume that we have a single data point in our x-y plane. The length of the projected line is denoted by \u2018b\u2019 and the distance of the projected point from the origin is denoted by \u2018c\u2019, finally, the distance of the data point from the origin is denoted by \u2018a\u2019.", "We are well aware that while projecting a point onto a line, the projected line is perpendicular to that line.", "Since this property is true, we are presented with a right angled triangle and \u2018Pythagoras\u2019s theorem\u2019 can be applied here.", "Therefore, we can observe that the value of a\u00b2 will remain constant even if we try to change the orientation of the blue line. The only variables we are having here are the values of b\u00b2 and c\u00b2.", "We can also observe that as we attempt to fit the blue line to our data, the value of \u2018b\u2019 decreases. Consequently, the value of \u2018b\u00b2\u2019 also decreases.", "According to \u2018Pythagoras\u2019 theorem\u2019 if \u2018b\u00b2\u2019 decreases and \u2018a\u00b2\u2019 remains constant, the only way we can maintain the equality is by increasing the value of \u2018c\u00b2\u2019.", "Intuitively, it is \u2018b\u2019 that has to be minimized but it is actually \u2018c\u2019 that is easier to calculate.", "PCA therefore attempts to maximize the value of \u2018c\u2019.", "Now that we are clear with this picture in mind, we shall attempt to apply this method for the data we have in our hand.", "This quantity is known as Sum of squared distances. We\u2019ll be representing this by \u2018SS\u2019.", "We\u2019ll now rotate the blue line by a small angle while calculating the sum of the squared distances (SS) in an attempt to find the best fit line to the data. This process is repeated until we achieve the maximum value of SS.", "We\u2019ve finally achieved the best fit line for the data in the above graph. For this line, we have the largest value for SS. This best fit line is also called the \u2018Principal Component 1\u2019 or \u2018PC1\u2019.", "Let\u2019s assume that for this data distribution, we have a PC1 slope of \u20180.25\u2019.", "This means, for every 4 points that we move in direction of the \u2018X-axis\u2019, we move 1 point in the direction of \u2018Y-axis\u2019. So what we can understand through this is that, PC1 is more spread out across \u2018Gene_1\u2019 and comparatively less spread out across the \u2018Gene_2\u2019 axis.", "This is analogous to a food recipe. In order to make PC1, we\u2019ll first add 4 parts of \u2018Gene_1\u2019 and 1 part \u2018Gene_2\u2019. This tells us that for PC1, \u2018Gene_1\u2019 is more important than \u2018Gene_2\u2019 relatively speaking.", "This combination of different features to make PC1 is called \u2018Linear Combination\u2019.", "So, for PC1 we have a linear combination of:-", "By following the \u2018Linear Combination\u2019 of variables we get a vector interpretation of PC1.", "Using Pythagoras\u2019 theorem, we can measure the magnitude of the PC1 vector.", "Singular Value Decomposition (SVD) is used to scale the PC1 vector to a unit vector. When we apply PCA with SVD we are presented with the following results.", "We can observe that even though the values for the Linear Combination have changed for the PC1 unit vector, the ratio remains the same for individual components.", "This unit vector for PC1 is known as the \u2018Eigenvector\u2019 or \u2018Singular Vector\u2019. The proportion of each of Gene_1 and Gene_2 is called the \u2018Loading Scores\u2019. The Loading Scores is instrumental in telling us which feature is more important, for example for PC1 in terms of the data projected onto it, Loading Scores can tell us that Gene_1 is 4 times more important than Gene_1.", "The Loading Scores for PC1 are:-", "PCA calls the Sum of the Squared distances or the SS distance for the best fit line the \u2018Eigenvalue\u2019 for PC1 and the square root of the Eigenvalue is called the \u2018Singular value for PC1\u2019.", "Principal Component 2 or PC2 is simply a line through the origin that is perpendicular to PC1.", "This is done in view of the principle of orthogonality. Two vectors are considered orthogonal if they are perpendicular to each other. Thus any change or shift of data in one axis or movement of one vector does not generate any corresponding change or shift in an orthogonal axis or the orthogonal vector. The two vectors are essentially independent of each other.", "The data is projected onto PC2 in a similar fashion to PC1.", "Since PC2 is orthogonal to PC1, the recipe for PC2 is:-", "After scaling through SVD, the Loading Scores for PC2 are:-", "PC1 and PC2 are then rotated such that PC1 is horizontal. We then use the projected points on the Principal Components to plot the data points in the new dimensional plane.", "We now have an entirely new frame to analyze our data. The original axis serves us no purpose and can be eliminated.", "We observe that the majority of the data points tend to lie on PC1. This brings us to an important observation. There exist a large amount of variation of the data across PC1 than on PC2, in fact, PC1 exhibits the largest amount of data variation compared to any other Principal Component and thus is an important feature in the analysis of our data.", "This is because it is the variation in data that machine learning algorithms attempt to learn in order to make predictions in the future.", "The Eigenvalues are used to calculate the contribution of variation of each Principal Components.", "Where \u2019n\u2019 represents the sample size or in simple words, the number of data points.", "The concept of PCA remains pretty much the same.", "Therefore, all PCs are perpendicular to each other.", "Note: In theory, there is one PCA axis per variable or feature but in practice, the number of PCs is either number of variables or the number of samples whichever is smaller.", "Once we have all PCs drawn out, we can use the Eigenvalues i.e. SS distances to determine the proportion of variation each PC accounts for.", "So, let\u2019s assume that in this case,", "We can draw a Scree plot of this PCA.", "We can observe that PC1 and PC2 account for 94% of the data. Therefore, we can omit PC3 in our analysis and resort to only use PC1 and PC2.", "This is how \u2018Dimensionality Reduction\u2019 comes into play. We effectively reduced the number of dimensions that our data depended upon from three to two.", "However, sometimes we do get situations like these.", "In such a case where each Principal Component contributes almost equally as the other, taking only a few PCs into consideration will not be enough to account for all the variation. However, even a noisy PCA can help in clustering the data.", "Employing Principal Component Analysis in the analysis of our data has its fair share of benefits. However, we do face a few drawbacks while using this method.", "Once we run our features through PCA, it effectively creates a new set of features that holds the information present in the original features. This new set of features thus created are the Principal Components. Without the domain expertise, we really can\u2019t tell what these Principal Components represent. Thus we have a general loss of interpretability.", "This, however, is not a major setback for our predictive model. If we are able to extract important information from our data, then this method remains a useful technique which we can employ without worrying about the model overfitting the data.", "Thanks for reading this blog. I would appreciate hearing your thoughts on this.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI Enthusiast | Ardent Learner | Let\u2019s Connect https://www.linkedin.com/in/ashuprasad/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9e820094ed44&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e820094ed44--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e820094ed44--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ashuprasad29516.medium.com/?source=post_page-----9e820094ed44--------------------------------", "anchor_text": ""}, {"url": "https://ashuprasad29516.medium.com/?source=post_page-----9e820094ed44--------------------------------", "anchor_text": "Ashu Prasad"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F999d67912c99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&user=Ashu+Prasad&userId=999d67912c99&source=post_page-999d67912c99----9e820094ed44---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e820094ed44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e820094ed44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@m_rags?utm_source=medium&utm_medium=referral", "anchor_text": "madeleine ragsdale"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.youtube.com/watch?v=FgakZw6K1QQ", "anchor_text": "https://www.youtube.com/watch?v=FgakZw6K1QQ"}, {"url": "https://towardsdatascience.com/understanding-pca-fae3e243731d", "anchor_text": "https://towardsdatascience.com/understanding-pca-fae3e243731d"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9e820094ed44---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9e820094ed44---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----9e820094ed44---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/statistics?source=post_page-----9e820094ed44---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/predictive-analytics?source=post_page-----9e820094ed44---------------predictive_analytics-----------------", "anchor_text": "Predictive Analytics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e820094ed44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&user=Ashu+Prasad&userId=999d67912c99&source=-----9e820094ed44---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e820094ed44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&user=Ashu+Prasad&userId=999d67912c99&source=-----9e820094ed44---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e820094ed44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e820094ed44--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9e820094ed44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9e820094ed44---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e820094ed44--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9e820094ed44--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9e820094ed44--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9e820094ed44--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9e820094ed44--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9e820094ed44--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9e820094ed44--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9e820094ed44--------------------------------", "anchor_text": ""}, {"url": "https://ashuprasad29516.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ashuprasad29516.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ashu Prasad"}, {"url": "https://ashuprasad29516.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "126 Followers"}, {"url": "https://www.linkedin.com/in/ashuprasad/", "anchor_text": "https://www.linkedin.com/in/ashuprasad/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F999d67912c99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&user=Ashu+Prasad&userId=999d67912c99&source=post_page-999d67912c99--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5e96b66a0c09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomprehending-principal-component-analysis-9e820094ed44&newsletterV3=999d67912c99&newsletterV3Id=5e96b66a0c09&user=Ashu+Prasad&userId=999d67912c99&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}