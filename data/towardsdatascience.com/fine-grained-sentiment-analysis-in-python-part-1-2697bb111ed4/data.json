{"url": "https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4", "time": 1683000224.007703, "path": "towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4/", "webpage": {"metadata": {"title": "Fine-grained Sentiment Analysis in Python (Part 1) | by Prashanth Rao | Towards Data Science", "h1": "Fine-grained Sentiment Analysis in Python (Part 1)", "description": "Fine-grained sentiment analysis using various Python NLP libraries: TextBlob, VADER, Logistic Regression, Support Vector Machines (SVM), FastText and Flair"}, "outgoing_paragraph_urls": [{"url": "https://python.swaroopch.com/oop.html", "anchor_text": "object-oriented", "paragraph_index": 3}, {"url": "https://nlp.stanford.edu/sentiment/", "anchor_text": "Stanford Sentiment Treebank", "paragraph_index": 7}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "Recursive Neural Tensor Network", "paragraph_index": 8}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "the paper", "paragraph_index": 8}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "Stanford paper", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1802.05365v2.pdf", "anchor_text": "ELMo embeddings", "paragraph_index": 9}, {"url": "https://github.com/sebastianruder/NLP-progress/blob/master/english/sentiment_analysis.md#sst", "anchor_text": "achieve a significantly higher accuracy", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1806.00807.pdf", "anchor_text": "a method that uses sentence-level embeddings", "paragraph_index": 9}, {"url": "https://pypi.org/project/pytreebank/", "anchor_text": "pytreebank", "paragraph_index": 11}, {"url": "https://github.com/prrao87/fine-grained-sentiment/blob/master/data/sst/tree2tabular.py", "anchor_text": "this project\u2019s GitHub repo", "paragraph_index": 11}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "original paper", "paragraph_index": 18}, {"url": "https://github.com/prrao87/fine-grained-sentiment/tree/master/training", "anchor_text": "available in the project\u2019s GitHub repo", "paragraph_index": 25}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html", "anchor_text": "confusion matrix", "paragraph_index": 28}, {"url": "https://github.com/prrao87/fine-grained-sentiment/blob/master/plotter.py", "anchor_text": "plotter.py", "paragraph_index": 28}, {"url": "https://en.wikipedia.org/wiki/Anti-diagonal_matrix", "anchor_text": "anti-diagonal matrix", "paragraph_index": 28}, {"url": "https://textblob.readthedocs.io/en/dev/", "anchor_text": "TextBlob", "paragraph_index": 30}, {"url": "http://www.nltk.org", "anchor_text": ",", "paragraph_index": 30}, {"url": "https://planspace.org/20150607-textblob_sentiment/", "anchor_text": "in this blog post", "paragraph_index": 31}, {"url": "https://en.wikipedia.org/wiki/Anti-diagonal_matrix", "anchor_text": "anti-diagonal", "paragraph_index": 35}, {"url": "https://sebastianraschka.com/faq/docs/logisticregr-neuralnet.html", "anchor_text": "gives a very concise explanation", "paragraph_index": 45}, {"url": "https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest", "anchor_text": "one-vs-rest", "paragraph_index": 46}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "CountVectorizer", "paragraph_index": 47}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html", "anchor_text": "scikit-learn documentation", "paragraph_index": 47}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html", "anchor_text": "L2 regularization is used by default", "paragraph_index": 49}, {"url": "https://towardsdatascience.com/support-vector-machine-vs-logistic-regression-94cc2975433f", "anchor_text": "This makes it more robust to outliers in the data", "paragraph_index": 54}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html", "anchor_text": "L2 regularization is applied during training", "paragraph_index": 55}, {"url": "https://fasttext.cc/blog/2016/08/18/blog-post.html", "anchor_text": "library for text representation and classification", "paragraph_index": 59}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Word2Vec", "paragraph_index": 59}, {"url": "https://fasttext.cc/blog/2016/08/18/blog-post.html", "anchor_text": "after several months of confusion within the community", "paragraph_index": 60}, {"url": "https://fasttext.cc/docs/en/support.html#building-fasttext-as-a-command-line-tool", "anchor_text": "fasttext", "paragraph_index": 61}, {"url": "https://fasttext.cc/docs/en/support.html#building-fasttext-as-a-command-line-tool", "anchor_text": "command line interface", "paragraph_index": 61}, {"url": "https://fasttext.cc/docs/en/autotune.html", "anchor_text": "documentation", "paragraph_index": 61}, {"url": "https://nervanasystems.github.io/distiller/quantization.html", "anchor_text": "Quantization", "paragraph_index": 63}, {"url": "https://fasttext.cc/docs/en/cheatsheet.html#quantization", "anchor_text": "FastText makes quantization very convenient", "paragraph_index": 63}, {"url": "https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3", "anchor_text": "this article gives a good description", "paragraph_index": 65}, {"url": "https://github.com/zalandoresearch/flair", "anchor_text": "Zalando Research published a state-of-the-art deep learning sequence tagging NLP library", "paragraph_index": 72}, {"url": "https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md#combining-bert-and-flair", "anchor_text": "\u201cstack\u201d word embeddings", "paragraph_index": 74}, {"url": "https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md#flair-embeddings", "anchor_text": "character-level string embeddings capture latent syntactic-semantic information", "paragraph_index": 75}, {"url": "https://github.com/tqdm/tqdm/blob/master/examples/pandas_progress_apply.py", "anchor_text": "tqdm", "paragraph_index": 77}, {"url": "https://github.com/tqdm/tqdm/blob/master/examples/pandas_progress_apply.py", "anchor_text": "progress bar", "paragraph_index": 77}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME Python library", "paragraph_index": 84}, {"url": "https://github.com/prrao87/fine-grained-sentiment", "anchor_text": "available in the project\u2019s Github repo,", "paragraph_index": 86}], "all_paragraphs": ["\u201cLearning to choose is hard. Learning to choose well is harder. And learning to choose well in a world of unlimited possibilities is harder still, perhaps too hard.\u201d \u2014 Barry Schwartz", "When starting a new NLP sentiment analysis project, it can be quite an overwhelming task to narrow down on a select methodology for a given application. Do we use a rule-based model, or do we train a model on our own data? Should we train a neural network, or will a simple linear model meet our requirements? Should we spend the time and effort in implementing our own text classification framework, or can we just use one off-the-shelf? How hard is it to interpret the results and understand why certain predictions were made?", "This series aims at answering some of the above questions, with a focus on fine-grained sentiment analysis. Through the remaining sections, we\u2019ll compare and discuss classification results using several well-known NLP libraries in Python. The methods described below fall under three broad categories:", "Each approach is implemented in an object-oriented manner in Python, to ensure that we can easily swap out models for experiments and extend the framework with better, more powerful classifiers in the future.", "In most cases today, sentiment classifiers are used for binary classification (just positive or negative sentiment), and for good reason: fine-grained sentiment classification is a significantly more challenging task! The typical breakdown of fine-grained sentiment uses five discrete classes, as shown below. As one might imagine, models very easily err on either side of the strong/weak sentiment intensities thanks to the wonderful subtleties of human language.", "Binary class labels may be sufficient for studying large-scale positive/negative sentiment trends in text data such as Tweets, product reviews or customer feedback, but they do have their limitations. When performing information extraction with comparative expressions, for example: \u201cThis OnePlus model X is so much better than Samsung model X.\u201d \u2014 a fine-grained analysis can provide more precise results to an automated system that prioritizes addressing customer complaints. In addition, dual-polarity sentences such as \u201cThe location was truly disgusting ... but the people there were glorious.\u201d can confuse binary sentiment classifiers, leading to incorrect class predictions.", "The above points provide sufficient motivation to tackle this problem!", "The Stanford Sentiment Treebank (SST-5, or SST-fine-grained) dataset is a suitable benchmark to test our application, since it was designed to help evaluate a model\u2019s ability to understand representations of sentence structure, rather than just looking at individual words in isolation. SST-5 consists of 11,855 sentences extracted from movie reviews with fine-grained sentiment labels [1\u20135], as well as 215,154 phrases that compose each sentence in the dataset.", "The raw data with phrase-based fine-grained sentiment labels is in the form of a tree structure, designed to help train a Recursive Neural Tensor Network (RNTN) from their 2015 paper. The component phrases were constructed by parsing each sentence using the Stanford parser (section 3 in the paper) and creating a recursive tree structure as shown in the below image. A deep neural network was then trained on the tree structure of each sentence to classify the sentiment of each phrase to obtain a cumulative sentiment of the entire sentence.", "The original RNTN implemented in the Stanford paper [Socher et al.] obtained an accuracy of 45.7% on the full-sentence sentiment classification. More recently, a Bi-attentive Classification Network (BCN) augmented with ELMo embeddings has been used to achieve a significantly higher accuracy of 54.7% on the SST-5 dataset. The current (as of 2019) state-of-the-art accuracy on the SST-5 dataset is 64.4%, by a method that uses sentence-level embeddings originally designed to solve a paraphrasing task \u2014 it ended up doing surprisingly well on fine-grained sentiment analysis as well.", "Although neural language models have been getting increasingly powerful since 2018, it might take far bigger deep learning models (with far more parameters) augmented with knowledge-based methods (such as graphs) to achieve sufficient semantic context for accuracies of 70\u201380% in fine-grained sentiment analysis.", "To evaluate our NLP methods and how each one differs from the other, we will use just the complete samples in the training dataset (ignoring the component phrases since we are not using a recursive tree-based classifier like the Stanford paper). The tree structure of phrases is converted to raw text and its associated class label using the pytreebank library. The code for this tree-to-tabular transformation is provided in this project\u2019s GitHub repo.", "The full-sentence text and their class labels (for the train, dev and test sets) are written to individual text files using a tab-delimiter between the sentence and class labels.", "We can then explore the tabular dataset in more detail using Pandas. To begin, read in the training set as a DataFrame while specifying the tab-delimiter to distinguish the class label from the text. Note that the class labels in the column \u201ctruth\u201d are cast to the data type category in Pandas rather than leaving it as a string.", "Using the command df.shape[0] tells us we have 8,544 training samples.", "One important aspect to note before analyzing a sentiment classification dataset is the class distribution in the training data.", "It is clear that most of the training samples belong to classes 2 and 4 (the weakly negative/positive classes). A sizeable number of samples belong to the neutral class. Barely 12% of the samples are from the strongly negative class 1, which is something to keep in mind as we evaluate our classifier accuracy.", "What about the test set? A quick look tells us that we have 2,210 test samples, with a very similar distribution to the training data \u2014 again, there are far fewer samples belonging to the strongly negative/positive classes (1 or 5) compared to the other classes. This is desirable, since the test set distribution on which our classifier makes predictions is not too different from that of the training set.", "An interesting point mentioned in the original paper is that many of the really short text examples belong to the neutral class (i.e. class 3). This can be easily visualized in Pandas. We can create a new column that stores the string length of each text sample, and then sort the DataFrame rows in ascending order of their text lengths.", "Samples with clearly polar words, such as \u201cgood\u201d and \u201cloved\u201d would offer greater context to a sentiment classifier\u2014 however, for neutral sounding words (such as \u201cHopkins\u201d, or \u201cBrimful\u201d), the classifier would have to not only work with extremely small context, i.e. single word samples, but also be able to deal with ambiguous or unseen words that did not appear in the training vocabulary.", "As mentioned in the paper, the SST dataset was labelled by human annotators via Amazon Mechanical Turk. Annotators were shown randomly selected phrases for which they chose labels from a continuous slider bar. A discrete sentiment label belonging to one of five classes was reconstructed based on an average of multiple annotators\u2019 chosen labels. Random sampling was used during annotation to ensure that labelling wasn\u2019t influenced by the phrase that preceded it.", "The above example makes it clear why this is such a challenging dataset on which to make sentiment predictions. For example, annotators tended to categorize the phrase \u201cnerdy folks\u201d as somewhat negative, since the word \u201cnerdy\u201d has a somewhat negative connotation in terms of our society\u2019s current perception of nerds. However, from a purely linguistic perspective, this sample could just as well be classified as neutral.", "It is thus important to remember that text classification labels are always subject to human perceptions and biases. In a real-world application, it absolutely makes sense to look at certain edge cases on a subjective basis. No benchmark dataset \u2014 and by extension, classification model \u2014 is ever perfect.", "With these points in mind, we can proceed onward to designing our sentiment classification framework!", "A general workflow for model training and evaluation is shown below.", "Model Training: Each classifier (except for the rule-based ones) is trained on the 8,544 samples from the SST-5 training set using a supervised learning algorithm. Separate training scripts are available in the project\u2019s GitHub repo.", "Prediction: As per our object-oriented design philosophy, we avoid repeating code blocks that perform the same tasks across the various classification methods. A Base class is defined in Python that contains the commonly used methods: one for reading in the SST-5 data into a Pandas DataFrame (read_data), and another to calculate the model\u2019s classification accuracy and F1-score (accuracy). Storing the dataset in a Pandas DataFrame this way makes it very convenient to apply custom transformations and user-defined functions while avoiding excessive use of for-loops.", "Next, each individual classifier added to our framework must inherit the Base class defined above. To make the framework consistent, a score method and a predict method are included with each new sentiment classifier, as shown below. The score method outputs a unique sentiment class for a text sample, and the predict method applies the score method to every sample in the test dataset to output a new column, 'pred' in the test DataFrame. It is then trivial to compute the model\u2019s accuracy and F1-scores by using the accuracy method defined in the Base class.", "Evaluation: To evaluate the model\u2019s accuracy, a confusion matrix of the model is plotted using scikit-learn and matplotlib (plotter.py on GitHub). The confusion matrix tabulates the number of correct predictions versus the number of incorrect predictions for each class, so it becomes easier to see which classes are the least accurately predicted for a given classifier. Note that the confusion matrix for our 5-class case is a normalized anti-diagonal matrix \u2014 ideally, the classifier would get almost 100% of its predictions correct so all elements outside the anti-diagonal would be as close to zero as possible.", "In this section, we\u2019ll go through some key points regarding the training, sentiment scoring and model evaluation for each method.", "TextBlob is a popular Python library for processing textual data. It is built on top of NLTK, another popular Natural Language Processing toolbox for Python. TextBlob uses a sentiment lexicon (consisting of predefined words) to assign scores for each word, which are then averaged out using a weighted average to give an overall sentence sentiment score. Three scores: \u201cpolarity\u201d, \u201csubjectivity\u201d and \u201cintensity\u201d are calculated for each word.", "Some intuitive rules are hardcoded inside TextBlob to detect modifiers (such as adverbs in English: \u201cvery good\u201d) that increase or decrease the overall polarity score of the sentence. A more detailed description of these rules is available in this blog post.", "Sentiment Scoring: To convert the polarity score returned by TextBlob (a continuous-valued float in the range [-1, 1]) to a fine-grained class label (an integer), we can make use of binning. This is easily done in Pandas using the pd.cut function \u2014 it allows us to go from a continuous variable to a categorical variable by using equal sized bins in the float interval of all TextBlob scores in the results.", "Evaluation: Since we are dealing with imbalanced classes during both training and testing, we look at the macro F1 score (which is the harmonic mean of the macro-averaged precision and recall) as well as classification accuracy. As can be seen , the accuracy of the TextBlob classification method is very low, as is the F1 score.", "The confusion matrix plot shows more detail about which classes were most incorrectly predicted by the classifier.", "To read the above confusion matrix plot, look at the cells along the anti-diagonal. Cell [1, 1] shows the percentage of samples belonging to class 1 that the classifier predicted correctly, cell [2, 2] for correct class 2 predictions, and so on. Cells away from the anti-diagonal show the percentage of wrong predictions made for each respective class \u2014 for example, looking at the cell [4, 5], we can see that 47% of all samples that actually belong to class 5 are (incorrectly) predicted as class 4 by TextBlob.", "It is clear that our TextBlob classifier predicts most samples as neutral or mildly positive, i.e. of class 3 or 4, which explains why the model accuracy is so low. Very few predictions are strongly negative or positive \u2014 this makes sense because TextBlob uses a weighted average sentiment score over all the words in each sample. This can very easily diffuse out the effect of sentences with widely varying polarities between words, such as \u201cThis movie is about lying , cheating , but loving the friends you betray.\u201d", "\u201cValence Aware Dictionary and sEntiment Reasoner\u201d is another popular rule-based library for sentiment analysis. Like TextBlob, it uses a sentiment lexicon that contains intensity measures for each word based on human-annotated labels. A key difference however, is that VADER was designed with a focus on social media texts. This means that it puts a lot of emphasis on rules that capture the essence of text typically seen on social media \u2014 for example, short sentences with emojis, repetitive vocabulary and copious use of punctuation (such as exclamation marks). Below are some examples of the sentiment intensity scores output by VADER.", "In the above text samples, minor variations are made to the same sentence. Note that VADER breaks down sentiment intensity scores into a positive, negative and neutral component, which are then normalized and squashed to be within the range [-1, 1] as a \u201ccompound\u201d score. As we add more exclamation marks, capitalization and emojis/emoticons, the intensity gets more and more extreme (towards +/- 1).", "Sentiment scoring: For returning discrete class values on the SST-5 dataset, we apply a similar technique as done for TextBlob \u2014 the continuous \u201ccompound\u201d polarity score (float) is converted to a discrete value using binning through the pandas pd.cut function. This returns one of five classes for each test sample, stored as a new column in the resulting DataFrame.", "Evaluation: The binning method used above is a rather crude way to equally divide the continuous (float) value from VADER into one of the five discrete classes we require. However, we do see an overall classification accuracy and macro F1 score improvement compared to TextBlob.", "The confusion matrix for VADER shows a lot more classes predicted correctly (along the anti-diagonal) \u2014 however, the spread of incorrect predictions about the diagonal is also greater, giving us a more \u201cconfused\u201d model.", "The greater spread (outside the anti-diagonal) for VADER can be attributed to the fact that it only ever assigns very low or very high compound scores to text that has a lot of capitalization, punctuation, repetition and emojis. Since SST-5 does not really have such annotated text (it is quite different from social media text), most of the VADER predictions for this dataset lie within the range -0.5 to +0.5 (raw scores). This results in a much more narrow distribution when converting to discrete class labels and hence, many predictions can err on either side of the true label.", "Although the result with VADER is still quite low in accuracy, it is clear that its rule-based approach does capture a good amount of fine-gradation in sentiment when compared to TextBlob \u2014 fewer cases that are truly negative get classified as positive, and vice versa.", "Moving onward from rule-based approaches, the next method attempted is a logistic regression \u2014 among the most commonly used supervised learning algorithms for classification. Logistic regression is a linear model trained on labelled data \u2014 the term linear is important because it means the algorithm only uses linear combinations (i.e. sums and not products) of inputs and parameters to produce a class prediction.", "Sebastian Raschka gives a very concise explanation of how the logistic regression equates to a very simple, one-layer neural network in his blog post. The input features and their weights are fed into an activation function (a sigmoid for binary classification, or a softmax for multi-class). The output of the classifier is just the index of the sigmoid/softmax vector with the highest value as the class label.", "For multi-class logistic regression, a one-vs-rest method is typically used \u2014 in this method, we train C separate binary classification models, where C is the number of classes. Each classifier f_c, for c \u2208 {1, \u2026, C} is trained to predict whether a sample is part of class c or not.", "Transforming words to features: To transform the text into features, the first step is to use scikit-learn\u2019s CountVectorizer. This converts the entire corpus (i.e. all sentences) of our training data into a matrix of token counts. Tokens (words, punctuation symbols, etc.) are created using NLTK\u2019s tokenizer and commonly-used stop words like \u201ca\u201d, \u201can\u201d, \u201cthe\u201d are removed because they do not add much value to the sentiment scoring. Next, the count matrix is converted to a TF-IDF (Term-frequency Inverse document frequency) representation. From the scikit-learn documentation:", "Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification. The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.", "Sentiment scoring: Once we obtain the TF-IDF representation of the training corpus, the classifier is trained by fitting it to the existing features. A \u201cnewton-cg\u201d solver is used for optimizing the loss in the logistic regression and L2 regularization is used by default. A sentiment label is returned for each test sample (using scikit-learn\u2019s learner.predict method) as the index of the maximum class probability in the softmax output vector.", "Evaluation: Switching from a rule-based method to a feature-based one shows a significant improvement in the overall classification accuracy and F1 scores, as can be seen below.", "However, the confusion matrix shows why looking at an overall accuracy measure is not very useful in multi-class problems.", "The logistic regression model classifies a large percentage of true labels 1 and 5 (strongly negative/positive) as belonging to their neighbour classes (2 and 4). Also, hardly any examples are correctly classified as neutral (class 3). Because most of the training samples belonged to classes 2 and 4, it looks like the logistic classifier mostly learned the features that occur in these majority classes.", "Support Vector Machines (SVMs) are very similar to logistic regression in terms of how they optimize a loss function to generate a decision boundary between data points. The primary difference, however, is the use of \u201ckernel functions\u201d, i.e. functions that transform a complex, nonlinear decision space to one that has higher dimensionality, so that an appropriate hyperplane separating the data points can be found. The SVM classifier looks to maximize the distance of each data point from this hyperplane using \u201csupport vectors\u201d that characterize each distance as a vector.", "A key feature of SVMs is the fact that it uses a hinge loss rather than a logistic loss. This makes it more robust to outliers in the data, since the hinge loss does not diverge as quickly as a logistic loss.", "Training and sentiment scoring: The linear SVM in scikit-learn is set up using a similar pipeline as done for the logistic regression described in earlier. Once we obtain the TF-IDF representation of the training corpus, we train the SVM model by fitting it to the training data features. A hinge loss function with a stochastic gradient descent (SGD) optimizer is used, and L2 regularization is applied during training. The sentiment label is returned (using scikit-learn\u2019s learner.predict method) as the index of the maximum class probability in the softmax output vector.", "Evaluation: Because quite a few features are likely to be outliers in a realistic dataset, the SVM should in practice produce results that are slightly better than the logistic regression. Looking at the improvement in accuracy and F1 scores, this appears to be true.", "The choice of optimizer combined with the SVM\u2019s ability to model a more complex hyperplane separating the samples into their own classes results in a slightly improved confusion matrix when compared with the logistic regression.", "The SVM model predicts the strongly negative/positive classes (1 and 5) more accurately than the logistic regression. However, it still fails to predict enough samples as belonging to class 3\u2014 a large percentage of the SVM predictions are once again biased towards the dominant classes 2 and 4. This tells us that there is scope for improvement in the way features are defined. A count vectorizer combined with a TF-IDF transformation does not really learn anything about how words are related to one another \u2014 they simply look at the number of word co-occurrences in the each sample to make a conclusion. Enter word embeddings.", "FastText, a highly efficient, scalable, CPU-based library for text representation and classification, was released by the Facebook AI Research (FAIR) team in 2016. A key feature of FastText is the fact that its underlying neural network learns representations, or embeddings that consider similarities between words. While Word2Vec (a word embedding technique released much earlier, in 2013) did something similar, there are some key points that stand out with regard to FastText.", "Python module: Although the source code for FastText is in C++, an official Python module was released by FAIR in June 2019 (after several months of confusion within the community). This makes it very convenient to train and test our model completely within Python, without the use of any external binaries. However, to find the optimum hyperparameters, the command line interface for FastText is recommended.", "Training FastText model: To train the FastText model, use the fasttext command line interface (Unix only) \u2014 this contains a very useful utility for hyperparameter auto-tuning. As per the documentation, this utility optimizes all hyper-parameters for the maximum F1 score, so we don\u2019t need to do a manual search for the best hyper-parameters for our specific dataset. This is run using the following command on the terminal, and takes about 5 minutes on CPU.", "The above command tells FastText to train the model on the training set and validate on the dev set while optimizing the hyper-parameters to achieve the maximum F1-score. The flag -autotune-modelsize 10M tells FastText to optimize the model\u2019s quantization parameters (explained below) such that the final trained model is under 10 MB in size, and the -verbose option is enabled to see which combination of hyper-parameters gives the best results.", "\ud83d\udca1 TIP: Quantize the FastText model: Quantization reduces the number of bits required to store a model\u2019s weights by using 16 or 8-bit integers, rather than standard 32-bit floating points. Doing so vastly reduces model size (by several orders of magnitude). FastText makes quantization very convenient in the latest release of its command line interface or its Python module as follows (the extension of the quantized model is .ftz, not .bin as the parent model). The cutoff option is set as per the value obtained during hyper-parameter optimization, which ensures that the final model size stays below 10 MB.", "The below snippet shows how to train the model from within Python using the optimum hyper-parameters (this step is optional \u2014 only the command-line training tool can be used, if preferred).", "For more details on the meaning of each hyper-parameter and how FastText works under the hood, this article gives a good description.", "Sentiment scoring: Sentiment predictions are made by loading in the trained, quantized (.ftz ) FastText model. The model has a predict method that outputs the most likely labels based on the probabilities extracted from the softmax output layer. For making a class prediction, we simply choose the most likely class label from this list of probabilities, directly extracting it as an integer.", "Evaluation: It can be seen that the FastText model accuracy and F1 scores do not vastly improve on the SVM for this dataset.", "The F1 score for FastText, however, is slightly higher than that for the SVM.", "The confusion matrix of both models side-by-side highlights this in more detail.", "The key difference between the FastText and SVM results is the percentage of correct predictions for the neutral class, 3. The SVM predicts more items correctly in the majority classes (2 and 4) than FastText, which highlight the weakness of feature-based approaches in text classification problems with imbalanced classes. Word embeddings and subword representations, as used by FastText, inherently give it additional context. This is especially true when it comes to classifying unknown words, which are quite common in the neutral class (especially the very short samples with one or two words, mostly unseen).", "However, our FastText model was trained using word trigrams, so for longer sentences that change polarities midway, the model is bound to \u201cforget\u201d the context several words previously. A sequential model such as an RNN or an LSTM would be able to much better capture longer-term context and model this transitive sentiment.", "In 2018, Zalando Research published a state-of-the-art deep learning sequence tagging NLP library called Flair. This quickly became a popular framework for classification tasks as well because of the fact that it allowed combining different kinds of word embeddings together to give the model even greater contextual awareness.", "At the heart of Flair is a contextualized representation called string embeddings. To obtain them, sentences from a large corpus are broken down into character sequences to pre-train a bidirectional language model that \u201clearns\u201d embeddings at the character-level. This way, the model learns to disambiguate case-sensitive characters (for example, proper nouns from similar sounding common nouns) and other syntactic patterns in natural language, which makes it very powerful for tasks like named entity recognition and part-of-speech tagging.", "Training a Flair Model for Classification: What makes Flair extremely convenient yet powerful is its ability to \u201cstack\u201d word embeddings (such as ELMo or BERT) with \u201cFlair\u201d (i.e. string) embeddings. The below example shows how to instantiate a stacked embedding of BERT (base, cased) or ELMo (original) embeddings with Flair embeddings. The stacked representation is converted to a document embedding, i.e. one that gives a single embedding for an entire text sample (no matter how many sentences). This allows us to condense a complex, arbitrary length representation to a fixed-size tensor representation that we can fit in GPU memory for training.", "The power of stacking embeddings (either BERT or ELMo) this way comes from the fact that character-level string embeddings capture latent syntactic-semantic information without using the notion of a word (they explicitly focus on subword representations) \u2014 while the stacked word embeddings from an external pre-trained neural network model give added word-level context. This enhances the model\u2019s ability to identify a wide range of syntactic features in the given text, allowing it to surpass the performance of classical word embedding models.", "Notes on training: The Flair model requires a GPU for training, and due to its LSTM architecture does not parallelize as efficiently as compared to transformer architectures \u2014 so training time even on this relatively small SST-5 dataset is of the order of several hours. For this project, 25 epochs of training were run, and the validation loss was still decreasing when training was stopped, meaning that the model was underfitting considerably. As a result, using Flair on a real-world, large dataset for classification tasks can come with a significant cost penalty.", "Sentiment scoring: Just as before, a scoring technique is implemented with the existing framework in Pandas. The trained model is first loaded, and the text converted to a Sentence object (which is a tokenized representation of each sentence in a sample). The Flair model\u2019s predict method is called to predict a class label using the maximum index from the softmax output layer, which is then extracted as an integer and stored sample-wise in a Pandas DataFrame. Since model inference can take quite a while even on a GPU, a tqdm progress bar is implemented to show how many test samples the model finished predicting.", "Evaluation: Two separate stacked representations are used to train two separate models \u2014 one using BERT (base, cased) and the other using ELMo (original). Inference is run using each model to give the following results.", "There is a sizeable improvement in accuracy and F1 scores over both the FastText and SVM models! Looking at the confusion matrices for each case yields insights into which classes were better predicted than others.", "The above plots highlight why stacking with BERT embeddings scored so much lower than stacking with ELMo embeddings. The BERT case almost makes no correct predictions for class 1 \u2014 however it does get a lot more predictions in class 4 correct. The ELMo model seems to stack much better with the Flair embeddings and generates a larger fraction of correct predictions for the minority classes (1 and 5).", "What went wrong with the Flair + BERT model during training? It could be that re-projecting and decreasing the number of hidden dimensions (during stacking) resulted in a loss of knowledge from the pre-trained BERT model, explaining why this model did not learn well enough on strongly negative samples. It is not exactly clear why stacking ELMo embeddings results in much better learning compared to stacking with BERT. In both cases, however, the Flair models took a large amount of time (several hours) to train, which can be a huge bottleneck in the real-world \u2014yet, they do highlight the power of using contextual embeddings over classical word embeddings for fine-grained classification.", "In this post, six different NLP classifiers in Python were used to make class predictions on the SST-5 fine-grained sentiment dataset. Using progressively more and more complex models, we were able to push up the accuracy and macro-average F1 scores to around 48%, which is not too bad! In a future post, we\u2019ll see how to further improve on these scores using a transformer model powered by transfer learning.", "Plotting normalized confusion matrices give some useful insights as to why the accuracies for the embedding-based methods are higher than the simpler feature-based methods like logistic regression and SVM. It is clear that overall accuracy is a very poor metric in multi-class problems with a class imbalance, such as this one \u2014 which is why macro F1-scores are needed to truly gauge which classifiers perform better.", "A key aspect of machine learning models (especially deep learning models) is that they are notoriously hard to interpret. To address this issue, we\u2019ll look at explaining our results and answering the question: \u201cWhy did X classifier predict this specific class for this specific sample?\u201d. The LIME Python library is used for this task, which will be described in the next post.", "If you made it through to the end of this article, thanks for reading!", "NOTE: All the training and evaluation code for this analysis are available in the project\u2019s Github repo, so feel free to reproduce the results and make your own findings!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Engineer by training. Machine Learning practitioner. I like writing about science, technology and computing."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2697bb111ed4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@tech_optimist?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tech_optimist?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "Prashanth Rao"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fefdb4f4a0d1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&user=Prashanth+Rao&userId=efdb4f4a0d1b&source=post_page-efdb4f4a0d1b----2697bb111ed4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2697bb111ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2697bb111ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/photos/smiley-emoticon-anger-angry-2979107/", "anchor_text": "Pixabay"}, {"url": "https://textblob.readthedocs.io/en/dev/", "anchor_text": "TextBlob"}, {"url": "https://github.com/cjhutto/vaderSentiment", "anchor_text": "VADER"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html", "anchor_text": "Logistic Regression"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier", "anchor_text": "Support Vector Machine (SVM)"}, {"url": "https://fasttext.cc/docs/en/supervised-tutorial.html", "anchor_text": "FastText"}, {"url": "https://github.com/zalandoresearch/flair", "anchor_text": "Flair"}, {"url": "https://python.swaroopch.com/oop.html", "anchor_text": "object-oriented"}, {"url": "https://nlp.stanford.edu/sentiment/", "anchor_text": "Stanford Sentiment Treebank"}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "Recursive Neural Tensor Network"}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "the paper"}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "Original paper"}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "Stanford paper"}, {"url": "https://arxiv.org/pdf/1802.05365v2.pdf", "anchor_text": "ELMo embeddings"}, {"url": "https://github.com/sebastianruder/NLP-progress/blob/master/english/sentiment_analysis.md#sst", "anchor_text": "achieve a significantly higher accuracy"}, {"url": "https://arxiv.org/pdf/1806.00807.pdf", "anchor_text": "a method that uses sentence-level embeddings"}, {"url": "https://pypi.org/project/pytreebank/", "anchor_text": "pytreebank"}, {"url": "https://github.com/prrao87/fine-grained-sentiment/blob/master/data/sst/tree2tabular.py", "anchor_text": "this project\u2019s GitHub repo"}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "original paper"}, {"url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf", "anchor_text": "Original Paper"}, {"url": "https://github.com/prrao87/fine-grained-sentiment/tree/master/training", "anchor_text": "available in the project\u2019s GitHub repo"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html", "anchor_text": "confusion matrix"}, {"url": "https://github.com/prrao87/fine-grained-sentiment/blob/master/plotter.py", "anchor_text": "plotter.py"}, {"url": "https://en.wikipedia.org/wiki/Anti-diagonal_matrix", "anchor_text": "anti-diagonal matrix"}, {"url": "https://en.wikipedia.org/wiki/Anti-diagonal_matrix", "anchor_text": "anti-diagonal matrix"}, {"url": "https://textblob.readthedocs.io/en/dev/", "anchor_text": "TextBlob"}, {"url": "http://www.nltk.org", "anchor_text": ","}, {"url": "https://planspace.org/20150607-textblob_sentiment/", "anchor_text": "in this blog post"}, {"url": "https://en.wikipedia.org/wiki/Anti-diagonal_matrix", "anchor_text": "anti-diagonal"}, {"url": "https://sebastianraschka.com/faq/docs/logisticregr-neuralnet.html", "anchor_text": "gives a very concise explanation"}, {"url": "https://sebastianraschka.com/faq/docs/logisticregr-neuralnet.html", "anchor_text": "Sebastian Raschka\u2019s blog"}, {"url": "https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest", "anchor_text": "one-vs-rest"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "CountVectorizer"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html", "anchor_text": "scikit-learn documentation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html", "anchor_text": "L2 regularization is used by default"}, {"url": "https://towardsdatascience.com/support-vector-machine-vs-logistic-regression-94cc2975433f", "anchor_text": "This makes it more robust to outliers in the data"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html", "anchor_text": "L2 regularization is applied during training"}, {"url": "https://fasttext.cc/blog/2016/08/18/blog-post.html", "anchor_text": "library for text representation and classification"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Word2Vec"}, {"url": "https://fasttext.cc/blog/2016/08/18/blog-post.html", "anchor_text": "after several months of confusion within the community"}, {"url": "https://fasttext.cc/docs/en/support.html#building-fasttext-as-a-command-line-tool", "anchor_text": "fasttext"}, {"url": "https://fasttext.cc/docs/en/support.html#building-fasttext-as-a-command-line-tool", "anchor_text": "command line interface"}, {"url": "https://fasttext.cc/docs/en/autotune.html", "anchor_text": "documentation"}, {"url": "https://nervanasystems.github.io/distiller/quantization.html", "anchor_text": "Quantization"}, {"url": "https://fasttext.cc/docs/en/cheatsheet.html#quantization", "anchor_text": "FastText makes quantization very convenient"}, {"url": "https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3", "anchor_text": "this article gives a good description"}, {"url": "https://github.com/zalandoresearch/flair", "anchor_text": "Zalando Research published a state-of-the-art deep learning sequence tagging NLP library"}, {"url": "https://research.zalando.com/welcome/mission/research-projects/flair-nlp/", "anchor_text": "Source"}, {"url": "https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md#combining-bert-and-flair", "anchor_text": "\u201cstack\u201d word embeddings"}, {"url": "https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md#flair-embeddings", "anchor_text": "character-level string embeddings capture latent syntactic-semantic information"}, {"url": "https://github.com/tqdm/tqdm/blob/master/examples/pandas_progress_apply.py", "anchor_text": "tqdm"}, {"url": "https://github.com/tqdm/tqdm/blob/master/examples/pandas_progress_apply.py", "anchor_text": "progress bar"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME Python library"}, {"url": "https://medium.com/@tech_optimist/fine-grained-sentiment-analysis-in-python-part-2-2a92fdc0160d", "anchor_text": "Part 2"}, {"url": "https://medium.com/@tech_optimist/fine-grained-sentiment-analysis-part-3-fine-tuning-transformers-1ae6574f25a6", "anchor_text": "Part 3"}, {"url": "https://github.com/prrao87/fine-grained-sentiment", "anchor_text": "available in the project\u2019s Github repo,"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2697bb111ed4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----2697bb111ed4---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----2697bb111ed4---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2697bb111ed4---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2697bb111ed4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2697bb111ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&user=Prashanth+Rao&userId=efdb4f4a0d1b&source=-----2697bb111ed4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2697bb111ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&user=Prashanth+Rao&userId=efdb4f4a0d1b&source=-----2697bb111ed4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2697bb111ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2697bb111ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2697bb111ed4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2697bb111ed4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2697bb111ed4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2697bb111ed4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tech_optimist?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tech_optimist?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Prashanth Rao"}, {"url": "https://medium.com/@tech_optimist/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "473 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fefdb4f4a0d1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&user=Prashanth+Rao&userId=efdb4f4a0d1b&source=post_page-efdb4f4a0d1b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5aedbeec5972&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4&newsletterV3=efdb4f4a0d1b&newsletterV3Id=5aedbeec5972&user=Prashanth+Rao&userId=efdb4f4a0d1b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}