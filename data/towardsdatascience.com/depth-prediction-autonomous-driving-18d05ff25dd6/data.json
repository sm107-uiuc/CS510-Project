{"url": "https://towardsdatascience.com/depth-prediction-autonomous-driving-18d05ff25dd6", "time": 1683000905.792874, "path": "towardsdatascience.com/depth-prediction-autonomous-driving-18d05ff25dd6/", "webpage": {"metadata": {"title": "Recognizing Depth in Autonomous Driving | by Madeline Schiappa | Towards Data Science", "h1": "Recognizing Depth in Autonomous Driving", "description": "This article will describe some of the state-of-the-art methods in depth predictions in image sequences captured by vehicles that help in the development of new autonomous driving models."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/slam-intro-fd833ef29e4e", "anchor_text": "How does Autonomous Driving Work? An Intro into SLAM", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Six_degrees_of_freedom#Engineering", "anchor_text": "6-DoF relative pose", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Interpolation", "anchor_text": "bilinearly interpolate", "paragraph_index": 5}, {"url": "https://arxiv.org/pdf/1806.01260.pdf", "anchor_text": "Digging into self-supervised monocular depth estimation", "paragraph_index": 13}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fcasser.io&sa=D&sntz=1&usg=AFQjCNH30qjULbsZQ2oeuUDvNTGLWjqpvA", "anchor_text": "Vincent Casser", "paragraph_index": 22}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.pirk.info&sa=D&sntz=1&usg=AFQjCNEUmFE9WFfLKUxNTNumX00TrO5CCw", "anchor_text": "Soeren Pirk", "paragraph_index": 22}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.cs.utexas.edu%2F~reza%2F&sa=D&sntz=1&usg=AFQjCNESkNsZ2t9xcsD6H0ny_Ia6bfIXpA", "anchor_text": "Reza Mahjourian", "paragraph_index": 22}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.vision.caltech.edu%2Fanelia%2F&sa=D&sntz=1&usg=AFQjCNGJGBfAFQAbD1mw4rWdjLpuuvPPVA", "anchor_text": "Anelia Angelova", "paragraph_index": 22}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fcasser.io&sa=D&sntz=1&usg=AFQjCNH30qjULbsZQ2oeuUDvNTGLWjqpvA", "anchor_text": "Vincent Casser", "paragraph_index": 23}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.pirk.info&sa=D&sntz=1&usg=AFQjCNEUmFE9WFfLKUxNTNumX00TrO5CCw", "anchor_text": "Soeren Pirk", "paragraph_index": 23}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.cs.utexas.edu%2F~reza%2F&sa=D&sntz=1&usg=AFQjCNESkNsZ2t9xcsD6H0ny_Ia6bfIXpA", "anchor_text": "Reza Mahjourian", "paragraph_index": 23}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.vision.caltech.edu%2Fanelia%2F&sa=D&sntz=1&usg=AFQjCNGJGBfAFQAbD1mw4rWdjLpuuvPPVA", "anchor_text": "Anelia Angelova", "paragraph_index": 23}, {"url": "https://www.linkedin.com/in/madelineschiappa/", "anchor_text": "https://www.linkedin.com/in/madelineschiappa/", "paragraph_index": 25}], "all_paragraphs": ["As mentioned in my previous article \u201cHow does Autonomous Driving Work? An Intro into SLAM\u201d, there are many sensors that are used to capture information while a vehicle is driving. The variety of measurements captured include velocity, position, depth, thermal and more. These measurements are fed into a feedback system that trains and utilizes motion models for the vehicle to abide by. This article focuses on the prediction of depth which is often captured by a LiDAR sensor. A LiDAR sensor captures distance from an object using a laser and measuring the reflected light with a sensor. However, a LiDAR sensor is not affordable for the everyday driver, so how else could we measure depth? The state-of-art methods I will describe are unsupervised deep learning approaches that use the disparity, or difference in, pixels from one frame to the next to measure depth.", "Authors in [1] developed a method that uses a combination of depth and pose networks to predict depth in a single frame. They do this by training their architecture on a sequence of frames and several loss functions to train the two networks. This method does not require a ground truth dataset for training. Instead, they use consecutive temporal frames in an image sequence to provide a training signal. To help constrain learning, they use a pose estimation network. The model is trained on the difference between the input image and the image reconstructed from the output of the pose network and the depth network. The reconstruction process will be described in more detail later. The main contributions of [1] are:", "The approach of this paper uses a depth network and a pose network. The depth network is a classic U-Net [2] encoder-decoder architecture. The encoder is a pre-trained ResNet model. The depth decoder is similar to previous work in which it converts the sigmoid output to depth values.", "The authors use a pose network from a ResNet18 that is modified for taking two colored images as input to predict a single 6-DoF relative pose, or rotation and translation. The pose network uses the temporal frames as the pair of images rather than the typical stereo pair. It predicts the appearance of a target image from the viewpoint of another image in the sequence, either a frame before or a frame after.", "The below figure illustrates the training process of the architecture.", "The target image is at frame 0 and the images used for our prediction process can be the frame before or the frame after, so frame+1 or frame-1. The loss is based on the similarity between the target image and a reconstructed target image. The process of reconstruction starts by calculating the transformation matrix from the source frame, either frame+1 or frame-1, using the pose network. This means we are calculating the mapping from the source frame to the target frame using information about rotation and translation. We then use the depth map predicted from the depth network for the target image and the transformation matrix from the pose network to project into a camera with intrinsics matrix K to get a reconstructed target image. This process requires transforming the depth map into a 3D point cloud first and then using the camera intrinsics to transform 3D positions into 2D points. The resulting points are used as a sampling grid to bilinearly interpolate from the target image.", "The goal of this loss is to reduce the difference between the target image and the reconstructed target image, in which both pose and depth are required.", "Typically, similar methods average together the reprojection error into each of the source images, e.g. frame+1 and frame-1. However, if a pixel is not visible in one of these frames but is in the target frame because it is close to the image boundary or occluded, the photometric error penalty will be unfairly high. To address issues related to this, they instead take the minimum photometric error over all source images.", "The final photometric loss is multiplied by a mask that addresses issues related to a change in the assumption that the camera is moving in a static scene, e.g. an object is moving at a similar speed as the camera or the camera has stopped while other objects are moving. The problem with this situation is the depth map predicts infinite depth. The authors address this with an auto-masking method that filters pixels that do not change appearance from one frame to the next. They generate their mask using binary in which it is 1 if the minimum photometric error between the target image and the reconstructed target image is less than the minimum photometric error of the target image and the source image, and 0 otherwise.", "When the camera is static, the result is all pixels in the image are masked out. When an object is moving at the same speed as the camera, it results in the pixels of stationary objects in the image to be masked out.", "The authors combine individual losses at each scale. They upsample the lower resolutions depth maps to the higher input image resolution and then re-project, re-sample and compute the photometric error at the higher input resolution. The authors claim this constrains the depth maps at each scale to work towards the same objective, an accurate high resolution reconstruction of the target image.", "The authors also use an edge-aware smoothness loss between the mean-normalized inverse depth map values and the input/target image. This encourages the model to learn sharp edges and to smooth away noise.", "The authors compared their model on three datasets that contain driving sequences. Their method outperformed almost all other methods across all experiments. An example of their performance is in the following image:", "For more details on their results, please see the original paper \u201cDigging into self-supervised monocular depth estimation\u201d", "Authors from Google brain published [3] which extends Monodepth2 even further. They improve upon the pose network from before by prediction motions of individual objects instead of the entire image as a whole. So instead of the reconstructed images being a single projection, it is now a sequence of projections that are then combined. They do this through two models, an object motion model and an ego-motion network (similar to the pose network described in the previous sections). The steps are as follows:", "The result is a representation of how the camera would have to move in order to \u201cexplain\u201d the change in appearance of the objects. We then want to move the objects according to the resulting motion models from the step 4 of the object motion modelling process. Finally, we combine the warped object movements with the warped static background to get the final warping:", "While Monodepth2 addresses issues of static objects or objects moving at the same speed as the camera through their auto-masking technique, these authors propose actually training the model to recognize object scale to improve the modelling of object motion.", "They define a loss for the scale of each object based on the category of the object, e.g. a house. It aims to constrain the depth based on the knowledge of the objects scale. The loss is the difference between the output depth map of the object in the image and the approximate depth map calculated by using the camera\u2019s focal length, height prior based on the category of the object, and the actual height of the segmented object in the image, both scaled by the mean depth for the target image:", "The extensions described in [3] were directly compared to the Monodepth2 model and showed significant improvement.", "The common methods of depth estimation in autonomous driving is to use a stereo pair of images, requiring two cameras, or a LiDAR depth sensor. However, these are costly and not always available. The methods described here are able to train deep learning models that predict depth on one image and are trained on just a sequence of images. They show good performance and a great future for research in autonomous driving.", "To try out the models yourselves, both papers have repositories located below:", "[2] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional networks for biomedical image segmen-tation. InMICCAI, 2015.", "[3] Vincent Casser, Soeren Pirk, Reza Mahjourian, Anelia Angelova: Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos. Thirty-Third AAAI Conference on Artificial Intelligence (AAAI\u201919).", "[5] Vincent Casser, Soeren Pirk, Reza Mahjourian, Anelia Angelova: Unsupervised Monocular Depth and Ego-motion Learning with Structure and Semantics. CVPR Workshop on Visual Odometry & Computer Vision Applications Based on Location Clues (VOCVALC), 2019", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD Student in the UCF Center for Research in Computer Vision https://www.linkedin.com/in/madelineschiappa/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F18d05ff25dd6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://maddyschiappa.medium.com/?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": ""}, {"url": "https://maddyschiappa.medium.com/?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "Madeline Schiappa"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3e21be1bb3e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&user=Madeline+Schiappa&userId=3e21be1bb3e7&source=post_page-3e21be1bb3e7----18d05ff25dd6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18d05ff25dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18d05ff25dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/slam-intro-fd833ef29e4e", "anchor_text": "How does Autonomous Driving Work? An Intro into SLAM"}, {"url": "https://en.wikipedia.org/wiki/Six_degrees_of_freedom#Engineering", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Six_degrees_of_freedom#Engineering", "anchor_text": "6-DoF relative pose"}, {"url": "https://en.wikipedia.org/wiki/Interpolation", "anchor_text": "bilinearly interpolate"}, {"url": "https://en.wikipedia.org/wiki/Iverson_bracket", "anchor_text": "Iverson bracket"}, {"url": "https://github.com/nianticlabs/monodepth2/", "anchor_text": "https://github.com/nianticlabs/monodepth2/"}, {"url": "https://arxiv.org/pdf/1806.01260.pdf", "anchor_text": "Digging into self-supervised monocular depth estimation"}, {"url": "https://sites.google.com/view/struct2depth", "anchor_text": "Struct2Depth"}, {"url": "https://github.com/nianticlabs/monodepth2", "anchor_text": "https://github.com/nianticlabs/monodepth2"}, {"url": "https://github.com/tensorflow/models/tree/master/research/struct2depth", "anchor_text": "https://github.com/tensorflow/models/tree/master/research/struct2depth"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fcasser.io&sa=D&sntz=1&usg=AFQjCNH30qjULbsZQ2oeuUDvNTGLWjqpvA", "anchor_text": "Vincent Casser"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.pirk.info&sa=D&sntz=1&usg=AFQjCNEUmFE9WFfLKUxNTNumX00TrO5CCw", "anchor_text": "Soeren Pirk"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.cs.utexas.edu%2F~reza%2F&sa=D&sntz=1&usg=AFQjCNESkNsZ2t9xcsD6H0ny_Ia6bfIXpA", "anchor_text": "Reza Mahjourian"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.vision.caltech.edu%2Fanelia%2F&sa=D&sntz=1&usg=AFQjCNGJGBfAFQAbD1mw4rWdjLpuuvPPVA", "anchor_text": "Anelia Angelova"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fcasser.io&sa=D&sntz=1&usg=AFQjCNH30qjULbsZQ2oeuUDvNTGLWjqpvA", "anchor_text": "Vincent Casser"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.pirk.info&sa=D&sntz=1&usg=AFQjCNEUmFE9WFfLKUxNTNumX00TrO5CCw", "anchor_text": "Soeren Pirk"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.cs.utexas.edu%2F~reza%2F&sa=D&sntz=1&usg=AFQjCNESkNsZ2t9xcsD6H0ny_Ia6bfIXpA", "anchor_text": "Reza Mahjourian"}, {"url": "http://www.google.com/url?q=http%3A%2F%2Fwww.vision.caltech.edu%2Fanelia%2F&sa=D&sntz=1&usg=AFQjCNGJGBfAFQAbD1mw4rWdjLpuuvPPVA", "anchor_text": "Anelia Angelova"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----18d05ff25dd6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/autonomous-driving?source=post_page-----18d05ff25dd6---------------autonomous_driving-----------------", "anchor_text": "Autonomous Driving"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----18d05ff25dd6---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/google-brain?source=post_page-----18d05ff25dd6---------------google_brain-----------------", "anchor_text": "Google Brain"}, {"url": "https://medium.com/tag/autonomous-vehicles?source=post_page-----18d05ff25dd6---------------autonomous_vehicles-----------------", "anchor_text": "Autonomous Vehicles"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18d05ff25dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&user=Madeline+Schiappa&userId=3e21be1bb3e7&source=-----18d05ff25dd6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18d05ff25dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&user=Madeline+Schiappa&userId=3e21be1bb3e7&source=-----18d05ff25dd6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18d05ff25dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F18d05ff25dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----18d05ff25dd6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----18d05ff25dd6--------------------------------", "anchor_text": ""}, {"url": "https://maddyschiappa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://maddyschiappa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Madeline Schiappa"}, {"url": "https://maddyschiappa.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "271 Followers"}, {"url": "https://www.linkedin.com/in/madelineschiappa/", "anchor_text": "https://www.linkedin.com/in/madelineschiappa/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3e21be1bb3e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&user=Madeline+Schiappa&userId=3e21be1bb3e7&source=post_page-3e21be1bb3e7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4aa8ac781e24&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-prediction-autonomous-driving-18d05ff25dd6&newsletterV3=3e21be1bb3e7&newsletterV3Id=4aa8ac781e24&user=Madeline+Schiappa&userId=3e21be1bb3e7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}