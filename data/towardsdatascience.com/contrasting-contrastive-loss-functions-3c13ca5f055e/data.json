{"url": "https://towardsdatascience.com/contrasting-contrastive-loss-functions-3c13ca5f055e", "time": 1683007914.057908, "path": "towardsdatascience.com/contrasting-contrastive-loss-functions-3c13ca5f055e/", "webpage": {"metadata": {"title": "Contrasting contrastive loss functions | by Zichen Wang | Towards Data Science", "h1": "Contrasting contrastive loss functions", "description": "In a previous post, I wrote about contrastive learning in supervised classification and performed some experiments on MNIST dataset and alike to find that the two-stage method proposed in the Khosla\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/contrastive-loss-for-supervised-classification-224ae35692e7", "anchor_text": "In a previous post", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/2004.11362", "anchor_text": "Khosla et al. 2020 paper", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Similarity_learning", "anchor_text": "metric learning", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/1911.12247", "anchor_text": "Contrastively-trained Structured World Models (C-SWMs)", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Hinge_loss", "anchor_text": "hinge loss", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1503.03832", "anchor_text": "FaceNet (Schroff et al. 2015) paper", "paragraph_index": 8}, {"url": "https://arxiv.org/abs/2002.05709", "anchor_text": "Chen et al. 2020 in the SimCLR paper", "paragraph_index": 14}, {"url": "https://docs.google.com/presentation/d/1iB59aKvWtjeN2ZYlPih2ygH8R4J8YS6k3iGQJNfukeE/edit?usp=sharing", "anchor_text": "my previous post", "paragraph_index": 17}, {"url": "https://github.com/wangz10/contrastive_loss", "anchor_text": "https://github.com/wangz10/contrastive_loss", "paragraph_index": 26}], "all_paragraphs": ["In a previous post, I wrote about contrastive learning in supervised classification and performed some experiments on MNIST dataset and alike to find that the two-stage method proposed in the Khosla et al. 2020 paper indeed shows significant improvement for supervised classification task by learning meaningful embeddings with contrastive loss. Later I found my experiments actually used a different contrastive loss function than Khosla et al. proposed. Although sharing the same intuition of explicitly contrasting examples against each other with respect to their labels, different contrastive loss functions can have their own nuances. In this post, I will review a series of contrastive loss functions and compare their performances in supervised classification task.", "Contrastive loss functions were invented for metric learning, which intends to learn similarity functions that measure the similarity or distance between a pair of objects. In the context of classification, the desired metric would render a pair of examples with the same label more similar than a pair of examples with different labels. Deep metric learning involves deep neural networks to embed data points to a lower-dimensional space with nonlinearity, then uses contrastive loss function to optimize the parameters in the neural networks. Recent research projects have applied deep metric learning to self-supervised learning, supervised learning and even reinforcement learning, for example, Contrastively-trained Structured World Models (C-SWMs).", "To review different contrastive loss functions in the context of deep metric learning, I use the following formalization. Let \ud835\udc31 be the input feature vector and \ud835\udc66 be its label. Let \ud835\udc53(\u22c5) be a encoder network mapping the input space to the embedding space and let \ud835\udc33=\ud835\udc53(\ud835\udc31) be the embedding vector.", "Here I review four contrastive loss functions in chronological order. I slightly changed the names of a few functions to highlight their distinctive characteristics.", "Max margin contrastive loss function takes a pair of embedding vectors z_i and z_j as inputs. It essentially equates the Euclidean distance between them if they have the same label (y_i=y_j) and is otherwise equivalent to hinge loss. It has a margin parameter m > 0 to impose a lower bound on the distance between a pair of samples with different labels.", "Triplet loss operates on a triplet of vectors whose labels follow \ud835\udc66_\ud835\udc56=\ud835\udc66_\ud835\udc57 and \ud835\udc66_\ud835\udc56\u2260\ud835\udc66_\ud835\udc58. That is to say two of the three (\ud835\udc33_\ud835\udc22 and \ud835\udc33_\ud835\udc23) shared the same label and a third vector \ud835\udc33_\ud835\udc24 has a different label. In triplet learning literatures, they are termed anchor (z_i), positive (z_j), and negative (z_k), respectively. Triplet loss is defined as:", ", where \ud835\udc5a again is a margin parameter that requires the delta distances between anchor-positive and anchor-negative to be larger than \ud835\udc5a. The intuition for this loss function is to push the negative sample outside of the neighborhood by a margin while keeping positive samples within the neighborhood. Here is a great graphical demonstration showing the effect of triplet loss from the original paper:", "Based on the definition of the triplet loss, a triplet may have the following three scenarios before any training:", "Triplet loss has been used to learn embeddings for faces in the FaceNet (Schroff et al. 2015) paper. Schroff et al. argued that triplet mining is crucial for model performance and convergence. They also found that the hardest triplets led to local minima early on in training, specifically resulted in collapsed models, whereas semi-hard triplets yields more stable results and faster convergence.", "Multi-class N-pair loss is a generalization of triplet loss allowing joint comparison among more than one negative samples. When applied on a pair of positive samples \ud835\udc33_\ud835\udc22 and \ud835\udc33_\ud835\udc23 sharing the same label (\ud835\udc66_\ud835\udc56=\ud835\udc66_\ud835\udc57) from a mini-batch with 2\ud835\udc41 samples, it is calculated as:", ", where z_i z_j is the inner product, which is equivalent to cosine similarity when both vectors have unit norm.", "As the figure below shows, N-pair loss pushes 2N-1 negative samples away simultaneously instead of one at a time:", "With some algebraic manipulations, multi-class N-pair loss can be written as the following:", "This form of multi-class N-pair loss helps us introduce the next loss function.", "Let\u2019s first look at the self-supervised version of NT-Xent loss. NT-Xent is coined by Chen et al. 2020 in the SimCLR paper and is short for \u201cnormalized temperature-scaled cross entropy loss\u201d. It is a modification of the multi-class N-pair loss with addition of the temperature parameter (\ud835\udf0f) to scale the cosine similarities:", "Chen et al. found that an appropriate temperature parameter can help the model learn from hard negatives. In addition, they showed that the optimal temperature differs on different batch sizes and number of training epochs.", "Khosla et al. later extended NT-Xent loss for supervised learning:", "Next I assess the whether these contrastive loss functions can help the encoder network to learn meaningful representations of the data to aid the classification task. Following the exact same experimental settings from my previous post, with small batch size (32) and low learning rate (0.001), I found all these contrastive loss functions except for triplet loss with hard negative mining outperforms the MLP baseline without the stage 1 pre-training:", "These results confirmed the benefit of using contrastive loss function in the pre-training the encoder part of the network for the subsequent classification. It also underscored the importance of triplet mining for triplet loss. Specifically, semi-hard mining works the best on these experiments, which is consistent with the FaceNet paper.", "Both Chen et al. (SimCLR) and Khosla et al. use very large batch sizes and higher learning rates for the NT-Xent loss to achieve greater performances. I next experimented with different batch sizes 32, 256 and 2048 with learning rates of 0.001, 0.01, and 0.2, respectively.", "The results show that the performances diminish as the batch size increases for all loss functions. Although triplet loss with semi-hard negative mining performs very well on small/medium batches, it is very memory intensive and my 16G RAM is impossible to handle it with a batch size of 2048. Supervised NT-Xent loss does turn to perform relatively better on larger batch size compared to its counterparts. There could be space for improvement for supervised NT-Xent if I were to optimize the temperature parameter. The temperature I used was 0.5.", "Next, I checked the PCA projections of the embeddings learned using contrastive loss functions to see if they learn any informative representations during the pre-training stage.", "Judging from the colored PCA projections and their densities, we can see both max margin and supervised NT-Xent learn tighter clusters for each class, whereas clusters from triplet loss with semi-hard mining are most dilated but still distinctive. As the batch size increase, the representation qualities degenerate in multi-class N-pair loss and max margin loss, but not so much in supervised NT-Xent loss, suggesting this loss is indeed more robust to larger batch size.", "Below are the PCA projections of the learned representation on a more difficult Fashion MNIST dataset. Overall it shows similar observations with MNIST.", "Contrastive loss functions are extremely helpful for improving supervised classification tasks by learning useful representations. Max margin and supervised NT-Xent loss are the top performers in the datasets experimented (MNIST and Fashion MNIST). Additionally, NT-Xent loss is robust to large batch sizes.", "Of note, all the contrastive loss functions reviewed here have hyperparameters e.g. margin, temperature, similarity/distance metrics for input vectors. These hyperparameter may affect the results drastically as suggested by other studies and should potentially be optimized for different datasets.", "Codes used for these experiments are available here: https://github.com/wangz10/contrastive_loss", "ML Scientist @AWS. Passionate about Machine Learning, Healthcare and Biology."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3c13ca5f055e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://wangz10.medium.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Zichen Wang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcefe6819be80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&user=Zichen+Wang&userId=cefe6819be80&source=post_page-cefe6819be80----3c13ca5f055e---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c13ca5f055e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&user=Zichen+Wang&userId=cefe6819be80&source=-----3c13ca5f055e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c13ca5f055e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&source=-----3c13ca5f055e---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/contrastive-loss-for-supervised-classification-224ae35692e7", "anchor_text": "In a previous post"}, {"url": "https://arxiv.org/abs/2004.11362", "anchor_text": "Khosla et al. 2020 paper"}, {"url": "https://en.wikipedia.org/wiki/Similarity_learning", "anchor_text": "metric learning"}, {"url": "https://arxiv.org/abs/1911.12247", "anchor_text": "Contrastively-trained Structured World Models (C-SWMs)"}, {"url": "https://en.wikipedia.org/wiki/Hinge_loss", "anchor_text": "hinge loss"}, {"url": "https://arxiv.org/abs/1503.03832", "anchor_text": "FaceNet (Schroff et al. 2015) paper"}, {"url": "https://arxiv.org/abs/2002.05709", "anchor_text": "Chen et al. 2020 in the SimCLR paper"}, {"url": "https://docs.google.com/presentation/d/1iB59aKvWtjeN2ZYlPih2ygH8R4J8YS6k3iGQJNfukeE/edit?usp=sharing", "anchor_text": "my previous post"}, {"url": "https://github.com/wangz10/contrastive_loss", "anchor_text": "https://github.com/wangz10/contrastive_loss"}, {"url": "http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf", "anchor_text": "Hadsell, R., Chopra, S., & LeCun, Y. (2006, June). Dimensionality reduction by learning an invariant mapping."}, {"url": "https://papers.nips.cc/paper/2795-distance-metric-learning-for-large-margin-nearest-neighbor-classification.pdf", "anchor_text": "Weinberger, K. Q., Blitzer, J., & Saul, L. K. (2006). Distance metric learning for large margin nearest neighbor classification."}, {"url": "https://arxiv.org/abs/1503.03832", "anchor_text": "Schroff, F., Kalenichenko, D., & Philbin, J. (2015). Facenet: A unified embedding for face recognition and clustering."}, {"url": "https://papers.nips.cc/paper/6200-improved-deep-metric-learning-with-multi-class-n-pair-loss-objective", "anchor_text": "Sohn, K. (2016). Improved deep metric learning with multi-class n-pair loss objective."}, {"url": "https://arxiv.org/pdf/2002.05709.pdf", "anchor_text": "Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. (2020). A simple framework for contrastive learning of visual representations."}, {"url": "https://arxiv.org/pdf/2004.11362.pdf", "anchor_text": "Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., \u2026 & Krishnan, D. (2020). Supervised Contrastive Learning."}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----3c13ca5f055e---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3c13ca5f055e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----3c13ca5f055e---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----3c13ca5f055e---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----3c13ca5f055e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c13ca5f055e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&user=Zichen+Wang&userId=cefe6819be80&source=-----3c13ca5f055e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c13ca5f055e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&user=Zichen+Wang&userId=cefe6819be80&source=-----3c13ca5f055e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c13ca5f055e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcefe6819be80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&user=Zichen+Wang&userId=cefe6819be80&source=post_page-cefe6819be80----3c13ca5f055e---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6eb2de67e9a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&newsletterV3=cefe6819be80&newsletterV3Id=6eb2de67e9a8&user=Zichen+Wang&userId=cefe6819be80&source=-----3c13ca5f055e---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Written by Zichen Wang"}, {"url": "https://wangz10.medium.com/followers?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "537 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcefe6819be80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&user=Zichen+Wang&userId=cefe6819be80&source=post_page-cefe6819be80----3c13ca5f055e---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6eb2de67e9a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontrasting-contrastive-loss-functions-3c13ca5f055e&newsletterV3=cefe6819be80&newsletterV3Id=6eb2de67e9a8&user=Zichen+Wang&userId=cefe6819be80&source=-----3c13ca5f055e---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/pca-and-svd-explained-with-numpy-5d13b0d2a4d8?source=author_recirc-----3c13ca5f055e----0---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=author_recirc-----3c13ca5f055e----0---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=author_recirc-----3c13ca5f055e----0---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Zichen Wang"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3c13ca5f055e----0---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/pca-and-svd-explained-with-numpy-5d13b0d2a4d8?source=author_recirc-----3c13ca5f055e----0---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "PCA and SVD explained with numpyHow exactly are principal component analysis and singular value decomposition related and how to implement using numpy."}, {"url": "https://towardsdatascience.com/pca-and-svd-explained-with-numpy-5d13b0d2a4d8?source=author_recirc-----3c13ca5f055e----0---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "\u00b76 min read\u00b7Mar 16, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5d13b0d2a4d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-and-svd-explained-with-numpy-5d13b0d2a4d8&user=Zichen+Wang&userId=cefe6819be80&source=-----5d13b0d2a4d8----0-----------------clap_footer----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/pca-and-svd-explained-with-numpy-5d13b0d2a4d8?source=author_recirc-----3c13ca5f055e----0---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d13b0d2a4d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-and-svd-explained-with-numpy-5d13b0d2a4d8&source=-----3c13ca5f055e----0-----------------bookmark_preview----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c13ca5f055e----1---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3c13ca5f055e----1---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3c13ca5f055e----1---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3c13ca5f055e----1---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c13ca5f055e----1---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c13ca5f055e----1---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c13ca5f055e----1---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----3c13ca5f055e----1-----------------bookmark_preview----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----3c13ca5f055e----2---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----3c13ca5f055e----2---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----3c13ca5f055e----2---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3c13ca5f055e----2---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----3c13ca5f055e----2---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----3c13ca5f055e----2---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----3c13ca5f055e----2---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----3c13ca5f055e----2-----------------bookmark_preview----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/practical-tips-for-class-imbalance-in-binary-classification-6ee29bcdb8a7?source=author_recirc-----3c13ca5f055e----3---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=author_recirc-----3c13ca5f055e----3---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=author_recirc-----3c13ca5f055e----3---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Zichen Wang"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3c13ca5f055e----3---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/practical-tips-for-class-imbalance-in-binary-classification-6ee29bcdb8a7?source=author_recirc-----3c13ca5f055e----3---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "Practical tips for class imbalance in binary classification0. Introduction and motivation"}, {"url": "https://towardsdatascience.com/practical-tips-for-class-imbalance-in-binary-classification-6ee29bcdb8a7?source=author_recirc-----3c13ca5f055e----3---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": "\u00b76 min read\u00b7Aug 10, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6ee29bcdb8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-tips-for-class-imbalance-in-binary-classification-6ee29bcdb8a7&user=Zichen+Wang&userId=cefe6819be80&source=-----6ee29bcdb8a7----3-----------------clap_footer----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/practical-tips-for-class-imbalance-in-binary-classification-6ee29bcdb8a7?source=author_recirc-----3c13ca5f055e----3---------------------936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "8"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6ee29bcdb8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-tips-for-class-imbalance-in-binary-classification-6ee29bcdb8a7&source=-----3c13ca5f055e----3-----------------bookmark_preview----936209a3_ef2b_40cd_a7cd_fcf552dfab9f-------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "See all from Zichen Wang"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----3c13ca5f055e----0-----------------bookmark_preview----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----1-----------------clap_footer----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----3c13ca5f055e----1-----------------bookmark_preview----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----3c13ca5f055e----0---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----3c13ca5f055e----0-----------------bookmark_preview----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3c13ca5f055e----1---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "90"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----3c13ca5f055e----1-----------------bookmark_preview----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----3c13ca5f055e----2---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----3c13ca5f055e----2---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----3c13ca5f055e----2---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3c13ca5f055e----2---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----3c13ca5f055e----2---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----3c13ca5f055e----2---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----2-----------------clap_footer----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----3c13ca5f055e----2---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----3c13ca5f055e----2-----------------bookmark_preview----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----3c13ca5f055e----3---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu?source=read_next_recirc-----3c13ca5f055e----3---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu?source=read_next_recirc-----3c13ca5f055e----3---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Steins"}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----3c13ca5f055e----3---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "Diffusion Model Clearly Explained!How does AI artwork work? Understanding the tech behind the rise of AI-generated art."}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----3c13ca5f055e----3---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": "\u00b77 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcd331bd41166&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40steinsfu%2Fdiffusion-model-clearly-explained-cd331bd41166&user=Steins&userId=a36be384d77d&source=-----cd331bd41166----3-----------------clap_footer----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----3c13ca5f055e----3---------------------b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcd331bd41166&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40steinsfu%2Fdiffusion-model-clearly-explained-cd331bd41166&source=-----3c13ca5f055e----3-----------------bookmark_preview----b6dee92e_5c69_4f2d_b7db_3f9f01bcc8b1-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----3c13ca5f055e--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}