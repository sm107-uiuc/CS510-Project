{"url": "https://towardsdatascience.com/are-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca", "time": 1683012296.129248, "path": "towardsdatascience.com/are-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca/", "webpage": {"metadata": {"title": "Are outliers ruining your machine learning predictions? Search for an optimal solution | by Kaushik Choudhury | Towards Data Science", "h1": "Are outliers ruining your machine learning predictions? Search for an optimal solution", "description": "In the world of data, we all love Gaussian distribution (also known as a normal distribution). In real-life, seldom we have normal distribution data. It is skewed, missing data points or has\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a", "anchor_text": "earlier article", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a", "anchor_text": "earlier", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/how-to-identify-the-right-independent-variables-for-machine-learning-supervised-algorithms-439986562d32", "anchor_text": "How to identify the right independent variables for Machine Learning Supervised Algorithms?", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Variance_inflation_factor", "anchor_text": "Variance inflation factor", "paragraph_index": 21}, {"url": "https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a", "anchor_text": "article", "paragraph_index": 31}, {"url": "https://towardsdatascience.com/how-to-identify-the-right-independent-variables-for-machine-learning-supervised-algorithms-439986562d32", "anchor_text": "article", "paragraph_index": 32}], "all_paragraphs": ["In the world of data, we all love Gaussian distribution (also known as a normal distribution). In real-life, seldom we have normal distribution data. It is skewed, missing data points or has outliers.", "As I mentioned in my earlier article, the strength of Scikit-learn inadvertently works to its disadvantage. Machine learning developers esp. with relatively lesser experience implements an inappropriate algorithm for prediction without grasping particular algorithms salient feature and limitations. We have seen earlier the reason we should not use the decision tree regression algorithm in making a prediction involving extrapolating the data.", "The success of any machine learning modelling always starts with understanding the existing dataset on which model will be trained. It is imperative to understand the data well before starting any modelling. I will even go to an extent to say that the prediction accuracy of the model is directly proportional to the extent we know the data.", "In this article, we will see the effect of outliers on various regression algorithms available in Scikit-learn, and learn about the most appropriate regression algorithm to apply in such a situation. We will start with a few techniques to understand the data and then train a few of the Sklearn algorithms with the data. Finally, we will compare the training results of the algorithms and learn the potential best algorithms to apply in the case of outliers.", "The training data consists of 200,000 records of 3 features (independent variable) and 1 target value (dependent variable). The true coefficient of the features 1, feature 2 and feature 3 is 77.74, 23.34, and 7.63 respectively.", "Step 1- First, we will import the packages required for data analysis and regressions.", "We will be comparing HuberRegressor, LinearRegression, Ridge, SGDRegressor, ElasticNet, PassiveAggressiveRegressor and Linear Support Vector Regression (SVR), hence we will import the respective packages.", "Most of the time, few data points are missing in the training data. In that case, if any particular features have a high proportion of null values then it may be better not consider that feature. Else, if a few data points are missing for a feature then either can drop those particular records from training data, or we can replace those missing values with mean, median or constant values. We will import SimpleImputer to fill the missing values.", "We will import the Variance Inflation Factor to find the severity of multicollinearity among the features. We will need Matplotlib and seaborn to draw various plots for analysis.", "Step 2- In the code below, training data containing 200.000 records are read from excel file into the PandasDataframe called \u201cRawData\u201d. Independent variables are saved into a new DataFrame.", "Step 3-Now we will start by getting a sense of the training data and understanding it. In my opinion, a heatmap is a good option to understand the relationship between different features.", "It shows that none of the independent variables (features) is closely related to each other. In case you would like to learn more on the approach and selection criteria of independent variables for regression algorithms, then please read my earlier article on it.", "How to identify the right independent variables for Machine Learning Supervised Algorithms?", "Step 4- After getting a sense of the correlation among the features in the training data next we will look into the minimum, maximum, median etc. of each feature value range. This will help us to ascertain whether there are any outliers in the training data and the extent of it. Below code instructs to draw boxplots for all the features.", "In case you don\u2019t know to read the box plot then please refer the Wikipedia to learn more on it. Feature values are spread across a wide range with a big difference from the median value. This confirms the presence of outlier values in the training dataset.", "Step 5- We will check if there are any null values in the training data and take any action required before going anywhere near modelling.", "Here we can see that there are total 200,000 records in the training data and all three features have few values missing. For example, feature 1 has 60 values (200000 \u2013199940) missing.", "Step 6- We use SimpleImputer to fill the missing values with the mean values of the other records for a feature. In the below code, we use the strategy= \u201cmean\u201d for the same. Scikit-learn provides different strategies viz. mean, median, most frequent and constant value to replace the missing value. I will suggest you please self explore the effect of each strategy on the training model as a learning exercise.", "In the code below, we have created an instance of SimpleImputer with strategy \u201cMean\u201d and then fit the training data into it to calculate the mean of each feature. Transform method is used to fill the missing values with the mean value.", "Step 7- It is good practice to check the features once more after replacing the missing values to ensure we do not have any null (blank) values remaining in our training dataset.", "We can see that now all the features have non-null i.e non-blank values for 200,000 records.", "Step 8- Before we start training the algorithms, let us check the Variance inflation factor (VIF) among the independent variables. VIF quantifies the severity of multicollinearity in an ordinary least squares regression analysis. It provides an index that measures how much the variance (the square of the estimate\u2019s standard deviation) of an estimated regression coefficient is increased because of collinearity. I will encourage you all to read the Wikipedia page on Variance inflation factor to gain a good understanding of it.", "In the above code, we calculate the VIF of each independent variables and print it. In general, we should aim for the VIF of less than 10 for the independent variables. We have seen earlier in the heatmap that none of the variables is highly correlated, and the same is reflecting in the VIF index among the features.", "Step 9- We will extract the target i.e. dependent variable values from the RawData dataframe and save it in a data series.", "Step 10- We will be evaluating the performance of various regressors viz. HuberRegressor, LinearRegression, Ridge and others on outlier dataset. In the below code, we created instances of the various regressors.", "Step 11- We declared a list with instances of the regressions to pass it in sequence in a for a loop later.", "Step 12- Finally, we will train the models in sequence with the training data set and print the coefficients of the features calculated by the model.", "We can observe a wide range of coefficients calculated by different models based on their optimisation and regularisation factors. Feature 1 coefficient calculated coefficient varies from 29.31 to 76.88.", "Due to a few outliers in the training dataset a few models, like linear and ridge regression predicted coefficients nowhere near the true coefficients. Huber regressor is quite robust to the outliers ensuring loss function is not heavily influenced by the outliers while not completely ignoring their effects like TheilSenRegressor and RANSAC Regressor. Linear SVR also more options in the selection of penalties and loss functions and performed better than other models.", "Learning Action for you- We trained different models with a training data set containing outliers and then compared the predicted coefficients with actual coefficients. I will encourage you all to follow the same approach and compare the prediction metrics viz. R2 score, mean squared error (MSE), RMSE of different models trained with outlier dataset.", "Hint \u2014 You may be surprised to see the R\u00b2 (coefficient of determination) regression score function for the models in comparison to the coefficient prediction accuracy we have seen in this article. In case, you stumble upon on any point then, feel free to reach out to me.", "As mentioned in my earlier article and keep stressing that main focus for us machine learning practitioners are to consider the data, prediction objective, algorithms strengths and limitations before starting the modelling. Every additional minute we spend in understanding the training data directly translates into prediction accuracy with the right algorithms. We don\u2019t want to use a hammer to unscrew and screwdriver to nail in the wall.", "If you want to learn more on a structured approach to identifying the right independent variables for Machine Learning Supervised Algorithms then please refer my article on this topic.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Kaushik Choudhury is an experienced Supply Chain Strategy and Digital Transformation manager in one of the Big 4 Consulting firm in the UK."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc81313e994ca&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c81313e994ca--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c81313e994ca--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kaushikthoughts.medium.com/?source=post_page-----c81313e994ca--------------------------------", "anchor_text": ""}, {"url": "https://kaushikthoughts.medium.com/?source=post_page-----c81313e994ca--------------------------------", "anchor_text": "Kaushik Choudhury"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdf006e67e544&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&user=Kaushik+Choudhury&userId=df006e67e544&source=post_page-df006e67e544----c81313e994ca---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc81313e994ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc81313e994ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@will_myers?utm_source=medium&utm_medium=referral", "anchor_text": "Will Myers"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a", "anchor_text": "earlier article"}, {"url": "https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a", "anchor_text": "earlier"}, {"url": "https://towardsdatascience.com/how-to-identify-the-right-independent-variables-for-machine-learning-supervised-algorithms-439986562d32", "anchor_text": "How to identify the right independent variables for Machine Learning Supervised Algorithms?"}, {"url": "https://en.wikipedia.org/wiki/Variance_inflation_factor", "anchor_text": "Variance inflation factor"}, {"url": "https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a", "anchor_text": "article"}, {"url": "https://towardsdatascience.com/how-to-identify-the-right-independent-variables-for-machine-learning-supervised-algorithms-439986562d32", "anchor_text": "article"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c81313e994ca---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c81313e994ca---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----c81313e994ca---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----c81313e994ca---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/programming?source=post_page-----c81313e994ca---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc81313e994ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&user=Kaushik+Choudhury&userId=df006e67e544&source=-----c81313e994ca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc81313e994ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&user=Kaushik+Choudhury&userId=df006e67e544&source=-----c81313e994ca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc81313e994ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c81313e994ca--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc81313e994ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c81313e994ca---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c81313e994ca--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c81313e994ca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c81313e994ca--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c81313e994ca--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c81313e994ca--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c81313e994ca--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c81313e994ca--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c81313e994ca--------------------------------", "anchor_text": ""}, {"url": "https://kaushikthoughts.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kaushikthoughts.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kaushik Choudhury"}, {"url": "https://kaushikthoughts.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "474 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdf006e67e544&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&user=Kaushik+Choudhury&userId=df006e67e544&source=post_page-df006e67e544--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F491da94209c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-outliers-ruining-your-machine-learning-predictions-search-for-an-optimal-solution-c81313e994ca&newsletterV3=df006e67e544&newsletterV3Id=491da94209c1&user=Kaushik+Choudhury&userId=df006e67e544&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}