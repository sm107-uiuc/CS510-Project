{"url": "https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39", "time": 1682995418.303514, "path": "towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39/", "webpage": {"metadata": {"title": "Attention in Deep Networks with Keras | by Thushan Ganegedara | Towards Data Science", "h1": "Attention in Deep Networks with Keras", "description": "This story introduces you to a Github repository which contains an atomic up-to-date Attention layer implemented using Keras backend operations. Available at attention_keras . With the unveiling of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/thushv89/attention_keras", "anchor_text": "attention_keras", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39", "anchor_text": "A", "paragraph_index": 2}, {"url": "http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/", "anchor_text": "C", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7", "anchor_text": "D", "paragraph_index": 2}, {"url": "http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/", "anchor_text": "K", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158", "anchor_text": "L", "paragraph_index": 2}, {"url": "https://medium.com/p/bee5af0c01aa", "anchor_text": "M", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee", "anchor_text": "N", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "W", "paragraph_index": 2}, {"url": "https://www.tensorflow.org/guide/keras", "anchor_text": "get first hand information", "paragraph_index": 4}, {"url": "https://github.com/thushv89/attention_keras", "anchor_text": "here", "paragraph_index": 6}, {"url": "http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/", "anchor_text": "C", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7", "anchor_text": "D", "paragraph_index": 8}, {"url": "http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/", "anchor_text": "K", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158", "anchor_text": "L", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee", "anchor_text": "N", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "W", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Word_order", "anchor_text": "word order topologies", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1409.0473.pdf", "anchor_text": "Bahdanau Attention", "paragraph_index": 16}, {"url": "https://github.com/thushv89/attention_keras", "anchor_text": "attention_keras", "paragraph_index": 18}, {"url": "https://github.com/thushv89/attention_keras/blob/master/examples/nmt/train.py", "anchor_text": "nmt/train.py", "paragraph_index": 20}, {"url": "https://github.com/thushv89/attention_keras/blob/master/examples/nmt/train.py", "anchor_text": "nmt/train.py", "paragraph_index": 33}, {"url": "https://github.com/thushv89/attention_keras/issues/59", "anchor_text": "not working on TensorFlow 2.4+ versions", "paragraph_index": 34}, {"url": "https://github.com/thushv89/attention_keras/tree/tf2-fix", "anchor_text": "https://github.com/thushv89/attention_keras/tree/tf2-fix", "paragraph_index": 35}, {"url": "https://www.manning.com/books/tensorflow-in-action", "anchor_text": "(Book) TensorFlow 2 in Action \u2014 Manning", "paragraph_index": 40}, {"url": "https://www.datacamp.com/courses/machine-translation-in-python", "anchor_text": "(Video Course) Machine Translation in Python", "paragraph_index": 41}, {"url": "https://www.amazon.com.au/Natural-Language-Processing-TensorFlow-Ganegedara/dp/1788478312/ref=sr_1_25?dchild=1&keywords=nlp+with+tensorflow&qid=1603009947&sr=8-25", "anchor_text": "(Book) Natural Language processing in TensorFlow 1", "paragraph_index": 42}, {"url": "https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/", "anchor_text": "DeepLearningHero", "paragraph_index": 43}], "all_paragraphs": ["This story introduces you to a Github repository which contains an atomic up-to-date Attention layer implemented using Keras backend operations. Available at attention_keras .", "To visit my previous articles in this series use the following letters.", "A B C D* E F G H I J K L* M N O P Q R S T U V W X Y Z", "With the unveiling of TensorFlow 2.0 it is hard to ignore the conspicuous attention (no pun intended!) given to Keras. There was greater focus on advocating Keras for implementing deep networks. Keras in TensorFlow 2.0 will come with three powerful APIs for implementing deep networks.", "For more information, get first hand information from TensorFlow team. However remember that while choosing advance APIs give more \u201cwiggle room\u201d for implementing complex models, they also increase the chances of blunders and various rabbit holes.", "Recently I was looking for a Keras based attention layer implementation or library for a project I was doing. I grappled with several repos out there that already has implemented attention. However my efforts were in vain, trying to get them to work with later TF versions. Due to several reasons:", "They are great efforts and I respect all those contributors. But I thought I would step in and implement an AttentionLayer that is applicable at more atomic level and up-to-date with new TF version. This repository is available here.", "Note: This is an article from the series of light on math machine learning A-Z. You can find the previous blog posts linked to the letter below.", "A B C D* E F G H I J K L* M N O P Q R S T U V W X Y Z", "In this article, first you will grok what a sequence to sequence model is, followed by why attention is important for sequential models? Next you will learn the nitty-gritties of the attention mechanism. This blog post will end by explaining how to use the attention layer.", "Sequence to sequence is a powerful family of deep learning models out there designed to take on the wildest problems in the realm of ML. For example,", "Which have very unique and niche challenges attached to them. For example, machine translation has to deal with different word order topologies (i.e. subject-verb-object order). So they are an imperative weapon for combating complex NLP problems.", "Let\u2019s have a look at how a sequence to sequence model might be used for a English-French machine translation task.", "A sequence to sequence model has two components, an encoder and a decoder. The encoder encodes a source sentence to a concise vector (called the context vector) , where the decoder takes in the context vector as an input and computes the translation using the encoded representation.", "There is a huge bottleneck in this approach. The context vector has been given the responsibility of encoding all the information in a given source sentence in to a vector of few hundred elements. Now to give a bit of context, this vector needs to preserve:", "This can be quite daunting especially for long sentences. Therefore a better solution was needed to push the boundaries.", "What if instead of relying just on the context vector, the decoder had access to all the past states of the encoder? That\u2019s exactly what attention is doing. At each decoding step, the decoder gets to look at any particular state of the encoder. Here we will be discussing Bahdanau Attention. The following figure depicts the inner workings of attention.", "So as the image depicts, context vector has become a weighted sum of all the past encoder states.", "It can be quite cumbersome to get some attention layers available out there to work due to the reasons I explained earlier. attention_keras takes a more modular approach, where it implements attention at a more atomic level (i.e. for each decoder step of a given decoder RNN/LSTM/GRU).", "You can use it as any other layer. For example,", "I have also provided a toy Neural Machine Translator (NMT) example showing how to use the attention layer in a NMT (nmt/train.py). But let me walk you through some of the details here.", "Here I will briefly go through the steps for implementing an NMT with Attention.", "First define encoder and decoder inputs (source/target words). Both are of shape (batch_size, timesteps, vocabulary_size).", "Define the encoder (note that return_sequences=True)", "Define the decoder (note that return_sequences=True)", "Defining the attention layer. Inputs to the attention layer are encoder_out (sequence of encoder outputs) and decoder_out (sequence of decoder outputs)", "Concatenate the attn_out and decoder_out as an input to the softmax layer.", "Define TimeDistributed Softmax layer and provide decoder_concat_input as the input.", "Not only this implements Attention, it also gives you a way to peek under the hood of the attention mechanism quite easily. This is possible because this layer returns both,", "for each decoding step. So by visualizing attention energy values you get full access to what attention is doing during training/inference. Below, I\u2019ll talk about some details of this process.", "Inferring from NMT is cumbersome! Because you have to,", "I\u2019m not going to talk about the model definition. Please refer examples/nmt/train.py for details. Let\u2019s jump into how to use this for getting attention weights.", "So as you can see we are collecting attention weights for each decoding step.", "Then you just have to pass this list of attention weights to plot_attention_weights(nmt/train.py) in order to get the attention heatmap with other arguments. The output after plotting will might like below.", "There was a recent bug report on the AttentionLayer not working on TensorFlow 2.4+ versions. It was leading to a cryptic error as follows,", "The error is due to a mixup between graph based KerasTensor objects and eager tf.Tensor objects. A fix is on the way in the branch https://github.com/thushv89/attention_keras/tree/tf2-fix which will be merged soon.", "In this article, I introduced you to an implementation of the AttentionLayer. Attention is very important for sequential models and even other types of models. However the current implementations out there are either not up-to-date or not very modular. Therefore, I dug a little bit and implemented an Attention layer using Keras backend operations. So I hope you\u2019ll be able to do great this with this layer. If you have any questions/find any bugs, feel free to submit an issue on Github.", "I would be very grateful to have contributors, fixing any bugs/ implementing new attention mechanisms. So contributions are welcome!", "If you enjoy the stories I share about data science and machine learning, consider becoming a member!", "Checkout my work on the subject.", "[1] (Book) TensorFlow 2 in Action \u2014 Manning", "[2] (Video Course) Machine Translation in Python \u2014 DataCamp", "[3] (Book) Natural Language processing in TensorFlow 1 \u2014 Packt", "If you are keen to see my videos on various machine learning/deep learning topics make sure to join DeepLearningHero.", "Google Developer Expert (ML) | ML @ Canva | Educator & Author\ud83d\udcd7| PhD\ud83d\udc68\ud83c\udffe\u200d\ud83c\udf93. Youtube: @DeepLearningHero Twitter:@thush89, LinkedIN: thushan.ganegedara"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdc8dbc1fad39&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/light-on-math", "anchor_text": "Light on Math Machine Learning"}, {"url": "https://thushv89.medium.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Thushan Ganegedara"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0b045d5681&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&user=Thushan+Ganegedara&userId=6f0b045d5681&source=post_page-6f0b045d5681----dc8dbc1fad39---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc8dbc1fad39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----dc8dbc1fad39---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8dbc1fad39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&source=-----dc8dbc1fad39---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://github.com/thushv89/attention_keras", "anchor_text": "attention_keras"}, {"url": "https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39", "anchor_text": "A"}, {"url": "http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/", "anchor_text": "C"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7", "anchor_text": "D"}, {"url": "http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/", "anchor_text": "K"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158", "anchor_text": "L"}, {"url": "https://medium.com/p/bee5af0c01aa", "anchor_text": "M"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee", "anchor_text": "N"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "W"}, {"url": "https://medium.com/p/bee5af0c01aa", "anchor_text": "M \u2014 Matrix factorization"}, {"url": "https://www.tensorflow.org/guide/keras", "anchor_text": "get first hand information"}, {"url": "https://github.com/thushv89/attention_keras", "anchor_text": "here"}, {"url": "http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/", "anchor_text": "C"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7", "anchor_text": "D"}, {"url": "http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/", "anchor_text": "K"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158", "anchor_text": "L"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee", "anchor_text": "N"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f", "anchor_text": "W"}, {"url": "https://en.wikipedia.org/wiki/Word_order", "anchor_text": "word order topologies"}, {"url": "https://arxiv.org/pdf/1409.0473.pdf", "anchor_text": "Bahdanau Attention"}, {"url": "https://github.com/thushv89/attention_keras", "anchor_text": "attention_keras"}, {"url": "https://github.com/thushv89/attention_keras/blob/master/examples/nmt/train.py", "anchor_text": "nmt/train.py"}, {"url": "https://github.com/thushv89/attention_keras/blob/master/examples/nmt/train.py", "anchor_text": "nmt/train.py"}, {"url": "https://github.com/thushv89/attention_keras/issues/59", "anchor_text": "not working on TensorFlow 2.4+ versions"}, {"url": "https://github.com/thushv89/attention_keras/tree/tf2-fix", "anchor_text": "https://github.com/thushv89/attention_keras/tree/tf2-fix"}, {"url": "https://thushv89.medium.com/membership", "anchor_text": "Join Medium with my referral link - Thushan GanegedaraAs a Medium member, a portion of your membership fee goes to writers you read, and you get full access to every story\u2026thushv89.medium.com"}, {"url": "https://www.manning.com/books/tensorflow-in-action", "anchor_text": "(Book) TensorFlow 2 in Action \u2014 Manning"}, {"url": "https://www.datacamp.com/courses/machine-translation-in-python", "anchor_text": "(Video Course) Machine Translation in Python"}, {"url": "https://www.amazon.com.au/Natural-Language-Processing-TensorFlow-Ganegedara/dp/1788478312/ref=sr_1_25?dchild=1&keywords=nlp+with+tensorflow&qid=1603009947&sr=8-25", "anchor_text": "(Book) Natural Language processing in TensorFlow 1"}, {"url": "https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/", "anchor_text": "DeepLearningHero"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dc8dbc1fad39---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----dc8dbc1fad39---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----dc8dbc1fad39---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----dc8dbc1fad39---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/light-on-math?source=post_page-----dc8dbc1fad39---------------light_on_math-----------------", "anchor_text": "Light On Math"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc8dbc1fad39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----dc8dbc1fad39---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc8dbc1fad39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----dc8dbc1fad39---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8dbc1fad39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0b045d5681&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&user=Thushan+Ganegedara&userId=6f0b045d5681&source=post_page-6f0b045d5681----dc8dbc1fad39---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F31796fe71410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&newsletterV3=6f0b045d5681&newsletterV3Id=31796fe71410&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----dc8dbc1fad39---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Written by Thushan Ganegedara"}, {"url": "https://thushv89.medium.com/followers?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "2.5K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0b045d5681&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&user=Thushan+Ganegedara&userId=6f0b045d5681&source=post_page-6f0b045d5681----dc8dbc1fad39---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F31796fe71410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-attention-with-keras-dc8dbc1fad39&newsletterV3=6f0b045d5681&newsletterV3Id=31796fe71410&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----dc8dbc1fad39---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010?source=author_recirc-----dc8dbc1fad39----0---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=author_recirc-----dc8dbc1fad39----0---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=author_recirc-----dc8dbc1fad39----0---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Thushan Ganegedara"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----dc8dbc1fad39----0---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010?source=author_recirc-----dc8dbc1fad39----0---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Light on Math ML: Intuitive Guide to Understanding GloVe EmbeddingsUnderstanding theory behind GloVe and Keras implementation!"}, {"url": "https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010?source=author_recirc-----dc8dbc1fad39----0---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "\u00b79 min read\u00b7May 5, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----b13b4f19c010----0-----------------clap_footer----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010?source=author_recirc-----dc8dbc1fad39----0---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb13b4f19c010&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010&source=-----dc8dbc1fad39----0-----------------bookmark_preview----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----dc8dbc1fad39----1---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----dc8dbc1fad39----1---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----dc8dbc1fad39----1---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----dc8dbc1fad39----1---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----dc8dbc1fad39----1---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----dc8dbc1fad39----1---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----dc8dbc1fad39----1---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----dc8dbc1fad39----1-----------------bookmark_preview----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----dc8dbc1fad39----2---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----dc8dbc1fad39----2---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----dc8dbc1fad39----2---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----dc8dbc1fad39----2---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----dc8dbc1fad39----2---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----dc8dbc1fad39----2---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----dc8dbc1fad39----2---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----dc8dbc1fad39----2-----------------bookmark_preview----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8?source=author_recirc-----dc8dbc1fad39----3---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=author_recirc-----dc8dbc1fad39----3---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=author_recirc-----dc8dbc1fad39----3---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Thushan Ganegedara"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----dc8dbc1fad39----3---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8?source=author_recirc-----dc8dbc1fad39----3---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "Intuitive Guide to Understanding KL DivergenceI\u2019m starting a new series of blog articles following a beginner friendly approach to understanding some of the challenging concepts in\u2026"}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8?source=author_recirc-----dc8dbc1fad39----3---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": "11 min read\u00b7Apr 30, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2b382ca2b2a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8&user=Thushan+Ganegedara&userId=6f0b045d5681&source=-----2b382ca2b2a8----3-----------------clap_footer----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8?source=author_recirc-----dc8dbc1fad39----3---------------------fd33f556_17e0_408b_a320_7c143aca1af9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b382ca2b2a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flight-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8&source=-----dc8dbc1fad39----3-----------------bookmark_preview----fd33f556_17e0_408b_a320_7c143aca1af9-------", "anchor_text": ""}, {"url": "https://thushv89.medium.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "See all from Thushan Ganegedara"}, {"url": "https://towardsdatascience.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----0-----------------clap_footer----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----dc8dbc1fad39----0-----------------bookmark_preview----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----1-----------------clap_footer----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----dc8dbc1fad39----1-----------------bookmark_preview----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Yujian Tang"}, {"url": "https://medium.com/plain-simple-software?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Plain Simple Software"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Long Short Term Memory in KerasHow to create an LSTM model with Tensorflow Keras"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "\u00b76 min read\u00b7Dec 1, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fplain-simple-software%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&user=Yujian+Tang&userId=1c4e6640433f&source=-----acdf61c056da----0-----------------clap_footer----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----dc8dbc1fad39----0---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&source=-----dc8dbc1fad39----0-----------------bookmark_preview----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Sunil Yadav"}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Variational AutoencodersIn this article, we will continue our discussion with variational autoencoders (VAEs) after covering DGM basics and AGM. Variational\u2026"}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "\u00b76 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fce7fe921cce7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sunil7545%2Fvariational-autoencoders-ce7fe921cce7&user=Sunil+Yadav&userId=9ee175d244fd&source=-----ce7fe921cce7----1-----------------clap_footer----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----dc8dbc1fad39----1---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce7fe921cce7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sunil7545%2Fvariational-autoencoders-ce7fe921cce7&source=-----dc8dbc1fad39----1-----------------bookmark_preview----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----dc8dbc1fad39----2---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----dc8dbc1fad39----2---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----dc8dbc1fad39----2---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----dc8dbc1fad39----2---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----dc8dbc1fad39----2---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----dc8dbc1fad39----2---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----2-----------------clap_footer----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----dc8dbc1fad39----2---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----dc8dbc1fad39----2-----------------bookmark_preview----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----dc8dbc1fad39----3---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----dc8dbc1fad39----3---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----dc8dbc1fad39----3---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----dc8dbc1fad39----3---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----dc8dbc1fad39----3---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----dc8dbc1fad39----3---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----3-----------------clap_footer----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----dc8dbc1fad39----3---------------------a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----dc8dbc1fad39----3-----------------bookmark_preview----a22dd21a_5080_4d13_ba34_1b7b85a7a0e1-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----dc8dbc1fad39--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}