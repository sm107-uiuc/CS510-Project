{"url": "https://towardsdatascience.com/monte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b", "time": 1683013026.503681, "path": "towardsdatascience.com/monte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b/", "webpage": {"metadata": {"title": "Monte Carlo Tree Search: Implementing Reinforcement Learning in Real-Time Game Player | by Masoud Masoumi Moghadam | Towards Data Science", "h1": "Monte Carlo Tree Search: Implementing Reinforcement Learning in Real-Time Game Player", "description": "In these series of articles, you are going to learn how we can implement a reinforcement learning algorithm called Monte Carlo Tree Search (MCTS) on a board game called HEX. MCTS uses randomness for deterministic problems which are difficult or impossible to solve."}, "outgoing_paragraph_urls": [{"url": "https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-1-a-brief-introduction-a53a849771cf", "anchor_text": "[2]", "paragraph_index": 20}, {"url": "https://hackernoon.com/reinforcement-learning-and-supervised-learning-a-brief-comparison-1b6d68c45ffa", "anchor_text": "[3]", "paragraph_index": 20}, {"url": "http://www.leemon.com/papers/1995b.pdf", "anchor_text": "4", "paragraph_index": 27}, {"url": "https://towardsdatascience.com/explaining-reinforcement-learning-active-vs-passive-a389f41e7195", "anchor_text": "5", "paragraph_index": 27}, {"url": "https://towardsdatascience.com/monte-carlo-tree-search-implementing-reinforcement-learning-in-real-time-game-player-25b6f6ac3b43", "anchor_text": "next article", "paragraph_index": 30}], "all_paragraphs": ["Reinforcement learning is a technique of machine learning in which we can design an agent that can gain experiences through interacting with environment and as it makes more mistakes, it learns how to modify the behavior to avoid the penalties and gain more rewards.", "What you are about to read is going to be a part of series of articles which we are going through ups and downs of implementation of a General Game Player on a board game namely as HEX. If you are in hurry, you can find the a pure python code in here:", "and also a newer version which is utilized cython to speed up the simulations in here:", "This is a demo of final product. Check it out:", "Since I have to warm up your vision with theoretical concepts before getting to implementation, in this very beginning article, I want to draw your attention on how a game environment (like chess) could be modeled as reinforcement learning problem. In this way I try to keep the contents simple (less math and formulas) and more tangible. The overall focus of the series is on the Monte Carlo Tree Search algorithm and how to implement it on a simple board game namely as HEX.", "Let\u2019s assume you are a chess player and consider this board as current state of the game:", "In this image, there is an environment which belongs to the game of chess. Game consists of situations (states) in which we have to decide to choose the best action between a other actions. The actions which we choose depends on states, and each action will cause environment to change and the changes might come with consequences that can affect the future decisions.", "For example in current situation in image 1, the black pawn in G5 cannot take any action in the board (According to chess rules).", "Now the question is that in the above image (assume that it`s black turn), how can we decide that some player chose the best move possible (for black)?", "These are some of black player options:", "Well, obviously the last one is the best move because winning the game is the ultimate goal for each player in chess. In chess maybe taking out the opponents pieces might increase the chances to win, but it\u2019s not the ultimate goal. Even if your pieces outnumber the ones of your opponent on the board, you might not be the winner (check the image below for instance).", "In this image, the black player is the winner, even though white player pieces has outnumbered the black ones.", "In other words, there is an immediate reward (taking out the opponent pieces) and long-term reward (winning the game) and the latter one is more desirable for players.", "Let\u2019s wrap up what we discussed to this point:", "Game is an environment which consists of states. In each state players are allowed to choose certain actions. Each action will cause state transition. This state transition might be advantageous/disadvantageous to player.Best player (winner) is the one who has better planning (strategy) for maximizing the long-term rewards.", "Doesn\u2019t that sound like how humans approach their goals?Humans with better perception (better planning) often sacrifice their short-term rewards (like eating fast foods) to maximize the long-term rewards (Get in shape). Reinforcement Learning specifically concentrates to design agents that can learn to maximize the long-term rewards through interacting with environment.", "OK. Now that we have some background idea of the subject, let\u2019s go through the reinforcement learning basics and learn how we utilize it to model the general game playing.", "R. Sutton et al [1] describes RL really well:", "Reinforcement learning is learning what to do \u2014 how to map situations to actions \u2014 so as to maximize a numerical reward signal. The learner is not told which actions to take, but instead must discover which actions yield the most reward by trying them.", "The key elements of RL are:", "As [1] asserts the key differences between RL and other techniques is in its trial and error nature and delayed rewards. I found [2] and [3] best to understand the differences between RL and other techniques.", "Reinforcement learning environment can be modeled with Markov Decision Process (MDP). MDP provides a mathematical framework for modeling sequential decision making in situations where outcomes are partly random and partly under the control of a decision maker (exactly like games which we can only control our moves but have no control on the opponent\u2019s actions).In MDP environment, Agent needs to find an optimal policy to maximize the rewards.", "I recommend you to watch this video which sums up all I explained to this point and best explains the mathematical notations:", "Now we need to figure out a way for fining optimal policy. What is the human approach when he wants to find the best possible solution for game state?", "He/She keeps estimating (the quality of) his actions in current state while thinking (in his imagination) that what would be the opponent best strategy in answer to his/her action. Through this she/he would choose the action with the most possible rewards (And of course humans can not imagine all the scenarios and memorize all the results!).", "To associate above statement with our project, we need to design an agent which is able to explore the environment through trial and error and model it by understanding the quality of its actions in states. But this trial and error can take place in its head and not in the environment that it\u2019s interacting with (just like how humans simulate games in their heads).", "I recommend this short video provided by Udacity team which kind of clarify the difference of the environment which is modeled by agent and the environment that agent interacts with:", "This is where the q-learning method comes in. Q learning is an RL algorithm which learns the optimal policy over maximizing the long-term rewards with respect to any and all successive states starting from current state (planning).Q-learning can learn the best policy if it\u2019s given infinite exploration time and partly random policy [4].Check this article to get through more details in the context [5].", "OK. We learned that RL-based agent is an agent that interacts with environment by choosing actions in states. by doing so, it changes the environment state and transits to other state. This transition might come with reward/penalty as consequence of its action (and this consequence might not be immediate).The goal of the agent is to find the best possible strategy to choose actions that maximizes the rewards.In the end I close the article with some questions that has to be answered in next article.", "1 \u2014 if there is only one best move between others how can we find it if we can not process all the successive states one by one due to limited amount of time?2 \u2014 how do we map finding best move to long-term rewards if we are limited in terms of computational resources and time?", "To address these problems, we are going to mine the Monte Carlo Tree Search concepts and its solutions for these problems in the next article.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Febc7753a5a3b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://m-m-moghadam.medium.com/?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": ""}, {"url": "https://m-m-moghadam.medium.com/?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "Masoud Masoumi Moghadam"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c9c75820911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&user=Masoud+Masoumi+Moghadam&userId=5c9c75820911&source=post_page-5c9c75820911----ebc7753a5a3b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Febc7753a5a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Febc7753a5a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@ninjason?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Jason Leung"}, {"url": "https://unsplash.com/s/photos/robot?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://github.com/masouduut94/MCTS-agent-python", "anchor_text": "masouduut94/MCTS-agent-pythonMonte Carlo Tree Search (MCTS) is a method for finding optimal decisions in a given domain by taking random samples in\u2026github.com"}, {"url": "https://github.com/masouduut94/MCTS-agent-cythonized", "anchor_text": "masouduut94/MCTS-agent-cythonizedMONTE Carlo Tree Search (MCTS) is a method for finding optimal decisions in a given domain by taking random samples in\u2026github.com"}, {"url": "https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-1-a-brief-introduction-a53a849771cf", "anchor_text": "[2]"}, {"url": "https://hackernoon.com/reinforcement-learning-and-supervised-learning-a-brief-comparison-1b6d68c45ffa", "anchor_text": "[3]"}, {"url": "http://www.leemon.com/papers/1995b.pdf", "anchor_text": "4"}, {"url": "https://towardsdatascience.com/explaining-reinforcement-learning-active-vs-passive-a389f41e7195", "anchor_text": "5"}, {"url": "https://towardsdatascience.com/monte-carlo-tree-search-implementing-reinforcement-learning-in-real-time-game-player-25b6f6ac3b43", "anchor_text": "next article"}, {"url": "https://hackernoon.com/reinforcement-learning-and-supervised-learning-a-brief-comparison-1b6d68c45ffa", "anchor_text": "https://hackernoon.com/reinforcement-learning-and-supervised-learning-a-brief-comparison-1b6d68c45ffa"}, {"url": "https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-2-introducing-markov-process-d3586d4003e0", "anchor_text": "https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-2-introducing-markov-process-d3586d4003e0"}, {"url": "https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-3-the-markov-decision-process-9f5066e073a2", "anchor_text": "https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-3-the-markov-decision-process-9f5066e073a2"}, {"url": "http://www.leemon.com/papers/1995b.pdf", "anchor_text": "http://www.leemon.com/papers/1995b.pdf"}, {"url": "https://towardsdatascience.com/explaining-reinforcement-learning-active-vs-passive-a389f41e7195", "anchor_text": "https://towardsdatascience.com/explaining-reinforcement-learning-active-vs-passive-a389f41e7195"}, {"url": "https://medium.com/tag/ai?source=post_page-----ebc7753a5a3b---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----ebc7753a5a3b---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ebc7753a5a3b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----ebc7753a5a3b---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/monte-carlo-tree-search?source=post_page-----ebc7753a5a3b---------------monte_carlo_tree_search-----------------", "anchor_text": "Monte Carlo Tree Search"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Febc7753a5a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&user=Masoud+Masoumi+Moghadam&userId=5c9c75820911&source=-----ebc7753a5a3b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Febc7753a5a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&user=Masoud+Masoumi+Moghadam&userId=5c9c75820911&source=-----ebc7753a5a3b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Febc7753a5a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Febc7753a5a3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ebc7753a5a3b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ebc7753a5a3b--------------------------------", "anchor_text": ""}, {"url": "https://m-m-moghadam.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://m-m-moghadam.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Masoud Masoumi Moghadam"}, {"url": "https://m-m-moghadam.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "63 Followers"}, {"url": "https://www.linkedin.com/in/masoud-masoumi-moghadam/", "anchor_text": "https://www.linkedin.com/in/masoud-masoumi-moghadam/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c9c75820911&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&user=Masoud+Masoumi+Moghadam&userId=5c9c75820911&source=post_page-5c9c75820911--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F181bb37885f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-a-case-study-along-with-implementation-part-1-ebc7753a5a3b&newsletterV3=5c9c75820911&newsletterV3Id=181bb37885f2&user=Masoud+Masoumi+Moghadam&userId=5c9c75820911&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}