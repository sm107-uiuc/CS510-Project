{"url": "https://towardsdatascience.com/serving-deep-learning-algorithms-as-a-service-6aa610368fde", "time": 1683012905.3465128, "path": "towardsdatascience.com/serving-deep-learning-algorithms-as-a-service-6aa610368fde/", "webpage": {"metadata": {"title": "Running Deep Learning Algorithms as a Service | by Nir Orman | Towards Data Science", "h1": "Running Deep Learning Algorithms as a Service", "description": "You have a really cool algorithmic library written in Python and TensorFlow/Keras/Some other platform that requires running workloads on a GPU and you want to be able to serve it at scale and have it\u2026"}, "outgoing_paragraph_urls": [{"url": "https://docs.celeryproject.org/en/stable/", "anchor_text": "Celery", "paragraph_index": 2}, {"url": "https://www.rabbitmq.com/", "anchor_text": "RabbitMQ", "paragraph_index": 4}, {"url": "https://redis.io/", "anchor_text": "redis", "paragraph_index": 4}, {"url": "https://console.cloud.google.com/marketplace/details/google/rabbitmq?pli=1", "anchor_text": "click to deploy", "paragraph_index": 4}, {"url": "https://aws.amazon.com/elasticache/", "anchor_text": "AWS Elastic Cache", "paragraph_index": 4}, {"url": "https://aws.amazon.com/ec2/instance-types/p3/", "anchor_text": "3.06$ an hour", "paragraph_index": 6}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-serializer", "anchor_text": "task_serializer", "paragraph_index": 19}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#result-serializer", "anchor_text": "result_serializer", "paragraph_index": 20}, {"url": "https://docs.celeryproject.org/en/stable/userguide/calling.html#serializers", "anchor_text": "here", "paragraph_index": 20}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#accept-content", "anchor_text": "accept_content", "paragraph_index": 21}, {"url": "https://en.wikipedia.org/wiki/Zen_of_Python", "anchor_text": "The Zen of Python", "paragraph_index": 22}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#std:setting-worker_prefetch_multiplier", "anchor_text": "worker_prefetch_multiplier", "paragraph_index": 23}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-acks-late", "anchor_text": "task_acks_late", "paragraph_index": 24}, {"url": "https://aws.amazon.com/ec2/spot/", "anchor_text": "spot instances", "paragraph_index": 24}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-track-started", "anchor_text": "task_track_started", "paragraph_index": 25}, {"url": "https://flower.readthedocs.io/en/latest/", "anchor_text": "Flower", "paragraph_index": 25}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#result-expires", "anchor_text": "result_expires", "paragraph_index": 26}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-reject-on-worker-lost", "anchor_text": "task_reject_on_worker_lost", "paragraph_index": 27}, {"url": "https://medium.com/cloudzone/running-elastic-gpu-workloads-cost-effectively-on-kubernetes-with-azure-low-priority-vms-b8b1b6662ed6", "anchor_text": "a totally different blog post.", "paragraph_index": 31}, {"url": "https://il.linkedin.com/in/nir-orman", "anchor_text": "LinkedIn", "paragraph_index": 32}], "all_paragraphs": ["So, You want to serve Deep Learning Algorithms as a service.", "You have a really cool algorithmic library written in Python and TensorFlow/Keras/Some other platform that requires running workloads on a GPU and you want to be able to serve it at scale and have it up and running fast.", "Celery is an open-source asynchronous task queue which is based on distributed message passing. After reading all possible blog posts and seeing all the Youtube videos about Celery, I decided it\u2019s the right solution for the task at hand.", "Please welcome our main characters of the plot:", "The best practice is to use Celery with RabbitMQ as the broker of the messages and with redis as the result\u2019s backend, in order to use all the unique features that Celery can provide. We know software requirements often change faster than we expect, this should provide us with maximum flexibility so we can use even the most complicated features of Celery. When choosing RabbitMQ and redis, each new task is transformed into a message which Celery then posts to a queue in RabbitMQ, and each return value of a task performed by a worker will automatically be written back to redis (you can easily host RabbitMQ on GCP using \u201cclick to deploy\u201d, and redis using AWS Elastic Cache).", "Once the message representing the task is in the queue, we need a GPU worker to compute it. The GPU worker will read a message from the queue and perform the task. For example, if it\u2019s a computer vision algorithm, a worker will download the original image from AWS S3, manipulate it, and upload the new image back to S3. The URL of the image will be passed as part of the task.", "GPUs, are very expensive machines. One instance of P2.Xlarge in AWS costs over 2,000$ a month (3.06$ an hour while writing these lines) or ~600$ if it\u2019s a spot instance. This obviously means we do NOT want them to be constantly up if there\u2019s no need. They have to be turned on, on-demand, and then turned off. The thing is, Elastic Beanstalk has no feature of auto-scaling according to RabbitMQ queue metrics.", "We have to write our own custom Auto Scaler. It\u2019s a big name for a small Python script that runs and polls RabbitMQ for the number of tasks in the queue every 30 seconds. If there\u2019re messages in the queue, it calls the AWS API and makes it start GPU workers accordingly.", "Each worker is booted with the docker container of the algorithmic repository (stored in ECR, Elastic Container Registry). Once the container is up and running, it connects to RabbitMQ and redis. It then takes a task from the queue and calculates it. The output is written by the worker to S3. If the task was completed successfully then the return value of the Celery task, is a json containing a URL to the output saved to S3 and its metadata. That return value is automatically saved to redis by Celery and also saved to Postgres DB. If the task failed to finish, an exception is saved to redis.", "Check out the diagram below to understand the architecture explained above:", "Sounds breezy so far? One of the main challenges using Celery is to configure it the right way.", "Here\u2019s a good configuration that\u2019ll save you time and tears when you try to perform Deep Learning tasks at scale. Check it out below and then we\u2019ll dive into every detail of it:", "Note: The configuration has been simplified in order to make it easier to understand.", "The first paragraph in the snippet is just some imports, trivial.", "The second paragraph defines the celery app itself, which has a broker and backend (As stated before, the best practice is to use RabbitMQ and redis).", "The third paragraph updates the configuration of Celery, This is the interesting part.", "The \u2018imports\u2019 section says in which of our python packages Celery should look for tasks.", "The \u2018tasks_routes\u2019 part maps between the task\u2019s name and the queue in which it should be stored. In the code snippet above, all tasks that are of type \u201ccalculate-image-task\u201d will be pushed into a queue named \u201cimages-queue\u201d. If you do not write which queue your task should be routed to, it will by default go to the default queue named \u2018celery\u2019. BTW, you can change the name of the default queue if you want by defining \u2018task_default_queue\u2019 property.", "FYI: The queue itself is automatically created on RabbitMQ once the first task is routed to it. Cool :)", "\u2018task_serializer\u2019: This is how tasks will be serialized once they are put in the queue and deserialized once they reach the worker. In the image processing case, we do not want the image itself to be serialized and deserialized, The best practice is to store it and only pass its location or URL. We\u2019ll use json as the serializer.", "\u2018result_serializer\u2019: Keep in mind, if you declare the serialization type as json and return a result that is an object or an exception (which is the return type in case there was an exception which wasn\u2019t caught) then your result serialization will throw an exception since any object that\u2019s not a json would throw an exception of failing to serialize. You can always read more about serializers here.", "\u2018accept_content\u2019: A white-list of content-types/serializers to allow.", "Tip: It\u2019s not recommended to use \u2018pickle\u2019 serializer since it is known to have security issues. Since Celery version 4.0, json is actually the default option of serialization, but \u201cExplicit is better than implicit\u201d (The Zen of Python).", "\u2018worker_prefetch_multiplier\u2019: The default of Celery is that each worker takes 4 tasks and computes all of them before it comes back for the next tasks. Their idea was to optimize network roundtrips. In our case, Deep Learning tasks tend to be long ones (way longer than the network time). This means we do not want a worker to take a bunch of tasks and perform them one after the other. We want each worker to take a single task at a time, and then come back to take the next task when it\u2019s done with the previous one. That way, if one task requires a very long computation, other workers could work on the next tasks simultaneously, since as long as the first worker is not working on them, they are kept in the queue.", "\u2018task_acks_late\u2019: By default, when a worker takes a task, the task will be \u201cacked\u201d just before its execution. In the case of Deep Learning tasks, which take a long time to compute, we would want them to be \u201cacked\u201d only after they are computed. This is especially useful when we use spot instances, which lower our average task price but may also be lost if there\u2019s a shortage of GPU instances and our bidding price wasn\u2019t competitive enough.", "\u2018task_track_started\u2019: Good for tracking that a task has started, cause when your task is long-running, you want to know it\u2019s no longer in the queue (which would be marked as \u2018pending\u2019.) I recommend using Flower as the monitor solution for Celery, which allows you to see exactly what\u2019s the status of every task.", "\u2018result_expires\u2019: by default, Celery keeps your results on redis only for 1 day. If you want it to be kept longer, define`result_expires` differently in the configuration file. I would recommend keeping it for at most 1 week and writing the results to a more organized DB that has a schema, such as PostgreSQL.", "\u2018task_reject_on_worker_lost\u2019: We\u2019ll set this to True. When we use spot instances, there\u2019s a chance a worker will be lost when a spot instance is taken away from us. We want the task to be put back into the queue and be computed by another worker. Be careful, if a worker was lost due to hardware errors like \u2018out of memory\u2019 etc., then the task will get partially calculated again and again in a loop since the worker will be lost every time it tries to compute it. If you see a task in an endless loop, this is the configuration you should be suspicious about.", "\u2018task_queue_max_priority\u2019: This is where you can make sure that important tasks get done first. You can set a priority for every Celery task (by assigning it with some int representing its priority). If you set this property, you must also set it to your RabbitMQ queue, it does not get set automatically. If a task with priority enters a queue that doesn\u2019t have the priority property, an exception will be thrown and the task will not enter the queue. This property is useful if you have a premium customer whose tasks should be computed first.", "If you\u2019re thinking about using this property in order to prioritize fast running tasks over slow ones (such as long GPU computing tasks) then consider adding another group of workers, that are CPU workers and not expensive GPU workers. It would be cheaper and faster.", "As you can see in the architecture diagram at the top, You can also have workers running on a totally different cloud.", "For example, you could run your workers on Azure AKS which is the Kubernetes of Azure. But that\u2019s a totally different blog post.", "Good luck serving your Deep Learning Algorithms with Celery, if you have any questions, feel free to contact me on LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Innovation lover, Technology geek, Enthusiastic Software Engineer"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6aa610368fde&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6aa610368fde--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6aa610368fde--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nir-orman.medium.com/?source=post_page-----6aa610368fde--------------------------------", "anchor_text": ""}, {"url": "https://nir-orman.medium.com/?source=post_page-----6aa610368fde--------------------------------", "anchor_text": "Nir Orman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9fb4d882e94f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&user=Nir+Orman&userId=9fb4d882e94f&source=post_page-9fb4d882e94f----6aa610368fde---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6aa610368fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6aa610368fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@marius?utm_source=medium&utm_medium=referral", "anchor_text": "Marius Masalar"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://docs.celeryproject.org/en/stable/", "anchor_text": "Celery"}, {"url": "https://www.rabbitmq.com/", "anchor_text": "RabbitMQ"}, {"url": "https://redis.io/", "anchor_text": "redis"}, {"url": "https://console.cloud.google.com/marketplace/details/google/rabbitmq?pli=1", "anchor_text": "click to deploy"}, {"url": "https://aws.amazon.com/elasticache/", "anchor_text": "AWS Elastic Cache"}, {"url": "https://aws.amazon.com/ec2/instance-types/p3/", "anchor_text": "3.06$ an hour"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-serializer", "anchor_text": "task_serializer"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#result-serializer", "anchor_text": "result_serializer"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/calling.html#serializers", "anchor_text": "here"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#accept-content", "anchor_text": "accept_content"}, {"url": "https://en.wikipedia.org/wiki/Zen_of_Python", "anchor_text": "The Zen of Python"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#std:setting-worker_prefetch_multiplier", "anchor_text": "worker_prefetch_multiplier"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-acks-late", "anchor_text": "task_acks_late"}, {"url": "https://aws.amazon.com/ec2/spot/", "anchor_text": "spot instances"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-track-started", "anchor_text": "task_track_started"}, {"url": "https://flower.readthedocs.io/en/latest/", "anchor_text": "Flower"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#result-expires", "anchor_text": "result_expires"}, {"url": "https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-reject-on-worker-lost", "anchor_text": "task_reject_on_worker_lost"}, {"url": "https://medium.com/cloudzone/running-elastic-gpu-workloads-cost-effectively-on-kubernetes-with-azure-low-priority-vms-b8b1b6662ed6", "anchor_text": "a totally different blog post."}, {"url": "https://il.linkedin.com/in/nir-orman", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/celery?source=post_page-----6aa610368fde---------------celery-----------------", "anchor_text": "Celery"}, {"url": "https://medium.com/tag/python?source=post_page-----6aa610368fde---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----6aa610368fde---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/gpu?source=post_page-----6aa610368fde---------------gpu-----------------", "anchor_text": "Gpu"}, {"url": "https://medium.com/tag/ds-in-the-real-world?source=post_page-----6aa610368fde---------------ds_in_the_real_world-----------------", "anchor_text": "Ds In The Real World"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6aa610368fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&user=Nir+Orman&userId=9fb4d882e94f&source=-----6aa610368fde---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6aa610368fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&user=Nir+Orman&userId=9fb4d882e94f&source=-----6aa610368fde---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6aa610368fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6aa610368fde--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6aa610368fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6aa610368fde---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6aa610368fde--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6aa610368fde--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6aa610368fde--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6aa610368fde--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6aa610368fde--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6aa610368fde--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6aa610368fde--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6aa610368fde--------------------------------", "anchor_text": ""}, {"url": "https://nir-orman.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nir-orman.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nir Orman"}, {"url": "https://nir-orman.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "88 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9fb4d882e94f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&user=Nir+Orman&userId=9fb4d882e94f&source=post_page-9fb4d882e94f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F9fb4d882e94f%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-deep-learning-algorithms-as-a-service-6aa610368fde&user=Nir+Orman&userId=9fb4d882e94f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}