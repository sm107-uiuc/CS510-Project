{"url": "https://towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9", "time": 1682993438.010696, "path": "towardsdatascience.com/building-neural-network-from-scratch-9c88535bf8e9/", "webpage": {"metadata": {"title": "Building Neural Network from scratch | by Aayush Agrawal | Towards Data Science", "h1": "Building Neural Network from scratch", "description": "In this notebook, we are going to build a neural network(multilayer perceptron) using numpy and successfully train it to recognize digits in the image. Deep learning is a vast topic, but we got to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/aayushmnit/Deep_learning_explorations/tree/master/1_MLP_from_scratch", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://aayushmnit.github.io/posts/2018/06/Building_neural_network_from_scratch/", "anchor_text": "website", "paragraph_index": 0}, {"url": "https://www.coursera.org/ml", "anchor_text": "week 1 of Machine learning by Andrew NG lectures", "paragraph_index": 7}, {"url": "http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization", "anchor_text": "read more", "paragraph_index": 15}, {"url": "http://aayushmnit.com", "anchor_text": "aayushmnit.com", "paragraph_index": 26}], "all_paragraphs": ["In this notebook, we are going to build a neural network(multilayer perceptron) using numpy and successfully train it to recognize digits in the image. Deep learning is a vast topic, but we got to start somewhere, so let\u2019s start with the very basics of a neural network which is Multilayer Perceptron. You can find the same blog in notebook version here or my website.", "A neural network is a type of machine learning model which is inspired by our neurons in the brain where many neurons are connected with many other neurons to translate an input to an output (simple right?). Mostly we can look at any machine learning model and think of it as a function which takes an input and produces the desired output; it\u2019s the same with a neural network.", "Multi-layer perceptron is a type of network where multiple layers of a group of perceptron are stacked together to make a model. Before we jump into the concept of a layer and multiple perceptrons, let\u2019s start with the building block of this network which is a perceptron. Think of perceptron/neuron as a linear model which takes multiple inputs and produce an output. In our case perceptron is a linear model which takes a bunch of inputs multiply them with weights and add a bias term to generate an output.", "Now, if we stack a bunch of these perceptrons together, it becomes a hidden layer which is also known as a Dense layer in modern deep learning terminology. Dense layer,", "Note that bias term is now a vector and W is a weight matrix", "Now we understand dense layer let\u2019s add a bunch of them, and that network becomes a multi-layer perceptron network.", "If you have noticed our dense layer, only have linear functions, and any combination of linear function only results in the linear output. As we want our MLP to be flexible and learn non-linear decision boundaries, we also need to introduce non-linearity into the network. We achieve the task of introducing non-linearity by adding activation function. There are various kinds of activation function which can be used, but we will be implementing Rectified Linear Units(ReLu) which is one of the popular activation function. ReLU function is a simple function which is zero for any input value below zero and the same value for values greater than zero. ReLU function", "Now, we understand dense layer and also understand the purpose of activation function, the only thing left is training the network. For training a neural network we need to have a loss function and every layer should have a feed-forward loop and backpropagation loop. Feedforward loop takes an input and generates output for making a prediction and backpropagation loop helps in training the model by adjusting weights in the layer to lower the output loss. In backpropagation, the weight update is done by using backpropagated gradients using the chain rule and optimized using an optimization algorithm. In our case, we will be using SGD(stochastic gradient descent). If you don\u2019t understand the concept of gradient weight updates and SGD, I recommend you to watch week 1 of Machine learning by Andrew NG lectures.", "So, to summarize a neural network needs few building blocks", "Let\u2019s approach them one at a time.", "Let\u2019s start by importing some libraires required for creating our neural network.", "Every layer will have a forward pass and backpass implementation. Let\u2019s create a main class layer which can do a forward pass .forward() and Backward pass .backward().", "This is the simplest layer you can get: it simply applies a nonlinearity to each element of your network.", "Now let\u2019s build something more complicated. Unlike nonlinearity, a dense layer actually has something to learn.", "A dense layer applies affine transformation. In a vectorized form, it can be described as:", "Both W and b are initialized during layer creation and updated each time backward is called. Note that we are using Xavier initialization which is a trick to train our model to converge faster read more. Instead of initializing our weights with small numbers which are distributed randomly we initialize our weights with mean zero and variance of 2/(number of inputs + number of outputs)", "Since we want to predict probabilities, it would be logical for us to define softmax nonlinearity on top of our network and compute loss given predicted probabilities. However, there is a better way to do so.", "If we write down the expression for crossentropy as a function of softmax logits (a), you\u2019ll see:", "If we take a closer look, we\u2019ll see that it can be rewritten as:", "It\u2019s called Log-softmax and it\u2019s better than naive log(softmax(a)) in all aspects:", "So why not just use log-softmax throughout our computation and never actually bother to estimate probabilities.", "Now let\u2019s combine what we\u2019ve just built into a working neural network. As I have told earlier, we are going to use MNIST data of handwritten digit for our example. Fortunately, Keras already have it in the numpy array format, so let\u2019s import it!.", "We\u2019ll define network as a list of layers, each applied on top of previous one. In this setting, computing predictions and training becomes trivial.", "We split data into minibatches, feed each such minibatch into the network and update weights. This training method is called a mini-batch stochastic gradient descent.", "As we can see we have successfully trained a MLP which was purely written in numpy with high validation accuracy!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Experienced data scientist. Passionate about solving interesting problems with data. All views are my own unless you share them. More on aayushmnit.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9c88535bf8e9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@aayushmnit?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aayushmnit?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "Aayush Agrawal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85dd669ac015&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&user=Aayush+Agrawal&userId=85dd669ac015&source=post_page-85dd669ac015----9c88535bf8e9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c88535bf8e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c88535bf8e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/aayushmnit/Deep_learning_explorations/tree/master/1_MLP_from_scratch", "anchor_text": "here"}, {"url": "https://aayushmnit.github.io/posts/2018/06/Building_neural_network_from_scratch/", "anchor_text": "website"}, {"url": "https://www.coursera.org/ml", "anchor_text": "week 1 of Machine learning by Andrew NG lectures"}, {"url": "http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization", "anchor_text": "read more"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9c88535bf8e9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----9c88535bf8e9---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/python?source=post_page-----9c88535bf8e9---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/numpy?source=post_page-----9c88535bf8e9---------------numpy-----------------", "anchor_text": "Numpy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c88535bf8e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&user=Aayush+Agrawal&userId=85dd669ac015&source=-----9c88535bf8e9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c88535bf8e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&user=Aayush+Agrawal&userId=85dd669ac015&source=-----9c88535bf8e9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c88535bf8e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9c88535bf8e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9c88535bf8e9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9c88535bf8e9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aayushmnit?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aayushmnit?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Aayush Agrawal"}, {"url": "https://medium.com/@aayushmnit/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "414 Followers"}, {"url": "http://aayushmnit.com", "anchor_text": "aayushmnit.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85dd669ac015&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&user=Aayush+Agrawal&userId=85dd669ac015&source=post_page-85dd669ac015--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8137fc02bcb8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-neural-network-from-scratch-9c88535bf8e9&newsletterV3=85dd669ac015&newsletterV3Id=8137fc02bcb8&user=Aayush+Agrawal&userId=85dd669ac015&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}