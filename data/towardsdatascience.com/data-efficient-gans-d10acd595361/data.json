{"url": "https://towardsdatascience.com/data-efficient-gans-d10acd595361", "time": 1683009923.912382, "path": "towardsdatascience.com/data-efficient-gans-d10acd595361/", "webpage": {"metadata": {"title": "Data-Efficient GANs!. A look at MIT\u2019s recent & exciting paper\u2026 | by Nicole Nair | Towards Data Science", "h1": "Data-Efficient GANs!", "description": "A prerequisite to understanding this article: you have trained a GAN or you understand the common difficulties that arise when training GANs such as the discriminator overfitting on the training\u2026"}, "outgoing_paragraph_urls": [{"url": "https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/", "anchor_text": "this", "paragraph_index": 0}, {"url": "https://developers.google.com/machine-learning/gan/problems", "anchor_text": "this", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "paper", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "main paper", "paragraph_index": 16}], "all_paragraphs": ["A prerequisite to understanding this article: you have trained a GAN or you understand the common difficulties that arise when training GANs such as the discriminator overfitting on the training data. Otherwise, do read this article and this article, or spend a couple of hours googling GANs on your own. And then come back here and enjoy this article!", "So you\u2019ve read about GANs. Maybe you\u2019ve even trained one. Maybe you\u2019ve tried to train one and watched as the discriminator loss goes down and down and down and \u201cBOOM\u201d you\u2019ve overfitted on the training data. You print out 100 images and 50 of them are the same malformed picture of a golden retriever. You\u2019ve gone to your professor, maybe with tears in your eyes, and you\u2019ve proclaimed:", "\u2018Add more data,\u2019 your professor says. \u2018And maybe take a nap.\u2019", "Fear not! The recent paper \u201cDifferentiable Augmentation for Data-Efficient GAN Training\u201d from MIT claims to be your salvation, or at least part of it (Zhao, Liu, Lin, Zhu & Han, 2020). The paper claims to require less data whilst still achieving state-of-the-art results using a special kind of data augmentation called \u2018differentiable\u2019 augmentation. In this blog post, I\u2019ll spill the tea on this paper (which if you can\u2019t already tell, I\u2019m very excited about). I\u2019ll tell you how this paper claims to improve GAN training, and I\u2019ll talk about whether it actually works. So grab a cuppa and a notebook, and pray to the GAN gods that this helps to vanquish the old monster of \u2018mode collapse.\u2019", "The Problem with GANs: A Very Quick Recap", "One of the first and most important concepts you\u2019ll learn about in machine learning is \u2018overfitting.\u2019 In the context of GANs, the discriminator, D continues to improve in training but does awfully during validation because it\u2019s begun to \u2018memorize\u2019 the image data. This does not necessarily lead to mode collapse where you get many of the same output image, though it often does. If you observe mode collapse, it\u2019s a form of evidence that the discriminator has overfitted on the data. Often, we just add more data in to prevent this problem \u2014 and of course, this does often help\u2026but so much data is not necessarily easy to collect. The paper provides a potent example: what if we are trying to generate images of a rare species? We do not have access to more data. We do not have to limit ourselves to such extreme edge cases as rare species, however. Even when we are talking about regular items like clothing, collecting data is expensive. Annotating data is expensive. It takes years (Zhao et al, 2020). We want the model to work now.", "So now we\u2019ll get to the solution that our paper talks about. The paper observes that when overfitting arises in situations of supervised learning (say a straightforward image classification problem), and we do not have more data to add, we would do something called augmentation of the data. [As a side note, do feel free to read up on other working solutions to the overfitting problem such as regularization].", "Image augmentation refers to flipping the picture on its side or changing its color a little, etc. etc. We just change the pictures a little so we get more samples. But with GANs, this augmentation can\u2019t straightforwardly work. The authors provide two ways we might augment data during GAN training, and why both fail to achieve good output images. And then they provide a third option which does work (differentiable augmentation) and that\u2019s what their paper is all about. So here are the two options that don\u2019t work:", "Option 1: Augment The Reals Only", "As you\u2019ll recall, when we\u2019re training a GAN, we have input images that are actual pictures of actual objects. We use this alongside the fakes that our generator makes, to input to the discriminator. So in this first approach to augmentation, we just augment these real images. Simple, right?", "Zhao et al (2020) report that the augmentation random horizontal flips do improve the results moderately. But stronger augmentations such as translations & cutouts to only the reals causes problems like distortion and weird coloring in the generated images. Whilst vanilla augmentation might work for regular classification problems, with GANs we are not classifying, we are trying to generate the true distribution of the data. But if we go and distort the real input data, then our generated outputs will be similarly distorted as well. The generator is encouraged to match the augmented & distorted distribution, NOT the true distribution. So what about option #2 for augmenting the data?", "Option 2: Augment All Discriminator Inputs", "In this option, we augment not just the reals, but also the fakes that are outputted by our generator and go into our discriminator. Interestingly, whilst the discriminator learns to perfectly classify between reals that are augmented and fakes that are augmented with an accuracy of above 90%, the discriminator fails to identify fakes that are not augmented, leading to an accuracy of below 10%. This is because the generator, G receives its gradient from the non-augmented fake images. So we need some way of propagating the gradient to our generator, G. Or else, in the horror-inducing words of Zhao et al (2020):", "the generator completely fools the discriminator", "So this is where the authors present a type of augmentation that does work, namely differentiable augmentation. To solve the issues with both option 1 and 2, the authors provide a solution that 1. augments real and fake images used in the discriminator network, but also 2. successfully \u201cpropagates the gradients of the augmented samples to G.\u201d This avoids the problem of failing to identify fakes that are not augmented which we discussed under option 2 earlier. This is the crux of the paper: to allow the propagation of the gradient to the generator G, they simply make very certain that the augmentation is, as the name says, differentiable. The authors provide three primary examples of such a differentiable augmentation:", "Cutout (masking with a random square of half image size), and", "So does this work? YES. Yes, it seems to work. The authors list some pretty cool results and I will list some of them here. I strongly encourage you to look at the rest of the results in the main paper \u2014 they well and truly blew my mind.", "Achievement #1: CIFAR-10 and CIFAR-100 Dataset. The authors used two famous GANs namely BigGAN and StyleGAN2 and tried several dataset sizes(100% data, 10% data, 20% data). To make their comparison fair to the baseline, they even made sure to use regularization & horizontal flips in the baseline method. For both CIFAR-10 and CIFAR-100, they demonstrate improvements over the baseline and are the new state-of-the-art for both CIFAR-10 and CIFAR-100.", "Achievement #2: ImageNet. Differentiable augmentation advanced the state-of-the-art on both 100% dataset and reduced size datasets.", "The reason that I love the solution presented in this paper is that it is so logical. The authors 1. tried different augmentation methods for GANs, 2. identified the exact difficulties and 3. promptly fixed the problem by using a specific kind of augmentation i.e. differentiable augmentation that is performed on both reals and fakes, and thus allowed the gradient to be propagated to the generator. And yet this logically deduced solution does so much. Now anyone else training a GAN can add \u2018use differentiable augmentation\u2019 to their toolbox of rules such as \u2018add noise to discriminator inputs\u2019 and \u2018penalize[regularize] discriminator weights\u2019 (\u201cGenerative Adversarial Networks\u201d, n.d.).", "This paper really made me excited, prompting me to write a post about it at 1 am. I hope that my discussion of it helps you to understand how the solution works and gets you hyped up as well!", "To end, a nice diagram from the paper which clearly displays their methodology:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist. Digital Humanist. Reader of Books."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd10acd595361&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d10acd595361--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d10acd595361--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nicarina98?source=post_page-----d10acd595361--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nicarina98?source=post_page-----d10acd595361--------------------------------", "anchor_text": "Nicole Nair"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8dddb92a2f6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&user=Nicole+Nair&userId=8dddb92a2f6e&source=post_page-8dddb92a2f6e----d10acd595361---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd10acd595361&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd10acd595361&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "paper"}, {"url": "https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/", "anchor_text": "this"}, {"url": "https://developers.google.com/machine-learning/gan/problems", "anchor_text": "this"}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "Zhao et al (2020)"}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "main paper"}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "Zhao et al (2020)"}, {"url": "https://arxiv.org/pdf/2006.10738v1.pdf", "anchor_text": "https://arxiv.org/pdf/2006.10738v1.pdf"}, {"url": "https://developers.google.com/machine-learning/gan/problems", "anchor_text": "https://developers.google.com/machine-learning/gan/problems"}, {"url": "https://medium.com/tag/generative-adversarial?source=post_page-----d10acd595361---------------generative_adversarial-----------------", "anchor_text": "Generative Adversarial"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d10acd595361---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d10acd595361---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----d10acd595361---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd10acd595361&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&user=Nicole+Nair&userId=8dddb92a2f6e&source=-----d10acd595361---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd10acd595361&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&user=Nicole+Nair&userId=8dddb92a2f6e&source=-----d10acd595361---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd10acd595361&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d10acd595361--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd10acd595361&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d10acd595361---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d10acd595361--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d10acd595361--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d10acd595361--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d10acd595361--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d10acd595361--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d10acd595361--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d10acd595361--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d10acd595361--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nicarina98?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nicarina98?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nicole Nair"}, {"url": "https://medium.com/@nicarina98/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "55 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8dddb92a2f6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&user=Nicole+Nair&userId=8dddb92a2f6e&source=post_page-8dddb92a2f6e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4482935f49a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-efficient-gans-d10acd595361&newsletterV3=8dddb92a2f6e&newsletterV3Id=4482935f49a5&user=Nicole+Nair&userId=8dddb92a2f6e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}