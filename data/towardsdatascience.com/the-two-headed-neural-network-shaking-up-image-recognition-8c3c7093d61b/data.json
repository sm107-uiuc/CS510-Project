{"url": "https://towardsdatascience.com/the-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b", "time": 1683014769.634666, "path": "towardsdatascience.com/the-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b/", "webpage": {"metadata": {"title": "The Two-Headed Neural Network Shaking Up Image Recognition | by Andre Ye | Towards Data Science", "h1": "The Two-Headed Neural Network Shaking Up Image Recognition", "description": "Deep neural networks have a big problem \u2014 they\u2019re constantly hungry for data. When there is too little data \u2014 an amount that would be acceptable for other algorithms \u2014 deep neural networks have\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/the-fascinating-blueprint-for-efficient-ai-self-supervised-learning-954f919f0d5d?source=---------12----------------------------", "anchor_text": "self-supervised learning", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/supervised-learning-but-a-lot-better-semi-supervised-learning-a42dff534781", "anchor_text": "Semi-supervised learning", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/the-intuition-and-applications-behind-autoencoders-variants-4afcd45559d4?source=your_stories_page-------------------------------------", "anchor_text": "utilizes latent variables learned through unsupervised training", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/we-need-to-rethink-convolutional-neural-networks-ccad1ba5dc1c?source=your_stories_page-------------------------------------", "anchor_text": "think a little more like humans do", "paragraph_index": 3}, {"url": "https://medium.com/analytics-vidhya/breaking-down-the-innovative-deep-learning-behind-google-translate-355889e104f1?source=your_stories_page-------------------------------------", "anchor_text": "zero-shot learning would be translating", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/exploring-the-simple-satisfying-math-behind-regularization-2c947755d19f?source=your_stories_page-------------------------------------", "anchor_text": "L1 difference", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/exploring-the-simple-satisfying-math-behind-regularization-2c947755d19f?source=your_stories_page-------------------------------------", "anchor_text": "L2", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/obtaining-top-neural-network-performance-without-any-training-5af0af464c59?source=your_stories_page-------------------------------------", "anchor_text": "care-free: \u201chere\u2019s a massive architecture, do what you want with it\u201d", "paragraph_index": 14}, {"url": "https://towardsdatascience.com/how-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d", "anchor_text": "convolutional neural networks", "paragraph_index": 21}, {"url": "https://towardsdatascience.com/manifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183?source=your_stories_page-------------------------------------", "anchor_text": "well-established manifold learning methods", "paragraph_index": 25}, {"url": "https://towardsdatascience.com/manifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183", "anchor_text": "like t-SNE and IsoMap", "paragraph_index": 25}, {"url": "http://www.cs.toronto.edu/~rsalakhu/papers/oneshot1.pdf", "anchor_text": "here", "paragraph_index": 26}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership", "paragraph_index": 28}], "all_paragraphs": ["Deep neural networks have a big problem \u2014 they\u2019re constantly hungry for data. When there is too little data \u2014 an amount that would be acceptable for other algorithms \u2014 deep neural networks have tremendous difficulty generalizing. This phenomenon highlights a gap between human and machine cognition; humans can learn complex patterns with few training examples (albeit at a slower rate).", "While research in self-supervised learning is growing to develop structures in which labels are completely unnecessary (labels are cleverly found in the training data itself), its use cases are restricted.", "Semi-supervised learning, another quickly growing field, utilizes latent variables learned through unsupervised training to boost the performance of supervised learning. This is an important concept, but its scope is limited to use cases where there is a relatively large unsupervised-to-supervised data ratio, and where the unlabeled data is compatible with labeled data.", "Perhaps one idea encapsulates all ideas \u2014 developing methods and architectures that make the most of limited labeled data; to make machines think a little more like humans do. A formal name is meta-learning, often referred to as \u2018learning to learn\u2019.", "A common term used in meta-learning and natural language processing is \u2018few-shot learning\u2019 or \u2018zero-shot learning\u2019. These refer to being able to recognize new concepts with few or no (respectively) data teaching the model the concept beforehand. One example of zero-shot learning would be translating from English to German after being trained on English-to-French and French-to-German translation tasks.", "Let\u2019s look at one machine learning task that requires few-shot learning, and how the unique architecture of the Siamese network approaches it. Our training data consists of ten shapes, belonging to one of four shape types. We have minimal amounts of data for each class, but we want to be able to generalize and recognize new shapes.", "The Siamese Neural Network measures the probability that two inputs belong to the same class. In this sense, it doesn\u2019t directly output the class of any one input; instead, it grounds its understanding of one input in explicit relation to the other input. The following data would be produced to train the model:", "Thus, for n samples in the dataset, the Siamese network can be trained on (n\u00b2 \u2212 n)/2 unique input pairs (n\u00b2 possible pairings between each input, n pairings between two of the same samples, /2 to account for a&b and b&a being counted as separate combinations).", "Then, during the prediction of some input a, the Siamese network runs a prediction on (a, x) for every sample x in the dataset. The class of a is that of the data point x that yields the largest network output.", "The Siamese network takes two inputs and encodes them (separately) into feature vectors via an embedding function, which consists of several convolutional layers. The two feature vectors are merged through a \u2018distance layer\u2019, which simply calculates the L1 difference |f1-f2|. Alternatively, distances can also be calculated via L2, cosine, etc. The output is a sigmoid-compressed linear combination of the distance vector.", "It\u2019s worth mentioning that in this case, the \u2018embedding\u2019 is really just an encoded representation of the original input layer with traditional elements of a convolutional neural network, like convolutional and pooling layers. What makes it an embedding is that the distances between embedded points is taken and processed to form an output", "*Note: an embedding is defined as a space in which distances between mapped points mean something; for example in NLP embeddings the words \u2018man\u2019 and \u2018boy\u2019 should be physically close in the space than, for instance, \u2018man\u2019 and \u2018purple\u2019, which have little relationship.", "The Siamese network gets its name from Siamese twins, or twins whose bodies are conjoined at birth and can appear to have two heads. This makes sense, given the appearance of the Siamese network.", "A key part of the Siamese network is that while there are two \u2018heads\u2019 to encode the two inputs, these share the same weights. This makes sense; f(a, b) should run the same internal dynamics as f(b, a). The encoding processes need to be the same, regardless of the order of the inputs.", "One could say that the Siamese network puts more structure into the image recognition process. Convolutional neural networks are much more care-free: \u201chere\u2019s a massive architecture, do what you want with it\u201d; Siamese networks map images to embeddings (determine key features in the image), through which distances are calculated (directly compare the two) and interpreted to produce a result.", "Fundamentally, Siamese networks represent a shift in how we view image recognition. When machines base their understanding of concepts in relation to each other \u2014 opposed to building representations from ground zero, as is with traditional image recognition \u2014 they can learn with fewer data.", "This very well may be an explanation as to why humans are able to recognize and learn concepts with few training examples. We store information through complex hierarchies and intertwining relationships: an orange is similar to an apple but vastly different from a car. When a new concept is described in relationship to existing concepts, learning is more efficient.", "Luckily, there\u2019s a more efficient way to memorize this set: express each number in relation to the previous. If we remember that the first number is 2101, we just need to remember 1, -3, 2, -4, 3, -5. Instead of working with complex and large (in terms of magnitude) concepts, it\u2019s much more effective to establish the presence of ones in relation to others.", "Siamese networks can be used for one-shot learning \u2014 learning a concept given only one training example \u2014 via data augmentation. For instance, one could make small rotations, shifts, and zooms to an image; since the dataset size grows at a rate of n\u00b2, this provides substantial information.", "Furthermore, they can be used in verification problems (recognizing two faces as the same person, two fingerprints, two hand signatures, etc.) \u2014 in fact, many state-of-the-art real-time face recognition systems employ Siamese neural networks. These networks are superior in this task to standard image recognition architectures, which have tremendous difficulty handing large amounts of classes (we\u2019re talking tens of thousands of people).", "As a general rule, Siamese networks can deal with class imbalances tremendously well. This makes it appealing to tasks like image recognition. Part of this can be attributed to the structured nature of embeddings; on the other hand, in the vast free-for-all terrain of vast convolutional networks, insignificant learnings tend to be filtered out.", "Usually, the answer is to simply make convolutional neural networks larger, but the continual supersizing of networks is coming to a practical limit.", "It\u2019s important to realize that while the prediction process may seem long \u2014 looping through each sample in the data \u2014 beyond the fact that Siamese networks are trained on small datasets, generally Siamese networks require smaller architectures while developing a strong understanding. Additionally, in practice the embeddings of items are usually pre-computed and cached, since their values are used often.", "They can also be used in ranking problems, in which the network outputs not whether two inputs are in the same class but rather whether the first input ranks higher than the second input, as well as similarity problems (like measuring the content of two excerpts).", "Additionally, Siamese networks can be adapted for any data type, including those beyond images like text and structured data.", "It\u2019s also of interest to note that Siamese Networks produce really, really great embeddings. They are more expensive to produce than other well-established manifold learning methods like t-SNE and IsoMap, but are a nice auxiliary result. This is likely the result of its unique architecture.", "Thanks for reading! Read the original Siamese Network paper here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML enthusiast. Join Medium through my referral link: https://andre-ye.medium.com/membership."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8c3c7093d61b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://andre-ye.medium.com/?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006----8c3c7093d61b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8c3c7093d61b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8c3c7093d61b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/4Mu2bXIsn5Y", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/the-fascinating-blueprint-for-efficient-ai-self-supervised-learning-954f919f0d5d?source=---------12----------------------------", "anchor_text": "self-supervised learning"}, {"url": "https://towardsdatascience.com/supervised-learning-but-a-lot-better-semi-supervised-learning-a42dff534781", "anchor_text": "Semi-supervised learning"}, {"url": "https://towardsdatascience.com/the-intuition-and-applications-behind-autoencoders-variants-4afcd45559d4?source=your_stories_page-------------------------------------", "anchor_text": "utilizes latent variables learned through unsupervised training"}, {"url": "https://towardsdatascience.com/we-need-to-rethink-convolutional-neural-networks-ccad1ba5dc1c?source=your_stories_page-------------------------------------", "anchor_text": "think a little more like humans do"}, {"url": "https://medium.com/analytics-vidhya/breaking-down-the-innovative-deep-learning-behind-google-translate-355889e104f1?source=your_stories_page-------------------------------------", "anchor_text": "zero-shot learning would be translating"}, {"url": "https://towardsdatascience.com/exploring-the-simple-satisfying-math-behind-regularization-2c947755d19f?source=your_stories_page-------------------------------------", "anchor_text": "L1 difference"}, {"url": "https://towardsdatascience.com/exploring-the-simple-satisfying-math-behind-regularization-2c947755d19f?source=your_stories_page-------------------------------------", "anchor_text": "L2"}, {"url": "http://www.cs.toronto.edu/~rsalakhu/papers/oneshot1.pdf", "anchor_text": "Siamese Network paper"}, {"url": "https://towardsdatascience.com/obtaining-top-neural-network-performance-without-any-training-5af0af464c59?source=your_stories_page-------------------------------------", "anchor_text": "care-free: \u201chere\u2019s a massive architecture, do what you want with it\u201d"}, {"url": "http://www.cs.toronto.edu/~rsalakhu/papers/oneshot1.pdf", "anchor_text": "Siamese Network paper"}, {"url": "https://towardsdatascience.com/how-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d", "anchor_text": "convolutional neural networks"}, {"url": "https://towardsdatascience.com/manifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183?source=your_stories_page-------------------------------------", "anchor_text": "well-established manifold learning methods"}, {"url": "https://towardsdatascience.com/manifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183", "anchor_text": "like t-SNE and IsoMap"}, {"url": "https://qph.fs.quoracdn.net/main-qimg-d1fd949737da3ecf2e2e9013f5c005ff", "anchor_text": "Left"}, {"url": "https://qph.fs.quoracdn.net/main-qimg-9b637f7f554ff5c8adb4e9345dfb5813", "anchor_text": "right"}, {"url": "http://www.cs.toronto.edu/~rsalakhu/papers/oneshot1.pdf", "anchor_text": "here"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8c3c7093d61b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8c3c7093d61b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----8c3c7093d61b---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----8c3c7093d61b---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8c3c7093d61b---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8c3c7093d61b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&user=Andre+Ye&userId=be743a65b006&source=-----8c3c7093d61b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8c3c7093d61b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&user=Andre+Ye&userId=be743a65b006&source=-----8c3c7093d61b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8c3c7093d61b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8c3c7093d61b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8c3c7093d61b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8c3c7093d61b--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://andre-ye.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.8K Followers"}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff44a966e4ff1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b&newsletterV3=be743a65b006&newsletterV3Id=f44a966e4ff1&user=Andre+Ye&userId=be743a65b006&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}