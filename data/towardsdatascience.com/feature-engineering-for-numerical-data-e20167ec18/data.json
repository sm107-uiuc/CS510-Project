{"url": "https://towardsdatascience.com/feature-engineering-for-numerical-data-e20167ec18", "time": 1683006431.269566, "path": "towardsdatascience.com/feature-engineering-for-numerical-data-e20167ec18/", "webpage": {"metadata": {"title": "Feature Engineering for Numerical Data | by Kurtis Pykes | Towards Data Science", "h1": "Feature Engineering for Numerical Data", "description": "Numeric data is almost a blessing. Why almost? Well, because it is already in a format that is ingestible by Machine Learning models. However, if we translate it into human-relatable terms, just\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/e2f299e30cb9?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Will Koehrsen", "paragraph_index": 2}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/effective-data-visualization-ef30ae560961", "anchor_text": "Effective data visualization", "paragraph_index": 6}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data", "anchor_text": "House Prices: Advanced regression techniques", "paragraph_index": 16}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data", "anchor_text": "Click here for access data", "paragraph_index": 16}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee", "paragraph_index": 18}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html", "anchor_text": "sklearn documentation.", "paragraph_index": 21}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html", "anchor_text": "Sklearn documentation", "paragraph_index": 22}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer", "anchor_text": "documentation", "paragraph_index": 23}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html", "anchor_text": "Documentation", "paragraph_index": 29}, {"url": "https://www.amazon.co.uk/Feature-Engineering-Machine-Learning-Principles-ebook/dp/B07BNX4MWC", "anchor_text": "Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists", "paragraph_index": 30}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee", "paragraph_index": 32}, {"url": "https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/", "anchor_text": "Discover Feature Engineering, How to Engineer Features and How to get good at it", "paragraph_index": 32}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee", "paragraph_index": 33}, {"url": "https://machinelearningmastery.com/how-to-transform-data-to-fit-the-normal-distribution/", "anchor_text": "How to data to better fit the Normal Distribution", "paragraph_index": 33}, {"url": "https://medium.com/u/c6b0b560a0c4?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Emre Ren\u00e7bero\u011flu", "paragraph_index": 34}, {"url": "https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114", "anchor_text": "Fundamental Techniques of Feature Engineering for Machine Learning", "paragraph_index": 34}, {"url": "https://www.dummies.com/education/math/statistics/types-of-statistical-data-numerical-categorical-and-ordinal/", "anchor_text": "Types of Statistical Data: Numerical, categorical and ordinal", "paragraph_index": 35}, {"url": "https://www.amazon.co.uk/Feature-Engineering-Machine-Learning-Principles-ebook/dp/B07BNX4MWC", "anchor_text": "Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists", "paragraph_index": 36}], "all_paragraphs": ["Numeric data is almost a blessing. Why almost? Well, because it is already in a format that is ingestible by Machine Learning models. However, if we translate it into human-relatable terms, just because a PhD level textbook is written in English \u2014 I speak, read and write in English \u2014 does not mean that I am capable of understanding the textbook well enough to derive useful insights. What would make the textbook useful to me is if it epitomizes the most important information in a manner that considers the assumptions of my mental model, such as \u201cMaths is a myth\u201d (which by the way is no longer my view since I am really starting to enjoying it). In the same way, a good feature should represent salient aspects of the data, as well as taking the shape of the assumptions that are made by the Machine Learning model.", "Feature engineering is the process of extracting features from raw data and transforming them into formats that can be ingested by a Machine learning model. Transformations are often required to ease the difficulty of modelling and boost the results of our models. Therefore, techniques to engineer numeric data types are fundamental tools for Data Scientist (Machine Learning Engineers alike) to add to their artillery.", "\u201cdata is like the crude oil of machine learning which means it has to be refined into features \u2014 predictor variables \u2014 to be useful for training a model.\u201d - Will Koehrsen", "As we strive for mastery, it is important to note that it is never enough to know why a mechanism works and what it can do. Mastery knows how something is done, has intuition for the underlying principles and has the neural connections that makes drawing the correct tool a seamless procedure when faced with a challenge. That will not come from reading this article, but from deliberate practice of which this article will open the door for you to do by providing the intuition behind the techniques, so that you may understand how and when to apply them.", "The features in your data will directly influence the predictive models you use and the results you can achieve.\u201d \u2014 Jason Brownlee", "Note: You can find the code used for this Article on my Github page", "There may be occasions where data is collected on a feature that accumulates, thereby having an infinite upper boundary. Examples of this type of continuous data may be a tracking system that monitors the amount of visits that all of my medium post receives on a daily basis. This type of data easily attracts outliers since there could be some unpredictable event that affects the total traffic that my articles are accumulating, for instance one day, people may decide they want to be able to do data analysis, so my article on Effective data visualization may spike for that day. In other words, when data can be collected quickly and in large amounts, then it is likely that it would contain some extreme values that would need engineering.", "Some methods to handle this instance are:", "This method contains the scale of the data by grouping the values into bins. Therefore, quantization maps a continuous value into a discrete value and conceptually, this can be thought of as an ordered sequence of bins. To implement this, we must consider the width of bins that we create of which the solutions fall into 2 categories, fixed-width bins or adaptive bins.", "Note: This is particularly useful for linear models, in tree based models this is not useful (Tree based models make their own splits).", "In the fixed-width scenario, the value is automatically or custom-designed to segment data into discrete bins \u2014 they can also be linearly scaled or exponentially scaled. A popular example is separating ages of people into partitions by decade intervals such that bin 1 contains ages 0\u20139, bin 2 has 10\u201319 etc.", "Note that if the values span across a large magnitude of numbers then a better method may be to group the values into powers of a constant, such as to the power of 10: 0\u20139, 10\u201399, 100\u2013999, 1000\u20139999. Notice that the bin widths grow exponentially, hence in the case of 1000\u20139999 the bin width is O(10000), whereas 0\u20139 is O(10). Take the log of the count to map from the count to the bin of the data.", "Adaptive bins are a better fit when there are large gaps within the counts. When there are large margins in-between the values of the counts then some of the fixed-width bins would be empty.", "To do adaptive binning we can make use of the quantiles of the data \u2014 the values that divide the data into equal portions like the median.", "We have already seen an example of this\u2026 The log transformation is part of a family of variance stabilizing transformations know as power transformations. Wikipedia describes power transformations as a \u201ctechnique used to stabilize variance, make the data more normal distribution-like, improve the validity of measures of association such as the Pearson correlation between variables and for other data stabilization procedures.\u201d", "Why would we want to transform our data to fit the Normal Distribution? Great question! You may want to use a parametric model \u2014 a model that makes assumptions of the data- rather than a non-parametric model. When the data is normally distributed, parametric models are powerful. However, in some cases, the data we have may need a helping hand to bring out the beautiful bell shaped curve of the normal distribution, for instance, the data may be skewed so we apply a power transformation to assist in helping our feature look more Gaussian.", "The code below leverages data science frameworks such as pandas, scipy and numpy to demonstrate power transformations and visualize them using the Plotly.py framework for interactive plots. The dataset used is the House Prices: Advanced regression techniques from Kaggle which you can easily download (Click here for access data).", "Note: Box-cox transformations only work when the data is non-negative", "\u201cWhich of these is best? You cannot know beforehand. You must try them and evaluate the results to achieve on your algorithm and performance measures.\u201d - Jason Brownlee", "As the name implies, feature scaling (also referred to as feature normalization), is concerned with changing the scale of features. When the features of a dataset differ greatly in scale, then a model that is sensitive to the scale of the input features (i.e. linear regression, logistic regression, neural networks) would be affected. Ensuring features are within a similar scale is imperative. Whereas, models such as tree-based models (i.e. Decision Trees, Random Forest, Gradient boosting) do not care about scale.", "Common ways to scale features include, min-max scaling, standardization and L\u00b2 normalization, next would be a brief introduction and implementation in python.", "Min-Max Scaling - The feature is scaled to a fixed range (which is usually between 0\u20131) meaning that we will have reduced standard deviations therefore suppressing the effect of outliers on the feature. Where x is the individual value of the instance (i.e. person 1, feature 2), max(x), min(x) is the maximum and minimum values of the feature \u2014 see figure 3. For more on this, see sklearn documentation.", "Standardization - The feature values will be rescaled so that they fit the properties of a normal distribution where the mean is 0 and standard deviation is 1. To do this, we subtract the mean of the feature \u2014 taken over all the instances- from the feature instance value, then divide by the variance \u2014 see figure 4. Sklearn documentation for standardization.", "L\u00b2 Normalization - This technique divides the original feature value by the l\u00b2 norm (also euclidean distance) \u2014 the second equation in figure 5. L\u00b2 norm takes the sum of squares of the values in the feature set across all instances. Sklearn documentation for L\u00b2 Norm (note that there is also the option to do L\u00b9 normalization by setting the norm parameter to \"l1\" ).", "Visualization of the effects of feature scaling will give a better image of what is going on. For this I am using the wine dataset that can be imported from sklearn datasets.", "We can create the logical AND function by using the product of pairwise interactions between features. In tree-based models, these interactions occur implicitly but in models that assume independence of the features, we can explicitly declare interactions between features to improve the output of the model.", "Think of a simple linear model that uses a linear combination of the input features to predict the output y:", "We can extend the linear model to capture the interactions that occur between features.", "Note: Linear functions are expensive to use and the scoring and training of a linear model with a pairwise interaction would go from O(n) to O(n\u00b2). However, you could perform feature extraction to overcome this problem (feature extraction is beyond the scope of this article, but will be something I discuss in a future article).", "Let\u2019s code this in python, I am going to leverage the scitkit-learn PolynomialFeatures class and you can read more about it in the Documentation:", "This article was heavily inspired by the book Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists which i\u2019d definitely recommend reading. Though it was published in 2016, it is still very informative and clearly explained, even for those without a mathematical background.", "There we have it\u2026 In this article we discussed techniques to deal with numerical features, such as quantization, power transformations, feature scaling and interaction features (which can be applied to various data types). This is by no means the be all and end all of feature engineering and there is always much more to learn on a daily basis. Feature engineering is an art and will take practice so now that you have the intuition, you are ready to begin practicing. You can find the code used in this article on my Github (linked below). Thank you so much for your time!", "Jason Brownlee - Discover Feature Engineering, How to Engineer Features and How to get good at it", "Jason Brownlee - How to data to better fit the Normal Distribution", "Emre Ren\u00e7bero\u011flu - Fundamental Techniques of Feature Engineering for Machine Learning", "Deborah Rumsey - Types of Statistical Data: Numerical, categorical and ordinal", "Alice Zheng & Amanda Casari - Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe20167ec18&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e20167ec18--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kurtispykes.medium.com/?source=post_page-----e20167ec18--------------------------------", "anchor_text": ""}, {"url": "https://kurtispykes.medium.com/?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Kurtis Pykes"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5ba760786877&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&user=Kurtis+Pykes&userId=5ba760786877&source=post_page-5ba760786877----e20167ec18---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe20167ec18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe20167ec18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@shaneavery?utm_source=medium&utm_medium=referral", "anchor_text": "Shane Avery"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/u/e2f299e30cb9?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Will Koehrsen"}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee"}, {"url": "https://github.com/kurtispykes/demo/tree/master", "anchor_text": "kurtispykes/demoDemonstration code related to Medium blog articles E.x. #. - path/to/file; link to article Effective Data Visualization\u2026github.com"}, {"url": "https://towardsdatascience.com/effective-data-visualization-ef30ae560961", "anchor_text": "Effective data visualization"}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data", "anchor_text": "House Prices: Advanced regression techniques"}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data", "anchor_text": "Click here for access data"}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html", "anchor_text": "sklearn documentation."}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html", "anchor_text": "Sklearn documentation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer", "anchor_text": "documentation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html", "anchor_text": "Documentation"}, {"url": "https://www.amazon.co.uk/Feature-Engineering-Machine-Learning-Principles-ebook/dp/B07BNX4MWC", "anchor_text": "Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists"}, {"url": "https://github.com/kurtispykes/demo/tree/master", "anchor_text": "kurtispykes/demoDemonstration code related to Medium blog articles E.x. #. - path/to/file; link to article Effective Data Visualization\u2026github.com"}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee"}, {"url": "https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/", "anchor_text": "Discover Feature Engineering, How to Engineer Features and How to get good at it"}, {"url": "https://medium.com/u/f374d0159316?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Jason Brownlee"}, {"url": "https://machinelearningmastery.com/how-to-transform-data-to-fit-the-normal-distribution/", "anchor_text": "How to data to better fit the Normal Distribution"}, {"url": "https://medium.com/u/c6b0b560a0c4?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Emre Ren\u00e7bero\u011flu"}, {"url": "https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114", "anchor_text": "Fundamental Techniques of Feature Engineering for Machine Learning"}, {"url": "https://www.dummies.com/education/math/statistics/types-of-statistical-data-numerical-categorical-and-ordinal/", "anchor_text": "Types of Statistical Data: Numerical, categorical and ordinal"}, {"url": "https://www.amazon.co.uk/Feature-Engineering-Machine-Learning-Principles-ebook/dp/B07BNX4MWC", "anchor_text": "Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e20167ec18---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e20167ec18---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e20167ec18---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----e20167ec18---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----e20167ec18---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe20167ec18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&user=Kurtis+Pykes&userId=5ba760786877&source=-----e20167ec18---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe20167ec18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&user=Kurtis+Pykes&userId=5ba760786877&source=-----e20167ec18---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe20167ec18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e20167ec18--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe20167ec18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e20167ec18---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e20167ec18--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e20167ec18--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e20167ec18--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e20167ec18--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e20167ec18--------------------------------", "anchor_text": ""}, {"url": "https://kurtispykes.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kurtispykes.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kurtis Pykes"}, {"url": "https://kurtispykes.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.3K Followers"}, {"url": "https://www.fullstackfreelancershub.com/wisdom-wednesday", "anchor_text": "https://www.fullstackfreelancershub.com/wisdom-wednesday"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5ba760786877&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&user=Kurtis+Pykes&userId=5ba760786877&source=post_page-5ba760786877--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffde3d752d24c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-engineering-for-numerical-data-e20167ec18&newsletterV3=5ba760786877&newsletterV3Id=fde3d752d24c&user=Kurtis+Pykes&userId=5ba760786877&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}