{"url": "https://towardsdatascience.com/python-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab", "time": 1683007828.577653, "path": "towardsdatascience.com/python-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab/", "webpage": {"metadata": {"title": "Python and world literature: elementary web scraping with BeautifulSoup | by Pavlo Horbonos | Towards Data Science", "h1": "Python and world literature: elementary web scraping with BeautifulSoup", "description": "Every new data scientist wants to create spectacular visualizations, build progressive prediction models, get sensational insights from the data. Okay, these things are very attractive and beautiful\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#", "anchor_text": "BeautifulSoap parser", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Literature", "anchor_text": "the appropriate Wikipedia page", "paragraph_index": 4}, {"url": "https://requests.readthedocs.io/en/master/user/advanced/", "anchor_text": "requests library page", "paragraph_index": 6}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#", "anchor_text": "in the documentation", "paragraph_index": 13}, {"url": "https://github.com/Midvel/medium_jupyter_notes/blob/master/bs_scrapping/bs-scrapping.ipynb", "anchor_text": "on my GitHub", "paragraph_index": 15}, {"url": "https://twitter.com/MidvelCorp", "anchor_text": "https://twitter.com/MidvelCorp", "paragraph_index": 23}, {"url": "https://blaize.tech/", "anchor_text": "https://blaize.tech/", "paragraph_index": 23}], "all_paragraphs": ["Every new data scientist wants to create spectacular visualizations, build progressive prediction models, get sensational insights from the data. Okay, these things are very attractive and beautiful. But sometimes people forget about a lot of \u201cdirty\u201d jobs at the beginning of each analytical process. And this is not even the data cleaning stage.", "Before you even start to work with the data, you need \u2026 the data!", "Yes, it is a common mistake to believe that data analysis starts from dataset cleaning because it refers to the fact you already have the data. Someone might believe that you will always have magically gotten the data from the air. But data scraping, gathering, digging, and collecting are the skills you need to improve constantly. You have to be able to work with different sources, formats, and sometimes even languages, and that fact assumes you have enough skills. One of the basic skills is web-scraping \u2014 loading data from websites and web-applications.", "Of course, there are a lot of technics and methods for spiders and crawlers creation. Today I want to start with the most primitive but very effective tools \u2014 BeautifulSoap parser. It is a very powerful HTML-parser, which combined with proper requests logic will automate your data collection process. So, no more words \u2014 let\u2019s start coding.", "I will repeat the first thought of the article: to work with the data you need \u2026 the data! So, we need some content to be loaded. I want to create my own dataset for further analysis, and it is dedicated to the Nobel prize. The starting point is the list of the laureates, and I have chosen the literature category to work with. I want to keep it simple, so I will use the appropriate Wikipedia page. Yes, it is not perfect, but still, a good place to start, since it has a lot of cross-links, which I will use for the additional information.", "But firstly we should prepare the engine for requests. I created a simple session (as I want to keep a stable connection to the same host) and a simple adapter (for the cases of timeouts or networks switching).", "You may read about additional settings on the requests library page. So, this was easy, let\u2019s move on.", "Still nothing interesting here: just load the page and create the appropriate BeautifulSoup parser:", "Now we are prepared for the next step, which involves some exploration.", "It may sound strange, but before we force the script to search the information automatically, we should find it manually. And no, it does not contradict the purpose of the article! We have to study the data, explore its internal structures, and apply that knowledge for the scrapper creation. In other words, we should find some orienteers for the scrapper to parse the desired HTML-tag. We can see a big table with the data on the page, but we need to dig down the HTML-code to see, where the table is actually located. We cannot refer to the place, because more table may be inserted before the desired one. We cannot refer to the number of lines from the start of the chapter, with the same reasons. But we may rely on the chapter name and different tag attributes. So, let\u2019s \u201cfind\u201d the tag with the \u201cLaureates\u201d name and id attribute and find the desired table under it. Every BeautifulSoup tag can use find_all() method to traverse its content (all internal tags):", "And here it is. Based on the standard Wiki-page structure we know, that it is the child tag of the header. Lucky for us, every parsed tag has a pointer to the parent tag:", "We use that information to find the desired table. Every BeautifulSoup tag has not only parent pointer, but also next_sibling and previous_sibling pointers. So, we can travel all over the \u201cneighbor\u201d tags. As we have seen in the page\u2019s code, our table is just under the found header.", "Here is the tricky part. We see, that the table has a lot of rows, and some rows have all the cells filled, but some have the common string \u201cNot awarded\u201d. But it is not the most difficult part: some years have two laureates. But we are armed with some BeautifulSoup instruments:", "and a lot of others, which you can find in the documentation.", "The main idea is to go through each row, which is represented as <tr> tag and get all the cells, which are represented as <td> tag. Since the table can be very large, we probably do not want to copy and traverse all its rows at once. Though, BeautifulSoup provides us tag.children accessor generator for all internal tags of the chosen one:", "You may check the parsing function itself in the complete code on my GitHub. Actually, it is pure parsing logic, which should include some exceptional cases. So, after some attempts, we have gathered the data. But is not enough for us!", "Together with the data we need, we have also scrapped the links to the individual pages of each author. We will use that information to build the next part of the scrapper. Actually, it is the very basic level of the crawler, since we will re-use scrapped links to the new pages.", "We have a lot of rows and of course, we will not check every page for every row. So, we will rely on the assumption, that every author\u2019s page has the biography element. That element is our aim since it contains a lot of additional data:", "One more cycle, one more parsing function: and the dataset is prepared!", "Nevertheless, it is just the first step in the long data analysis process. The data is raw and needs a lot of cleaning. But, that is a very different story.", "As always (old readers already know it, the new ones \u2014 your pleasure), here is the link to my GitHub working example.", "Also, since the next logical step is data cleaning, make sure you didn\u2019t miss my articles about missing data handling:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Art & Code | https://twitter.com/MidvelCorp \ud83d\udcbb| Head of Blockchain Security in https://blaize.tech/ | web3 and blockchain enthusiast and researcher"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa43daaf46ab&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@midvel.corp?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@midvel.corp?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "Pavlo Horbonos"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7154b5bfb5f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&user=Pavlo+Horbonos&userId=7154b5bfb5f6&source=post_page-7154b5bfb5f6----a43daaf46ab---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa43daaf46ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa43daaf46ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@daiga_ellaby?utm_source=medium&utm_medium=referral", "anchor_text": "Daiga Ellaby"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#", "anchor_text": "BeautifulSoap parser"}, {"url": "https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Literature", "anchor_text": "the appropriate Wikipedia page"}, {"url": "https://requests.readthedocs.io/en/master/user/advanced/", "anchor_text": "requests library page"}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#", "anchor_text": "in the documentation"}, {"url": "https://github.com/Midvel/medium_jupyter_notes/blob/master/bs_scrapping/bs-scrapping.ipynb", "anchor_text": "on my GitHub"}, {"url": "https://github.com/Midvel/medium_jupyter_notes/blob/master/bs_scrapping/bs-scrapping.ipynb", "anchor_text": "Midvel/medium_jupyter_notesPermalink Dismiss GitHub is home to over 50 million developers working together to host and review code, manage\u2026github.com"}, {"url": "https://towardsdatascience.com/7-idioms-to-acquire-missing-values-every-data-scientist-should-know-2edf4224360c", "anchor_text": "7 idioms to acquire missing values every data scientist should knowCommands you should bring to automatismtowardsdatascience.com"}, {"url": "https://towardsdatascience.com/handle-missing-data-with-r-10-daily-used-idioms-13d849d01690", "anchor_text": "Handle missing data with R: 10 daily used idiomsCommands you should bring to automatismtowardsdatascience.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a43daaf46ab---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----a43daaf46ab---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/programming?source=post_page-----a43daaf46ab---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/software-development?source=post_page-----a43daaf46ab---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----a43daaf46ab---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa43daaf46ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&user=Pavlo+Horbonos&userId=7154b5bfb5f6&source=-----a43daaf46ab---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa43daaf46ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&user=Pavlo+Horbonos&userId=7154b5bfb5f6&source=-----a43daaf46ab---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa43daaf46ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa43daaf46ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a43daaf46ab---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a43daaf46ab--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a43daaf46ab--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a43daaf46ab--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@midvel.corp?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@midvel.corp?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Pavlo Horbonos"}, {"url": "https://medium.com/@midvel.corp/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "406 Followers"}, {"url": "https://twitter.com/MidvelCorp", "anchor_text": "https://twitter.com/MidvelCorp"}, {"url": "https://blaize.tech/", "anchor_text": "https://blaize.tech/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7154b5bfb5f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&user=Pavlo+Horbonos&userId=7154b5bfb5f6&source=post_page-7154b5bfb5f6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6a79629f6cc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpython-and-world-literature-elementary-web-scraping-with-beautifulsoup-a43daaf46ab&newsletterV3=7154b5bfb5f6&newsletterV3Id=6a79629f6cc9&user=Pavlo+Horbonos&userId=7154b5bfb5f6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}