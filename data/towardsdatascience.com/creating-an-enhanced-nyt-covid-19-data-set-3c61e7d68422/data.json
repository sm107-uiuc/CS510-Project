{"url": "https://towardsdatascience.com/creating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422", "time": 1683009465.002078, "path": "towardsdatascience.com/creating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422/", "webpage": {"metadata": {"title": "Creating an Enhanced NYT COVID-19 Data Set | by Kelly Joyner | Towards Data Science", "h1": "Creating an Enhanced NYT COVID-19 Data Set", "description": "Note from the editors: Towards Data Science is a Medium publication primarily based on the study of data science and machine learning. We are not health professionals or epidemiologists, and the\u2026"}, "outgoing_paragraph_urls": [{"url": "http://towardsdatascience.com", "anchor_text": "Towards Data Science", "paragraph_index": 0}, {"url": "https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/2004.00756.pdf?fbclid=IwAR39ljXM6aSaAftwFZII2-UAJArQKLVYw8uYRW_hY5Th6ak0K6fOeruhuKI", "anchor_text": "built by a team of people", "paragraph_index": 4}, {"url": "https://github.com/delusionary/covid_bigquery_dataset", "anchor_text": "checked in some files", "paragraph_index": 7}, {"url": "https://console.cloud.google.com/bigquery?project=covid-project-275201&page=project", "anchor_text": "publicly available", "paragraph_index": 8}, {"url": "https://covidtracking.com", "anchor_text": "COVID Tracking Project", "paragraph_index": 9}, {"url": "https://github.com/nytimes/covid-19-data", "anchor_text": "source", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/FIPS_county_code", "anchor_text": "FIPS codes", "paragraph_index": 24}, {"url": "https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html", "anchor_text": "GEOID", "paragraph_index": 24}, {"url": "https://www.nrcs.usda.gov/wps/portal/nrcs/detail/?cid=nrcs143_013696", "anchor_text": "two-digit number", "paragraph_index": 26}, {"url": "https://www.dshs.texas.gov/chs/info/info_txco.shtm", "anchor_text": "three-digit number", "paragraph_index": 27}, {"url": "https://console.cloud.google.com/marketplace/details/united-states-census-bureau/us-geographic-boundaries?filter=solution-type:dataset&q=counties&id=20d75072-82af-4fd3-a235-7080e71bcc1b", "anchor_text": "public datasets", "paragraph_index": 42}, {"url": "https://cloud.google.com/bigquery/docs/gis-visualize", "anchor_text": "BigQueryGeoViz", "paragraph_index": 44}, {"url": "https://cloud.google.com/bigquery/docs/reference/standard-sql/geography_functions", "anchor_text": "documentation", "paragraph_index": 45}, {"url": "https://cloud.google.com/bigquery/docs/gis-getting-started", "anchor_text": "Getting Started", "paragraph_index": 45}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/200_nyt_counties.sql", "anchor_text": "aggregate", "paragraph_index": 48}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/130_nyt_kc_county_temp_1.sql", "anchor_text": "build", "paragraph_index": 52}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/150_nyt_kc_mo_trimmed_counties.sql", "anchor_text": "subtract out", "paragraph_index": 53}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/150_nyt_kc_mo_trimmed_counties.sql", "anchor_text": "trimmed out", "paragraph_index": 54}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/140_nyt_kc_county.sql", "anchor_text": "Kansas City", "paragraph_index": 54}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/010_county_area_acs.sql", "anchor_text": "first", "paragraph_index": 63}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/100_nyt_kcmo_agg_bg_by_county.sql", "anchor_text": "aggregate", "paragraph_index": 63}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/920_nyt_7_day_counts.sql", "anchor_text": "first", "paragraph_index": 71}, {"url": "https://cloud.google.com/bigquery/docs/reference/standard-sql/navigation_functions#lag", "anchor_text": "LAG", "paragraph_index": 71}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/930_nyt_acceleration.sql", "anchor_text": "acceleration", "paragraph_index": 71}], "all_paragraphs": ["Note from the editors: Towards Data Science is a Medium publication primarily based on the study of data science and machine learning. We are not health professionals or epidemiologists, and the opinions of this article should not be interpreted as professional advice. To learn more about the coronavirus pandemic, you can click here.", "I\u2019ve been working in Google Cloud for ten months, but haven\u2019t had any experience with our product offerings, so when I read that Google was adding COVID data, including the New York Times county-level data, to their public BigQuery data sets, it seemed like a good opportunity to learn how the tools work. (Disclaimer: This is a project I did on my own time, and is not associated with Google.)", "I\u2019ve been very anxious during the pandemic, and my main coping mechanism for dealing with anxiety is to try to understand the thing that is making me anxious. When I started this project in mid-March, there were a lot fewer sources of deep analytics regarding the virus, and I wanted to be able to pose questions of the raw data, to pose and test hypotheses, to better understand its spread and the implications for public health policy and my own actions.", "I also wanted to learn some new stuff.", "If you are looking for a reliable, tested, high-quality demographic data set for COVID-19 in the US, this is not that data set. I think it\u2019s pretty great, but I did it myself, in my spare time, as a learning exercise and for my own use. You\u2019d be much better off using a data set built by a team of people, with actual training, automated correctness tests, better metrics tests, and more adoption.", "I thought sharing my neophyte experiences building a reporting schema like this might be useful or interesting to others in the same way that the many articles I read in the course of doing so were helpful to me.", "This project required learning to work with GIS and SQL geometry primitives, how Census Bureau data was put together, and some strategies for dealing with complex subsets of that data, such as city boundaries and parts of counties. I hope these strategies and tools might be useful to others who are learning to manipulate similar data sets.", "I\u2019ve checked in some files on GitHub that can be used to recreate the reporting schema, if you\u2019re into that sort of thing. I purposefully didn\u2019t put in any integrity tests or installation automation. It\u2019s not that I\u2019m lazy, it\u2019s for some other reason.", "If you are interested in the data set itself, it is publicly available through BigQuery. I materialize a couple of tables every six hours or so, but you\u2019re better off querying my views and materializing your own table if you want the most up-to-date data.", "There are several datasets of raw numbers reported by counties and states out there. At first, I quickly built a BigQuery importer for COVID Tracking Project data, which started out as a project of The Atlantic. It\u2019s a widely-used data set at a state level and tracks hospitalizations and tests as well as infections and deaths.", "It seemed to me, however, that the variation within states, however, was more important than the variation between states. This is a disease that, in the beginning at least, impacts dense urban areas much more than less dense rural areas, and that seems likely to continue due to the factors that increase its spread.", "In addition to the density issue, 50 or so is a small number of samples. It represents an aggregation of a much larger number of county reports, and information is lost in that aggregation.", "I wanted the finest-grained data I could find, and in the U.S., that means looking at reporting data for each county separately.", "I wanted to be able to look at county-level data with regard to geographical location, as well as demographic and geographic data, such as total population and land area, and I wanted to join that data to MIT election data and to Google\u2019s COVID-19 Mobility Report so that I could look for relationships between mobility and the spread of the disease, as well as partisan relationships with mobility data.", "I chose the New York Times data for a few reasons:", "One of the things I wanted to be able to do was compare numbers from different data sets to see how much they agree, so my plan was (is) to work with all of them eventually. I decided to work first with what was easy and available.", "If you intend to work with the NYT data, you should go to the source on GitHub, carefully read, and fully understand the authors\u2019 description of the data set. But in brief:", "The NYT data set is very straightforward.", "There are three dimension fields, date, state_name and county, that identify the U.S. County that the data applies to. There is another field, county_fips_code, that gives a unique FIPS code that is a widely used standard value for identifying counties.", "The data contains data for all fifty states, plus U.S. territories.", "There are also rows where the county name is \u201cUnknown\u201d. This is used to record deaths that are reported at the state or territory level that the Times was unable to assign to a county. There is no FIPS code for these rows, and in my data set they are not populated with any enhancement data from other sources.", "There are only two data values for each row: deaths and confirmed_cases. These give the cumulative numbers reported by the county. The data set does not supply new cases or deaths, which must be calculated by comparing to the day before.", "It happened, rarely, and especially in the early days, that a county would revise its estimates of death or confirmed cases downward from one day to the next. This causes the \u201cnew cases\u201d for a day to be negative. In my analyses, I generally filter out these anomalies or set the floor for new cases to 0. It\u2019s not a major issue if you are doing your analysis on daily cases. For comparing to other data sets that report things differently, it may require some remediation.", "The NYT data has a couple of geographic reporting exceptions that made for some of the most challenging and fun parts of this project, and gave me excellent learning opportunities to work with a lot of basic GIS operations and tools:", "FIPS codes are, technically, a deprecated federal standard for identifying counties, but are still widely used outside the government or in older data sources. Today, the Census Bureau uses a newer system, the GEOID, to identify counties and other types of places. Mappings from GEOID to FIPS codes are easy to find.", "There are two types of FIPS code: state and county.", "A state FIPS code is a two-digit number. Calfornia is 06. Texas is 48.", "A county FIPS code is a three-digit number, unique within the state. Many data sources concatenate these two codes to form a five-digit code that is unique in the nation. Travis County, in Texas, for instance, has a combined fips code of 48453, because it is in Texas (48) and has a county FIPS code of 453.", "In many web pages and data sources, this combined number is referred to as a \u201ccounty FIPS code\u201d, so you will have to check whether the value is a three-digit code with a separate state field, or a five-digit code. In addition, some sources will store these values as integers, others as strings. It is a good idea to write helper functions or have ready expressions for transforming between these representations of the same data.", "Every year, the Census Burea surveys about 3.5 million households every year. It collects information about ancestry, citizenship, educational attainment, income, language proficiency, migration, disability, employment, and housing characteristics, so it provides a very rich data source.", "Like all Census Bureau data, ACS survey data is divided into several successively smaller levels. Each state is divided into a number of counties (or county-like division, such as parishes). Counties are broken up into census tracts, which are divided into block groups, which are composed of the smallest division, blocks. A block is an arbitrary division, but in cities it often corresponds to an actual city block.", "For each block, the bureau records the actual number of whatever they are surveying (people, children, people of color, people within an age group, people within income ranges, males, females, etc.) They also record some aggregate values, such as the median income, median rent, et cetera, that cannot be directly computed.", "The structure of the data is important, because in order to address geographic exceptions in the NYT data, I will need to add some counties together to build a new county, and subtract parts from other counties in order to eliminate overlap.", "One other important thing to note is that because the ACS data is a survey, not a census, sampling error becomes a bigger factor at lower levels of the geographic hierarchy. When the error bars get too big, some fields are not included. The columns simply aren\u2019t there. You cannot, for instance, at the block group level, get breakdowns of men by ethnicity and age. In some counties in Kansas City, I had to set these values to NULL because they were not present.", "Census bureau divisions have two very important properties: they are disjoint, meaning they don\u2019t overlap, and they are comprehensive, meaning that all the land in a state is in one of the counties, all of the land in a county is in a census tract, and so on.", "Together, these properties mean that when you add up, say, the total population of all the blockgroups in the county, you get the total population of the county.", "Importantly for our purposes, this also means that if you take only some of the blockgroups in a county (ones that are part of a city), and you subtract their population from the total population for the county, then what is left is the population of all the parts of the county that are not in the selected blockgroups.", "Aggregating computed values (means, medians, and quartiles)", "With median values, it is a bit more complex. You can\u2019t subtract the median income of a city from the median income of a county to find the median income of the rest of the county: you\u2019d likely get a negative number!", "Likewise, the sum of the median values for blockgroups in a county (or counties in a state, etc.) does not give you the median value for the county.", "In these cases, in order to estimate aggregate values of medians, etc., I took the population-weighted mean of the median values. For example, I used SUM(median_income*total_pop)/SUM(total_pop) over New York, Kings, Queens, Bronx and Richmond counties in New York state to estimate the median income for \u201cNew York City\u201d as reported in the NYT data.", "Because incomes in the US follow are distributed so unevenly, this population-weighted mean is not as accurate as using a \u201cPareto distribution\u201d-based estimate, but they appear to be fairly close in most cases, based on what randos on the Internet say, and I had more interesting things to do than learn how to write such an estimation function. If anybody would like to do so, you are welcome to!", "BigQuery has public datasets that contain two attributes for counties and blockgroups that I wanted for my data: land area in square meters, and the geographic boundaries of the area. Each row contains a geo_id field, a county_fips_code field, and a state_fips_code field that identify the county or blockgroup, and are essential for mapping from the geo_id field in ACS data to the FIPS codes used by other data sets.", "The geographic data is in the form of polygons where each point is mapped to an exact latitude and longitude on a spheroid model of the Earth. Such data has several representations. By default, if you SELECT a geographic field, it will show you the WKT representation:", "Google has a demonstration tool, BigQueryGeoViz, that will render query result shapes on a map and allow you to color and shade them using other attributes you can specify. This tool is incredibly handy, if a little basic, and is the only GIS visualization tool I used while building my data set.", "I won\u2019t spend much time on GIS functionality in BigQuery. I suggest consulting the documentation and Getting Started guide. They were enough to\u2026get me started.", "However, I will briefly mention the functions that BigQuery provides that were essential in building this data set:", "New York is a fairly easy case. NYT reports on a county called \u201cNew York City\u201d that covers five actual New York counties \u2014 New York, Kings, Queens, Bronx, and Richmond.", "In order to fix this, I just need to aggregate the census data and the geometry data for these five counties.", "Fixing Kansas City is harder. The New York Times reports on the municipality of Kansas City, Missouri, as if it were a county, and does not report deaths and infections that occur there as occurring in the four counties (!) that make up up the municipality.", "The Kansas City metro area sprawls across two states:", "The Kansas side of Kansas City reports its deaths as part of the county it is in, so I only need to correct the Missouri side.", "Instead of just aggregating multiple real-world counties, I need to build an \u201cimaginary\u201d county that covers just the Missouri portion of Kansas City:", "Then I need to \u201csubtract out\u201d the portions of each county that are also part of Kansas City:", "When I\u2019m done, I\u2019ll have a set of five counties: four \u201creal\u201d counties that have Kansas City trimmed out, and a fifth county, \u201cKansas City\u201d.", "The Census bureau\u2019s data does not line up with city boundaries, because those boundaries change all the time. But it does have census tracts and block groups that we can use to do an approximate alignment.", "I obtained an outline for the Missiour part of Kansas City by taking the ST_INTERSECTION of the bigquery-public-data:utility_us.us_cities_area row for Kansas City and the state of Missouri from bigquery-public-data:utility_us.us_states_area", "It\u2019s difficult to completely automatically find a set of blockgroups that approximate the area of Kansas City. If I use ST_INTERSECT between blockgroups I get a large number of blockgroups that are outside the city:", "On the other hand, if I use ST_COVERS, I get an undercount:", "In order to get a better approximation, I started with the ST_INTERSECT set in BigQueryGeoViz; I then clicked on each blockgroup I wanted to remove, and pasted it into an exclude list in the query. It took a little bit, but the end result was pretty close to what I was looking for:", "The nice thing about this method is that it\u2019s easy to reload the query and check my work as I go.", "Once I found a set of blockgroups that comprised my virtual \u201ccounty\u201d of Kansas City, Missouri, I estimated the ACS data using the arithmetic method above. I create a GIS boundary for it by calling ST_UNION_AGG to put all the blockgroup shapes together.", "Once I have a set of blockgroups that approximate Kansas City, I use it to adjust the four counties that make it up by subtracting out the portions that are also part of Kansas City.", "To do so, I first join the ACS blockgroup data to Census Bureau data for blockgroups, which contains the county FIPS code for the county. I group the blockgroups by FIPS code and then aggregate them as specified above. This gives me one row for each county, where I have the total population for all the blockgroups in that county. I use ST_UNION_AGG to compute the shapes for these blockgroup aggregates.", "I then use the techniques detailed above to subtract out the Kansas City portions of the county from the values for the county as a whole, and I am basically done!", "Now that I have synthesized the county data I need, I need join them to the NYT data. Because the other counties are joined on FIPS code, and that field is blank for the synthetic counties, this was the natural choice.", "I want to avoid FIPS code conflicts between real counties and my synthetic counties. This is pretty easy: \u201creal\u201d fips codes are never more than five digits long. As long as the lower five digits of my synthetic FIPS code are \u20180\u2019, they could not possibly be confused with a real FIPS code, because \u201c00\u201d is not a valid state FIPS code, and \u201c000\u201d is not a valid county FIPS code.", "I can then fix up the blank FIPS codes for these counties by creating a view on top of the NYT data. Counties in the NYT data that have a county FIPS code use that code, but if it is blank, the the state is \u201cNew York\u201d and the county is \u201cNew York City\u201d, then the FIPS code is \u201c1000000\u201d, and so on.", "Each step in the construction and remediation of the data sets creates a new view that builds on top of the old views. Originally I was materializing tables for intermediate steps, but this unnecessarily consumes space and negatively impacts performance in an environment with a low number of queries and the low numbers of updates for the data. NYT data is updated daily, the ACS data does not change, and the county geographic data is updated once a year.", "Instead, I materialize one large reporting table daily, at the end of the process for use with tools like Google\u2019s Data Studio and BigQuery GeoViz. Mostly, I don\u2019t actually use this table, but more on that later.", "The NYT data, raw, includes only the cumulative deaths and cases reported by each county each day. The first thing I wanted to do was compute some basic deltas and acceleration rates:", "I first compute (1) and (2) using LAG OVER PARTITION, and then in a separate view divide these values to get the acceleration.", "I did these same steps (2\u20134) several times, time-shifted by a week, so that I have new cases 4 weeks back, and 3 bi-weekly values for case acceleration.", "At first, I was using this data set in Google\u2019s Data Studio, and in Tableau, to do basic data exploration and verify that I could see in the data what I expected to seek. That was useful as far as it went, and built my confidence in the data set, but ultimately those are tools that allow you to build visualizations quickly without learning to code.", "The thing is, though, that I already know how to code, and knowing how to code lets you save little bits of functionality and numeric processing and come back to them later and combine them in interesting ways. It also allows you to build much more complex visualizations.", "These days I\u2019m using BigQuery\u2019s iPython Magics to refresh this data set periodically into a Jupyter notebook. From there I use Pandas to derive new metrics and to transform data.", "I have been using Pandas built-in Matplotlib integration to do quick-and-dirty visualizations, and Plotly to create interactive Javascript plots.", "Using the GIS boundaries for the counties, I can create chloropleth maps in Plotly to show various metrics for counties geographically.", "I am not a big believer in geographic maps for this purpose. They are maps of land, and the virus attacks people. People are very unevenly distributed across the land in the U.S. \u2014 20% of the counties contain 80% of the people \u2014 and map charts often don\u2019t give a good sense of the problem.", "I was also gratified to see that my geometry for Kansas City and the surrounding area fairly closely matches chloropleth maps from the Times:", "I can also use ACS data to identify counties with higher percentages of people of color, who are at higher risk of death from the disease, as in this tree map of total cases from 5/1:", "So far, however, the big wins from joining in this data is from two fields: total_pop from the ACS, and area_land_meters from the GIS data. With the first you can get per-capita infection and death rates, and with both of them together you can get population density.", "I also have created mapping tables the can be used to join this data to Google\u2019s COVID-19 Mobility Report data, and to an MIT county-level data set for election data. Relating the NYT data to mobility data has so far not been very fruitful, but joining each separately to the county geography, election, and ACS data has given me a bunch of useful insights!", "I hope this has been helpful to someone out there. If so, or if you have a project to which I might usefully contribute, let me know!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a software craftsman and leader from Texas, now living in the Bay Area."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3c61e7d68422&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kellyjoyner.medium.com/?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": ""}, {"url": "https://kellyjoyner.medium.com/?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "Kelly Joyner"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F420b8c3ec73c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&user=Kelly+Joyner&userId=420b8c3ec73c&source=post_page-420b8c3ec73c----3c61e7d68422---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c61e7d68422&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c61e7d68422&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://storage.googleapis.com/covid.lusion.org/new_cases_x_cum_pop_by_density_surface.html", "anchor_text": "Interactive version"}, {"url": "http://towardsdatascience.com", "anchor_text": "Towards Data Science"}, {"url": "https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/2004.00756.pdf?fbclid=IwAR39ljXM6aSaAftwFZII2-UAJArQKLVYw8uYRW_hY5Th6ak0K6fOeruhuKI", "anchor_text": "built by a team of people"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset", "anchor_text": "checked in some files"}, {"url": "https://console.cloud.google.com/bigquery?project=covid-project-275201&page=project", "anchor_text": "publicly available"}, {"url": "https://covidtracking.com", "anchor_text": "COVID Tracking Project"}, {"url": "https://github.com/nytimes/covid-19-data", "anchor_text": "source"}, {"url": "https://en.wikipedia.org/wiki/FIPS_county_code", "anchor_text": "FIPS codes"}, {"url": "https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html", "anchor_text": "GEOID"}, {"url": "https://www.nrcs.usda.gov/wps/portal/nrcs/detail/?cid=nrcs143_013696", "anchor_text": "two-digit number"}, {"url": "https://www.dshs.texas.gov/chs/info/info_txco.shtm", "anchor_text": "three-digit number"}, {"url": "https://console.cloud.google.com/marketplace/details/united-states-census-bureau/us-geographic-boundaries?filter=solution-type:dataset&q=counties&id=20d75072-82af-4fd3-a235-7080e71bcc1b", "anchor_text": "public datasets"}, {"url": "https://cloud.google.com/bigquery/docs/gis-visualize", "anchor_text": "BigQueryGeoViz"}, {"url": "https://cloud.google.com/bigquery/docs/reference/standard-sql/geography_functions", "anchor_text": "documentation"}, {"url": "https://cloud.google.com/bigquery/docs/gis-getting-started", "anchor_text": "Getting Started"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/200_nyt_counties.sql", "anchor_text": "aggregate"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/130_nyt_kc_county_temp_1.sql", "anchor_text": "build"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/150_nyt_kc_mo_trimmed_counties.sql", "anchor_text": "subtract out"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/150_nyt_kc_mo_trimmed_counties.sql", "anchor_text": "trimmed out"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/140_nyt_kc_county.sql", "anchor_text": "Kansas City"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/010_county_area_acs.sql", "anchor_text": "first"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/100_nyt_kcmo_agg_bg_by_county.sql", "anchor_text": "aggregate"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/920_nyt_7_day_counts.sql", "anchor_text": "first"}, {"url": "https://cloud.google.com/bigquery/docs/reference/standard-sql/navigation_functions#lag", "anchor_text": "LAG"}, {"url": "https://github.com/delusionary/covid_bigquery_dataset/blob/master/930_nyt_acceleration.sql", "anchor_text": "acceleration"}, {"url": "https://storage.googleapis.com/covid.lusion.org/new_cases_sunburst_20200618.html", "anchor_text": "Interactive version"}, {"url": "https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html", "anchor_text": "New York Times"}, {"url": "https://medium.com/tag/bigquery?source=post_page-----3c61e7d68422---------------bigquery-----------------", "anchor_text": "Bigquery"}, {"url": "https://medium.com/tag/covid-19?source=post_page-----3c61e7d68422---------------covid_19-----------------", "anchor_text": "Covid-19"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----3c61e7d68422---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/gis?source=post_page-----3c61e7d68422---------------gis-----------------", "anchor_text": "GIS"}, {"url": "https://medium.com/tag/sql?source=post_page-----3c61e7d68422---------------sql-----------------", "anchor_text": "Sql"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c61e7d68422&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&user=Kelly+Joyner&userId=420b8c3ec73c&source=-----3c61e7d68422---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c61e7d68422&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&user=Kelly+Joyner&userId=420b8c3ec73c&source=-----3c61e7d68422---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c61e7d68422&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3c61e7d68422&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3c61e7d68422---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3c61e7d68422--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3c61e7d68422--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3c61e7d68422--------------------------------", "anchor_text": ""}, {"url": "https://kellyjoyner.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kellyjoyner.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kelly Joyner"}, {"url": "https://kellyjoyner.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "18 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F420b8c3ec73c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&user=Kelly+Joyner&userId=420b8c3ec73c&source=post_page-420b8c3ec73c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F420b8c3ec73c%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-an-enhanced-nyt-covid-19-data-set-3c61e7d68422&user=Kelly+Joyner&userId=420b8c3ec73c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}