{"url": "https://towardsdatascience.com/padding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781", "time": 1683001023.854493, "path": "towardsdatascience.com/padding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781/", "webpage": {"metadata": {"title": "Padding Word2Vec Embeddings with Simple Document Encodings | by Russell Jurney | Towards Data Science", "h1": "Padding Word2Vec Embeddings with Simple Document Encodings", "description": "In this post, we\u2019ll cover how to pad text sequences with three values that perform surprisingly well: the min/max and mean. These are a simple form of document encoding that characterize the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://data.stackexchange.com/stackoverflow/query/new", "anchor_text": "Stackoverflow questions", "paragraph_index": 1}, {"url": "https://archive.org/details/stackexchange", "anchor_text": "Stack Exchange Data Dump", "paragraph_index": 1}, {"url": "https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/", "anchor_text": "The Amazing Power of Word Vectors", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/1607.00570.pdf", "anchor_text": "Representation learning for very short texts using weighted word embedding aggregation", "paragraph_index": 4}, {"url": "https://stats.stackexchange.com/a/239071/35715", "anchor_text": "this Stack Overflow answer", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779", "anchor_text": "this post", "paragraph_index": 4}, {"url": "https://medium.com/u/551ba3f6b67d?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Will Badr", "paragraph_index": 4}, {"url": "https://keras.io/preprocessing/sequence/#pad_sequences", "anchor_text": "keras.preprocessing.sequence.pad_sequences", "paragraph_index": 8}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch", "paragraph_index": 8}, {"url": "https://radimrehurek.com/gensim/models/word2vec.html", "anchor_text": "models.Word2Vec", "paragraph_index": 9}, {"url": "https://medium.com/explore-artificial-intelligence/word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba", "anchor_text": "this post", "paragraph_index": 9}, {"url": "https://medium.com/u/ac3247b15c91?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Suvro Banerjee", "paragraph_index": 9}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "RandomForestClassifier", "paragraph_index": 11}, {"url": "http://linkedin.com/in/russelljurney", "anchor_text": "Russell Jurney", "paragraph_index": 13}, {"url": "http://datasyndrome.com", "anchor_text": "Data Syndrome", "paragraph_index": 13}, {"url": "http://datasyndrome.com/training", "anchor_text": "agile data science coaching", "paragraph_index": 13}], "all_paragraphs": ["In this post, we\u2019ll cover how to pad text sequences with three values that perform surprisingly well: the min/max and mean. These are a simple form of document encoding that characterize the approximate meaning of the entire document. They tend to perform better than imputing a single static value across all documents.", "This is part 1 of a series of posts where I will demonstrate techniques from weakly supervised learning using Stackoverflow questions from the Stack Exchange Data Dump as part of writing my forthcoming book Weakly Supervised Learning (O\u2019Reilly, 2020). These techniques include transfer learning, semi-supervised learning, distant supervision and weak supervision. In these posts I\u2019ll be demonstrating technical recipes, while the book will be a cohesive overview of the field by solving real-world problems.", "Most of you can skip ahead, but if you\u2019re new to deep learning and natural language processing, you need an understanding of text embeddings and sequence padding to move forward. In short, in this post, we\u2019re encoding words in documents according to the meaning of the words (this is what Word2Vec does) and making them all the same length so we can use linear algebra to process them. This post is about what value(s) to use to make short documents the same length as longer documents.", "Check out the post The Amazing Power of Word Vectors by Adrian Colyer, and then come back and start here.", "The performance of different methods of imputation when padding encoded documents is described in the paper Representation learning for very short texts using weighted word embedding aggregation which was [very helpfully] referenced from this Stack Overflow answer. For more on imputation in general, check out this post by Will Badr.", "One simple technique that seems to work reasonably well for short texts (e.g., a sentence or a tweet) is to compute the vector for each word in the document, and then aggregate them using the coordinate-wise mean, min, or max.", "The paper uses the mean, max and min/max as baselines and measures performance on a semantic similarity task compared to the author\u2019s algorithm.", "While not state of the art at the time, min/max/mean are easy to compute and can be an excellent baseline \u2014 which is why they were used for the book (although I ended up going with a simple Conv1D model as a baseline, which uses its own embedding).", "Note that padding with alternating min/max is something that keras.preprocessing.sequence.pad_sequences can\u2019t do, as it accepts only a single float/string as an argument for the pad value. Keras has many limitations like this one because its goal is simplicity and accessibility, not state of the art performance. I\u2018ve found that as I\u2019ve gotten deeper into deep learning and natural language processing, the limitations of keras have driven me towards keras internals, raw Tensorflow and PyTorch when I\u2019m refining models.", "We use Gensim\u2019s models.Word2Vec to encode our tokenized text. Nothing new here. First we check if the model is loaded and if not, we recreate and save it. Then as a sanity check, we test the embedding model out by predicting lookalikes in terms of semantic similarity for an example word. We apply the model to the documents one by one, token by token, creating a new list of numpy.arrays, one for each document. Note: if you\u2019re new to Word2Vec, check out this post by Suvro Banerjee.", "We will now compute a position-wise minimum, maximum and mean, concatenate the first two values, and use either min/max or mean to pad any documents with less than MAX_LENGTH words. We will simultaneously truncate any documents with more than MAX_LENGTH words. If the row has an odd number of values and the min/max padding extends the document past MAX_LENGTH, we chop off the extra value to make it even.", "Tada! Not a bad recipe for cooking up something simple :) I used this with scikit-learn\u2019s RandomForestClassifier to create a baseline model, but found that I needed something non-linear as a baseline.", "In the next post, we\u2019ll look at how I used CuPy and CUDA to speed up reshaping this encoded/padded data from a 3D vector to a long 2D vector for consumption by a random forest model.", "Russell Jurney is a machine learning and visualization consultant at Data Syndrome where he specializes in weakly supervised learning (doing more with less data), end-to-end machine learning product development, data labeling, agile data science coaching and predictive lead generation.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am obsessed with knowledge graphs, networks, motifs, graphlets and GNNs. Founder of Graphlet AI: Knowledge Graph Factory"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faa27e1b1c781&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rjurney?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rjurney?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Russell Jurney"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b00541c45c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&user=Russell+Jurney&userId=6b00541c45c8&source=post_page-6b00541c45c8----aa27e1b1c781---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faa27e1b1c781&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faa27e1b1c781&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://data.stackexchange.com/stackoverflow/query/new", "anchor_text": "Stackoverflow questions"}, {"url": "https://archive.org/details/stackexchange", "anchor_text": "Stack Exchange Data Dump"}, {"url": "https://www.mathworks.com/help/matlab/ref/mean.html", "anchor_text": "Mathworks Documentation"}, {"url": "https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/", "anchor_text": "The Amazing Power of Word Vectors"}, {"url": "https://arxiv.org/pdf/1607.00570.pdf", "anchor_text": "Representation learning for very short texts using weighted word embedding aggregation"}, {"url": "https://stats.stackexchange.com/a/239071/35715", "anchor_text": "this Stack Overflow answer"}, {"url": "https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779", "anchor_text": "this post"}, {"url": "https://medium.com/u/551ba3f6b67d?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Will Badr"}, {"url": "https://stats.stackexchange.com/users/2921/d-w", "anchor_text": "D.W."}, {"url": "https://keras.io/preprocessing/sequence/#pad_sequences", "anchor_text": "keras.preprocessing.sequence.pad_sequences"}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch"}, {"url": "https://radimrehurek.com/gensim/models/word2vec.html", "anchor_text": "models.Word2Vec"}, {"url": "https://medium.com/explore-artificial-intelligence/word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba", "anchor_text": "this post"}, {"url": "https://medium.com/u/ac3247b15c91?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Suvro Banerjee"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "RandomForestClassifier"}, {"url": "http://linkedin.com/in/russelljurney", "anchor_text": "Russell Jurney"}, {"url": "http://datasyndrome.com", "anchor_text": "Data Syndrome"}, {"url": "http://datasyndrome.com/training", "anchor_text": "agile data science coaching"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----aa27e1b1c781---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----aa27e1b1c781---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/word2vec?source=post_page-----aa27e1b1c781---------------word2vec-----------------", "anchor_text": "Word2vec"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----aa27e1b1c781---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----aa27e1b1c781---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faa27e1b1c781&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&user=Russell+Jurney&userId=6b00541c45c8&source=-----aa27e1b1c781---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faa27e1b1c781&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&user=Russell+Jurney&userId=6b00541c45c8&source=-----aa27e1b1c781---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faa27e1b1c781&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Faa27e1b1c781&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----aa27e1b1c781---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----aa27e1b1c781--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rjurney?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rjurney?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Russell Jurney"}, {"url": "https://medium.com/@rjurney/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b00541c45c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&user=Russell+Jurney&userId=6b00541c45c8&source=post_page-6b00541c45c8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe91dbe50a5e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpadding-sequences-with-simple-min-max-mean-document-encodings-aa27e1b1c781&newsletterV3=6b00541c45c8&newsletterV3Id=e91dbe50a5e3&user=Russell+Jurney&userId=6b00541c45c8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}