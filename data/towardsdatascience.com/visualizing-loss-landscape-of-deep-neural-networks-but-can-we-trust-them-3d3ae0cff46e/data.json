{"url": "https://towardsdatascience.com/visualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e", "time": 1682996075.615684, "path": "towardsdatascience.com/visualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e/", "webpage": {"metadata": {"title": "Visualizing Loss Landscape of Deep Neural Networks\u2026..but can we Trust them? | by Jae Duk Seo | Towards Data Science", "h1": "Visualizing Loss Landscape of Deep Neural Networks\u2026..but can we Trust them?", "description": "Recently a method has been developed to visualize the loss landscape of deep neural networks. I personally believe that this is a huge breakthrough, however, I feel a bit questionable about the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "a method", "paragraph_index": 0}, {"url": "https://github.com/tomgoldstein/loss-landscape", "anchor_text": "link", "paragraph_index": 3}, {"url": "https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/", "anchor_text": "local response normalization.", "paragraph_index": 6}, {"url": "https://www.tensorflow.org/api_docs/python/tf/linalg/qr", "anchor_text": "QR decompositions", "paragraph_index": 12}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-3/blob/master/Loss%20LanScape/0%20create%20viz.ipynb", "anchor_text": "click here.", "paragraph_index": 19}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-3/tree/master/Loss%20LanScape", "anchor_text": "click here", "paragraph_index": 19}, {"url": "https://arxiv.org/abs/1703.04933", "anchor_text": "Sharp Minima Can Generalize For Deep Nets", "paragraph_index": 20}, {"url": "https://jaedukseo.me/", "anchor_text": "website", "paragraph_index": 21}], "all_paragraphs": ["Recently a method has been developed to visualize the loss landscape of deep neural networks. I personally believe that this is a huge breakthrough, however, I feel a bit questionable about the validity of the created visualization. And today I will investigate the author\u2019s visualization method as well as introduce a few other methods that I think are pretty cool.", "The whole process of creating loss landscape is pretty easy and straight forward.", "The only thing to note is how those random directions are created. Let's take a look at the author's method.", "Their method is called \u2018filter normalization\u2019 and it is pretty easy to understand. (Here is the link to the author's code). Basically, for tensors with 4 dimension such as (64,3,3,3), we are going to match the norm respect to the first dimension, so (64,1,1,1), between the weight\u2019s norm and random direction\u2019s norm. (In a more simplified term, we can understand this as matching the scale between the weights and the random directions).", "Above is a partial result when running the authors code. Now we can simplify the whole process by taking advantage of tensor operation. (which I will show later)", "Green Ball \u2192 Input Image (64,64,3)Blue Rectangle \u2192 Convolution + ReLU activationRed Rectangle \u2192 Soft Max output", "For this post, I have trained three nine-layered fully convolutional neural networks (as seen above) on the CIFAR 10 data set. Without any normalization, with Batch Normalization and with local response normalization.", "And from the above plots, we can see that the network with Batch Normalization has achieved the highest performance.", "From here now on I will call each network as following Normal: a network without any normalization layerBatch Norm: a network with Batch normalization layerLocal Norm: a network with Local Response normalization layer", "The above snippet shows how to do filter normalization using tensor operations.", "When we use the filter normalization method to visualize the loss landscape, we can see that each of the landscape does not look that different from one another. Only in the case when we show the landscape in log scale we can see that in fact, the landscape for local response normalization is much sharper.", "When we overlay all three plots together in their original scales, we can see how similar they look.", "The above method is just a simple modification of the author's method, we generate random directions from simple Gaussian distribution but via QR decompositions we orthogonalize the directions.", "When we orthogonalize the directions respect to different dimensions we can see right away how the created loss landscapes are different from one another. Compared to the author's method we can see a difference in the loss landscape between the three networks.", "This is mostly the same as Filter Orthogonalization the only difference being, performing ZCA whitening on a different dimension of the converged weights rather than generating from Gaussian distributions.", "Similar to Filter Orthogonalization we can see some differences between the generated visualizations.", "The final method is to perturb the weights in their first principle directions, just between different dimensions.", "And we can clearly see a difference between the generated loss landscapes.", "The only reason why I am making this post is to show that depending on the directions we use the created loss landscapes can change dramatically. Hence, we need to question the validity of generated loss landscapes, whether they truly reflect the characteristics of the trained network.", "To access the codes for creating the visualizations please click here. To access the codes for the whole blog post please click here.", "I don\u2019t want to make any bold claims, but it seems like different choices of directions produces different visualizations. The question still remains, which direction is the most \u2018correct\u2019 one? Can there be a correct one, and which one reveals the truth? Additionally, I want to mention the paper called \u201cSharp Minima Can Generalize For Deep Nets\u201d, which shows that deep neural networks that have converged to sharp minima can generalize well, and the theory does not hold up for network with ReLU activations. Like how that paper proofs that depending on our definition our observations can change, we should aim to create definitions that reflect the truth.", "There are still more researches to do, and I am looking forward to it. If you wish to see more post like this please visit my website.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Exploring the intersection of AI, deep learning, and art. Passionate about pushing the boundaries of multi-media production and beyond. #AIArt"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3d3ae0cff46e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jdseo?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jdseo?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "Jae Duk Seo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F70eb2d57a447&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&user=Jae+Duk+Seo&userId=70eb2d57a447&source=post_page-70eb2d57a447----3d3ae0cff46e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d3ae0cff46e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d3ae0cff46e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/illustrations/evening-sun-sunset-backlighting-55067/", "anchor_text": "website"}, {"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "a method"}, {"url": "https://github.com/tomgoldstein/loss-landscape", "anchor_text": "link"}, {"url": "https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/", "anchor_text": "local response normalization."}, {"url": "https://www.tensorflow.org/api_docs/python/tf/linalg/qr", "anchor_text": "QR decompositions"}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-3/blob/master/Loss%20LanScape/0%20create%20viz.ipynb", "anchor_text": "click here."}, {"url": "https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-3/tree/master/Loss%20LanScape", "anchor_text": "click here"}, {"url": "https://arxiv.org/abs/1703.04933", "anchor_text": "Sharp Minima Can Generalize For Deep Nets"}, {"url": "https://jaedukseo.me/", "anchor_text": "website"}, {"url": "https://arxiv.org/abs/1712.09913", "anchor_text": "https://arxiv.org/abs/1712.09913"}, {"url": "https://github.com/tomgoldstein/loss-landscape", "anchor_text": "https://github.com/tomgoldstein/loss-landscape"}, {"url": "https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/", "anchor_text": "https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3d3ae0cff46e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----3d3ae0cff46e---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----3d3ae0cff46e---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/visualization?source=post_page-----3d3ae0cff46e---------------visualization-----------------", "anchor_text": "Visualization"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----3d3ae0cff46e---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3d3ae0cff46e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&user=Jae+Duk+Seo&userId=70eb2d57a447&source=-----3d3ae0cff46e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3d3ae0cff46e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&user=Jae+Duk+Seo&userId=70eb2d57a447&source=-----3d3ae0cff46e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3d3ae0cff46e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3d3ae0cff46e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3d3ae0cff46e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3d3ae0cff46e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jdseo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jdseo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jae Duk Seo"}, {"url": "https://medium.com/@jdseo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "5.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F70eb2d57a447&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&user=Jae+Duk+Seo&userId=70eb2d57a447&source=post_page-70eb2d57a447--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd9ea20dd433a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-loss-landscape-of-deep-neural-networks-but-can-we-trust-them-3d3ae0cff46e&newsletterV3=70eb2d57a447&newsletterV3Id=d9ea20dd433a&user=Jae+Duk+Seo&userId=70eb2d57a447&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}