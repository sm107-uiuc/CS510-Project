{"url": "https://towardsdatascience.com/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d", "time": 1682994662.066586, "path": "towardsdatascience.com/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d/", "webpage": {"metadata": {"title": "An intuitive guide to Gaussian processes | by Oscar Knagg | Towards Data Science", "h1": "An intuitive guide to Gaussian processes", "description": "Gaussian processes are a powerful algorithm for both regression and classification. Their greatest practical advantage is that they can give a reliable estimate of their own uncertainty. By the end\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Uncertainty_principle", "anchor_text": "intrinsic", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Bayes%27_theorem", "anchor_text": "Bayes\u2019 rule", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Bayes'_theorem", "anchor_text": "Bayes\u2019 rule", "paragraph_index": 19}, {"url": "https://towardsdatascience.com/know-your-enemy-7f7c5038bdf3", "anchor_text": "adversarial", "paragraph_index": 28}, {"url": "https://towardsdatascience.com/know-your-enemy-the-fascinating-implications-of-adversarial-examples-5936bccb24af", "anchor_text": "examples", "paragraph_index": 28}, {"url": "https://www.cs.toronto.edu/~duvenaud/cookbook/", "anchor_text": "kernel", "paragraph_index": 30}, {"url": "http://proceedings.mlr.press/v5/titsias09a/titsias09a.pdf", "anchor_text": "sparse", "paragraph_index": 34}, {"url": "http://www.auai.org/uai2013/prints/papers/244.pdf", "anchor_text": "minibatch", "paragraph_index": 34}, {"url": "http://proceedings.mlr.press/v31/damianou13a.pdf", "anchor_text": "deep", "paragraph_index": 34}, {"url": "https://arxiv.org/abs/1709.01894", "anchor_text": "convolutional", "paragraph_index": 34}], "all_paragraphs": ["Gaussian processes are a powerful algorithm for both regression and classification. Their greatest practical advantage is that they can give a reliable estimate of their own uncertainty. By the end of this maths-free, high-level post I aim to have given you an intuitive idea for what a Gaussian process is and what makes them unique among other algorithms.", "Machine learning is linear regression on steroids.", "Machine learning is using data we have (known as training data) to learn a function that we can use to make predictions about data we don\u2019t have yet. The simplest example of this is linear regression, where we learn the slope and intercept of a line so we can predict the vertical position of points from their horizontal position. This is shown below, the training data are the blue points and the learnt function is the red line.", "Machine learning is an extension of linear regression in a few ways. Firstly is that modern ML deals with much more complicated data, instead of learning a function to calculate a single number from another number like in linear regression we might be dealing with different inputs and outputs such as:", "Secondly, modern ML uses much more powerful methods for extracting patterns of which deep learning is only one of many. Gaussian processes are another of these methods and their primary distinction is their relation to uncertainty.", "Uncertainty can be represented as a set of possible outcomes and their respective likelihood \u2014called a probability distribution", "The world around us is filled with uncertainty \u2014 we do not know exactly how long our commute will take or precisely what the weather will be at noon tomorrow. Some uncertainty is due to our lack of knowledge is intrinsic to the world no matter how much knowledge we have. Since we are unable to completely remove uncertainty from the universe we best have a good way of dealing with it. Probability distributions are exactly that and it turns out that these are the key to understanding Gaussian processes.", "The most obvious example of a probability distribution is that of the outcome of rolling a fair 6-sided dice i.e. a one in six chance of any particular face.", "This is an example of a discrete probability distributions as there are a finite number of possible outcomes. In the discrete case a probability distribution is just a list of possible outcomes and the chance of them occurring. In many real world scenarios a continuous probability distribution is more appropriate as the outcome could be any real number and example of one is explored in the next section.", "Another key concept that will be useful later is sampling from a probability distribution. This means going from a set of possible outcomes to just one real outcome \u2014 rolling the dice in this example.", "Bayesian inference might be an intimidating phrase but it boils down to just a method for updating our beliefs about the world based on evidence that we observe. In Bayesian inference our beliefs about the world are typically represented as probability distributions and Bayes\u2019 rule tells us how to update these probability distributions.", "Bayesian statistics provides us the tools to update our beliefs (represented as probability distributions) based on new data", "Let\u2019s run through an illustrative example of Bayesian inference \u2014 we are going to adjust our beliefs about the height of Barack Obama based on some evidence.", "Let\u2019s consider that we\u2019ve never heard of Barack Obama (bear with me), or at least we have no idea what his height is. However we do know he\u2019s a male human being resident in the USA. Hence our belief about Obama\u2019s height before seeing any evidence (in Bayesian terms this is our prior belief) should just be the distribution of heights of American males.", "Now let\u2019s pretend that Wikipedia doesn\u2019t exist so we can\u2019t just look up Obama\u2019s height and instead observe some evidence in the form of a photo.", "Our updated belief (posterior in Bayesian terms) looks something like this.", "We can see that Obama is definitely taller than average, coming slightly above several other world leaders, however we can\u2019t be quite sure how tall exactly. The probability distribution shown still reflects the small chance that Obama is average height and everyone else in the photo is unusually short.", "Now that we know how to represent uncertainty over numeric values such as height or the outcome of a dice roll we are ready to learn what a Gaussian process is.", "A Gaussian process is a probability distribution over possible functions.", "Since Gaussian processes let us describe probability distributions over functions we can use Bayes\u2019 rule to update our distribution of functions by observing training data.", "To reinforce this intuition I\u2019ll run through an example of Bayesian inference with Gaussian processes which is exactly analogous to the example in the previous section. Instead of updating our belief about Obama\u2019s height based on photos we\u2019ll update our belief about an unknown function given some samples from that function.", "Our prior belief about the the unknown function is visualized below. On the right is the mean and standard deviation of our Gaussian process \u2014 we don\u2019t have any knowledge about the function so the best guess for our mean is in the middle of the real numbers i.e. 0.", "On the left each line is a sample from the distribution of functions and our lack of knowledge is reflected in the wide range of possible functions and diverse function shapes on display. Sampling from a Gaussian process is like rolling a dice but each time you get a different function, and there are an infinite number of possible functions that could result.", "Instead of observing some photos of Obama we will instead observe some outputs of the unknown function at various points. For Gaussian processes our evidence is the training data.", "Now that we\u2019ve seen some evidence let\u2019s use Bayes\u2019 rule to update our belief about the function to get the posterior Gaussian process AKA our updated belief about the function we\u2019re trying to fit.", "Similarly to the narrowed distribution of possible heights of Obama what you can see is a narrower distribution of functions. The updated Gaussian process is constrained to the possible functions that fit our training data \u2014the mean of our function intercepts all training points and so does every sampled function. We can also see that the standard deviation is higher away from our training data which reflects our lack of knowledge about these areas.", "Gaussian processes know what they don\u2019t know.", "This sounds simple but many, if not most ML methods don\u2019t share this. A key benefit is that the uncertainty of a fitted GP increases away from the training data \u2014 this is a direct consequence of GPs roots in probability and Bayesian inference.", "Above we can see the classification functions learned by different methods on a simple task of separating blue and red dots. Note that two commonly used and powerful methods maintain high certainty of their predictions far from the training data \u2014 this could be linked to the phenomenon of adversarial examples where powerful classifiers give very wrong predictions for strange reasons. This characteristic of Gaussian processes is particularly relevant for identity verification and security critical uses as you want to be completely certain your models output is for a good reason.", "Gaussian processes let you incorporate expert knowledge.", "When you\u2019re using a GP to model your problem you can shape your prior belief via the choice of kernel (a full explanation of these is beyond the scope of this post).", "This lets you shape your fitted function in many different ways. The observant among you may have been wondering how Gaussian processes are ever supposed to generalize beyond their training data given the uncertainty property discussed above. Well the answer is that the generalization properties of GPs rest almost entirely within the choice of kernel.", "Gaussian processes are a non-parametric method. Parametric approaches distill knowledge about the training data into a set of numbers. For linear regression this is just two numbers, the slope and the intercept, whereas other approaches like neural networks may have 10s of millions. This means that after they are trained the cost of making predictions is dependent only on the number of parameters.", "However as Gaussian processes are non-parametric (although kernel hyperparameters blur the picture) they need to take into account the whole training data each time they make a prediction. This means not only that the training data has to be kept at inference time but also means that the computational cost of predictions scales (cubically!) with the number of training samples.", "The world of Gaussian processes will remain exciting for the foreseeable as research is being done to bring their probabilistic benefits to problems currently dominated by deep learning \u2014 sparse and minibatch Gaussian processes increase their scalability to large datasets while deep and convolutional Gaussian processes put high-dimensional and image data within reach. Watch this space.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I like to build novel things"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fec2f0b45c71d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@oknagg?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@oknagg?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "Oscar Knagg"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc510ccc9027c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&user=Oscar+Knagg&userId=c510ccc9027c&source=post_page-c510ccc9027c----ec2f0b45c71d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fec2f0b45c71d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fec2f0b45c71d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques", "anchor_text": "price of a house"}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "content of an image"}, {"url": "https://deepmind.com/blog/alphazero-shedding-new-light-grand-games-chess-shogi-and-go/", "anchor_text": "best move"}, {"url": "https://arxiv.org/abs/1609.04802", "anchor_text": "higher resolution image"}, {"url": "https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf", "anchor_text": "AlphaGo paper,"}, {"url": "https://arxiv.org/pdf/1609.04802.pdf", "anchor_text": "Ledig et al"}, {"url": "https://en.wikipedia.org/wiki/ImageNet", "anchor_text": "ImageNet"}, {"url": "https://www.kaggle.com/c/zillow-prize-1", "anchor_text": "Zillow house price prediction competition"}, {"url": "https://en.wikipedia.org/wiki/Uncertainty_principle", "anchor_text": "intrinsic"}, {"url": "https://en.wikipedia.org/wiki/Bayes%27_theorem", "anchor_text": "Bayes\u2019 rule"}, {"url": "https://en.wikipedia.org/wiki/Bayes'_theorem", "anchor_text": "Bayes\u2019 rule"}, {"url": "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html", "anchor_text": "Classifier comparison"}, {"url": "https://towardsdatascience.com/know-your-enemy-7f7c5038bdf3", "anchor_text": "adversarial"}, {"url": "https://towardsdatascience.com/know-your-enemy-the-fascinating-implications-of-adversarial-examples-5936bccb24af", "anchor_text": "examples"}, {"url": "https://www.cs.toronto.edu/~duvenaud/cookbook/", "anchor_text": "kernel"}, {"url": "http://proceedings.mlr.press/v5/titsias09a/titsias09a.pdf", "anchor_text": "sparse"}, {"url": "http://www.auai.org/uai2013/prints/papers/244.pdf", "anchor_text": "minibatch"}, {"url": "http://proceedings.mlr.press/v31/damianou13a.pdf", "anchor_text": "deep"}, {"url": "https://arxiv.org/abs/1709.01894", "anchor_text": "convolutional"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ec2f0b45c71d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/bayesian-statistics?source=post_page-----ec2f0b45c71d---------------bayesian_statistics-----------------", "anchor_text": "Bayesian Statistics"}, {"url": "https://medium.com/tag/gaussian-process?source=post_page-----ec2f0b45c71d---------------gaussian_process-----------------", "anchor_text": "Gaussian Process"}, {"url": "https://medium.com/tag/tutorial?source=post_page-----ec2f0b45c71d---------------tutorial-----------------", "anchor_text": "Tutorial"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----ec2f0b45c71d---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fec2f0b45c71d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&user=Oscar+Knagg&userId=c510ccc9027c&source=-----ec2f0b45c71d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fec2f0b45c71d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&user=Oscar+Knagg&userId=c510ccc9027c&source=-----ec2f0b45c71d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fec2f0b45c71d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fec2f0b45c71d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ec2f0b45c71d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ec2f0b45c71d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@oknagg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@oknagg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Oscar Knagg"}, {"url": "https://medium.com/@oknagg/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "654 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc510ccc9027c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&user=Oscar+Knagg&userId=c510ccc9027c&source=post_page-c510ccc9027c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3bb863a32894&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-gaussian-processes-ec2f0b45c71d&newsletterV3=c510ccc9027c&newsletterV3Id=3bb863a32894&user=Oscar+Knagg&userId=c510ccc9027c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}