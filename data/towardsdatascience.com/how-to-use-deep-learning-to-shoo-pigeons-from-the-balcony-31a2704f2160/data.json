{"url": "https://towardsdatascience.com/how-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160", "time": 1683012594.029643, "path": "towardsdatascience.com/how-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160/", "webpage": {"metadata": {"title": "How to use Deep Learning to shoo pigeons from the balcony | by Tatiana Sennikova | Towards Data Science", "h1": "How to use Deep Learning to shoo pigeons from the balcony", "description": "Deep Learning with Keras package. Image classification running on a Raspberry Pi. Home automation project with Artificial Intelligence."}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@tatianasennikova/how-artificial-intelligence-helped-me-to-win-the-war-against-the-pigeons-9458293983a1", "anchor_text": "Part 1", "paragraph_index": 0}, {"url": "https://medium.com/@tatianasennikova/how-to-set-up-data-collection-for-the-pigeon-avoidance-system-eba572fe6dc9", "anchor_text": "Part 2", "paragraph_index": 0}, {"url": "https://keras.io/api/applications/resnet/", "anchor_text": "ResNet50", "paragraph_index": 5}, {"url": "https://keras.io/api/applications/vgg/", "anchor_text": "VGG19", "paragraph_index": 5}, {"url": "https://qengineering.eu/install-tensorflow-2.2.0-on-raspberry-pi-4.html", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://www.linkedin.com/in/tatiana-sennikova-7b864140/", "anchor_text": "LinkedIn", "paragraph_index": 29}], "all_paragraphs": ["Disclaimer: You are reading Part 3 which is about how to train a Pigeon Recognition Model. Part 1 provides an architectural overview, and Part 2 describes the technical setup.", "In this part, I provide details on the process of training the Pigeon Classification Model. This article consists of four sections:", "In the previous part, I set up a Raspberry Pi on the balcony and started collecting images. In the meantime, I was labeling images with Pigeon Tinder, a self-made web app that helps me to sort images into the designated class folders: \u201cpigeon\u201d, \u201chuman\u201d, and \u201cnothing\u201d. Obviously, I am getting plenty of pictures without pigeons. That happens because the sensors are triggered by the motion of tree branches and light change. On a calm, sunny day, I am generally getting fewer images than on the days that are cloudy and windy. Pigeons land on my balcony every day and spend there 5\u201310 minutes in total. This leads to the highly imbalanced classes in my data set. I am dealing with it by augmenting pigeon and human classes. Sadly, I cannot apply a lot of different augmentation techniques, as it makes no sense to flip pigeons vertically or horizontally, because the layout of the balcony is constant and the pigeons rarely land on it upside down. The same applies to random cropping, as the pigeons can often be found on the borders of the image, therefore there is a high risk to crop them away. This leaves me with just a few augmentation techniques that play around with blur and sharpness. I use the following code for the data augmentation:", "It is crucial to augment only the training data. Another essential aspect is the time component. The first time as I trained the model, I generated the train and test dataset by randomly (without replacement) picking images from the bucket of labeled photos. I quickly got 100% accuracy on the validation and training data, which already looked suspicious, but when I put the model into production, it did not perform well. The classification looked awfully random. Then I decided to split the data by the timestamp and train the model on the first ten days of data, validate on the next three days, and test on the last two days. That produced a more robust model and prevented data leakage that happens if we split the data randomly. Overall I had 200 pigeon images in the training dataset. After applying data augmentation I increased it to 600. I also apply augmentation to the human pictures to get to 600, and the majority class of \u201cnothing\u201d contains 600 images without humans or pigeons. In the validation dataset, I have 50/50/50 images for each class and in the test 30/30/30. As we will see later, it is enough to have just 200 images for each class to train a very accurate model by leveraging the power of transfer learning.", "Since training of a neural network is a computationally expensive task, I do not perform it on the Raspberry. Currently, I am training models locally, but consider switching to one of the cloud solutions in the near future.", "Keras is my default choice for deep learning for several years now, mostly for LSTMs. However, after finishing this project I now think that PyTorch might be a better choice when it is about transfer learning for the following reason. Initially, I wanted to use transfer learning on the pre-trained ResNet50, as it has been constantly showing very good results on image classification tasks. However, Keras has a very wired implementation of BatchNormalisation layers in the ResNet architecture. During fine-tuning, the Batch Normalisation layers are frozen and use the mean and standard deviation of the original imagnet dataset on which it has been trained. However, the mean and standard deviation of imagenet is different from the new data sets which are used for fine-tuning and inference. There are multiple workarounds like unfreezing Batch Normalisation layers during fine-tuning and manipulating the lerning_phase flag during training and inference. However, I could not justify the usage of these workarounds just for the sake of applying a state of the art model. Therefore I went for VGG19, which provided me with 98% accuracy on the test dataset after just 30 epochs.", "Now let\u2019s look into the modeling part. First, we need to load the data. I am using the ImageDataGenerator class from Keras to progressively load images. It loads just enough images into memory for the current mini-batch. An additional benefit of the ImageDataGenerator class is that it can also automatically scale pixel values and does the image preprocessing such as normalization.", "I keep the training and testing data generators separately so that in the future I can perform the data augmentation only of the training data. Note that we apply the same preprocessing function to both datasets and it performs the data preprocessing that is expected by the pre-trained VGG19.", "Next, in order to progressively load the data, we need to create an iterator. This requires calling the flow_from_directory() method and specifying the dataset directory, such as the train, test, or validation directory. This method allows us to configure multiple parameters such as class_mode, target_size, etc.", "We need to set the steps per epoch parameter for the training and validation iterators in order to specify how many batches of images define a single epoch. It is usually calculated as the length of the dataset divided by the batch size, however, it could be set to a lower number to allow more frequent callbacks.", "Now let\u2019s define the model architecture. The sequence of steps for the transfer learning with Keras is:", "Note that I use a relatively small learning rate for this task. That is generally applicable to all transfer learning problems. As we just fine-tune the top layers, we should keep it lower to avoid gradient descent jumping.", "Let\u2019s go to the training loop. To avoid the model been overfitted, I apply earlier stoping and regularly save the model checkpoints while training.", "Running the specified model architecture on my pigeon recognition problem for 30 epochs gives me a forecast on the test dataset with 98% accuracy, meaning that I misclassify two images. On both of them, the pigeon stands in a very unfortunate perspective by facing the camera with its tail. Even I would not be able to recognize a pigeon in this fluffy blob.", "As mentioned earlier, I perform the training on a local machine and the inference on a Raspberry Pi. As I was using deep learning for the classification model, I need to install TensorFlow first. Apparently it was not as trivial as it used to be on my local machine. There are some issues with an atomic library on the Raspberry Pi. Therefore I needed to go through a number of steps that are very well described here. I will duplicate the main installation script here, just to avoid it being lost. But the full credit for it goes to Q-engineering who originally came out with the installation tutorial:", "After this, we just need to install Keras which usually goes smoothly.", "When everything is ready, we can start implementing the inferencing pipeline. We transfer the model that was trained locally to the Raspberry Pi for the inference. Then we load it for future use.", "It takes around 2 minutes on the Raspberry to load the model, so we are doing it only once after starting the Main Pipeline. Then we need to read the image that was taken after a motion was detected.", "After that, we provide it to the prediction method. Note that we apply the preprocess_input method from tensorflow.keras.applications.vgg19 that preprocess images in the same way as it was done during training.", "Finally, we provide the predicted class to the Main Pipeline and rename the original image by adding the class name at the end. The renaming part is necessary for future evaluation.", "Now when we have our model running on the Raspberry, we can check its performance in terms of speed and accuracy. As I mentioned earlier, it takes 2 minutes to load the model, 0.2 seconds to load the saved image, and another 2 seconds to classify the image. That is fast enough to scare the pigeon away. However, the problem that I started facing after just a few days of the model been running in the production environment is a data drift. Reality is always more complex than a staged experiment. Reality is wild and things that have never happen before can suddenly happen. We can not foresee it, we just need to be skeptical about our laboratory achieved performance and be flexible enough to adjust to the changing environment. What I am talking about is the change in the pigeons' behavior. They started building a nest on the tree in front of my balcony. And why exactly is it a problem? Because they started appearing on my balcony with sticks in their beaks. That is something the model has not been ready to handle, as it has never seen a pigeon carrying a stick. Therefore it decided that it is not a pigeon.", "The next days, pigeons with sticks were frequent guests on my balcony, which allowed me to collect new data. I retrained the model and was already celebrating success, watching how the pigeons fly away from my balcony after just three seconds after landing. However, my celebration was too early. One day I decided to clean up the balcony from the sticks that pigeons were dropping when they were surprised by my Pigeon Avoidance System. Now I have been taken by surprise realizing that the system identified me as a pigeon, just because I am holding sticks in my hand.", "On the left photo, I am holding sticks in my hands and I am classified as a pigeon. On the right photo the same hands, but without sticks classified as a human.", "When we retrieve activations from the first layers of the neural network, we can observe in the right bottom corner a filter map activated in the spot with the hand and the sticks. This way we can build some intuition about how the classification decision has been taken.", "The next step that I took was to collect images of sticks, me holding the sticks, and pigeons with the sticks and without. Then I retrained the model on the new data. That gave me again around 98% accuracy on the test dataset and about the same on the production, but just for the next 5 days. After that, I had to retrain the model on newly collected data. That brings us to the main learning of this project:", "To develop robust Machine Learning products, data scientists should take end-to-end ownership. This implies not only training models in a jupyter notebook, but also production deployment and further support and development of the product.", "I have to say that after several circles of \u201c model backup \u2192 data collection \u2192 data labeling \u2192 model evaluation \u2192 model retraining \u2192 production deployment,\u201d the model started generalizing images much better. In the end, it learned the concept of a \u201cbird\u201d and the Pigeon Avoidance System started shooing away all sorts of birds from my balcony, not just the pigeons.", "Finally, that is how the system works in production:", "As we have seen, data drift is a severe problem for Machine Learning solutions running in production. Therefore I would like to automate the circle of model backup \u2192 data collection \u2192 data labeling \u2192 model evaluation \u2192 model training \u2192 production deployment. For that, I am planning to use a cloud solution. That might be the topic of a future article.", "Stay updated and feel free to reach me via LinkedIn if you have any questions about this project.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Solutions Engineer at Databricks | all views are my own"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F31a2704f2160&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----31a2704f2160--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----31a2704f2160--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tatianasennikova.medium.com/?source=post_page-----31a2704f2160--------------------------------", "anchor_text": ""}, {"url": "https://tatianasennikova.medium.com/?source=post_page-----31a2704f2160--------------------------------", "anchor_text": "Tatiana Sennikova"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3c2625b643a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&user=Tatiana+Sennikova&userId=3c2625b643a&source=post_page-3c2625b643a----31a2704f2160---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F31a2704f2160&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F31a2704f2160&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/@tatianasennikova/how-artificial-intelligence-helped-me-to-win-the-war-against-the-pigeons-9458293983a1", "anchor_text": "Part 1"}, {"url": "https://medium.com/@tatianasennikova/how-to-set-up-data-collection-for-the-pigeon-avoidance-system-eba572fe6dc9", "anchor_text": "Part 2"}, {"url": "https://keras.io/api/applications/resnet/", "anchor_text": "ResNet50"}, {"url": "https://keras.io/api/applications/vgg/", "anchor_text": "VGG19"}, {"url": "https://qengineering.eu/install-tensorflow-2.2.0-on-raspberry-pi-4.html", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/tatiana-sennikova-7b864140/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/data-science?source=post_page-----31a2704f2160---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----31a2704f2160---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----31a2704f2160---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/raspberry-pi?source=post_page-----31a2704f2160---------------raspberry_pi-----------------", "anchor_text": "Raspberry Pi"}, {"url": "https://medium.com/tag/keras?source=post_page-----31a2704f2160---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F31a2704f2160&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&user=Tatiana+Sennikova&userId=3c2625b643a&source=-----31a2704f2160---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F31a2704f2160&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&user=Tatiana+Sennikova&userId=3c2625b643a&source=-----31a2704f2160---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F31a2704f2160&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----31a2704f2160--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F31a2704f2160&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----31a2704f2160---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----31a2704f2160--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----31a2704f2160--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----31a2704f2160--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----31a2704f2160--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----31a2704f2160--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----31a2704f2160--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----31a2704f2160--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----31a2704f2160--------------------------------", "anchor_text": ""}, {"url": "https://tatianasennikova.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tatianasennikova.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tatiana Sennikova"}, {"url": "https://tatianasennikova.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "193 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3c2625b643a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&user=Tatiana+Sennikova&userId=3c2625b643a&source=post_page-3c2625b643a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F58b331b01bd3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-deep-learning-to-shoo-pigeons-from-the-balcony-31a2704f2160&newsletterV3=3c2625b643a&newsletterV3Id=58b331b01bd3&user=Tatiana+Sennikova&userId=3c2625b643a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}