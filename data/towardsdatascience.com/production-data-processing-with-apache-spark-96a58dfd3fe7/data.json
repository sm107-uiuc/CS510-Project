{"url": "https://towardsdatascience.com/production-data-processing-with-apache-spark-96a58dfd3fe7", "time": 1682997355.379563, "path": "towardsdatascience.com/production-data-processing-with-apache-spark-96a58dfd3fe7/", "webpage": {"metadata": {"title": "Production Data Processing with PySpark on AWS EMR | by Brent Lemieux | Towards Data Science", "h1": "Production Data Processing with PySpark on AWS EMR", "description": "Data Pipelines with PySpark and AWS EMR is a multi-part series. This is part 2 of 2. Check out part 1 if you need a primer on AWS EMR. Apache Spark has been all the rage for large-scale data\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921", "anchor_text": "part 1", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921", "anchor_text": "creating an Amazon EMR cluster and connecting to it with a Jupyter notebook", "paragraph_index": 5}, {"url": "https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/", "anchor_text": "Cron", "paragraph_index": 6}, {"url": "https://airflow.apache.org/start.html", "anchor_text": "Apache Airflow", "paragraph_index": 6}, {"url": "https://aws.amazon.com/", "anchor_text": "Create your AWS account", "paragraph_index": 8}, {"url": "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html#install-tool-pip", "anchor_text": "Install", "paragraph_index": 8}, {"url": "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html#post-install-configure", "anchor_text": "configure", "paragraph_index": 8}, {"url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html", "anchor_text": "these instructions", "paragraph_index": 8}, {"url": "https://docs.aws.amazon.com/quickstarts/latest/s3backup/step-1-create-bucket.html", "anchor_text": "create an S3 bucket now", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/set-up-an-airflow-environment-on-aws-in-minutes-f934cf10ec54", "anchor_text": "standing up an Airflow environment on Amazon to schedule and monitor your pipelines", "paragraph_index": 19}, {"url": "https://www.linkedin.com/in/brent-lemieux/?source=post_page---------------------------", "anchor_text": "LinkedIn", "paragraph_index": 21}], "all_paragraphs": ["Data Pipelines with PySpark and AWS EMR is a multi-part series. This is part 2 of 2. Check out part 1 if you need a primer on AWS EMR.", "Apache Spark has been all the rage for large-scale data processing and analytics \u2014 for good reason. With Spark, organizations are able to extract a ton of value from their ever-growing piles of data. Because of this, data scientists and engineers who can build Spark applications are highly valued by businesses. This article will show you how to run your Spark application on an Amazon EMR cluster from the command line.", "Most of the PySpark tutorials out there use Jupyter notebooks to demonstrate Spark\u2019s data processing and machine learning functionality. The reason is simple. When working on a cluster, notebooks make it much easier to test syntax and debug Spark applications by giving you quick feedback and presenting error messages within the UI. Otherwise, you would have to dig through log files to figure out what went wrong \u2014 not ideal for learning.", "Once you\u2019re confident your code works, you may want to integrate your Spark application into your systems. Here, notebooks are much less useful. To run PySpark on a schedule, we need to move our code from a notebook to a Python script and submit that script to a cluster. In this tutorial, I\u2019ll show you how.", "Submitting Spark applications to a cluster from the command line can be intimidating at first. My goal is to demystify the process. This guide will show you how to use the AWS Command Line Interface to:", "When developing Spark applications for processing data or running machine learning models, my preference is to start by using a Jupyter notebook for the reasons stated above. Here\u2019s a guide to creating an Amazon EMR cluster and connecting to it with a Jupyter notebook.", "Once I know my code works, I may want to put the process in play as a scheduled job. I\u2019ll put the code in a script so I can put it on a schedule with Cron or Apache Airflow.", "IMPORTANT UPDATE: This guide uses AWS CLI version 1 \u2014 the commands below will need some adjustment to work with version 2.", "Create your AWS account if you haven\u2019t already. Install and configure the AWS Command Line Interface. To configure the AWS CLI, you\u2019ll need to add your credentials. You can create credentials by following these instructions. You\u2019ll also need to specify your default region. For this tutorial, we\u2019re using us-west-2. You can use whichever region you want. Just be sure to use the same region for all of your resources.", "For this example, we\u2019ll load Amazon book review data from S3, perform basic processing, and calculate some aggregates. We\u2019ll then write our aggregated data frame back to S3.", "The example is simple, but this is a common workflow for Spark.", "If you haven\u2019t already, create an S3 bucket now. Make sure the region you create the bucket in is the same region you use for the rest of this tutorial. I\u2019ll be using region \u201cUS West (Oregon)\u201d. Copy the file below. Be sure to edit the output_path in main() to use your S3 bucket. Then upload pyspark_job.py to your bucket.", "It\u2019s time to create our cluster and submit our application. Once our application finishes, we\u2019ll tell the cluster to terminate. Auto-terminate allows us to pay for the resources only when we need them.", "Depending on our use case, we may not want to terminate our cluster upon completion. For instance, if you have a web application that relies on Spark for a data processing task, you may want to have a dedicated cluster running at all times.", "Run the command below. Make sure you replace the bold italicized pieces with your own files. Details on --ec2-attributes and --bootstrap-actions, and all of the other arguments, are included below.", "Other aws emr create-cluster arguments explained:", "After you execute the aws emr create-cluster command, you should get a response:", "Sign-in to the AWS console and navigate to the EMR dashboard. Your cluster status should be \u201cStarting\u201d. It should take about ten minutes for your cluster to start up, bootstrap, and run your application (if you used my example code). Once the step is complete, you should see the output data in your S3 bucket.", "You now know how to create an Amazon EMR cluster and submit Spark applications to it. This workflow is a crucial component of building production data processing applications with Spark. I hope you\u2019re now feeling more confident working with all of these tools.", "Once you have your job running smoothly, consider standing up an Airflow environment on Amazon to schedule and monitor your pipelines.", "Thank you for reading! Please let me know if you liked the article or if you have any critiques. If you found this guide useful, be sure to follow me so you don\u2019t miss my future articles.", "If you need help with a data project or want to say hi, connect with me on LinkedIn. Cheers!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F96a58dfd3fe7&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://brentlemieux.medium.com/?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": ""}, {"url": "https://brentlemieux.medium.com/?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "Brent Lemieux"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F621935543&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&user=Brent+Lemieux&userId=621935543&source=post_page-621935543----96a58dfd3fe7---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96a58dfd3fe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96a58dfd3fe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921", "anchor_text": "Getting Started with PySpark on AWS EMR"}, {"url": "https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921", "anchor_text": "creating an Amazon EMR cluster and connecting to it with a Jupyter notebook"}, {"url": "https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/", "anchor_text": "Cron"}, {"url": "https://airflow.apache.org/start.html", "anchor_text": "Apache Airflow"}, {"url": "https://aws.amazon.com/", "anchor_text": "Create your AWS account"}, {"url": "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html#install-tool-pip", "anchor_text": "Install"}, {"url": "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html#post-install-configure", "anchor_text": "configure"}, {"url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html", "anchor_text": "these instructions"}, {"url": "https://docs.aws.amazon.com/quickstarts/latest/s3backup/step-1-create-bucket.html", "anchor_text": "create an S3 bucket now"}, {"url": "https://medium.com/@brent_64035/create-a-key-pair-file-for-aws-ec2-b71c6badb16", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/set-up-an-airflow-environment-on-aws-in-minutes-f934cf10ec54", "anchor_text": "standing up an Airflow environment on Amazon to schedule and monitor your pipelines"}, {"url": "https://www.linkedin.com/in/brent-lemieux/?source=post_page---------------------------", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/aws?source=post_page-----96a58dfd3fe7---------------aws-----------------", "anchor_text": "AWS"}, {"url": "https://medium.com/tag/spark?source=post_page-----96a58dfd3fe7---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/big-data?source=post_page-----96a58dfd3fe7---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/data-science?source=post_page-----96a58dfd3fe7---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data?source=post_page-----96a58dfd3fe7---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96a58dfd3fe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&user=Brent+Lemieux&userId=621935543&source=-----96a58dfd3fe7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96a58dfd3fe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&user=Brent+Lemieux&userId=621935543&source=-----96a58dfd3fe7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96a58dfd3fe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F96a58dfd3fe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----96a58dfd3fe7---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----96a58dfd3fe7--------------------------------", "anchor_text": ""}, {"url": "https://brentlemieux.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://brentlemieux.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Brent Lemieux"}, {"url": "https://brentlemieux.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "348 Followers"}, {"url": "https://www.linkedin.com/in/brent-lemieux/", "anchor_text": "https://www.linkedin.com/in/brent-lemieux/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F621935543&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&user=Brent+Lemieux&userId=621935543&source=post_page-621935543--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb7be1b858b8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproduction-data-processing-with-apache-spark-96a58dfd3fe7&newsletterV3=621935543&newsletterV3Id=b7be1b858b8c&user=Brent+Lemieux&userId=621935543&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}