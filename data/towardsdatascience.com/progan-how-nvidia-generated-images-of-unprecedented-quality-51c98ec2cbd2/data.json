{"url": "https://towardsdatascience.com/progan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2", "time": 1682994237.390104, "path": "towardsdatascience.com/progan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2/", "webpage": {"metadata": {"title": "ProGAN: How NVIDIA Generated Images of Unprecedented Quality | by Sarah Wolf | Towards Data Science", "h1": "ProGAN: How NVIDIA Generated Images of Unprecedented Quality", "description": "The people in the high resolution images above may look real, but they are actually not \u2014 they were synthesized by a ProGAN trained on millions of celebrity images. \u201cProGAN\u201d is the colloquial term\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1710.10196.pdf", "anchor_text": "Progressive Growing of GANs For Improved Quality, Stability, and and Variation", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1406.2661.pdf", "anchor_text": "now famous 2014 paper", "paragraph_index": 2}, {"url": "https://arxiv.org/pdf/1711.10337.pdf", "anchor_text": "Are GANs Created Equal? A Large Scale Study", "paragraph_index": 7}, {"url": "https://arxiv.org/pdf/1511.06434.pdf", "anchor_text": "Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1611.07004.pdf", "anchor_text": "some image-to-image translation techniques", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1502.01852.pdf", "anchor_text": "He initialization", "paragraph_index": 31}, {"url": "https://arxiv.org/pdf/1704.00028.pdf", "anchor_text": "WGAN-GP", "paragraph_index": 34}, {"url": "https://github.com/tkarras/progressive_growing_of_gans", "anchor_text": "official implementation", "paragraph_index": 36}, {"url": "https://www.youtube.com/watch?v=ReZiqCybQPA", "anchor_text": "talk", "paragraph_index": 36}], "all_paragraphs": ["The people in the high resolution images above may look real, but they are actually not \u2014 they were synthesized by a ProGAN trained on millions of celebrity images. \u201cProGAN\u201d is the colloquial term for a type of generative adversarial network that was pioneered at NVIDIA. It was published by Karras et al. last year in Progressive Growing of GANs For Improved Quality, Stability, and and Variation. In this post, we are going to walk through this paper to understand how this type of network works, how it can produce images like the ones above, and why this was a breakthrough.", "This post assumes you are familiar with deep learning for visual tasks in general, but not that you have extensive knowledge of GANs.", "Generative Adversarial Networks (GANs) have been around for a few years now. They were introduced in a now famous 2014 paper by Ian Goodfellow and colleagues at the University of Montreal, and have been a popular field of inquiry ever since.", "In short, GANs are a type of generative model that attempts to synthesize novel data that is indistinguishable from the training data. This is a form of unsupervised learning. It has two neural networks, locked in competition: a generator, that is fed a vector of random numbers and outputs synthesized data, and a discriminator, which is fed a piece of data and outputs a probability of it being from the training set (as opposed to synthesized). In other words, the generator creates \u201cfakes\u201d, and the discriminator attempts to distinguish these \u201cfake\u201d samples from the \u201creal\u201d ones.", "Both networks start out performing quite poorly at their tasks, but when training goes well, they improve in tandem until the generator is producing convincing fakes. The two networks are locked in a zero sum game, where the success of one corresponds to a failure of the other. Because of this, the value of the loss function at any given time does not tell us how well-trained the system is overall, only how well the generator or discriminator are doing relative to the other.", "The random code we feed into the generator is particularly important. It is a source of noise that enables the synthesized samples to be new and unique. It also tends to control the output in interesting ways. As we linearly interpolate around the vector space of the random code, the corresponding generated output also interpolates smoothly, sometimes even in ways that are intuitive for us humans.", "While this was all very exciting for researchers interested in new ways to learn representations of unlabeled data, using GANs in practice was often quite difficult. From the beginning, practitioners noticed that they were challenging to train. This is largely due to a problem called mode collapse. Mode collapse can occur when the discriminator essentially \u201cwins\u201d the game, and the training gradients for the generator become less and less useful. This can happen relatively quickly during training, and when it does, the generator starts outputting nearly the same sample every time. It stops getting better.", "Even Ian Goodfellow admits he got lucky when the hyperparameters he chose for his first GAN worked when he tried it on a hunch\u2014 they could have easily failed. In the years since, the research community has come up with many ways to make training more reliable. Certain families of architectures seem to work better than others, and several variations on the adversarial loss functions have been explored. Some of these seem more stable than others. I\u2019d recommend Are GANs Created Equal? A Large Scale Study by Lucic et al., an excellent recent review of the GAN landscape, if you\u2019d like to read more.", "However, none of these approaches have eliminated the issue entirely, and the theoretical reasons for mode collapse remain an area of active research.", "A major improvement in image generation occured in 2016, when Radford et al published Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks. They had found a family of GAN architectures that worked well for creating images, called \u201cDCGANs\u201d for short. DCGANs got rid of the pooling layers used in some CNNs, and relied on convolutions and transpose convolutions to change the representation size. Most layers were followed by a batch normalization and a leaky ReLU activation.", "Yet even DCGANs could only create images of a certain size. The higher the resolution of an image, the easier it becomes for the discriminator to tell the \u201creal\u201d images from the \u201cfakes\u201d. This makes mode collapse more likely. While synthesizing 32x32 or even 128x128 images became routine tutorial material, generating images at resolutions above 512x512 remained challenging in practice.", "I should note, some image-to-image translation techniques can handle high resolutions, but that is a different task, since those only learn to change surface-level features of an input image, and are not generating an entirely new image from scratch.", "As you might imagine, the difficulty of generating large images from scratch severely limited the usefulness of GANs for many kinds of practical applications.", "It was in this context that the team at NVIDIA presented the stunningly detailed 1024x1024 images at the top of this article, generated by their new ProGAN. Better yet, they knew of no reason their technique could not be used to synthesize even higher resolution images. It was even more efficient (in terms of training time) than previous GANs.", "Instead of attempting to train all layers of the generator and discriminator at once \u2014 as is normally done \u2014 the team gradually grew their GAN, one layer at a time, to handle progressively higher resolution versions of the images.", "To do this, they first artificially shrunk their training images to a very small starting resolution (only 4x4 pixels). They created a generator with just a few layers to synthesize images at this low resolution, and a corresponding discriminator of mirrored architecture. Because these networks were so small, they trained relatively quickly, and learned only the large-scale structures visible in the heavily blurred images.", "When the first layers completed training, they then add another layer to G and D, doubling the output resolution to 8x8. The trained weights in the earlier layers were kept, but not locked, and the new layer was faded in gradually to help stabilize the transition (more on that later). Training resumed until the GAN was once again synthesizing convincing images, this time at the new 8x8 resolution.", "In this way, they continued to add layers, double the resolution and train until the desired output size was reached.", "By increasing the resolution gradually, we are continuously asking the networks to learn a much simpler piece of the overall problem. The incremental learning process greatly stabilizes training. This, in combination with some training details we\u2019ll discuss below, reduces the chance of mode collapse.", "The low-to-high resolution trend also forces the progressively grown networks to focus on high level structure first (patterns discernible in the most blurred versions of the image), and fill in the details later. This improves the quality of the final image by reducing the likelihood that the network will get some high-level structure drastically wrong.", "Increasing the network size gradually is also more computationally efficient than the more traditional approach of initializing all the layers at once. Fewer layers are faster to train, as there are simply fewer parameters in them. Since all but the final set of training iterations are done with a subset of the eventual layers, this leads to some impressive efficiency gains. Karras et al. found that their ProGAN generally trained about 2\u20136 times faster than a corresponding traditional GAN, depending on the output resolution.", "In addition to gradually growing the networks, the authors of the NVIDIA paper made several other architectural changes to facilitate stable, efficient training.", "The generator architecture for a given resolution k follows a familiar high level pattern: each set of layers doubles the representation size, and halves the number of channels, until the output layer creates an image with just three channels corresponding to RGB. The discriminator does almost exactly the opposite, halving the representation size and doubling the number of channels with each set of layers. In both networks, the channel-doubling pattern is interrupted by capping the number of filters at a reasonable value, like 512, to prevent the total number of parameters from becoming too high.", "In this sense, ProGAN resembles earlier image-producing GANs. A similar structure was used by DCGAN.", "However, DCGAN used transpose convolutions to change the representation size. In constrast, ProGAN uses nearest neighbors for upscaling and average pooling for downscaling. These are simple operations with no learned parameters. They are then followed by two convolutional layers.", "The networks are progressively grown by adding a new set of layers to double the resolution each time training completes at the existing resolution. When new layers are added, the parameters in the previous layers remain trainable.", "To prevent shocks in the pre-existing lower layers from the sudden addition of a new top layer, the top layer is linearly \u201cfaded in\u201d. This fading in is controlled by a parameter \u03b1, which is linearly interpolated from 0 to 1 over the course of many training iterations. As you can see in the diagram above, the final generated image is the weighted sum of the last and second-to-last layers in the generator.", "Instead of using batch normalization, as is commonly done, the authors used pixel normalization. This \u201cpixelnorm\u201d layer has no trainable weights. It normalizes the feature vector in each pixel to unit length, and is applied after the convolutional layers in the generator. This is done to prevent signal magnitudes from spiraling out of control during training.", "The generator and discriminator are roughly mirror images of each other, and always grow in synchrony. The discriminator takes an input image x, which is either the output of the generator, or a training image scaled down to the current training resolution. As is typical of GAN discriminators, it attempts to distinguish the \u201creal\u201d training set images from the \u201cfake\u201d generated images. It outputs D(x), a value that captures the discriminator\u2019s confidence that the input image came from the training set.", "In general, GANs tend to produce samples with less variation than that found in the training set. One approach to combat this is to have the discriminator compute statistics across the batch, and use this information to help distinguish the \u201creal\u201d training data batches from the \u201cfake\u201d generated batches. This encourages the generator to produce more variety, such that statistics computed across a generated batch more closely resemble those from a training data batch.", "In ProGAN, this is done by inserting a \u201cminibatch standard deviation\u201d layer near the end of the discriminator. This layer has no trainable parameters. It computes the standard deviations of the feature map pixels across the batch, and appends them as an extra channel.", "The authors found that to ensure healthy competition between the generator and discriminator, it is essential that layers learn at a similar speed. To achieve this equalized learning rate, they scale the weights of a layer according to how many weights that layer has. They do this using the same formula as is used in He initialization, except they do it in every forward pass during training, rather than just at initialization.", "Due to this intervention, no fancy tricks are needed for weight initialization \u2014 simply initializing weights with a standard normal distribution works fine.", "The authors say that the choice of loss function is orthogonal to their contribution \u2014 meaning that none of the above improvements rely on a specific loss function. It would be reasonable to use any of the popular GAN loss functions that have come out in the last few years.", "However, if you are looking to follow the paper exactly, they used the improved Wasserstein loss function, also known as WGAN-GP. It is one of the fancier common loss functions, and has been shown to stabilize training and improve the odds of convergence.", "It is important to note that the WGAN-GP loss function expects D(x) and D(x\u2019) to be unbounded real-valued numbers. In other words, the output of the discriminator is not expected to be a value between 0 and 1. This is slightly different than the traditional GAN formulation, which views the output of the discriminator as a probability.", "If you\u2019ve made it this far, congrats! You now have a pretty good understanding of one of the most state-of-the-art image generation algorithms out there. If you would like to see more training details, there is an excellent official implementation that was released by the NVIDIA team. They also have a talk on the subject.", "Thanks for reading! I hope this was a useful overview. Please leave a comment if you have questions, corrections, or suggestions for improving this post."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F51c98ec2cbd2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://arxiv.org/pdf/1710.10196.pdf", "anchor_text": "paper"}, {"url": "https://medium.com/@sarah.wolf32?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Sarah Wolf"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d66e5a14198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&user=Sarah+Wolf&userId=1d66e5a14198&source=post_page-1d66e5a14198----51c98ec2cbd2---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F51c98ec2cbd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&user=Sarah+Wolf&userId=1d66e5a14198&source=-----51c98ec2cbd2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F51c98ec2cbd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&source=-----51c98ec2cbd2---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arxiv.org/pdf/1710.10196.pdf", "anchor_text": "Progressive Growing of GANs For Improved Quality, Stability, and and Variation"}, {"url": "https://arxiv.org/pdf/1406.2661.pdf", "anchor_text": "now famous 2014 paper"}, {"url": "https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf", "anchor_text": "Goodfellow paper"}, {"url": "https://arxiv.org/pdf/1711.10337.pdf", "anchor_text": "Are GANs Created Equal? A Large Scale Study"}, {"url": "https://arxiv.org/pdf/1511.06434.pdf", "anchor_text": "Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks"}, {"url": "https://arxiv.org/pdf/1611.07004.pdf", "anchor_text": "some image-to-image translation techniques"}, {"url": "https://arxiv.org/pdf/1502.01852.pdf", "anchor_text": "He initialization"}, {"url": "https://arxiv.org/pdf/1704.00028.pdf", "anchor_text": "WGAN-GP"}, {"url": "https://github.com/tkarras/progressive_growing_of_gans", "anchor_text": "official implementation"}, {"url": "https://www.youtube.com/watch?v=ReZiqCybQPA", "anchor_text": "talk"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----51c98ec2cbd2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nvidia?source=post_page-----51c98ec2cbd2---------------nvidia-----------------", "anchor_text": "Nvidia"}, {"url": "https://medium.com/tag/gans?source=post_page-----51c98ec2cbd2---------------gans-----------------", "anchor_text": "Gans"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----51c98ec2cbd2---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----51c98ec2cbd2---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F51c98ec2cbd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&user=Sarah+Wolf&userId=1d66e5a14198&source=-----51c98ec2cbd2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F51c98ec2cbd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&user=Sarah+Wolf&userId=1d66e5a14198&source=-----51c98ec2cbd2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F51c98ec2cbd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d66e5a14198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&user=Sarah+Wolf&userId=1d66e5a14198&source=post_page-1d66e5a14198----51c98ec2cbd2---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Faa826e4e4c27&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&newsletterV3=1d66e5a14198&newsletterV3Id=aa826e4e4c27&user=Sarah+Wolf&userId=1d66e5a14198&source=-----51c98ec2cbd2---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Written by Sarah Wolf"}, {"url": "https://medium.com/@sarah.wolf32/followers?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "434 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d66e5a14198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&user=Sarah+Wolf&userId=1d66e5a14198&source=post_page-1d66e5a14198----51c98ec2cbd2---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Faa826e4e4c27&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprogan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2&newsletterV3=1d66e5a14198&newsletterV3Id=aa826e4e4c27&user=Sarah+Wolf&userId=1d66e5a14198&source=-----51c98ec2cbd2---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d?source=author_recirc-----51c98ec2cbd2----0---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=author_recirc-----51c98ec2cbd2----0---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=author_recirc-----51c98ec2cbd2----0---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Sarah Wolf"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----51c98ec2cbd2----0---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d?source=author_recirc-----51c98ec2cbd2----0---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "CycleGAN: Learning to Translate Images (Without Paired Training Data)Image-to-image translation is the task of transforming an image from one domain (e.g., images of zebras), to another (e.g., images of\u2026"}, {"url": "https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d?source=author_recirc-----51c98ec2cbd2----0---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "7 min read\u00b7Nov 19, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5b4e93862c8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d&user=Sarah+Wolf&userId=1d66e5a14198&source=-----5b4e93862c8d----0-----------------clap_footer----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d?source=author_recirc-----51c98ec2cbd2----0---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b4e93862c8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d&source=-----51c98ec2cbd2----0-----------------bookmark_preview----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----51c98ec2cbd2----1---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----51c98ec2cbd2----1---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----51c98ec2cbd2----1---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----51c98ec2cbd2----1---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----51c98ec2cbd2----1---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----51c98ec2cbd2----1---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----51c98ec2cbd2----1---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----51c98ec2cbd2----1-----------------bookmark_preview----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----51c98ec2cbd2----2---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----51c98ec2cbd2----2---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----51c98ec2cbd2----2---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----51c98ec2cbd2----2---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----51c98ec2cbd2----2---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----51c98ec2cbd2----2---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----51c98ec2cbd2----2---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----51c98ec2cbd2----2-----------------bookmark_preview----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/coinmonks/8-things-to-do-differently-in-tensorflows-eager-execution-mode-47cf429aa3ad?source=author_recirc-----51c98ec2cbd2----3---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=author_recirc-----51c98ec2cbd2----3---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=author_recirc-----51c98ec2cbd2----3---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Sarah Wolf"}, {"url": "https://medium.com/coinmonks?source=author_recirc-----51c98ec2cbd2----3---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "Coinmonks"}, {"url": "https://medium.com/coinmonks/8-things-to-do-differently-in-tensorflows-eager-execution-mode-47cf429aa3ad?source=author_recirc-----51c98ec2cbd2----3---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "8 Things To Do Differently in Tensorflow\u2019s Eager Execution ModeUpdate: The Tensorflow 2.0 beta is out, and it uses Eager Execution by default. Much of the advice in this article is only relevant for 1.x\u2026"}, {"url": "https://medium.com/coinmonks/8-things-to-do-differently-in-tensorflows-eager-execution-mode-47cf429aa3ad?source=author_recirc-----51c98ec2cbd2----3---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": "4 min read\u00b7Aug 17, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcoinmonks%2F47cf429aa3ad&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoinmonks%2F8-things-to-do-differently-in-tensorflows-eager-execution-mode-47cf429aa3ad&user=Sarah+Wolf&userId=1d66e5a14198&source=-----47cf429aa3ad----3-----------------clap_footer----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/coinmonks/8-things-to-do-differently-in-tensorflows-eager-execution-mode-47cf429aa3ad?source=author_recirc-----51c98ec2cbd2----3---------------------9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F47cf429aa3ad&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoinmonks%2F8-things-to-do-differently-in-tensorflows-eager-execution-mode-47cf429aa3ad&source=-----51c98ec2cbd2----3-----------------bookmark_preview----9f7fd0a5_33f4_4ed9_a8c6_ef4d2da9d16d-------", "anchor_text": ""}, {"url": "https://medium.com/@sarah.wolf32?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "See all from Sarah Wolf"}, {"url": "https://towardsdatascience.com/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----51c98ec2cbd2----0-----------------bookmark_preview----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Youssef Hosni"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Getting Started With Stable DiffusionStable Diffusion is a text-to-image latent diffusion model created by researchers and engineers from CompVis, Stability AI, and LAION. It\u2019s\u2026"}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "\u00b712 min read\u00b7Nov 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Ff343639e4931&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fgetting-started-with-stable-diffusion-f343639e4931&user=Youssef+Hosni&userId=859af34925b7&source=-----f343639e4931----1-----------------clap_footer----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff343639e4931&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fgetting-started-with-stable-diffusion-f343639e4931&source=-----51c98ec2cbd2----1-----------------bookmark_preview----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----51c98ec2cbd2----0---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----51c98ec2cbd2----0-----------------bookmark_preview----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----51c98ec2cbd2----1---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----51c98ec2cbd2----1-----------------bookmark_preview----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----51c98ec2cbd2----2---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----51c98ec2cbd2----2---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----51c98ec2cbd2----2---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Josep Ferrer"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----51c98ec2cbd2----2---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----51c98ec2cbd2----2---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Stop doing this on ChatGPT and get ahead of the 99% of its usersUnleash the Power of AI Writing with Effective Prompts"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----51c98ec2cbd2----2---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "\u00b78 min read\u00b7Mar 31"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&user=Josep+Ferrer&userId=8213af8f3ccf&source=-----f3441bf7a25a----2-----------------clap_footer----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----51c98ec2cbd2----2---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "71"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&source=-----51c98ec2cbd2----2-----------------bookmark_preview----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----51c98ec2cbd2----3---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----51c98ec2cbd2----3---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----51c98ec2cbd2----3---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----51c98ec2cbd2----3---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----51c98ec2cbd2----3---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----3-----------------clap_footer----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----51c98ec2cbd2----3---------------------36a27040_6a20_44ef_908e_9c1f03cd0941-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----51c98ec2cbd2----3-----------------bookmark_preview----36a27040_6a20_44ef_908e_9c1f03cd0941-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----51c98ec2cbd2--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}