{"url": "https://towardsdatascience.com/addressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3", "time": 1683012193.076766, "path": "towardsdatascience.com/addressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3/", "webpage": {"metadata": {"title": "Addressing Racial Bias in AI: A Guide for Curious Minds | by Fahim Hassan | Towards Data Science", "h1": "Addressing Racial Bias in AI: A Guide for Curious Minds", "description": "It\u2019s no secret that humans are fallible and susceptible to biases, nor it is a secret that these biases can influence algorithms to behave in discriminatory ways. However, it is hard to get a sense\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html", "anchor_text": "being wrongfully jailed", "paragraph_index": 2}, {"url": "https://www.vox.com/recode/2020/6/10/21287194/amazon-microsoft-ibm-facial-recognition-moratorium-police", "anchor_text": "announcements", "paragraph_index": 3}, {"url": "https://www.goodreads.com/book/show/34762552-algorithms-of-oppression", "anchor_text": "Algorithms of Oppression", "paragraph_index": 6}, {"url": "https://safiyaunoble.com/", "anchor_text": "Safiya Umoja Noble", "paragraph_index": 6}, {"url": "https://weaponsofmathdestructionbook.com/", "anchor_text": "Weapons of Math Destruction", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Cathy_O%27Neil", "anchor_text": "Cathy O\u2019Neil", "paragraph_index": 7}, {"url": "https://mathbabe.org/", "anchor_text": "mathbabe.org", "paragraph_index": 7}, {"url": "https://www.youtube.com/watch?v=_2u_eHHzRto&t=96s", "anchor_text": "TED talk", "paragraph_index": 7}, {"url": "https://www.youtube.com/watch?v=heQzqX35c9A", "anchor_text": "this short video animation", "paragraph_index": 7}, {"url": "https://www.youtube.com/watch?v=TQHs8SA1qpk", "anchor_text": "lecture at Google", "paragraph_index": 7}, {"url": "https://www.goodreads.com/book/show/42527493-race-after-technology", "anchor_text": "Race After Technology: Abolitionist Tools for the New Jim Code", "paragraph_index": 9}, {"url": "https://www.ruhabenjamin.com/", "anchor_text": "Ruha Benjamin", "paragraph_index": 9}, {"url": "https://cyber.harvard.edu/", "anchor_text": "Harvard\u2019s Berkman Klein Center for Internet & Society", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Joy_Buolamwini", "anchor_text": "Joy Buolamwini", "paragraph_index": 10}, {"url": "https://www.youtube.com/watch?v=_sgji-Bladk", "anchor_text": "Compassion through Computation: Fighting Algorithmic Bias", "paragraph_index": 10}, {"url": "https://www.media.mit.edu/", "anchor_text": "MIT Media Lab", "paragraph_index": 10}, {"url": "https://www.ajlunited.org/", "anchor_text": "Algorithmic Justice League", "paragraph_index": 10}, {"url": "https://www.law.georgetown.edu/privacy-technology-center/", "anchor_text": "Center on Privacy & Technology at Georgetown Law", "paragraph_index": 10}, {"url": "https://www.safefacepledge.org/", "anchor_text": "The Safe Face Pledge", "paragraph_index": 10}, {"url": "https://www.youtube.com/watch?v=UG_X_7g63rY", "anchor_text": "How I\u2019m fighting bias in algorithms", "paragraph_index": 11}, {"url": "https://www.machine-ethics.net/podcast/25-miranda-mowbray/", "anchor_text": "Respecting data with Miranda Mowbray", "paragraph_index": 11}, {"url": "https://www.machine-ethics.net/podcast/23-derek-leben/", "anchor_text": "How to design a moral algorithm with Derek Leben", "paragraph_index": 11}, {"url": "https://podcasts.ox.ac.uk/discussion-ethical-challenges-posed-ai-involving-experts-fields-across-oxford-seminar-1", "anchor_text": "discussion on AI Ethics and legal regulation", "paragraph_index": 11}, {"url": "https://www.youtube.com/watch?v=MMqfOGA6TaQ", "anchor_text": "Dear Algorithmic Bias", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Dear_White_People_(TV_series)", "anchor_text": "Dear White People", "paragraph_index": 13}, {"url": "https://www.avriele.com/#overview", "anchor_text": "Avriel Epps-Darling", "paragraph_index": 13}, {"url": "https://www.youtube.com/watch?v=Xk3XGcvRNeA", "anchor_text": "Can Algorithms Reduce Inequality?", "paragraph_index": 14}, {"url": "https://www.cs.cornell.edu/~red/", "anchor_text": "Rediet Abebe", "paragraph_index": 14}, {"url": "https://nips.cc/Conferences/2018/Schedule?showEvent=10904#:~:text=The%20AI%20for%20Social%20Good,of%20solutions%20for%20social%20good.", "anchor_text": "AI for Social Good", "paragraph_index": 14}, {"url": "https://blackinai.github.io/", "anchor_text": "Black in AI", "paragraph_index": 14}, {"url": "https://ai.stanford.edu/~tgebru/", "anchor_text": "Timnit Gebru", "paragraph_index": 14}, {"url": "https://ainowinstitute.org/people/deborah-raji.html", "anchor_text": "Deborah Raj", "paragraph_index": 15}, {"url": "https://ainowinstitute.org/people/deborah-raji.html", "anchor_text": "a technology fellow", "paragraph_index": 15}, {"url": "https://ainowinstitute.org/", "anchor_text": "research institute AI Now", "paragraph_index": 15}, {"url": "https://www.nytimes.com/2019/01/24/technology/amazon-facial-technology-study.html", "anchor_text": "The New York Times article", "paragraph_index": 15}, {"url": "https://www.hrwfilmfestivalstream.org/film/coded-bias/", "anchor_text": "Coded Bias", "paragraph_index": 16}, {"url": "https://www.facebook.com/watch/live/?v=739250666844809&ref=watch_permalink", "anchor_text": "Q&A with the filmmaker Shalini Kantayya", "paragraph_index": 16}], "all_paragraphs": ["Co-authored by Fahim Hassan and Helen Gezahegn", "It\u2019s no secret that humans are fallible and susceptible to biases, nor it is a secret that these biases can influence algorithms to behave in discriminatory ways. However, it is hard to get a sense of how pervasiveness these biases are in the technology that we use in our everyday lives. In today\u2019s technology-driven world, we need to critically think about the impact of artificial intelligence on society and how it intersects gender, class and race.", "Speaking of race \u2014 just imagine being wrongfully arrested because of racial biases in algorithms. That\u2019s exactly what happened to Robert Julian-Borchak Williams \u2014 an African American in Michigan who was arrested from his home in front of his wife and young children. He didn\u2019t commit any crime but a facial recognition software used by the police suspected him for shoplifting. His experience of being wrongfully jailed epitomizes how flawed technology in the hands of law enforcement can magnify the discrimination against black communities.", "Biases in facial recognition technology is now trending all over the media. Recently, a number of tech companies (including giants like Amazon, IBM, Microsoft etc.) made announcements of ceasing the design and development of facial-recognition services or products and stop selling them to state and local police departments and law-enforcement agencies. Several researchers have pointed out the limitations and inaccuracies of these technologies and voiced concerns on how it can perpetuate discrimination and racial profiling. Robert Junior\u2019s case clearly shows that, while these decisions by technology giants can be considered as baby steps towards the right direction, these will clearly not solve the problem of racism of science that is deeply rooted in its history.", "As we realize the dangerous consequences of applying biased AI technology, we also realize our need to unlearn the racism we\u2019ve all been taught. It raises the question \u2014 how do we ensure the technology we create can unlearn it too?", "To answer the question, we need to understand how technology reinforces oppression and perpetuates racial stereotypes.", "A great primer on this topic is the book \u201cAlgorithms of Oppression\u201d by Safiya Umoja Noble \u2014 an Associate Professor of Information Studies at the University of California, Los Angeles(1). In plain language, Safiya explains the mathematical foundations behind the automated decisions and how human bias is embedded in key concepts such as \u201cbig data\u201d, \u201csearch engine\u201d and \u201calgorithm\u201d. By using a wide range of examples, she showed that even though the algorithmic decision making seems like a fair and objective process, in reality, it reflects the human biases, and racial stereotypes. The book encourages the readers to pay attention to the search engines and other information portals they use for finding information and ask critical questions \u201cIs this the right information? For whom?\u201d", "Another great read on the same topic is \u201cWeapons of Math Destruction\u201d by Cathy O\u2019Neil \u2014 a Harvard-trained mathematician and a data scientist who is famous for her blog mathbabe.org (2). Like Safiya, Cathy also uses several case studies to raise awareness about the social risks of using algorithms that influence policy decisions and amplify inequality and biasness. These cases are based on her own career in Wall Street and her extensive investigative research. For example \u2014 algorithms in hiring and firing people in the modern workplace, providing access to credit and many more. As a vocal advocate of algorithmic fairness, she has shared her experiences through lectures and presentations (check out her TED talk, this short video animation or her lecture at Google).", "So what can we do to address these biases in algorithms?", "First of all, we have to understand the design process of these biased, pervasive technologies and this is exactly what has been the key emphasis of the book Race After Technology: Abolitionist Tools for the New Jim Code by Ruha Benjamin (3). As an Associate Professor of African American Studies at Princeton University, Ruha studies and teaches the relationship between race, technology, and justice. She describes her job is to \u201cto create an environment in which they (students) can stretch themselves beyond the limits they may inadvertently set for their intellectual growth.\u201d This philosophy is instilled into her books and presentations as well. In addition to her academic articles, she speaks tirelessly about the collective effort and civic engagement that is required to fight this battle. A quick-and-easy way to get more familiar with her work is this video presentation hosted at Harvard\u2019s Berkman Klein Center for Internet & Society where she discusses more details about \u201ca range of discriminatory designs that encode inequity: by explicitly amplifying racial hierarchies, by ignoring but thereby replicating social divisions, or by aiming to fix racial bias but ultimately doing quite the opposite.\u201d", "Secondly, we can team up to overcome these flawed design approaches. The common thread that will knit us together is empathy which is central to Joy Buolamwini\u2019s spoken word performance at the World Economic Forum \u201cCompassion through Computation: Fighting Algorithmic Bias\u201d. Joy, a computer scientist at the MIT Media Lab, has been a champion of algorithmic fairness. She founded Algorithmic Justice League (ASJ) \u2014 an organization with interdisciplinary researchers dedicated to design more inclusive technology and to mitigate the harmful impact of AI on society. In collaboration with the Center on Privacy & Technology at Georgetown Law, ASJ developed The Safe Face Pledge that helps organizations to commit publicly on algorithmic fairness.", "If you are more interested in streaming, you can watch the Ted Talk by Joy Buolamwini \u201cHow I\u2019m fighting bias in algorithms\u201d. There are several podcasts worth eavesdropping; for example \u2014 Respecting data with Miranda Mowbray, How to design a moral algorithm with Derek Leben and the discussion on AI Ethics and legal regulation at the University of Oxford.", "Now if you made it this far along the list and hungry to learn more, check out the following -", "\u25cf Dear Algorithmic Bias, a discussion at Google with Logan Browning (that\u2019s right! She is from Netflix\u2019s Dear White People!) and Avriel Epps-Darling (a PhD student at Harvard studying the intersection between music, technology, youth of color and their gendered identities).", "\u25cf A related talk is \u201cCan Algorithms Reduce Inequality?\u201d by Rediet Abebe. Rediet is a computer science researcher and an Assistant Professor at University of California (Berkeley). She also organized the workshop on AI for Social Good in 2019 and co-founded Black in AI with Timnit Gebru. Timnit, a computer scientist at Google, is another inspiring figure in the area of algorithmic bias.", "\u25cf Another fierce critic of facial recognition technology is Deborah Raji \u2014 an engineering student from University of Toronto who is currently working as a technology fellow at the research institute AI Now. For a quick read, check out The New York Times article that covered her academic work.", "\u25cf Stay tuned for the documentary film \u201cCoded Bias\u201d. Inspired by the work of Joy Buolamwini, the film explores two key questions: \u201cwhat is the impact of Artificial Intelligence\u2019s increasing role in governing our liberties? And what are the consequences for people stuck in the crosshairs due to their race, color, and gender?\u201d For behind the scene stories, you can also watch the Q&A with the filmmaker Shalini Kantayya and other influential researchers mentioned above \u2014 Safiya Noble, Deborah Raji and Joy Buolamwini.", "Reading on these topics can help us understand our world better \u2014 a world that is getting shaped by the rapid innovation in technology. These issues impact our society at large, so we need to have discussions beyond the academic circle and among our friends and family members (let\u2019s spice up the dinner table conversation, shall we?). If it is for us, we, humans, need to be at the center of the design process \u2014 as simple as that. To make such participatory designs a reality, let\u2019s pay closer attention to the design of both new and existing technologies. Anytime we see the media hype on technology saving the world, let\u2019s talk about how it has been designed. For whom? To do what? And as we talk, let\u2019s add our own life experiences in relation to the books we are reading, podcasts that we are listening to, and the videos we are watching (or hopefully binge watching!).", "Fahim Hassan and Helen Gezahegn are BIPOC students at the University of Alberta, Canada. Fahim is a PhD student in public health with an interest in machine learning. He is also an advisory council member for Alberta Health Services. Helen is studying computing science; she is also the president of a student group called Ada\u2019s Team that\u2019s dedicated to promoting diversity in STEM with a special focus on technology at the University of Alberta.", "Authors are responsible for their views. Opinions do not reflect the view of the employer(s) or the university.", "Thanks to JuSong Baek for the illustration and Susie Moloney for her thoughtful review and feedback. We also appreciate the encouragement from the members of Black Graduate Students Association and Ada\u2019s Team at the University of Alberta, Canada.", "(1) Noble SU. Algorithms of oppression : how search engines reinforce racism. New York: New York University Press; 2018.", "(2) O\u2019Neil C. Weapons of math destruction : how big data increases inequality and threatens democracy. First ed. New York: Crown; 2016.", "(3) Benjamin R. Race after technology : abolitionist tools for the new Jim code. Cambridge, England ;Medford, Massachusetts: Polity Press; 2019.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Civil servant, Ph.D. student in Public Health. Passionate about citizen science & lifelong learning. Opinions = mine."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Febdf403696e3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@hassanfahim?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hassanfahim?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "Fahim Hassan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc325d6e8545c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&user=Fahim+Hassan&userId=c325d6e8545c&source=post_page-c325d6e8545c----ebdf403696e3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Febdf403696e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Febdf403696e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@thisisengineering?utm_source=medium&utm_medium=referral", "anchor_text": "ThisisEngineering RAEng"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html", "anchor_text": "being wrongfully jailed"}, {"url": "https://www.vox.com/recode/2020/6/10/21287194/amazon-microsoft-ibm-facial-recognition-moratorium-police", "anchor_text": "announcements"}, {"url": "https://www.goodreads.com/book/show/34762552-algorithms-of-oppression", "anchor_text": "Algorithms of Oppression"}, {"url": "https://safiyaunoble.com/", "anchor_text": "Safiya Umoja Noble"}, {"url": "https://weaponsofmathdestructionbook.com/", "anchor_text": "Weapons of Math Destruction"}, {"url": "https://en.wikipedia.org/wiki/Cathy_O%27Neil", "anchor_text": "Cathy O\u2019Neil"}, {"url": "https://mathbabe.org/", "anchor_text": "mathbabe.org"}, {"url": "https://www.youtube.com/watch?v=_2u_eHHzRto&t=96s", "anchor_text": "TED talk"}, {"url": "https://www.youtube.com/watch?v=heQzqX35c9A", "anchor_text": "this short video animation"}, {"url": "https://www.youtube.com/watch?v=TQHs8SA1qpk", "anchor_text": "lecture at Google"}, {"url": "https://www.goodreads.com/book/show/42527493-race-after-technology", "anchor_text": "Race After Technology: Abolitionist Tools for the New Jim Code"}, {"url": "https://www.ruhabenjamin.com/", "anchor_text": "Ruha Benjamin"}, {"url": "https://cyber.harvard.edu/", "anchor_text": "Harvard\u2019s Berkman Klein Center for Internet & Society"}, {"url": "https://en.wikipedia.org/wiki/Joy_Buolamwini", "anchor_text": "Joy Buolamwini"}, {"url": "https://www.youtube.com/watch?v=_sgji-Bladk", "anchor_text": "Compassion through Computation: Fighting Algorithmic Bias"}, {"url": "https://www.media.mit.edu/", "anchor_text": "MIT Media Lab"}, {"url": "https://www.ajlunited.org/", "anchor_text": "Algorithmic Justice League"}, {"url": "https://www.law.georgetown.edu/privacy-technology-center/", "anchor_text": "Center on Privacy & Technology at Georgetown Law"}, {"url": "https://www.safefacepledge.org/", "anchor_text": "The Safe Face Pledge"}, {"url": "https://www.youtube.com/watch?v=UG_X_7g63rY", "anchor_text": "How I\u2019m fighting bias in algorithms"}, {"url": "https://www.machine-ethics.net/podcast/25-miranda-mowbray/", "anchor_text": "Respecting data with Miranda Mowbray"}, {"url": "https://www.machine-ethics.net/podcast/23-derek-leben/", "anchor_text": "How to design a moral algorithm with Derek Leben"}, {"url": "https://podcasts.ox.ac.uk/discussion-ethical-challenges-posed-ai-involving-experts-fields-across-oxford-seminar-1", "anchor_text": "discussion on AI Ethics and legal regulation"}, {"url": "https://www.youtube.com/watch?v=MMqfOGA6TaQ", "anchor_text": "Dear Algorithmic Bias"}, {"url": "https://en.wikipedia.org/wiki/Dear_White_People_(TV_series)", "anchor_text": "Dear White People"}, {"url": "https://www.avriele.com/#overview", "anchor_text": "Avriel Epps-Darling"}, {"url": "https://www.youtube.com/watch?v=Xk3XGcvRNeA", "anchor_text": "Can Algorithms Reduce Inequality?"}, {"url": "https://www.cs.cornell.edu/~red/", "anchor_text": "Rediet Abebe"}, {"url": "https://nips.cc/Conferences/2018/Schedule?showEvent=10904#:~:text=The%20AI%20for%20Social%20Good,of%20solutions%20for%20social%20good.", "anchor_text": "AI for Social Good"}, {"url": "https://blackinai.github.io/", "anchor_text": "Black in AI"}, {"url": "https://ai.stanford.edu/~tgebru/", "anchor_text": "Timnit Gebru"}, {"url": "https://ainowinstitute.org/people/deborah-raji.html", "anchor_text": "Deborah Raj"}, {"url": "https://ainowinstitute.org/people/deborah-raji.html", "anchor_text": "a technology fellow"}, {"url": "https://ainowinstitute.org/", "anchor_text": "research institute AI Now"}, {"url": "https://www.nytimes.com/2019/01/24/technology/amazon-facial-technology-study.html", "anchor_text": "The New York Times article"}, {"url": "https://www.hrwfilmfestivalstream.org/film/coded-bias/", "anchor_text": "Coded Bias"}, {"url": "https://www.facebook.com/watch/live/?v=739250666844809&ref=watch_permalink", "anchor_text": "Q&A with the filmmaker Shalini Kantayya"}, {"url": "https://medium.com/tag/ai?source=post_page-----ebdf403696e3---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/facial-recognition?source=post_page-----ebdf403696e3---------------facial_recognition-----------------", "anchor_text": "Facial Recognition"}, {"url": "https://medium.com/tag/equity?source=post_page-----ebdf403696e3---------------equity-----------------", "anchor_text": "Equity"}, {"url": "https://medium.com/tag/ethics?source=post_page-----ebdf403696e3---------------ethics-----------------", "anchor_text": "Ethics"}, {"url": "https://medium.com/tag/society?source=post_page-----ebdf403696e3---------------society-----------------", "anchor_text": "Society"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Febdf403696e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&user=Fahim+Hassan&userId=c325d6e8545c&source=-----ebdf403696e3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Febdf403696e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&user=Fahim+Hassan&userId=c325d6e8545c&source=-----ebdf403696e3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Febdf403696e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Febdf403696e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ebdf403696e3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ebdf403696e3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ebdf403696e3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ebdf403696e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hassanfahim?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hassanfahim?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Fahim Hassan"}, {"url": "https://medium.com/@hassanfahim/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc325d6e8545c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&user=Fahim+Hassan&userId=c325d6e8545c&source=post_page-c325d6e8545c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fc325d6e8545c%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faddressing-racial-bias-in-ai-a-guide-for-curious-minds-ebdf403696e3&user=Fahim+Hassan&userId=c325d6e8545c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}