{"url": "https://towardsdatascience.com/regularized-greedy-forest-a17cd0c85f06", "time": 1683003786.895021, "path": "towardsdatascience.com/regularized-greedy-forest-a17cd0c85f06/", "webpage": {"metadata": {"title": "Regularized Greedy Forest. Modifications to the GBM which won many\u2026 | by Manu Joseph | Towards Data Science", "h1": "Regularized Greedy Forest", "description": "In 2011, Rie Johnson and Tong Zhang proposed a modification to the Gradient Boosting model. they called it Regularized Greedy Forest. When they came up with the modification, GBDTs were already, sort\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/RGF-team/rgf", "anchor_text": "Regularized Greedy Forest", "paragraph_index": 0}, {"url": "https://www.kaggle.com/c/benchmark-bond-trade-price-challenge", "anchor_text": "Bond Price challenge", "paragraph_index": 0}, {"url": "https://www.kaggle.com/c/bioresponse", "anchor_text": "Biological Response Prediction", "paragraph_index": 0}, {"url": "https://github.com/RGF-team/rgf/blob/master/RGF/rgf-guide.rst#432-parameters-to-control-training", "anchor_text": "Github Page", "paragraph_index": 28}], "all_paragraphs": ["In 2011, Rie Johnson and Tong Zhang proposed a modification to the Gradient Boosting model. they called it Regularized Greedy Forest. When they came up with the modification, GBDTs were already, sort of, ruling the tabular world. They tested the new modification of a wide variety of datasets, both synthetic and real world, and found that their modification achieves a better performance than standard GBDTs. They also entered a few Kaggle type competitions ( Bond Price challenge, Biological Response Prediction, and Heritage Provider Network Health Prize) and won them beating out other GBDT models in the running.", "The key modifications to the core GBDT algorithm they suggested are as follows:", "According to Friedman[1], one of the disadvantages of the standard Gradient Boosting is that the shrinkage/learning rate needs to be small to achieve convergence. In fact, he argued for infinitesimal step size. They suggested a modification which made the shrinkage parameter unnecessary.", "In standard Gradient Boosting, the algorithm does a partial corrective step in each iteration. The algorithm only optimizes the base learner in the current iteration and ignores all the previous ones. It creates the best regression tree for the current timestep and adds it to the ensemble. But they proposed that at every iteration, we update the whole forest( m base learners for iteration m) and readjust the scaling factor at each iteration.", "While the fully corrective greedy update means that the algorithm will converge faster, it also means that it overfitted faster. Therefore Structured Sparsity Regularization was adopted to combat this problem. The general idea of structured sparsity is that in a situation where a sparse solution is assumed, one can take advantage of the sparsity structure underlying the task. In this specific setting, it was implemented as a sparse search of decision rules in the forest structure.", "In addition to the Structured Sparsity Regularization, they also included an explicit Regularization term to the loss function.", "where l is the differentiable convex loss function and \u03a9 is the regularisation term penalising the complexity of the tree structure, and \u03d5 is the Forest structure.", "The paper introduces three types of Regularization options:", "where \u03d5 is the forest structure, \u03bb is the constant for controlling the strength of regularization, \u03b1\u1d65 are the weights of the node v (which is restricted to leaf nodes), L\u209c is the leaves of the tree T, and \ud835\udcaf is the set of all Trees in the forest.", "The minimum penalty regularization penalises the depth of the trees. This is a regularization that acts on all nodes and not just the leaves of the trees. This uses the principle that any leaf node can be written in terms of its ancestor nodes. The intuition behind the regularization is that it penalises depth, which is conceptually a complex decision rule.", "The exact formula is beyond our scope, but the key hyperparameters in there are l2 which governs the overall strength of regularization, and reg_depth which controls how severely you penalise the depth of a tree. Suggested values for l2 are 1, 0.1, 0.01 and reg_depth should be a value greater than 1", "This is very similar to Minimum-penalty regularization, but with an added condition that the weights of sibling nodes should sum to zero. The intuition behind the sum-to-zero constraint is that less redundant models are preferable and that the models are least redundant when branches at internal nodes lead to completely opposite actions, like adding \u2018x\u2019 to versus subtracting \u2018x\u2019 from the output value. So this penalises two things- depth of the tree and redundancy of the tree. There are no additional hyperparameters here.", "Note: An interesting tidbit to note here is that all the bechmarks in the paper and the competitions only used simple L2 regularization.", "The general concept is still similar to Gradient Boosting, but the key differences are in the tree updates in each iteration. And also the easy and convenient derivations or gradients to be mean or median does not work anymore because of the regularization term in the objective function.", "Let\u2019s look at the new algorithm, albeit at a high level.", "1.1 \u03d5 is the optimum forest that minimizes \u2112(\u03d5) among all the forests that can be obtained by applying one step of structure-changing operation to the current forest \u03d5", "1.2 Optimize the leaf weights in \u03d5 to minimize the loss \u2112(\u03d5)", "2. until some exit criteria is met", "3. Optimize the leaf weights in \u03d5 to minimize the loss \u2112(\u03d5)", "There is one key difference in the way the trees are built in the forest in Regularized Greedy Forest. In classical Gradient Boosting, at each stage a new tree is built, with a specific criteria of stopping, like depth or number of leaves. Once you pass a stage, you do not touch that tree or the weights associated with it. On the contrary, in RGF, at any m iteration, the option to update any of the previously created m-1 trees or starting a new tree is open. The exact update to the forest is determined by the action which minimizes the loss function.", "Let\u2019s look at an example to understand the fundamental difference in Tree Building between Gradient Boosting and Regularized Greedy Forest", "Standard Gradient Boosting builds successive trees and sum those up into an additive function which approximates the desired function.", "RGF takes a slightly different route. For each step change in the structure of the tree, it evaluates the possibility of growing a new leaf in an existing tree vs starting a new tree with the help of the loss function, and then takes the greedy approach of taking the route with least loss. So in the diagram above, we can choose to grow leaves in T1, T2, or T3, or we can start a new tree T4 depending on which one gives you the most reduction in loss.", "But practically, it is computationally challenging to do this as the possible splits to evaluate grows exponentially as we move deeper and deeper into the forest. So, there is a hyperparameter, n_tree_search, in the implementation which restricts the retrospective update of trees to those many latest trees only. The default value is set as 1 so that the update always looks at one previously created tree. In our example, this reduces the possibilities to growing leaves in T3 or growing a new tree T4.", "Conceptually, this becomes an additive function over leaves of the forest than an additive function of trees in a forest, and consequently, there is not max_depth parameter in RGF as the depth of the tree is automatically restrained by the incremental updates to the tree structure.", "The next step is the weights of the new leaf that was selected to be the best structural change. This is an optimization problem and can be solved using any of the multiple methods like Gradient Descent, or Newton-Raphson\u2019s method. Since the optimization that we are looking at is simpler, the paper uses a Newton\u2019s step, which is much more accurate than Gradient Descent, to get an approximately optimal weight for the new leaf. Refer to Appendix A, if you are interested in how and why we need a Newton\u2019s step to optimize such functions.", "With the base learner or the basis function fixed, we need to optimize the weights of all the leaves in the forest. This is again an optimization problem, and this is solved using Cordinate Descent, which iteratively go through each of the leaves and update the weights by a Newton Step with a small step size.", "Since the initial weights that is already set are approximately optimal, we do not need to re-optimize the weights every iteration. It would be computationally expensive if we do that. This is another hyperparameter in the implementation called opt_interval. Empirically, it was observed that unless opt_interval is an extreme value, the choice of opt_interval is not critical. For all the competitions they won, they had simply set the value as 100.", "Below is a list of key Hyperparameters that the authors of the paper suggest. It is almost directly taken from their Github Page, but adopted to the Python Wrapper.", "Youtube Channel 3Blue1Brown(which I recommend strongly if you want fundamental intuitions about Math), has a yet another brilliant video for explaining the Taylor Expansions/Approximations. Be sure to check out at least the first 6 minutes of the video.", "Taylor\u2019s approximation lets us approximate a function close to a point by using the derivatives of that function.", "Suppose we are taking a second order approximation and finding a local minima, we can do that by setting the derivative to zero", "Setting it to zero, we get:", "This (x-a) is the optimum step to minimize the function at that point. So, this minima is more like the step direction towards the minima than the actual minima.", "To optimize the non-differentiable function, we need to take multiple steps in the step direction until we are relatively satisfied with the loss, or technically until the loss is below our tolerance. This is called the Newton-Raphson method of optimization.", "Other Articles in The Gradient Boosters", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa17cd0c85f06&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@manujosephv?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@manujosephv?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "Manu Joseph"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8dcc7fb5ce5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&user=Manu+Joseph&userId=c8dcc7fb5ce5&source=post_page-c8dcc7fb5ce5----a17cd0c85f06---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa17cd0c85f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa17cd0c85f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://towardsdatascience.com/tagged/the-gradient-boosters", "anchor_text": "THE GRADIENT BOOSTERS"}, {"url": "https://unsplash.com/photos/-IZ2sgQKIhM", "anchor_text": "Unsplash"}, {"url": "https://github.com/RGF-team/rgf", "anchor_text": "Regularized Greedy Forest"}, {"url": "https://www.kaggle.com/c/benchmark-bond-trade-price-challenge", "anchor_text": "Bond Price challenge"}, {"url": "https://www.kaggle.com/c/bioresponse", "anchor_text": "Biological Response Prediction"}, {"url": "https://github.com/RGF-team/rgf/blob/master/RGF/rgf-guide.rst#432-parameters-to-control-training", "anchor_text": "Github Page"}, {"url": "https://towardsdatascience.com/the-good-old-gradient-boosting-f4614b0e62b0", "anchor_text": "The Good Old Gradient Boosting"}, {"url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34", "anchor_text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"}, {"url": "https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6809246", "anchor_text": "Issue: 5"}, {"url": "https://deep-and-shallow.com/2020/02/09/the-gradient-boosters-ii-regularized-greedy-forest/", "anchor_text": "http://deep-and-shallow.com"}, {"url": "https://medium.com/tag/the-gradient-boosters?source=post_page-----a17cd0c85f06---------------the_gradient_boosters-----------------", "anchor_text": "The Gradient Boosters"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a17cd0c85f06---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/gradient-boosting?source=post_page-----a17cd0c85f06---------------gradient_boosting-----------------", "anchor_text": "Gradient Boosting"}, {"url": "https://medium.com/tag/regularized-greedy-forest?source=post_page-----a17cd0c85f06---------------regularized_greedy_forest-----------------", "anchor_text": "Regularized Greedy Forest"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a17cd0c85f06---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa17cd0c85f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&user=Manu+Joseph&userId=c8dcc7fb5ce5&source=-----a17cd0c85f06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa17cd0c85f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&user=Manu+Joseph&userId=c8dcc7fb5ce5&source=-----a17cd0c85f06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa17cd0c85f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa17cd0c85f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a17cd0c85f06---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a17cd0c85f06--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@manujosephv?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@manujosephv?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Manu Joseph"}, {"url": "https://medium.com/@manujosephv/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "183 Followers"}, {"url": "https://www.linkedin.com/in/manujosephv/", "anchor_text": "https://www.linkedin.com/in/manujosephv/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8dcc7fb5ce5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&user=Manu+Joseph&userId=c8dcc7fb5ce5&source=post_page-c8dcc7fb5ce5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7cea8b947fdd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregularized-greedy-forest-a17cd0c85f06&newsletterV3=c8dcc7fb5ce5&newsletterV3Id=7cea8b947fdd&user=Manu+Joseph&userId=c8dcc7fb5ce5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}