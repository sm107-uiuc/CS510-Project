{"url": "https://towardsdatascience.com/support-vector-machines-explained-25a685e4d228", "time": 1683007875.483171, "path": "towardsdatascience.com/support-vector-machines-explained-25a685e4d228/", "webpage": {"metadata": {"title": "Support Vector Machines explained | by James Thorn | Towards Data Science", "h1": "Support Vector Machines explained", "description": "In this post we will unveil all the magic of what goes on in an SVM, cover a little bit of their history, and clarify when they should and should not be used. We will go through the theory and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://howtolearnmachinelearning.com/books/machine-learning-books/", "anchor_text": "How to Learn Machine Learning", "paragraph_index": 46}, {"url": "https://aigents.co/", "anchor_text": "AIgents.co \u2014 A career community for Data Scientists & Machine Learning Engineers", "paragraph_index": 46}], "all_paragraphs": ["In this post we will unveil all the magic of what goes on in an SVM, cover a little bit of their history, and clarify when they should and should not be used.", "We will go through the theory and intuition of SVMs, seeing the minimum amount of maths necessary to understand how everything works, without diving into the details.", "Support vector Machines or SVMs are a widely used family of Machine Learning models, that can solve many ML problems, like linear or non-linear classification, regression, or even outlier detection.", "Having said this, their best application comes when applied to the classification of small or medium-sized, complex datasets. Throughout this article, it will become clear why.", "To understand how SVMs work, it is best if we first explore Linear SVMs, hard, and soft margin classifications.", "Imagine we have the following set of data, with just two features (feature 1 and feature 2), representing two different classes (Class A and Class B).", "A normal linear classifier would attempt to draw a line that perfectly separates both classes of our data. However, as we can see from the following figure, there are many lines that can do this. Which one should we choose?", "The previous decision boundaries separate the training data with utter perfection, however, they come so close to the training instances (the red and purple dots with black circle around them), that they will probably generalise very badly on new data (the New samples on the figure).", "Support vector machine classifiers try to solve this problem by fitting a line to the model that tries to maximise the distance to the closest training instances (known as Support Vectors), so that the margin parallel to the decision boundary line is as wide as possible.", "Think of the decision boundary like the centre of a country road and the data as trees, with trees of different types at each side of the road. What SVMs try to do is to find widest road as possible that separates our two kinds of trees, so that we can safely drive through it while feeling secure. It does this by trying to maximise the margin.", "If we now consider the previous data set, fit a Linear Support Vector Classifier (Linear SVC) to it, and plot the decision boundary, with its margin, we get the following figure:", "In this type of SVC, no points are allowed to cross the margin: we are talking about a Hard Margin Classifier. When some points are allowed to cross the margin line, allowing us to fit a wider street, we are talking about a Soft Margin Classifier.", "It is interesting to note, that for this hard margin classifier, the fit only depends on the position of the support vectors: adding points to our training data that do not touch the street (but are on the correct side), will leave the decision boundary and the margin untouched.", "The boundary is fully defined or \u2018supported\u2019 by these key support vector points, giving them, and the algorithm their name. Hard margin classifiers, however, only work when the data is perfectly separable in a linear manner, and are also very sensitive to outliers.", "To solve this, we progress onto soft margin classifiers, which are more flexible models that allow some points to cross the margin, leading us to the compromise of how wide our street is, and how many margin violations there are (points that are inside the street or on wrong side of the decision boundary). The following figure shows a linear soft margin classifier.", "In most SVC implementations, we control this with a hyperparameter of the model (C in Scikit-Learn). A lower value of this parameter means we have a wider margin with more margin violations, resulting in a more flexible model that will generalise better. By reducing C we can regularise our model if we think it might be over-fitting.", "Increasing the value of C leads us towards a hard margin classifiers. The following figure shows this behaviour: as we decrease the value of C, the street becomes wider but we have more points that cross it.", "Most times, however, data sets are not linearly separable, and softening our margin doesn\u2019t quite do the trick.", "One way to make a non-linearly separable data set, into a separable one is to include additional features derived from the original ones, for example using polynomial features or similarity feature techniques, like Radial Basis Functions (RBF).", "The next figure shows how by transforming a data set with only 1 feature into a 2 feature data set using a 2nd degree polynomial, we are able to linearly separate the two existing classes.", "The issue here is that as the number of features that we have increased the computational cost of computing high degree polynomial features skyrockets, making the model slow.", "Another way of making a data set linearly separable are the Radial Basis functions mentioned previously. The following example shows how we can transform a non linearly separable data set into one that can be easily divided using an RBF:", "Now, if on the data set shown in the previous image, we compute a third feature, using an RBF centred on the origin, and we plot this new feature along with the previous two, our data set is transformed into the following one, which can be linearly separated by a horizontal plane at the height of 0.7 on the new feature r.", "In this previous example, however, we choose a point to centre our RBF that gave us good results, which is not trivial to do in most cases. What it\u2019s done most of the time is computing an RBF from every point in the data set to all the other data points using the original features, and using those RBF computed distances as new features.", "The issue here is, that if we have a large training set, computing all these features is very computationally expensive. Again we reach problems when trying to use a linear SVC to separate non-linear data.", "In the solution to these problems lies the true power of Support Vector Machines: Kernels.", "In both of the previous cases, to be able to separate our data, we needed to compute a transformation on it (a polynomial transformation, and an RBF similarity function), which as we saw was very computationally expensive.", "A Kernel in Machine Learning is a mathematical function that allows us to compute the dot product of the transformation of two vectors, without actually having to compute the transformations itself.", "The idea behind kernels is illustrated in the following formula.", "K(a,b) in the previous formula represents the kernel of vectors a and b (a random kernel, later we will see there are many different ones). We can see that this kernel is equal to the dot product of \u03d5(a) and \u03d5(b), where \u03d5 represents an specific transformation (which could be a polynomial, or RBF transformation) of the vector that is given to it as an argument.", "To understand how this largely simplifies our problem, and by the use of kernels we can use SVMs to classify non-linearly separable data sets, it is best if we first see how a Support Vector Machine is trained.", "In the end, training an SVM Classifier, comes down to solving an optimisation problem, called the Dual Problem. An SVM makes predictions pretty much like any other classifier: it takes the input vector x, multiplies it by some weight vector w, and adds a bias term b, like shown in the following formula.", "If this operation gives a result greater than some threshold (0 in our case), then the sample gets classified as a positive instance (1). If it yields a result lower than the threshold, then it gets classified as a negative instance (0).", "To obtain the weight and bias vectors, we have to solve an optimisation problem that tries to maximise the margin of the street we spoke about while limiting the margin violations. Mathematically this is translated into finding the minimal value of the weight vector that satisfies a certain condition of vagueness or slack (how many times and how heavily the margin can be crossed).", "This optimisation problem can be solved using a normal QP solver, as it is a convex, quadratic problem. The final equation which this problem solves is the following:", "Formula 3, however, is not strictly correct. \u03b1 should be greater than or equal to 0, taking this last value for every data point that is not a support vector.", "Don\u2019t mind about the t(i) or t(j), there are two important things about this equation: once we solve it and get the value of \u03b1, we can calculate the weight and bias vectors. The other thing to notice is the term inside the orange dotted line: the dot product of two training instances, which we have to repeat for all the training set.", "This is where the Kernel trick we spoke about before comes in handy: if we have transformed our training instances to make them separable using any kind of transformation, we would have to compute the transformation on every training instance, do the dot product\u2026 and it would all be amazingly expensive in terms of computation. This is shown in the following formula.", "If like above, we use a Kernel, then we don\u2019t have to actually compute the transformations. Cool right? Lets see some of the most popular kernels:", "Notice how for the dot product of two vectors to which we apply a polynomial transformation of degree d, where we would theoretically be increasing the n\u00ba of features of our data and therefore the complexity, we can use a kernel to avoid computing that transformation, and simply compute (\u03b3aTb+r)d.", "This is where the magic of SVMs lie. We can train them and make predictions, having the advantages of performing operations on our data without actually having to compute those operations.", "Lets finish off now, seeing the beauty of how these predictions are actually made.", "Like we saw before, to make a prediction we have to compute the dot product of our weight vector and our new data point x(n) and add a bias term. For this, if we plug into the equation on Formula 2 the value of w obtained from solving the optimisation problem, we get:", "Now, remember how we said that \u03b1 is 0 for all the data points that are not support vectors? This means that to make predictions, we just have to compute the kernel of the support vectors and our new data points and add the bias term. Awesome right?", "Kernels and SVMs showing their magic once again. Lastly, here are some practical tips and tricks for using Support Vector Machines.", "That is all! We have learned the intuition behind SVMs, and some of the maths of how they work under the hood.", "For further resources on Machine Learning and Data Science check out the following repository: How to Learn Machine Learning! For career resources (jobs, events, skill tests) go to AIgents.co \u2014 A career community for Data Scientists & Machine Learning Engineers.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F25a685e4d228&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----25a685e4d228--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----25a685e4d228--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://james-thorn.medium.com/?source=post_page-----25a685e4d228--------------------------------", "anchor_text": ""}, {"url": "https://james-thorn.medium.com/?source=post_page-----25a685e4d228--------------------------------", "anchor_text": "James Thorn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1fd70d25ff14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&user=James+Thorn&userId=1fd70d25ff14&source=post_page-1fd70d25ff14----25a685e4d228---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F25a685e4d228&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F25a685e4d228&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.pexels.com/es-es/foto/al-aire-libre-amanecer-arboles-asfalto-531321/", "anchor_text": "Pexels"}, {"url": "https://www.flaticon.com/free-icon/tree_489969", "anchor_text": "Flaticon."}, {"url": "https://howtolearnmachinelearning.com/books/machine-learning-books/", "anchor_text": "How to Learn Machine Learning"}, {"url": "https://aigents.co/", "anchor_text": "AIgents.co \u2014 A career community for Data Scientists & Machine Learning Engineers"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----25a685e4d228---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----25a685e4d228---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----25a685e4d228---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/startup?source=post_page-----25a685e4d228---------------startup-----------------", "anchor_text": "Startup"}, {"url": "https://medium.com/tag/technology?source=post_page-----25a685e4d228---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F25a685e4d228&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&user=James+Thorn&userId=1fd70d25ff14&source=-----25a685e4d228---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F25a685e4d228&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&user=James+Thorn&userId=1fd70d25ff14&source=-----25a685e4d228---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F25a685e4d228&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----25a685e4d228--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F25a685e4d228&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----25a685e4d228---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----25a685e4d228--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----25a685e4d228--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----25a685e4d228--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----25a685e4d228--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----25a685e4d228--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----25a685e4d228--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----25a685e4d228--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----25a685e4d228--------------------------------", "anchor_text": ""}, {"url": "https://james-thorn.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://james-thorn.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "James Thorn"}, {"url": "https://james-thorn.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3K Followers"}, {"url": "https://howtolearnmachinelearning.com/", "anchor_text": "https://howtolearnmachinelearning.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1fd70d25ff14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&user=James+Thorn&userId=1fd70d25ff14&source=post_page-1fd70d25ff14--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5ad84c2cef18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsupport-vector-machines-explained-25a685e4d228&newsletterV3=1fd70d25ff14&newsletterV3Id=5ad84c2cef18&user=James+Thorn&userId=1fd70d25ff14&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}