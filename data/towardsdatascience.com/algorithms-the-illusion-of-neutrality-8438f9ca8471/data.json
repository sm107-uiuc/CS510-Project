{"url": "https://towardsdatascience.com/algorithms-the-illusion-of-neutrality-8438f9ca8471", "time": 1682995742.0611799, "path": "towardsdatascience.com/algorithms-the-illusion-of-neutrality-8438f9ca8471/", "webpage": {"metadata": {"title": "Algorithms, the Illusion of Neutrality | by Olivier Penel | Towards Data Science", "h1": "Algorithms, the Illusion of Neutrality", "description": "Bias is a fundamental human characteristic. We are all biased, by our very nature, and every day we make countless decisions based on our gut feelings. We all have preconceived ideas, prejudices, and\u2026"}, "outgoing_paragraph_urls": [{"url": "http://go.sas.com/9bnhdb", "anchor_text": "Road2AI", "paragraph_index": 5}, {"url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G", "anchor_text": "announced", "paragraph_index": 13}, {"url": "https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/", "anchor_text": "Forget killer robots \u2014 because bias is the real AI danger", "paragraph_index": 23}], "all_paragraphs": ["Bias is a fundamental human characteristic. We are all biased, by our very nature, and every day we make countless decisions based on our gut feelings. We all have preconceived ideas, prejudices, and opinions. And that is fine, as long as we recognize it and take responsibility for it.", "The fundamental promise of AI, besides the dramatic increase of data processing power and business efficiency, is to help reduce the conscious or unconscious bias of human decisions. At the end of the day, this is what we expect from algorithms, isn\u2019t it? Objectivity, mathematical detachment rather than fuzzy emotions, fact-based rather than instinctive decisions. Algorithms are supposed to alert people to their cognitive blind spots, so they can make more accurate, unbiased decisions.", "In reality, bias is like a virus that travels and replicates. Human bias is transferred to AI and Machine Learning (ML) applications, primarily through the data they are fed and trained with. AI learns from whatever we give it. This means that the quality of the decisions depends on the quality of the training data. But training data can be incomplete and non-representative, it can inherit the prejudices of prior decision makers, or it may simply reflect the widespread biases that persist in the world.", "Bias can also be introduced by the design of the models. From an algorithmic perspective, bias can be understood as over-simplification. Models can be too rigid and therefore unable to grasp the underlying trends and complexity in the data. However, they can also be so sensitive to small fluctuations that they capture a lot of noise along with the signal. On this spectrum between fully biased and fully variable models, there is a middle ground that skilled data scientists must find when designing and developing models.", "The issue is that bias is not only transferred to algorithms, but it can also be amplified. This happens when biased ML algorithms create new data that is re-injected into the model as part of its continuous training. It becomes worse when the biased algorithm is used to make millions of predictions per minute as part of an automatic decision-making process, bringing bias back into the real world, at scale!", "Recently, during the SAS Analytics Roadshow (#Road2AI), I was asked by one of the attendees: \u201cIf we accept that humans are biased by nature, why should we expect anything different from algorithms?\u201d", "That\u2019s a fair question, but I think there are reasons for setting higher standards for algorithms. The first is because of the amplification. Algorithms can make things much worse by replicating and amplifying the bias that was already there. The second reason is accountability. When an individual makes a decision, that person is accountable for the consequences of that decision. Who is accountable when it is an algorithm that makes the decision?", "Algorithmic bias has the potential to create discrimination and inequalities in the real world. This is even more concerning when we see how easily bias and stereotypes can creep unchecked into day-to-day applications.", "Until last year, when you typed \u201cCEO\u201d in a text, iOS offered an icon of a businessman. In other words, it was set to assume that a CEO would probably be a man. Similarly, Google Translate seemed to have a lot of built-in gender prejudice, which popped up when translating several simple sentences from Turkish to English. Doctors, soldiers and presidents, it seemed, should be HE and nurses, teachers and singers SHE. Worse, though, was that HE is hard-working, but SHE is lazy. In both cases, adjustments have now been made to the model to correct this bias, but unfortunately, only after the event. It is obvious in hindsight that this should never have happened, but after all, it\u2019s only a matter of a bit of embarrassment and negative publicity, isn\u2019t it?", "The impact of bias on individuals, however, can be much more serious.", "For instance, AI can be used to deliver justice. It can help judges to evaluate the likelihood that a defendant will re-offend, and suggest whether to grant parole, or the duration of a prison term. This could help reduce prison populations and recidivism rates, but it could also increase discrimination. It turned out that the system was actually biased against minorities, who were twice as likely to be labelled as high-risk re-offenders than white offenders.", "Same issue with predictive policing. ML algorithms are used with large amounts of data to predict the likelihood that particular individuals will commit a crime. Besides the obvious privacy implications, these algorithms are not free of bias towards minorities. This again raises the question of accountability. Who is responsible for those decisions? How can we ensure that the data used is accurate? How can we justify decisions made by black box ML algorithms that nobody can fully understand?", "In the financial industry, most mortgage and insurance pricing decisions are made by algorithms. How do we make sure that those decisions are fair and non-discriminatory? In other words, how do we ensure that algorithmic choices are not based on input variables that correlate with protected demographic variables (like race and gender)?", "In HR, pre-existing human bias is undeniable. Many HR departments have therefore started to use AI techniques to address this issue, to increase diversity in the workforce and improve the quality of the new hires by bringing more impartiality into the hiring process. But again, algorithmic bias often creates the opposite effect. Recently, Amazon announced that it was retiring its AI recruiting tool because it was biased against women. Let\u2019s say that you\u2019re trying to hire an engineer, using a ML algorithm that was trained using historical data. If the training data is based on existing post-holders, it will almost certainly include a majority of men. As a result, the algorithm is likely to recommend male candidates, even if you removed gender as an input variable \u2014 which, to be fair, Amazon had done. This leads to discrimination against women, but it also deprives the company of the chance to hire a better skilled (female) engineer. In this case, the gender parameter in the model was too strong because of the lack of representativity in the data used to build the model.", "The problem with bias is that it delivers inaccurate results and bad decisions. It\u2019s not just about \u201cbeing nice\u201d or doing the \u201cright thing\u201d. It is also about making sure that investments in AI deliver the expected benefits. It is about ensuring that business decisions are made based on unbiased, accurate insights. It is about making sure that employees can rely on AI applications to make the right decisions.", "Finally, it is necessary to proactively address the question of bias because of the reputational damage caused when discriminatory practices, even unintentional, are made public. This is a matter of protecting your brand. Nowadays, people rightly expect organizations to treat them fairly. Losing the trust of customers is the worst thing that can happen to any business.", "I would not be surprised if the ability to deliver trustworthy, responsible and ethical AI becomes a competitive differentiator. It may even develop into a way for organizations to promote their brand as they do with labels such as WWF and Fairtrade.", "So, how do we reduce or eliminate the bias from automatic decision-making?", "There is, unfortunately, no magic bullet. Instead, organizations need constant effort to proactively scrutinize the design, development, deployment and use of AI applications, and to apply corrective measures when necessary.", "The first step is to raise awareness among those involved in developing AI applications. This means not just data scientists (who should already be well aware of the issue). It also means the domain experts and technologists. All of these have a role to play in the end-to-end analytics life-cycle.", "The second step is to have processes in place to audit both the input and output of models used by AI applications. This should ensure that the data used to train the models is representative and free of bias. When developing models, data scientists should incorporate logic to help recognize and highlight bias in the data. Statistical analysis can also be used with the predictions made by AI applications to look for unexpected patterns or trends that could indicate a bias.", "Finally, it is critical to establish a strong governance framework around the use of AI applications. This should include a multi-disciplinary governing body responsible for:", "Beyond the question of ethics, the war against bias is a business imperative. It is necessary to ensure the adoption of AI applications and the realization of the expected value. There is much talk about how AI will take over from humans, but we are not there yet. We are, indeed, far from it, but that does not mean the world of AI is danger-free.", "As John Giannandrea, Senior VP of ML and AI Strategy at Apple, formerly head of AI at Google, said: \u201cForget killer robots \u2014 because bias is the real AI danger\u201d.", "For more, read my 2 other blogs on this topic:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Passionate about data-driven innovation (AI, IoT, Analytics\u2026), how it creates value and how it relates to bigger questions such as privacy and ethics"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8438f9ca8471&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://olivierpenel.medium.com/?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": ""}, {"url": "https://olivierpenel.medium.com/?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "Olivier Penel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F84d55fb0fe47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&user=Olivier+Penel&userId=84d55fb0fe47&source=post_page-84d55fb0fe47----8438f9ca8471---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8438f9ca8471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8438f9ca8471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://go.sas.com/9bnhdb", "anchor_text": "The Road to Trusted AI"}, {"url": "https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral", "anchor_text": "Markus Spiske"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://go.sas.com/9bnhdb", "anchor_text": "Road2AI"}, {"url": "https://unsplash.com/@yasinyusuf?utm_source=medium&utm_medium=referral", "anchor_text": "Yasin Yusuf"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G", "anchor_text": "announced"}, {"url": "https://unsplash.com/@little_klein?utm_source=medium&utm_medium=referral", "anchor_text": "Vitolda Klein"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@marilezhava?utm_source=medium&utm_medium=referral", "anchor_text": "mari lezhava"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.blog.google/technology/ai/ai-principles/", "anchor_text": "Google was eventually forced to do this"}, {"url": "https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/", "anchor_text": "Forget killer robots \u2014 because bias is the real AI danger"}, {"url": "https://towardsdatascience.com/x-ai-black-boxes-and-crystal-balls-fd27a00752ec?source=friends_link&sk=134d1a420e0368e64577b3b7a6ae89db", "anchor_text": "X-AI, Crystal Balls and Black Boxes"}, {"url": "https://towardsdatascience.com/ethics-the-new-frontier-of-technology-815454f0d158?source=friends_link&sk=f659b80ca31c9694abab235664b0c935", "anchor_text": "Ethics, the new Frontier of Technology"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----8438f9ca8471---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/bias?source=post_page-----8438f9ca8471---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/tag/fairness?source=post_page-----8438f9ca8471---------------fairness-----------------", "anchor_text": "Fairness"}, {"url": "https://medium.com/tag/ethics?source=post_page-----8438f9ca8471---------------ethics-----------------", "anchor_text": "Ethics"}, {"url": "https://medium.com/tag/ai?source=post_page-----8438f9ca8471---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8438f9ca8471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&user=Olivier+Penel&userId=84d55fb0fe47&source=-----8438f9ca8471---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8438f9ca8471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&user=Olivier+Penel&userId=84d55fb0fe47&source=-----8438f9ca8471---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8438f9ca8471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8438f9ca8471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8438f9ca8471---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8438f9ca8471--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8438f9ca8471--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8438f9ca8471--------------------------------", "anchor_text": ""}, {"url": "https://olivierpenel.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://olivierpenel.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Olivier Penel"}, {"url": "https://olivierpenel.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "100 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F84d55fb0fe47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&user=Olivier+Penel&userId=84d55fb0fe47&source=post_page-84d55fb0fe47--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F332b75d1b435&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falgorithms-the-illusion-of-neutrality-8438f9ca8471&newsletterV3=84d55fb0fe47&newsletterV3Id=332b75d1b435&user=Olivier+Penel&userId=84d55fb0fe47&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}