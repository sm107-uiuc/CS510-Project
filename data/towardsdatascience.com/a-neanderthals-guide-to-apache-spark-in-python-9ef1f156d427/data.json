{"url": "https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427", "time": 1682996656.5163782, "path": "towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427/", "webpage": {"metadata": {"title": "A Neanderthal\u2019s Guide to Apache Spark in Python | by Evan Heitman | Towards Data Science", "h1": "A Neanderthal\u2019s Guide to Apache Spark in Python", "description": "If you\u2019re anything like me, you heard about a fancy-sounding technology called Spark and wanted to test your coding mettle to see if you could add another tool to your data-science toolkit. Hopefully\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/baseds/many-nodes-one-distributed-system-9921f85205c4", "anchor_text": "Introduction to distributed computing", "paragraph_index": 7}, {"url": "https://www.digitalocean.com/community/tutorials/hadoop-storm-samza-spark-and-flink-big-data-frameworks-compared", "anchor_text": "Processing Engines explained and compared", "paragraph_index": 8}, {"url": "https://mapr.com/blog/5-minute-guide-understanding-significance-apache-spark/", "anchor_text": "5 minute guide to understanding the significance of Spark", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/database-terminologies-partitioning-f91683901716", "anchor_text": "Explanation of Data Partitioning", "paragraph_index": 10}, {"url": "https://www.quora.com/How-is-fault-tolerance-achieved-in-Apache-Spark", "anchor_text": "How is Spark fault tolerant", "paragraph_index": 11}, {"url": "https://medium.com/background-thread/what-is-lazy-evaluation-programming-word-of-the-day-8a6f4410053f", "anchor_text": "What is Lazy Evaluation", "paragraph_index": 12}, {"url": "https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html", "anchor_text": "RDDs, DataFrames, & DataSets compared", "paragraph_index": 13}, {"url": "https://medium.com/@chris_bour/6-differences-between-pandas-and-spark-dataframes-1380cec394d2", "anchor_text": "Pandas v. Spark DataFrames", "paragraph_index": 13}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd.html", "anchor_text": "Helpful RDD Documentation", "paragraph_index": 13}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-transformations.html", "anchor_text": "Helpful Transformation Documentation", "paragraph_index": 14}, {"url": "https://data-flair.training/blogs/spark-rdd-operations-transformations-actions/", "anchor_text": "More in-depth Documentation", "paragraph_index": 14}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-actions.html", "anchor_text": "Helpful Action Documentation", "paragraph_index": 15}, {"url": "https://data-flair.training/blogs/spark-rdd-operations-transformations-actions/", "anchor_text": "More in-depth Documentation", "paragraph_index": 15}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-lineage.html#logical-execution-plan", "anchor_text": "Helpful Lineage Documentation", "paragraph_index": 16}, {"url": "https://spark.apache.org/docs/latest/cluster-overview.html", "anchor_text": "Cluster Mode Overview", "paragraph_index": 17}, {"url": "https://stackoverflow.com/questions/32621990/what-are-workers-executors-cores-in-spark-standalone-cluster", "anchor_text": "Helpful Answer on StackOverflow", "paragraph_index": 17}, {"url": "https://www.cloudera.com/documentation/enterprise/5-6-x/topics/cdh_ig_spark_apps.html", "anchor_text": "Spark Application Overview", "paragraph_index": 17}, {"url": "https://spark.apache.org/downloads.html", "anchor_text": "spark.apache.org", "paragraph_index": 20}, {"url": "https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f", "anchor_text": "run in Jupyter Notebooks", "paragraph_index": 20}, {"url": "https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c", "anchor_text": "this super helpful article", "paragraph_index": 21}, {"url": "https://spark.apache.org/downloads.html", "anchor_text": "this website", "paragraph_index": 23}, {"url": "https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f", "anchor_text": "Getting Started with PySpark and Jupyter", "paragraph_index": 26}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617", "anchor_text": "How to use PySpark on your computer", "paragraph_index": 26}, {"url": "https://medium.com/tinghaochen/how-to-install-pyspark-locally-94501eefe421", "anchor_text": "How to install PySpark locally", "paragraph_index": 26}, {"url": "https://towardsdatascience.com/how-to-get-started-with-pyspark-1adc142456ec", "anchor_text": "How to Get Started with PySpark", "paragraph_index": 26}, {"url": "https://spark.apache.org/docs/2.2.0/api/java/index.html?org/apache/spark/sql/SparkSession.Builder.html", "anchor_text": "Builder API", "paragraph_index": 31}, {"url": "https://www.kaggle.com/gregorut/videogamesales", "anchor_text": "here", "paragraph_index": 33}, {"url": "https://stackoverflow.com/questions/36786722/how-to-display-full-output-in-jupyter-not-only-last-result", "anchor_text": "this", "paragraph_index": 39}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html", "anchor_text": "Machine Learning in Spark", "paragraph_index": 55}, {"url": "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1779476228152266/1437143569842658/5673666086694627/latest.html", "anchor_text": "Detailed Code example of Linear Regression", "paragraph_index": 72}, {"url": "https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html", "anchor_text": "Detailed Code example of Logistic Regression using SQL", "paragraph_index": 72}, {"url": "https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a", "anchor_text": "Example of Linear Regression, Decision Tree, and Gradient-Boosted Tree Regression", "paragraph_index": 72}, {"url": "https://github.com/evanheitman/Neaderthals_Guide_to_Apache_Spark/blob/master/Neanderthal's_Guide_to_Apache_Spark.ipynb", "anchor_text": "here", "paragraph_index": 75}], "all_paragraphs": ["If you\u2019re anything like me, you heard about a fancy-sounding technology called Spark and wanted to test your coding mettle to see if you could add another tool to your data-science toolkit. Hopefully you\u2019re not exactly like me because in my case I promptly hit an installation wall, and then a terminology wall, and then a conceptual wall, and four hours later, I hadn\u2019t written a single line of code. And so, after hours of scouring the internet, and more so-called \u201cbeginner\u2019s guides\u201d than I care to mention, I decided to write a \u201cneanderthal\u2019s guide\u201d to hopefully spare you some of the hassle that I endured.", "Even a quick search online for learning material on Spark will leave you swimming in documentation, online courses (many of which are not cheap), and a menagerie of other resources. From my experience, the majority of these either assumed I knew too much about distributed computing (like assuming I knew what distributed computing meant for example), or they gave high-level or background information without helping me understand how to actually implement anything in Spark.", "With that in mind, in this guide I try to do my best to either explain a concept, or direct you somewhere else with an explanation, all with the goal of getting you writing Spark code as quickly as possible. Because I try to do this for as many topics pertaining to Spark as I can, feel free to jump around if you already have a decent grasp of a particular topic. I\u2019ll also try to leave you with links to resources that I found helpful as I was diving into Spark.", "This is the structure of the guide: I start by explaining some key terminology and concepts so we can be on the same page for the rest of the material and also to lower the barrier to entry to the external resources on Spark you\u2019ll find here and elsewhere. Next, I walk through getting a working version of Spark running on your machine using Google Colab. And finally I go through a use case to demonstrate how PySpark is actually implemented and what a first pass through an example problem looks like.", "Here is a list of various terms and concepts that will be helpful to know as you delve into the world of Spark.", "If you\u2019ve Googled \u201cwhat is Spark\u201d, there\u2019s a chance you\u2019ve run into the following description, or something like it: \u201cSpark is a general-purpose distributed data processing engine\u201d. Without a background in Spark or any familiarity with what those terms mean, that definition is rather unhelpful. So let\u2019s break it down:", "NOTE: In a distributed computing system, each individual computer is called a node and the collection of all of them is called a cluster", "Further Reading \u2014 Introduction to distributed computing (8 min read)", "Further Reading \u2014 Processing Engines explained and compared (~10 min read)", "Further Reading \u2014 5 minute guide to understanding the significance of Spark (probably more like ~10 min read)", "Further Reading \u2014 Explanation of Data Partitioning (2 min read)", "Further Reading \u2014 How is Spark fault tolerant (~1 min read)", "Further Reading \u2014 What is Lazy Evaluation (4 min read)", "Further Reading \u2014 RDDs, DataFrames, & DataSets compared (~5 min read)Further Reading \u2014 Pandas v. Spark DataFrames (4 min read)Further Reading \u2014 Helpful RDD Documentation (~5 min read)", "Further Reading \u2014 Helpful Transformation Documentation (~2 min read) Further Reading \u2014 More in-depth Documentation (5\u201310 min read; Transformations in first half)", "Further Reading \u2014 Helpful Action Documentation (~1 min read)Further Reading \u2014 More in-depth Documentation (~5 min read; Actions in second half)", "Further Reading \u2014 Helpful Lineage Documentation (~2 min read)", "Further Reading \u2014 Cluster Mode Overview from Spark API (~3 min read)Further Reading \u2014 Helpful Answer on StackOverflow (~2 min read)Further Reading \u2014 Spark Application Overview on Cloudera (~2 min read)", "Phew you made it through all the terminology and concepts! Now let\u2019s get into implementation!", "That heading might be a bit of a misnomer, because, strictly speaking, this guide won\u2019t show you how to install Apache Spark. Installing Spark can be a pain in the butt. For one, writing Spark applications can be done in multiple languages and each one is installed slightly differently. The underlying API for Spark is written in Scala but PySpark is an overlying API for implementation in Python. For data science applications, using PySpark and Python is widely recommended over Scala, because it is relatively easier to implement. And so instead of installing PySpark, this guide will show you how to run it in Google Colab.", "When I was trying to get PySpark running on my computer, I kept getting conflicting instructions on where to download it from (it can be downloaded from spark.apache.org or pip installed for example), what to run it in (it can be run in Jupyter Notebooks or in the native pyspark shell in the command line), and there were numerous obscure bash commands sprinkled throughout. As a data analyst, my reaction to bash commands that aren\u2019t pip installs is generally a mix of disgust and despair, and so I turned to Google Colab.", "Google Colab is a really powerful interactive python notebook (.ipynb) tool that has a lot data science libraries pre-installed. For more information on what it is and how to run it check out this super helpful article (8 min read).", "Once you\u2019ve got a Colab notebook up, to get Spark running you have to run the following block of code (I know it\u2019s not my fault, but I apologize for how ugly it is).", "NOTE: When I first ran this block of code it did not run. It was because there had been a new version of Spark released since the code I found was written and I was trying to access an older version of Spark that couldn\u2019t be found. So if the above code doesn\u2019t run, double check this website to see what the latest version of Spark is and replace everywhere you see \u201c2.4.3\u201d in the above snippet to whatever the newest version is.", "Basically what this block of code does is download the right versions of Java (Spark uses some Java) and Spark, set the PATH to those versions, and to initialize Spark in your notebook.", "If you want to use Spark on another platform besides Colab, here are the most helpful guides I found (in order of helpfulness), hopefully one of them is able to get you going:", "Installation Resource\u2014 Getting Started with PySpark and JupyterInstallation Resource \u2014 How to use PySpark on your computerInstallation Resource \u2014 How to install PySpark locallyInstallation Resource \u2014 How to Get Started with PySpark", "Because we want to be working with columnar data, we\u2019ll be using DataFrames which are a part of Spark SQL.", "NOTE: To avoid possible confusion, despite the fact that we will be working with Spark SQL, none of this will be SQL code. You can write SQL queries when working with Spark DataFrames but you don\u2019t have to.", "The entry point to using Spark SQL is an object called SparkSession. It initiates a Spark Application which all the code for that Session will run on.", "NOTE: the \u201c \\\u201d character is this context is called a continuation character which is just a helpful wrapping tool for making long lines of code more readable.", "Check the Builder API for more options when building a SparkSession.", "To open a local file on Google Colab you need to run the following code which will prompt you to select a file from your computer:", "For this guide we\u2019ll be working with a dataset on video game sales from Kaggle. It can be found here.", "Now load our data into a Spark DataFrame using the .read.csv() function: (I shortened the file name for brevity\u2019s sake)", "NOTE: This function is specifically for reading CSV files into a DataFrame in PySparkSQL. It won\u2019t work for loading data into an RDD and different languages (besides Python) have different syntax. Exercise caution when searching online for help because many resources do not assume Spark SQL or Python.", "Now let\u2019s move into understanding how we can get more familiar with our data!", "The first thing we can do is check the shape of of our DataFrame. Unlike Pandas, there is no dedicated method for this but we can use the .count() and .columns() to retrieve the information ourselves.", "The .count() method returns the number of rows in the DataFrame and .columns returns a list of column names.", "NOTE: We don\u2019t have to actually print them because Colab will automatically display the last output of each cell. If you want to show more than one output you will have to print them (unless you use this workaround, which is super nice and works in Jupyter Notebooks as well)", "Viewing DataFramesTo view a DataFrame, use the .show() method:", "As you can see, running data.show(5) displayed the first 5 rows of our DataFrame, along with the header. Calling .show() with no parameters will return the first 20 records.", "Let\u2019s see what our data is comprised of using the .printSchema() method (alternatively you can use .dtypes):", "Some takeaways from this output is that Year_of_Release and User_Score have a type of string, despite them being numbers. It also tells us that each of the columns allows null values which can be seen in the first 5 rows.", "We can also selectively choose which columns we want to display with the .select() method. Let\u2019s view only Name, Platform, User_Score, and User_Count:", "Included is the truncate=False parameter that adjusts the size of columns to prevent values from being cut off.", "Summary Statistics/InformationWe can use the .describe() method to get summary statistics on columns of our choosing:", "Some takeaways from this output is that there seems to be a strange \u201ctbd\u201d value in the User_Score column. The count for User_Score is also higher than User_Count but it\u2019s hard to tell if that\u2019s because there are actually more values in User_Score or if \u201ctbd\u201d values are artificially raising the count. We\u2019ll learn how to filter those values out later on.", "We might also want to get some information on what kinds of platforms are in the Platform column and how they are distributed. We can use a groupBy() for this and sort it using .orderBy():", "Here we\u2019re looking at the top 10 most frequent platforms. We can tell this dataset is pretty old because I don\u2019t see PS4 anywhere \ud83e\udd14", "Filtering DataFramesLets create a new DataFrame that has the null values for User_Score and User_Count, and the \u201ctbd\u201d values filtered out using the .filter() method:", "condition1 returns True for any record that does not have a null value in User_Score or in User_Count. condition2 returns True for any record that does not have \u201ctbd\u201d in User_Score.", "We can double check to see if our filtering worked by reconstructing our earlier visualizations", "That\u2019s enough Data Exploration to get started, now lets build a model!", "Building models in PySpark looks a little different than you might be used to, and you\u2019ll see terms like Transformer, Estimator, and Param. This guide won\u2019t go in-depth into what those terms mean but below is a link to a brief description of what they mean.", "Further Reading \u2014 Machine Learning in Spark (~5\u201310 min read)", "SetupFor an example of linear regression, let\u2019s see if we can predict User_Score from Year_of_Release, Global_Sales, Critic_Score, and User_Count.", "First let\u2019s recode all of our predictors to be Doubles (I found that this got rid of some really gnarly errors later on).", "We use the method withColumn(), which either creates a new column or replaces one that already exists. So, for example, the Year_of_Release column is replaced with a version of itself that has been cast as doubles .", "VectorAssemblerThe next step is to get our data into a form that PySpark can create a model with. To do this we use something called a VectorAssembler.", "Here we\u2019ve delineated what features we want our model to use as predictors so that VectorAssembler can take those columns and transform them into a single column (named \u201cpredictors\u201d) that contains all the data we want to predict with.", "What VectorAssembler.transform() does is create a new DataFrame with a new column at the end where each row contains a list of all the features we included in the inputCols parameter when we created the assembler.", "The final step to getting our data ready to be used in a model is to collect the new predictions column we just made and User_Score (our target variable) by themselves in a DataFrame.", "Next is to split model_data into a training and testing set:", "Model TrainingNow to train the model!", "After importing LinearRegression from pyspark.ml.regression, we construct a regressor and we specify that it should look for a column named \u201cpredictors\u201d as the features of the model and a column named \u201cUser_Score\u201d as the labels of the model. Next we train it with .fit() and finally produce predictions with .evaluate().", "We can access the parameters of our model with the following code", "We can also view the final predictions our model made:", "The object named \u201cpred\u201d is a LinearRegressionSummary object and so to retrieve the DataFrame with predictions we call .predictions.show()", "Model EvaluatingTo get more detailed information on how our model performed, we can use RegressionEvaluator which is constructed like this:", "Let\u2019s compute some statistics for the model:", "From this we can interpret that our model tended to be about 1.125 rating points off from the actual User_Score (according to rmse). The r\u00b2 value for tells us that the predictors in our model are able to account for a little under 40% of the total variability in User_Score. This was just a first pass look, and I recommend playing around with the model parameters and features for more practice!", "Further Reading \u2014 Detailed Code example of Linear Regression (~20+ min to go through the whole thing)Further Reading \u2014 Detailed Code example of Logistic Regression using SQL (~10 minutes)Further Reading \u2014 Example of Linear Regression, Decision Tree, and Gradient-Boosted Tree Regression (6 min read)", "This is just the tip of the iceberg as far as the kind of modeling you can do in PySpark, but I hope this guide has equipped you with enough to get your foot into the door of Big Data!", "Wow. Props to you if you made it all the way to the end. You were exposed to a ton of new concepts, from the terminology of distributed computing and Spark, to implementing data exploration and data modeling techniques in PySpark. My hope is that this guide can be a resource for you as you continue working with Spark!", "All the code used in this article can be found on GitHub here.", "Learning Data Science with as few clicks as possible | University of Virginia Systems Engineering Graduate"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9ef1f156d427&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@eth6re?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@eth6re?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Evan Heitman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F598b9c6fe800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&user=Evan+Heitman&userId=598b9c6fe800&source=post_page-598b9c6fe800----9ef1f156d427---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9ef1f156d427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&user=Evan+Heitman&userId=598b9c6fe800&source=-----9ef1f156d427---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9ef1f156d427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&source=-----9ef1f156d427---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://xkcd.com/908/", "anchor_text": "xkcd"}, {"url": "https://medium.com/baseds/many-nodes-one-distributed-system-9921f85205c4", "anchor_text": "Introduction to distributed computing"}, {"url": "https://medium.com/@bradanderson.contacts/spark-vs-hadoop-mapreduce-c3b998285578", "anchor_text": "Brad Anderson"}, {"url": "https://www.digitalocean.com/community/tutorials/hadoop-storm-samza-spark-and-flink-big-data-frameworks-compared", "anchor_text": "Processing Engines explained and compared"}, {"url": "https://databricks.com/spark/about", "anchor_text": "Databricks.com"}, {"url": "https://mapr.com/blog/5-minute-guide-understanding-significance-apache-spark/", "anchor_text": "5 minute guide to understanding the significance of Spark"}, {"url": "https://towardsdatascience.com/database-terminologies-partitioning-f91683901716", "anchor_text": "Explanation of Data Partitioning"}, {"url": "https://www.quora.com/How-is-fault-tolerance-achieved-in-Apache-Spark", "anchor_text": "How is Spark fault tolerant"}, {"url": "https://medium.com/background-thread/what-is-lazy-evaluation-programming-word-of-the-day-8a6f4410053f", "anchor_text": "What is Lazy Evaluation"}, {"url": "https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html", "anchor_text": "RDDs, DataFrames, & DataSets compared"}, {"url": "https://medium.com/@chris_bour/6-differences-between-pandas-and-spark-dataframes-1380cec394d2", "anchor_text": "Pandas v. Spark DataFrames"}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd.html", "anchor_text": "Helpful RDD Documentation"}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-transformations.html", "anchor_text": "Helpful Transformation Documentation"}, {"url": "https://data-flair.training/blogs/spark-rdd-operations-transformations-actions/", "anchor_text": "More in-depth Documentation"}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-actions.html", "anchor_text": "Helpful Action Documentation"}, {"url": "https://data-flair.training/blogs/spark-rdd-operations-transformations-actions/", "anchor_text": "More in-depth Documentation"}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-lineage.html#logical-execution-plan", "anchor_text": "Jacek Laskowski"}, {"url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-lineage.html#logical-execution-plan", "anchor_text": "Helpful Lineage Documentation"}, {"url": "https://spark.apache.org/docs/latest/cluster-overview.html", "anchor_text": "Spark API"}, {"url": "https://spark.apache.org/docs/latest/cluster-overview.html", "anchor_text": "Cluster Mode Overview"}, {"url": "https://stackoverflow.com/questions/32621990/what-are-workers-executors-cores-in-spark-standalone-cluster", "anchor_text": "Helpful Answer on StackOverflow"}, {"url": "https://www.cloudera.com/documentation/enterprise/5-6-x/topics/cdh_ig_spark_apps.html", "anchor_text": "Spark Application Overview"}, {"url": "https://spark.apache.org/downloads.html", "anchor_text": "spark.apache.org"}, {"url": "https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f", "anchor_text": "run in Jupyter Notebooks"}, {"url": "https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c", "anchor_text": "this super helpful article"}, {"url": "https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz", "anchor_text": "https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz"}, {"url": "https://spark.apache.org/downloads.html", "anchor_text": "this website"}, {"url": "https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f", "anchor_text": "Getting Started with PySpark and Jupyter"}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617", "anchor_text": "How to use PySpark on your computer"}, {"url": "https://medium.com/tinghaochen/how-to-install-pyspark-locally-94501eefe421", "anchor_text": "How to install PySpark locally"}, {"url": "https://towardsdatascience.com/how-to-get-started-with-pyspark-1adc142456ec", "anchor_text": "How to Get Started with PySpark"}, {"url": "https://spark.apache.org/docs/2.2.0/api/java/index.html?org/apache/spark/sql/SparkSession.Builder.html", "anchor_text": "Builder API"}, {"url": "https://spark.apache.org/docs/2.2.0/api/java/index.html?org/apache/spark/sql/SparkSession.Builder.html", "anchor_text": "Builder API"}, {"url": "https://www.kaggle.com/gregorut/videogamesales", "anchor_text": "here"}, {"url": "https://stackoverflow.com/questions/36786722/how-to-display-full-output-in-jupyter-not-only-last-result", "anchor_text": "this"}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html", "anchor_text": "Machine Learning in Spark"}, {"url": "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1779476228152266/1437143569842658/5673666086694627/latest.html", "anchor_text": "Detailed Code example of Linear Regression"}, {"url": "https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html", "anchor_text": "Detailed Code example of Logistic Regression using SQL"}, {"url": "https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a", "anchor_text": "Example of Linear Regression, Decision Tree, and Gradient-Boosted Tree Regression"}, {"url": "https://github.com/evanheitman/Neaderthals_Guide_to_Apache_Spark/blob/master/Neanderthal's_Guide_to_Apache_Spark.ipynb", "anchor_text": "here"}, {"url": "https://medium.com/tag/spark?source=post_page-----9ef1f156d427---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----9ef1f156d427---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/big-data?source=post_page-----9ef1f156d427---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/python?source=post_page-----9ef1f156d427---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/distributed-computing?source=post_page-----9ef1f156d427---------------distributed_computing-----------------", "anchor_text": "Distributed Computing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9ef1f156d427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&user=Evan+Heitman&userId=598b9c6fe800&source=-----9ef1f156d427---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9ef1f156d427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&user=Evan+Heitman&userId=598b9c6fe800&source=-----9ef1f156d427---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9ef1f156d427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@eth6re?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F598b9c6fe800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&user=Evan+Heitman&userId=598b9c6fe800&source=post_page-598b9c6fe800----9ef1f156d427---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F86230d07b3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&newsletterV3=598b9c6fe800&newsletterV3Id=86230d07b3e5&user=Evan+Heitman&userId=598b9c6fe800&source=-----9ef1f156d427---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@eth6re?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Written by Evan Heitman"}, {"url": "https://medium.com/@eth6re/followers?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "267 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F598b9c6fe800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&user=Evan+Heitman&userId=598b9c6fe800&source=post_page-598b9c6fe800----9ef1f156d427---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F86230d07b3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427&newsletterV3=598b9c6fe800&newsletterV3Id=86230d07b3e5&user=Evan+Heitman&userId=598b9c6fe800&source=-----9ef1f156d427---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/beginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d?source=author_recirc-----9ef1f156d427----0---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://medium.com/@eth6re?source=author_recirc-----9ef1f156d427----0---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://medium.com/@eth6re?source=author_recirc-----9ef1f156d427----0---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Evan Heitman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9ef1f156d427----0---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/beginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d?source=author_recirc-----9ef1f156d427----0---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Beginner\u2019s Guide to Building Neural Networks in TensorFlowDetailed Walkthrough of the TensorFlow 2.0 Beginner Notebook"}, {"url": "https://towardsdatascience.com/beginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d?source=author_recirc-----9ef1f156d427----0---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "\u00b712 min read\u00b7Jun 5, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdab7a09b941d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d&user=Evan+Heitman&userId=598b9c6fe800&source=-----dab7a09b941d----0-----------------clap_footer----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/beginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d?source=author_recirc-----9ef1f156d427----0---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdab7a09b941d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d&source=-----9ef1f156d427----0-----------------bookmark_preview----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9ef1f156d427----1---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9ef1f156d427----1---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9ef1f156d427----1---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9ef1f156d427----1---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9ef1f156d427----1---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9ef1f156d427----1---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9ef1f156d427----1---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----9ef1f156d427----1-----------------bookmark_preview----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9ef1f156d427----2---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9ef1f156d427----2---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9ef1f156d427----2---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9ef1f156d427----2---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9ef1f156d427----2---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9ef1f156d427----2---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9ef1f156d427----2---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----9ef1f156d427----2-----------------bookmark_preview----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----9ef1f156d427----3---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----9ef1f156d427----3---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----9ef1f156d427----3---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9ef1f156d427----3---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----9ef1f156d427----3---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----9ef1f156d427----3---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": "15 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----3-----------------clap_footer----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----9ef1f156d427----3---------------------8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----9ef1f156d427----3-----------------bookmark_preview----8df02291_f580_4c64_a5dc_5b1f9cb57a6c-------", "anchor_text": ""}, {"url": "https://medium.com/@eth6re?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "See all from Evan Heitman"}, {"url": "https://towardsdatascience.com/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Anuj Syal"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "12 Must-Have Skills to become a Data EngineerThe Essential Skills for a Successful Data Engineering Career"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "\u00b78 min read\u00b7Jan 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&user=Anuj+Syal&userId=df3997c527b4&source=-----35b100dbee0a----0-----------------clap_footer----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&source=-----9ef1f156d427----0-----------------bookmark_preview----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-art-of-speeding-up-python-loop-4970715717c?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://casey-cheng.medium.com/?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://casey-cheng.medium.com/?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Casey Cheng"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-art-of-speeding-up-python-loop-4970715717c?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "The Art of Speeding Up Python LoopThere is no \u201cbest\u201d looping technique in Python, only the most suitable."}, {"url": "https://towardsdatascience.com/the-art-of-speeding-up-python-loop-4970715717c?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "\u00b710 min read\u00b7Oct 31, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4970715717c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-speeding-up-python-loop-4970715717c&user=Casey+Cheng&userId=514ba843cfe4&source=-----4970715717c----1-----------------clap_footer----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-art-of-speeding-up-python-loop-4970715717c?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4970715717c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-speeding-up-python-loop-4970715717c&source=-----9ef1f156d427----1-----------------bookmark_preview----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.com/codex/say-goodbye-to-loops-in-python-and-welcome-vectorization-e4df66615a52?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://anmol3015.medium.com/?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://anmol3015.medium.com/?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Anmol Tomar"}, {"url": "https://medium.com/codex?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "CodeX"}, {"url": "https://medium.com/codex/say-goodbye-to-loops-in-python-and-welcome-vectorization-e4df66615a52?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Say Goodbye to Loops in Python, and Welcome Vectorization!Use Vectorization \u2014 a super fast alternative to loops in Python"}, {"url": "https://medium.com/codex/say-goodbye-to-loops-in-python-and-welcome-vectorization-e4df66615a52?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "\u00b75 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcodex%2Fe4df66615a52&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fsay-goodbye-to-loops-in-python-and-welcome-vectorization-e4df66615a52&user=Anmol+Tomar&userId=d80580992695&source=-----e4df66615a52----0-----------------clap_footer----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.com/codex/say-goodbye-to-loops-in-python-and-welcome-vectorization-e4df66615a52?source=read_next_recirc-----9ef1f156d427----0---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "49"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4df66615a52&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fsay-goodbye-to-loops-in-python-and-welcome-vectorization-e4df66615a52&source=-----9ef1f156d427----0-----------------bookmark_preview----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9ef1f156d427----1---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----9ef1f156d427----1-----------------bookmark_preview----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----9ef1f156d427----2---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----9ef1f156d427----2---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----9ef1f156d427----2---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9ef1f156d427----2---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----9ef1f156d427----2---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----9ef1f156d427----2---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----9ef1f156d427----2---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----9ef1f156d427----2-----------------bookmark_preview----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----9ef1f156d427----3---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.com/@lgsoliveira?source=read_next_recirc-----9ef1f156d427----3---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.com/@lgsoliveira?source=read_next_recirc-----9ef1f156d427----3---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Lu\u00eds Oliveira"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----9ef1f156d427----3---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----9ef1f156d427----3---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "How to Run Spark With DockerTutorial with Pyspak"}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----9ef1f156d427----3---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": "\u00b76 min read\u00b7Dec 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fc6287a11a437&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-to-run-spark-with-docker-c6287a11a437&user=Lu%C3%ADs+Oliveira&userId=6bd0a8d7aa96&source=-----c6287a11a437----3-----------------clap_footer----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----9ef1f156d427----3---------------------1b4ed290_4721_4e6a_8630_77e977ea1777-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc6287a11a437&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-to-run-spark-with-docker-c6287a11a437&source=-----9ef1f156d427----3-----------------bookmark_preview----1b4ed290_4721_4e6a_8630_77e977ea1777-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----9ef1f156d427--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}