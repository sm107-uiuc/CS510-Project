{"url": "https://towardsdatascience.com/your-first-apache-spark-ml-model-d2bb82b599dd", "time": 1683009392.117978, "path": "towardsdatascience.com/your-first-apache-spark-ml-model-d2bb82b599dd/", "webpage": {"metadata": {"title": "Your First Apache Spark ML Model. How to build a basic machine learning\u2026 | by Favio V\u00e1zquez | Towards Data Science", "h1": "Your First Apache Spark ML Model", "description": "I love Apache Spark. It was one of the first frameworks I used for machine learning and data science. It has been growing steadily in the past years, and we are close to its 3rd version. The changes\u2026"}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html#data-sources", "anchor_text": "sources", "paragraph_index": 17}, {"url": "https://databricks.com/blog/2017/08/31/cost-based-optimizer-in-apache-spark-2-2.html", "anchor_text": "Catalyst", "paragraph_index": 20}, {"url": "https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html", "anchor_text": "example", "paragraph_index": 22}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617", "anchor_text": "this article.", "paragraph_index": 27}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html", "anchor_text": "official documentation", "paragraph_index": 33}, {"url": "https://spark.apache.org/docs/latest/ml-features#stringindexer", "anchor_text": "StringIndexer", "paragraph_index": 52}, {"url": "https://spark.apache.org/docs/latest/ml-features#vectorassembler", "anchor_text": "VectorAssembler", "paragraph_index": 58}, {"url": "https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier", "anchor_text": "Random Forest Classifier", "paragraph_index": 63}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html#estimators", "anchor_text": "estimator", "paragraph_index": 63}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html#transformers", "anchor_text": "transformer", "paragraph_index": 65}, {"url": "https://en.wikipedia.org/wiki/Accuracy_and_precision", "anchor_text": "accuracy", "paragraph_index": 66}, {"url": "https://www.linkedin.com/company/closter/", "anchor_text": "Closter", "paragraph_index": 71}], "all_paragraphs": ["I love Apache Spark. It was one of the first frameworks I used for machine learning and data science. It has been growing steadily in the past years, and we are close to its 3rd version. The changes we are expecting are mostly in the optimization of queries and processes so the API won\u2019t change that much. This means that what you will learn in this article will work for a while (we don\u2019t know for how long because life it\u2019s tricky).", "The article it\u2019s divided into three parts:", "A lot of the things you are going to see in the first two sections are coming from two other articles I wrote about Apache Spark in the past:", "But it\u2019s time for a renewal :)", "A few years ago, Apache Spark was defined by its creators as:", "A fast and general engine for large-scale data processing.", "The \u201cfast\u201d part means that it\u2019s faster than previous approaches to work with Big Data like classical MapReduce. The secret for being faster is that Spark runs on Memory (RAM), and that makes the processing much faster than on Disk.", "The \u201cgeneral\u201d part means that it can be used for multiple things, like running distributed SQL, create data pipelines, ingest data into a database, run Machine Learning algorithms, work with graphs, data streams, and much more.", "Now they have changed the definition to:", "Apache Spark is a unified analytics engine for large-scale data processing.", "We still have the general part there, but now it\u2019s broader with the word \u201cunified,\u201d and this is to explain that it can do almost everything in the data science or machine learning workflow. You can use the Spark framework alone for end-to-end projects.", "The \u201clarge-scale\u201d part means that this is a framework that works perfectly with significant amounts of data, what we used to call \u201cBig Data\u201d back in the day (interesting how fast things change).", "The central abstraction and the beginnings of Apache Spark are the Resilient Distributed Datasets (RDD).", "An RDD is a fault-tolerant collection of elements that can be operated on in parallel. You can create them parallelizing an existing collection in your driver program, or referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat.", "Something very important to know about Spark is that all transformations are lazy, which means that they do not compute their results right away. Instead, Spark remembers the transformations applied to some base dataset (e.g. a file). The transformations are only computed when an action requires a result to be returned to the driver program.", "By default, each transformed RDD may be recomputed each time you run an action on it. However, you may also persist an RDD in memory using the persist (or cache) method, in which case Spark will keep the elements around on the cluster for much faster access the next time you query it. There is also support for persisting RDDs on disk or replicated across multiple nodes.", "Since Spark 2.0.0 a DataFrame is a Dataset organized into named columns. It is conceptually equivalent to a table in a relational database or a DataFrame in R/Python, but with richer optimizations under the hood.", "DataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing RDDs.", "In simple words, the Dataframes API was the way from Spark creators to make it easy to work with Data in the framework. They are very similar to Pandas Dataframes or R Dataframes, but with several advantages. The first of course is that they can be distributed across a cluster, so they work with a lot of data, and the second one is that it\u2019s optimized.", "It was a very important step that the community took. By the year 2014, it was much faster to use Spark with Scala or Java, and the whole Spark world turned into Scala because of performance. But with the DF API, this was no longer an issue, and now you can get the same performance working with it in R, Python, Scala or Java.", "The responsible for this optimization is the Catalyst. You can think of it as a wizard, it will take your queries (oh yes!, you can run SQL-like queries in Spark, run them against the DF and they will be parallelized as well) and your actions and create an optimized plan for distributing the computation.", "The process is not that simple, but you as a programmer won\u2019t even notice it. Just now that it is there helping you out all the time.", "In Spark 3.0 we will get something called \u201cAdaptive Query Execution\u201d (AQE) that will reoptimize and adjust query plans based on runtime statistics collected in the process of query execution. This is going to be huge on performance, for example let\u2019s say we are running the query", "Without AQE, Spark will start five tasks to do the final aggregation:", "But with AQE, Spark will coalesce these three small partitions into one and, as a result, the final aggregation now only needs to perform three tasks rather than five:", "With this new release, Spark will solve one big problem: the cost-based optimization. If you want to know more please check the link in the two images above.", "We will see more things about Spark and it\u2019s machine learning (ML) library in the next sessions.", "We will install PySpark locally and then use Jupyter to work with it. There are more ways of using Spark, and if you want to know more about them check this article.", "PySpark, as you can imagine, is the Python API of Apache Spark. It\u2019s the way we have to interact with the framework using Python. The installation is very simple. These are the steps:", "The default version at this point is the 3.0.0, it\u2019s experimental, but it should work for our experiment.", "To test your installation, go to your terminal and then open Python. Then write:", "If you don\u2019t get an error, you are on the right path. To check the installed version of Spark write:", "Spark\u2019s library for machine learning is called MLlib (Machine Learning library). It\u2019s heavily based on Scikit-learn\u2019s ideas on pipelines. In this library to create an ML model the basics concepts are:", "If you want to know more about the APIs and how they work check the official documentation.", "For this example, we will use a very basic dataset. The Titanic dataset, hopefully, you are all familiar with the case and the data. To start we have to download the data, for that we are using Kaggle:", "Just download the \u201ctrain.csv\u201d file and that\u2019s it :).", "We will be predicting if a passenger survived or not depending on its features.", "Before starting: Make sure to close and stop all other Spark notebooks. Java can complain sometimes when working with multiple instances of Spark.", "To load the data we are using Spark DataFrames. Spark it\u2019s a little bit more complicated than Pandas. You can\u2019t just do \u201cimport -> read_csv()\u201d. You first need to start a Spark Session, to do that write:", "on your notebook, you should get:", "That means that you are using Spark locally with all the cores (that\u2019s the *), with version 3.0.0 and the name of the session is \u201cTitanic Data\u201d. That think there the \u201cSpark UI\u201d will be useful when you are working with Spark, if you click it you\u2019ll see:", "I won\u2019t have time to explain the UI in detail, but if you want to know more about it let me know :).", "Cool! So now we have everything in place to read the data. To do so write:", "And that\u2019s it! You have created your first Spark DataFrame. To see the internals of the DataFrame write:", "And you will get something not that pretty but useful at least:", "Yeah, I know, not that pretty. One good thing about using Python is that you can interact with Pandas easily. And to show our data in a prettier format you can write:", "But be careful my friends!!! You can only do this if the data you are working with is small enough, because when you do \u201ctoPandas()\u201d you are getting all the data at once, and it won\u2019t be distributed in that cell. So it will have to fit in Memory.", "There are basic functions to get more information out of your dataset. In the next code I put the basics ones (-> means the result of the computation):", "And finally some stats about our data:", "One of the things we noticed from the data exploration from above was that all the columns were of String type. But that doesn\u2019t seem right. Some of them should be numeric. So we are going to cast them. Also because of time I\u2019m only selecting a few variables for modeling so we don\u2019t have to deal with the whole dataset:", "In the end, you\u2019ll get this dataset:", "We see that we also have null values in some columns, so we will just eliminate them:", "Now, the Spark ML library only works with numeric data. But we still want to use the Sex and the Embarked column. For that, we will need to encode them. To do it let\u2019s use something called the StringIndexer:", "If you do that you\u2019ll get:", "As you can see we\u2019ve created two new columns \u201cGender\u201d and \u201cBoarded\u201d that contain the same information as \u201cSex\u201d and \u201cEmbarked\u201d but now they are numeric. Let\u2019s do a final check for our data types:", "So all the columns we want are numeric. We now have to get rid of the old columns \u201cSex\u201d and \u201cEmbarked\u201d because we won\u2019t be using them:", "Jut one step left before going into the machine learning part. Spark actually works to predict with a column with all the features smashed together into a list-like structure. For example, if you have the features:", "And you want to predict \u201cSurvived\u201d, you need to combine the information of the columns \u201cPclass\u201d, \u201cAge\u201d, \u201cFare\u201d, \u201cGender\u201d and \u201cBoarded\u201d into one column. We normally call that column features and it should look like this:", "As you can see the new column features contain the same information from all of our features but in a list-like object. To do that in Spark we use the VectorAssembler:", "Now if we check our data we have:", "That is exactly what we wanted.", "Now for the fun part right? NO! Haha. Modeling is important but without all the previous steps it would be impossible. So have fun in all the steps :)", "Before modeling let\u2019s do the usual splitting between training and testing:", "Ok. Modeling. That means, in this case, build and fit an ML model to our dataset to predict the \u201cSurvived\u201d columns with all the other ones. We will be using a Random Forest Classifier. This is actually an estimator that we have to fit.", "This is actually the easy part:", "This will give us something called a transformer. And finally, we predict using the test dataset:", "And that\u2019s it! You did it. Congratulations :). Your first Spark ML model. Now let\u2019s see how well we did. For that, we will use a basic metric called the accuracy:", "And we to get the accuracy we do:", "Our basic model is giving us an accuracy of 0.843. Not bad at all :).", "It should be noted that we have to much more to actually build a data science project, and a good ML model, like cross-validation, feature selection, we also have to test more models, etc.", "I have created a repo in GitHub with all the code for this article. You can find it here:", "Hopefully, you learned something new from this article. I\u2019ll be creating more in the subject, and I\u2019m also launching courses on Spark, Python and Data Science with my company Closter very soon. You can contact me at: favio [at] closer [dot] net", "See you in the next article :)", "Data scientist, physicist and computer engineer. Love sharing ideas, thoughts and contributing to Open Source in Machine Learning and Deep Learning ;)."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd2bb82b599dd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@faviovazquez?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Favio V\u00e1zquez"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe8ec6fa4d7d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=post_page-e8ec6fa4d7d4----d2bb82b599dd---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2bb82b599dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=-----d2bb82b599dd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2bb82b599dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&source=-----d2bb82b599dd---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://instagram.com/heizelvazquez", "anchor_text": "H\u00e9izel V\u00e1zquez"}, {"url": "https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd", "anchor_text": "Deep Learning With Apache Spark \u2014 Part 1First part on a full discussion on how to do Distributed Deep Learning with Apache Spark. This part: What is Spark\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617", "anchor_text": "How to use PySpark on your computerI\u2019ve found that is a little difficult to get started with Apache Spark (this will focus on PySpark) on your local\u2026towardsdatascience.com"}, {"url": "https://www.freepik.com/free-vector/background-several-colored-pieces_1174026.htm#page=1&query=blocks&position=10", "anchor_text": "Freepik"}, {"url": "https://instagram.com/heizelvazquez", "anchor_text": "H\u00e9izel V\u00e1zquez"}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html#data-sources", "anchor_text": "sources"}, {"url": "https://aspgems.com/blog/big-data/migrando-de-pandas-spark-dataframes", "anchor_text": "https://aspgems.com/blog/big-data/migrando-de-pandas-spark-dataframes"}, {"url": "https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html", "anchor_text": "Databricks"}, {"url": "https://databricks.com/blog/2017/08/31/cost-based-optimizer-in-apache-spark-2-2.html", "anchor_text": "Catalyst"}, {"url": "https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html", "anchor_text": "Databricks"}, {"url": "https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html", "anchor_text": "example"}, {"url": "https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html", "anchor_text": "https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html"}, {"url": "https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html", "anchor_text": "https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html"}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617", "anchor_text": "this article."}, {"url": "https://www.freepik.com/free-vector/website-setup-illustration-concept_6193236.htm#page=1&query=install&position=12", "anchor_text": "Freepik"}, {"url": "https://www.continuum.io/downloads", "anchor_text": "Anaconda"}, {"url": "https://www.freepik.com/free-vector/programmer-concept-illustration_8611162.htm#page=1&query=programming&position=6", "anchor_text": "Freepik"}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html", "anchor_text": "official documentation"}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "Titanic: Machine Learning from DisasterStart here! Predict survival on the Titanic and get familiar with ML basicswww.kaggle.com"}, {"url": "https://spark.apache.org/docs/latest/ml-features#stringindexer", "anchor_text": "StringIndexer"}, {"url": "https://spark.apache.org/docs/latest/ml-features#vectorassembler", "anchor_text": "VectorAssembler"}, {"url": "https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier", "anchor_text": "Random Forest Classifier"}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html#estimators", "anchor_text": "estimator"}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html#transformers", "anchor_text": "transformer"}, {"url": "https://en.wikipedia.org/wiki/Accuracy_and_precision", "anchor_text": "accuracy"}, {"url": "https://github.com/FavioVazquez/first_spark_model", "anchor_text": "FavioVazquez/first_spark_modelYour first Apache Spark model :). Contribute to FavioVazquez/first_spark_model development by creating an account on\u2026github.com"}, {"url": "https://www.linkedin.com/company/closter/", "anchor_text": "Closter"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d2bb82b599dd---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----d2bb82b599dd---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d2bb82b599dd---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/technology?source=post_page-----d2bb82b599dd---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----d2bb82b599dd---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2bb82b599dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=-----d2bb82b599dd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2bb82b599dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=-----d2bb82b599dd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2bb82b599dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe8ec6fa4d7d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=post_page-e8ec6fa4d7d4----d2bb82b599dd---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe5c1070d2e27&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&newsletterV3=e8ec6fa4d7d4&newsletterV3Id=e5c1070d2e27&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=-----d2bb82b599dd---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Written by Favio V\u00e1zquez"}, {"url": "https://medium.com/@faviovazquez/followers?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "9K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe8ec6fa4d7d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=post_page-e8ec6fa4d7d4----d2bb82b599dd---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe5c1070d2e27&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-apache-spark-ml-model-d2bb82b599dd&newsletterV3=e8ec6fa4d7d4&newsletterV3Id=e5c1070d2e27&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=-----d2bb82b599dd---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617?source=author_recirc-----d2bb82b599dd----0---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=author_recirc-----d2bb82b599dd----0---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=author_recirc-----d2bb82b599dd----0---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Favio V\u00e1zquez"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d2bb82b599dd----0---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617?source=author_recirc-----d2bb82b599dd----0---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "How to use PySpark on your computerI\u2019ve found that is a little difficult to get started with Apache Spark (this will focus on PySpark) on your local machine for most people\u2026"}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617?source=author_recirc-----d2bb82b599dd----0---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "4 min read\u00b7Apr 17, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c7180075617&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-pyspark-on-your-computer-9c7180075617&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=-----9c7180075617----0-----------------clap_footer----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-use-pyspark-on-your-computer-9c7180075617?source=author_recirc-----d2bb82b599dd----0---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c7180075617&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-pyspark-on-your-computer-9c7180075617&source=-----d2bb82b599dd----0-----------------bookmark_preview----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2bb82b599dd----1---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d2bb82b599dd----1---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d2bb82b599dd----1---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d2bb82b599dd----1---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2bb82b599dd----1---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2bb82b599dd----1---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d2bb82b599dd----1---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----d2bb82b599dd----1-----------------bookmark_preview----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2bb82b599dd----2---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d2bb82b599dd----2---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d2bb82b599dd----2---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d2bb82b599dd----2---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2bb82b599dd----2---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2bb82b599dd----2---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d2bb82b599dd----2---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d2bb82b599dd----2-----------------bookmark_preview----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd?source=author_recirc-----d2bb82b599dd----3---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=author_recirc-----d2bb82b599dd----3---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=author_recirc-----d2bb82b599dd----3---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Favio V\u00e1zquez"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d2bb82b599dd----3---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd?source=author_recirc-----d2bb82b599dd----3---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "Deep Learning With Apache Spark \u2014 Part 1First part on a full discussion on how to do Distributed Deep Learning with Apache Spark. This part: What is Spark, basics on Spark+DL and\u2026"}, {"url": "https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd?source=author_recirc-----d2bb82b599dd----3---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": "8 min read\u00b7Apr 9, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6d397c16abd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-with-apache-spark-part-1-6d397c16abd&user=Favio+V%C3%A1zquez&userId=e8ec6fa4d7d4&source=-----6d397c16abd----3-----------------clap_footer----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd?source=author_recirc-----d2bb82b599dd----3---------------------603f483b_8a19_4df7_b8db_c0ee1c43419b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d397c16abd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-with-apache-spark-part-1-6d397c16abd&source=-----d2bb82b599dd----3-----------------bookmark_preview----603f483b_8a19_4df7_b8db_c0ee1c43419b-------", "anchor_text": ""}, {"url": "https://medium.com/@faviovazquez?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "See all from Favio V\u00e1zquez"}, {"url": "https://towardsdatascience.com/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d2bb82b599dd----0-----------------bookmark_preview----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/@weiyunna91?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/@weiyunna91?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "YUNNA WEI"}, {"url": "https://medium.com/trigger-ai?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Efficient Data+AI Stack"}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "MLOps in Practice \u2014 Machine Learning (ML) model deployment patterns (Part 1)Machine Learning (ML) model serving and deployment is one of the most critical components of any solid ML solution architecture. This\u2026"}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "\u00b711 min read\u00b7Jan 26"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftrigger-ai%2Fce7cb575feda&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ftrigger-ai%2Fmlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda&user=YUNNA+WEI&userId=4b47aa84fc4&source=-----ce7cb575feda----1-----------------clap_footer----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce7cb575feda&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ftrigger-ai%2Fmlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda&source=-----d2bb82b599dd----1-----------------bookmark_preview----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Anuj Syal"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "12 Must-Have Skills to become a Data EngineerThe Essential Skills for a Successful Data Engineering Career"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "\u00b78 min read\u00b7Jan 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&user=Anuj+Syal&userId=df3997c527b4&source=-----35b100dbee0a----0-----------------clap_footer----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----d2bb82b599dd----0---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&source=-----d2bb82b599dd----0-----------------bookmark_preview----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/machine-learning-orchestration-using-apache-airflow-beginner-level-e4939492568c?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://iamstevegeorge.medium.com/?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://iamstevegeorge.medium.com/?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Steve George"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/machine-learning-orchestration-using-apache-airflow-beginner-level-e4939492568c?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Machine Learning Orchestration using Apache Airflow -Beginner levelIn this article, we will create an ML training pipeline and orchestrate it with the help of Apache Airflow. We will first extract the data\u2026"}, {"url": "https://medium.datadriveninvestor.com/machine-learning-orchestration-using-apache-airflow-beginner-level-e4939492568c?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "\u00b79 min read\u00b7Feb 8"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2Fe4939492568c&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fmachine-learning-orchestration-using-apache-airflow-beginner-level-e4939492568c&user=Steve+George&userId=73955688ba37&source=-----e4939492568c----1-----------------clap_footer----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/machine-learning-orchestration-using-apache-airflow-beginner-level-e4939492568c?source=read_next_recirc-----d2bb82b599dd----1---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4939492568c&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fmachine-learning-orchestration-using-apache-airflow-beginner-level-e4939492568c&source=-----d2bb82b599dd----1-----------------bookmark_preview----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d2bb82b599dd----2---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----d2bb82b599dd----2---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----d2bb82b599dd----2---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----d2bb82b599dd----2---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d2bb82b599dd----2---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d2bb82b599dd----2---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----2-----------------clap_footer----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d2bb82b599dd----2---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----d2bb82b599dd----2-----------------bookmark_preview----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-test-pyspark-etl-data-pipeline-1c5a6ab6a04b?source=read_next_recirc-----d2bb82b599dd----3---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/@edwin.tan?source=read_next_recirc-----d2bb82b599dd----3---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/@edwin.tan?source=read_next_recirc-----d2bb82b599dd----3---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Edwin Tan"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d2bb82b599dd----3---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-test-pyspark-etl-data-pipeline-1c5a6ab6a04b?source=read_next_recirc-----d2bb82b599dd----3---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "How to Test PySpark ETL Data PipelineValidate big data pipeline with Great Expectations"}, {"url": "https://towardsdatascience.com/how-to-test-pyspark-etl-data-pipeline-1c5a6ab6a04b?source=read_next_recirc-----d2bb82b599dd----3---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": "\u00b76 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1c5a6ab6a04b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-test-pyspark-etl-data-pipeline-1c5a6ab6a04b&user=Edwin+Tan&userId=484e02c96aa7&source=-----1c5a6ab6a04b----3-----------------clap_footer----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-test-pyspark-etl-data-pipeline-1c5a6ab6a04b?source=read_next_recirc-----d2bb82b599dd----3---------------------9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c5a6ab6a04b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-test-pyspark-etl-data-pipeline-1c5a6ab6a04b&source=-----d2bb82b599dd----3-----------------bookmark_preview----9d8b22ab_478b_4111_9afa_c1eb8cfff5b2-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----d2bb82b599dd--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}