{"url": "https://towardsdatascience.com/must-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d", "time": 1682988194.2570271, "path": "towardsdatascience.com/must-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d/", "webpage": {"metadata": {"title": "Must know Information Theory concepts in Deep Learning (AI) | by Abhishek Parbhakar | Towards Data Science", "h1": "Must know Information Theory concepts in Deep Learning (AI)", "description": "Information theory is an important field that has made significant contribution to deep learning and AI, and yet is unknown to many. Information theory can be seen as a sophisticated amalgamation of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/3faa5cdb7ab4?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Abhishek Parbhakar", "paragraph_index": 28}], "all_paragraphs": ["Information theory is an important field that has made significant contribution to deep learning and AI, and yet is unknown to many. Information theory can be seen as a sophisticated amalgamation of basic building blocks of deep learning: calculus, probability and statistics. Some examples of concepts in AI that come from Information theory or related fields:", "In the early 20th century, scientists and engineers were struggling with the question: \u201cHow to quantify the information? Is there a analytical way or a mathematical measure that can tell us about the information content?\u201d. For example, consider below two sentences:", "It is not difficult to tell that the second sentence gives us more information since it also tells that Bruno is \u201cbig\u201d and \u201cbrown\u201d in addition to being a \u201cdog\u201d. How can we quantify the difference between two sentences? Can we have a mathematical measure that tells us how much more information second sentence have as compared to the first?", "Scientists were struggling with these questions. Semantics, domain and form of data only added to the complexity of the problem. Then, mathematician and engineer Claude Shannon came up with the idea of \u201cEntropy\u201d that changed our world forever and marked the beginning of \u201cDigital Information Age\u201d.", "Shannon proposed that the \u201csemantic aspects of data are irrelevant\u201d, and nature and meaning of data doesn\u2019t matter when it comes to information content. Instead he quantified information in terms of probability distribution and \u201cuncertainty\u201d. Shannon also introduced the term \u201cbit\u201d, that he humbly credited to his colleague John Tukey. This revolutionary idea not only laid the foundation of Information Theory but also opened new avenues for progress in fields like artificial intelligence.", "Below we discuss four popular, widely used and must known Information theoretic concepts in deep learning and data sciences:", "Also called Information Entropy or Shannon Entropy.", "Entropy gives a measure of uncertainty in an experiment. Let\u2019s consider two experiments:", "If we compare the two experiments, in exp 2 it is easier to predict the outcome as compared to exp 1. So, we can say that exp 1 is inherently more uncertain/unpredictable than exp 2. This uncertainty in the experiment is measured using entropy.", "Therefore, if there is more inherent uncertainty in the experiment then it has higher entropy. Or lesser the experiment is predictable more is the entropy. The probability distribution of experiment is used to calculate the entropy.", "A deterministic experiment, which is completely predictable, say tossing a coin with P(H)=1, has entropy zero. An experiment which is completely random, say rolling fair dice, is least predictable, has maximum uncertainty, and has the highest entropy among such experiments.", "Another way to look at entropy is the average information gained when we observe outcomes of an random experiment. The information gained for a outcome of an experiment is defined as a function of probability of occurrence of that outcome. More the rarer is the outcome, more is the information gained from observing it.", "For example, in an deterministic experiment, we always know the outcome, so no new information gained is here from observing the outcome and hence entropy is zero.", "For a discrete random variable X, with possible outcomes (states) x_1,\u2026,x_n the entropy, in unit of bits, is defined as:", "where p(x_i) is the probability of i^th outcome of X.", "Cross entropy is used to compare two probability distributions. It tells us how similar two distributions are.", "Cross entropy between two probability distributions p and q defined over same set of outcomes is given by:", "Mutual information is a measure of mutual dependency between two probability distributions or random variables. It tells us how much information about one variable is carried by the another variable.", "Mutual information captures dependency between random variables and is more generalized than vanilla correlation coefficient, which captures only the linear relationship.", "Mutual information of two discrete random variables X and Y is defined as:", "where p(x,y) is the joint probability distribution of X and Y, and p(x) and p(y) are the marginal probability distribution of X and Y respectively.", "KL divergence is another measure to find similarities between two probability distributions. It measures how much one distribution diverges from the other.", "Suppose, we have some data and true distribution underlying it is \u2018P\u2019. But we don\u2019t know this \u2018P\u2019, so we choose a new distribution \u2018Q\u2019 to approximate this data. Since \u2018Q\u2019 is just an approximation, it won\u2019t be able to approximate the data as good as \u2018P\u2019 and some information loss will occur. This information loss is given by KL divergence.", "KL divergence between \u2018P\u2019 and \u2018Q\u2019 tells us how much information we lose when we try to approximate data given by \u2018P\u2019 with \u2018Q\u2019.", "KL divergence of a probability distribution Q from another probability distribution P is defined as:", "KL divergence is commonly used in unsupervised machine learning technique Variational Autoencoders.", "Information Theory was originally formulated by mathematician and electrical engineer Claude Shannon in his seminal paper \u201cA Mathematical Theory of Communication\u201d in 1948.", "Note: Terms experiments, random variable & AI, machine learning, deep learning, data science have been used loosely above but have technically different meanings.", "In case you liked the article, do follow me Abhishek Parbhakar for more articles related to AI, philosophy and economics.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe54a5da9769d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@abhishek.parbhakar?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@abhishek.parbhakar?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Abhishek Parbhakar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3faa5cdb7ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&user=Abhishek+Parbhakar&userId=3faa5cdb7ab4&source=post_page-3faa5cdb7ab4----e54a5da9769d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe54a5da9769d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe54a5da9769d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/u/3faa5cdb7ab4?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Abhishek Parbhakar"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e54a5da9769d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e54a5da9769d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----e54a5da9769d---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/information-theory?source=post_page-----e54a5da9769d---------------information_theory-----------------", "anchor_text": "Information Theory"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----e54a5da9769d---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe54a5da9769d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&user=Abhishek+Parbhakar&userId=3faa5cdb7ab4&source=-----e54a5da9769d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe54a5da9769d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&user=Abhishek+Parbhakar&userId=3faa5cdb7ab4&source=-----e54a5da9769d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe54a5da9769d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe54a5da9769d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e54a5da9769d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e54a5da9769d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e54a5da9769d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e54a5da9769d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@abhishek.parbhakar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@abhishek.parbhakar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Abhishek Parbhakar"}, {"url": "https://medium.com/@abhishek.parbhakar/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.1K Followers"}, {"url": "http://www.linkedin.com/in/abhishek-parbhakar", "anchor_text": "www.linkedin.com/in/abhishek-parbhakar"}, {"url": "https://topmate.io/abhishek_parbhakar", "anchor_text": "https://topmate.io/abhishek_parbhakar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3faa5cdb7ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&user=Abhishek+Parbhakar&userId=3faa5cdb7ab4&source=post_page-3faa5cdb7ab4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8dce0cfde9f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmust-know-information-theory-concepts-in-deep-learning-ai-e54a5da9769d&newsletterV3=3faa5cdb7ab4&newsletterV3Id=8dce0cfde9f7&user=Abhishek+Parbhakar&userId=3faa5cdb7ab4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}