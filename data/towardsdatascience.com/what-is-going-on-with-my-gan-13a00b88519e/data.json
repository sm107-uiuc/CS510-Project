{"url": "https://towardsdatascience.com/what-is-going-on-with-my-gan-13a00b88519e", "time": 1683010844.561131, "path": "towardsdatascience.com/what-is-going-on-with-my-gan-13a00b88519e/", "webpage": {"metadata": {"title": "What is going on with my GAN? - Part 1 | Towards Data Science", "h1": "What is going on with my GAN?", "description": "GANs is a novel class of deep generative models, that have gained a lot of attention, but how can we handle with challenges such as mode collapse and non-convergence?"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-1-866705a77302?source=friends_link&sk=beee724f8445a7f9ed66aaf41660325c", "anchor_text": "Tabular synthetic data", "paragraph_index": 0}, {"url": "https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-1-866705a77302?source=friends_link&sk=beee724f8445a7f9ed66aaf41660325c", "anchor_text": "Tabular synthetic dat", "paragraph_index": 0}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "synthesize tabular data", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/2005.00065.pdf", "anchor_text": "article about GANs challenges, solutions, and future", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1705.07215.pdf", "anchor_text": "GANs convergence and stability", "paragraph_index": 11}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "synthetic data creation", "paragraph_index": 14}, {"url": "https://www.researchgate.net/publication/337876790_AN_ANALYSIS_OF_EVALUATION_METRICS_OF_GANS", "anchor_text": "GANs evaluation metrics", "paragraph_index": 14}, {"url": "https://arxiv.org/abs/1411.1784", "anchor_text": "CGAN", "paragraph_index": 18}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "VAE-GAN", "paragraph_index": 18}, {"url": "https://arxiv.org/pdf/1803.01500.pdf", "anchor_text": "Memory GAN", "paragraph_index": 18}, {"url": "https://arxiv.org/pdf/1803.01500.pdf", "anchor_text": "Memory GAN", "paragraph_index": 19}, {"url": "https://arxiv.org/abs/1701.07875", "anchor_text": "WGAN", "paragraph_index": 21}, {"url": "https://arxiv.org/pdf/1704.00028.pdf", "anchor_text": "WGAN-GP", "paragraph_index": 21}, {"url": "https://arxiv.org/abs/1701.07875", "anchor_text": "WGAN", "paragraph_index": 21}, {"url": "https://arxiv.org/pdf/1705.10461.pdf", "anchor_text": "Simultaneous Gradient Descen", "paragraph_index": 22}, {"url": "https://www.linkedin.com/in/fabiana-clemente/", "anchor_text": "Fabiana Clemente", "paragraph_index": 25}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "YData", "paragraph_index": 25}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "YData helps data science teams deliver ML models, simplifying data acquisition, so data scientists can focus their time on things that matter.", "paragraph_index": 27}], "all_paragraphs": ["Generative Adversarial Networks are a novel class of deep generative models, that have recently gained a lot of attention. I\u2019ve covered them in the past ( Tabular synthetic data \u2014 Part 1 and Tabular synthetic data \u2014 Part 2), in very general terms, and with particular attention to their application to synthesize tabular data. But today, the focus will be a bit different \u2014 in a series of articles, I\u2019ll be covering the challenges that you can find while training GANs, the most common solutions, and future directions in literature. This review was inspired by this amazing article about GANs challenges, solutions, and future \u2014 I strongly advise you to have a deeper look.", "Generative models have been widely used in the latest years in a broad and varied number of real applications. Generative Models\u2019 can be defined as models that compute the density estimation where model distribution is learned to approximate the real data distribution.", "This brings some challenges, as researches have shown that maximum likelihood is not a good option \u2014 leads to overgeneralized and unplausible samples.", "Generative Adversarial Nets (GANs) can solve this by introducing a Discriminator network that brings the capacity to discriminate original data samples, and samples generated by a model.", "They have a wide scope of application, as they are able to learn implicitly over images, audio, and data which are challenging to model with an explicit likelihood.", "GANs can be very helpful and pretty disruptive in some areas of application, but, as in everything, it\u2019s a trade-off between their benefits and the challenges that we easily find while working with them. We can break down GANs challenges in 3 main problems:", "GANs can sometimes suffer from the limitation of generating samples with little representative of the population, which means that, for example, after training a GAN on the MNIST dataset, it may happen that our Generator is unable to generate digits different from digit 0. This condition is called mode collapse.", "The main drawback is related to the fact that GANs are to able to focus on the whole data distribution due to its objective function. Some experiments have shown that even for bi-modal distribution, GANs tend to produce a good fit to the principal mode, struggling to generalize. In summary, mode collapse is a consequence of poor generalization and can be classified into two different types:", "The causes for mode collapse can vary, from an ill-suited objective function to the impact of the chosen GAN architecture having in consideration the data under analysis. But fear no more, there are options to solve this many have been the efforts dedicated to this particular challenge.", "The fact that GANs are composed by two networks, and each one of them has its loss function, results in the fact that GANs are inherently unstable- diving a bit deeper into the problem, the Generator (G) loss can lead to the GAN instability, which can be the cause of the gradient vanishing problem when the Discriminator (D) can easily distinguish between real and fake samples.", "In GANs architecture, the D tries to minimize a cross-entropy while the G tries to maximize it. When D confidence is high and starts to reject the samples that are produced by G leads to G\u2019s gradient vanishes.", "This might refer to the hypothesis of the existence of local equilibria in the non-convex game that we are targeting when training GANs, as proposed in an article about GANs convergence and stability. There are some options already proposed in the literature to mitigate this problem, such as reversing the target employed for construction the cross-entropy cost or the application of gradient penalty to avoid local equilibria.", "No cost function will work without the selection of good hyperparameters, and GANs are not an exception they are even more sensitive to the selection of the network hyperparameters. The right selection of hyperparameters can be tedious and time-consuming, and so far the majority of the efforts have been in topics such as mode-collapse or GAN\u2019s struggles to converge.", "No cost function will work without the selection of good hyperparameters!", "Moreover, GANs lack meaningful measures to evaluate the quality of their output. Since its creation, GANs have been widely used with a variety of application areas, from supervised representation learning, semi-supervised learning, inpainting, denoising, and synthetic data creation. The extensive applications brings along a lot of heterogeneity, which makes it harder to define how we can evaluate the equality of these networks. Because there are no robust or consistent metrics defined, in particular for image generation, it is difficult to evaluate which GANs algorithms outperform others. A series of evaluation methods have been proposed in the literature, to overcome this challenge \u2014 you can find interesting details about GANs evaluation metrics in this article.", "Challenges covered, it\u2019s time to check the solutions that have been proposed and most widely applied to GANs.", "As mentioned before, although there are many challenges related to GANs training, there\u2019s a lot of research for mode collapse and non-convergence issues\u2019 solutions. The image below depicts an interesting taxonomy for GANs challenges solutions, which leaves us with a pretty good idea of the options that we\u2019ve available in literature.", "Further, will be covered the three main techniques to improve GANs training and overall results.", "Better design of GAN models architectures is definitely one valid option. In fact, there are several GANs in the literature that result from exploring new architectures to solve particular data challenges \u2014 for example, CGAN is a conditional version of the first proposed GAN architecture, that undoubtedly leads to better results when synthesizing data, on the other hand, VAE-GAN follows an encoder-encoder architecture, that leverages learned representations to better measure similarities in the data space which results to improved visual fidelity and, finally, for example, Memory GAN follows a memory architecture that can alleviate two of the main issues related to unsupervised learning, the ability of the Generators to learn correctly the representation of the training samples, and Discriminators to better memorize already seen generated samples.", "Memory GAN follows a memory architecture that can alleviate two of the main issues related to unsupervised learning", "In summary, in what concerns architecture re-engineering, the research positions the solutions as following:", "As the model parameters oscillate a lot, and can vary in a way that never converge, some have decided to explore new loss functions, to help GANs to reach a better optimum. In fact, several researchers have pointed out that the selection of the right loss function can effectively tackle the training instability. Improvements in the loss functions can be categorized as the proposal of a new probability distance and divergence, that can solve the mode collapse problem as it stabilized the GAN training as observed in WGAN or, with the introduction of Regularization or Gradient Penalty, as observed in WGAN-GP, which improved previously proposed WGAN, training stability.", "The concept behind GANs optimization is a min-max game, which often results in during the training process we are unable to find a local nash-equilibria, meaning, they fail to converge. In some articles found in the literature the use of Simultaneous Gradient Descent has been proposed, leading to a more stable training and improved convergence even on GAN architectures that are known to be hard to train.", "Congratulations! In a nutshell, you\u2019ve learned about the most commons challenges found when working with GANs along with some of the most commonly proposed solutions in the literature! From this review, it\u2019s possible to understand that, although there are many challenges to be solved when working with GANs, they are without a doubt one of the most important findings in the area of Machine Learning in the latest years.", "Hopefully, this review inspires you to start digging these amazing algorithms and explore new applications!", "Fabiana Clemente is Chief Data Officer at YData.", "Making data available with privacy by design.", "YData helps data science teams deliver ML models, simplifying data acquisition, so data scientists can focus their time on things that matter.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Passionate for data. Thriving for the development of data privacy solutions while unlocking new data sources for data scientists at @YData"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F13a00b88519e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----13a00b88519e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----13a00b88519e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@fabiana_clemente?source=post_page-----13a00b88519e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabiana_clemente?source=post_page-----13a00b88519e--------------------------------", "anchor_text": "Fabiana Clemente"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff957353899a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&user=Fabiana+Clemente&userId=f957353899a&source=post_page-f957353899a----13a00b88519e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13a00b88519e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13a00b88519e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-1-866705a77302?source=friends_link&sk=beee724f8445a7f9ed66aaf41660325c", "anchor_text": "Tabular synthetic data"}, {"url": "https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-1-866705a77302?source=friends_link&sk=beee724f8445a7f9ed66aaf41660325c", "anchor_text": "Tabular synthetic dat"}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "synthesize tabular data"}, {"url": "https://arxiv.org/pdf/2005.00065.pdf", "anchor_text": "article about GANs challenges, solutions, and future"}, {"url": "https://arxiv.org/pdf/1612.02136.pdf", "anchor_text": "https://arxiv.org/pdf/1612.02136.pdf"}, {"url": "https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/", "anchor_text": "https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/"}, {"url": "https://arxiv.org/pdf/1705.07215.pdf", "anchor_text": "GANs convergence and stability"}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "synthetic data creation"}, {"url": "https://www.researchgate.net/publication/337876790_AN_ANALYSIS_OF_EVALUATION_METRICS_OF_GANS", "anchor_text": "GANs evaluation metrics"}, {"url": "https://arxiv.org/pdf/2005.00065.pdf", "anchor_text": "https://arxiv.org/pdf/2005.00065.pdf"}, {"url": "https://arxiv.org/abs/1411.1784", "anchor_text": "CGAN"}, {"url": "https://arxiv.org/abs/1512.09300", "anchor_text": "VAE-GAN"}, {"url": "https://arxiv.org/pdf/1803.01500.pdf", "anchor_text": "Memory GAN"}, {"url": "https://arxiv.org/pdf/1803.01500.pdf", "anchor_text": "Memory GAN"}, {"url": "https://arxiv.org/abs/1701.07875", "anchor_text": "WGAN"}, {"url": "https://arxiv.org/pdf/1704.00028.pdf", "anchor_text": "WGAN-GP"}, {"url": "https://arxiv.org/abs/1701.07875", "anchor_text": "WGAN"}, {"url": "https://arxiv.org/pdf/1705.10461.pdf", "anchor_text": "Simultaneous Gradient Descen"}, {"url": "https://github.com/whyjay/memoryGAN", "anchor_text": "https://github.com/whyjay/memoryGAN"}, {"url": "https://github.com/kozistr/Awesome-GANs/tree/master/CGAN", "anchor_text": "https://github.com/kozistr/Awesome-GANs/tree/master/CGAN"}, {"url": "https://github.com/crmaximo/VAEGAN", "anchor_text": "https://github.com/crmaximo/VAEGAN"}, {"url": "https://github.com/martinarjovsky/WassersteinGAN", "anchor_text": "https://github.com/martinarjovsky/WassersteinGAN"}, {"url": "https://github.com/caogang/wgan-gp", "anchor_text": "https://github.com/caogang/wgan-gp"}, {"url": "https://www.linkedin.com/in/fabiana-clemente/", "anchor_text": "Fabiana Clemente"}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "YData"}, {"url": "https://ydata.ai/?utm_source=medium&utm_medium=signature&utm_campaign=blog", "anchor_text": "YData helps data science teams deliver ML models, simplifying data acquisition, so data scientists can focus their time on things that matter."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----13a00b88519e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----13a00b88519e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----13a00b88519e---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----13a00b88519e---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----13a00b88519e---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F13a00b88519e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&user=Fabiana+Clemente&userId=f957353899a&source=-----13a00b88519e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F13a00b88519e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&user=Fabiana+Clemente&userId=f957353899a&source=-----13a00b88519e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13a00b88519e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----13a00b88519e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F13a00b88519e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----13a00b88519e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----13a00b88519e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----13a00b88519e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----13a00b88519e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----13a00b88519e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----13a00b88519e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----13a00b88519e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----13a00b88519e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----13a00b88519e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabiana_clemente?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabiana_clemente?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Fabiana Clemente"}, {"url": "https://medium.com/@fabiana_clemente/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "777 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff957353899a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&user=Fabiana+Clemente&userId=f957353899a&source=post_page-f957353899a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd7ddbab12422&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-going-on-with-my-gan-13a00b88519e&newsletterV3=f957353899a&newsletterV3Id=d7ddbab12422&user=Fabiana+Clemente&userId=f957353899a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}