{"url": "https://towardsdatascience.com/visualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5", "time": 1682995969.222025, "path": "towardsdatascience.com/visualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5/", "webpage": {"metadata": {"title": "Visualizing Relationships between Loss Functions and Gradient Descent | by Hugegene | Towards Data Science", "h1": "Visualizing Relationships between Loss Functions and Gradient Descent", "description": "Visualize the relationships when performing Gradient Descend and Back propagation on Loss functions and Activation functions."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["This article assumes you have prior knowledge on training Neural Net and seeks to demystify the relationships between Loss function, Gradient Descent and Backpropagation through visualisation.", "The figure on the left shows the relationship between a loss function and gradient descent.", "To visualise gradient descent, imagine an example that is over-simplified to a neural net\u2019s last node outputting a weight number, w, and the target is 0. The Loss function, in this case, is Mean Square Error (MSE).", "The derivative of MSE, dy/dw, is positive when w is bigger than 0. A positive dy/dw can be interpreted as a positive step in w will result in a positive change in y. To lead to a decrease in loss, a negative step in the w direction is needed:", "When w is smaller than 0, dy/dw of MSE is negative and it implies that a positive step in w will result in a negative change in y. To lead to a decrease in loss, a positive step in the w direction is needed:", "Hence the formula that summarized the update of weight is as follows:", "where learning_rate is a constant that adjusts how much percentage of the derivative should be stepped. Learning_rate should be adjusted to prevent w from taking too small a step or too big a step. Learning_rate should also be adjusted to prevent gradient explosion (too big a gradient) or vanishing gradient problem (too small a gradient).", "For a longer and more realistic computation graph where the weight is behind a sigmoid activation, to update the weight w1, the derivative of loss with respect to w1 can be found as follows:", "As seen from the illustrated steps above, the weight in the neural net is revised or backpropagated by the derivative of the Loss function and not by the loss function. The loss function does not contribute to the backpropagation.", "The derivative of MSE (L2 loss) has a magnitude of 2w. The changes in the magnitude of the derivative of MSE help to backpropagate a bigger step to w when w is far away from target 0 and smaller step to w when w is closer to target 0", "Mean Absolute Error (MAE)(L1 loss) has a constant derivative of 1 or negative 1, which may not be ideal in differentiating how far is w from the target. Backpropagation only uses the derivative of the loss function and does not use the loss function.", "Cross-Entropy loss only concerns the domain of w in between 0 and 1. As w approaches 1, Cross-Entropy decrease to 0. The derivative of Cross-Entropy is -1/w.", "Sigmoid function has a derivative of range in between 0 and 0.25. Multiple products of the derivatives of sigmoid functions may result in a very small number close to 0 and this makes backpropagation useless. This is known as the vanishing gradient problem.", "Relu makes a good activation function as the derivative is 1 or 0, allowing a constant update to the weights or 0 updates to the weights in backpropagation.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F312a3963c9a5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://eugene-chian.medium.com/?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": ""}, {"url": "https://eugene-chian.medium.com/?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "Hugegene"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2f6311f540e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&user=Hugegene&userId=2f6311f540e9&source=post_page-2f6311f540e9----312a3963c9a5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F312a3963c9a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F312a3963c9a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/tag/gradient-descent?source=post_page-----312a3963c9a5---------------gradient_descent-----------------", "anchor_text": "Gradient Descent"}, {"url": "https://medium.com/tag/backpropagation?source=post_page-----312a3963c9a5---------------backpropagation-----------------", "anchor_text": "Backpropagation"}, {"url": "https://medium.com/tag/loss?source=post_page-----312a3963c9a5---------------loss-----------------", "anchor_text": "Loss"}, {"url": "https://medium.com/tag/activation-functions?source=post_page-----312a3963c9a5---------------activation_functions-----------------", "anchor_text": "Activation Functions"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----312a3963c9a5---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F312a3963c9a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&user=Hugegene&userId=2f6311f540e9&source=-----312a3963c9a5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F312a3963c9a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&user=Hugegene&userId=2f6311f540e9&source=-----312a3963c9a5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F312a3963c9a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F312a3963c9a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----312a3963c9a5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----312a3963c9a5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----312a3963c9a5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----312a3963c9a5--------------------------------", "anchor_text": ""}, {"url": "https://eugene-chian.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://eugene-chian.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Hugegene"}, {"url": "https://eugene-chian.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "119 Followers"}, {"url": "https://www.linkedin.com/in/eugene-c-616768142/", "anchor_text": "https://www.linkedin.com/in/eugene-c-616768142/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2f6311f540e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&user=Hugegene&userId=2f6311f540e9&source=post_page-2f6311f540e9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcb798ef7a5f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualising-relationships-between-loss-activation-functions-and-gradient-descent-312a3963c9a5&newsletterV3=2f6311f540e9&newsletterV3Id=cb798ef7a5f1&user=Hugegene&userId=2f6311f540e9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}