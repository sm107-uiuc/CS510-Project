{"url": "https://towardsdatascience.com/solving-the-ai-accountability-gap-dd35698249fe", "time": 1682995664.235466, "path": "towardsdatascience.com/solving-the-ai-accountability-gap-dd35698249fe/", "webpage": {"metadata": {"title": "Solving the AI Accountability Gap | by Matt Bartlett | Towards Data Science", "h1": "Solving the AI Accountability Gap", "description": "Yesterday, a leaked white paper from the United Kingdom government suggested that social media executives could be held legally responsible for harmful content proliferating on their platform\u2019s\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.theguardian.com/technology/2019/apr/04/social-media-bosses-could-be-liable-for-harmful-content-leaked-uk-plan-reveals", "anchor_text": "suggested that", "paragraph_index": 0}, {"url": "https://www.academia.edu/37924523/Do_We_Need_New_Legal_Personhood_in_the_Age_of_Robots_and_AI", "anchor_text": "with some experts suggesting", "paragraph_index": 3}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "fiendishly difficult", "paragraph_index": 10}, {"url": "https://www.bbc.com/news/technology-44640959", "anchor_text": "cough", "paragraph_index": 17}, {"url": "https://www.acc.co.nz/", "anchor_text": "New Zealand\u2019s ACC system", "paragraph_index": 21}, {"url": "https://www.tu-auto.com/how-many-lives-could-self-driving-cars-save-this-tool-predicts-it/", "anchor_text": "many lives might be saved", "paragraph_index": 21}, {"url": "https://technocracy.substack.com/", "anchor_text": "https://technocracy.substack.com/", "paragraph_index": 27}], "all_paragraphs": ["Yesterday, a leaked white paper from the United Kingdom government suggested that social media executives could be held legally responsible for harmful content proliferating on their platform\u2019s algorithms. This proposal aims to address one of the single biggest problems brought about by autonomous decision-making: who should be blamed when an AI causes harm?", "This \u2018accountability gap\u2019 is a worse problem than it might first seem. Our legal system is built on a fundamental assumption of human agents. Replacing human actors with autonomous agents (self-driving cars, social media algorithms and other kinds of AI) throws that system into disarray. This accountability gap causes problems in three areas: causality, justice, and compensation.", "When someone shoots and kills another person with a gun, the causality from a legal perspective is generally pretty simple: the human that made the decision to pull the trigger is the greatest \u2018cause\u2019 of the other\u2019s death, and is dealt with by the legal system accordingly. But that process of legal accountability is thrown into disarray when an AI autonomously makes a decision that causes harm to a person.", "Take a self-driving car. Even if the vehicle makes a completely autonomous decision to leave a motorway at high speed and crash (perhaps foreseeing an oncoming crash, and preferring to take evasive action), you obviously cannot drag that self-driving car in front of a court to force it to face justice. And even if you could (with some experts suggesting AI programs be given legal personhood, meaning in theory they would be able to be dragged in front of a court), there is no precedent or process for establishing causality.", "Can it really be said that the autonomous system\u2019s decision making was the \u2018greatest cause\u2019 in causing the death of the passenger, as opposed to the developer, the manufacturer, or the chief executive? I\u2019m not so sure.", "Similarly, the penalties and remedies of the legal system are for the most part built to be levelled against humans, not autonomous computer programs. Far from being an appendix to the legal process, the ability to impose effective penalties to those who break the law is absolutely crucial to the underlying justice of the system. In order to be credible, it\u2019s vital that the legal system can punish wrongdoing proportionately and effectively.", "Put another way, if murderers were sentenced to absurd \u2018punishments\u2019 that didn\u2019t affect their lives in any meaningful way, the justice system would lose its value as a deterrent, and the moral credibility built on the principle that justice is done. And that captures the problem posed by AI: you can\u2019t throw an AI in jail, or impose a fine on it, or make it pay compensation - no matter whether it has legal personhood or not. None of the legal system\u2019s penalties or remedies work on autonomous computer programs. And without effective penalties or remedies, our legal system loses that underlying foundation of justice.", "Justice for victims doesn\u2019t just include an effective punishment for the person who inflicted harm - in many cases victims seek some kind of monetary compensation for loss suffered, even if just the recouping of legal costs. A general legal principle is that someone who suffered harm should be placed in the position they would have been in had the act not been committed. So if an autonomous medical device, like a robotic surgery tool, were to malfunction and harm a patient, that patient ought to be able to pursue compensation in the legal system to pay for medical care.", "Again, our legal system struggles to apply a general principle (in this case, victim compensation) where the harm is inflicted by an autonomous agent. It\u2019s obviously impossible for a court to compel an AI - a computer program - to pay thousands of dollars to a victim to cover their medical costs. So in order for victims to have any recourse in the legal system, they have to be able to pursue a human (or, at least, a business) with the capacity to pay compensation. Consequently, the \u2018accountability gap\u2019 adds serious difficulty to victims looking to receive compensation through the legal system.", "These issues of causality, justice and compensation are interlinked, and collectively present a huge challenge to our legal system. For the system to remain credible and just, there is a fundamental need to fill the AI accountability gap somehow: to attribute AI-related harm to a human or group of humans in the first instance.", "This necessity of tying an AI\u2019s actions (and any consequential harm) to a human, or group of humans, presents us with issues of fairness. The decision-making of contemporary AI systems is fiendishly difficult to understand or explain - even for the developers and coders responsible for programming it. AI algorithms and processes are so complex that autonomous decision-making is sometimes likened to a black box. In the context of that complication, is it really fair to hold a human legally accountable?", "In short: yes. My view is that AI developers - defined as the person or group of people who directly shaped the programming of the AI - should be held legally responsible at first instance for the actions (and any harm) caused by that AI\u2019s decision-making.", "Morally, AI developers are the group most responsible for the decisions made by an AI. Despite the black box dynamic captured above, if any party ought to have been able to foresee future harm caused by an AI, it is the group that created the AI\u2019s decision-making capacity out of nothing.", "One (not unreasonable) analogy is that of a misbehaving child who causes a tantrum in a store and destroys some products - we would reasonably expect the child\u2019s parents to pay for the destroyed products, even though they didn\u2019t do the damage themselves and couldn\u2019t be said to fully understand why the child inflicted the damage. Developers, like those parents, are in the best position to prevent the harm, even if they lack full control over their creation, and a moral responsibility flows from that dynamic.", "Practically, the same developers are also the actors with by far the strongest position to actively take steps around risk management and security measures with respect to the complicated process of creating the AI. The imposition of legal liability on AI developers, like this piece proposes, creates a strong incentive on that group to strengthen security measures and adhere to a more stringent risk mitigation framework.", "This kind of healthy incentive doesn\u2019t occur to the same extent if a group like regulators or manufacturers are held responsible for AI at the first instance, as they have far less direct control over the way the AI has been developed. AI developers have the power to make AI safer, and my proposal aligns their personal incentives with that responsibility.", "In practice, I imagine this proposal looks like a \u2018rebuttable presumption\u2019 that AI developers should have to face lawsuits by any victims of that particular AI. A rebuttable presumption is not the same thing as an admission of guilt: it just means that if an AI developer believes another party (like the chief executive of their organisation) is more responsible for harm caused by the AI, they have to prove that belief to a court in order to avoid responsibility.", "Take a hypothetical example (cough) of AI developers at a given social media giant, who create an algorithm designed to be as addictive as a slot machine. My rebuttable presumption allows someone who thinks they\u2019ve suffered harm from that algorithm to sue those developers. But if those developers could point to strong evidence that they were directly instructed by management to make the AI as addictive as possible, the lawsuit would instead fall at the feet of those growth-addicted managers.", "No matter whether the ultimate respondent to a case of AI harm is the developer or another party that the developer can point to, the problems associated with the AI accountability gap are addressed. The burden on establishing causation is placed on the developer (not the victim), justice can be achieved through effective penalties and remedies, and victims can seek compensation against a human party.", "There is no perfect solution to AI accountability. One of the biggest risks with the proposal to hold developers responsible is a chilling effect on AI development. After all, AI developers are often small actors - individuals or small companies. Whether or not they are the most culpable when their creations cause harm, the practical nightmare of facing lawsuits every time their AI causes damage might reasonably make AI developers exceedingly wary of releasing their creations into the world (and their hedge fund investors might pause before reaching for their chequebooks).", "Yet the threat of a chilling effect is not enough to outweigh the ethical and practical considerations described above. Many developers working for large tech giants will benefit from vicarious liability, meaning the tech giants will be forced to put their legal resources to the defence of their developers.", "We might ultimately see governments adopting \u2018no-fault\u2019 coverage policies (similar to New Zealand\u2019s ACC system for covering medical costs associated with accidents) to pay for AI-related lawsuits. Given how many lives might be saved with the deployment of self-driving cars, for instance, there are certainly strong incentives for the state to support the deployment of AI in this way. Victims would lose their ability to sue individual developers, but would receive acknowledgement of harm and their medical costs covered by the government.", "Alternatively, governments might reserve for themselves the ability to prosecute AI developers whose creations cause harm. This might be a more efficient system for taking the worst offenders to court. Victims of autonomous decisions can work through a dedicated body to bring developers to account, similar to how the police work with victims in a criminal context. This helps prevent the floodgates being opened, and helps stop garage-based AI coders from being drowned in civil lawsuits.", "What these thought experiments captures is that that the AI accountability gap can be solved - with a new presumption that the developers of AI are responsible in the first instance - without stalling the industry by bankrupting its coders.", "Judging from this month\u2019s leaked paper, the UK will suggest one way forward with the AI accountability gap: targeting chief executives of technology giants. This piece has laid out a different path, holding the developers responsible at first instance. In any case, it is growing more and more necessary to adapt our legal system so it can process cases with autonomous agents in a way that is morally and legally fair.", "Is this kind of structural course correction easy? Of course not. But it replaces an alarming accountability gap with a public policy debate, and that surely is a step in the right direction.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Writing about the intersection of technology and society at https://technocracy.substack.com/."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdd35698249fe&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd35698249fe--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd35698249fe--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mattjbartlett.medium.com/?source=post_page-----dd35698249fe--------------------------------", "anchor_text": ""}, {"url": "https://mattjbartlett.medium.com/?source=post_page-----dd35698249fe--------------------------------", "anchor_text": "Matt Bartlett"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa529686e9478&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&user=Matt+Bartlett&userId=a529686e9478&source=post_page-a529686e9478----dd35698249fe---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd35698249fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd35698249fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.theguardian.com/technology/2019/apr/04/social-media-bosses-could-be-liable-for-harmful-content-leaked-uk-plan-reveals", "anchor_text": "suggested that"}, {"url": "https://www.academia.edu/37924523/Do_We_Need_New_Legal_Personhood_in_the_Age_of_Robots_and_AI", "anchor_text": "with some experts suggesting"}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "fiendishly difficult"}, {"url": "https://www.bbc.com/news/technology-44640959", "anchor_text": "cough"}, {"url": "https://www.acc.co.nz/", "anchor_text": "New Zealand\u2019s ACC system"}, {"url": "https://www.tu-auto.com/how-many-lives-could-self-driving-cars-save-this-tool-predicts-it/", "anchor_text": "many lives might be saved"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----dd35698249fe---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/technology?source=post_page-----dd35698249fe---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dd35698249fe---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/future?source=post_page-----dd35698249fe---------------future-----------------", "anchor_text": "Future"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dd35698249fe---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd35698249fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&user=Matt+Bartlett&userId=a529686e9478&source=-----dd35698249fe---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd35698249fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&user=Matt+Bartlett&userId=a529686e9478&source=-----dd35698249fe---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd35698249fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd35698249fe--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdd35698249fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dd35698249fe---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd35698249fe--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dd35698249fe--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dd35698249fe--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dd35698249fe--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dd35698249fe--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dd35698249fe--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dd35698249fe--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dd35698249fe--------------------------------", "anchor_text": ""}, {"url": "https://mattjbartlett.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mattjbartlett.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Matt Bartlett"}, {"url": "https://mattjbartlett.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "https://technocracy.substack.com/", "anchor_text": "https://technocracy.substack.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa529686e9478&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&user=Matt+Bartlett&userId=a529686e9478&source=post_page-a529686e9478--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcb1cf3ee778a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-the-ai-accountability-gap-dd35698249fe&newsletterV3=a529686e9478&newsletterV3Id=cb1cf3ee778a&user=Matt+Bartlett&userId=a529686e9478&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}