{"url": "https://towardsdatascience.com/the-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c", "time": 1683015731.709988, "path": "towardsdatascience.com/the-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c/", "webpage": {"metadata": {"title": "The question of single unit semantics in deep networks | by Sofia Broom\u00e9 | Towards Data Science", "h1": "The question of single unit semantics in deep networks", "description": "A familiar hypothesis in deep learning is that a single higher-layer unit of a network may correspond to a complex semantic entity, such as a person or a specific type of dog [2, 9]. This has\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["A familiar hypothesis in deep learning is that a single higher-layer unit of a network may correspond to a complex semantic entity, such as a person or a specific type of dog [2, 9]. This has colloquially been referred to as grandmother cells or Homer Simpson cells.", "These names stem from neuroscience. It has been observed for the human brain that specific cortical cells in late stages of the visual pathway can activate when a person is shown any variant of a photograph of, for instance, Jennifer Aniston, as was done in the study by Quiroga et al. [6]. In the study, however, it was also found that the same response could be elicited by the printed name of Jennifer Aniston, indicating that the firing resulted from memory mechanisms rather than pure visual stimuli and geometric transformations thereof.", "The concept of grandmother cells has made an impression on the broad community of practitioners in deep learning, being both captivating and easy to grasp. Visualization methods of these cells have been presented, both network-based [2,7] and input-based [9].", "In deep learning papers, it is not uncommon to show these kinds of visualizations and assume that they are proof that the network has learned something sensible, e.g., [3].", "Whether this really is the case is what I intend to investigate in this blog post. For this purpose, I will mainly refer to three papers that represent three different perspectives on the matter. They are Visualizing and understanding convolutional neural networks by Zeiler & Fergus [9], Salient deconvolutional networks by Mahendran & Vedaldi [4], and On the importance of single directions for generalization by Morcos & Barrett [5].", "The first one is perhaps the most well-known paper that attempts to study the inner workings of convolutional networks. Here, deconvolutions (or transposed convolutions as they are also called) are used to project the feature activations of a certain filter back to the pixel space, in order to see what the neurons \u2018saw\u2019. We can refer to this as feature reconstruction.", "On the other hand, there is the method of activity maximization, which term was coined by Erhan et al. [2]. In activity maximization, optimization is performed over input noise to find the input which would result in maximal activation of one particular unit. Erhan et al. used this method to visualize the hidden units of deep belief networks.", "There is a crucial difference between activity maximization and feature reconstruction. The method of [9] is data-centric in the sense that natural images are input to the networks. In activity maximization, the input is only noise so as to not constrain the possible responses (although regularization can be applied on top of the noise to enforce smoothness). If feature reconstruction is data-centric, activity maximization is instead a network-centric method as it is the activation space of the network that is being studied.", "The method of feature reconstruction introduced in [9] was applied to specific units in a given layer in a network. The reconstructions were presented as if these neurons had semantic preferences.", "But the second paper I want to mention, by Mahendran et al. [4], questions this assumption by showing that when applying the same method of projecting the activations back to the pixel space from a randomly chosen neuron, the same reconstruction is obtained. Here, the concept of the information bottleneck is brought forward as a possible explanation as to why feature reconstructions from random units give virtually the same responses as from the maximally activating units. The idea is that the unique information created by the information bottleneck of the forward-pass is in fact the dominating response when recreating the features.", "Additionally, even prior to this, Szegedy et al. [8] question the semantic interpretation of single units and claim that semantics just as well can be found as a distributed code, across many units of a layer. This is shown by comparing feature reconstructions for a single maximally activating unit to that of a random (distributed) direction in the filter space: both show clear semantic grouping of their responses. Another paper by Agrawal et al. [1] runs experiments that show that among the highest activating units for a certain image, the more units that are kept for subsequent classification, the better the performance.", "The last paper is the one by Morcos & Barrett [5]. Their motivation is to investigate the role of grandmother cells, or single unit reliance, for generalization. They furthermore study whether neurons that activate for specific semantic concepts are important for the classification decisions of these networks.", "Among their results is that networks that generalize well in effect tend to minimize their reliance on single directions. This is found via accumulative ablations of units of a network. Non-generalizing networks (in the sense that they have memorized a training dataset with random labels, as per the experiment design) are less robust to these ablations. Furthermore, they investigate whether it matters if they ablate units that are class-selective or not (a metric for class-selectivity is introduced). On CIFAR-10, strikingly, it is slightly better to remove the class-selective units for the performance of the network. On ImageNet there is no preference at all between the non-selective and class selective directions.", "I have briefly gone through a selection of results on the topic of single unit semantics. We have seen that a neural network unit can have maximal* activation for a particular semantic concept (i.e. be class selective, within classification). However, this does not tell us about the general performance of the network or whether this unit is important. For this reason, as concluded in [5], it might be misleading to focus on class-selective units. Similarly to the results in [4], it would be interesting to see activity maximization for distributed sets of units, instead of for single units. It happens to be convenient to visualize what one unit activates the most for, but likely there are non-coordinate aligned directions in the activation space of a network that may contain findings that are at least as interesting. These other directions are just more difficult to put in a compelling story, and more difficult to investigate systematically.", "* In [2], it, however, seems that a global maximum is missing for data with complicated distributions such as images.", "[1] P. Agrawal, R. Girshick, and J. Malik, Analyzing the Performance of Multilayer Neural Networks for Object Recognition (2014), ECCV 2014", "[2] D. Erhan, Y. Bengio, A. Courville, and P. Vincent, Visualizing higher-layer features of a deep network (2009), ICML 2009 Workshop on Learning Feature Hierarchies", "[3] C. Feichtenhofer, A. Pinz, R. P. Wildes, and A. Zisserman, What have we learned from deep representations for action recognition? (2018), CVPR 2018", "[6] R. Q. Quiroga, L. Reddy, G. Kreiman, C. Koch, and I. Fried, Invariant visual representation by single neurons in the human brain (2005), Nature, Vol. 435", "[7] K. Simonyan, A. Vedaldi, and A. Zisserman, Deep inside convolutional networks: Visualising image classification models and saliency maps (2014), ICLR 2014", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine learning PhD student at the division of Robotics, perception and learning, KTH Royal Institute of Technology."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffba6a84d616c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sofiabroome?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sofiabroome?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "Sofia Broom\u00e9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F72c6fb832898&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&user=Sofia+Broom%C3%A9&userId=72c6fb832898&source=post_page-72c6fb832898----fba6a84d616c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffba6a84d616c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffba6a84d616c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@solenfeyissa?utm_source=medium&utm_medium=referral", "anchor_text": "Solen Feyissa"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----fba6a84d616c---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/explainability?source=post_page-----fba6a84d616c---------------explainability-----------------", "anchor_text": "Explainability"}, {"url": "https://medium.com/tag/model-interpretability?source=post_page-----fba6a84d616c---------------model_interpretability-----------------", "anchor_text": "Model Interpretability"}, {"url": "https://medium.com/tag/representation-learning?source=post_page-----fba6a84d616c---------------representation_learning-----------------", "anchor_text": "Representation Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----fba6a84d616c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffba6a84d616c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&user=Sofia+Broom%C3%A9&userId=72c6fb832898&source=-----fba6a84d616c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffba6a84d616c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&user=Sofia+Broom%C3%A9&userId=72c6fb832898&source=-----fba6a84d616c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffba6a84d616c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffba6a84d616c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fba6a84d616c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fba6a84d616c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fba6a84d616c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fba6a84d616c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sofiabroome?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sofiabroome?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sofia Broom\u00e9"}, {"url": "https://medium.com/@sofiabroome/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F72c6fb832898&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&user=Sofia+Broom%C3%A9&userId=72c6fb832898&source=post_page-72c6fb832898--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F72c6fb832898%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-question-of-single-unit-semantics-in-deep-networks-fba6a84d616c&user=Sofia+Broom%C3%A9&userId=72c6fb832898&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}