{"url": "https://towardsdatascience.com/three-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df", "time": 1683002176.8351731, "path": "towardsdatascience.com/three-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df/", "webpage": {"metadata": {"title": "Three Model Explanability Methods Every Data Scientist Should Know | by Moto DEI | Towards Data Science", "h1": "Three Model Explanability Methods Every Data Scientist Should Know", "description": "On December 3rd, 2019, new version of scikit-learn version 0.22 was released which came with a lot of great and can\u2019t-miss features as their Release Highlights for scikit-learn 0.22 gave a quick\u2026"}, "outgoing_paragraph_urls": [{"url": "https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html#", "anchor_text": "Release Highlights for scikit-learn 0.22", "paragraph_index": 0}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.partial_dependence.plot_partial_dependence.html", "anchor_text": "plot_partial_dependence", "paragraph_index": 1}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html", "anchor_text": "permutation_importance", "paragraph_index": 1}, {"url": "https://www.kaggle.com/learn/machine-learning-explainability", "anchor_text": "\u201cMachine Learning Explainability\u201d", "paragraph_index": 7}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "this brilliant post", "paragraph_index": 18}, {"url": "https://stats.stackexchange.com/questions/92419/relative-importance-of-a-set-of-predictors-in-a-random-forests-classification-in/92843#92843", "anchor_text": "see here", "paragraph_index": 22}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html", "anchor_text": "permutation_importance", "paragraph_index": 34}, {"url": "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data", "anchor_text": "Kaggle competition \u201cNew York City Taxi Fare Prediction\u201d", "paragraph_index": 34}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.plot_partial_dependence.html", "anchor_text": "plot_partial_dependence", "paragraph_index": 38}, {"url": "https://christophm.github.io/interpretable-ml-book/shapley.html", "anchor_text": "here", "paragraph_index": 43}, {"url": "https://github.com/slundberg/shap", "anchor_text": "python library", "paragraph_index": 44}, {"url": "https://github.com/slundberg/shap", "anchor_text": "shap", "paragraph_index": 44}, {"url": "https://christophm.github.io/interpretable-ml-book/shap.html#examples-4", "anchor_text": "This web page", "paragraph_index": 50}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Christoph Molnar \u201cInterpretable Machine Learning \u2014 A Guide for Making Black Box Models Explainable.\u201d", "paragraph_index": 68}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "Joshua Poduska \u201cSHAP and LIME Python Libraries: Part 1 \u2014 Great Explainers, with Pros and Cons to Both\u201d", "paragraph_index": 69}, {"url": "https://fr.linkedin.com/in/motoharu-dei-358abaa", "anchor_text": "https://fr.linkedin.com/in/motoharu-dei-358abaa", "paragraph_index": 71}], "all_paragraphs": ["On December 3rd, 2019, new version of scikit-learn version 0.22 was released which came with a lot of great and can\u2019t-miss features as their Release Highlights for scikit-learn 0.22 gave a quick summary:", "See? A lot of long-awaited features! Particularly the native support to stacking ROCKS! But in this post let\u2019s see three important tools of model explanability, part of which was implemented in new version scikit-learn by plot_partial_dependence and permutation_importance.", "It is frequently stated that the machine learning model is a \u2018black box\u2019.", "People know they are very good at prediction but when somebody asks why they are, jargon like loss function minimization or margin maximization would not help.", "Instead, what people want to hear is \u201cvariable A works positively by+10, variable B works negatively by -2\u2026\u201d like stuff and that\u2019s where linear models have advantage against the usual suspects of advanced ML algorithms.", "Thanks to many researchers\u2019s contributions, though, there are some useful tools to give explanability to the machine learning models.", "With those tools, we can know and understand (at least feel like we understand) that \u201cwhich variable affect the prediction how much\u201d?", "According to Kaggle course \u201cMachine Learning Explainability\u201d, the benefits of explanability are followings:", "- You can identify the erroneous preprocessing or data leakage from suspicious influence to the prediction.", "- When you have no intuition what kind of combination of variables can give good prediction power, data explanability study may give you an answer.", "- What is the possible new variable which is worth investing in collection?", "- Giving insight for human decision making through visualization of the reason for prediction.", "- If the explanation matches the common perception of human or experts, it can build a trust to the model.", "Now I will introduce three common explanability tools,", "SHAP was not a part of this sklearn update but I included it in the list because it is important for model explanability.", "- \u201cVariable importance\u201d gives the amount of \u2018importance\u2019 of each variables. Each variable has single value representing importance and their absolute value does not have any practical use because they are like the influence to loss function value by the presence of the variable.", "- \u201cPartial dependence plot\u201d gives the extent of influence to prediction by change of the variable. Scale of the plot actually corresponds to the scale of target variable and easy to understand. Also, we can check the curve over the variable change, not a single value to a variable unlike variable importance stated above.", "- \u201cSHAP\u201d gives how much each variable on each row contributed to the prediction. Its output is a matrix with the same format as the original input table, with each cell has the value of impact to the prediction of that data row, just like decomposing the predicted amount into each variable.", "- As a bonus, \u201cLIME\u201d is another model explanation approaches which gives row and column-level decomposition of the prediction. I will not talk too much about LIME here but let\u2019s just say LIME is a lite version of SHAP (SHAP takes time to compute particularly in the case of Kernel SHAP.) See this brilliant post by Joshua Poduska for more comparison of LIME and SHAP.", "But before diving in to the individual explanability approaches, I need to point out that the first thing we do is to make a good performing model and we cannot expect to derive a right insight from poor models! This is because every explanability logic assumes the prediction of the model is good enough.", "So therefore, you cannot expect model explanation to replace EDA. Instead, it is to support and enhance EDA for better feature engineering (go back to the first chapter and review \u201cWhy Explanability Matters?\u201d!!)", "\u201cVariable importance\u201d gives the amount of \u2018importance\u2019 of each variable. Each variable will have a single value representing importance. Another property we should remember is that their scale does not have any practical meaning because they are the amount of influence to loss function value by the presence of the variable.", "Decision-tree based models (decision tree classifier, CART, random forest, lightgbm etc.) have their own variable importance calculation logic based on the reduction of loss function by node split (see here for more details), but keep in mind that GBDT tends to have multiple options to calculate the importance and default option is not necessary loss function reduction. It can be other metrics like count of splits by the variable in interest.", "Let\u2019s call it as \u201ctree-based model variable importance.\u201d Tree-based model importance is calculable thanks to the model specific architecture such that the training process is split the node on a single variable, a discrete decision, and it is easy to compare go or not go.", "Then however, aren\u2019t other models able to perform variable importance? The answer is yes! That is what \u201cpermutation importance\u201d for!", "\u201cPermutation importance\u201d is model-agnostic variable importance approach, meaning they do not require a single variable-related discrete training process like decision tree. How do they do that?", "Using the variable name in the table above, let\u2019s say we want to predict a person\u2019s height when they become 20 years old (the first column), using data available at age 10 (other columns).", "Now I assume we have already trained some model and have descent accuracy (step 0 below) \u2014 again, we cannot get variable importance without descent model.", "0. Succeed in making a good predictive model.", "1. Permutation importance starts from shuffling the values in single column randomly to prepare a kind of \u2018new\u2019 data set.", "2. Next using the \u2018new\u2019 data, make predictions using the pre-trained model (do not re-train the model with \u2018new\u2019 data!). The accuracy should be somewhat worse than the one by original data and should have increase in loss function. Note that increase of loss function.", "3. Return the data to original order, repeat the same shuffle and measure on next column.", "4. Optionally but commonly, normalize the importance in all variables to total 1.0.", "5. Changing the shuffles, we can calculate the importance to one variable multiple times. Therefore, we can calculate mean and standard deviation of permutation importance.", "Here\u2019s the sample code using new function permutation_importance in scikit-learn version 0.22. The data set used was from Kaggle competition \u201cNew York City Taxi Fare Prediction\u201d. The output of the code is comparison of the tree-based variable importance vs. permutation importance output.", "Variable importance give one importance score per variable and is useful to know which variable affects more or less.", "\u201cPDP\u201d, on the other hand, gives the curve representing how much the variable affects to the final prediction at which value range of the variable.", "After fitting a model from original data table, intentionally changing the variable value where you want to get the PDP to specific amount and run prediction and repeat it to cover the interval.", "PDP can be implemented by the new function plot_partial_dependence in scikit-learn version 0.22.", "There can exist two-variable version of PDP. New scikit-learn function supports any of them.", "Out of PDP outputs above, we can see PDP is more computationally intensive and takes time to run, particularly even one 2D PDP took as long as 13 seconds.", "The most important distinction of \u201cSHAP\u201d from other methodologies is that SHAP gives the row&variable-level influence to prediction.", "In the illustration, the predicted values for each record ID is going to be decomposed such that \u201cPrediction\u201d = \u201cAverage prediction\u201d + \u201cSHAP value per variable\u201d.", "Then, how do they make it work? SHAP is based on Shapley value, a method in coalitional game theory. The essence of Shapley value is to measure the contribution to final outcome from each player separately among the coalition, with preserving the sum of contributions being equal to final outcome. See here for further discussion.", "The mathematical mechanism is too difficult to describe here, and I do not understand it completely :), but at least we can run API to get SHAP values thanks to the python library shap.", "We saw three different kinds of model explanability outputs: variable importance, PDP, and SHAP. They all provide different looking outputs. How can we choose one of them when we want explanability?", "SHAP has advantage in a sense that they provide the most granular outputs.", "Granular outputs can be rolled up to less granular outputs, while the other way around is never true. This indicates that:", "from SHAP values we can calculate variable importance-like results and PDP-like plot:", "taking the averages of absolute SHAP value per variable will be a kind of variable importance, and plotting variable value vs. SHAP value of the same variable is a kind of PDP.", "This web page gives an awesome list and explanation of possible uses of SHAP values, even like clustering using SHAP values.", "One drawback of SHAP is that it takes longer computation time. There are two types of SHAP and it is reported that \u201cKernelSHAP\u201d is super super slow (see the comment in sample code above; it was 40K times slower!!), while another type \u201cTreeSHAP\u201d is faster implementation. Yet let\u2019s keep one thing in mind:", "Unfortunately, TreeSHAP is only available for decision tree-based models.", "Another reason not to use SHAP is, per purpose why you want the model explanation,", "getting row&column-level SHAP values can be overkill and not a straight way to accomplish your goal.", "There could be some scenarios when variable importance is enough and we do not need PDP or SHAP.", "Variable importance gives single score about its importance to prediction. This can let the domain expert who is not data specialist make sure the model is reasonable. They just can judge from one bar chart with importance per variable, and if uncommon variable comes high it can be a hint to identify model bug or data leakage.", "Variable selection is useful in modeling to explain model in simpler way, remove model noise to improve accuracy, avoid collinearity, and etc.", "With variable importance outputs, we can choose subset of original variable set having the highest importance.", "In the NY taxi fare example above, it is clear that the count of passenger does not matter to the amount of fare, which makes sense from common sense, because NY taxi fare formula is irrelevant to the number of passengers (though the taxi with more passengers may tend to go farther than single rider but that\u2019s no new information to what we get from pick-up/drop-off location.)", "Also, in some scenarios we want more than variable importance but PDP is enough and SHAP is overkill.", "Through variable importance study, we can know which variable makes the model predictive but next we naturally start to wonder how it can \u2014 i.e. which range of the important variable makes the prediction higher or lower.", "In the NY taxi fare example above, what we learned was that the taxi who got or left passengers at the end longitude or latitude, not in the middle, should have higher benefit \u2014 riders in the middle of Manhattan are likely to be short-distance riders.", "From here, it is naturally to come up with a new feature engineering idea to take the distance between pick-up and drop-off locations, not just the absolute locations of those two separately.", "Model explanability is useful in debugging, feature engineering, directing future data collection, human decision-making, and building trust.", "I have introduced three types of explanability methodologies, variable importance (tree-based and permutation), partial dependency plot (PDP), and SHAP.", "Though SHAP is the most granular way to know the model explanability and can retrieve outputs similar to other approaches, the run can take time and become overkill.", "We data scientist should first start from why we want to know the explanation of the model and use the methodology which matches the purpose best.", "Christoph Molnar \u201cInterpretable Machine Learning \u2014 A Guide for Making Black Box Models Explainable.\u201d", "Joshua Poduska \u201cSHAP and LIME Python Libraries: Part 1 \u2014 Great Explainers, with Pros and Cons to Both\u201d", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist and actuary with 15+ yrs experience in media, marketing, insurance, and healthcare. LinkedIn: https://fr.linkedin.com/in/motoharu-dei-358abaa"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc332bdfd8df&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@daydreamersjp?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@daydreamersjp?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "Moto DEI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fecff78021d2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&user=Moto+DEI&userId=ecff78021d2d&source=post_page-ecff78021d2d----c332bdfd8df---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc332bdfd8df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc332bdfd8df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@sagarp7?utm_source=medium&utm_medium=referral", "anchor_text": "Sagar Patil"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html#", "anchor_text": "Release Highlights for scikit-learn 0.22"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html", "anchor_text": "plot_roc_curve"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.plot_partial_dependence.html#sklearn.inspection.plot_partial_dependence", "anchor_text": "plot_partial_dependence"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html", "anchor_text": "plot_precision_recall_curve"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html", "anchor_text": "plot_confusion_matrix"}, {"url": "http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/", "anchor_text": "stacking"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html", "anchor_text": "StackingClassifier"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html", "anchor_text": "StackingRegressor"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html", "anchor_text": "permutation_importance"}, {"url": "https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning", "anchor_text": "A new parameter"}, {"url": "https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning", "anchor_text": "ccp_alpha"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html", "anchor_text": "AUCROC function"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html", "anchor_text": "roc_auc_score"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.partial_dependence.plot_partial_dependence.html", "anchor_text": "plot_partial_dependence"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html", "anchor_text": "permutation_importance"}, {"url": "https://www.kaggle.com/learn/machine-learning-explainability", "anchor_text": "\u201cMachine Learning Explainability\u201d"}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "this brilliant post"}, {"url": "https://unsplash.com/@jtzanno?utm_source=medium&utm_medium=referral", "anchor_text": "Joao Tzanno"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://stats.stackexchange.com/questions/92419/relative-importance-of-a-set-of-predictors-in-a-random-forests-classification-in/92843#92843", "anchor_text": "see here"}, {"url": "https://www.kaggle.com/dansbecker/permutation-importance", "anchor_text": "https://www.kaggle.com/dansbecker/permutation-importance"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html", "anchor_text": "permutation_importance"}, {"url": "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data", "anchor_text": "Kaggle competition \u201cNew York City Taxi Fare Prediction\u201d"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.plot_partial_dependence.html", "anchor_text": "plot_partial_dependence"}, {"url": "https://christophm.github.io/interpretable-ml-book/shapley.html", "anchor_text": "here"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "python library"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "shap"}, {"url": "https://unsplash.com/@lanipham?utm_source=medium&utm_medium=referral", "anchor_text": "Lan Pham"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://christophm.github.io/interpretable-ml-book/shap.html#examples-4", "anchor_text": "This web page"}, {"url": "https://unsplash.com/@priscilladupreez?utm_source=medium&utm_medium=referral", "anchor_text": "Priscilla Du Preez"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html", "anchor_text": "Release Highlights for scikit-learn 0.22"}, {"url": "https://www.kaggle.com/learn/machine-learning-explainability", "anchor_text": "\u201cMachine Learning Explainability\u201d"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Christoph Molnar \u201cInterpretable Machine Learning \u2014 A Guide for Making Black Box Models Explainable.\u201d"}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "Joshua Poduska \u201cSHAP and LIME Python Libraries: Part 1 \u2014 Great Explainers, with Pros and Cons to Both\u201d"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c332bdfd8df---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/scikit-learn?source=post_page-----c332bdfd8df---------------scikit_learn-----------------", "anchor_text": "Scikit Learn"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c332bdfd8df---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----c332bdfd8df---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/model-interpretability?source=post_page-----c332bdfd8df---------------model_interpretability-----------------", "anchor_text": "Model Interpretability"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc332bdfd8df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&user=Moto+DEI&userId=ecff78021d2d&source=-----c332bdfd8df---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc332bdfd8df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&user=Moto+DEI&userId=ecff78021d2d&source=-----c332bdfd8df---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc332bdfd8df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc332bdfd8df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c332bdfd8df---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c332bdfd8df--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c332bdfd8df--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c332bdfd8df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@daydreamersjp?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@daydreamersjp?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Moto DEI"}, {"url": "https://medium.com/@daydreamersjp/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "453 Followers"}, {"url": "https://fr.linkedin.com/in/motoharu-dei-358abaa", "anchor_text": "https://fr.linkedin.com/in/motoharu-dei-358abaa"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fecff78021d2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&user=Moto+DEI&userId=ecff78021d2d&source=post_page-ecff78021d2d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7abec96ee7b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthree-model-explanability-methods-every-data-scientist-should-know-c332bdfd8df&newsletterV3=ecff78021d2d&newsletterV3Id=7abec96ee7b0&user=Moto+DEI&userId=ecff78021d2d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}