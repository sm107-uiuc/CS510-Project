{"url": "https://towardsdatascience.com/an-intuitive-guide-to-pca-1174055fc800", "time": 1683015304.496663, "path": "towardsdatascience.com/an-intuitive-guide-to-pca-1174055fc800/", "webpage": {"metadata": {"title": "An intuitive guide to PCA. Ideas behind Principal Component\u2026 | by Sahil Gupta | Towards Data Science", "h1": "An intuitive guide to PCA", "description": "Principal Component Analysis (PCA) is an extremely useful tool that can be used to gain intuition about the data set. It\u2019s primarily used for dimensionality reduction. I recently came across a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "a tutorial paper on PCA", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "the original paper", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Spring_(device)", "anchor_text": "spring", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Hooke%27s_law", "anchor_text": "Hooke\u2019s Law", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Rotation_(mathematics)", "anchor_text": "rotation", "paragraph_index": 28}, {"url": "https://en.wikipedia.org/wiki/Shear_mapping", "anchor_text": "shear", "paragraph_index": 28}, {"url": "https://en.wikipedia.org/wiki/Linear_map#Examples_of_linear_transformation_matrices", "anchor_text": "\u2026.", "paragraph_index": 28}, {"url": "https://en.wikipedia.org/wiki/Covariance_matrix", "anchor_text": "covariance matrix", "paragraph_index": 33}, {"url": "https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix", "anchor_text": "Eigenvalue Decomposition", "paragraph_index": 41}, {"url": "https://en.wikipedia.org/wiki/Singular_value_decomposition", "anchor_text": "ingular Value Decomposition", "paragraph_index": 41}, {"url": "https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data", "anchor_text": "this data set", "paragraph_index": 43}, {"url": "http://ww2010.atmos.uiuc.edu/(Gh)/guides/maps/sfcobs/dwp.rxml", "anchor_text": "dew point temp (closely related to air density)", "paragraph_index": 43}, {"url": "https://en.wikipedia.org/wiki/Tropospheric_ozone#Formation", "anchor_text": "compounds react to form O\u2083", "paragraph_index": 45}, {"url": "https://www.omnicalculator.com/physics/air-density", "anchor_text": "large negative correlation between Temperature, Dew Point Temperature, and Pressure", "paragraph_index": 46}, {"url": "https://en.wikipedia.org/wiki/Ideal_gas_law", "anchor_text": "Ideal gas law", "paragraph_index": 46}, {"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "the original paper", "paragraph_index": 47}], "all_paragraphs": ["Principal Component Analysis (PCA) is an extremely useful tool that can be used to gain intuition about the data set. It\u2019s primarily used for dimensionality reduction. I recently came across a tutorial paper on PCA that demystified PCA for me by talking about the intuition behind this powerful concept and inspired me to share a few things I discovered in the process. Most of the ideas in this piece are inspired by the original paper and I am thankful to the author for writing that. I will be building the concept from fundamentals and ending up with the application of PCA on some real data.", "Humans learn by observing stuff. One of the most common learning techniques is to conduct an experiment, gather some data, study it, and reach a conclusion about the phenomenon we are trying to study. For example, suppose I have a coin in my pocket and I am trying to determine if it\u2019s biased. To find this, I toss the coin multiple times, collect data from my experiment, and using principles from statistics I can conclude my coin. Similarly, in more realistic settings, we have a data set at hand that represents observations from a real-world phenomenon and our objective is to study it to gain insight into the underlying phenomenon.", "Let\u2019s suppose that we are interested in understanding how spring works. For those unfamiliar with this, the dynamics of spring are governed by Hooke\u2019s Law. I picked this example (similar to the original paper) to keep the discussion simple and tease out the underlying idea. To do this, we would set up an experiment with a camera and record the position of the spring tip at various times (I might have a strong suspicion for whatever reason that the dynamics are completely contained in the position of spring which is why I am recording it in the first place). So, our collected data set here would a matrix, X, with n observations and 2 features (x and y coordinate). Suppose we ran our experiment and obtained some observations, figure 1 (left).", "There two interesting things going on in our observations: a) it looks like the position of the spring tip at various points in time lies almost along a straight line tilted relative to the x-axis (if you read about Hooke\u2019s Law you already know why this happens), b) collected data is noisy, eg. due to unstable mount on which camera was fixed. The first observation is more of a heuristic about the dynamics of spring (I only mentioned Hooke\u2019s law to provide some context and it should be remembered that we are ignorant about this law while conducting this experiment, and trying to discover this law ourselves with the experiment).", "Although we collected the observations along our arbitrarily selected x- and y-axis, it looks like the dynamics of the spring may be described in a single direction. For instance, we could rotate our frame of reference such that all the points lie along X` in the rotated coordinate frame (figure 1, right). We can also see that the variability in our observations in Y` direction seems to be small compared to the variability in the X` direction, and this might be noise from the data collection process. In other words, the dynamics of spring can be described completely by a single direction of motion (the new x-axis) and there is some redundancy in our observations in form of noise.", "Summary: data set can contain unnecessary complexity which may sometimes hide simplified structures. There is a need for systematic way of reducing this complexity and removing redundancy from our data set.", "PCA aims at identifying the most meaningful frame of reference (also called basis in linear algebra) to re-express our dataset with the hope that this new basis will filter out the noise and reveal any hidden structure.", "In the spring experiment, we manually achieved this goal: plot of observations revealed we could rotate the coordinate axis, and small variability in the y-direction (compared to x-direction) revealed that there was some noise, which could be filtered.", "Let\u2019s continue building on our spring experiment to come up with ideas for a more systematic approach to dimensionality reduction, i.e. PCA. We will need to bring in some fundamental concepts from linear algebra. I will try to keep the discussion as simple as possible.", "In the spring experiment, we collected our observations using a camera that was arbitrarily mounted in the lab (this is similar to a real-world situation where we would collect data in some dimensions/ features). Based on the orientation of our camera, an implicit coordinate frame was defined, i.e. the x- and y-axis defined w.r.t. the camera (figure 1, left). This is called a Naive frame of reference.", "The key in the previous paragraph is the word implicit, i.e. we couldn\u2019t have picked a better frame even if we wanted to without some additional information about how a spring works. Similarly, in real-world situations we don\u2019t have the freedom to control the dimensions along which we are recording the observations, so the Naive choice is already made for us.", "Summary: Naive frame of reference is a property of data collection method which is (implicitly) given to us.", "Detour: Before moving forward in our discussion, let\u2019s briefly talk about a fundamental concept from linear algebra called basis.", "Basis can be thought of as a building block of reference frames. Consider an observation from our experiment (0.9, 0.85). This observation can be viewed as being constructed using some part (=0.9) of the x-axis vector and some part (=0.85) of the y-axis vector.", "This is a very powerful way of thinking because using just two vectors in the direction of the coordinate axis (along with information about the multipliers (0.9, 0.85)), we can describe our observation. A slightly technical term for these multipliers is projection. For example, the projection of observation along the x-axis direction is a vector with a magnitude 0.9. The rightmost equality in the above equation is a matrix formulation of this fact.", "Put it another way, we can decompose the observation (0.9, 0.85) into a combination of two independent pieces: x-axis (given by the vector (1,0)) and y-axis (vector (0,1)). The vectors along the x- and y-axis together form a basis. I called them a building block because any vector in the 2-D plane can be represented (or in other words built) as a combination of just these two vectors.", "Let\u2019s collect the building block of our naive reference frame in form of a matrix, B.", "We can concisely describe the above discussion for our entire data set as follows,", "This matrix equation describes the observation vectors (x,y) (i.e. the data) in terms of the Naive basis (this like stating 2 = 2, which is why we see the identity matrix appear in RHS). The LHS is just individual observation vectors stacked side-by-side in form of the matrix X^T, and RHS is a concise way of saying what we said earlier for all observation vectors. I skipped a step here: every observation can be decomposed similarly to the first observation and then the rightmost matrix equation follows.", "This equation looks fairly trivial because the matrix B is simply the identity matrix. The magic happens if we start thinking about the equation in a slightly different way: matrix X^T is the data, whereas the rightmost matrix (one that multiplies with the identity matrix) is a collection of multipliers which give us the recipe to build our data set. This might feel like an awkward way to think, but it will become clear in just a minute why this can be so powerful.", "Recall that as the first step towards a systematic approach for dimensionality reduction (PCA), motivated by the spring experiment, we are trying to find a better frame of reference that might simplify the data to reveal hidden structures (similar to how we were able to identify that the dynamics of spring was basically 1-D). I will once again motivate the discussion by going back to the spring experiment. Identifying a better frame of reference in the spring experiment would mean simply rotating the coordinate frame (figure 1, left to right looks like a rotation of all points about the origin).", "The recipe for rotating the first observation is depicted in fig. 2. The observation in our Naive frame of reference is colored in black and the rotated result is in red (components along the Naive x- and y-axis are dotted lines). The direction along the rotated observation vector could then serve as the new x-axis, X\u2019, which is similar to what you see in figure 1, right. Remember in the detour we saw that any observation in our data can be constructed using the basis and multipliers. This is where that alternative way of looking at the matrix equation comes in handy. Let\u2019s see if we can leverage that idea here.", "The rotation of Naive basis with this angle (43.5\u1d52) is given as,", "Can we use this insight to compute the new location of the first observation?", "Yes! We already know the recipe for creating the first observation using vectors (1,0) and (0,1): combine them using multipliers 0.9 and 0.85. So, the new position for the first observation is simply combining the transformed basis vectors using the same multipliers,", "If you are left wondering how we could use the same multipliers with the transformed vectors of the Naive x- and y-axis, look at figure 2 to notice that everything is being rotated by the same angle.", "This is just one observation, wouldn\u2019t it be nice if we had a concise way of describing this for all 100 observations? Turns out it\u2019s a simple extension of the idea from the detour,", "Hopefully, by now you see what\u2019s going on and why this holds: to rotate any observation in our data set, we need to combine the transformed x- and y-axis vectors from above using the corresponding multiplier for an observation. In other words, P is a matrix that rotates a vector by 43.5\u1d52 and takes our data set from the Naive frame of reference (figure 1, left) to a much better one (figure 1, right).", "Let\u2019s generalize this idea a bit. Motivated by looking at the plot of our observations, we decided that rotation could be a good choice for a transformation that could help us find a better frame of reference for studying our problem. Turns out there are lots of available choices for such transformations such as rotation, shear, \u2026. A natural question would be how to pick the best one? We will try to answer in the upcoming section.", "The important thing to notice is that by changing the numbers stored inside the matrix P, I can generate new transformations. An example is shown in figure 3. I generated a random 2 x 2 matrix and the resulting transformation is depicted in red. Although it\u2019s not an intuitive choice, the red vectors together form a basis: any vector in 2-dimension can be constructed using a combination of these.", "Summary: multiplying a matrix of size p x p to our data matrix of size p x n (where p is no. of dimensions) changes the frame of reference, or more formally can be called as a change of basis.", "The ideas from the previous sections enable us to ask better and more precise questions about our ultimate goal,", "We will answer the first question in the process of investigating the second one. One reasonable assumption we can make about our data is that the measurement noise is low compared to the signal (otherwise the data is too noisy to derive anything useful), which in other words is the same as saying that the variance of noise << variance of the signal. This assumption gives us a way to mathematically solve for our 2nd goal, i.e. we can maximize variance to identify the signal. Recall that we saw this assumption holds in the context of the spring experiment in figure 1 (right, where the variance in the y-direction is very small compared to the x-direction).", "Suppose matrix X is our data with n observations and each observation has p dimensions. To maximize the variance of our data, we first need to compute the variance of our data. Each of the p dimensions represents a possible direction along which our data could vary, i.e. have variance. So, a natural way of mathematically describing the variance of data would be the covariance matrix,", "provided the data is mean-centered. The diagonal entries of this matrix represent the variance along each dimension and the off-diagonal entries are the co-variances. Notice that \u03a3 is a square matrix (p x p) and is symmetric: covariance(X, Y) = covariance(Y, X).", "A good covariance matrix based on our objectives (and intuition from the spring experiment) would have large diagonal entries and small (preferably zero) off-diagonal entries. This is because of two reasons,", "This gives us a template matrix we are looking for, i.e. preferably a diagonal matrix. Now, all that remains is to find such a matrix. Let\u2019s build some intuition on the way forward with a simple example.", "In figure 4, we are given a 2 x 2 covariance matrix (represented by black vectors). We see from this example that choosing the \u201cright\u201d matrix P transforms the covariance matrix into a diagonal matrix (represented by the red vectors). So, converting a given matrix into a diagonal matrix is a matter of finding the right basis (or frame of reference).", "There are many ways (/ potential basis) for diagonalizing the covariance matrix and PCA is based on a simple method: assume that all directions (forming the basis) are mutually perpendicular. Then, diagonalizing the covariance matrix would involve a generalized rotation (in 2D this would be similar to figure 4).", "Finally, we have an algorithm for Principal Component Analysis,", "In the spring experiment (figure 1), this algorithm would involve identifying d\u2081 as the direction along X\u2019, and d\u2082 as Y\u2019. The resulting set of directions {d\u2081, d\u2082, \u2026} are the principal components, and the importance of each of these components is associated with the variability of the data along each of these directions. Finally, the resulting matrix that we obtain after the change of basis represents our data in terms of these principal components (see figure 1 right and section on change of basis).", "The algorithm we discovered above is a rough outline of the steps that form PCA. The main step (diagonalization of the covariance matrix) is a well-studied problem in linear algebra, and there are two main decompositions to do this: Eigenvalue Decomposition, and Singular Value Decomposition. The practical implementations of PCA use either of these decomposition techniques.", "Summary: PCA transforms our data into a new basis which is defined by mutually perpendicular directions, called principal components, along which the variance is maximized, and the importance of each direction is associated with the variance of data in that direction.", "I will be using this data set for the example. The data set contains hourly air pollutants data from 12 nationally-controlled air-quality monitoring sites in Beijing. I will use data from only one of these sites (PRSA_Data_Wanshouxigong_20130301\u201320170228.csv). The various dimensions (/features) are the concentration of common pollutants found in air such as SO\u2082, NO\u2082, CO, O\u2083, different sizes of Particulate Matter, ambient air conditions such as temperature, pressure, dew point temp (closely related to air density), wind speed, and time of day. These dimensions were probably selected by experts at the environmental monitoring center based on their domain knowledge and measured using sensors (which would have some measurement noise). The data set has 32,829 observations and 15 dimensions.", "Figure 5 shows the scatter plot of the data set in the plane defined by two principal components: PC1 and PC2. PC1 and PC2 are the two most important principal components, i.e. associated with the largest and second-largest variance directions, respectively. Each observation from our data set is 15-dimensional and is projected along PC1 and PC2, which is exactly depicted in the plot (figure 5). The red arrows in the scatter plot indicate the original dimensions relative to the two principal components. The direction vectors corresponding to the two principal components are given in the table on right.", "We can already see some interesting stuff revealed in these directions. In the PC1 direction, we see that pollutants such as PM2.5, PM10, SO\u2082, NO\u2082, CO are negatively correlated with O\u2083, Temperature, Dew Pressure, Wind Speed. In other words, as temperature and wind speed goes down, the concentration of pollutants increases, which makes sense because at cooler temperatures molecules tend to settle down closer to Earths\u2019 surface due to gravity, and lesser wind would mean less dispersion of air (higher pressure, concentration\u2026). Another interesting thing we can see is the negative correlation of Ozone (O\u2083) with all other pollutants. Although it\u2019s been a while since my last encounter with chemical reactions, a little digging revealed that the formation of chemical reactions for Ozone is dependent on the ambient air conditions. For instance, at lower temperatures CO (/ NO\u2082)is stable, but at higher temperatures (i.e. sunlight), compounds react to form O\u2083. In essence, PC1 is contrasting the ambient air conditions and the concentration of pollutants.", "The PC2 direction has a large negative correlation between Temperature, Dew Point Temperature, and Pressure, which is probably linked to the fundamental Ideal gas law that links these variables.", "We saw that PCA is useful in understanding and visualizing the data set, and provides us with a systematic way to extract useful information. PCA is not always the best choice and can sometimes hurt. It helps to know about the limitations of this technique which are driven by some of the assumptions we made while deriving it. For a more rigorous and elaborate treatment of PCA, check out the original paper, which is really interesting reading.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1174055fc800&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1174055fc800--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1174055fc800--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sahilgupta_86549?source=post_page-----1174055fc800--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sahilgupta_86549?source=post_page-----1174055fc800--------------------------------", "anchor_text": "Sahil Gupta"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fafb6a5fd07b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&user=Sahil+Gupta&userId=afb6a5fd07b4&source=post_page-afb6a5fd07b4----1174055fc800---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1174055fc800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1174055fc800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@nate_dumlao?utm_source=medium&utm_medium=referral", "anchor_text": "Nathan Dumlao"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "a tutorial paper on PCA"}, {"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "the original paper"}, {"url": "https://en.wikipedia.org/wiki/Spring_(device)", "anchor_text": "spring"}, {"url": "https://en.wikipedia.org/wiki/Hooke%27s_law", "anchor_text": "Hooke\u2019s Law"}, {"url": "https://en.wikipedia.org/wiki/Rotation_(mathematics)", "anchor_text": "rotation"}, {"url": "https://en.wikipedia.org/wiki/Shear_mapping", "anchor_text": "shear"}, {"url": "https://en.wikipedia.org/wiki/Linear_map#Examples_of_linear_transformation_matrices", "anchor_text": "\u2026."}, {"url": "https://en.wikipedia.org/wiki/Covariance_matrix", "anchor_text": "covariance matrix"}, {"url": "https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix", "anchor_text": "Eigenvalue Decomposition"}, {"url": "https://en.wikipedia.org/wiki/Singular_value_decomposition", "anchor_text": "ingular Value Decomposition"}, {"url": "https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data", "anchor_text": "this data set"}, {"url": "http://ww2010.atmos.uiuc.edu/(Gh)/guides/maps/sfcobs/dwp.rxml", "anchor_text": "dew point temp (closely related to air density)"}, {"url": "https://en.wikipedia.org/wiki/Tropospheric_ozone#Formation", "anchor_text": "compounds react to form O\u2083"}, {"url": "https://www.omnicalculator.com/physics/air-density", "anchor_text": "large negative correlation between Temperature, Dew Point Temperature, and Pressure"}, {"url": "https://en.wikipedia.org/wiki/Ideal_gas_law", "anchor_text": "Ideal gas law"}, {"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "the original paper"}, {"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "A Tutorial on Principal Component Analysis"}, {"url": "http://www.ulaff.net/", "anchor_text": "Linear Algebra: Foundations to Frontiers"}, {"url": "https://www.cs.utexas.edu/users/flame/laff/alaff/", "anchor_text": "Advanced Linear Algebra: Foundations to Frontiers"}, {"url": "http://www.stat.cmu.edu/~cshalizi/uADA/15/lectures/17.pdf", "anchor_text": "Advanced-Data Analysis from an Elementary Point of View"}, {"url": "https://medium.com/tag/statistics?source=post_page-----1174055fc800---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----1174055fc800---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1174055fc800---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----1174055fc800---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1174055fc800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&user=Sahil+Gupta&userId=afb6a5fd07b4&source=-----1174055fc800---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1174055fc800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&user=Sahil+Gupta&userId=afb6a5fd07b4&source=-----1174055fc800---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1174055fc800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1174055fc800--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1174055fc800&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1174055fc800---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1174055fc800--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1174055fc800--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1174055fc800--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1174055fc800--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1174055fc800--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1174055fc800--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1174055fc800--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1174055fc800--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sahilgupta_86549?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sahilgupta_86549?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sahil Gupta"}, {"url": "https://medium.com/@sahilgupta_86549/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "106 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fafb6a5fd07b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&user=Sahil+Gupta&userId=afb6a5fd07b4&source=post_page-afb6a5fd07b4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb14b0a1adbc5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-guide-to-pca-1174055fc800&newsletterV3=afb6a5fd07b4&newsletterV3Id=b14b0a1adbc5&user=Sahil+Gupta&userId=afb6a5fd07b4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}