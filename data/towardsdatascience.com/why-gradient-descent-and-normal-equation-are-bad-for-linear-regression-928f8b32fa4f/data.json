{"url": "https://towardsdatascience.com/why-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f", "time": 1683013770.893732, "path": "towardsdatascience.com/why-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f/", "webpage": {"metadata": {"title": "Why gradient descent and normal equation are BAD for linear regression | by Jakub Adamczyk | Towards Data Science", "h1": "Why gradient descent and normal equation are BAD for linear regression", "description": "Why gradient descent and normal equation are BAD for linear regression, and why you should use singular value decomposition and Moore-Penrose pseudoinverse instead."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Most of the ML courses start with linear regression and gradient descent and/or normal equations for this problem. Probably the most well-known Andrew Ng\u2019s course also introduces linear regression as a very basic machine learning algorithm and how to solve it using gradient descent and normal equations methods. Unfortunately, usually, those are quite terrible ways to do it. In fact, if you have ever used LinearRegression from Scikit-learn, you have used alternative methods!", "In linear regression, we have to estimate parameters theta \u2014 coefficients for linear combination of terms for regression (where x_0 = 1 and theta_0 is a free term/bias):", "We do it by minimizing residual sum of squares (RSS), i. e. average of the squared differences between the output of our model and true values:", "Gradient descent, a very general method for function optimization, iteratively approaches the local minimum of the function. Since the loss function for linear regression is quadratic, it is also convex, i. e. there is a unique local and global minimum. We approach it by taking steps based on the negative gradient and chosen learning rate alpha.", "Why is this approach bad in most cases? The main reasons are:", "So why do we even bother with gradient descent for linear regression? There are two main reasons:", "Quadratic cost function has been originally chosen for linear regression because of its nice mathematical properties. It\u2019s easy to use and we are able to get a closed form solution, i. e. a mathematical formula for theta parameters \u2014 a normal equation. In the derivation below, we get rid of 1/2n, since in the derivation it will vanish anyway.", "We arrive at a system of linear equations and finally at the normal equation:", "And why is this approach bad too? Main reasons are:", "This method should never be used in practice in machine learning. It is nice for mathematical analysis, but that\u2019s it. However, it has become the basis for methods that are actually used by Scikit-learn and other libraries.", "As we\u2019ve seen the downsides of the approaches shown in ML courses, let\u2019s see what is used in practice. In Scikit-learn LinearRegression we can see:", "So Scikit-learn does not bother with its own implementation, instead, it just uses Scipy. In scipy.linalg.lstsq we can see that even this library does not use it\u2019s own implementation, instead using LAPACK:", "Finally, we arrive at gelsd, gelsy and gelss entries in Intel LAPACK documentation:", "2 out of those 3 methods use Singular Value Decomposition (SVD), a very important algorithm both in numerical methods and machine learning. You may have heard about it in context of NLP or recommender systems, where it\u2019s used for dimensionality reduction. It turns out, it\u2019s also used for practical linear regression, where it provides a reasonably fast and very accurate method for computing least squares problem that lies in the heart of linear regression.", "If we stop one step before the normal equations, we get a regular least squares problem:", "Since X is almost never square (usually we have more samples than features, i. e. a \u201ctall and skinny\u201d matrix X), this equation does not have an exact solution. Instead, we use the least squares approximation, i. e. the theta vector as close as possible to the solution in terms of Euclidean distance (L2 norm):", "This problem (OLS, Ordinary Least Square) can be solved in many ways, but it turns out that we have a very useful theorem to help us:", "The Moore-Penrose pseudoinverse is the matrix inverse approximation for arbitrary matrices \u2014 even not square ones! In practice it\u2019s calculated through SVD \u2014 Singular Value Decomposition. We decompose the matrix X into the product of 3 matrices:", "The Moore-Penrose pseudoinverse is then defined as:", "As you can see, if we have the SVD, computing the pseudoinverse is quite a trivial operation, since the sigma matrix is diagonal.", "Finally, we arrive at a very practical formula for linear regression coefficient vector:", "This is what is used in practice by Scikit-learn, Scipy, Numpy and a number of other packages. There are of course some optimizations that can enhance the performance, like divide-and-conquer approach for faster SVD computation (used by Scikit-learn and Scipy by default), but those are more of implementation details. The main idea remains \u2014 use SVD and Moore-Penrose pseudoinverse.", "Beware though \u2014 this article is about linear regression, not about regularized versions like LASSO or ElasticNet! While this method works wonders for linear regression, with regularization we don\u2019t have the nice least squares minimization and have to use e. g. coordinate descent.", "In this article you\u2019ve learned what\u2019s really happening under the mask of the Scikit-learn LinearRegression. While gradient descent and normal equations have their applications (education and mathematical properties), in practice we use the Moore-Penrose pseudoinverse with SVD to get accurate predictions for our linear regression models.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science student, ML engineer, Data Science and ML algorithms enthusiast."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F928f8b32fa4f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jakubadamczyk10?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jakubadamczyk10?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "Jakub Adamczyk"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa2bd22267201&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&user=Jakub+Adamczyk&userId=a2bd22267201&source=post_page-a2bd22267201----928f8b32fa4f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F928f8b32fa4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F928f8b32fa4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Linear_regression#/media/File:Linear_regression.svg", "anchor_text": "source"}, {"url": "https://www.deeplearningbook.org/", "anchor_text": "https://www.deeplearningbook.org/"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html", "anchor_text": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"}, {"url": "https://math.stackexchange.com/questions/1816364/the-svd-solution-to-linear-least-squares-linear-system-of-equations", "anchor_text": "https://math.stackexchange.com/questions/1816364/the-svd-solution-to-linear-least-squares-linear-system-of-equations"}, {"url": "https://math.stackexchange.com/questions/974193/why-does-svd-provide-the-least-squares-and-least-norm-solution-to-a-x-b", "anchor_text": "https://math.stackexchange.com/questions/974193/why-does-svd-provide-the-least-squares-and-least-norm-solution-to-a-x-b"}, {"url": "https://math.stackexchange.com/questions/218333/svd-and-linear-least-squares-problem", "anchor_text": "https://math.stackexchange.com/questions/218333/svd-and-linear-least-squares-problem"}, {"url": "https://docs.google.com/viewer?url=https://github.com/RoyiAvital/Projects/raw/master/SingularValueDecomposition/SVD.pdf", "anchor_text": "https://docs.google.com/viewer?url=https://github.com/RoyiAvital/Projects/raw/master/SingularValueDecomposition/SVD.pdf"}, {"url": "https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution", "anchor_text": "https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution"}, {"url": "https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution", "anchor_text": "https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution"}, {"url": "https://stats.stackexchange.com/questions/1829/what-algorithm-is-used-in-linear-regression", "anchor_text": "https://stats.stackexchange.com/questions/1829/what-algorithm-is-used-in-linear-regression"}, {"url": "https://stats.stackexchange.com/questions/160179/do-we-need-gradient-descent-to-find-the-coefficients-of-a-linear-regression-mode", "anchor_text": "https://stats.stackexchange.com/questions/160179/do-we-need-gradient-descent-to-find-the-coefficients-of-a-linear-regression-mode"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----928f8b32fa4f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----928f8b32fa4f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----928f8b32fa4f---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----928f8b32fa4f---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/regression?source=post_page-----928f8b32fa4f---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F928f8b32fa4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&user=Jakub+Adamczyk&userId=a2bd22267201&source=-----928f8b32fa4f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F928f8b32fa4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&user=Jakub+Adamczyk&userId=a2bd22267201&source=-----928f8b32fa4f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F928f8b32fa4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F928f8b32fa4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----928f8b32fa4f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----928f8b32fa4f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jakubadamczyk10?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jakubadamczyk10?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jakub Adamczyk"}, {"url": "https://medium.com/@jakubadamczyk10/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "89 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa2bd22267201&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&user=Jakub+Adamczyk&userId=a2bd22267201&source=post_page-a2bd22267201--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F494f9b4fd578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-gradient-descent-and-normal-equation-are-bad-for-linear-regression-928f8b32fa4f&newsletterV3=a2bd22267201&newsletterV3Id=494f9b4fd578&user=Jakub+Adamczyk&userId=a2bd22267201&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}