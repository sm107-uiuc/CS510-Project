{"url": "https://towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1", "time": 1682993803.053426, "path": "towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1/", "webpage": {"metadata": {"title": "Speed Up your Algorithms Part 2\u2014 Numba | by Puneet Grover | Towards Data Science", "h1": "Speed Up your Algorithms Part 2\u2014 Numba", "description": "Numba is a Just-in-time compiler for python, i.e. whenever you make a call to a python function all or part of your code is converted to machine code \u201cjust-in-time\u201d of execution, and it will then run\u2026"}, "outgoing_paragraph_urls": [{"url": "https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html", "anchor_text": "numpy library", "paragraph_index": 3}, {"url": "http://numba.pydata.org/numba-doc/0.17.0/reference/pysupported.html", "anchor_text": "here", "paragraph_index": 3}, {"url": "http://cython.org/", "anchor_text": "cython", "paragraph_index": 4}, {"url": "http://doc.pypy.org/en/latest/faq.html#what-is-pypy", "anchor_text": "pypy", "paragraph_index": 4}, {"url": "https://numba.pydata.org/numba-doc/dev/user/jitclass.html", "anchor_text": "wrapper for a class", "paragraph_index": 6}, {"url": "http://llvm.org/", "anchor_text": "LLVM compiler infrastructure", "paragraph_index": 9}, {"url": "http://numba.pydata.org/numba-doc/latest/user/jit.html#jit", "anchor_text": "generate", "paragraph_index": 12}, {"url": "http://numba.pydata.org/numba-doc/latest/cuda/index.html", "anchor_text": "GPU", "paragraph_index": 12}, {"url": "http://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel", "anchor_text": "parallelizable", "paragraph_index": 16}, {"url": "http://numba.pydata.org/numba-doc/latest/reference/jit-compilation.html#numba.jit", "anchor_text": "multiple", "paragraph_index": 18}, {"url": "https://numba.pydata.org/numba-doc/dev/user/pycc.html", "anchor_text": "AOT", "paragraph_index": 20}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/memory.html", "anchor_text": "functions", "paragraph_index": 33}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/cudapysupported.html", "anchor_text": "here", "paragraph_index": 35}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/intrinsics.html", "anchor_text": "atomic operations", "paragraph_index": 36}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/random.html", "anchor_text": "random number generators", "paragraph_index": 36}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/memory.html#cuda-shared-memory", "anchor_text": "shared memory implementation", "paragraph_index": 36}], "all_paragraphs": ["This is the third post in a series I am writing. All posts are here:", "And these goes with Jupyter Notebooks available here:", "Numba is a Just-in-time compiler for python, i.e. whenever you make a call to a python function all or part of your code is converted to machine code \u201cjust-in-time\u201d of execution, and it will then run on your native machine code speed! It is sponsored by Anaconda Inc and has been/is supported by many other organisations.", "With Numba, you can speed up all of your calculation focused and computationally heavy python functions(eg loops). It also has support for numpy library! So, you can use numpy in your calculations too, and speed up the overall computation as loops in python are very slow. You can also use many of the functions of math library of python standard library like sqrt etc. For a comprehensive list of all compatible functions look here.", "So, why numba? When there are many other compilers like cython, or any other similar compilers or something like pypy.", "For a simple reason that here you don\u2019t have to leave the comfort zone of writing your code in python. Yes, you read it right, you don\u2019t have to change your code at all for basic speedup which is comparable to speedup you get from similar cython code with type definitions. Isn\u2019t that great?", "You just have to add a familiar python functionality, a decorator (a wrapper) around your functions. A wrapper for a class is also under development.", "So, you just have to add a decorator and you are done. eg:", "It still looks like a pure python code, doesn\u2019t it?", "Numba generates optimized machine code from pure Python code using LLVM compiler infrastructure. Speed of code run using numba is comparable to that of similar code in C, C++ or Fortran.", "Here is how the code is compiled:", "First, Python function is taken, optimized and is converted into Numba\u2019s intermediate representation, then after type inference which is like Numpy\u2019s type inference (so python float is a float64), it is converted into LLVM interpretable code. This code is then fed to LLVM\u2019s just-in-time compiler to give out machine code.", "You can generate code at runtime or import time on CPU (default) or GPU, as you prefer it.", "For best performance numba recommends using nopython = True argument with your jit wrapper, using which it won\u2019t use the Python interpreter at all. Or you can also use @njit too. If your wrapper with nopython = True fails with an error, you can use simple @jit wrapper which will compile part of your code, loops it can compile, and turns them into functions, to compile into machine code and give the rest to the python interpreter.So, you just have to do:", "When using @jit make sure your code has something numba can compile, like a compute-intensive loop, maybe with libraries (numpy) and functions it supports. Otherwise, it won\u2019t be able to compile anything.", "To put a cherry on top, numba also caches the functions after first use as machine code. So after the first time, it will be even faster because it doesn\u2019t need to compile that code again, given that you are using the same argument types that you used before.", "And if your code is parallelizable you can also pass parallel = True as an argument, but it must be used in conjunction with nopython = True. For now, it only works on CPU.", "You can also specify function signature you want your function to have, but then it won\u2019t compile for any other types of arguments you give to it. For example:", "Now your function will only take two int32\u2019s and return an int32. By this, you can have more control over your functions. You can even pass multiple functional signatures if you want.", "You can also use other wrappers provided by numba:", "Numba also has Ahead of time (AOT) compilation, which produces a compiled extension module which does not depend on Numba. But:", "It also produces generic code for your CPU\u2019s architectural family.", "By using @vectorize wrapper you can convert your functions which operate on scalars only, for example, if you are using python\u2019s math library which only works on scalars, to work for arrays. This gives speed similar to that of a numpy array operations (ufuncs). For example:", "You can also pass target argument to this wrapper which can have a value equal to parallel for parallelizing code, cuda for running code on cuda/GPU.", "Vectorizing with target = \u201cparallel\u201d or \u201ccuda\u201d will generally run faster than numpy implementation, given your code is sufficiently compute-intensive or array is sufficiently large. If not then it comes with an overhead of the time for making threads and splitting elements for different threads, which can be larger than actual compute time for the whole process. So, work should be sufficiently heavy to get a speedup.", "This great video has an example of speeding up Navier Stokes equation for computational fluid dynamics with Numba:", "You can also pass @jit like wrappers to run functions on cuda/GPU also. For that, you will have to import cuda from numba library. But running your code on GPU is not going to be as easy as before. It has some initial computations that need to be done for running function on hundreds or even thousands of threads on GPU. You have to declare and manage a hierarchy of grids, blocks and threads. And it\u2019s not that hard.", "To execute a function on GPU, you have to either define something called a kernel function or a device function. Firstly let\u2019s see a kernel function.", "Some points to remember about kernel functions:", "a) kernels explicitly declare their thread hierarchy when called, i.e. the number of blocks and number of threads per block. You can compile your kernel once, and call it multiple times with different block and grid sizes.", "b) kernels cannot return a value. So, either you will have to do changes on original array, or pass another array for storing the result. For computing scalar, you will have to pass a 1 element array.", "So for launching a kernel, you will have to pass two things:", "Kernel function in every thread has to know in which thread it is, to know which elements of array it is responsible for. Numba makes it easy to get these positions of elements, just by one call.", "To save the time which will be wasted in copying numpy array to a specific device and then again storing result in numpy array, Numba provides some functions to declare and send arrays to specific device, like: numba.cuda.device_array, numba.cuda.device_array_like, numba.cuda.to_device, etc. to save time of needless copies to cpu(unless necessary).", "On the other hand, a device function can only be invoked from inside a device (by a kernel or another device function). The plus point is, you can return a value from a device function. So, you can use this return value of the function to compute something inside a kernel function or a device function.", "You should also look into supported functionality of Numba\u2019s cuda library, here.", "Numba also has implementations of atomic operations, random number generators, shared memory implementation (to speed up access to data) etc within its cuda library.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F293e554c5cc1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://techelfpuneet.medium.com/?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": ""}, {"url": "https://techelfpuneet.medium.com/?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "Puneet Grover"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfddda6ba487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&user=Puneet+Grover&userId=dfddda6ba487&source=post_page-dfddda6ba487----293e554c5cc1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F293e554c5cc1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F293e554c5cc1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@joseph3088?utm_source=medium&utm_medium=referral", "anchor_text": "Duncan Sanchez"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051", "anchor_text": "Speed Up your Algorithms Part 1 \u2014 PyTorch"}, {"url": "https://towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1", "anchor_text": "Speed Up your Algorithms Part 2 \u2014 Numba"}, {"url": "https://towardsdatascience.com/speed-up-your-algorithms-part-3-parallelization-4d95c0888748", "anchor_text": "Speed Up your Algorithms Part 3 \u2014 Parallelization"}, {"url": "https://towardsdatascience.com/speeding-up-your-algorithms-part-4-dask-7c6ed79994ef", "anchor_text": "Speed Up your Algorithms Part 4 \u2014 Dask"}, {"url": "https://github.com/PuneetGrov3r/MediumPosts/tree/master/SpeedUpYourAlgorithms", "anchor_text": "Github-SpeedUpYourAlgorithms"}, {"url": "https://www.kaggle.com/puneetgrover/kernels", "anchor_text": "Kaggle"}, {"url": "https://nbviewer.jupyter.org/github/PuneetGrov3r/MediumPosts/blob/master/SpeedUpYourAlgorithms/2%29%20Numba.ipynb", "anchor_text": "SpeedUpYourAlgorithms-Numba"}, {"url": "https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html", "anchor_text": "numpy library"}, {"url": "http://numba.pydata.org/numba-doc/0.17.0/reference/pysupported.html", "anchor_text": "here"}, {"url": "http://rebloggy.com/post/snake-crown-zeus-ball-python-python-i-cant-believe-he-let-me-do-this-snakes-in-h/30972529459", "anchor_text": "Source"}, {"url": "http://cython.org/", "anchor_text": "cython"}, {"url": "http://doc.pypy.org/en/latest/faq.html#what-is-pypy", "anchor_text": "pypy"}, {"url": "https://numba.pydata.org/numba-doc/dev/user/jitclass.html", "anchor_text": "wrapper for a class"}, {"url": "https://unsplash.com/@emilymorter?utm_source=medium&utm_medium=referral", "anchor_text": "Emily Morter"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://llvm.org/", "anchor_text": "LLVM compiler infrastructure"}, {"url": "https://github.com/ContinuumIO/gtc2017-numba/blob/master/1%20-%20Numba%20Basics.ipynb", "anchor_text": "Source"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/jit.html#jit", "anchor_text": "generate"}, {"url": "http://numba.pydata.org/numba-doc/latest/cuda/index.html", "anchor_text": "GPU"}, {"url": "https://unsplash.com/@charlesetoroma?utm_source=medium&utm_medium=referral", "anchor_text": "Charles Etoroma"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel", "anchor_text": "parallelizable"}, {"url": "http://numba.pydata.org/numba-doc/latest/reference/jit-compilation.html#numba.jit", "anchor_text": "multiple"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/vectorize.html", "anchor_text": "@vectorize"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/vectorize.html#guvectorize", "anchor_text": "@guvectorize"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/stencil.html#numba-stencil", "anchor_text": "@stencil"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/jitclass.html#jitclass", "anchor_text": "@jitclass"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/cfunc.html#cfunc", "anchor_text": "@cfunc"}, {"url": "http://numba.pydata.org/numba-doc/latest/extending/high-level.html#high-level-extending", "anchor_text": "@overload"}, {"url": "https://numba.pydata.org/numba-doc/dev/user/pycc.html", "anchor_text": "AOT"}, {"url": "https://unsplash.com/@publicpowerorg?utm_source=medium&utm_medium=referral", "anchor_text": "American Public Power Association"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@marcsm?utm_source=medium&utm_medium=referral", "anchor_text": "Marc Sendra martorell"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/memory.html", "anchor_text": "functions"}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/cudapysupported.html", "anchor_text": "here"}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/intrinsics.html", "anchor_text": "atomic operations"}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/random.html", "anchor_text": "random number generators"}, {"url": "https://numba.pydata.org/numba-doc/dev/cuda/memory.html#cuda-shared-memory", "anchor_text": "shared memory implementation"}, {"url": "http://numba.pydata.org/numba-doc/latest/reference/pysupported.html#cffi-support", "anchor_text": "CFFI"}, {"url": "http://numba.pydata.org/numba-doc/latest/reference/pysupported.html#ctypes-support", "anchor_text": "ctypes"}, {"url": "http://numba.pydata.org/numba-doc/latest/extending/high-level.html#cython-support", "anchor_text": "are callable"}, {"url": "https://nbviewer.jupyter.org/github/ContinuumIO/gtc2017-numba/tree/master/", "anchor_text": "https://nbviewer.jupyter.org/github/ContinuumIO/gtc2017-numba/tree/master/"}, {"url": "https://devblogs.nvidia.com/seven-things-numba/", "anchor_text": "https://devblogs.nvidia.com/seven-things-numba/"}, {"url": "https://devblogs.nvidia.com/numba-python-cuda-acceleration/", "anchor_text": "https://devblogs.nvidia.com/numba-python-cuda-acceleration/"}, {"url": "https://jakevdp.github.io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/", "anchor_text": "https://jakevdp.github.io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/"}, {"url": "https://www.youtube.com/watch?v=1AwG0T4gaO0", "anchor_text": "https://www.youtube.com/watch?v=1AwG0T4gaO0"}, {"url": "http://numba.pydata.org/numba-doc/latest/user/index.html", "anchor_text": "http://numba.pydata.org/numba-doc/latest/user/index.html"}, {"url": "https://github.com/ContinuumIO/gtc2018-numba", "anchor_text": "https://github.com/ContinuumIO/gtc2018-numba"}, {"url": "http://stephanhoyer.com/2015/04/09/numba-vs-cython-how-to-choose/", "anchor_text": "http://stephanhoyer.com/2015/04/09/numba-vs-cython-how-to-choose/"}, {"url": "https://medium.com/tag/data-science?source=post_page-----293e554c5cc1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/parallel-computing?source=post_page-----293e554c5cc1---------------parallel_computing-----------------", "anchor_text": "Parallel Computing"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----293e554c5cc1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----293e554c5cc1---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----293e554c5cc1---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "http://creativecommons.org/licenses/by/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F293e554c5cc1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&user=Puneet+Grover&userId=dfddda6ba487&source=-----293e554c5cc1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F293e554c5cc1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&user=Puneet+Grover&userId=dfddda6ba487&source=-----293e554c5cc1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F293e554c5cc1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F293e554c5cc1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----293e554c5cc1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----293e554c5cc1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----293e554c5cc1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----293e554c5cc1--------------------------------", "anchor_text": ""}, {"url": "https://techelfpuneet.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://techelfpuneet.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Puneet Grover"}, {"url": "https://techelfpuneet.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "408 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfddda6ba487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&user=Puneet+Grover&userId=dfddda6ba487&source=post_page-dfddda6ba487--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8beb028904ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-algorithms-part-2-numba-293e554c5cc1&newsletterV3=dfddda6ba487&newsletterV3Id=8beb028904ce&user=Puneet+Grover&userId=dfddda6ba487&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}