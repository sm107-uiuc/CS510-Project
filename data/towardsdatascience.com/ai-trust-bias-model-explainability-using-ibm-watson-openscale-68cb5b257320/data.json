{"url": "https://towardsdatascience.com/ai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320", "time": 1683000373.007976, "path": "towardsdatascience.com/ai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320/", "webpage": {"metadata": {"title": "AI Trust, Model Bias & Explainability using IBM Watson Openscale | by George Regkas | Towards Data Science", "h1": "AI Trust, Model Bias & Explainability using IBM Watson Openscale", "description": "AI trust, bias and model explainability provide a significant piece in the business puzzle to help organizations get AI projects out of development and put them into production at scale. AI bias and\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["AI trust, bias and model explainability provide a significant piece in the business puzzle to help organizations get AI projects out of development and put them into production at scale. AI bias and model explainability helps ensure fair and unbiased outcomes while giving business process owners confidence in AI\u2019s ability to augment decision-making. At the same time, it provides a robust framework to ensure that AI maintains compliance with corporate policies and regulatory requirements.", "A short survey showed that business stakeholders have mixed and confusing feedback regarding their trust to AI applications for various reasons:", "Furthermore, it is widely known among business owners that there are existing challenges related to bias and explainability:", "Watson OpenScale achieves these goals by focusing on 4 stages of an AI application\u2019s lifecycle: Build, Run, Manage and In-App operations.", "At build time, data scientists use their preferred popular open source frameworks and tools while gaining access to toolkits for bias detection and explainability of transactions.", "Development and operations teams then scale and manage AI applications using their existing DevOps tools and processes in the runtime environment.", "As a result, business users are then able to measure and trace the outcome of individual AI workflows for auditing and regulatory purposes.", "Watson OpenScale helps deliver and operate trusted AI apps for business users at scale:", "a. Define business KPIs and feed into existing business applications to measure business impactb. Define app contract to evaluate AI models at build time and get metrics to track those in run-timec. Actionable metrics and alerts through error analysis and descriptive analytics of payload, in runtime", "2. Meet regulatory constraints & govern AI in production", "a. Simulate business conditions with operations data, validate and approve AI models for productionb. Trace and explain AI decisions for full audit across multiple models in an appc. AI-powered bias detection and mitigation in run time, to drive fair outcomes", "3. Adapt AI to changing business situation in production", "a. Collect feedback through existing business apps to teach the AI, in runtimeb. Detect drift in business situations, alert users and trigger actions to mitigate", "c. Automatically trigger model retraining pipelines with specific inputs from payload analytics to meet business goals and adapt to new data", "Indicative example: A bank was fined for unequal treatment of minority customers. Minority customers were given fewer loans and charged a higher interest rate.", "How can Watson Openscale help to mitigate this bias in this case in model development?", "Step 1: Monitor Predictions, Model Performance and Accuracy", "Openscale provides a dashboard which displays model accuracy. Model accuracy is determined using the standard model evaluation approaches (different for various model types).", "Step 2: Provide an explanation for model predictions", "We can use the explainability feature to understand why certain predictions are made. The two main components of explainability are:", "Predictor Importance: Which factors/predictors influence the prediction", "Statistical Significance: Identify the statistical importance of each predictor", "Constrastive Explanation: which features do we need to change in order to control the prediction", "Step 3: Monitor for unfair predictions and automatically correct them", "i. Define protected fields: typically demographic information about a customer, such as race, age, gender, population segment", "ii. Define the context: number of records to use for determining the threshold i.e. evaluate every 100 approvals or every 1000 loan applications", "iii. Define a threshold for bias, defined as a percentage of minority approvals compared to approvals of majority. Optionally, OpenScale can \u201cde-bias\u201d the model, i.e automatically correct the results:", "Models embedded in production need to make fair decisions and can not be biased in their recommendations. Those that they exhibit bias need to be corrected without interfering in current path of predictions to application.", "Most of the industries are embracing AI taking into account AI Model Bias, Model Explainability and Trust.", "Industry-wide use cases leveraging on Watson Openscale from telecom to financial services and healthcare:", "Effectively maintaining physical assets and infrastructure is essential for telco industry \u2014 asset failure can lead to service outages, a key cause of customer churn. Maintenance prioritization is an expensive and difficult process, and it\u2019s often difficult to catch asset failure in the field before it leads to a problem on the network. Machine learning offers an opportunity to predict failure based on sensor data before a problem occurs.", "Predictive maintenance of network infrastructure can prevent outages that lead to costly customer churn, but training a model on historical asset data is difficult because failures tend to be rare \u2014 training a predictive model can be time consuming, and even after it\u2019s trained, it may not accurately perform in all failure scenarios", "Watson OpenScale\u2019s runtime monitoring features allow teams to track performance of their models in the field, on real data, to ensure continued performance \u2014 and guide retraining when necessary. OpenScale\u2019s traceability features also help engineers and technicians capture information critical for an audit trail, so the organization can more easily connect preventative maintenance actions taken because of the model with key business outcomes \u2014 like failure prevention and increased customer satisfaction.", "The insurance industry market landscape is becoming increasingly competitive. Companies are trying to streamline their processes with the help of data science and AI \u2014 and insurance underwriting is a prime target for AI insights. Traditional underwriting methods rely on complex rules-based processes and expensive manual analysis, whereas machine learning models can analyze complex interactions among diverse data to deliver risk scores.", "Risk assessment models trained on historical customer and claims data can help underwriters make more consistent and accurate decisions. These models can provide price suggestions for individual customers based on different features in their profile.", "Watson OpenScale\u2019s explainability features allow underwriters and regulators to see the exact features prioritized by these risk assessment models, on a decision-by-decision basis. During a Department of Insurance audit, commissioners can review model lineage, inputs, and outputs for each decision in business-friendly language. Its bias detection and mitigation features help underwriters ensure that these models continue to make fair decisions after they\u2019ve been deployed.", "3. Financial Services: Credit Risk Modeling", "Traditional lenders are under pressure to expand their digital portfolio of financial services to a larger and more diverse audience, which requires a new approach to credit risk modeling. To provide credit access to a wider and riskier population, applicant credit histories must expand beyond traditional credit \u2014 like mortgages and car loans \u2014 to alternate sources, such as utility and cell plan payment histories, plus education and job titles.", "These additional features increase the likelihood of unexpected correlations that introduce bias based on an applicant\u2019s age, gender and other personal traits. The data science techniques most suited to these diverse datasets can generate highly accurate risk models but at a cost \u2014 such models are black boxes whose inner workings are not easily understood.", "Banks and credit unions need to be able to check their credit risk models for bias, not just during training but also after these models are deployed. And in order to be compliant with regulations like the Equal Credit Opportunity Act, they need to be able to explain why their models make individual credit decisions.", "Watson OpenScale\u2019s bias detection and mitigation features allow risk and governance officers to monitor bias within their models at runtime. And Watson OpenScale\u2019s explainability support provides loan officers and credit analysts with post-facto explanations for model decisions which provide high accuracy in credit risk modeling.", "4. Supply Chain: Effective Demand Forecasting", "Effective demand forecasting is essential to keeping operational costs down while still meeting consumer demand \u2014 but it\u2019s very difficult. Companies aren\u2019t equipped to deal with the volume and diversity of data needed to account for real-time changes in demand. Forecasts that can\u2019t adapt to constantly-changing variables in today\u2019s market can lead to multimillion-dollar miscalculations, severely damaging a company\u2019s bottom line", "Demand forecasters must constantly monitor the performance of their deployed models to prevent miscalculations that could cost their organizations millions of dollars in lost revenue. The data these models rely on are not stationary, and the statistical properties of their distributions will keep shifting as new actuals come in.", "Watson OpenScale\u2019s runtime monitoring features allow demand planners to track performance of their deployed models in production, so they can ensure accuracy and identify skewed results and inherent bias in the data.", "Specific diseases are so complex and difficult to identify early, as its symptoms overlap with those of other common illnesses. Mortality from sspecific disease diagnosis increases every hour that treatment is delayed \u2014 so it is critical for doctors and nurses to be able to catch them before patients go into disease shock. Being able to identify those patients who are at highest risk can help clinicians prioritize care. Machine learning models can be trained on hospitalization data and patient data to identify high-risk patients and predict death outcomes. The algorithms and methods used to build accurate models, such as XGBoost gradient boosted trees, do sometimes behave like black boxes.", "Watson OpenScale\u2019s explainability features provide a breakdown of the specific patient and hospitalization characteristics that contribute to the decision for each prediction that is made. These results are displayed in a language that the clinicians caring for the patient can understand, increasing their trust in the predictive models and helping them make better care decisions. OpenScale also provides traceability features and runtime monitoring, so the hospital has an audit trail for all patient care decisions that are made and can track the performance of these models over time.", "Disclaimer: The views expressed here are those of the article\u2019s author(s) and may or may not represent the views of IBM Corporation. Part of the content on the blog is copyright and all rights are reserved \u2014 but, unless otherwise noted under IBM Corporation (e.g. photos, images).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Lead Data Scientist, Data & AI, Client Engineering, IBM Middle East"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F68cb5b257320&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----68cb5b257320--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----68cb5b257320--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@geotzal?source=post_page-----68cb5b257320--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@geotzal?source=post_page-----68cb5b257320--------------------------------", "anchor_text": "George Regkas"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8b838f729c32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&user=George+Regkas&userId=8b838f729c32&source=post_page-8b838f729c32----68cb5b257320---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68cb5b257320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68cb5b257320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----68cb5b257320---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----68cb5b257320---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai-trust?source=post_page-----68cb5b257320---------------ai_trust-----------------", "anchor_text": "Ai Trust"}, {"url": "https://medium.com/tag/ai-bias?source=post_page-----68cb5b257320---------------ai_bias-----------------", "anchor_text": "Ai Bias"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68cb5b257320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&user=George+Regkas&userId=8b838f729c32&source=-----68cb5b257320---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68cb5b257320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&user=George+Regkas&userId=8b838f729c32&source=-----68cb5b257320---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68cb5b257320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----68cb5b257320--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F68cb5b257320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----68cb5b257320---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----68cb5b257320--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----68cb5b257320--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----68cb5b257320--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----68cb5b257320--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----68cb5b257320--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----68cb5b257320--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----68cb5b257320--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----68cb5b257320--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@geotzal?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@geotzal?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "George Regkas"}, {"url": "https://medium.com/@geotzal/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "55 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8b838f729c32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&user=George+Regkas&userId=8b838f729c32&source=post_page-8b838f729c32--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F912048fda3f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-trust-bias-model-explainability-using-ibm-watson-openscale-68cb5b257320&newsletterV3=8b838f729c32&newsletterV3Id=912048fda3f0&user=George+Regkas&userId=8b838f729c32&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}