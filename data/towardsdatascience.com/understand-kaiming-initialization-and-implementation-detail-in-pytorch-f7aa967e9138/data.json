{"url": "https://towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138", "time": 1682997542.484417, "path": "towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138/", "webpage": {"metadata": {"title": "Understand Kaiming Initialization and Implementation Detail in PyTorch | by Xu LIANG | Towards Data Science", "h1": "Understand Kaiming Initialization and Implementation Detail in PyTorch", "description": "Initialization is a process to create weight. In the below code snippet, we create a weight w1 randomly with the size of(784, 50). You may wonder why need we care about initialization if the weight\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1502.01852.pdf", "anchor_text": "Kaiming et al.", "paragraph_index": 10}, {"url": "https://pytorch.org/docs/stable/nn.html#torch.nn.init.kaiming_normal_", "anchor_text": "nn.init.kaiming_normal_()", "paragraph_index": 18}, {"url": "https://pytorch.org/docs/stable/nn.html#torch.nn.init.kaiming_normal_", "anchor_text": "document", "paragraph_index": 22}, {"url": "https://github.com/pytorch/pytorch/blob/d58059bc6fa9b5a0c9a3186631029e4578ca2bbd/torch/nn/init.py#L202", "anchor_text": "source code", "paragraph_index": 25}, {"url": "https://pytorch.org/docs/stable/nn.html#torch.nn.init.kaiming_normal_", "anchor_text": "nn.init.kaiming_normal_()", "paragraph_index": 25}, {"url": "https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L1354", "anchor_text": "torch.nn.functional.linear", "paragraph_index": 28}, {"url": "https://gist.github.com/BrambleXu/feb892476202ecc55d03f1f377869755", "anchor_text": "snippet", "paragraph_index": 33}, {"url": "https://medium.com/@bramblexu", "anchor_text": "Medium", "paragraph_index": 34}, {"url": "https://bramblexu.com/posts/eb7bd472/", "anchor_text": "a categorized view", "paragraph_index": 34}, {"url": "https://github.com/BrambleXu", "anchor_text": "BrambleXu", "paragraph_index": 34}, {"url": "https://www.linkedin.com/in/xu-liang-99356891/", "anchor_text": "Xu Liang", "paragraph_index": 34}, {"url": "https://bramblexu.com", "anchor_text": "BrambleXu", "paragraph_index": 34}, {"url": "http://linkedin.com/in/xu-liang-99356891/", "anchor_text": "linkedin.com/in/xu-liang-99356891/", "paragraph_index": 36}], "all_paragraphs": ["If you create weight implicitly by creating a linear layer, you should set modle='fan_in'.", "If you create weight explicitly by creating a random matrix, you should set modle='fan_out'.", "The content is structured as follows.", "Initialization is a process to create weight. In the below code snippet, we create a weight w1 randomly with the size of(784, 50).", "torhc.randn(*sizes) returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution). The shape of the tensor is defined by the variable argument sizes.", "And this weight will be updated during the training phase.", "You may wonder why need we care about initialization if the weight can be updated during the training phase. No matter how to initialize the weight, it will be updated \u201cwell\u201d eventually.", "But the reality is not so sweet. If we random initialize the weight, it will cause two problems, the vanishing gradient problem and exploding gradient problem.", "Vanishing gradient problem means weights vanish to 0. Because these weights are multiplied along with the layers in the backpropagation phase. If we initialize weights very small(<1), the gradients tend to get smaller and smaller as we go backward with hidden layers during backpropagation. Neurons in the earlier layers learn much more slowly than neurons in later layers. This causes minor weight updates.", "Exploding gradient problem means weights explode to infinity(NaN). Because these weights are multiplied along with the layers in the backpropagation phase. If we initialize weights very large(>1), the gradients tend to get larger and larger as we go backward with hidden layers during backpropagation. Neurons in the earlier layers update in huge steps, W = W \u2014 \u237a * dW, and the downward moment will increase.", "Kaiming et al. derived a sound initialization method by cautiously modeling non-linearity of ReLUs, which makes extremely deep models (>30 layers) to converge. Below is the Kaiming initialization function.", "We compare the random initialization and Kaiming initialization to show the effectiveness of Kaiming initialization.", "We initialize weight with a normal distribution with mean 0 and variance 1, and the ideal distribution of weight after ReLU should have slightly incremented mean layer by layer and variance close to 1. But the distribution changes a lot after some layers in the feedforward phase.", "Why the mean of weight should be slightly incremented layer by layer?", "Because we use the ReLU as the activation function. ReLU will return the value provided if input value is bigger than 0 and return value 0 if the input value is less than 0.", "After ReLU, all negative values become 0. The mean will become larger when the layer becomes deeper.", "We initialize weight with a normal distribution with mean 0 and variance std, and the ideal distribution of weight after relu should have slightly incremented mean layer by layer and variance close to 1. We can see the output is close to what we expected. The mean increment slowly and std is close to 1 in the feedforward phase. And such stability will avoid the vanishing gradient problem and exploding gradient problem in the backpropagation phase.", "Kaiming initialization shows better stability than random initialization.", "nn.init.kaiming_normal_() will return tensor that has values sampled from mean 0 and variance std. There are two ways to do it.", "One way is to create weight implicitly by creating a linear layer. We set mode='fan_in' to indicate that using node_in calculate the std", "Another way is to create weight explicitly by creating a random matrix, you should set mode='fan_out'.", "Two implementation methods are both right. The mean is close to 0.5 and std is close to 1. But wait a minute, do you find something strange?", "According to the document, choosing 'fan_in' preserves the magnitude of the variance of the weights in the forward pass. Choosing 'fan_out' preserves the magnitudes in the backward pass. We can write as below.", "In the linear layer implementation, we set mode='fan_in'. Yes, this is the feedforward phase, we should set mode='fan_in' . Nothing wrong.", "But why we set the mode as fan_out in the weight matrix implementation?", "The reason behind the source code of nn.init.kaiming_normal_()", "This is the source code to get the right mode. The tensor is the w1 with size of (784, 50). So fan_in = 50, fan_out=784. When we set the mode as fan_out in the weight matrix implementation. The init.kaiming_normal_() actually calculates like below.", "Ok, make sense. But how to explain using fan_in in the linear layer implementation?", "When we use linear to create weight implicitly, the weight is transposed implicitly. Here is the source code of torch.nn.functional.linear.", "The weight is initialized with the size of (out_features, in_features). For example, if we input the size (784, 50) , the size of weight is actually (50, 784).", "That\u2019s why linear need to first transpose the weight and then do the matmul operation.", "Because the weight in the linear layer has size of (50, 784), the init.kaiming_normal_() actually calculates like below.", "In this post, I first talked about why initialization matters and what is kaiming initialization. And I break down how to use PyTorch to implement it. Hope this post be helpful. Leave a comment if you have any advice.", "The full code in this snippet.", "Check out my other posts on Medium with a categorized view!GitHub: BrambleXuLinkedIn: Xu LiangBlog: BrambleXu", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m an engineer focusing on NLP and Data Science. I write stuff to repay the engineer community. You can find me on linkedin.com/in/xu-liang-99356891/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff7aa967e9138&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@bramblexu?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "Xu LIANG"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fee86e6752cb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&user=Xu+LIANG&userId=ee86e6752cb4&source=post_page-ee86e6752cb4----f7aa967e9138---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7aa967e9138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7aa967e9138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@tateisimikito?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Jukan Tateisi"}, {"url": "https://unsplash.com/search/photos/challenge?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1502.01852.pdf", "anchor_text": "Kaiming et al."}, {"url": "https://pytorch.org/docs/stable/nn.html#torch.nn.init.kaiming_normal_", "anchor_text": "nn.init.kaiming_normal_()"}, {"url": "https://pytorch.org/docs/stable/nn.html#torch.nn.init.kaiming_normal_", "anchor_text": "document"}, {"url": "https://github.com/pytorch/pytorch/blob/d58059bc6fa9b5a0c9a3186631029e4578ca2bbd/torch/nn/init.py#L202", "anchor_text": "source code"}, {"url": "https://pytorch.org/docs/stable/nn.html#torch.nn.init.kaiming_normal_", "anchor_text": "nn.init.kaiming_normal_()"}, {"url": "https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L1354", "anchor_text": "torch.nn.functional.linear"}, {"url": "https://gist.github.com/BrambleXu/feb892476202ecc55d03f1f377869755", "anchor_text": "snippet"}, {"url": "https://medium.com/@bramblexu", "anchor_text": "Medium"}, {"url": "https://bramblexu.com/posts/eb7bd472/", "anchor_text": "a categorized view"}, {"url": "https://github.com/BrambleXu", "anchor_text": "BrambleXu"}, {"url": "https://www.linkedin.com/in/xu-liang-99356891/", "anchor_text": "Xu Liang"}, {"url": "https://bramblexu.com", "anchor_text": "BrambleXu"}, {"url": "https://towardsdatascience.com/what-is-weight-initialization-in-neural-nets-and-why-it-matters-ec45398f99fa", "anchor_text": "Why cautiously initializing deep neural networks matters?"}, {"url": "https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94", "anchor_text": "Deep Learning Best Practices (1) \u2014 Weight Initialization"}, {"url": "https://arxiv.org/pdf/1502.01852.pdf", "anchor_text": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"}, {"url": "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/", "anchor_text": "A Gentle Introduction to the Rectified Linear Unit (ReLU)"}, {"url": "https://course.fast.ai/videos/?lesson=8", "anchor_text": "Fast.ai\u2019s course Deep Learning for coders lesson 8"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f7aa967e9138---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f7aa967e9138---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----f7aa967e9138---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----f7aa967e9138---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----f7aa967e9138---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7aa967e9138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&user=Xu+LIANG&userId=ee86e6752cb4&source=-----f7aa967e9138---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7aa967e9138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&user=Xu+LIANG&userId=ee86e6752cb4&source=-----f7aa967e9138---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7aa967e9138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff7aa967e9138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f7aa967e9138---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f7aa967e9138--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f7aa967e9138--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f7aa967e9138--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Xu LIANG"}, {"url": "https://medium.com/@bramblexu/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "http://linkedin.com/in/xu-liang-99356891/", "anchor_text": "linkedin.com/in/xu-liang-99356891/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fee86e6752cb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&user=Xu+LIANG&userId=ee86e6752cb4&source=post_page-ee86e6752cb4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd5c245665a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138&newsletterV3=ee86e6752cb4&newsletterV3Id=d5c245665a2&user=Xu+LIANG&userId=ee86e6752cb4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}