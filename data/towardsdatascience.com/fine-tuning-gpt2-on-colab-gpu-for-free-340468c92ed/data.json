{"url": "https://towardsdatascience.com/fine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed", "time": 1683009093.3410718, "path": "towardsdatascience.com/fine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed/", "webpage": {"metadata": {"title": "Fine-Tuning GPT2 on Colab GPU\u2026 For Free! | by Joey S | Towards Data Science", "h1": "Fine-Tuning GPT2 on Colab GPU\u2026 For Free!", "description": "Leveraging Google Colab\u2019s GPU to fine-tune pretrained GPT2 on PyTorch"}, "outgoing_paragraph_urls": [{"url": "http://huggingface.co", "anchor_text": "HuggingFace", "paragraph_index": 0}, {"url": "https://huggingface.co/transformers/pretrained_models.html", "anchor_text": "pretrained models in PyTorch", "paragraph_index": 0}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab", "paragraph_index": 0}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab", "paragraph_index": 1}, {"url": "https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/", "anchor_text": "WikiText data here", "paragraph_index": 4}, {"url": "https://github.com/huggingface/transformers/tree/master/examples/language-modeling", "anchor_text": "here", "paragraph_index": 5}, {"url": "https://github.com/huggingface/transformers/tree/master/examples/language-modeling", "anchor_text": "reading the manual", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Jordan_Mathews", "anchor_text": "Jordan Matthews", "paragraph_index": 18}], "all_paragraphs": ["Models these days are very big, and most of us don\u2019t have the resources to train them from scratch. Luckily, HuggingFace has generously provided pretrained models in PyTorch, and Google Colab allows usage of their GPU (for a fixed time). Otherwise, even fine-tuning a dataset on my local machine without a NVIDIA GPU would take a significant amount of time. While the tutorial here is for GPT2, this can be done for any of the pretrained models given by HuggingFace, and for any size too.", "Go to Google Colab and create a new notebook. It should look something like this.", "Set to use GPU by clicking Runtime > Change runtime type", "We would run pip3 install transformers normally in Bash, but because this is in Colab, we have to run it with !", "You can read more about WikiText data here. Overall, there\u2019s WikiText-2 and WikiText-103. We\u2019re going to use WikiText-2 because it\u2019s smaller, and we have limits in terms of how long we can run on GPU, and how much data we can load into memory in Colab. To download and run, in a cell, run", "HuggingFace actually provides a script to help fine-tune models here. We can just download the script by running", "Now we are ready to fine-tune.", "There are many parameters to the script, and you can understand them by reading the manual. I\u2019m just going to go over the important ones for basic training.", "Some extra ones you MAY care about, but you can also skip this.", "All in all, to train, run this in a cell", "Note that if you want to fine-tune the model you just trained, you can change MODEL_NAME=gpt2 to MODEL_NAME=output/ so it\u2019ll load the model we just trained", "When you run this, if it takes some time without any output, you can hover over the RAM/Disk on the top right corner to see what\u2019s happening.", "The downside to Colab GPU is that it\u2019s shared between Colab users. That means execution may not happen right away, as it\u2019s being used by another user. When that happens, it\u2019ll say something like", "There\u2019s really nothing to do but wait it out.", "After you\u2019ve finished running the model, you can check that it exists in your output directory.", "To use it, you can run something like", "where = Toronto Raptors = is the equivalent of describing Toronto Raptors as the title of the article.", "The result I got (and yours will differ) is", "From my example, I only generated the first 250 words, which is why it was cut off so abruptly. You can expand that if you want. Notice that this description of the Toronto Raptors is completely fake, as Jordan Matthews never played for the Raptors. The text coherency can be better as well, which can be adjusted by tuning with more epochs, or simply using a larger model. However, that requires more memory, so be careful with it.", "In order for us to preserve this model, we should compress it and save it somewhere. This can be done easily with", "which creates a file called gpt2-tuned.tar.gz", "To save it to your Google Drive from Colab, first you must have a Google account/Gmail account. In your Colab cell, you can run", "without needing to install anything additional, since google.colab library comes with using Google Colab. When you run the code described above, you should see something like this", "You have to click on the link, sign in and allow your Google Drive to access the your Colab. Then at the end, you\u2019ll see something like", "Copy that and paste it back into your Colab notebook.", "Now you can copy your output model to your Google Drive by running", "And Voila! You\u2019ve successfully tuned a pretrained model on a GPU, and saved it in your Google Drive. And you did it completely for free.", "If you have any questions or improvements based on what we\u2019ve worked on, please let me know in the comments.", "You can run this Colab Notebook to reproduce everything shown above", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior Machine Learning Engineer \u2014 Snaptravel"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F340468c92ed&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----340468c92ed--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----340468c92ed--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://joeyism.medium.com/?source=post_page-----340468c92ed--------------------------------", "anchor_text": ""}, {"url": "https://joeyism.medium.com/?source=post_page-----340468c92ed--------------------------------", "anchor_text": "Joey S"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fadafcd009fc8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&user=Joey+S&userId=adafcd009fc8&source=post_page-adafcd009fc8----340468c92ed---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F340468c92ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F340468c92ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@celinen?utm_source=medium&utm_medium=referral", "anchor_text": "Celine Nadon"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://huggingface.co", "anchor_text": "HuggingFace"}, {"url": "https://huggingface.co/transformers/pretrained_models.html", "anchor_text": "pretrained models in PyTorch"}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab"}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab"}, {"url": "https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/", "anchor_text": "WikiText data here"}, {"url": "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip", "anchor_text": "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip"}, {"url": "https://github.com/huggingface/transformers/tree/master/examples/language-modeling", "anchor_text": "here"}, {"url": "https://github.com/huggingface/transformers/tree/master/examples/language-modeling", "anchor_text": "reading the manual"}, {"url": "https://huggingface.co/transformers/pretrained_models.html", "anchor_text": "HuggingFace pretrained models list"}, {"url": "https://en.wikipedia.org/wiki/Jordan_Mathews", "anchor_text": "Jordan Matthews"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----340468c92ed---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/gpt2?source=post_page-----340468c92ed---------------gpt2-----------------", "anchor_text": "Gpt2"}, {"url": "https://medium.com/tag/fine-tuning?source=post_page-----340468c92ed---------------fine_tuning-----------------", "anchor_text": "Fine Tuning"}, {"url": "https://medium.com/tag/gpu?source=post_page-----340468c92ed---------------gpu-----------------", "anchor_text": "Gpu"}, {"url": "https://medium.com/tag/google-colab?source=post_page-----340468c92ed---------------google_colab-----------------", "anchor_text": "Google Colab"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F340468c92ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&user=Joey+S&userId=adafcd009fc8&source=-----340468c92ed---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F340468c92ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&user=Joey+S&userId=adafcd009fc8&source=-----340468c92ed---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F340468c92ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----340468c92ed--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F340468c92ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----340468c92ed---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----340468c92ed--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----340468c92ed--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----340468c92ed--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----340468c92ed--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----340468c92ed--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----340468c92ed--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----340468c92ed--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----340468c92ed--------------------------------", "anchor_text": ""}, {"url": "https://joeyism.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://joeyism.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Joey S"}, {"url": "https://joeyism.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "63 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fadafcd009fc8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&user=Joey+S&userId=adafcd009fc8&source=post_page-adafcd009fc8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F85043adc6245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-gpt2-on-colab-gpu-for-free-340468c92ed&newsletterV3=adafcd009fc8&newsletterV3Id=85043adc6245&user=Joey+S&userId=adafcd009fc8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}