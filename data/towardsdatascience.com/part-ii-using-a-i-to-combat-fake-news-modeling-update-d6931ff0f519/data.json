{"url": "https://towardsdatascience.com/part-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519", "time": 1683007464.645458, "path": "towardsdatascience.com/part-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519/", "webpage": {"metadata": {"title": "Part II: Using A.I to Combat Fake News Modeling Update | by Michael Harder | Towards Data Science", "h1": "Part II: Using A.I to Combat Fake News Modeling Update", "description": "In this follow-up post to our post on Fake News classification, we will introduce our own updated model and walk you through the steps. To quickly summarize, the task at hand is composed of 49,972\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/abe8cf70429?source=post_page-----725daee16102----------------------", "anchor_text": "David Kebudi", "paragraph_index": 0}, {"url": "https://medium.com/u/da8692cb0f64?source=post_page-----725daee16102----------------------", "anchor_text": "Jason Katz", "paragraph_index": 0}, {"url": "https://medium.com/u/8c20c2ac3641?source=post_page-----725daee16102----------------------", "anchor_text": "Michael Harder", "paragraph_index": 0}, {"url": "https://medium.com/u/29b5f12bdec0?source=post_page-----725daee16102----------------------", "anchor_text": "Naina Wodon", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/using-a-i-to-combat-fake-news-34f5a51907d6", "anchor_text": "Part I: Using A.I. to Combat Fake News", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/part-iii-using-a-i-to-combat-fake-news-final-model-933f75657ae0", "anchor_text": "Part III: Using A.I to Combat Fake News Final Model", "paragraph_index": 2}, {"url": "http://www.fakenewschallenge.org", "anchor_text": "competition website", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Readability_test", "anchor_text": "readability test", "paragraph_index": 15}, {"url": "https://bitbucket.org/spirit/language_tool/src/default/", "anchor_text": "Language Tool", "paragraph_index": 16}, {"url": "https://github.com/uclnlp/fakenewschallenge", "anchor_text": "https://github.com/uclnlp/fakenewschallenge", "paragraph_index": 35}], "all_paragraphs": ["Work conducted by: David Kebudi, Jason Katz, Michael Harder, and Naina Wodon", "Part I: Using A.I. to Combat Fake News", "Part III: Using A.I to Combat Fake News Final Model", "In this follow-up post to our post on Fake News classification, we will introduce our own updated model and walk you through the steps. To quickly summarize, the task at hand is composed of 49,972 observations. Of the 49,972, about 75% or 36,545 of them belong to the \u201cunrelated\u201d class. The goal of the task is to classify the input data, which is a headline of an article and its associated article body, as (1) agree, (2) disagree, (3) discuss or (4) unrelated. The discuss label compromised 17.8% (8,909 obs.) of the data, followed by the agree label (7.3%), and the disagree label (1.68%).", "The competition website provides competitors with a training set and a test set, and a baseline GradientBoosting classifier with a weighted accuracy score of 79.53%. The task is a multi-label multi-class problem, where the network needs to first decide if the headline and body are related or unrelated, and only then, if the two are related, categorize their relationship as agree, disagree or discuss.", "The accuracy scores of the submissions to the competition are calculated through a function given by the competition\u2019s organizers and can be summarized as:", "The winning model, with a 82.02% accuracy score, is the model we are trying to improve upon in this project. The neural network architecture of the winning model is as follows:", "The architecture of the model treats the problem as a multi-class, multi-label problem and feeds both of the inputs, headline texts and body, into the network. However, in doing so, they use different embedding layers, customized for the headline and/or body, with the inputs concatenating later on in the network. The inputs go through a series of identical convolutional layers, eventually going through a series of dense layers post-concatenation. The last layer of the network is a dense layer with 4 tensors, representing the 2 categories and their 3 (agree, disagree, discuss) and 1 labels (related, unrelated).", "The model, however, does not process the engineered features such as sentiment features about the text, in the neural network. Instead, the architects of the model opted to use a XGBoost classifier, that classifies the data.", "They then combine the two models, the CNN and XGBoost, with a weighted average for predictions. With this technique, they achieve 82.02%.", "Our model improves on 2 main points: (1) treats the problem as a classification problem and (2) feeds the engineered features into the CNN.", "The problem defined by the competition, as explained above, is inherently a multi-label multi-class problem. However, we do not have to solve it as one. We can split the problem into two main chunks, where we train models for the two different classifications.", "The first model is to classify whether the headline and the body are related or unrelated. This model takes in the headlines, bodies, engineered features and labels. However, it is important to note that the data given by the competition does not have any label named \u201crelated\u201d. Instead, if related, the data simply classifies the headline/body relationship as agree/disagree/discuss. Thus, we need to create a new dataset with the label \u201crelated\u201d in the place of \u201cagree/disagree/discuss\u201d. To do so, we simply use the following chunk of code:", "We concatenate the agree dataset, which refers to the dataset that only has \u201crelated\u201d headline/body pairs, with the related dataset, which only has the \u201cunrelated\u201d labels. Then we simply code anything that is not \u201cunrelated\u201d in the labels and \u201crelated\u201d. This also allows us to use the whole dataset for training the related/unrelated model. It is important to remember to shuffle the new data frame after the concatenation. Without it, the dataset labels will be polarized at the beginning and at the end. (unrelated at the top, related at the bottom).", "The second model simply classifies the relationship between headline and body as agree/disagree/discuss. The dataset for the second model is significantly smaller than that of the first model. This is because only 25% of the whole data is actually classified as \u201crelated\u201d. It is also important to note that the two models are identical.", "Instead of using an XGBoost, we decided to create a third input to the network, composed of Dense layers. This input would be a matrix nx3, where n is the number of observations and 3 represents the three engineered features: [\u201cfk_scores\u201d, \u201cword_count\u201d, \u201cnum_grammar_errors\u201d]. All of these 3 features are for the body. fk_score is a widely used linguistic metric that measures the complexity of the language the article was written in. The Flesch-Kincaid grade level test is a readability test designed to indicate how difficult a passage in English is to understand. It is calculated as:", "The result of the function is a number that corresponds with a U.S. grade level. \u201cnum_grammar_errors\u201d was calculated using a program called Language Tool, which checks a body of text for grammar errors. The model is composed of two CNNs with different embeddings, and one dense network. The three later converges and concatenates, to be processed another few dense layers before the prediction.", "The convolutional networks, (input 1 and input 2 of the model), follow a simple architecture with two convolutional layers. They, output a dense layer with 34 tensors, which then connects to the concatenating layer.", "The embedding layer, which serves as the first layer of the network, is initialized using the embedding weights previously calculated using Google\u2019s word2vec.", "Before we train the embedding weights, we process the input data by taking out punctuation and then tokenizing the text into an array of words. We have entertained the thought of using a linguistic root reduction method which converts the words to their roots. Such that, \u201cdescribing\u201d and \u201cdescribed\u201d, both become \u201cdescribe\u201d. However, due to embedding concerns, we decided to not use rooting in this version of the model.", "We then import the word2vec Google has trained on billions of news articles:", "Then in a single embedding matrix creating method, we pass in the headlines and body of the model separately both for the agree dataset and related dataset. This gives us 4 matrixes to be used in the 2 different models for the two classifications.", "The Dense layers for the network are also very simple. We used the following architecture:", "It is important to note that, while we are not putting up the code for it; we used LabelEncoding and StandardScaler to preprocess the engineered features as well as the labels. After LabelEncoding we used one-hot-encoding for the multi-label agree/disagree/discuss model.", "To calculate the weighted accuracy score that the competition score described where a fourth of the score corresponds to correctly classifying the headline-body pairs as related or unrelated, and the remainder of the score corresponds to the accuracy score for correctly characterizing the headline-body pairs as in agreement, in disagreement, or as the body discusses the headline. As we can see from the graph below, the accuracy score for classifying headline-body pairs as related or unrelated was 73.13%.", "Surprisingly, across the 8 epochs the training and test scores stayed constant. The next graph below displays the accuracy scores of the second CNN which classifies the headline-body pairs into the agree, disagree, or discusses categories. As previously mentioned, only about 25% of the data was inputted into the second CNN as the other 75% was classified as unrelated in the first CNN. After 4 epochs the train accuracy score was 96.01%, and the test accuracy score was 94.97%. The overall weighted accuracy score was 89.51% = 73.13*(\u00bc) + 94.97*(\u00be), significantly higher than that of the baseline model score of 79.53%.", "Moreover, while this score was for the test set and not the final test data that was used in the competition and so this cannot be directly compared, it is still important to note that the winning model had an accuracy score of 82.02%. As such, we can hypothesize that the model outlined above performs better than the winning model.", "One way to improve the model is to train your own word2vec for your own corpus. Since this requires a very large dataset to train on, we can simply import Google\u2019s word2vec and then use TFIDF embedding to train the already trained weights according to our smaller dataset.", "To do so, you first need to calculate the TFIDF values in the vector space, which can easily be done by using the TfidfVectorizer.", "Once done, then you build a function that updates Google\u2019s word2vec matrix according to the TFIDF matrix calculated before.", "We then simply convert the tokenized words into the vector space using the new weights. This process also allows the user to skip the embedding layer, and simply feed the inputs to a convolutional layer.", "We attempted to use this method to build a more customized word2vector space however the process proved itself to be computationally expensive. Thus, we plan on doing this for the final leg of our project.", "Another way we can improve the project is to make out network more similar to that of the winning model\u2019s. This means treating the problem as a multi-label multi-class problem instead of two separate classification problems.", "There are two ways to do this. (1) we simply don\u2019t create two datasets as agree dataset and related dataset to be fed into the network but simply feed in a single dataset with multi-class, multi-label target variables. (2) we still have two networks but they converge before making a prediction. The last layer is a Dense layer with 4 tensors, treating the problem as multi-label multi-class problem it is.", "We can use upsampling in the related model to make the dataset more balanced. The related model, at 73% accuracy, is predicting the balance accuracy. The balance of the data is already 75% with 75% of the dataset being classified as unrelated.", "Github Repo for the third best model in the competition that used a cosine concatenation, when joining the inputs of the neural nets: https://github.com/uclnlp/fakenewschallenge", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Masters in Data Science student at Brown University"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd6931ff0f519&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@michael_harder?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@michael_harder?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "Michael Harder"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c20c2ac3641&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&user=Michael+Harder&userId=8c20c2ac3641&source=post_page-8c20c2ac3641----d6931ff0f519---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6931ff0f519&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6931ff0f519&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://www.fakenewschallenge.org/", "anchor_text": "competition"}, {"url": "https://medium.com/u/abe8cf70429?source=post_page-----725daee16102----------------------", "anchor_text": "David Kebudi"}, {"url": "https://medium.com/u/da8692cb0f64?source=post_page-----725daee16102----------------------", "anchor_text": "Jason Katz"}, {"url": "https://medium.com/u/8c20c2ac3641?source=post_page-----725daee16102----------------------", "anchor_text": "Michael Harder"}, {"url": "https://medium.com/u/29b5f12bdec0?source=post_page-----725daee16102----------------------", "anchor_text": "Naina Wodon"}, {"url": "https://towardsdatascience.com/using-a-i-to-combat-fake-news-34f5a51907d6", "anchor_text": "Part I: Using A.I. to Combat Fake News"}, {"url": "https://towardsdatascience.com/part-iii-using-a-i-to-combat-fake-news-final-model-933f75657ae0", "anchor_text": "Part III: Using A.I to Combat Fake News Final Model"}, {"url": "http://www.fakenewschallenge.org", "anchor_text": "competition website"}, {"url": "https://github.com/Cisco-Talos/fnc-1/tree/master/deep_learning_model", "anchor_text": "https://github.com/Cisco-Talos/fnc-1/tree/master/deep_learning_model"}, {"url": "https://github.com/Cisco-Talos/fnc-1/tree/master/tree_model", "anchor_text": "https://github.com/Cisco-Talos/fnc-1/tree/master/tree_model"}, {"url": "https://en.wikipedia.org/wiki/Readability_test", "anchor_text": "readability test"}, {"url": "https://bitbucket.org/spirit/language_tool/src/default/", "anchor_text": "Language Tool"}, {"url": "https://towardsdatascience.com/natural-language-processing-classification-using-deep-learning-and-word2vec-50cbadd3bd6a", "anchor_text": "https://towardsdatascience.com/natural-language-processing-classification-using-deep-learning-and-word2vec-50cbadd3bd6a"}, {"url": "https://github.com/uclnlp/fakenewschallenge", "anchor_text": "https://github.com/uclnlp/fakenewschallenge"}, {"url": "https://medium.com/saarthi-ai/sentence-classification-using-convolutional-neural-networks-ddad72c7048c", "anchor_text": "https://medium.com/saarthi-ai/sentence-classification-using-convolutional-neural-networks-ddad72c7048c"}, {"url": "https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/", "anchor_text": "https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/"}, {"url": "https://arxiv.org/pdf/1301.3781.pdf", "anchor_text": "https://arxiv.org/pdf/1301.3781.pdf"}, {"url": "https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/", "anchor_text": "https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/"}, {"url": "https://towardsdatascience.com/nlp-learning-series-part-1-text-preprocessing-methods-for-deep-learning-20085601684b", "anchor_text": "https://towardsdatascience.com/nlp-learning-series-part-1-text-preprocessing-methods-for-deep-learning-20085601684b"}, {"url": "https://github.com/Cisco-Talos/fnc-1/blob/master/deep_learning_model/Vectors.py", "anchor_text": "https://github.com/Cisco-Talos/fnc-1/blob/master/deep_learning_model/Vectors.py"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d6931ff0f519---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/fake-news?source=post_page-----d6931ff0f519---------------fake_news-----------------", "anchor_text": "Fake News"}, {"url": "https://medium.com/tag/ai?source=post_page-----d6931ff0f519---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6931ff0f519&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&user=Michael+Harder&userId=8c20c2ac3641&source=-----d6931ff0f519---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6931ff0f519&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&user=Michael+Harder&userId=8c20c2ac3641&source=-----d6931ff0f519---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6931ff0f519&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd6931ff0f519&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d6931ff0f519---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d6931ff0f519--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d6931ff0f519--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d6931ff0f519--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@michael_harder?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@michael_harder?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Michael Harder"}, {"url": "https://medium.com/@michael_harder/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "13 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c20c2ac3641&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&user=Michael+Harder&userId=8c20c2ac3641&source=post_page-8c20c2ac3641--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6544d303967e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpart-ii-using-a-i-to-combat-fake-news-modeling-update-d6931ff0f519&newsletterV3=8c20c2ac3641&newsletterV3Id=6544d303967e&user=Michael+Harder&userId=8c20c2ac3641&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}