{"url": "https://towardsdatascience.com/visualizing-bias-in-data-using-embedding-projector-649bc65e7487", "time": 1682996531.0628018, "path": "towardsdatascience.com/visualizing-bias-in-data-using-embedding-projector-649bc65e7487/", "webpage": {"metadata": {"title": "Visualizing Bias in Data using Embedding Projector | by Parul Pandey | Towards Data Science", "h1": "Visualizing Bias in Data using Embedding Projector", "description": "Before a machine learning model is deployed, its performance is evaluated. However, apart from the performance aspect, it is also important to know what the model has learnt. This is necessary so as\u2026"}, "outgoing_paragraph_urls": [{"url": "http://projector.tensorflow.org/", "anchor_text": "Embedding Projector", "paragraph_index": 3}, {"url": "http://projector.tensorflow.org/", "anchor_text": "Embedding Projector", "paragraph_index": 8}, {"url": "https://www.tensorflow.org/tensorboard/r1/summaries", "anchor_text": "TensorFlow", "paragraph_index": 9}, {"url": "http://projector.tensorflow.org/", "anchor_text": "projector.tensorflow.org", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Principal_component_analysis", "anchor_text": "PCA", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding", "anchor_text": "t-SNE", "paragraph_index": 13}, {"url": "https://umap-learn.readthedocs.io/en/latest/index.html", "anchor_text": "UMAP", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1802.03426", "anchor_text": "UMAP paper", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Wikipedia", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Word_embedding", "anchor_text": "word embeddings", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Text_corpus", "anchor_text": "corpus of text", "paragraph_index": 18}], "all_paragraphs": ["Debug your data before debugging your model", "Before a machine learning model is deployed, its performance is evaluated. However, apart from the performance aspect, it is also important to know what the model has learnt. This is necessary so as to ensure that the model hasn\u2019t learnt something discriminatory or biased.", "One way of approaching this problem is from a data visualisation perspective. By visualising how the model groups the data, we can get an idea of what the model thinks are similar and dissimilar data points. This is beneficial in order to understand why a model makes certain predictions and what kind of data is fed into the algorithm.", "In this article, we will look at a tool called Embedding Projector, which enables us to visualise high dimensional data easily so that we can understand what does a model learn about data.", "An embedding is essentially a low-dimensional space into which a high dimensional vector can be translated. During translation, an embedding preserves the semantic relationship of the inputs by placing similar inputs close together in the embedding space. Let\u2019s try and wrap our head around this concept with examples. Here is a grab from the creators of the Embedding projector.", "Words can also be represented as embeddings. Here is an example of a 300-dimensional embedding that maps words to vectors of real numbers. It is important to note that, the individual dimensional in these vectors do not provide much information. However, it\u2019s the overall patters of distance and location between different vectors that are of use to machine learning.", "Multidimensional space helps to group semantically related items together while keeping the dissimilar items apart. This can prove to be highly useful in a machine learning task. Consider the following visualisations of real embeddings:", "These embeddings capture the semantic relationships between words like verb tense, country capital relationship and gender analogies.", "Embedding Projector is a web application tool that interactively visualizes embeddings by reading them from our model and rendering them in two or three dimensions. Here is a visualisation of the ten thousand MNIST images which have been coloured by their label.", "The Embedding Projector is open-sourced and integrated into the TensorFlow platform or can be used as a standalone tool at projector.tensorflow.org. The standalone tool works without the need to install and run TensorFlow.", "The figure above shows the main view of the web app which consists of five distinct panels.", "The Embedding Projector offers four well-known methods for reducing the dimensionality of the data. Each method can be used to create either a two- or three-dimensional view for exploration.", "PCA is a technique which extracts a new set of variables called Principal Components from the existing data. These Principal Components are a linear combination of original features and try to capture as much information from the original dataset. The Embedding Projector computes the top 10 principal components for the data, from which we can choose two or three to view. Let\u2019s look at the PCA projection of 10000 MNIST Digits. Each MNIST digit has 784 pixels and the projection treats each pixel as a dimension.", "t-SNE or T-distributed stochastic neighbour embedding visualizes high-dimensional data by giving each data point a location in a two or three-dimensional map. This technique finds clusters in data thereby making sure that an embedding preserves the meaning in the data. The following t-SNE projection for the famous MNIST dataset clearly shows that similar digits are clustered together.", "A custom projection is a linear projection onto the horizontal and vertical axes which have been specified using the data labels. The custom projections mainly help to decipher the meaningful \u201cdirections\u201d in data sets.", "UMAP stands for Uniform Manifold Approximation and Projection for Dimension Reduction. t-SNE is an excellent technique to visualise high dimensional datasets but has certain drawbacks like high computation time and loss of large scale information. UMAP, on the other hand, tries to overcome these limitations as it can handle pretty large datasets easily while also preserving the local and global structure of data.", "If you are looking for the mathematical description please see the UMAP paper.", "We shall now examine how a Word2Vec model that has been trained to work with text, groups the meanings of words. It will be interesting to see these groupings since they will reveal a lot about the relationships between the words. The dataset has been included with the tool.", "Wikipedia describes Word2vec as a group of related models that are used to produce word embeddings. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space.", "We shall work with Word2Vec 10K dataset. Here each dot represents one word and every word has 200 dimensions. Let\u2019s quickly go through the steps to create the projections:", "Notice how juice, wine and fruit occur together while Macintosh, technology and microprocessor, are also grouped together at the top. It is important to note here that the model hasn\u2019t been told the meaning of words, instead, it has been just shown millions of sentences as examples of how words are used.", "Here are some more examples which will make things more clear.", "On the left is the cluster of words related to sound. The middle figure shows words similar to silver while the rightmost picture shows words related to soccer.", "Sometimes models learn things that are a cause for concern especially when machine learning models are used to make decisions for humans. This time we shall use the Word2Vec All corpus and search for the word Engineer to see its nearest neighbours. The embedding projector also allows us to reorient the visualization in order to perform more sophisticated tests for these cases so we shall re-orient our results using the Custom Projections tab.", "I fixed an axis that goes from man to woman so words closed to man lie towards left while words similar to woman will be found on the right. Let\u2019s look at the results for our anchor word which is Engineer, given the above axis.", "It appears that the word engineer is already closer to man than woman. The words closer to man are in orange and include astronomer, physicist, mathematician while words like dancer, songwriter, teacher appear closer to woman.", "How about changing the anchor word to math? Are the results affected? Let\u2019s see for ourselves:", "We have words like computational, geometry, arithmetic next to man, while the nearest neighbours to woman are music, teaching, philosophy etc.", "Imagine if a machine learning algorithm trained on this dataset is used to predict how good someone is at their job related to art or math? Also, what will happen if a company relies on such an algorithm to hire potential engineers? The model might mistakenly believe that gender affected how good a candidate they were and the resulting decisions will be gender biased.", "Bias in machine learning models is an area of concern. However, it is important to understand that most of the times the training data on which the model is trained is actually biased which is then ultimately reflected in the model. Therefore whereas it is important to emphasize on creating accurate models, it is also important to debug the training data for any bias or anomalies that is present in it.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Principal Data Scientist @H2O.ai | Author of Machine Learning for High-Risk Applications"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F649bc65e7487&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----649bc65e7487--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----649bc65e7487--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://pandeyparul.medium.com/?source=post_page-----649bc65e7487--------------------------------", "anchor_text": ""}, {"url": "https://pandeyparul.medium.com/?source=post_page-----649bc65e7487--------------------------------", "anchor_text": "Parul Pandey"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7053de462a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&user=Parul+Pandey&userId=7053de462a28&source=post_page-7053de462a28----649bc65e7487---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F649bc65e7487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F649bc65e7487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://projector.tensorflow.org/", "anchor_text": "Embedding Projector"}, {"url": "https://www.youtube.com/watch?v=wvsE8jm1GzE", "anchor_text": "https://www.youtube.com/watch?v=wvsE8jm1GzE"}, {"url": "https://www.tensorflow.org/guide/embedding", "anchor_text": "Source"}, {"url": "https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space", "anchor_text": "Source: Embeddings- Translating to a Lower-Dimensional Space"}, {"url": "http://projector.tensorflow.org/", "anchor_text": "Embedding Projector"}, {"url": "https://www.tensorflow.org/tensorboard/r1/summaries", "anchor_text": "TensorFlow"}, {"url": "http://projector.tensorflow.org/", "anchor_text": "projector.tensorflow.org"}, {"url": "https://www.tensorflow.org/guide/embedding#metadata", "anchor_text": "load our own datasets"}, {"url": "https://en.wikipedia.org/wiki/Principal_component_analysis", "anchor_text": "PCA"}, {"url": "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding", "anchor_text": "t-SNE"}, {"url": "https://umap-learn.readthedocs.io/en/latest/index.html", "anchor_text": "UMAP"}, {"url": "https://arxiv.org/abs/1802.03426", "anchor_text": "UMAP paper"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Word_embedding", "anchor_text": "word embeddings"}, {"url": "https://en.wikipedia.org/wiki/Text_corpus", "anchor_text": "corpus of text"}, {"url": "http://ai.googleblog.com/2016/12/open-sourcing-embedding-projector-tool.html", "anchor_text": "Open sourcing the Embedding Projector: a tool for visualizing high dimensional data"}, {"url": "https://arxiv.org/abs/1611.05469", "anchor_text": "Embedding Projector: Interactive Visualization and Interpretation of Embeddings"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----649bc65e7487---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/bias?source=post_page-----649bc65e7487---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----649bc65e7487---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/embedding?source=post_page-----649bc65e7487---------------embedding-----------------", "anchor_text": "Embedding"}, {"url": "https://medium.com/tag/projection?source=post_page-----649bc65e7487---------------projection-----------------", "anchor_text": "Projection"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F649bc65e7487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&user=Parul+Pandey&userId=7053de462a28&source=-----649bc65e7487---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F649bc65e7487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&user=Parul+Pandey&userId=7053de462a28&source=-----649bc65e7487---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F649bc65e7487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----649bc65e7487--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F649bc65e7487&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----649bc65e7487---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----649bc65e7487--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----649bc65e7487--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----649bc65e7487--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----649bc65e7487--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----649bc65e7487--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----649bc65e7487--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----649bc65e7487--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----649bc65e7487--------------------------------", "anchor_text": ""}, {"url": "https://pandeyparul.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://pandeyparul.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Parul Pandey"}, {"url": "https://pandeyparul.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "20K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7053de462a28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&user=Parul+Pandey&userId=7053de462a28&source=post_page-7053de462a28--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5be6ccf82bc8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-bias-in-data-using-embedding-projector-649bc65e7487&newsletterV3=7053de462a28&newsletterV3Id=5be6ccf82bc8&user=Parul+Pandey&userId=7053de462a28&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}