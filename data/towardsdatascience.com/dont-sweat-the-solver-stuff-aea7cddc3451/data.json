{"url": "https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451", "time": 1683000629.203532, "path": "towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451/", "webpage": {"metadata": {"title": "Don\u2019t Sweat the Solver Stuff. Tips for Better Logistic Regression\u2026 | by Jeff Hale | Towards Data Science", "h1": "Don\u2019t Sweat the Solver Stuff", "description": "Logistic regression is the bread-and-butter algorithm for machine learning classification. If you\u2019re a practicing or aspiring data scientist, you\u2019ll want to know the ins and outs of how to use it\u2026"}, "outgoing_paragraph_urls": [{"url": "https://stackoverflow.com/a/52388406/4590385", "anchor_text": "this Stack Overflow answer", "paragraph_index": 11}, {"url": "https://scikit-learn.org/stable/modules/linear_model.html", "anchor_text": "Scikit-learn documentation", "paragraph_index": 12}, {"url": "https://github.com/scikit-learn/scikit-learn/issues/9997", "anchor_text": "this GitHub issue", "paragraph_index": 14}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "scikit-learn breast_cancer dataset", "paragraph_index": 16}, {"url": "https://www.kaggle.com/discdiver/logistic-regression-don-t-sweat-the-solver-stuff", "anchor_text": "Kaggle", "paragraph_index": 17}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine", "anchor_text": "wine dataset", "paragraph_index": 22}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html", "anchor_text": "docs", "paragraph_index": 32}, {"url": "https://scikit-learn.org/stable/modules/multiclass.html", "anchor_text": "here", "paragraph_index": 42}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02?source=friends_link&sk=a82c5faefadd171fe07506db4d4f29db", "anchor_text": "here", "paragraph_index": 49}, {"url": "http://www.frontiersin.org/files/EBooks/194/assets/pdf/Sweating%20the%20Small%20Stuff%20-%20Does%20data%20cleaning%20and%20testing%20of%20assumptions%20really%20matter%20in%20the%2021st%20century.pdf", "anchor_text": "Kraha et al. (2012) here", "paragraph_index": 54}, {"url": "https://www.researchgate.net/post/Multicollinearity_issues_is_a_value_less_than_10_acceptable_for_VIF", "anchor_text": "lively debate", "paragraph_index": 55}, {"url": "https://scikit-learn.org/stable/modules/linear_model.html", "anchor_text": "LogisticRegressionCV", "paragraph_index": 59}, {"url": "https://memorablepython.com", "anchor_text": "Python", "paragraph_index": 63}, {"url": "https://memorabledocker.com", "anchor_text": "Docker", "paragraph_index": 63}, {"url": "https://memorablesql.com", "anchor_text": "SQL", "paragraph_index": 63}, {"url": "https://medium.com/@jeffhale", "anchor_text": "here", "paragraph_index": 63}, {"url": "https://dataawesome.com", "anchor_text": "newsletter", "paragraph_index": 63}, {"url": "https://dataawesome.com", "anchor_text": "https://dataawesome.com", "paragraph_index": 65}], "all_paragraphs": ["Logistic regression is the bread-and-butter algorithm for machine learning classification. If you\u2019re a practicing or aspiring data scientist, you\u2019ll want to know the ins and outs of how to use it. Also, Scikit-learn\u2019s LogisticRegression is spitting out warnings about changing the default solver, so this is a great time to learn when to use which solver. \ud83d\ude00", "In this article, you\u2019ll learn about Scikit-learn LogisticRegression solver choices and see two evaluations of them. Also, you\u2019ll see key API options and get answers to frequently asked questions. By the end of the article, you\u2019ll know more about logistic regression in Scikit-learn and not sweat the solver stuff. \ud83d\ude13", "I\u2019m using Scikit-learn version 0.21.3 in this analysis.", "UPDATE December 20, 2019: I made several edits to this article after helpful feedback from Scikit-learn core developer and maintainer, Andreas Mueller.", "A classification problem is one in which you try to predict discrete outcomes, such as whether someone has a disease. In contrast, a regression problem is one in which you are trying to predict a value of a continuous variable, such as the sale price of a home. Although logistic regression has regression in its name, it\u2019s an algorithm for classification problems.", "Logistic regression is probably the most important supervised learning classification method. It\u2019s a fast, versatile extension of a generalized linear model.", "Logistic regression makes an excellent baseline algorithm. It works well when the relationship between the features and the target aren\u2019t too complex.", "Logistic regression produces feature weights that are generally interpretable, which makes it especially useful when you need to be able to explain the reasons for a decision. This interpretability often comes in handy \u2014 for example, with lenders who need to justify their loan decisions.", "There is no closed-form solution for logistic regression problems. This is fine \u2014 we don\u2019t use the closed form solution for linear regression problems anyway because it\u2019s slow. \ud83d\ude09", "Solving logistic regression is an optimization problem. Thankfully, nice folks have created several solver algorithms we can use. \ud83d\ude01", "Scikit-learn ships with five different solvers. Each solver tries to find the parameter weights that minimize a cost function. Here are the five options:", "An excellent discussion of the different options can be found in this Stack Overflow answer.", "The chart below from the Scikit-learn documentation lists characteristics of the solvers, including the the regularization penalties available.", "liblinear is fast with small datasets, but has problems with saddle points and can't be parallelized over multiple processor cores. It can only use one-vs.-rest to solve multi-class problems. It also penalizes the intercept, which isn't good for interpretation.", "lbfgs avoids these drawbacks and is relatively fast. It's the best choice for most cases without a really large dataset. Some discussion of why the default was changed is in this GitHub issue.", "Let\u2019s evaluate the Logistic Regression solvers with two prediction classification projects \u2014 one binary and one multi-class.", "First, let\u2019s look at a binary classification problem. I used the built-in scikit-learn breast_cancer dataset. The goal is to predict whether a breast mass is cancerous.", "The features consist of numeric data about cell nuclei. They were computed from digitized images of biopsies. The dataset contains 569 observations and 30 numeric features. I split the dataset into training and test sets and conducted a grid search on the training set with each different solver. You can access my Jupyter notebook used in all analyses on Kaggle.", "The most relevant code snippet is below.", "The accuracy values for sag and saga are a bit lower than their peers.", "After scaling the features, the solvers all perform better and sag and saga are just as accurate as the other solvers.", "Now let\u2019s look at an example with three classes.", "I evaluated the logistic regression solvers in a multi-class classification problem with Scikit-learn\u2019s wine dataset. The dataset contains 178 samples and 13 numeric features. The goal is to predict the type of grapes used to make the wine from the chemical features of the wine.", "Scikit-learn gives a warning that the sag and saga models did not converge. In other words, they never arrived at a minimum point. Unsurprisingly, the results aren\u2019t so great for those solvers.", "Let\u2019s make a little bar chart using the Seaborn library to show the scores.", "After scaling the features between 0 and 1, then sag and saga reach the same mean accuracy scores as the other models.", "Note the caveat that both of these examples are with small datasets. Also, we\u2019re not looking at memory and speed requirements in these examples.", "Bottom line: the forthcoming default lbfgs solver is a good first choice for most cases. If you\u2019re dealing with a large dataset or want to apply L1 regularization, I suggest you start with saga. Remember that saga needs the features to be on a similar scale.", "Do you have a use case for newton-cg or sag? If so, please share in the comments. \ud83d\udcac", "Next, I\u2019ll demystify key parameter options for LogisticRegression in Scikit-learn.", "The Scikit-learn LogisticRegression class can take the following arguments.", "penalty, dual, tol, C, fit_intercept, intercept_scaling, class_weight, random_state, solver, max_iter, verbose, warm_start, n_jobs, l1_ratio", "I won\u2019t include all of the parameters below, just excerpts from those parameters most likely to be valuable to most folks. See the docs for those that are omitted. I\u2019ve added additional information in italics.", "random_state : int, RandomState instance or None, optional (default=None) Note that you must set the random state here for reproducibility.", "multi_class : str, {\u2018ovr\u2019, \u2018multinomial\u2019, \u2018auto\u2019}, optional (default=\u2019ovr\u2019) If the option chosen is \u2018ovr\u2019, then a binary problem is fit for each label. For \u2018multinomial\u2019 the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. \u2018multinomial\u2019 is unavailable when solver=\u2019liblinear\u2019. \u2018auto\u2019 selects \u2018ovr\u2019 if the data is binary, or if solver=\u2019liblinear\u2019, and otherwise selects \u2018multinomial\u2019.", "Changed in version 0.20: Default will change from \u2018ovr\u2019 to \u2018auto\u2019 in 0.22. ovr stands for one vs. rest. See further discussion below.", "l1_ratio : float or None, optional (default=None) The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Only used if penalty='elasticnet'. Setting `l1_ratio=0 is equivalent to using penalty='l2', while setting l1_ratio=1 is equivalent to using penalty='l1'. For 0 < l1_ratio <1, the penalty is a combination of L1 and L2. Only for saga.", "Commentary: If you have a multiclass problem, then setting multi-class to auto will use the multinomial option every time it's available. That's the most theoretically sound choice. auto will soon be the default.", "Use l1_ratio if want to use some L1 regularization with the saga solver. Note that like the ElasticNet linear regression option, you can use a mix of L1 and L2 penalization.", "Also note that an L2 regularization of C=1 is applied by default. This default regularization makes models more robust to multicollinearity, but at the expense of less interpretability (hat tip to Andreas Mueller).", "After fitting the model the attributes are: classes_, coef_, intercept_, and n_iter. coef_ contains an array of the feature weights.", "Now let\u2019s address those nagging questions you might have about Logistic Regression in Scikit-learn.", "Nope. Sorry, if you need that, find another classification algorithm here.", "Regularization shifts your model toward the bias side of things in the bias/variance tradeoff. Regularization makes for a more generalizable logistic regression model, especially in cases with few data points. You\u2019ll probably want to hyperparameter search over the regularization parameter C.", "If you want to do some dimensionality reduction through regularization, use L1 regularization. L1 regularization is Manhattan or Taxicab regularization. L2 regularization is Euclidian regularization and generally performs better in generalized linear regression problems.", "You must use the saga solver if you want to apply a mix of L1 and L2 regularization. The liblinear solver requires you to have regularization. However, you could just make C such as a large value that it had a very, very small regularization penalty. Again, C is currently set to 1 by default.", "If using sag and saga solvers, make sure the features are on a similar scale. We saw the importance of this above. Andreas Mueller, in private correspondence, also mentioned that he found convergence issues on unscaled data with lbfgs, although it was more robust than sag and saga.", "Bottom line: to be safe, scale your data.", "Probably. Removing outliers will generally improve model performance. Standardizing the inputs would also reduce outliers\u2019 effects.", "RobustScaler can scale features and you can avoid dropping outliers. See my article discussing scaling and standardizing here.", "Observations should be independent of each other.", "Just as in linear regression, you can use higher order polynomials and interactions. This transformation allows your model to learn a more complex decision boundary. Then, you aren\u2019t limited to a linear decision boundary. However, overfitting becomes a risk and interpreting feature importances gets trickier. It might also be more difficult for the solver to find the global minimum.", "Maybe. Principal Components Analysis is a nice choice if interpretability isn\u2019t vital. Recursive Feature Elimination can help you remove the least important features. Alternatively, L1 regularization can drive less important feature weights to zero if you are using the saga solver.", "It is for interpretation of the feature importances. You can\u2019t rely on the model weights to be meaningful when there is high correlation between the variables. Credit for affecting the outcome variable might go to just one of the correlated features.", "There are many ways to test for multicollinearity. See Kraha et al. (2012) here.", "One popular option is to check the Variance Inflation Factor (VIF). A VIF cutoff around 5 to 10 is common, but there\u2019s a lively debate as to what an appropriate VIF cutoff should be.", "You can compute the VIF by taking the correlation matrix, inverting it, and taking the values on the diagonal for each feature.", "The correlation coefficients alone are not sufficient to determine problematic multicollinearity with multiple features.", "If the sample size is small, getting more data might be most helpful for removing multi-collinearity.", "LogisticRegressionCV is the Scikit-learn algorithm you want if you have a lot of data and want to speed up your calculations while doing cross-validation to tune your hyperparameters.", "Now you know what to do when you see the LogisticRegression solver warning \u2014 and better yet, how to avoid it in the first place. No more sweat! \ud83d\ude05", "I suggest you use the upcoming default lbfgs solver for most cases. If you have a lot of data or need L1 regularization, try saga. Make sure you scale your features if you\u2019re using saga.", "I hope you found this discussion of logistic regression helpful. If you did, please share it on your favorite social media so other people can find it, too. \ud83d\udc4d", "I write about Python, Docker, SQL, data science and other tech topics. If any of that\u2019s of interest to you, read more here and sign up for my newsletter.\ud83d\ude04", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I write about data science. Join my Data Awesome mailing list to stay on top of the latest data tools and tips: https://dataawesome.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faea7cddc3451&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jeffhale.medium.com/?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": ""}, {"url": "https://jeffhale.medium.com/?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "Jeff Hale"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F451599b1142a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&user=Jeff+Hale&userId=451599b1142a&source=post_page-451599b1142a----aea7cddc3451---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faea7cddc3451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faea7cddc3451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Coordinate_descent", "anchor_text": "liblinear"}, {"url": "https://hal.inria.fr/hal-00860051/document", "anchor_text": "sag"}, {"url": "https://stackoverflow.com/a/52388406/4590385", "anchor_text": "this Stack Overflow answer"}, {"url": "https://scikit-learn.org/stable/modules/linear_model.html", "anchor_text": "Scikit-learn documentation"}, {"url": "https://github.com/scikit-learn/scikit-learn/issues/9997", "anchor_text": "this GitHub issue"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "scikit-learn breast_cancer dataset"}, {"url": "https://www.kaggle.com/discdiver/logistic-regression-don-t-sweat-the-solver-stuff", "anchor_text": "Kaggle"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine", "anchor_text": "wine dataset"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html", "anchor_text": "docs"}, {"url": "https://scikit-learn.org/stable/modules/multiclass.html", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02?source=friends_link&sk=a82c5faefadd171fe07506db4d4f29db", "anchor_text": "here"}, {"url": "http://www.frontiersin.org/files/EBooks/194/assets/pdf/Sweating%20the%20Small%20Stuff%20-%20Does%20data%20cleaning%20and%20testing%20of%20assumptions%20really%20matter%20in%20the%2021st%20century.pdf", "anchor_text": "Kraha et al. (2012) here"}, {"url": "https://www.researchgate.net/post/Multicollinearity_issues_is_a_value_less_than_10_acceptable_for_VIF", "anchor_text": "lively debate"}, {"url": "https://scikit-learn.org/stable/modules/linear_model.html", "anchor_text": "LogisticRegressionCV"}, {"url": "https://memorablepython.com", "anchor_text": "Python"}, {"url": "https://memorabledocker.com", "anchor_text": "Docker"}, {"url": "https://memorablesql.com", "anchor_text": "SQL"}, {"url": "https://medium.com/@jeffhale", "anchor_text": "here"}, {"url": "https://dataawesome.com", "anchor_text": "newsletter"}, {"url": "https://dataawesome.com", "anchor_text": ""}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----aea7cddc3451---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----aea7cddc3451---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----aea7cddc3451---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/technology?source=post_page-----aea7cddc3451---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----aea7cddc3451---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faea7cddc3451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&user=Jeff+Hale&userId=451599b1142a&source=-----aea7cddc3451---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faea7cddc3451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&user=Jeff+Hale&userId=451599b1142a&source=-----aea7cddc3451---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faea7cddc3451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Faea7cddc3451&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----aea7cddc3451---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----aea7cddc3451--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----aea7cddc3451--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----aea7cddc3451--------------------------------", "anchor_text": ""}, {"url": "https://jeffhale.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jeffhale.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jeff Hale"}, {"url": "https://jeffhale.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "18K Followers"}, {"url": "https://dataawesome.com", "anchor_text": "https://dataawesome.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F451599b1142a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&user=Jeff+Hale&userId=451599b1142a&source=post_page-451599b1142a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7ae6804f27a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdont-sweat-the-solver-stuff-aea7cddc3451&newsletterV3=451599b1142a&newsletterV3Id=e7ae6804f27a&user=Jeff+Hale&userId=451599b1142a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}