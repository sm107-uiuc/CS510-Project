{"url": "https://towardsdatascience.com/getting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b", "time": 1683007808.202934, "path": "towardsdatascience.com/getting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b/", "webpage": {"metadata": {"title": "Getting started with Computer Vision Datasets: a 5-step primer | by Dylan Seychell | Towards Data Science", "h1": "Getting started with Computer Vision Datasets: a 5-step primer", "description": "Just like we need material such as textbooks/blogs/videos to learn new skills and test our knowledge, machine learning algorithms need datasets to do the same thing. The choice of a dataset is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/9fdf3479c58d?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Ali Borji", "paragraph_index": 7}, {"url": "https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e", "anchor_text": "Object Detection", "paragraph_index": 12}, {"url": "https://medium.com/free-code-camp/diving-into-deep-convolutional-semantic-segmentation-networks-and-deeplab-v3-4f094fa387df", "anchor_text": "Semantic Segmentation", "paragraph_index": 13}, {"url": "https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46", "anchor_text": "Instance Segmentation", "paragraph_index": 13}, {"url": "http://twitter.com/jiayin_Supahands", "anchor_text": "@jiayin_Supahands", "paragraph_index": 15}, {"url": "http://labelme.csail.mit.edu/Release3.0/", "anchor_text": "LabelMe", "paragraph_index": 17}, {"url": "https://ieeexplore.ieee.org/document/8868795", "anchor_text": "Detecting abnormal human behaviour through a video generated model", "paragraph_index": 19}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "Image-net competition", "paragraph_index": 22}, {"url": "https://medium.com/u/7a81f3024ce?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Fei-Fei Li", "paragraph_index": 22}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "original MNIST", "paragraph_index": 24}, {"url": "https://medium.com/u/cbdda5bf53df?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Yann Le Cun", "paragraph_index": 24}, {"url": "http://www.lrec-conf.org/proceedings/lrec2018/pdf/226.pdf", "anchor_text": "publication introducing this dataset can be found here", "paragraph_index": 27}, {"url": "http://www.twitter.com/dylanseychell", "anchor_text": "Twitter", "paragraph_index": 36}, {"url": "https://www.linkedin.com/in/dylanseychell/", "anchor_text": "LinkedIn", "paragraph_index": 36}, {"url": "http://www.instagram.com/dylanseychell", "anchor_text": "Instagram", "paragraph_index": 36}], "all_paragraphs": ["Just like we need material such as textbooks/blogs/videos to learn new skills and test our knowledge, machine learning algorithms need datasets to do the same thing.", "The choice of a dataset is crucial. It\u2019s precisely what stands between an outstanding machine learning model or just another experiment.", "There are plenty of excellent articles about text-based datasets. Over the past years lecturing topics in computer vision, I noticed students struggling to get their head around understanding the what/when/where/how of computer vision datasets.", "So here\u2019s the primer I usually give to those getting started:", "By definition, a dataset is a collection of related examples that are used to train and test a model. This can be a selection of examples belonging to a particular topic or domain, and a dataset generally aims to cater to one or more application. A dataset may be labelled, and therefore, ideal for training and testing supervised models. However, there are also unlabeled datasets that are used to train unsupervised models.", "From a machine learning perspective, we need Datasets to train models and subsequently test them. This process requires us to choose a part of the dataset (e.g. 70% of it) and \u2018show\u2019 it to the machine learning algorithm for learning purpose. We then select the remaining unseen examples in the dataset (e.g. the remaining 30%) and use them to test how well the model learnt. It is crucial that we don\u2019t test with examples that were already used for training since the model will be predicting something it already knows, which is known as \u2018overfitting\u2019 a model. This is something that we wouldn\u2019t want because it only guarantees the failure of the model once it is used on a different dataset. There are various methods for organising the train-test set, and you can take a look at these examples.", "Datasets also serve as a measurement tool when it comes to the performance of machine learning techniques. A selection of models performing the same task needs to be compared fairly. This is carried out by running the different methods on a range of datasets. The performance measurement of each method would, therefore, be comparable and allows for the neat comparison of results.", "Ali Borji carried out and published an outstanding set of benchmarking exercises on Saliency techniques. These are some of his papers that I recommend to my students:", "Bias is a vast topic within itself. There are some critical matters that we need to keep in mind.", "Just like any other source of information, Datasets carry within them an inherent level of bias.", "This might not necessarily have negative implications, especially if you want your model to survive the test of relevance in an already biased world. However, it\u2019s very important that we are aware of any bias and measure any implications.", "The aim of this article is not to focus on specific computer vision techniques. However, I\u2019ll quickly walk you through a selection of topics and highlight the need for a dataset.", "Object Detection deals with identifying and locating an object of certain classes in an image. Interpreting the object localisation can be done in various ways. A commonly used approach in dataset annotation includes the drawing of a bounding box or polygon around the object as discussed below. Such an annotation allows the dataset to be used for detection. The same dataset can then be used for recognition if every annotation is accompanied by a label. Once objects are selected, they can also be used to mark every pixel in the image which contains the object (segmentation).", "Segmentation is the process of partitioning an image into multiple segments (sets of pixels) that correspond to a specific region or object. This can be applied to objects using thresholding techniques such as Otsu\u2019s method.Segmentation can also make use of features. Modern approaches make use of deep learning methods where models trained over datasets containing thousands of pixel-level annotated labels. These approaches include Semantic Segmentation (region selection accompanied by a label) and Instance Segmentation (semantic segmentation that identifies multiple separate objects per class).", "Visual saliency is a less popular area in computer vision that answers the following question: Which part of the image attracts more attention? Saliency detection techniques receive a colour image as input and return an 8-bit saliency map where the brighter the pixel value (max 255) implies a very salient pixel. Visual Saliency is used in different applications ranging from data compression to product placement and image manipulation. Datasets such as the MSRA10K featured below provide a binary image as ground-truth that indicates which pixels are salient or not.", "The type and quality of annotations available in a dataset are crucial to its relevance. In this section, I\u2019ll quickly walk you through the main types of annotations. Credit goes to @jiayin_Supahands for her neat outline of this aspect, and I encourage you to read her article. Here, I\u2019m only giving an overview of the most commonly used annotations and their relation to the topic.", "The bounding box approach is the simplest type of annotations and naturally involves the drawing of a bounding box around an object of interest. It is generally defined by a pair of coordinates and corresponding width and height. The bounding box definition often needs to be accompanied by a label if used for classification or recognition. The main drawback of using a bounding box is that it labels any background pixels caught in the bounding box in the same way as target object pixels. From an error metric perspective, it can be helpful for tracking recall, but it is then weak for precision, hence generating the need for something which is more specific.", "The limitation of bounding boxes brings along the need for something more precise: polygon annotation. The idea of polygon annotation is similar to the bounding box but allows for better pixel precision in labelling by reducing the number of background pixels being miss-labelled. A tool such as LabelMe is required for such an annotation. Label me is an opensource online annotation tool to build image databases for computer vision research. It also offers its own datasets.", "As the name implies, this approach uses lines to annotate specific regions in an image. Lines can be useful in a situation where a bounding box would take a substantial area of pixels. Lane detection is an easily applied case for the use of such an annotation. This can be also used for monitoring of queues and quality control situations.", "These annotations are a specification of groups of keypoints on an image, often carrying a semantic connotation. This approach is very commonly used for pose estimation and facial recognition. The geometrical properties between different points are used as features, and machine learning algorithms are trained using these features. This approach was used in our recent work titled \u201cDetecting abnormal human behaviour through a video generated model\u201d published in 2019.", "There are dozens of remarkable computer vision datasets that were crucial to the development of models that are changing the world. In this section, I am focusing on a selection of landmark datasets that every computer vision professional should know about.", "Image-Net is the legendary computer vision dataset that contributed to the rise of deep learning. It is an image database organised according to the WordNet hierarchy where each meaningful concept in, possibly described by multiple words, is called a \u201csynonym set\u201d or \u201csynset\u201d. Image-net is generally used for object classification/recognition. This dataset contains a total of 14,197,122 with a total of 1,034,908 images with bounding box annotations.", "This dataset gained its popularity for the Image-net competition through which Deep Learning gained its traction after AlexNet won this competition in 2012. It was founded by Fei-Fei Li, and she shared the remarkable journey behind this dataset in the Ted talk I\u2019m featuring below:", "No matter how experienced you think/feel you are in computer vision, I strongly advise you invest some time in listening to this inspirational talk. Even though techniques have advanced since its release in 2015, the mindset and humbleness presented in this video are still highly relevant.", "The original MNIST dataset, led by Yann Le Cun, consisted of a large volume of handwritten images. It served the vital role of providing a much needed easy-access benchmark for early convolutional neural networks. By 2017, CNNs achieved constant outstanding accuracy (over 99%) on MNIST, and the need for a more challenging benchmark dataset arose. This served as a motivation for the Fashion MNSIT dataset. The latter version includes a training set of 60,000 examples and a test set of 10,000 examples, where every example is a 28x28px of a fashion item from 10 different classes.", "This dataset was released by the Canadian Institute For Advanced Research (CIFAR) and probably gained some of its popularity through the involvement of Geoffrey Hinton and his associates. The CIFAR-10 dataset contains 60,000 32x32px colour images in 10 different classes. It is used for train/testing of object recognition models.", "The Common Objects in Context (COCO) dataset is an object detection, segmentation, and captioning dataset. The COCO 2017 has a training and validation collection of 123,287 images containing a total of 886,284 instances. These instances are spread over 80 object categories.", "There is a significant number of datasets covering different sorts of facial data. Here, I chose to feature a new and innovative dataset compiled by my colleagues at the Unversity of Malta. Unlike other facial detection or recognition datasets, this one is annotated using descriptive text. This allows machine learning models to be trained to return a textual description of a face given just an image. The full details of the publication introducing this dataset can be found here and the dataset itself may be acquired by filling in the contact form on the official website of this project.", "This is a Salient Object Image Database. Every image in this dataset has a mask for the most salient region in the image. The MSRA10K dataset gained its relevance from the volume of images it contains. It consists of 10,000 colour images with a corresponding binary image mask for the salient object.", "The Microsoft Research Dataset (MSR) includes a sequence of 100 images (colour and depth) captured from 8 cameras showing the breakdancing and ballet scenes. This dataset contains frames for each scene. Every frame has a colour image and high-quality grayscale depth image, captured by an infrared camera.", "This is a dataset I carefully designed and built last year to evaluate image manipulation techniques. One of such applications is inpainting where an object is removed from an image. Inpainting techniques are usually evaluated using subjective or opinion-based approach because datasets would lack adequate ground truth. This served as a motivation behind this dataset that has a series of progressive scenes as demonstrated below. Further details about this dataset and the experience behind its construction will be shared in separate work.", "In academia, you\u2019ll typically come across datasets in peer-reviewed publications about your topic of interest. However, you sometimes just need to browse your options, and for that, you need a good platform. Here follow my 4 favourite sources:", "This article aims to provide a primer covering all the basics that one needs to get accustomed to the exciting area of computer vision. I hope that by now you feel more confident about datasets and that this topic itself has been demystified for you. If not, I look forward to receiving your feedback so that I can address any challenges you may find.", "We\u2019ve seen how we can use datasets and which ones serve us well for different situations. However, that\u2019s not the end of the story. Machine Learning and datasets have a very complicated and demanding relationship. Sometimes, Machine Learning models just can\u2019t get enough and datasets can be limiting. This is where Data Augmentation is needed. In this blog, I also explained how datasets are essential for benchmarking different techniques. Then again, it\u2019s easier said and done because the choice of evaluation metrics is a delicate recipe that needs to be adapted.", "Bottom line, this article is far from the end to the topic of computer vision datasets. This is a fast-paced and evolving area that has many topics to be explored. I can only promise to keep on sharing my perspective in the midst of this progress.", "Dylan Seychell is a resident academic at the Department of Artificial Intelligence at the University of Malta, specialised in Computer Vision. published several internationally peer-reviewed publications and two books. He was awarded a number of international awards for his work such as the Gold Seal for e-Excellence at CeBit, the first prize by the European Space Agency Satellite Navigation Competition in 2010 and runner up in 2017. In 2015, Dylan was selected to lead Malta\u2019s Google Developers Group and served as a member of the Maltese Government national AI task-force. Dylan is also very active in the startup field, where he founded award-winning startups and mentors other startups, helping them surpass the initial challenges of business.", "You can get in contact via Twitter, LinkedIn or Instagram.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Academic @UMmalta specialised in #AI, #UX & Computer Vision. Founder of @colourmytravel & #gdgMalta. Traveller"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5aaf6d63552b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dylanseychell?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dylanseychell?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Dylan Seychell"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9a2114515441&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&user=Dylan+Seychell&userId=9a2114515441&source=post_page-9a2114515441----5aaf6d63552b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5aaf6d63552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5aaf6d63552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@hjrc33", "anchor_text": "Hector Rivas"}, {"url": "https://unsplash.com/photos/QNc9tTNHRyI", "anchor_text": "Unsplash"}, {"url": "https://medium.com/u/9fdf3479c58d?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Ali Borji"}, {"url": "https://link.springer.com/article/10.1007/s41095-019-0149-9", "anchor_text": "Salient object detection: A survey"}, {"url": "https://arxiv.org/abs/1801.07424", "anchor_text": "Revisiting Video Saliency: A Large-scale Benchmark and a New Model"}, {"url": "https://arxiv.org/abs/1501.02741", "anchor_text": "Salient Object Detection: A Benchmark"}, {"url": "https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e", "anchor_text": "Object Detection"}, {"url": "https://medium.com/free-code-camp/diving-into-deep-convolutional-semantic-segmentation-networks-and-deeplab-v3-4f094fa387df", "anchor_text": "Semantic Segmentation"}, {"url": "https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46", "anchor_text": "Instance Segmentation"}, {"url": "http://twitter.com/jiayin_Supahands", "anchor_text": "@jiayin_Supahands"}, {"url": "https://medium.com/supahands-techblog/what-is-image-annotation-caf4107601b7", "anchor_text": "Jiayin"}, {"url": "http://labelme.csail.mit.edu/Release3.0/", "anchor_text": "LabelMe"}, {"url": "http://labelme.csail.mit.edu/Release3.0/", "anchor_text": "official LabelMe Website"}, {"url": "https://medium.com/supahands-techblog/what-is-image-annotation-caf4107601b7", "anchor_text": "Jiayin"}, {"url": "https://ieeexplore.ieee.org/document/8868795", "anchor_text": "Detecting abnormal human behaviour through a video generated model"}, {"url": "https://medium.com/u/b1d410cb9700?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "TensorFlow"}, {"url": "https://www.tensorflow.org/lite/models/pose_estimation/overview", "anchor_text": "source of this image"}, {"url": "http://www.image-net.org/", "anchor_text": "http://www.image-net.org/"}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "Image-net competition"}, {"url": "https://medium.com/u/7a81f3024ce?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Fei-Fei Li"}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "http://yann.lecun.com/exdb/mnist/"}, {"url": "https://github.com/zalandoresearch/fashion-mnist", "anchor_text": "https://github.com/zalandoresearch/fashion-mnist"}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "original MNIST"}, {"url": "https://medium.com/u/cbdda5bf53df?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Yann Le Cun"}, {"url": "https://github.com/zalandoresearch/fashion-mnist", "anchor_text": "official GitHub repository"}, {"url": "https://www.cs.toronto.edu/~kriz/cifar.html", "anchor_text": "https://www.cs.toronto.edu/~kriz/cifar.html"}, {"url": "https://www.cs.toronto.edu/~kriz/cifar.html", "anchor_text": "CIFAR website"}, {"url": "http://cocodataset.org/", "anchor_text": "http://cocodataset.org/"}, {"url": "http://cocodataset.org/", "anchor_text": "COCO dataset"}, {"url": "https://rival.research.um.edu.mt/", "anchor_text": "https://rival.research.um.edu.mt/"}, {"url": "http://www.lrec-conf.org/proceedings/lrec2018/pdf/226.pdf", "anchor_text": "publication introducing this dataset can be found here"}, {"url": "http://www.lrec-conf.org/proceedings/lrec2018/pdf/226.pdf", "anchor_text": "the official publication"}, {"url": "https://mmcheng.net/msra10k/", "anchor_text": "https://mmcheng.net/msra10k/"}, {"url": "https://mmcheng.net/msra10k/", "anchor_text": "MSRA10K dataset"}, {"url": "https://www.microsoft.com/en-us/download/details.aspx?id=52358", "anchor_text": "https://www.microsoft.com/en-us/download/details.aspx?id=52358"}, {"url": "http://www.cotsdataset.info", "anchor_text": "www.cotsdataset.info"}, {"url": "https://datasetsearch.research.google.com/", "anchor_text": "Dataset SearchLearn more about including your datasets in Dataset Search. \u202b\u0627\u0644\u0639\u0631\u0628\u064a\u0629\u202c \u202aDeutsch\u202c \u202aEnglish\u202c \u202aEspa\u00f1ol (Espa\u00f1a)\u202c \u202aEspa\u00f1ol\u2026datasetsearch.research.google.com"}, {"url": "http://www.visualdata.io", "anchor_text": "www.visualdata.io"}, {"url": "http://www.kaggle.com", "anchor_text": "www.kaggle.com"}, {"url": "https://www.tensorflow.org/datasets", "anchor_text": "TensorFlow DatasetsA collection of datasets ready to use with TensorFlow or other Python ML frameworks, such as Jax, enabling easy-to-use\u2026www.tensorflow.org"}, {"url": "http://www.twitter.com/dylanseychell", "anchor_text": "Twitter"}, {"url": "https://www.linkedin.com/in/dylanseychell/", "anchor_text": "LinkedIn"}, {"url": "http://www.instagram.com/dylanseychell", "anchor_text": "Instagram"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----5aaf6d63552b---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5aaf6d63552b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/datasets-review?source=post_page-----5aaf6d63552b---------------datasets_review-----------------", "anchor_text": "Datasets Review"}, {"url": "https://medium.com/tag/datasets?source=post_page-----5aaf6d63552b---------------datasets-----------------", "anchor_text": "Datasets"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----5aaf6d63552b---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5aaf6d63552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&user=Dylan+Seychell&userId=9a2114515441&source=-----5aaf6d63552b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5aaf6d63552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&user=Dylan+Seychell&userId=9a2114515441&source=-----5aaf6d63552b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5aaf6d63552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5aaf6d63552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5aaf6d63552b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5aaf6d63552b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dylanseychell?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dylanseychell?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dylan Seychell"}, {"url": "https://medium.com/@dylanseychell/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "136 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9a2114515441&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&user=Dylan+Seychell&userId=9a2114515441&source=post_page-9a2114515441--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F9a2114515441%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-computer-vision-datasets-a-5-step-primer-5aaf6d63552b&user=Dylan+Seychell&userId=9a2114515441&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}