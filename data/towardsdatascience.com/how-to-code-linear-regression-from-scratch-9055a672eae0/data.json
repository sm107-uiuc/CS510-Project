{"url": "https://towardsdatascience.com/how-to-code-linear-regression-from-scratch-9055a672eae0", "time": 1683016588.884143, "path": "towardsdatascience.com/how-to-code-linear-regression-from-scratch-9055a672eae0/", "webpage": {"metadata": {"title": "How to Code Linear Regression from Scratch | by Jake Miller Brooks | Towards Data Science", "h1": "How to Code Linear Regression from Scratch", "description": "Numpy implementation of linear regression from scratch based on a bit of matrix algebra, and the normal equation."}, "outgoing_paragraph_urls": [{"url": "https://mathworld.wolfram.com/NormalEquation.html", "anchor_text": "Wolfram defines", "paragraph_index": 8}, {"url": "https://mathworld.wolfram.com/MatrixInverse.html", "anchor_text": "inverse", "paragraph_index": 9}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html", "anchor_text": "sklearn.datasets.load_boston", "paragraph_index": 10}], "all_paragraphs": ["These days, it\u2019s easy to fit pretty much any model you can think of with one library or another, but how much do you really learn by calling .fit() and .predict()? While it\u2019s certainly much more practical to use a framework like python\u2019s statsmodels or scikit-learn for the normal use-case, it seems equally logical that when learning data science it makes a lot of sense to get a feel for how these models actually work. Below we show how to use numpy to implement a basic linear regression model from the ground up. Let\u2019s get started!", "Think back to your first algebra class: do you remember the equation for a line? If you said \u201cy = mx + b\u201d, you\u2019re absolutely right. I think it\u2019s also helpful to start in two dimensions, because without using any matrices or vectors, we can already see that given inputs x, and outputs y, we are actually looking for not one, but two coefficients: m and b.", "\u201cBut wait!\u201d you might say. \u201cThat\u2019s the slope coefficient m, and the intercept b.\u201d And you\u2019d be right again! But in order to find the line that best fits our data, we need not just a slope, but an intercept as well, otherwise we\u2019d be looking at infinitely many lines of best fit, instead of just the one that we\u2019re after. Rather than thinking about b as being added to our x term, it\u2019s useful to rewrite this simple equation as \u201cy = m*x + b*1\u201d. This makes the next little bit of linear algebra much easier to understand.", "Let\u2019s imagine a very simple dataset for our slope intercept equation where the line of best fit is actually a perfect fit. We\u2019ll say we have the points:", "We\u2019d like to solve for the coefficients m and b that best solve some cost function we\u2019ll define in a moment, but in order to do this efficiently, we\u2019ll first rewrite our equation one more time. We\u2019ll define a single vector y = [3, 5, 7, 9], and we\u2019ll be looking for some coefficients (often denoted by \u0398, theta, or \u03b2, beta). How many elements of our coefficient vector depends on how many features there are in our feature space X (note, that we are switching to capital X to denote a matrix, which we\u2019re going to discuss now). Instead of a vector like we used to define our y term, we\u2019re going to add a column of ones to our column of x terms from above. By convention we\u2019ll put the column of ones in front of the X values since you can think of our constant coefficient as having lower degree than our X. That will look something like this:", "Now our equation looks like this:", "The next thing we\u2019re going to do is employ a little trick, not all of matrix algebra works exactly like you might be used to, but it\u2019s generally fair game to multiply by the same term on either side of the equation, as long as our dimensions are compatible, which is what we\u2019ll do. We add the transpose of X on both sides, the transpose looks like this:", "And our new equation can be written like this:", "This is the point of our funky manipulations. This equation is called the normal equation, and it happens to have some special properties. Wolfram defines this equation as \u201cthat which minimizes the sum of the square distances between the left and right sides\u201d of the equation Ax = b, which though they\u2019ve used some different notation, is exactly what we\u2019re looking for.", "Our last trick is going to be to isolate \u0398, which we\u2019ll do by taking the inverse of (X\u1d40X), resulting in the following equation that will yield a solution in all cases where (X\u1d40X) is invertible. We\u2019ll skip some of the details, but so long as the columns of X are linearly independent, this ought to work.", "Here\u2019s our solution written out in Python, feel free to try it out! I\u2019ll claim this code works about the same as scikit-learn\u2019s LinearRegression. It will yield the same results on, for example, the Boston Housing dataset, which you can retrieve with sklearn.datasets.load_boston. Can you think of some cases where it breaks? (Hint: check the last paragraph of the preceding section).", "And last, for those who would like a simple convenience function to test outputs of this method vs. an implementation from another library, feel free to use this:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist, lifelong learner, background in Housing Finance, Transportation and Infrastructure."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9055a672eae0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9055a672eae0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9055a672eae0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://brooksjacobm.medium.com/?source=post_page-----9055a672eae0--------------------------------", "anchor_text": ""}, {"url": "https://brooksjacobm.medium.com/?source=post_page-----9055a672eae0--------------------------------", "anchor_text": "Jake Miller Brooks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F23ce7c561c61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&user=Jake+Miller+Brooks&userId=23ce7c561c61&source=post_page-23ce7c561c61----9055a672eae0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9055a672eae0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9055a672eae0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://mathworld.wolfram.com/NormalEquation.html", "anchor_text": "Wolfram defines"}, {"url": "https://mathworld.wolfram.com/MatrixInverse.html", "anchor_text": "inverse"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html", "anchor_text": "sklearn.datasets.load_boston"}, {"url": "https://medium.com/tag/python?source=post_page-----9055a672eae0---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9055a672eae0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----9055a672eae0---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/numpy?source=post_page-----9055a672eae0---------------numpy-----------------", "anchor_text": "Numpy"}, {"url": "https://medium.com/tag/linear-algebra?source=post_page-----9055a672eae0---------------linear_algebra-----------------", "anchor_text": "Linear Algebra"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9055a672eae0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&user=Jake+Miller+Brooks&userId=23ce7c561c61&source=-----9055a672eae0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9055a672eae0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&user=Jake+Miller+Brooks&userId=23ce7c561c61&source=-----9055a672eae0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9055a672eae0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9055a672eae0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9055a672eae0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9055a672eae0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9055a672eae0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9055a672eae0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9055a672eae0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9055a672eae0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9055a672eae0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9055a672eae0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9055a672eae0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9055a672eae0--------------------------------", "anchor_text": ""}, {"url": "https://brooksjacobm.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://brooksjacobm.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jake Miller Brooks"}, {"url": "https://brooksjacobm.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "78 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F23ce7c561c61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&user=Jake+Miller+Brooks&userId=23ce7c561c61&source=post_page-23ce7c561c61--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea3f579f9ca5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-linear-regression-from-scratch-9055a672eae0&newsletterV3=23ce7c561c61&newsletterV3Id=ea3f579f9ca5&user=Jake+Miller+Brooks&userId=23ce7c561c61&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}