{"url": "https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8", "time": 1682993886.846296, "path": "towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8/", "webpage": {"metadata": {"title": "Image Captioning with Keras. Table of Contents: | by Harshall Lamba | Towards Data Science", "h1": "Image Captioning with Keras", "description": "Well some of you might say \u201cA white dog in a grassy area\u201d, some may say \u201cWhite dog with brown spots\u201d and yet some others might say \u201cA dog on grass and some pink flowers\u201d. Definitely all of these\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/andrej-karpathy-9a650716", "anchor_text": "Andrej Karapathy", "paragraph_index": 5}, {"url": "https://www.captionbot.ai/", "anchor_text": "Caption Bot", "paragraph_index": 7}, {"url": "https://forms.illinois.edu/sec/1713398", "anchor_text": "form", "paragraph_index": 11}, {"url": "https://wiki.python.org/moin/Generators", "anchor_text": "here", "paragraph_index": 96}, {"url": "https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/", "anchor_text": "link", "paragraph_index": 100}, {"url": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "here", "paragraph_index": 107}, {"url": "http://www.paperspace.com", "anchor_text": "www.paperspace.com", "paragraph_index": 116}, {"url": "https://github.com/hlamba28/Automatic-Image-Captioning.git", "anchor_text": "here", "paragraph_index": 150}], "all_paragraphs": ["What do you see in the below picture?", "Well some of you might say \u201cA white dog in a grassy area\u201d, some may say \u201cWhite dog with brown spots\u201d and yet some others might say \u201cA dog on grass and some pink flowers\u201d.", "Definitely all of these captions are relevant for this image and there may be some others also. But the point I want to make is; it\u2019s so easy for us, as human beings, to just have a glance at a picture and describe it in an appropriate language. Even a 5 year old could do this with utmost ease.", "But, can you write a computer program that takes an image as input and produces a relevant caption as output?", "Just prior to the recent development of Deep Neural Networks this problem was inconceivable even by the most advanced researchers in Computer Vision. But with the advent of Deep Learning this problem can be solved very easily if we have the required dataset.", "This problem was well researched by Andrej Karapathy in his PhD thesis at Stanford [1], who is also now the Director of AI at Tesla.", "The purpose of this blog post is to explain (in as simple words as possible) that how Deep Learning can be used to solve this problem of generating a caption for a given image, hence the name Image Captioning.", "To get a better feel of this problem, I strongly recommend to use this state-of-the-art system created by Microsoft called as Caption Bot. Just go to this link and try uploading any picture you want; this system will generate a caption for it.", "We must first understand how important this problem is to real world scenarios. Let\u2019s see few applications where a solution to this problem can be very useful.", "This post assumes familiarity with basic Deep Learning concepts like Multi-layered Perceptrons, Convolution Neural Networks, Recurrent Neural Networks, Transfer Learning, Gradient Descent, Backpropagation, Overfitting, Probability, Text Processing, Python syntax and data structures, Keras library, etc.", "There are many open source datasets available for this problem, like Flickr 8k (containing8k images), Flickr 30k (containing 30k images), MS COCO (containing 180k images), etc.", "But for the purpose of this case study, I have used the Flickr 8k dataset which you can download by filling this form provided by the University of Illinois at Urbana-Champaign. Also training a model with large number of images may not be feasible on a system which is not a very high end PC/Laptop.", "This dataset contains 8000 images each with 5 captions (as we have already seen in the Introduction section that an image can have multiple captions, all being relevant simultaneously).", "These images are bifurcated as follows:", "If you have downloaded the data from the link that I have provided, then, along with images, you will also get some text files related to the images. One of the files is \u201cFlickr8k.token.txt\u201d which contains the name of each image along with its 5 captions. We can read this file as follows:", "The text file looks as follows:", "Thus every line contains the <image name>#i <caption>, where 0\u2264i\u22644", "i.e. the name of the image, caption number (0 to 4) and the actual caption.", "Now, we create a dictionary named \u201cdescriptions\u201d which contains the name of the image (without the .jpg extension) as keys and a list of the 5 captions for the corresponding image as values.", "For example with reference to the above screenshot the dictionary will look as follows:", "When we deal with text, we generally perform some basic cleaning like lower-casing all the words (otherwise\u201chello\u201d and \u201cHello\u201d will be regarded as two separate words), removing special tokens (like \u2018%\u2019, \u2018$\u2019, \u2018#\u2019, etc.), eliminating words which contain numbers (like \u2018hey199\u2019, etc.).", "The below code does these basic cleaning steps:", "Create a vocabulary of all the unique words present across all the 8000*5 (i.e. 40000) image captions (corpus) in the data set :", "This means we have 8763 unique words across all the 40000 image captions. We write all these captions along with their image names in a new file namely, \u201cdescriptions.txt\u201d and save it on the disk.", "However, if we think about it, many of these words will occur very few times, say 1, 2 or 3 times. Since we are creating a predictive model, we would not like to have all the words present in our vocabulary but the words which are more likely to occur or which are common. This helps the model become more robust to outliers and make less mistakes.", "Hence we consider only those words which occur at least 10 times in the entire corpus. The code for this is below:", "So now we have only 1651 unique words in our vocabulary. However, we will append 0\u2019s (zero padding explained later) and thus total words = 1651+1 = 1652 (one index for the 0).", "The text file \u201cFlickr_8k.trainImages.txt\u201d contains the names of the images that belong to the training set. So we load these names into a list \u201ctrain\u201d.", "Thus we have separated the 6000 training images in the list named \u201ctrain\u201d.", "Now, we load the descriptions of these images from \u201cdescriptions.txt\u201d (saved on the hard disk) in the Python dictionary \u201ctrain_descriptions\u201d.", "However, when we load them, we will add two tokens in every caption as follows (significance explained later):", "\u2018startseq\u2019 -> This is a start sequence token which will be added at the start of every caption.", "\u2018endseq\u2019 -> This is an end sequence token which will be added at the end of every caption.", "Images are nothing but input (X) to our model. As you may already know that any input to a model must be given in the form of a vector.", "We need to convert every image into a fixed sized vector which can then be fed as input to the neural network. For this purpose, we opt for transfer learning by using the InceptionV3 model (Convolutional Neural Network) created by Google Research.", "This model was trained on Imagenet dataset to perform image classification on 1000 different classes of images. However, our purpose here is not to classify the image but just get fixed-length informative vector for each image. This process is called automatic feature engineering.", "Hence, we just remove the last softmax layer from the model and extract a 2048 length vector (bottleneck features) for every image as follows:", "The code for this is as follows:", "Now, we pass every image to this model to get the corresponding 2048 length feature vector as follows:", "We save all the bottleneck train features in a Python dictionary and save it on the disk using Pickle file, namely \u201cencoded_train_images.pkl\u201d whose keys are image names and values are corresponding 2048 length feature vector.", "NOTE: This process might take an hour or two if you do not have a high end PC/laptop.", "Similarly we encode all the test images and save them in the file \u201cencoded_test_images.pkl\u201d.", "We must note that captions are something that we want to predict. So during the training period, captions will be the target variables (Y) that the model is learning to predict.", "But the prediction of the entire caption, given the image does not happen at once. We will predict the caption word by word. Thus, we need to encode each word into a fixed sized vector. However, this part will be seen later when we look at the model design, but for now we will create two Python Dictionaries namely \u201cwordtoix\u201d (pronounced \u2014 word to index) and \u201cixtoword\u201d (pronounced \u2014 index to word).", "Stating simply, we will represent every unique word in the vocabulary by an integer (index). As seen above, we have 1652 unique words in the corpus and thus each word will be represented by an integer index between 1 to 1652.", "These two Python dictionaries can be used as follows:", "wordtoix[\u2018abc\u2019] -> returns index of the word \u2018abc\u2019", "ixtoword[k] -> returns the word whose index is \u2018k\u2019", "The code used is as below:", "There is one more parameter that we need to calculate, i.e., the maximum length of a caption and we do it as below:", "So the maximum length of any caption is 34.", "This is one of the most important steps in this case study. Here we will understand how to prepare the data in a manner which will be convenient to be given as input to the deep learning model.", "Hereafter, I will try to explain the remaining steps by taking a sample example as follows:", "Consider we have 3 images and their 3 corresponding captions as follows:", "Now, let\u2019s say we use the first two images and their captions to train the model and the third image to test our model.", "Now the questions that will be answered are: how do we frame this as a supervised learning problem?, what does the data matrix look like? how many data points do we have?, etc.", "First we need to convert both the images to their corresponding 2048 length feature vector as discussed above. Let \u201cImage_1\u201d and \u201cImage_2\u201d be the feature vectors of the first two images respectively", "Secondly, let\u2019s build the vocabulary for the first two (train) captions by adding the two tokens \u201cstartseq\u201d and \u201cendseq\u201d in both of them: (Assume we have already performed the basic cleaning steps)", "Caption_1 -> \u201cstartseq the black cat sat on grass endseq\u201d", "Caption_2 -> \u201cstartseq the white cat is walking on road endseq\u201d", "vocab = {black, cat, endseq, grass, is, on, road, sat, startseq, the, walking, white}", "Let\u2019s give an index to each word in the vocabulary:", "Now let\u2019s try to frame it as a supervised learning problem where we have a set of data points D = {Xi, Yi}, where Xi is the feature vector of data point \u2018i\u2019 and Yi is the corresponding target variable.", "Let\u2019s take the first image vector Image_1 and its corresponding caption \u201cstartseq the black cat sat on grass endseq\u201d. Recall that, Image vector is the input and the caption is what we need to predict. But the way we predict the caption is as follows:", "For the first time, we provide the image vector and the first word as input and try to predict the second word, i.e.:", "Then we provide image vector and the first two words as input and try to predict the third word, i.e.:", "Thus, we can summarize the data matrix for one image and its corresponding caption as follows:", "It must be noted that, one image+caption is not a single data point but are multiple data points depending on the length of the caption.", "Similarly if we consider both the images and their captions, our data matrix will then look as follows:", "We must now understand that in every data point, it\u2019s not just the image which goes as input to the system, but also, a partial caption which helps to predict the next word in the sequence.", "Since we are processing sequences, we will employ a Recurrent Neural Network to read these partial captions (more on this later).", "However, we have already discussed that we are not going to pass the actual English text of the caption, rather we are going to pass the sequence of indices where each index represents a unique word.", "Since we have already created an index for each word, let\u2019s now replace the words with their indices and understand how the data matrix will look like:", "Since we would be doing batch processing (explained later), we need to make sure that each sequence is of equal length. Hence we need to append 0\u2019s (zero padding) at the end of each sequence. But how many zeros should we append in each sequence?", "Well, this is the reason we had calculated the maximum length of a caption, which is 34 (if you remember). So we will append those many number of zeros which will lead to every sequence having a length of 34.", "The data matrix will then look as follows:", "I hope this gives you a good sense as to how we can prepare the dataset for this problem. However, there is a big catch in this.", "In the above example, I have only considered 2 images and captions which have lead to 15 data points.", "However, in our actual training dataset we have 6000 images, each having 5 captions. This makes a total of 30000 images and captions.", "Even if we assume that each caption on an average is just 7 words long, it will lead to a total of 30000*7 i.e. 210000 data points.", "Compute the size of the data matrix:", "Size of the data matrix = n*m", "And m-> length of each data point", "Clearly m= Length of image vector(2048) + Length of partial caption(x).", "But what is the value of x?", "Well you might think it is 34, but no wait, it\u2019s wrong.", "Every word (or index) will be mapped (embedded) to higher dimensional space through one of the word embedding techniques.", "Later, during the model building stage, we will see that each word/index is mapped to a 200-long vector using a pre-trained GLOVE word embedding model.", "Now even if we assume that one block takes 2 byte, then, to store this data matrix, we will require more than 3 GB of main memory.", "This is pretty huge requirement and even if we are able to manage to load this much data into the RAM, it will make the system very slow.", "For this reason we use data generators a lot in Deep Learning. Data Generators are a functionality which is natively implemented in Python. The ImageDataGenerator class provided by the Keras API is nothing but an implementation of generator function in Python.", "So how does using a generator function solve this problem?", "If you know the basics of Deep Learning, then you must know that to train a model on a particular dataset, we use some version of Stochastic Gradient Descent (SGD) like Adam, Rmsprop, Adagrad, etc.", "With SGD, we do not calculate the loss on the entire data set to update the gradients. Rather in every iteration, we calculate the loss on a batch of data points (typically 64, 128, 256, etc.) to update the gradients.", "This means that we do not require to store the entire dataset in the memory at once. Even if we have the current batch of points in the memory, it is sufficient for our purpose.", "A generator function in Python is used exactly for this purpose. It\u2019s like an iterator which resumes the functionality from the point it left the last time it was called.", "To understand more about Generators, please read here.", "The code for data generator is as follows:", "As already stated above, we will map the every word (index) to a 200-long vector and for this purpose, we will use a pre-trained GLOVE Model:", "Now, for all the 1652 unique words in our vocabulary, we create an embedding matrix which will be loaded into the model before training.", "To understand more about word embeddings, please refer this link", "Since the input consists of two parts, an image vector and a partial caption, we cannot use the Sequential API provided by the Keras library. For this reason, we use the Functional API which allows us to create Merge Models.", "First, let\u2019s look at the brief architecture which contains the high level sub-modules:", "We define the model as follows:", "Let\u2019s look at the model summary:", "The below plot helps to visualize the structure of the network and better understand the two streams of input:", "The text in red on the right side are the comments provided for you to map your understanding of the data preparation to model architecture.", "The LSTM (Long Short Term Memory) layer is nothing but a specialized Recurrent Neural Network to process the sequence input (partial captions in our case). To read more about LSTM, click here.", "If you have followed the previous section, I think reading these comments should help you to understand the model architecture in a straight forward manner.", "Recall that we had created an embedding matrix from a pre-trained Glove model which we need to include in the model before starting the training:", "Notice that since we are using a pre-trained embedding layer, we need to freeze it (trainable = False), before training the model, so that it does not get updated during the backpropagation.", "Finally we compile the model using the adam optimizer", "Finally the weights of the model will be updated through backpropagation algorithm and the model will learn to output a word, given an image feature vector and a partial caption. So in summary, we have:", "Output -> An appropriate word, next in the sequence of partial caption provided in the input_1 (or in probability terms we say conditioned on image vector and the partial caption)", "The model was then trained for 30 epochs with the initial learning rate of 0.001 and 3 pictures per batch (batch size). However after 20 epochs, the learning rate was reduced to 0.0001 and the model was trained on 6 pictures per batch.", "This generally makes sense because during the later stages of training, since the model is moving towards convergence, we must lower the learning rate so that we take smaller steps towards the minima. Also increasing the batch size over time helps your gradient updates to be more powerful.", "Time Taken: I used the GPU+ Gradient Notebook on www.paperspace.com and hence it took me approximately an hour to train the model. However if you train it on a PC without GPU, it could take anywhere from 8 to 16 hours depending on the configuration of your system.", "So till now, we have seen how to prepare the data and build the model. In the final step of this series, we will understand how do we test (infer) our model by passing in new images, i.e. how can we generate a caption for a new test image.", "Recall that in the example where we saw how to prepare the data, we used only first two images and their captions. Now let\u2019s use the third image and try to understand how we would like the caption to be generated.", "The third image vector and caption were as follows:", "Caption -> the black cat is walking on grass", "Also the vocabulary in the example was:", "vocab = {black, cat, endseq, grass, is, on, road, sat, startseq, the, walking, white}", "We will generate the caption iteratively, one word at a time as follows:", "Input: Image vector + \u201cstartseq\u201d (as partial caption)", "(You should now understand the importance of the token \u2018startseq\u2019 which is used as the initial partial caption for any image during inference).", "But wait, the model generates a 12-long vector(in the sample example while 1652-long vector in the original example) which is a probability distribution across all the words in the vocabulary. For this reason we greedily select the word with the maximum probability, given the feature vector and partial caption.", "If the model is trained well, we must expect the probability for the word \u201cthe\u201d to be maximum:", "This is called as Maximum Likelihood Estimation (MLE) i.e. we select that word which is most likely according to the model for the given input. And sometimes this method is also called as Greedy Search, as we greedily select the word with maximum probability.", "Input: Image vector + \u201cstartseq the\u201d", "Input: Image vector + \u201cstartseq the black\u201d", "Input: Image vector + \u201cstartseq the black cat\u201d", "Input: Image vector + \u201cstartseq the black cat is\u201d", "Input: Image vector + \u201cstartseq the black cat is walking\u201d", "Input: Image vector + \u201cstartseq the black cat is walking on\u201d", "Input: Image vector + \u201cstartseq the black cat is walking on grass\u201d", "This is where we stop the iterations.", "So we stop when either of the below two conditions is met:", "If any of the above conditions is met, we break the loop and report the generated caption as the output of the model for the given image. The code for inference is as follows:", "To understand how good the model is, let\u2019s try to generate captions on images from the test dataset (i.e. the images which the model did not see during the training).", "Note: We must appreciate how the model is able to identify the colors precisely.", "Of course, I would be fooling you if I only showed you the appropriate captions. No model in the world is ever perfect and this model also makes mistakes. Let\u2019s look at some examples where the captions are not very relevant and sometimes even irrelevant.", "Probably the color of the shirt got mixed with the color in the background", "Why does the model classify the famous Rafael Nadal as a woman :-) ? Probably because of the long hair.", "The model gets the grammar incorrect this time", "Clearly, the model tried its best to understand the scenario but still the caption is not a good one.", "Again one more example where the model fails and the caption is irrelevant.", "So all in all, I must say that my naive first-cut model, without any rigorous hyper-parameter tuning does a decent job in generating captions for images.", "We must understand that the images used for testing must be semantically related to those used for training the model. For example, if we train our model on the images of cats, dogs, etc. we must not test it on images of air planes, waterfalls, etc. This is an example where the distribution of the train and test sets will be very different and in such cases no Machine Learning model in the world will give good performance.", "Thanks a lot if you have reached here. This is my first attempt in blogging so I expect the readers to be a bit generous and ignore the minor mistakes I might have made.", "Please refer my GitHub link here to access the full code written in Jupyter Notebook.", "Note that due to the stochastic nature of the models, the captions generated by you (if you try to replicate the code) may not be exactly similar to those generated in my case.", "Of course this is just a first-cut solution and a lot of modifications can be made to improve this solution like:", "PS: Feel free to provide comments/criticisms if you think they can improve this blog, I will definitely try to make the required changes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc88a46a311b8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@harshall.lamba?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Harshall Lamba"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa35dfc76e885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&user=Harshall+Lamba&userId=a35dfc76e885&source=post_page-a35dfc76e885----c88a46a311b8---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc88a46a311b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&user=Harshall+Lamba&userId=a35dfc76e885&source=-----c88a46a311b8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc88a46a311b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&source=-----c88a46a311b8---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www.linkedin.com/in/andrej-karpathy-9a650716", "anchor_text": "Andrej Karapathy"}, {"url": "https://www.captionbot.ai/", "anchor_text": "Caption Bot"}, {"url": "https://www.youtube.com/watch?v=rLyF4XQLwr0", "anchor_text": "link"}, {"url": "https://forms.illinois.edu/sec/1713398", "anchor_text": "form"}, {"url": "https://wiki.python.org/moin/Generators", "anchor_text": "here"}, {"url": "https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/", "anchor_text": "link"}, {"url": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "here"}, {"url": "http://www.paperspace.com", "anchor_text": "www.paperspace.com"}, {"url": "https://github.com/hlamba28/Automatic-Image-Captioning.git", "anchor_text": "here"}, {"url": "https://cs.stanford.edu/people/karpathy/cvpr2015.pdf", "anchor_text": "https://cs.stanford.edu/people/karpathy/cvpr2015.pdf"}, {"url": "https://arxiv.org/abs/1411.4555", "anchor_text": "https://arxiv.org/abs/1411.4555"}, {"url": "https://arxiv.org/abs/1703.09137", "anchor_text": "https://arxiv.org/abs/1703.09137"}, {"url": "https://arxiv.org/abs/1708.02043", "anchor_text": "https://arxiv.org/abs/1708.02043"}, {"url": "https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/", "anchor_text": "https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/"}, {"url": "https://www.youtube.com/watch?v=yk6XDFm3J2c", "anchor_text": "https://www.youtube.com/watch?v=yk6XDFm3J2c"}, {"url": "https://www.appliedaicourse.com/", "anchor_text": "https://www.appliedaicourse.com/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c88a46a311b8---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----c88a46a311b8---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c88a46a311b8---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----c88a46a311b8---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----c88a46a311b8---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc88a46a311b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&user=Harshall+Lamba&userId=a35dfc76e885&source=-----c88a46a311b8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc88a46a311b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&user=Harshall+Lamba&userId=a35dfc76e885&source=-----c88a46a311b8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc88a46a311b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa35dfc76e885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&user=Harshall+Lamba&userId=a35dfc76e885&source=post_page-a35dfc76e885----c88a46a311b8---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbafcdf1b349d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&newsletterV3=a35dfc76e885&newsletterV3Id=bafcdf1b349d&user=Harshall+Lamba&userId=a35dfc76e885&source=-----c88a46a311b8---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Written by Harshall Lamba"}, {"url": "https://medium.com/@harshall.lamba/followers?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa35dfc76e885&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&user=Harshall+Lamba&userId=a35dfc76e885&source=post_page-a35dfc76e885----c88a46a311b8---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbafcdf1b349d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&newsletterV3=a35dfc76e885&newsletterV3Id=bafcdf1b349d&user=Harshall+Lamba&userId=a35dfc76e885&source=-----c88a46a311b8---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47?source=author_recirc-----c88a46a311b8----0---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=author_recirc-----c88a46a311b8----0---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=author_recirc-----c88a46a311b8----0---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Harshall Lamba"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c88a46a311b8----0---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47?source=author_recirc-----c88a46a311b8----0---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Understanding Semantic Segmentation with UNETA Salt Identification Case Study"}, {"url": "https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47?source=author_recirc-----c88a46a311b8----0---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "15 min read\u00b7Feb 17, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6be4f42d4b47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-semantic-segmentation-with-unet-6be4f42d4b47&user=Harshall+Lamba&userId=a35dfc76e885&source=-----6be4f42d4b47----0-----------------clap_footer----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47?source=author_recirc-----c88a46a311b8----0---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "48"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6be4f42d4b47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-semantic-segmentation-with-unet-6be4f42d4b47&source=-----c88a46a311b8----0-----------------bookmark_preview----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c88a46a311b8----1---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c88a46a311b8----1---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c88a46a311b8----1---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c88a46a311b8----1---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c88a46a311b8----1---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c88a46a311b8----1---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c88a46a311b8----1---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----c88a46a311b8----1-----------------bookmark_preview----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c88a46a311b8----2---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----c88a46a311b8----2---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----c88a46a311b8----2---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c88a46a311b8----2---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c88a46a311b8----2---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c88a46a311b8----2---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c88a46a311b8----2---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----c88a46a311b8----2-----------------bookmark_preview----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f?source=author_recirc-----c88a46a311b8----3---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=author_recirc-----c88a46a311b8----3---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=author_recirc-----c88a46a311b8----3---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Harshall Lamba"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c88a46a311b8----3---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f?source=author_recirc-----c88a46a311b8----3---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "Intuitive Understanding of Attention Mechanism in Deep LearningA TensorFlow Implementation of Neural Machine Translation with Attention"}, {"url": "https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f?source=author_recirc-----c88a46a311b8----3---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": "\u00b711 min read\u00b7Mar 20, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6c9482aecf4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f&user=Harshall+Lamba&userId=a35dfc76e885&source=-----6c9482aecf4f----3-----------------clap_footer----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f?source=author_recirc-----c88a46a311b8----3---------------------c1f82614_2333_4050_b9c9_10e8cb7b06f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c9482aecf4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f&source=-----c88a46a311b8----3-----------------bookmark_preview----c1f82614_2333_4050_b9c9_10e8cb7b06f2-------", "anchor_text": ""}, {"url": "https://medium.com/@harshall.lamba?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "See all from Harshall Lamba"}, {"url": "https://towardsdatascience.com/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----c88a46a311b8----0-----------------bookmark_preview----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----1-----------------clap_footer----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----c88a46a311b8----1-----------------bookmark_preview----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Josep Ferrer"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Stop doing this on ChatGPT and get ahead of the 99% of its usersUnleash the Power of AI Writing with Effective Prompts"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "\u00b78 min read\u00b7Mar 31"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&user=Josep+Ferrer&userId=8213af8f3ccf&source=-----f3441bf7a25a----0-----------------clap_footer----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----c88a46a311b8----0---------------------b37ffc16_4be4_4852_838d_a846d323b054-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "71"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&source=-----c88a46a311b8----0-----------------bookmark_preview----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----c88a46a311b8----1---------------------b37ffc16_4be4_4852_838d_a846d323b054-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----c88a46a311b8----1-----------------bookmark_preview----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c88a46a311b8----2---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----c88a46a311b8----2---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----c88a46a311b8----2---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c88a46a311b8----2---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c88a46a311b8----2---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c88a46a311b8----2---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----c88a46a311b8----2---------------------b37ffc16_4be4_4852_838d_a846d323b054-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----c88a46a311b8----2-----------------bookmark_preview----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c88a46a311b8----3---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----c88a46a311b8----3---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----c88a46a311b8----3---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c88a46a311b8----3---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c88a46a311b8----3---------------------b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----3-----------------clap_footer----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c88a46a311b8----3---------------------b37ffc16_4be4_4852_838d_a846d323b054-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----c88a46a311b8----3-----------------bookmark_preview----b37ffc16_4be4_4852_838d_a846d323b054-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----c88a46a311b8--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}