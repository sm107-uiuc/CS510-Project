{"url": "https://towardsdatascience.com/memory-efficient-data-science-types-53423d48ba1d", "time": 1683017329.008769, "path": "towardsdatascience.com/memory-efficient-data-science-types-53423d48ba1d/", "webpage": {"metadata": {"title": "Memory Efficient Data Science: Types | by Ygor Serpa | Towards Data Science", "h1": "Memory Efficient Data Science: Types", "description": "Many of us data scientists deal with massive amounts of information daily. More often than not, these data streams doesn\u2019t fit the available memory, and when this happens, things can get pretty slow\u2026"}, "outgoing_paragraph_urls": [{"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html", "anchor_text": "one-hot encoding", "paragraph_index": 25}, {"url": "https://cocodataset.org/#home", "anchor_text": "COCO object detection problem", "paragraph_index": 26}, {"url": "https://www.linkedin.com/in/ygorreboucas/", "anchor_text": "connect with me", "paragraph_index": 34}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "subscribing", "paragraph_index": 34}, {"url": "https://stackoverflow.com/", "anchor_text": "StackOverflow", "paragraph_index": 34}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "my affiliate link when signing up.", "paragraph_index": 34}], "all_paragraphs": ["Many of us data scientists deal with massive amounts of information daily. More often than not, these data streams doesn\u2019t fit the available memory, and when this happens, things can get pretty slow \u2014 or crash. Buying more RAM isn\u2019t your only option; there are many tricks to use the system memory better. This can be as simple as changing data types or employing smart caching/paging strategies to hide latency.", "In this article, I go over the most fundamental way of reducing memory consumption: using the right data-types. While some memory saving tricks can be quite tricky, changing types usually boils down to a few lines of code that can save dramatic amounts of memory.", "While some of this might sound trivial to people with a computer science degree or some experience with statically typed languages, typing and how it relates to memory might not be familiar to many who have worked solely with languages such as Python and JavaScript.", "Whenever we create variables, some space is allocated in memory to store them. The type of a variable determines how the value is stored, how many bytes are used, and its properties.", "In languages such as Python, the types are implicit; we don\u2019t have to state them in code. For instance, a = 2 is automatically recognized as an integer while b = 3.14159 is identified as a float. In languages such as C, we have to explicitly state the type of a variable to create it, for instance: int a = 10.", "By having implicit types, it is easy to forget types even exist \u2014 and that large chunks of memory can be saved by properly choosing them. In this article, I mention three categories of types explicitly:", "Floats and ints in Python default to using 8 bytes, which is too much for most cases. Merely changing to a 4 bytes variant is a 50% cut on memory use. Ints can be as small as 1 byte, using only 12.5% percent as much memory. Strings, on the other hand, can\u2019t be simplified but can be avoided.", "In the following, I delve into specific type choices for each category.", "By default, NumPy stores floating-point data in the np.float64 format, which occupies 8 bytes per value and is slower to process by either CPU or GPU. As a general rule of thumb, you can expect np.float32 to be twice as fast and take half the memory.", "To make use of np.float32, simply downcast your data to it:", "One caveat is that any operation between a np.float32 array and a np.float64 array will upcast the result back tonp.float64. Thus, you have to either downcast all relevant arrays to np.float32 or make sure you keep tabs on all data types \u2014 which you are doing anyway, right?", "The downside of this operation is reduced precision. Floats are not perfectly accurate: most operations cause rounding errors. These are rarely problematic, but hard-to-track bugs are bound to happen when they add up. \u201cDouble-precision,\u201d as np.float64 is typically called, is less prone to numerical issues \u2014 at the cost of a larger memory footprint", "A quick way to see the precision in action is to open an image, compute each column's mean, subtract it from each column, and compute the mean again. One should expect all new column means to be zero, but, in reality, many will be really close to zero, but not exactly zero. Here is a quick demo:", "As a rule of thumb, stick to np.float64 as long as memory is not a concern. If you run into out-of-memory issues, downcasting the most memory hungry arrays to np.float32 is a generally safe and effective way to half your memory use. And, as a plus, you get some speed boost as well.", "On GPUs, some even cheaper alternatives to the float64 format exist. These are known as half-precision floats and use only 16 bits. However, these do not work as a memory saving solution, as they are not useful for storage. Their purpose is to speed up the training of neural networks.", "Unlike float32, half-precision types are tricky to use. They are (1) not supported on CPUs, (2) not fully supported on most packages, and (3) unstable. For this reason, most packages use a mixed-precision setting: computations are half-precision, but results are saved at regular-precision. Thus, storage is largely unaffected.", "The real value of mixed-precision is that intermediate results are saved at half-precision. Thus, in mixed-precision mode, users can often double their batch-size and, therefore, train faster. This won\u2019t lead to storage savings but is damn useful in practice\u2014training faster rocks.", "In practice, avoid using half-precision directly and, instead, rely on TensorFlow / PyTorch implementations of automatic mixed-precision. This way, you avoid dealing with complexities such as scaling losses/gradients.", "While floats generally come in two flavors, ints boast several. In short, integer types vary concerning signedness (if negative numbers are allowed) and capacity (the largest value it can store). A uint8 cannot hold negative values (it is unsigned) and can store up to 8 bits of information (0 to 255). Its signed counterpart, int8, allocates its 8bits for negative and positive values; thus, it can store any number from -128 to 127.", "Here is a quick breakdown of what each integer type can store", "Respectively, the ranges for the unsigned counterparts are:", "In practice, the most widely used options are the np.int32 and np.uint8 data types. The former is your average integer, it rarely fails and is not as hungry as the 64 bits variant, and the latter is intended as a \u201cbyte\u201d data type, which works wonders in many domains. Using int8 or uint8 can reduce an array memory consumption to one-eighth of its original size.", "One of the most common applications of uint8 is image data. Most monitors are limited to 255 shades of red, green, and blue. The advertised \u201c16 million colors\u201d come from multiplying 255 * 255 * 255, all the combinations of the available 255 colors for each channel. Thus, it makes little sense to store images with more than a uint8.", "The exception is color processing, such as feeding images to neural networks or using photoshop. In these scenarios, images are temporarily stored as floats for higher precision. However, whenever the processing ends, they are reverted to uint8 for storage. Similarly, audio data is often stored in uint8 and processed asfloat.", "In terms of a training pipeline, the conversion to/from floats should be done right before feeding data to the model and rightly after collecting its outputs. This ensures that your data will stay in a lower-consumption format for as long as possible, and only one batch of data will be in float at a time.", "It is important to highlight the amount of memory that can be saved by not using one-hot encoding arbitrarily. You should one-hot encode your data just before you use it, not in advance. This can yield orders of magnitude savings.", "Consider the COCO object detection problem. It features 1.5M objects that come from 80 labels. Since 80 < 255, we can store our label data in uint8. Doing the math, this equates to 1.43 megabytes of memory. A naive coder might one-hot encode all this to int32 or float, creating a 1.5M \u00d7 80 array that uses 4 bytes per element. Now we are using 457.76 megabytes. Near half a GB on just labels, and we still have bounding boxes and other stuff to store.", "Consider the same scenario for a segmentation task with 10 thousand 256\u00d7256 images containing 8 classes. Doing the math, 10.000 \u00d7 256\u00d7256 \u00d7 8 \u00d7 4 bytes is a whooping ~19 gigabytes of labels. Storing the same data with class indices in uint8 is 32 times cheaper, less than a GB is spent.", "The easiest fix is to encode one batch at a time and not your entire dataset. This will leave all your data neatly packed as uint8s while keeping everything the same for your model. Another solution is to one-hot encode your outputs directly at your loss function, right before being used.", "While the major memory savings come from using smaller floats and ints, some can be accomplished with strings.", "Although strings are meant for text, we typically use them for simpler tasks, such as single words or paths. These are often highly redundant and can be simplified to a list of indices of a look-up. In other cases, one can extract a common prefix, such as the root directory of a list of files.", "For instance, the 80 object categories recognized by the COCO dataset can be represented by 80 integer values plus a dictionary mapping each value to its respective name. Similarly, a list of file paths might be shrunk to a string containing the path and a list of file names. For large text corpora, the words might be replaced by indices to a word look-up.", "Apart from these suggestions, strings tend to be too application-specific. Therefore, string memory reduction is often done based on knowledge of the problem being solved and the data's specific traits. However, in most machine learning and deep learning scenarios, strings are converted into a numerical representation, which can benefit from the general float and int recommendations given above.", "This article overviewed the basics of data types, better choices for floats and ints, and some general guidelines for strings. While most of it might seem trivial, these small changes can yield dramatic results and are often forgotten due to the implicit typing of dynamic languages. And, besides the memory savings, using smaller types is often faster as well. It\u2019s a win-win.", "Feel free to comment or connect with me if you have any questions on this article. If you are new to Medium, I highly recommend subscribing. Medium articles are the perfect pair to StackOverflow for Data and IT professionals, and even more so for new comers. Please consider using my affiliate link when signing up.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Former game developer turned data scientist after falling in love with AI and all its branches."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F53423d48ba1d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ygorserpa.medium.com/?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": ""}, {"url": "https://ygorserpa.medium.com/?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "Ygor Serpa"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F857d8734c7da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&user=Ygor+Serpa&userId=857d8734c7da&source=post_page-857d8734c7da----53423d48ba1d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F53423d48ba1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F53423d48ba1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@zeak?utm_source=medium&utm_medium=referral", "anchor_text": "Dmitrij Paskevic"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/taking-keras-and-tensorflow-to-the-next-level-c73466e829d3", "anchor_text": "Taking Keras and TensorFlow to the Next Level11 tips and tricks to make the most out of Keras and TensorFlowtowardsdatascience.com"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html", "anchor_text": "one-hot encoding"}, {"url": "https://cocodataset.org/#home", "anchor_text": "COCO object detection problem"}, {"url": "https://www.linkedin.com/in/ygorreboucas/", "anchor_text": "connect with me"}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "subscribing"}, {"url": "https://stackoverflow.com/", "anchor_text": "StackOverflow"}, {"url": "https://ygorserpa.medium.com/membership", "anchor_text": "my affiliate link when signing up."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----53423d48ba1d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----53423d48ba1d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----53423d48ba1d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----53423d48ba1d---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/programming?source=post_page-----53423d48ba1d---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F53423d48ba1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&user=Ygor+Serpa&userId=857d8734c7da&source=-----53423d48ba1d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F53423d48ba1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&user=Ygor+Serpa&userId=857d8734c7da&source=-----53423d48ba1d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F53423d48ba1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F53423d48ba1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----53423d48ba1d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----53423d48ba1d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----53423d48ba1d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----53423d48ba1d--------------------------------", "anchor_text": ""}, {"url": "https://ygorserpa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ygorserpa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ygor Serpa"}, {"url": "https://ygorserpa.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F857d8734c7da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&user=Ygor+Serpa&userId=857d8734c7da&source=post_page-857d8734c7da--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3644829c90d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmemory-efficient-data-science-types-53423d48ba1d&newsletterV3=857d8734c7da&newsletterV3Id=3644829c90d9&user=Ygor+Serpa&userId=857d8734c7da&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}