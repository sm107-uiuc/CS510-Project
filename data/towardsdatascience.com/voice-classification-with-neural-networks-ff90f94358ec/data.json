{"url": "https://towardsdatascience.com/voice-classification-with-neural-networks-ff90f94358ec", "time": 1683003955.998824, "path": "towardsdatascience.com/voice-classification-with-neural-networks-ff90f94358ec/", "webpage": {"metadata": {"title": "Voice Classification with Neural Networks | by Jurgen Arias | Towards Data Science", "h1": "Voice Classification with Neural Networks", "description": "Imagine a conference room, a meeting is taking place. There are several people, they all take turns to speak. We want to transcribe what they are saying. There are tools that can transcribe voice to t"}, "outgoing_paragraph_urls": [{"url": "https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://drive.google.com/drive/folders/0By0bAi7hOBAFUHVXd1JCN3MwTEU", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://librosa.org/doc/latest/feature.html", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://librosa.org/doc/latest/generated/librosa.display.specshow.html", "anchor_text": "Specshow from librosa", "paragraph_index": 14}, {"url": "https://keras.io/preprocessing/image/", "anchor_text": "here", "paragraph_index": 16}, {"url": "http://www.openslr.org/12/", "anchor_text": "here", "paragraph_index": 19}, {"url": "https://en.wikipedia.org/wiki/Voice_frequency", "anchor_text": "Wikipedia", "paragraph_index": 26}, {"url": "https://en.wikipedia.org/wiki/Voice_frequency).", "anchor_text": ")", "paragraph_index": 26}, {"url": "https://towardsdatascience.com/google-colab-jupyter-lab-on-steroids-perfect-for-deep-learning-cdddc174d77a", "anchor_text": "this", "paragraph_index": 28}, {"url": "https://github.com/jurgenarias/Portfolio/tree/master/Voice%20Classification", "anchor_text": "github", "paragraph_index": 32}, {"url": "https://medium.com/@patrickbfuller/librosa-a-python-audio-libary-60014eeaccfb", "anchor_text": "Librosa: A Python Audio Library (2019)", "paragraph_index": 33}, {"url": "https://www.hindawi.com/journals/sp/2019/7213717/", "anchor_text": "DGR: Gender Recognition of Human Speech Using One-Dimensional Conventional Neural Network", "paragraph_index": 34}, {"url": "http://www.primaryobjects.com/2016/06/22/identifying-the-gender-of-a-voice-using-machine-learning/", "anchor_text": "Identifying the Gender of a Voice using Machine Learning", "paragraph_index": 35}, {"url": "https://medium.com/@CVxTz?source=post_page-----b0a4fce8f6c----------------------", "anchor_text": "Youness Mansar", "paragraph_index": 36}, {"url": "https://medium.com/@CVxTz/audio-classification-a-convolutional-neural-network-approach-b0a4fce8f6c", "anchor_text": "Audio Classification : A Convolutional Neural Network Approach", "paragraph_index": 36}, {"url": "https://www.analyticsvidhya.com/blog/author/jalfaizy/", "anchor_text": "Faizan Shaik", "paragraph_index": 37}, {"url": "https://www.analyticsvidhya.com/blog/2017/08/audio-voice-processing-deep-learning/", "anchor_text": "Getting Started with Audio Data Analysis using Deep Learning (with case study)", "paragraph_index": 37}, {"url": "https://upcommons.upc.edu/bitstream/handle/2117/86673/113166.pdf", "anchor_text": "Voice gender identification using deep neural networks running on FPGA", "paragraph_index": 38}, {"url": "https://www.endpoint.com/team/kamil_ciemniewski", "anchor_text": "Kamil Ciemniewski", "paragraph_index": 39}, {"url": "https://www.endpoint.com/blog/2019/01/08/speech-recognition-with-tensorflow", "anchor_text": "Speech Recognition from scratch using Dilated Convolutions and CTC in TensorFlow", "paragraph_index": 39}, {"url": "https://towardsdatascience.com/@admond1994?source=post_page-----81d0fe3cea9a----------------------", "anchor_text": "Admond Lee", "paragraph_index": 40}, {"url": "https://towardsdatascience.com/how-to-build-a-speech-recognition-bot-with-python-81d0fe3cea9a", "anchor_text": "How To Build A Speech Recognition Bot With Python", "paragraph_index": 40}, {"url": "https://medium.com/@adrianitsaxu?source=post_page-----486e92785df4----------------------", "anchor_text": "Adrian Yijie Xu", "paragraph_index": 41}, {"url": "https://medium.com/gradientcrescent/urban-sound-classification-using-convolutional-neural-networks-with-keras-theory-and-486e92785df4", "anchor_text": "Urban Sound Classification using Convolutional Neural Networks with Keras: Theory and Implementation", "paragraph_index": 41}], "all_paragraphs": ["Imagine a conference room where a meeting is taking place. There are several people, they all take turns to speak. We would like to transcribe what they are saying. There are tools that can transcribe voice to text (most of us have that feature on our phones and do not even know it), but can we train a model to learn voices and accurately predict who is speaking just by listening to their voice? Can we predict their gender?", "We will tackle these problems by using Machine Learning with Neural Networks.", "The first step was to learn how to manipulate audio data and build models to classify sounds. I found a great competition called the Urban Sound Classification here. The problem was to classify 10 different urban sounds like children playing, street music, car engine, etc. I did a lot of research to understand how to solve the problem and how a lot of people have tackled the problem. I focused on two approaches. The first approach was to extract numerical features from the audio clips using the librosa library for python and using those features to train a neural network model (NN) and the second approach was to convert the audio clips to pictures and use those images to train a convolutional neural network model (CNN).", "I got good results with the NN (93% on test data) and with the CNN (92% on test data). I combined those two models together in a voting classifier by joining the probability of the predictions and got a 95% accuracy when using the NN and CNN together.", "Now I could move forward and use what I learned to tackle the speaker and speaker\u2019s gender classifier problem.", "I used a NN model to classify 115 speakers and got 99.8% accuracy. I did not do the CNN anymore because of the high accuracy (almost perfect) of the NN model.", "I used a NN model for predicting gender and got 99.8% accuracy when classifying the gender of speakers that the model had listened to before. I got new data from speakers that the model had never heard before and got a 95% accuracy.", "I also used a CNN model for predicting gender and got 97.7% accuracy (compare to 99.8% from the NN model) on previously heard speakers. I got 95% accuracy on never before heard speakers.", "Now let\u2019s dive deeper into each different project.", "I got the link for the data from the competition\u2019s website. They are in a google drive here. I only used the train data since I wanted to test on label data to see how good my model was. The test data from the source is unlabeled and only for predictions submitted for the competition.", "The data contains 5435 labeled sounds from 10 different classes. The classes are siren, street music, drilling, engine idling, air conditioner, car horn, dog bark, drilling, gun shot and jackhammer. Most classes are balanced but there are two that have low representation. Most represent 11% of the data but one only represents 5% and one only 4%. I did not balance the classes because I took it as a good challenge to build a good model with somewhat unbalanced classes.", "Librosa is a fantastic library for python to use with audio files and it is what most people used in the audio classification problems. I used the librosa library to extract features. After doing some research, I found some features from the librosa information here.", "I loaded the csv file that came with the training data into a dataframe with all the names of the audio files and its corresponding labels. I extracted the features through a function that iterates through every row of the dataframe accessing the file in the computer by reading the file\u2019s path. I used Mel-frequency Cepstral Coefficients (MFCCs), Chromagram, Mel-scaled Spectrogram, Spectral Contrast and Tonal Centroid Features (tonnetz). I got an array of 193 features with their respective label. I set them to be my X and y and split them into training, validation and test data. I checked that I kept the same proportions for the classes as the total data and scaled the data. I chose 3435 audios for my train data, 1000 for my validation data and 1000 for my test data.", "I built a feed forward neural network with dense layers with two hidden layers using relu and softmax for the 10 outputs. I then compiled the model using the adam optimizer and categorical crossentrophy for loss. I also gridsearched the best parameters for the number of neurons and the dropout proportions for the layers and came up with a decent model that predicted my test never before seen (or heard) data with an accuracy of 93%.", "Using the same data and the same steps as above, I generated my dataframe for the audio files. Now I needed to use a function to create images for every audio file. As before, my function iterated through every row of the dataframe and created an image using librosa and saved it to a local folder. Here is the information about how to create an image from librosa and the different kinds of images you can create: Specshow from librosa.", "After creating the images, I again split my data intro training, validation and test (I used the same proportions as with the neural network from before). I checked that I had the same balance on classes and changed the dataframe file names from .wav to .jpg so that I could use the same dataframe to access the images from my local folder.", "Keras has some wonderful information about how to load and preprocess images from your local files specially the .flow_from_dataframe which is what I used. The documentation is here. This way, I loaded my train, validation and test data into generators and I was ready to build the model.", "I built a convolutional neural network with a Conv2D and MaxPooling2D input and five hidden layers: three Conv2D with their respective MaxPooling2D, then flatten and two Dense layers (all with relu). Finally I had the Dense output layer for the 10 classes with softmax activation. I, again, compiled the model using the adam optimizer and categorical crossentrophy for loss. I did not use gridsearch because it took too long (about two hours) so I trained on 250 epochs. I got 92% accuracy on my never before seen test data.", "I decided that since I have two models that do the same thing, I might as well use them together. I got the predictions probabilities for each class from my NN and the predictions probabilities for my CNN and added them together and got the maximum for each one. In other words, if my NN was 65% sure that a sound was some children playing and my CNN was 95% sure it was instead street music, then street music would have a higher probability thus my prediction would have to be street music. I did this and bumped my predictions to 95% accuracy on never before seen test data (remember I got 93% for the NN and 92% for the CNN). I found this to be an amazing way to combine different models together to have better predictions.", "Now I have the tools to tackle my original problem which was classifying speakers. The first problem was to get good audio data. After much research, I ran into an absolutely amazing database for audio clips from audiobooks recordings here. This dataset contains many gigabytes of clean data in \u201c.flac\u201d files that work great with macs. I used a subset of the train-clean-100.tar.gz [6.3G]. The data comes very well organized in folders by speakers with speaker ids, books, chapters and file number. I also got a \u201c.txt\u201d file with information from the speakers letting you know their gender, the length of their recordings and even their name. The subset I used has 13,000 voice clips usually ranging from 12 to 18 seconds.", "I tried the feed forward neural network since it is faster and gave me better accuracy for the Urban Sound Challenge problem. I followed the same steps as before, only now dealing with much more data (around 13k instead of 5k) and longer voice clips (average of around 14 seconds instead of 4 seconds). Extracting the features took around 3 hours but it needed to be done only once and I saved that array as a numpy array in a local folder and loaded it whenever I needed to use it or change anything.", "I used 115 different speakers both male and female where the minimum number of voice clips per speaker was 56 and the maximum was 166 (randomly selected). The standard deviation of the number of clips per speaker was about 16. I considered them to be balanced classes.", "I fitted the data into a neural network model with the same configuration of my gridsearched model from the Urban Sound Challenge and got a whopping 99.8% accuracy. I predicted on 1312 audio samples and classified them into the 115 speakers and only got two audio samples wrong. The model only took 20 seconds to fit and it was almost perfect so I decided it was not necessary to do the CNN model.", "Using the same amount of data as for the speaker classifier, I labeled the voice clips by male and female by placing them into two separate folders. I generated dataframes from each folder and then concatenated (fancy term for putting together) them into a dataframe. I shuffled the data and reset the index to get a brand new dataframe of all the files with labeled gender data.", "I used the same split and extracted the same features as the Urban Sound Challenge NN model. I used the same configuration from my Feed Forward Neural Network and again, it only took 20 seconds to fit the model. I got an accuracy of 99.8% on my test data. Even though my model had never seen (or heard) my test data, it had been trained with data that contains the same people speaking, that is why my model was almost perfect. I taught the model which speaker was male and female and when I predicted new voice clips, it was almost perfect because it already knew the people. After considering this, I gathered more data. I collected 100 new voice clips from new people that my model had never heard before. I cleaned it in the same way and made predictions on it. I got 97% accuracy on my new test data from 100 never before heard speakers.", "I have a good model but it is not almost perfect like the model for Speaker Classifier so I decided to do a CNN to see if I could improve my results.", "Just like in the urban sound classifier problem, I created images from my data that I labeled and placed into local folders. I created the dataframes and used my function to create the images in a different folder to use with the Keras Generator. Since I was dealing with voice, I reduced the frequency of the audio clip images to only include frequencies from 50 Hz to 280 Hz. \u201cThe voiced speech of a typical adult male will have a fundamental frequency from 85 to 180 Hz, and that of a typical adult female from 165 to 255 Hz\u201d (from Wikipedia). I, again, used the same CNN configuration as before and fitted the model (which took a couple of hours). I got a 97.7% accuracy on my test data. Remember, I got 99.8% accuracy on my test data with my simple dense feed forward neural network so this was a little disappointing. I, again, generated predictions on 100 new never before heard speakers and got a 95% accuracy.", "I could combine these two models with a voting classifier and get a better accuracy or train the models with more data to make them more accurate but I had a time constraint to present my project and I wanted to implement this model to be able to use it for an interactive demonstration and the CNN model\u2019s process takes too long. It takes a long time to create the images and also to fit the model so I used the NN with 97% accuracy since it is fast and accurate.", "I would like to gridsearch over the best parameters on my CNN and see if I could get the same or better accuracy than my Dense Layered Neural Network. This could also be done by uploading the data and using Google Colab since they provide free GPU usage that make Neural Networks run considerably much faster. If your laptop takes 4 hours to fit a neural network, Google Colab can probably do it in 15 minutes. If Google Colab sounds interesting, I recommend reading this blog post from my friend and colleague Brenda Hali about Google Colab.", "I would also like to try CNN models with all the different kinds of images that librosa provides from audio files and see which kind of images give better predictions.", "I would like to add more training data to see if I can get better results in the speaker\u2019s gender classifier. I had to label the data by hand and this was time consuming. With more data, I can probably have more accurate models.", "I would also like to fit a Recurrent Neural Network and see how accurate it is since they are good with time series data and voice clips are basically time series.", "The code for the whole project in jupyter notebooks is available on my github.", "[1] David Kaspar, Alexander Bailey, Patrick Fuller, Librosa: A Python Audio Library (2019)", "[2] Rami S. Alkhawaldeh, DGR: Gender Recognition of Human Speech Using One-Dimensional Conventional Neural Network (2019)", "[3] Kory Becker, Identifying the Gender of a Voice using Machine Learning (2016)", "[5] Youness Mansar, Audio Classification : A Convolutional Neural Network Approach (2018)", "[6] Faizan Shaikh, Getting Started with Audio Data Analysis using Deep Learning (with case study) (2017)", "[9] Marc Palet Gual, Voice gender identification using deep neural networks running on FPGA, (2016)", "[10] Kamil Ciemniewski, Speech Recognition from scratch using Dilated Convolutions and CTC in TensorFlow, (2019)", "[11] Admond Lee, How To Build A Speech Recognition Bot With Python (2019)", "[12] Adrian Yijie Xu, Urban Sound Classification using Convolutional Neural Networks with Keras: Theory and Implementation, (2019)", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fff90f94358ec&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jurgenarias?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jurgenarias?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "Jurgen Arias"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5f9078a89846&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&user=Jurgen+Arias&userId=5f9078a89846&source=post_page-5f9078a89846----ff90f94358ec---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fff90f94358ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fff90f94358ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://searchmobilecomputing.techtarget.com/photostory/450428625/Get-personal-with-mobile-biometric-authentication/5/Get-in-tune-with-voice-recognition-authentication", "anchor_text": "searchmobilecomputing"}, {"url": "https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/", "anchor_text": "here"}, {"url": "https://drive.google.com/drive/folders/0By0bAi7hOBAFUHVXd1JCN3MwTEU", "anchor_text": "here"}, {"url": "https://librosa.org/doc/latest/feature.html", "anchor_text": "here"}, {"url": "https://librosa.org/doc/latest/generated/librosa.display.specshow.html", "anchor_text": "Specshow from librosa"}, {"url": "https://keras.io/preprocessing/image/", "anchor_text": "here"}, {"url": "http://www.openslr.org/12/", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Voice_frequency", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Voice_frequency).", "anchor_text": ")"}, {"url": "https://towardsdatascience.com/google-colab-jupyter-lab-on-steroids-perfect-for-deep-learning-cdddc174d77a", "anchor_text": "this"}, {"url": "https://github.com/jurgenarias/Portfolio/tree/master/Voice%20Classification", "anchor_text": "github"}, {"url": "https://searchmobilecomputing.techtarget.com/photostory/450428625/Get-personal-with-mobile-biometric-authentication/5/Get-in-tune-with-voice-recognition-authentication", "anchor_text": "searchmobilecomputing.techtarget.com"}, {"url": "http://www.openslr.org/12/", "anchor_text": "http://www.openslr.org/12/"}, {"url": "https://drive.google.com/drive/folders/0By0bAi7hOBAFUHVXd1JCN3MwTEU.", "anchor_text": "https://drive.google.com/drive/folders/0By0bAi7hOBAFUHVXd1JCN3MwTEU."}, {"url": "https://medium.com/@patrickbfuller/librosa-a-python-audio-libary-60014eeaccfb", "anchor_text": "Librosa: A Python Audio Library (2019)"}, {"url": "https://www.hindawi.com/journals/sp/2019/7213717/", "anchor_text": "DGR: Gender Recognition of Human Speech Using One-Dimensional Conventional Neural Network"}, {"url": "http://www.primaryobjects.com/2016/06/22/identifying-the-gender-of-a-voice-using-machine-learning/", "anchor_text": "Identifying the Gender of a Voice using Machine Learning"}, {"url": "https://towardsdatascience.com/@ultimatist?source=post_page-----1ef708ec5f53----------------------", "anchor_text": "Jonathan Balaban"}, {"url": "https://towardsdatascience.com/deep-learning-tips-and-tricks-1ef708ec5f53", "anchor_text": "Deep Learning Tips and Tricks"}, {"url": "https://medium.com/@CVxTz?source=post_page-----b0a4fce8f6c----------------------", "anchor_text": "Youness Mansar"}, {"url": "https://medium.com/@CVxTz/audio-classification-a-convolutional-neural-network-approach-b0a4fce8f6c", "anchor_text": "Audio Classification : A Convolutional Neural Network Approach"}, {"url": "https://www.analyticsvidhya.com/blog/author/jalfaizy/", "anchor_text": "Faizan Shaik"}, {"url": "https://www.analyticsvidhya.com/blog/2017/08/audio-voice-processing-deep-learning/", "anchor_text": "Getting Started with Audio Data Analysis using Deep Learning (with case study)"}, {"url": "https://medium.com/@mikesmales?source=post_page-----8bc2aa1990b7----------------------", "anchor_text": "Mike Smales"}, {"url": "https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7", "anchor_text": "Sound Classification using Deep Learning"}, {"url": "http://aqibsaeed.github.io/", "anchor_text": "Aaqib Saeed"}, {"url": "http://aqibsaeed.github.io/2016-09-03-urban-sound-classification-part-1/", "anchor_text": "Urban Sound Classification, Part 1"}, {"url": "https://upcommons.upc.edu/bitstream/handle/2117/86673/113166.pdf", "anchor_text": "Voice gender identification using deep neural networks running on FPGA"}, {"url": "https://www.endpoint.com/team/kamil_ciemniewski", "anchor_text": "Kamil Ciemniewski"}, {"url": "https://www.endpoint.com/blog/2019/01/08/speech-recognition-with-tensorflow", "anchor_text": "Speech Recognition from scratch using Dilated Convolutions and CTC in TensorFlow"}, {"url": "https://towardsdatascience.com/@admond1994?source=post_page-----81d0fe3cea9a----------------------", "anchor_text": "Admond Lee"}, {"url": "https://towardsdatascience.com/how-to-build-a-speech-recognition-bot-with-python-81d0fe3cea9a", "anchor_text": "How To Build A Speech Recognition Bot With Python"}, {"url": "https://medium.com/@adrianitsaxu?source=post_page-----486e92785df4----------------------", "anchor_text": "Adrian Yijie Xu"}, {"url": "https://medium.com/gradientcrescent/urban-sound-classification-using-convolutional-neural-networks-with-keras-theory-and-486e92785df4", "anchor_text": "Urban Sound Classification using Convolutional Neural Networks with Keras: Theory and Implementation"}, {"url": "https://github.com/sainathadapa/kaggle-freesound-audio-tagging", "anchor_text": "aggle freesound audio tagging"}, {"url": "https://librosa.github.io/librosa/0.6.0/feature.html", "anchor_text": "Librosa Feature Extraction"}, {"url": "https://librosa.github.io/librosa/generated/librosa.display.specshow.html", "anchor_text": "Librosa Display Specshow"}, {"url": "https://keras.io/preprocessing/image/", "anchor_text": "Keras Image Preprocessing"}, {"url": "https://keras.io/models/sequential/", "anchor_text": "Keras Sequential Model Methods"}, {"url": "https://medium.com/tag/python?source=post_page-----ff90f94358ec---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----ff90f94358ec---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/voice-recognition?source=post_page-----ff90f94358ec---------------voice_recognition-----------------", "anchor_text": "Voice Recognition"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ff90f94358ec---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fff90f94358ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&user=Jurgen+Arias&userId=5f9078a89846&source=-----ff90f94358ec---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fff90f94358ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&user=Jurgen+Arias&userId=5f9078a89846&source=-----ff90f94358ec---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fff90f94358ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fff90f94358ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ff90f94358ec---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ff90f94358ec--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ff90f94358ec--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ff90f94358ec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jurgenarias?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jurgenarias?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jurgen Arias"}, {"url": "https://medium.com/@jurgenarias/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "89 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5f9078a89846&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&user=Jurgen+Arias&userId=5f9078a89846&source=post_page-5f9078a89846--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6f3f53dcac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvoice-classification-with-neural-networks-ff90f94358ec&newsletterV3=5f9078a89846&newsletterV3Id=6f3f53dcac&user=Jurgen+Arias&userId=5f9078a89846&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}