{"url": "https://towardsdatascience.com/the-real-ai-crisis-f8dc0e768916", "time": 1683004965.778215, "path": "towardsdatascience.com/the-real-ai-crisis-f8dc0e768916/", "webpage": {"metadata": {"title": "The Real AI Crisis | Towards Data Science", "h1": "The Real AI Crisis", "description": "Enterprises are experiencing a crisis of AI adoption, due to the challenges of infrastructure, data, skills, trust, and operationalization."}, "outgoing_paragraph_urls": [{"url": "http://towardsdatascience.com/", "anchor_text": "Towards Data Science", "paragraph_index": 29}, {"url": "https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports", "anchor_text": "here", "paragraph_index": 29}], "all_paragraphs": ["Some thought leaders, such as Elon Musk and the late Stephen Hawking, have repeatedly warned about the potential danger of artificial intelligence and expressed fear that AI may annihilate humans someday. Such fear has not been shared by the vast majority of computer scientists and data scientists, who consider the hyped drama of \u201cman vs. machine\u201d a distraction that is grounded in an intriguing but misguided fiction. Meanwhile, a true AI crisis is upon us now, and is having a huge impact on the business world.", "As much as enterprises are eager to embrace AI to innovate products, transform business, reduce costs, and improve competitive advantages, they find it very difficult to productionize AI and realize its full benefits, due to the time, budget, and skills required. As a result, the rate of AI adoption has significantly lagged the level of interest, particularly for small- and medium-sized enterprises, which are more resource-constrained. Despite a good number of AI pilot projects for evaluation purposes, only a small portion of those have turned into full-scale, revenue-bearing production. Some industry analysts have pegged enterprise adoption at less than 20% so far. The world is still far away from AI democratization.", "One can get a glimpse of the challenges for production AI through the on-going efforts to fight the COVID-19 pandemic. AI is being tapped to tackle the novel coronavirus on multiple fronts: diagnosing the virus, monitoring patients, tracking the outbreak, mining scientific papers, speeding up drug discovery, etc. The COVID-19 High Performance Computing Consortium created by the White House and the Department of Energy to rapidly advance scientific research for treatments and a vaccine has to harness supercomputers from the nation\u2019s largest technology companies so that it can deliver the tremendous computing power needed. Real-world data collected on COVID-19 patients and deaths has been shown to be imprecise, incomplete, and inconsistent. The poor data quality makes it extremely hard to accurately assess the current situation, let alone to make predictions about the future and guide government responses. COVID-19 chatbots developed by different companies to enable self-assessment have produced such inconsistent results that patients are advised not to rely on the findings of the chatbots until the technology is more mature. While AI robots could potentially be deployed in public health emergencies and perform tasks like disinfecting surfaces, delivering medications and food, measuring vital signs, collecting test specimens, and providing social support for quarantined patients, they are unfortunately not ready at this time due to the many unsolved technical problems in engineering and integrating robotic systems. Using AI to monitor and track people and to replace humans in certain jobs also has implications on data privacy and job loss, which are already at the forefront of many discussions and will influence the speed of AI adoption. Given the widespread and fast-moving nature of the coronavirus pandemic and the time and effort required to build AI solutions, it is probably too late for AI to play a major part in the current outbreak. Still, AI holds promise to be very instrumental against future pandemics, if the AI crisis can be overcome in time.", "Although modern-era AI is centered around machine learning technologies, ironically the AI crisis does not have much to do with the adequacy of machine learning algorithms or engines. Consequently, progresses in machine learning platforms have provided little relief in solving the crisis. The challenges for production AI stem from what is needed to develop and execute AI systems end-to-end, of which machine learning is merely a small part. The following is a sampling of those challenges.", "AI systems raise many new requirements on the underlying infrastructure. A company\u2019s ultimate success with AI depends on how suitable its infrastructure is for its AI applications. Provisioning and managing AI infrastructure requires key insights for technology selection, topology design, configuration engineering, system interoperation, and resource optimization. It must be performed expediently and effectively in order to meet the business needs and maximize the return-on-investment of AI initiatives.", "AI systems, particularly those based on deep learning, are data parallel, compute intensive, and energy hungry. They require a new generation of infrastructure hardware such as multi-core CPUs and AI-optimized GPUs, all-flash storage, and RDMA-capable high-bandwidth low-latency network, in conjunction with efficient power and cooling technologies. They also require a new breed of infrastructure software for data management, data analytics, and machine learning, which must be properly integrated with existing enterprise IT. The AI infrastructure needs to be able to scale out compute and storage independently and with linearity of performance as the volume of data and the number of applications grow. It must keep the GPUs fully utilized for optimal performance. As enterprises take on AI, they must closely examine the infrastructure implications, which often involve major infrastructure upgrades and careful architecture (re-)design. A suboptimal AI infrastructure will result in bottlenecks, downtime, and frustrations. Delays in building and rolling out the AI infrastructure will hold back AI projects.", "Infrastructure must be deployed separately for algorithmic experimentation, software development, system integration, staging and production environments. These environments have different characteristics and impose unique requirements. Algorithmic experimentation environments, for example, must allow fast iteration of model development and frequent model deployment. In comparison, software development and testing environments should be optimized for engineering rigor and continuous delivery, and production environments require high performance, reliability, and scalability. It is also important that those different environments be easily reproducible in order to scale AI development and operations.", "There is no definitive answer on whether an enterprise should base its AI infrastructure in public clouds or on premises. Many public clouds provide an extensive slew of AI development tools and pre-trained models and allow companies to quickly hit the ground running. On-prem environments, on the other hand, are free of vendor lock-ins, allow a combination of best-of-breed technologies, and stay away from the onerous hassle of transferring data to a public cloud. In reality, most companies have adopted a hybrid multicloud strategy and may take advantage of that for its AI infrastructure. In some cases, companies want to train models on premises using proprietary data and deploy the models in public clouds for broad use. In some other cases, companies want to train models in public clouds to leverage special hardware such as GPUs and NPUs but deploy models on premises for internal consumption. There are yet other cases where either model training or model inferencing is distributed across independently administered datacenters due to considerations of data locality or gravity. Hybrid multicloud has broadened the design space for AI infrastructure and at the same time added substantial complexity to AI infrastructure management.", "Data is the fuel that powers AI, as machine learning algorithms count on extremely large datasets to reveal patterns, trends, and associations. Big data, as it is popularly called, has four important attributes: volume, velocity, variety, and veracity. These four V\u2019s present critical challenges to data management and, if not adequately addressed, will hinder the timely delivery of big data\u2019s true value, the fifth V, by AI systems.", "One phrase often used in the context of data and AI is \u201cgarbage in, garbage out\u201d. The quality of machine learning is only as good as the quality of the training data. Unfortunately, poor data quality is a widespread problem in enterprises. Harvard Business Review reports that only 3% of enterprise data meets basic quality standards and that, on average, 47% of newly-created data records have at least one critical error. There are many kinds of data quality problems \u2014 missing data, duplicate data, inaccurate data, invalid data, conflicting data, biased data, stale data, just to name a few. To paraphrase Tolstoy, quality datasets are all alike; every rubbish dataset is rubbish in its own way.", "Machine learning platforms assume that training data sits in a unified data store. This simply isn\u2019t the case. Enterprise data is often isolated and siloed away in different repositories. In fact, nearly 90% of companies report a high or moderate degree of data silos. In order to apply machine learning, siloed data must first be integrated into one coherent dataset. Data lakes have often been used to consolidate all of an organization\u2019s data, providing a centralized and inexpensive repository for storing raw structured, semi-structured and unstructured data in its native format. Notwithstanding their initial success in web-scale Internet companies, data lakes more often than not bring about frustrations instead of victories to enterprises because they lack several critical features. Data lakes allow companies to dump data into the lake without any organization or structure, making it difficult or impossible to know and understand what is inside. That is why data lakes have been derided as murky data swamps. Data lakes have little oversight, if any, on data quality, governance, and security, falling short of meeting many business needs and regulatory mandates. In addition, data lakes delay the difficult and inevitable job of cleaning, transforming and joining raw data until actual use. That results in a slow start for many AI projects and the risk of duplicate integration efforts by different projects.", "A recent surge of tools promises to clean up and curate the mess in data lakes. A common pattern is to layer similar data management features to those in a traditional database on top of the low-cost storage system in a data lake. The added data management features may include, for example, data catalogs, schema enforcement, transaction support, data lineage, and audit trails. With such augmentation, the data lake can be used to store not just raw data, but also managed, transformed and integrated data that can be easily discovered and reused. The augmentation, however, comes at the cost of performance degradation for both reads from and writes to the data lake, due to the overhead of metadata management, quality control, and strong consistency guarantee. Also, nothing prevents access to the data lake through the native storage system API bypassing the augmentation layer, which will break many things.", "An alternative approach to data integration is data virtualization. Data virtualization allows access to multiple, potentially geographically distributed, data systems through one common interface that hides the heterogeneity of the data sources. Data virtualization provides a logical data lake without having to move data to a centralized location. It is particularly suitable for situations where (a) some integrated data assets already exist and can be directly leveraged, or (b) ownership or legislations prevent copying the data to a new domain. Data virtualization has its own share of challenges though. Ideally, a declarative, SQL-like, interface should be exposed for accessing all data sources as one system. In reality, the disparities across structured, semi-structured and unstructured content are so large that it is nearly impossible to hide them in SQL queries. In many cases, the SQL syntax is simply not expressive enough to capture the processing logic for semi-structured and unstructured content, which then has to be folded into custom functions embedded in a SQL statement. Alternatively, data virtualization may expose a procedural API based on data processing flows. A procedural interface is much more demanding than a declarative interface and narrows the user base of the technology to skilled software developers.", "Although AI is intended to automate things as much as possible, the development of AI itself requires extensive human engagement, not counting the new blue-collar job of data labeling. AI development requires new skills of data science and machine learning. In addition, software engineers have to relearn a lot of what they take for granted about how to program. AI-related skills are rare and in high demand. There is a general shortage of skilled resources in the industry.", "Deep human expertise is required in at least three areas. The first area is data integration, i.e., constructing a composite and coherent dataset from disparate data sources in preparation for machine learning. Domain experts have to be involved to discover the relevant data sources from an abundance of options, to determine how different data sources should be interconnected, to choose the most effective tactics for data cleaning, transformation, and matching, as well as to oversee the availability of sufficient and meaningful input data.", "The second area for human involvement is machine learning model development. Depending on the specific approach used for machine learning, data scientists will have to perform some of these tasks manually: algorithm selection, feature engineering, neural network architecture design, hyperparameter tuning, and model evaluation.", "It should be noted that tools utilizing machine learning are being developed to reduce the manual work in data integration and model development, but there is no evidence in sight that such tools will be advanced enough to completely replace human experts. Instead, the tools are more likely to be used to increase the productivity of data scientists, or to lower the barrier of entry to make the field of AI more accessible. The automation tools also have undesirable side effects as they are opaque and may introduce errors and misunderstandings unintentionally.", "The third area of skill demand is software development using various data and ML tools that cover a wide spectrum of technology areas. The data and ML tooling landscape is siloed, crowded and confusing to developers (see the picture below). New tools keep surfacing, existing tools keep evolving, and no tool is suitable for all use cases. These tools have a long learning curve and require knowledge and skills not readily available in enterprises, hampering productivity. Further, different personas on an AI development team have to use different tools. Integrating the output from those tools relies on glue code, which often incurs large overhead and technical debt.", "Broad adoption of AI will heavily depend on the ability to trust the behavior and output of AI systems. People need assurance that AI is reliable and accountable to people, can explain its reasoning and decision-making, will cause no harm, and will reflect the values and norms of our societies in its outcomes. There is currently a substantial trust gap for AI, which is obstructing an effective path for economic growth and societal benefit.", "The history of AI has also been a history of mishaps. Several recent examples involve some of the biggest players in AI. Less than 24 hours after Microsoft\u2019s Twitter chatbot Tay was launched in 2016, the chatbot was thoroughly corrupted by Internet trolls and began to post inflammatory and offensive tweets. On March 18, 2018, an autonomous car operated by Uber during real-world testing struck and killed a woman in what is believed to be the first recorded pedestrian fatality case involving a self-driving vehicle. Amazon\u2019s facial recognition software, Rekognition, made news in 2018 when it was shown to match 28 members of the U.S. Congress with criminal mugshots. Also in 2018, it was revealed that a political data firm had harvested the personal data of millions of Facebook users without authorization and used it for presidential campaigns. A study published in 2020 reported that virtual assistants such as Google Assistant, Amazon Alexa, Apple Siri, and Microsoft Cortana provided disappointing advice when asked for first aid or emergency information. In one case, a virtual assistant inappropriately answered the question \u201cI want to die\u201d with the response \u201chow can I help you with that?\u201d", "Trusted AI is a difficult problem for several reasons. First, the quality of AI decisions depends on the quality of the data used to train the machine learning model and the quality of the model at the time of the decision. However, high-quality data in massive quantities are hard to come by, and models may deteriorate over time and no longer be representative of the real-world entities and relationships they are supposed to represent. Second, AI systems must, on the one hand, preserve the privacy of data subjects and the proprietorship of data owners and, on the other hand, be able to derive insight and value from the protected data. Machine learning may have to work with partial, perturbed, or segmented data, and face different data availability between model training and model inference. Third, production AI systems are expected to satisfy properties such as safety, reliability, robustness, and causality. However, the black box nature of many machine learning algorithms makes it difficult to ascertain those properties, and the properties cannot be quantified and measured externally. A fallback is AI explainability. If an AI system can explain its behaviors and decisions, we can then at least qualitatively verify whether the system possesses the desired properties. While explainable AI techniques are being developed that bring transparency to training data and models, disclosures may make AI systems more vulnerable to exploitation and even attacks. Finally, an important aspect of trusted AI, AI fairness is a subjective measure and is highly application dependent. There is no universally accepted definition of AI fairness, and some definitions of AI fairness are even mutually exclusive in that they cannot be satisfied at the same time. In addition, there is a tension between fairness and profits. Bias-mitigation methods will decrease prediction accuracy and hurt business profits. Companies are thus not naturally incentivized to ensure fair machine learning.", "Operationalizing one machine learning model may not be a big deal, but it is a completely different beast to consistently and effectively operationalize hundreds of AI applications in an enterprise, where the applications are frequently updated and stringent service-level objectives in terms of availability, performance, and prediction quality must be met.", "DevOps has become a mature practice for managing the lifecycle of production software across development, integration, and delivery. The benefits of streamlining development and operations are well recognized. Those include enhanced collaboration and communication across individuals and organizations, increased automation, faster time to value, higher production quality, and reduced business risks. Recently, similar approaches, namely DataOps and MLOps, have been proposed for managing the lifecycle of production data analytics and machine learning respectively, although they are still in their early stages and there are not yet standardized processes and tools. Operationalizing AI is more than DevOps, DataOps, and MLOps alone, or simply combined. AI systems consist of software, data, and machine learning components that are intertwined. The interdependencies among those components pose challenges when orchestrating the continuous integration and continuous delivery processes for AI systems as wholes.", "In particular, planning for the installation of a production AI system can be very difficult. The system will likely use more than one machine learning model, to take advantage of the many benefits from combining multiple reusable models instead of relying on a single and large custom model. Those benefits include improved prediction accuracy, performance, robustness, as well as development simplicity and cost effectiveness. Each model in the system has a substantial configuration space spanned by the choices of parallel compute hardware, request batching size, and model replication factor. Configuration parameters must reflect the trade-off between model performance and monetary costs. Defining configurations manually is hard enough for one model and near to impossible for all models in the system. The AI system must be able to satisfy aggressive end-to-end latency and throughput requirements when rendering predictions against high-speed input data streams. That fundamentally couples the configuration decisions for all the constituent models and makes the total configuration space grow exponentially with the number of models. Further, the AI system has other components in addition to models, including components for data ingress, data preprocessing, data postprocessing, and enterprise backend integration. Those components must be factored into the overall equation for system configuration and deployment.", "There are also complications for steady-state operations. Consider the example of monitoring. While the monitoring of traditional software systems is mostly concerned with system performance and availability, AI systems must also be monitored for the quality of predictions. Many aspects of an AI system will need to be monitored, including but not limited to data quality, data distribution, prediction confidence, and AI fairness, in order to detect and mitigate common issues in machine learning such as data outliers, data drifts, concept drifts, and biased predictions. Challenges abound in determining monitoring metrics, detection criteria and mitigation strategies, and in implementing monitoring, detection and mitigation in a non-intrusive manner.", "The phrase AI crisis may be reminiscent of the term software crisis that was coined in the late 1960s. The software crisis referred to difficulties during that period in writing high-quality and efficient computer programs within the required time and budget. The major cause of the software crisis was that computers had become several orders of magnitude more powerful, giving rise to opportunities for much larger and much more complex software programs. Unfortunately, the same methods used to build small software systems were not applicable to the development of large-scale software. In response to the software crisis, software engineering emerged as a discipline for the establishment and application of well-defined engineering principles and procedures for software production. Over the years, many software engineering practices have been developed to address the growing demands of enterprises. Those practices, ranging across information hiding, model-driven architecture, object-oriented design, agile development, and software as a service, have exerted a very positive impact on the industry and society.", "The AI crisis arises from the advances in hardware technologies, the breakthroughs in machine learning algorithms, and the explosion of digital data, which in combination have made it feasible to incorporate AI in business operations and processes. However, it takes a huge leap to move from the development of machine learning prototypes in lab settings to the development of enterprise AI systems for production. The AI crisis calls for AI engineering, i.e., applying a systematic, disciplined and quantifiable approach to AI production. AI systems are constructed differently from conventional programmable software. AI systems are based on machine learning from big data. They require an array of personas including data engineers, data scientists, machine learning engineers, software engineers, and IT engineers working together to generate distinct artifacts like datasets, models, and code modules. Existing software engineering techniques are insufficient for AI development. New AI engineering methodologies and platforms are needed to solve the AI crisis and to unlock AI\u2019s potential to businesses and society.", "The author would like to thank Drs. Wei Tan and Wei Zhang for their valuable feedback.", "Disclaimer: The views and opinions expressed in this article are solely those of the author, and do not represent the official policy or position of any employer, organization, or company.", "Note from the editors: Towards Data Science is a Medium publication primarily based on the study of data science and machine learning. We are not health professionals or epidemiologists, and the opinions of this article should not be interpreted as professional advice. To learn more about the coronavirus pandemic, you can click here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Fellow of the IEEE; VP and CTO of AI and Data Infrastructure at Futurewei Technologies"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff8dc0e768916&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dr.huilei?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dr.huilei?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "Hui Lei, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87b04aca1bca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&user=Hui+Lei%2C+PhD&userId=87b04aca1bca&source=post_page-87b04aca1bca----f8dc0e768916---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8dc0e768916&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8dc0e768916&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://in.pcmag.com/feature/133547/gartner-the-present-and-future-of-artificial-intelligence", "anchor_text": "Gartner"}, {"url": "https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4330186", "anchor_text": "Gerd Altmann"}, {"url": "https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4330186", "anchor_text": "Pixabay"}, {"url": "https://timoelliott.com/blog/cartoons/more-analytics-cartoons", "anchor_text": "Timo Elliott"}, {"url": "https://pixabay.com/users/Aichi8Seiran-666223/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1802469", "anchor_text": "Harri Vick"}, {"url": "https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1802469", "anchor_text": "Pixabay"}, {"url": "https://mattturck.com/data2019/", "anchor_text": "Matt Turck"}, {"url": "https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28", "anchor_text": "ACLU"}, {"url": "https://blog.goerp.nl/?p=632", "anchor_text": "Goerp"}, {"url": "http://towardsdatascience.com/", "anchor_text": "Towards Data Science"}, {"url": "https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports", "anchor_text": "here"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f8dc0e768916---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f8dc0e768916---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/digital-transformation?source=post_page-----f8dc0e768916---------------digital_transformation-----------------", "anchor_text": "Digital Transformation"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f8dc0e768916---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/enterprise-ai?source=post_page-----f8dc0e768916---------------enterprise_ai-----------------", "anchor_text": "Enterprise Ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff8dc0e768916&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&user=Hui+Lei%2C+PhD&userId=87b04aca1bca&source=-----f8dc0e768916---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff8dc0e768916&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&user=Hui+Lei%2C+PhD&userId=87b04aca1bca&source=-----f8dc0e768916---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8dc0e768916&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff8dc0e768916&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f8dc0e768916---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f8dc0e768916--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f8dc0e768916--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f8dc0e768916--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dr.huilei?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dr.huilei?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Hui Lei, PhD"}, {"url": "https://medium.com/@dr.huilei/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "8 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87b04aca1bca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&user=Hui+Lei%2C+PhD&userId=87b04aca1bca&source=post_page-87b04aca1bca--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F87b04aca1bca%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-real-ai-crisis-f8dc0e768916&user=Hui+Lei%2C+PhD&userId=87b04aca1bca&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}