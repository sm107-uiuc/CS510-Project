{"url": "https://towardsdatascience.com/logistic-regression-the-basics-b1716661c71b", "time": 1683002855.967329, "path": "towardsdatascience.com/logistic-regression-the-basics-b1716661c71b/", "webpage": {"metadata": {"title": "Logistic regression: the basics. Understanding the foundations of\u2026 | by Arthur Mello | Towards Data Science", "h1": "Logistic regression: the basics", "description": "Logistic regression is a technique for modelling the probability of an event. Just like linear regression, it helps you understand the relationship between one or more variables and a target\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/linear-regression-the-basics-4daad1aeb845", "anchor_text": "linear regression", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "maximum likelihood method", "paragraph_index": 3}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "Titanic dataset", "paragraph_index": 5}, {"url": "https://github.com/arthurmello/statistics/tree/master/2.%20Logistic%20regression", "anchor_text": "here", "paragraph_index": 29}], "all_paragraphs": ["Logistic regression is a technique for modelling the probability of an event. Just like linear regression, it helps you understand the relationship between one or more variables and a target variable, except that, in this case, our target variable is binary: its value is either 0 or 1. For example, it can allow us to say that \u201csmoking can increase your risk of having lung cancer by 20%\u201d, since having lung cancer is a binary variable: you either have it or not (hopefully not). From that, we can infer answers to classification problems. For example, it can help us make an educated guess of whether someone will have lung cancer given that he/she does not smoke, lives in a polluted city and has a family history of lung cancer.", "With that said, the structure of a logistic regression is also similar to that of a linear regression model: you have a set of explanatory variables (X1, X2\u2026) and our target binary variable (Y). The function behind it, however, is a bit more complicated:", "P(Y=1) represents the probability of your Y being equal to 1, while b0 is a parameter not linked to X and B is a vector of coefficients that represent the relationship between Y and each one of X1, X2 and so on.", "The logistic regression will then estimate the values for the b parameters that better fit your data, usually using the maximum likelihood method. Once we have those estimators, we can calculate P(Y=1) for new data points and either stick with that probability or use it to classify those observations based on a threshold (ex.: if the probability of someone having lung cancer is greater than 50%, we can make an educated guess that they will have it).", "To better understand the difference between a linear and a logistic regression, imagine we plotted the lung cancer variable in the Y-axis (Y = 1 if patient has lung cancer and 0 otherwise) and the patient\u2019s age in the X-axis. Below we have the resulting lines from each regression. Which one seems more fit to our data?", "One of the most famous datasets for working with classification problems is the Titanic dataset, where we have the list of the Titanic passengers, some of their characteristics, such as age, sex and name, and whether they have survived the disaster or not (for some reason, many classification problems tend to be related to bad things such as lung cancer and dying in a disaster). We\u2019ll be working in R, but you can do the same thing in Python if you want.", "Let\u2019s first take a look at the available variables:", "So, besides the Id, we have some possibly useful information about them, such as their class in the ship (1st, 2nd or 3rd) and their sex.", "Before we start modelling, we have to clean our data. Keep in mind, however, that the goal of this article is to introduce logistic regressions, not data cleaning, so we are not going too deep in here.", "We have to first replace missing ages by the median of the ages. Then, we turned the passenger class feature into a factor: this means that, instead of reading it as integers, R will read it as a category, which makes more sense in this case.", "Next step is to split our dataset into train and test, so we can build our model and then calculate some accuracy metrics in another dataset, that has not been used by our model. We have chosen an arbitrary size for the training set, but it usually is something around 70% and 80% of the original dataset.", "For our first model, let\u2019s choose variables that we intuitively believe could have some link with the probability of surviving the Titanic disaster. Personally, I would guess that the passenger\u2019s class, age and sex can help us predict if they survived or not:", "Wow, that\u2019s a lot of information at once, right? But let\u2019s focus on the basics for now, starting by how we build our model:", "We started by calling out a function called glm, that is used for fitting generalised linear models. To make it work specifically as a logistic regression, we set family = binomial and link = \u2018logit\u2019. For our problem, we could also have set link to \u2018probit\u2019 or \u2018cochit\u2019, but we\u2019ll stick to the logit function. The difference between them is mainly theoretical and their results are usually fairly similar.", "Now, moving on to the coefficients, we can see that all of them are negative (look at the Estimate column), meaning that all these variables are negatively correlated with the probability of survival. That is: being a man or being in classes 2 or 3 (instead of being a woman or in class 1) made you less likely to survive the Titanic disaster. The age coefficient is also negative, so, the older you were the less likely you were to survive. To interpret the precise values of the coefficients, let\u2019s go back to our probability function:", "Here the Intercept coefficient is the b0 and the other coefficients are the vector B. Our model would look like this (I have rounded the coefficients for better readability):", "Where Pclass2 = 1 if the passenger was in class 2 and 0 otherwise (similarly for the other variables, except for Age, which is equal to the passenger\u2019s actual age). In addition to being part of our probability equation, they also help us interpret the odds: the coefficient of -2.6 for Sexmale means that the odds of surviving when you are a man are exp(-2.6) = 0.07 times the odds of surviving when you are a woman.", "The other important column in that table is Pr(>|z|), which we call p-value. It shows us how confident we are that the estimated coefficient is significant (the closer it is to zero, the more confident we are). If we had some coefficients with high p-values, we should probably not include the related variables in our model.", "Finally, the last item we\u2019ll talk about is the Akaike Information Criterion (AIC), shown at the end of the model summary. In simple terms, the AIC is an estimation of what our error would be if we applied our model to a test sample, and it helps us compare models (the smaller the AIC, the better).", "Now, let\u2019s try a second model, adding the Fare variable (how much the passenger paid for the ticket):", "Notice how the p-value for Fare is high, meaning that it is not a significant variable, and that the AIC has increased, meaning a slightly worse model. One possibility is that, since we already consider the passenger\u2019s class, the ticket fare doesn\u2019t add much new information. To test this, let\u2019s run a third model, with the fare but removing Pclass:", "This time, our AIC is dramatically worse and Fare has a significant coefficient but Age is no longer significant. Any idea why that is? Comment your hypothesis here :)", "Let\u2019s now apply our first model, which performed better than the following two, to the test sample to see how it goes:", "We started by applying our model to the test set, and stating that the passenger survived if the calculated probability is greater than 0.5. The first metric we calculated was accuracy, which represents our ratio of right predictions. An accuracy of 0.82 means that we got our predictions right 82% of the time. Not bad, right? Well, it depends. Imagine that 99% of the passengers had died. We could then predict that all passengers died, and our accuracy would be of 99% without needing a model for that. Therefore, we should somehow take into account the ratio of survivors in our metrics. That\u2019s where the ROC curve and the AUC come in.", "ROC stands for Receiver Operating Characteristic, and it\u2019s a plot of the True Positive Rate (probability of predicting 1 when the actual value is 1), against the False Positive Rate (probability of predicting 1 when the actual value is 0). When we plot that curve and calculate the area underneath it, we get the AUC, that stands for Area Under the Curve. That area is always between 0.5 and 1, which gives us a good scale to measure our model performance taking into account the sample distribution of 1's and 0's.", "To perform these calculations in R, we need the ROCR package:", "The bigger the area underneath the curve, the better our model, so we want a curve that goes as close as possible to the top-left corner of the plot. Note in our code how we created it using the performance() function and used \u201cfpr\u201d for x.measure and \u201ctpr\u201d for measure. FPR stands for False Positive Rate and TPR for True Positive Rate. To calculate the AUC, we use the performance() function again, but we input \u201cauc\u201d as measure this time:", "We have an AUC of 0.86, which is quite good for a classification problem.", "Logistic models are used for classification problems, and one of their advantages when compared to more complex alternatives is their interpretability: their results are easy to translate to layman\u2019s terms. We have seen how to run a logistic regression in R, understand its results, how to compare different models and evaluate their performance. As the title suggests, this is an introductory article, and I encourage you to dig deeper in all the possibilities that arise from it. You can start by trying to improve this model, by setting a different link for the glm() function or adding/removing variables. Maybe there\u2019s an automated way of doing it, like for linear regressions?", "You can access the full R script here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist and educator. I write about data analysis and machine learning applied to marketing."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb1716661c71b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b1716661c71b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b1716661c71b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@arthurmello_?source=post_page-----b1716661c71b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=post_page-----b1716661c71b--------------------------------", "anchor_text": "Arthur Mello"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9d32d5e0ac40&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&user=Arthur+Mello&userId=9d32d5e0ac40&source=post_page-9d32d5e0ac40----b1716661c71b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1716661c71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1716661c71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@hypn0fiddl3r?utm_source=medium&utm_medium=referral", "anchor_text": "Nick Hawkes"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/linear-regression-the-basics-4daad1aeb845", "anchor_text": "linear regression"}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "maximum likelihood method"}, {"url": "https://bit.ly/35MhQwg", "anchor_text": "https://bit.ly/35MhQwg"}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "Titanic dataset"}, {"url": "https://github.com/arthurmello/statistics/tree/master/2.%20Logistic%20regression", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b1716661c71b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----b1716661c71b---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/classification?source=post_page-----b1716661c71b---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b1716661c71b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/titanic?source=post_page-----b1716661c71b---------------titanic-----------------", "anchor_text": "Titanic"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb1716661c71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----b1716661c71b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb1716661c71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----b1716661c71b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1716661c71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b1716661c71b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb1716661c71b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b1716661c71b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b1716661c71b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b1716661c71b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b1716661c71b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b1716661c71b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b1716661c71b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b1716661c71b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b1716661c71b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b1716661c71b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Arthur Mello"}, {"url": "https://medium.com/@arthurmello_/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9d32d5e0ac40&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&user=Arthur+Mello&userId=9d32d5e0ac40&source=post_page-9d32d5e0ac40--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1fb0cddb25fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-the-basics-b1716661c71b&newsletterV3=9d32d5e0ac40&newsletterV3Id=1fb0cddb25fe&user=Arthur+Mello&userId=9d32d5e0ac40&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}