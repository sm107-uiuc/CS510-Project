{"url": "https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4", "time": 1683006008.7940102, "path": "towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4/", "webpage": {"metadata": {"title": "Recommender systems using LinUCB: A contextual multi-armed bandit approach | by Yogesh Narang | Towards Data Science", "h1": "Recommender systems using LinUCB: A contextual multi-armed bandit approach", "description": "A multi-armed bandit problem, in its essence, is just a repeated trial wherein the user has a fixed number of options (called arms) and receives a reward on the basis of the option he chooses. Say, a\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["A multi-armed bandit problem, in its essence, is just a repeated trial wherein the user has a fixed number of options (called arms) and receives a reward on the basis of the option he chooses. Say, a business owner has 10 advertisements for a particular product and has to show one of the advertisements on a website. The reward is translated by observing whether the advertisement was lucrative enough for the user to click on it and get redirected to the product website.", "The business owner runs an algorithm for the first 1000 users to decide the best advertisement out of the 10 available advertisements and after his trial run ends, decides to display the best advertisement to the rest of the users. The algorithm evaluates the best advertisement on the basis of the performance of the advertisements in the trial run (First 1000 users)", "Here\u2019s where we start thinking. Is a SINGLE advertisement really good enough to satisfy a vast and diverse audience?", "This is where contextual bandits come in. If we knew enough about the user, we could predict with much more accuracy the advertisement that would be best suited towards the user and this is what contextual MAB algorithms do. The advertisement(arm) is selected based on the features of the user (called context). Before we move on to analysing one of such algorithms, there\u2019s something we need to ponder upon.", "The dilemma of choosing between exploration and exploitation exists in various aspects of life.", "Say, you go to the ice-cream parlour around the corner and you get your favourite flavour \u2014 chocolate. You don\u2019t try other flavours because you\u2019re afraid you might not like them. But, there\u2019s also a small probability that if you try a new flavour, say red velvet, you might end up liking it even more than chocolate. It\u2019s important to strike the balance between trying out new flavours (exploration) and always getting your favourite (exploitation).", "MAB algorithms have to find the exact trade-off between choosing a random arm (which might end up being the optimal arm) or exploiting its history to choose what it thinks is the best arm (which might just be a sub-optimal arm because the optimal arm may not have been explored enough yet)", "Online recommender systems try to use such algorithms to display content that they think the user will prefer based on a record of the user\u2019s activity on the website.", "One such algorithm that we will later build on is called the upper confidence bound algorithm.", "A very naive greedy approach to solving the multi-armed bandit problem would be selecting the arm that has given us the maximum mean reward with ties being broken arbitrarily. Though this approach tries to select the best possible arm, the algorithm loses and scope for exploration and might select a sub-optimal arm in the long run because there can be arms which have not been tried enough but are potentially optimal the choice.", "The UCB algorithm goes beyond this approach and finds the balance between exploration and exploitation. Here\u2019s how it works.", "The UCB algorithm keeps a track of the mean reward for each arm up to the present trial and also calculates the upper confidence bound for each arm. The upper bound indicates the uncertainty in our evaluation of the potential of the arm.", "The algorithm is highly unsure of an arm\u2019s potential if it has a very high upper confidence bound and hence chooses the arm because of a great exploration opportunity.", "Consider a running UCB algorithm with its present confidence bounds (dotted outlines) as shown in the figure below.", "Even though the recorded mean award achieved for Arm 3 is higher, the algorithm selects arm 2 because of the uncertainty of its potential and updates its confidence bound for future trials.", "The UCB algorithm does not take into account user and content features (context) that may include the user\u2019s historical activities at an aggregated level as well as declared demographic information.", "The exploitation/exploration problem for contextual MAB problems is formalised as follows :", "The expected payoff of an arm is assumed to be linear in its d-dimensional feature vector X with some unknown coefficient vector theta.", "This model is called disjoint since the parameters are not shared among different arms. To solve for the coefficient vector theta in the above equation ridge regression is applied to the training data.", "An upper confidence bound has to be calculated for each arm for the algorithm to be able to choose an arm at every trial. The strategy for choosing the arm at every trial t is formalised as :", "The goal of the algorithm is to maximise total reward (total user clicks in the long run)", "The algorithm is formalised by its authors as follows :", "We don\u2019t dwell upon the mathematics of the algorithm but we focus on the results that I achieved by simulating the algorithm on the standard dataset.", "Usually, MAB problems are analysed on the basis of regret that is the difference of the total reward achieved by always selecting the optimal arm and the total reward achieved by the algorithm.", "The below doughnut plot shows a comparison of the maximum reward we can achieve if we choose only one arm ( and treat it as the optimal arm ). The plot indicates that irrespective of the chosen optimal arm, if we don\u2019t show flexibility in our decisions, we can achieve a maximum of 20% of the total reward. This type of comparison isn\u2019t typically possible in real life because we don\u2019t have access to the entire data beforehand, but this helps us realise the fact that we can\u2019t just rely on one optimal arm.", "The LinUCB algorithm does an excellent job of deciding the choice for the arm in every trial and the below plot reflects the same. It compares the maximum possible achievable reward per arm to the reward actually realised per arm. The results indicate that we\u2019re able to exploit each arm up to 90% of its potential.", "Recommender Systems can be directly modelled as a contextual MAB problem where the different options for recommendations are the arms and whether the user likes the recommendation can be translated to the reward and the ultimate goal is to be able to provide personalised recommendations to each user.", "CMAB algorithms are combined with various filtering techniques based on user preferences to achieve an even more personalised recommendation.", "The LinUCB Algorithm enables us to obtain around 90% of the total possible reward which is much higher than other MAB algorithms. Recommender Systems are an extremely important use-case wherein reward usually translates to higher revenue generation which is the ultimate goal of a business.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F35a6f0eb6c4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@yogesh.narang49?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yogesh.narang49?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "Yogesh Narang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fe90c43504e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&user=Yogesh+Narang&userId=5fe90c43504e&source=post_page-5fe90c43504e----35a6f0eb6c4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35a6f0eb6c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35a6f0eb6c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/1003.0146.pdf", "anchor_text": "https://arxiv.org/pdf/1003.0146.pdf"}, {"url": "https://arxiv.org/pdf/1003.0146.pdf", "anchor_text": "https://arxiv.org/pdf/1003.0146.pdf"}, {"url": "https://arxiv.org/pdf/1003.0146.pdf", "anchor_text": "https://arxiv.org/pdf/1003.0146.pdf"}, {"url": "https://arxiv.org/pdf/1003.0146.pdf", "anchor_text": "https://arxiv.org/pdf/1003.0146.pdf"}, {"url": "http://incompleteideas.net/book/the-book-2nd.html", "anchor_text": "http://incompleteideas.net/book/the-book-2nd.html"}, {"url": "https://arxiv.org/pdf/1003.0146.pdf", "anchor_text": "https://arxiv.org/pdf/1003.0146.pdf"}, {"url": "https://medium.com/tag/multi-armed-bandit?source=post_page-----35a6f0eb6c4---------------multi_armed_bandit-----------------", "anchor_text": "Multi Armed Bandit"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----35a6f0eb6c4---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/linucb?source=post_page-----35a6f0eb6c4---------------linucb-----------------", "anchor_text": "Linucb"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----35a6f0eb6c4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/personalisation?source=post_page-----35a6f0eb6c4---------------personalisation-----------------", "anchor_text": "Personalisation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35a6f0eb6c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&user=Yogesh+Narang&userId=5fe90c43504e&source=-----35a6f0eb6c4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35a6f0eb6c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&user=Yogesh+Narang&userId=5fe90c43504e&source=-----35a6f0eb6c4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35a6f0eb6c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F35a6f0eb6c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----35a6f0eb6c4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----35a6f0eb6c4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yogesh.narang49?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yogesh.narang49?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yogesh Narang"}, {"url": "https://medium.com/@yogesh.narang49/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "19 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fe90c43504e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&user=Yogesh+Narang&userId=5fe90c43504e&source=post_page-5fe90c43504e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F5fe90c43504e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4&user=Yogesh+Narang&userId=5fe90c43504e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}