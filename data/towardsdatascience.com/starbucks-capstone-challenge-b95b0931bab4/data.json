{"url": "https://towardsdatascience.com/starbucks-capstone-challenge-b95b0931bab4", "time": 1683007067.543263, "path": "towardsdatascience.com/starbucks-capstone-challenge-b95b0931bab4/", "webpage": {"metadata": {"title": "Starbucks Capstone Challenge. This project is a part of Udacity Data\u2026 | by Laila Sabar | Towards Data Science", "h1": "Starbucks Capstone Challenge", "description": "Starbucks provided simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/LailaSabar/Starbucks-Capstone-Challenge", "anchor_text": "here", "paragraph_index": 65}], "all_paragraphs": ["Starbucks provided simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offers during certain weeks. Not all users receive the same offer, and that is the challenge to solve with this data set.", "The task is to combine transaction, demographic, and offer data to determine which demographic groups respond best to which offer type.", "The data is contained in three files:", "Here is the schema and explanation of each variable in the files:", "The problem that I chose to solve was to build a model that predicts whether a customer will respond to an offer or not.", "Here are the main steps that I followed through the analysis :", "1- Exploring and cleaning the given data sets.", "2- Combining data sets to get a final clean data containing relevant features.", "3- Splitting data into training and test data sets / Scaling features.", "4- Selecting the appropriate performance matrix.", "5- Training the classifier and choosing the best estimator using GridSearch", "6- Calculating features importance given by the best estimator.", "7- Computing performance of the model using test data, and plot a confusion matrix.", "In order to understand the datasets and uncover initial patterns, characteristics, and points of interest, first we need to explore the datasets which include checking the missing value, visualizing the data distribution, etc. In that way, we could see what the data can tell us and how to select the important features to support the model implementation.And also we will do some preprocessing, that step in which the data gets transformed, or Encoded, to bring it to such a state that now the machine can easily parse it.", "The preprocessing of the portfolio are performed as follow :", "All those steps are included in the function below :", "Applying the function to portfolio dataset", "After cleaning the data, it looks like this :", "From the plot above, we can clearly see that customers with age 118 stand out in the distribution plot, which seems outliers. and I checked that for all profiles that have age equal to 118, they do not have any gender and income, also the number of customers with age 118 which is 2175 is unrealistic, For those reasons, I will drop all rows that have an age of 118.", "The preprocessing of the profile are performed as follow :", "All those steps are included in the function below", "Applying the function to the dataset profile", "And here are our new columns of the data set profile", "The plot shows that the feature age after dropping age 118 is uniformly distributed, we see that the age of the majority f our costumers is between 40 and 80 years old.", "The results suggest that most customers joined the Starbucks rewards program in 2017 followed by 2018.", "From the plot above, we see that most customers' incomes are between 30 000 and 90 000.", "The plot depicts that there are more male customers joining the program every year than female customers.", "From the plots above we conclude that minimum and maximum incomes for both males and females are approximately the same but the count of male customers in low-income levels is slightly higher than that of female customers. Also, income distribution for Others is also similar to males and females, with a minimum and maximum incomes less than males and females.", "The preprocessing of the transcript are performed as follow :", "First, we cleaned the dataset transcript using the function below", "Applying the function on the transcript dataset", "Create data frames offers_df containing only offers events and transaction_df containing only transaction event", "And those are our new tables", "It seems that those tables need some cleaning", "These are the final look of produced datasets (offers_df and transaction_df):", "2- Combining data sets to get a final clean data containing relevant features.", "The function below included the code for combining datasets clean_portfolip, clean_profile, offers_df, and transaction_df.", "below are the features of the combined data :", "Creating a data frame named offer_success with features offer_id, count, success_pourcentage, and offer_type, to establish a comparison between offers.", "Plotting 2 bar charts one to illustrate how many customers were provided with a specific offer, and the other shows the success rate of each offer.", "From the results shown above, we notice that the number of offers sent to customers is almost the same.For the percentage of success of an offer, we observe that the offer numbers 10 and 2 are the most successful with rates 75.20% and 72.28%, the lowest is offer number 4 with rate 36.76%.", "After cleaning does features we obtain the columns above :", "The data we use is usually split into training data and test data. The training set contains a known output and the model learns on this data in order to be generalized to other data later on. We have the test dataset in order to test our model\u2019s prediction on this subset.", "Then we proceed with Feature scaling which is a method used to normalize the range of independent variables or features of data using MinMaxScaler.", "Preparing a list of features to scale", "Then the function that will scale the features", "Calculating the percentage of distribution of the target class in the training set", "From the results shown above, we can observe that our training dataset is nearly balanced, it has a nearly equal number of customers who responded to an offer (53.8%) and customers who did not respond to an offer (46.2%). Since, our training dataset is nearly balanced, we do not have to deal with techniques to combat class imbalance.", "We found that our training data is nearly balanced in terms of the distribution of target class, performance metrics like precision, recall, and f1_score are perfect measures for evaluating a model. The F1-score metric is \u201cthe harmonic mean of the precision and recall metrics\u201d and is a better way of providing greater predictive power on the problem and how good the predictive model is making predictions.", "The function below will fit a classifier using k-fold cross-validation and calculates f1-score", "RandomForestClassifier and GradientBoostingClassifier has nearly equal f1_score(approx. 0.92) but RandomForestClassifier take very less time to train than the GradientBoostingClassifier. Therefore, the best performing classifier algorithm among the above 4 classifiers is RandomForestClassifier.", "After tunning we obtain the results below :", "to choose which hyperparameters to adjust we conduct an exhaustive grid search, which takes in many hyperparameters, and tries every single possible combination of the hyperparameters as well as many cross-validations as we like it to perform (here we chose cv=5). An exhaustive grid search is a good way to determine the best hyperparameter values to use, but it can quickly become time-consuming with every additional parameter value and cross-validation that we add.", "The parameters we chose to tune are : min_samples_leaf, min_samples_split, n_estimators, max_depth. Before tuning the values of those parameters were max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10.", "The code shown above took over 20 minutes to run but did choose hyperparameters that had 92.94% accuracy in predicting the training models. The resulting \u201cbest\u201d hyperparameters are as follows: min_samples_leaf = 1, min_samples_split = 2, n_estimators = 100, max_depth=None.", "Carefully and methodically adjusting hyperparameters can be advantageous. It can make our classification model more accurate, which will lead to more accurate predictions overall.", "We notice that after fine-tuning the trained RandomForestClassifier, we get a better f1_score of 0.9294, and before tuning it was 0.9196 so we could observe the progress.", "Preparing a data frame with features and their importance by RandomForestClassifier", "Plotting a bar chart of features with their importance", "From the results shown above, we notice that :", "Top 4 features that influence whether the customer will respond to an offer or not after viewing the offer are:", "the results show that there are 4% percentage misclassifying customer acceptance for an offer and 11% misclassifying customer refusal for an offer. As, False Negatives is less than False positives, our predictive model is doing perfectly as it has very low chances of missing an individual who would respond.", "As Starbucks would not like to miss sending offers to individuals who would respond, this model is suitable for this case, since it wouldn\u2019t miss sending offers to individuals who can respond. Also, Starbucks would not mind sending offers to a few individuals who would not respond, as they have covered up all the individuals who would respond. Therefore, our predictive model would work fine in this case.", "The problem that I chose to solve was to build a model that predicts whether a customer will respond to an offer. My strategy for solving this problem has mainly three steps. First, after preprocessing portfolio, profile, and transaction datasets, I combined them to get a final clean data containing relevant features which can be used to train our model. Second, After splitting data to train and test datasets, we chose the best estimator \u201cRandomForestClassifier\u201d using GridSearch which is the best performing classifier algorithm among the above 4 classifiers tested (I compared F1-score and time taken). Third, I predicted the test target using test data, and plot a confusion matrix to ensure the performance of our model, we found that our predictive model is well suited for this case.", "I enjoyed working on this project which allowed me to work on a real-world project. The most interesting aspect of this project is the combination of different datasets and using predictive modeling techniques and analysis to provide better decisions and value to the business. The wrangling step was the longest and most challenging part. The toughest part of this entire analysis was finding logic and strategy to make a combined dataset, and deciding on the problem statement.", "Please note that the article discusses the important code of the analysis, you can find the complete code of the Starbuck Capstone Challenge project here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb95b0931bab4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@laila.sabar?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@laila.sabar?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "Laila Sabar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F52145c0efa79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&user=Laila+Sabar&userId=52145c0efa79&source=post_page-52145c0efa79----b95b0931bab4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb95b0931bab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb95b0931bab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://cdn.vox-cdn.com/thumbor/L8oitvUmrZbnqzJn5V4yA3-GLL4=/0x0:4608x3072/920x613/filters:focal(2154x1388:2890x2124):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/66466902/shutterstock_1516971902.0.jpg", "anchor_text": "seattle.eater (free for commercial use)"}, {"url": "https://github.com/LailaSabar/Starbucks-Capstone-Challenge", "anchor_text": "here"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b95b0931bab4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/starbucks?source=post_page-----b95b0931bab4---------------starbucks-----------------", "anchor_text": "Starbucks"}, {"url": "https://medium.com/tag/data-pre-processing?source=post_page-----b95b0931bab4---------------data_pre_processing-----------------", "anchor_text": "Data Pre Processing"}, {"url": "https://medium.com/tag/udacity-nanodegree?source=post_page-----b95b0931bab4---------------udacity_nanodegree-----------------", "anchor_text": "Udacity Nanodegree"}, {"url": "https://medium.com/tag/random-forest-classifiers?source=post_page-----b95b0931bab4---------------random_forest_classifiers-----------------", "anchor_text": "Random Forest Classifiers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb95b0931bab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&user=Laila+Sabar&userId=52145c0efa79&source=-----b95b0931bab4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb95b0931bab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&user=Laila+Sabar&userId=52145c0efa79&source=-----b95b0931bab4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb95b0931bab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb95b0931bab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b95b0931bab4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b95b0931bab4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b95b0931bab4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b95b0931bab4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@laila.sabar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@laila.sabar?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Laila Sabar"}, {"url": "https://medium.com/@laila.sabar/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "6 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F52145c0efa79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&user=Laila+Sabar&userId=52145c0efa79&source=post_page-52145c0efa79--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F583106d82354&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstarbucks-capstone-challenge-b95b0931bab4&newsletterV3=52145c0efa79&newsletterV3Id=583106d82354&user=Laila+Sabar&userId=52145c0efa79&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}