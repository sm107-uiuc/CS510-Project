{"url": "https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d", "time": 1683001755.4696162, "path": "towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d/", "webpage": {"metadata": {"title": "The Unknown Benefits of using a Soft-F1 Loss in Classification Systems | by Ashref Maiza | Towards Data Science", "h1": "The Unknown Benefits of using a Soft-F1 Loss in Classification Systems", "description": "Deploying machine learning systems in production and ensuring their day-to-day efficiency can be a very hard challenge. During the last five years, I have seen and increasing number of technologies\u2026"}, "outgoing_paragraph_urls": [{"url": "http://research.google.com/pubs/pub43146.html", "anchor_text": "Machine Learning: The High-Interest Credit Card of Technical Debt\u201d,", "paragraph_index": 2}, {"url": "https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb", "anchor_text": "Jupyter Notebook", "paragraph_index": 8}, {"url": "https://github.com/ashrefm/multi-label-soft-f1", "anchor_text": "Github", "paragraph_index": 8}, {"url": "https://medium.com/@ashrefm/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72", "anchor_text": "Multi-Label Image Classification in TensorFlow 2.0", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Confusion_matrix", "anchor_text": "confusion matrix", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/F1_score", "anchor_text": "F1-score", "paragraph_index": 14}, {"url": "https://arxiv.org/pdf/1402.1892.pdf", "anchor_text": "paper", "paragraph_index": 37}], "all_paragraphs": ["Deploying machine learning systems in production and ensuring their day-to-day efficiency can be a very hard challenge. During the last five years, I have seen and increasing number of technologies that are becoming more and more complex (algorithms, coding libraries, cloud services,\u2026). This is all good news to reshape our world with useful AI applications.", "But, like in many other domains, simplicity in complexity is key to success.Leonardo da Vinci described simplicity as \u201cthe ultimate sophistication\u201d.In data science, it is not just a theory, it can take the form of a process.", "Anyway, why am I talking about this topic?In a very inspiring paper entitled \u201cMachine Learning: The High-Interest Credit Card of Technical Debt\u201d, a team of AI researchers at Google shared some very pragmatic advice on how to manage the complexity of machine learning systems in production. Among all the aspects they described, there is the question of adapting the ML system to changes in the external world.", "Here is what they said about fixing thresholds in dynamic systems:", "\u201c It is often necessary to pick a decision threshold for a given model to perform some action: to predict true or false, to mark an email as spam or not spam, to show or not show a given ad. One classic approach in machine learning is to choose a threshold from a set of possible thresholds, in order to get good tradeoffs on certain metrics, such as precision and recall. However, such thresholds are often manually set. Thus if a model updates on new data, the old manually set threshold may be invalid. Manually updating many thresholds across many models is time-consuming and brittle. A useful mitigation strategy for this kind of problem is learning thresholds via simple evaluation on heldout validation data.\u201d", "Recently, I have been working on an ML system to help automate car diagnosis. Based on car data, the system should predict which parts need to be replaced in case of incident. It is a multi-label classification problem that can be decomposed into hundreds of binary classification subproblems (one for each part).", "With all production contraints in mind, learning and continuously updating one decision threshold for each subproblem appeared to me very tedious.", "In this blog post, I want to share some extra mitigation strategy to ignore the tuning of decision thresholds and still get optimized performance in classification systems. As far as I know, there is no common practice like this, no article, no recognized research. It is just the results of my experiments. So I recommend using the following insights carefully and feel free to share your opinion and any questions that we could discuss together.", "If you want to reproduce the results, you can step through this Jupyter Notebook. The complete code is shared on Github under MIT Licence.", "In order to illustrate the idea, let\u2019s consider a machine learning system that predicts movie genres from poster images. For each poster, one or many labels can be assigned (Action, Thriller, Drama, Horror, Fantasy, etc.). Convolutional neural networks are certainly a very nice way to learn a mapping from movie posters to the list of possible labels. You can read my article about \u201cMulti-Label Image Classification in TensorFlow 2.0\u201d for implementation details, but you can also continue reading this article independently.", "Given a movie poster, we need the predictive system to generate a 0 or 1 prediction for each label. For example, if a movie has some \u2018Action\u2019 content, the system should assign 1 to the \u2018Action\u2019 label, otherwise it should assign 0 for that same label. For each movie, we end up with an N-dimentional binary vector representing all guesses with N the number of all possible labels (movie genres). The binary prediction vector may look like this: 00011000001..000.", "When reasoning about one single label, there are four types of predictions:", "This is usally visualized using a confusion matrix.", "Based on that, it is common to analyze two metrics which are:", "But because these two metrics usually play against each other, we may rely on their harmonic mean which is the F1-score.", "Having one single metric for evaluation speeds up progress when developing your ML system.", "Before training and evaluating a machine learning algorithm such as neural networks, we need to define two major functions:", "If we want to use the F1-score as an evaluation metric, there are two possible strategies to maximize it:", "When the model generates probability values, we need to set a threshold for each label to get binary predictions. For example, we can predict 1 (a movie is about Action) if the probability for Action is above the threshold of 0.5, otherwise we predict 0 (no Action). The optimal threshold that maximizes the F1-score for each label is somewhere between 0 and 0.5 (There is a mathematical proof on that but it is not covered in this post). We usually search for that threshold on a held-out validation set.", "This would be the straightforward way if you ever want to optimize directly for the F1 metric. The loss function provides not only a measure of model error, it is in the heart of the learning process defining how to best fit the data to achieve optimal goals. For some reason though, embeddding the F1-score in the loss function is not a common practice.", "The problem of the F1-score is that it is not differentiable and so we cannot use it as a loss function to compute gradients and update the weights when training the model. Remember that the F1-score needs binary predictions (0/1) to be measured.", "Usually we use the binary cross-entropy loss which represents the negative log likelihood -log(p) of an observation being of a specific class with the model predicting a probability p for that class. Generally this loss works well and is widely used to train classifiers using Strategy 1, but it does not directly align with the F1-score we want to maximize.", "We can modifiy the F1-score to make it differentiable. Instead of computing the number of True Positives, False Positives, False Negatives as discrete integer values, we can compute them as a continuous sum of likelihood values by using probabilities without applying any threshold.", "Let\u2019s see two examples that could help understand this transformation:", "We will call this version a soft-F1-score. Below, you can see the code that implements it on a batch of predictions in TensorFlow.", "Let\u2019s assume that for simplicity reasons, we want to use only one threshold for all labels to convert any probability value into a binary prediction. In other terms, instead of maximizing the performance by thresholding for each label apart, we will now consider the default threshold of 0.5 and try to maximize the macro F1-score @ threshold 0.5 by optimizing the macro soft-F1 loss that we defined earlier (Strategy 2).", "Unlike the macro soft-F1 which uses likelihood terms, we will use the threshold of 0.5 in the implementation of the macro F1-score.", "On the following learning curves, we observe the change in the loss metric (macro soft-F1) and the evaluation metric (macro F1-score @ threshold 0.5) during the training process.", "You may notice on the learning curves that a decrease in the macro soft-F1 loss to a level near 0.69 is associated with an increase in the macro F1-score to a level near 0.33. These two values almost complement to 1. Remember that the macro soft-F1 loss we defined was actually the macro of 1- soft-F1 that we needed to minimize. This is a first indicator that the macro soft-F1 loss is directly optimizing for our evaluation metric which is the macro F1-score @ threshold 0.5.", "In order to explain the implications of this loss function, I have trained two neural network models with same architecture but two different optimizations. The first model was optimizing directly for the macro F1-score using the macro soft-F1 loss, while the second one is more classic and optimized for the binary cross-entropy. In both cases, the model trained will generate an independent probability score for each label when predicting the genre of a movie poster. To create a final decision system, we need to pick a decision threshold between 0 and 1 for each label so as to transform each probability into a binary information. Usually the performance of the system depends on the choice of these decision thresholds. So, let\u2019s examine, for each type of optimization, how the system behaves on the validation set depending on the level where we set the threshold for some labels.", "When training the model using the macro soft-F1 loss, we get an F1-score that is almost independent of the threshold (green curve). We don\u2019t have this effect when using the binary cross-entropy loss. It is actually an interesting effect because it offers the possibility to fix the threshold at 0.5 for all labels and still get a performance close to the one we would obtain by searching for an optimal threshold when using the BCE loss. When it comes to building production ML systems, this is a very nice feature. Updating the thresholds and making sure they remain optimal on new coming data is a lot of effort. Using the macro soft-F1 loss can help solve that problem, but actually where does that behaviour come from?", "It would be interesting to analyze the spread of prabability values that come out of the neural network when using the two different optimizations.", "When training using the binary cross-entropy loss, the probability distribution of the output has some gaussian properties (notice the bell shape of the blue histograms). Actually, this optimization learns from the original distribution of the data. We can see that for label \u2018Drama\u2019 which coveres 50% of the dataset, the probability distribution is centred at 0.5. By the way, the classifier that was built for \u2018Drama\u2019 appears to be very weak as both classes do not appear to be separated in probability values. We can also notice that the less frequent a label is, the more shifted to the left the distribution will be. For example, probability scores appear to be lower for \u2018Comedy\u2019 and this label coveres only 32% of the dataset. The model learns from this rarity to predict lower probability values. On the other hand, when using the macro soft-F1 loss, we are creating a system that does not reflect the same magnitude of conditional probability values. Instead, it learns to be less hesitating and generates predictions that are either very close to 1 or very close to 0. We have less probability values in the middle range. So, the performance does not change too much when varying the threshold in that range.", "Optimizing with the macro soft-F1 loss could replace some exhaustive techniques like:", "1- Searching for the optimal decision threshold that maximizes performance on a validation set", "2- Calibrating probability values by oversampling a minority class or undersampling a majority class before training (very complex in case of multi-label classification because of the cooccurrence of labels)", "You may have noticed that in the case of label \u2018Drama\u2019, optimizing using the macro soft-F1 loss resulted in a model that predicts always positive for \u2018Drama\u2019 (Notice how the probability histogram is on the very right close to 1 and how the Recall curve is constant at the maximum level of 100%).", "This side effect may happen everytime the trained classifier is uninformative. It is due to some property of the F1 metric that is demonstrated on page 10 of this paper by researchers at University of California.", "\u201cWhenever the frequency of actual positives in the test set is nonzero, and the classifier is uninformative, expected F1 is maximized by predicting all examples positive.\u201d", "The paper focuses on maximizing the F1-score by thresholding (Strategy 1), but same logic applies when maximizing based on soft-F1 optimization described in this post (Strategy 2).", "We basicly want to maximize the expectation of F1 as a function of positive predictions and thus we may need to define the following terms:", "When the classifier if uninformative, the number of true positives is expected to be a fraction of all positive predictions that is equal to the base rate (label frequency)", "The expected F1 can then be calculated by using this formula :", "And the partial derivative of expected F1 with respect to c can be decomposed as follows:", "This derivative is always positive, which proves that whenever the classifier is uninformative, the system will learn to get an optimal F1 by predicting all examples positive.", "When thinking about the F1-socre, we are reasoning by default about the positive class (outcome equal to 1). But, you can also, consider the F1-score you would obtain in the same conditions if you were reasoning about the negative class (outcome equal to 0). The only difference is the alternation between TP and TN quantities.", "We can then take the average of these two quantities to define a new metric.", "And, of course make it differentiable:", "By doing so, you can expect the system to counter-balance its previous behaviour by generating not only positive predictions but also negative predictions in order to optimize this new loss.", "This would protect the system from inacceptable behaviour of predicting always positive in case of uninformative classifier.", "Performance of production ML systems comes from deploying reliable and easy to maintain models. Decision thresholds are yet another source of complexity. In this blog post, I shared an optimization trick to avoid continuously tuning the decision threshold by incorporating the definition of F1-score inside a loss function (soft-F1 loss). This can be extremely helpful especially in case of multi-label classification where you want to use the same default threshold of 0.5 to turn predictions into binary outcomes while keeping an optimal classification performance.", "Predicting movie genre from its poster was one example where the number of labels can get high. But it is actually a hard classification challenge. On some of the labels, we could only get very weak classifiers. In case of uninformative classifier, the technique described can lead to the undesirable effect of predicting always positive. If you want to avoid that effect, you could probably use the double soft-F1 loss.", "On some other datasets like car diagnosis, I could see very interesting results. So, if you are working on similar tasks, you can try it on your own dataset and let me know the results you get!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F753902c0105d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@ashrefm?source=post_page-----753902c0105d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----753902c0105d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Ashref Maiza"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80c2f1871537&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&user=Ashref+Maiza&userId=80c2f1871537&source=post_page-80c2f1871537----753902c0105d---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F753902c0105d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&user=Ashref+Maiza&userId=80c2f1871537&source=-----753902c0105d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F753902c0105d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&source=-----753902c0105d---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@h3p?utm_source=medium&utm_medium=referral", "anchor_text": "Hilthart Pedersen"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://research.google.com/pubs/pub43146.html", "anchor_text": "Machine Learning: The High-Interest Credit Card of Technical Debt\u201d,"}, {"url": "https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb", "anchor_text": "Jupyter Notebook"}, {"url": "https://github.com/ashrefm/multi-label-soft-f1", "anchor_text": "Github"}, {"url": "https://medium.com/@ashrefm/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72", "anchor_text": "Multi-Label Image Classification in TensorFlow 2.0"}, {"url": "https://en.wikipedia.org/wiki/Confusion_matrix", "anchor_text": "confusion matrix"}, {"url": "https://en.wikipedia.org/wiki/F1_score", "anchor_text": "F1-score"}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "backpropagate"}, {"url": "https://algorithmia.com/blog/introduction-to-loss-functions", "anchor_text": "Introduction to loss functions (Algorithmia)"}, {"url": "https://arxiv.org/pdf/1402.1892.pdf", "anchor_text": "paper"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----753902c0105d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/classification?source=post_page-----753902c0105d---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----753902c0105d---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/optimization?source=post_page-----753902c0105d---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----753902c0105d---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F753902c0105d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&user=Ashref+Maiza&userId=80c2f1871537&source=-----753902c0105d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F753902c0105d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&user=Ashref+Maiza&userId=80c2f1871537&source=-----753902c0105d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F753902c0105d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=post_page-----753902c0105d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----753902c0105d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80c2f1871537&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&user=Ashref+Maiza&userId=80c2f1871537&source=post_page-80c2f1871537----753902c0105d---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3a2ae36b9258&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&newsletterV3=80c2f1871537&newsletterV3Id=3a2ae36b9258&user=Ashref+Maiza&userId=80c2f1871537&source=-----753902c0105d---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Written by Ashref Maiza"}, {"url": "https://medium.com/@ashrefm/followers?source=post_page-----753902c0105d--------------------------------", "anchor_text": "130 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80c2f1871537&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&user=Ashref+Maiza&userId=80c2f1871537&source=post_page-80c2f1871537----753902c0105d---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3a2ae36b9258&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d&newsletterV3=80c2f1871537&newsletterV3Id=3a2ae36b9258&user=Ashref+Maiza&userId=80c2f1871537&source=-----753902c0105d---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72?source=author_recirc-----753902c0105d----0---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=author_recirc-----753902c0105d----0---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=author_recirc-----753902c0105d----0---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Ashref Maiza"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----753902c0105d----0---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72?source=author_recirc-----753902c0105d----0---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Multi-Label Image Classification in TensorFlow 2.0Learn what it takes to predict the genre of a movie from its poster."}, {"url": "https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72?source=author_recirc-----753902c0105d----0---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "\u00b712 min read\u00b7Dec 4, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&user=Ashref+Maiza&userId=80c2f1871537&source=-----7d4cf8a4bc72----0-----------------clap_footer----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72?source=author_recirc-----753902c0105d----0---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=-----753902c0105d----0-----------------bookmark_preview----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----753902c0105d----1---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----753902c0105d----1---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----753902c0105d----1---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----753902c0105d----1---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----753902c0105d----1---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----753902c0105d----1---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----753902c0105d----1---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----753902c0105d----1-----------------bookmark_preview----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----753902c0105d----2---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----753902c0105d----2---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----753902c0105d----2---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----753902c0105d----2---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----753902c0105d----2---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----753902c0105d----2---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----753902c0105d----2---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----753902c0105d----2-----------------bookmark_preview----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-for-formula-1-race-strategy-7f29c966472a?source=author_recirc-----753902c0105d----3---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=author_recirc-----753902c0105d----3---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=author_recirc-----753902c0105d----3---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Ashref Maiza"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----753902c0105d----3---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/reinforcement-learning-for-formula-1-race-strategy-7f29c966472a?source=author_recirc-----753902c0105d----3---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "Reinforcement Learning for Formula 1 Race StrategyUnderstand how Deep Q-Networks learn to decide pit stops like AlphaGo learns to play Go."}, {"url": "https://towardsdatascience.com/reinforcement-learning-for-formula-1-race-strategy-7f29c966472a?source=author_recirc-----753902c0105d----3---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": "\u00b715 min read\u00b7Jun 24, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7f29c966472a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-formula-1-race-strategy-7f29c966472a&user=Ashref+Maiza&userId=80c2f1871537&source=-----7f29c966472a----3-----------------clap_footer----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-for-formula-1-race-strategy-7f29c966472a?source=author_recirc-----753902c0105d----3---------------------c43d109a_c6b6_4a86_9565_a18e4efd5298-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7f29c966472a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-formula-1-race-strategy-7f29c966472a&source=-----753902c0105d----3-----------------bookmark_preview----c43d109a_c6b6_4a86_9565_a18e4efd5298-------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=post_page-----753902c0105d--------------------------------", "anchor_text": "See all from Ashref Maiza"}, {"url": "https://towardsdatascience.com/?source=post_page-----753902c0105d--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Amy @GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Imbalanced Multi-Label Classification: Balanced Weights May Not Improve Your Model PerformanceCompare the random forest model and logistic regression model with and without balanced weights on imbalanced multi-class classification"}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "\u00b711 min read\u00b7Feb 1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgrabngoinfo%2Fcf71c6df030c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fimbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c&user=Amy+%40GrabNGoInfo&userId=ef6171ffb4ed&source=-----cf71c6df030c----0-----------------clap_footer----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf71c6df030c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fimbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c&source=-----753902c0105d----0-----------------bookmark_preview----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/sdv-generate-synthetic-data-using-gan-and-python-4c26a1e4b3c2?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@davide.gazze?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@davide.gazze?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Davide Gazz\u00e8 - Ph.D."}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/sdv-generate-synthetic-data-using-gan-and-python-4c26a1e4b3c2?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "SDV: Generate Synthetic Data using GAN and Python"}, {"url": "https://medium.datadriveninvestor.com/sdv-generate-synthetic-data-using-gan-and-python-4c26a1e4b3c2?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "\u00b711 min read\u00b7Feb 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F4c26a1e4b3c2&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fsdv-generate-synthetic-data-using-gan-and-python-4c26a1e4b3c2&user=Davide+Gazz%C3%A8+-+Ph.D.&userId=f38a0112847&source=-----4c26a1e4b3c2----1-----------------clap_footer----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/sdv-generate-synthetic-data-using-gan-and-python-4c26a1e4b3c2?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c26a1e4b3c2&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fsdv-generate-synthetic-data-using-gan-and-python-4c26a1e4b3c2&source=-----753902c0105d----1-----------------bookmark_preview----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----753902c0105d----0---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----753902c0105d----0-----------------bookmark_preview----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----1-----------------clap_footer----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----753902c0105d----1---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----753902c0105d----1-----------------bookmark_preview----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----753902c0105d----2---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----753902c0105d----2---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----753902c0105d----2---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----753902c0105d----2---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----753902c0105d----2---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----753902c0105d----2---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----2-----------------clap_footer----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----753902c0105d----2---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----753902c0105d----2-----------------bookmark_preview----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----753902c0105d----3---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----753902c0105d----3---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----753902c0105d----3---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----753902c0105d----3---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----753902c0105d----3---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----753902c0105d----3---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----3-----------------clap_footer----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----753902c0105d----3---------------------d054e9fe_1681_498f_9b59_5d817fe4bcdb-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----753902c0105d----3-----------------bookmark_preview----d054e9fe_1681_498f_9b59_5d817fe4bcdb-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----753902c0105d--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----753902c0105d--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----753902c0105d--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}