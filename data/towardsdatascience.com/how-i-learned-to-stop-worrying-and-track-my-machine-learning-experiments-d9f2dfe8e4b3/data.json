{"url": "https://towardsdatascience.com/how-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3", "time": 1683016632.7164412, "path": "towardsdatascience.com/how-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3/", "webpage": {"metadata": {"title": "How I Learned to Stop Worrying and Track my Machine Learning Experiments | by Felipe de Pontes Adachi | Towards Data Science", "h1": "How I Learned to Stop Worrying and Track my Machine Learning Experiments", "description": "From my personal experience, one thing I realized is that tracking machine learning experiments is important. This realization was eventually followed by another one: tracking machine learning\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/FelipeAdachi/fake-news-experiments", "anchor_text": "Github repository", "paragraph_index": 1}, {"url": "https://medium.com/@hadyelsahar/how-do-you-manage-your-machine-learning-experiments-ab87508348ac", "anchor_text": "Here", "paragraph_index": 2}, {"url": "https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://www.wandb.com/", "anchor_text": "W&B", "paragraph_index": 7}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab", "paragraph_index": 8}, {"url": "https://www.kaggle.com/madz2000/nlp-using-glove-embeddings-99-87-accuracy", "anchor_text": "Kaggle notebook", "paragraph_index": 9}, {"url": "https://boto3.amazonaws.com/v1/documentation/api/latest/index.html", "anchor_text": "Boto3", "paragraph_index": 11}, {"url": "https://docs.aws.amazon.com/AmazonS3/latest/dev/walkthrough1.html", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://docs.wandb.com/artifacts/api#data-privacy", "anchor_text": "official documentation", "paragraph_index": 15}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "sklearn", "paragraph_index": 22}, {"url": "https://www.kaggle.com/madz2000/nlp-using-glove-embeddings-99-87-accuracy", "anchor_text": "here", "paragraph_index": 23}, {"url": "https://docs.wandb.com/sweeps", "anchor_text": "W&B Sweeps", "paragraph_index": 29}, {"url": "https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf", "anchor_text": "Hidden Technical Debt in Machine Learning Systems", "paragraph_index": 50}], "all_paragraphs": ["From my personal experience, one thing I realized is that tracking machine learning experiments is important. This realization was eventually followed by another one: tracking machine learning experiments is hard.", "In this article, I want to share my take on tracking machine learning experiments. Everything discussed here can be found at the project\u2019s Github repository.", "Nowadays, you have at your disposal various platforms to track your experiments. Here is an article comparing some of those. This is one way among several to do it, so consider this as a beginner\u2019s attempt to do things organized, and please share your thoughts if you think of any improvements to be made!", "First, we need an experiment to track. For this purpose, I decided to train a fake news classifier model, using a Kaggle dataset that you can find here. In it, you have csv files for both fake and real news articles containing information such as title, text, subject, and date of each article. All of the articles were posted between the years 2015 and 2018.", "This is, therefore, a text classification task.", "Let\u2019s first define what is important to keep track of. We should ask ourselves this: Which piece of information I have to have available so that, in the future, I\u2019ll have everything I need to debug and/or reproduce this text classification model?", "The answer I gave to myself was this:", "This is a very simple diagram, just to show the main components I used in this project. I store my artifacts \u2014 dataset and models \u2014 in an S3 bucket. I used W&B as a central dashboard to log and visualize my experiments. In there, we\u2019ll have our plots, metrics, and everything we mentioned previously. Since I want to have everything centralized at W&B, I also logged the artifacts in there, but as references to objects located at my bucket. During my experiments, when I need to fetch data, I get the references I need from W&B.", "The experiments are run in my local notebook, but I could have used Google Colab or any other cloud environment.", "The first thing we should do is to get our dataset ready. Initially, we have from Kaggle one file for fake news and another for real news (True.csv and Fake.csv). The next step would be an exploratory data analysis, but I will skip it in this article. Not because it is not important (it is!), but because it has already been thoroughly done in this Kaggle notebook.", "From there, we should arrange the data to put it in the desired structure and split it into a train and test dataset. The following piece of code does exactly that. A categorylabel is created to be used as our target, and the input is the article\u2019s text, which is concatenated with the title, forming the textfeature.", "At this point, we have our train/test splits in our local folder. Each run with possible variations would overwrite existing files, so we need to upload that to S3. To do that I used AWS\u2019s SDK for Python \u2014 Boto3. Aside from following the Quickstart section of the docs, I also created the bucket at AWS\u2019s console. Then I created an IAM User and gave it permission to access the bucket. You can find more about that in AWS\u2019s documentation here. When creating your bucket, make sure to enable bucket versioning!", "The following piece of code uploads the train-test files to the bucket. Additionally, it stores information about the file\u2019s version ID and access URL that will be used in the next step, when logging the artifacts at W&B.", "At our bucket, you can check that the files were uploaded, and are properly being versioned:", "Note: Since I\u2019m working with publicly available data and this is a personal project, data privacy issues are not being considered. As you might have noticed, to make the artifacts downloadable by W&B, the artifacts from my S3 bucket were set to public read.", "If privacy is an issue for you, W&B also tracks references to private buckets, as stated in the official documentation. It might be a good idea to get in contact with them to get more info.", "Now we\u2019re set to log those objects as artifacts at W&B. If you don\u2019t have an account yet, the wandb.login() command will prompt you to create one. Then, a run is initiated at your project of choice, which will be created for you if it doesn\u2019t exist already.", "You can see above that we can define a job type, which is useful to distinguish each job according to its function. In this case, it\u2019s a dataset producer. The unprocessed tag is added to the dataset because I decided to preprocess the text at a later stage, during the grid search, as I wanted to assess the impact of it on the performance. Additionally, W&B also allows inserting metadata, if you want to store any additional information about the artifact.", "At our project\u2019s dashboard, we can check the artifact and its versions:", "W&B performs a checksum and automatically creates new versions when needed. As it goes along, the latest tag is also created automatically, so you can use an artifact directly by its version or tags associated with it.", "The metadata is also nicely displayed on your dashboard. I added the S3\u2019s version ID\u2019s to make sure the artifacts are appropriately synced between S3 and W&B.", "In the Graph view tab, there is a graph denoting the relationship between artifacts and runs. In this example, you can see that one run of the dataset_producer type outputs an artifact of the dataset type, which in turn is used as input to several jobs of the types grid_search and final_model_trainer. You can also explode this view so you can see the names of each run.", "Alright, now we have our dataset under control. Time to use it to start training our models. Since performance is not my main concern here, I\u2019ll leave the fancy transformers models aside for the moment, and experiment with some classifiers available in sklearn.", "In this experiment, I chose two parameters to assess: the type of model and the text preprocessing step. The text preprocessing can be done in several different ways, so I figured it would be nice to include it as a varying parameter. But in here, I just tested with or without, for demonstration purposes. I didn\u2019t include the code for the preprocessing in this article, but you can check at the project\u2019s repository under src/features/denoise, and it was mainly copied from here.", "The dataset is fairly balanced, so I adopted accuracy as a performance score to log to W&B and compare the different combinations. I left out the test set to be used only for the final model, so for the tuning stage, I did a k-fold (k=5) cross-validation using only the train split. The logged accuracy is an average of the k iterations.", "The train_and_log function takes as parameters the data, type of model, and whether to apply the denoising function or not. Every time the function is called, it logs the resulting score to the dashboard.", "The function is supposed to be called by the script below, which is run in the command line like this:", "python -m src.models.grid_search --model svc --denoise True", "grid_search.py will then fetch the train-test-dataset to access its metadata and get the required URL from the bucket, and proceed to call the training function.", "Well, calling grid_search directly will only run one combination. To actually run the grid search, we use W&B Sweeps. We define the parameters of the sweep with a .yaml configuration file, like this:", "This tells us that we\u2019ll be making a sweep using the grid search strategy by calling grid_search, varying the model and denoise parameters as defined above. The goal is to maximize accuracy_score, and the sweep should be linked to the fn_experiments project.", "Now we can run the following command:", "Which will launch the sweep server at W&B. That will give you a sweep_id, which you\u2019ll use to run an agent in your local notebook. That agent will interact with the server, asking for the set of parameters to try next. To run the agent, in my case, the command was:", "That will start the sweep, and by the end of it, you should have some nice plots displayed on your dashboard, like this one:", "This is a parallel coordinates plot and maps parameter values to the metric of interest. From this, we can clearly see the best model types, and how much of an impact our preprocessing step has on the outcome. Apparently, the degree of influence of the preprocessing varies with the model type.", "In this case, since we didn\u2019t use that many combinations, the correlations are pretty obvious, but to more complex setups the parameter importance plot above can be very helpful.", "Now that we found that svc yielded the best results for our case, we could perform further experiments to tune parameters of the svc model, like the kernel type and strength of regularization. Since the accuracy is already pretty good, I chose to train the final model as is.", "Those are just some examples of plots available at W&B. You can plot learning curves, calibration curves, and a lot more.", "Once the model and parameters are defined, we can finally train the final model. This time, we\u2019ll use the whole train set to train the model. It\u2019s not that different from what we did previously. Particularly in this case, if you think you might need the prediction probabilities in the future, just remember to set probability=True when training the model. It might come in handy in the future, for monitoring purposes.", "For the final model, I plot the confusion matrix and the classification reports given by sklearn. There are other options, but these are enough for me.", "Then I fetch the data as before and call the training function above. I can get the name of the current run with wandb.run.name, which I will use to name the generated model, and save it as a joblib file.", "As with the dataset, I can upload the model to my bucket and reference it at W&B:", "Let\u2019s see the results on our dashboard. Here\u2019s an example of the model versioning:", "And the confusion matrix according to the category label:", "Another important feature of W&B is that it stores your run\u2019s logs. So I just printed the classification reports during the run, and it persists on my dashboard:", "We have some additional information about the run, such as the date, OS, and Python version. It also creates a branch in your project\u2019s git, letting you see the exact state of your code when the run was executed. That was all a part of our requirements, so that\u2019s nice.", "In the files section, we have access to the requirements.txt, which gives us more information about the environment. If you want exclusively the packages that are needed for your experiment, it is recommended to create a new environment for it.", "So, I think that\u2019s it. There\u2019s much more information on the dashboard, but I think that covers all of our requirements: we have data, code, and models appropriately traced. If I forgot about something, please let me know!", "In this article, I wanted to talk about tracking your ML experiments. This is a very important stage of your ML project\u2019s life cycle. You carefully tracked the steps of your project during its infancy, but now it\u2019s time for you to let it reach adulthood and go into production.", "But just to deploy it is not enough. You have to constantly monitor it after it is deployed, and much of what was done in this article is precisely to make the monitoring process easier.", "Technical debt is an important matter in machine learning systems. Tracking your experiments will certainly help to reduce this debt, but there are also other aspects involved. This is brilliantly discussed in this paper by Google: Hidden Technical Debt in Machine Learning Systems.", "That\u2019s it for now! I intend to keep going with this project to learn more about deploying and monitoring, and when I do, I\u2019ll make sure to share my attempts!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd9f2dfe8e4b3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://felipe-p-adachi.medium.com/?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": ""}, {"url": "https://felipe-p-adachi.medium.com/?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "Felipe de Pontes Adachi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa038269245d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=post_page-a038269245d5----d9f2dfe8e4b3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9f2dfe8e4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9f2dfe8e4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral", "anchor_text": "Annie Spratt"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/FelipeAdachi/fake-news-experiments", "anchor_text": "Github repository"}, {"url": "https://medium.com/@hadyelsahar/how-do-you-manage-your-machine-learning-experiments-ab87508348ac", "anchor_text": "Here"}, {"url": "https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset", "anchor_text": "here"}, {"url": "https://www.wandb.com/", "anchor_text": "W&B"}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab"}, {"url": "https://www.kaggle.com/madz2000/nlp-using-glove-embeddings-99-87-accuracy", "anchor_text": "Kaggle notebook"}, {"url": "https://boto3.amazonaws.com/v1/documentation/api/latest/index.html", "anchor_text": "Boto3"}, {"url": "https://docs.aws.amazon.com/AmazonS3/latest/dev/walkthrough1.html", "anchor_text": "here"}, {"url": "https://docs.wandb.com/artifacts/api#data-privacy", "anchor_text": "official documentation"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "sklearn"}, {"url": "https://www.kaggle.com/madz2000/nlp-using-glove-embeddings-99-87-accuracy", "anchor_text": "here"}, {"url": "https://docs.wandb.com/sweeps", "anchor_text": "W&B Sweeps"}, {"url": "https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf", "anchor_text": "Hidden Technical Debt in Machine Learning Systems"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d9f2dfe8e4b3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d9f2dfe8e4b3---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----d9f2dfe8e4b3---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----d9f2dfe8e4b3---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----d9f2dfe8e4b3---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd9f2dfe8e4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=-----d9f2dfe8e4b3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd9f2dfe8e4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=-----d9f2dfe8e4b3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd9f2dfe8e4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd9f2dfe8e4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d9f2dfe8e4b3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d9f2dfe8e4b3--------------------------------", "anchor_text": ""}, {"url": "https://felipe-p-adachi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://felipe-p-adachi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Felipe de Pontes Adachi"}, {"url": "https://felipe-p-adachi.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "118 Followers"}, {"url": "https://datatravelogues.substack.com/", "anchor_text": "https://datatravelogues.substack.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa038269245d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=post_page-a038269245d5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd79b2569b413&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-learned-to-stop-worrying-and-track-my-machine-learning-experiments-d9f2dfe8e4b3&newsletterV3=a038269245d5&newsletterV3Id=d79b2569b413&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}