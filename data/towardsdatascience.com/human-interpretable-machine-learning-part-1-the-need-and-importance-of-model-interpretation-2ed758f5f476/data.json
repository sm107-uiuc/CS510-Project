{"url": "https://towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476", "time": 1682993392.158798, "path": "towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476/", "webpage": {"metadata": {"title": "The Importance of Human Interpretable Machine Learning | by Dipanjan (DJ) Sarkar | Towards Data Science", "h1": "The Importance of Human Interpretable Machine Learning", "description": "This article is the first in my series of articles aimed at \u2018Explainable Artificial Intelligence (XAI)\u2019. The field of Artificial Intelligence powered by Machine Learning and Deep Learning has gone\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Capsule_neural_network", "anchor_text": "Capsule Networks", "paragraph_index": 0}, {"url": "https://www.ncbi.nlm.nih.gov/pubmed/21554073", "anchor_text": "model interpretability vs. model performance trade-off", "paragraph_index": 5}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "predicting potential criminals", "paragraph_index": 6}, {"url": "https://www.propublica.org/article/making-algorithms-accountable", "anchor_text": "judicial sentencing risk scores", "paragraph_index": 6}, {"url": "https://weaponsofmathdestructionbook.com/", "anchor_text": "\u2018Weapons of Math Destruction\u2019", "paragraph_index": 6}, {"url": "https://www.facebook.com/nipsfoundation/videos/1553500344741199", "anchor_text": "\u2018The Trouble with Bias\u2019", "paragraph_index": 7}, {"url": "https://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html", "anchor_text": "\u2018Artificial Intelligence\u2019s White Guy Problem\u2019", "paragraph_index": 8}, {"url": "https://github.com/dipanjanS/practical-machine-learning-with-python", "anchor_text": "\u2018Practical Machine Learning with Python\u2019", "paragraph_index": 9}, {"url": "https://www.datascience.com/", "anchor_text": "DataScience.com", "paragraph_index": 9}, {"url": "https://github.com/datascienceinc/Skater", "anchor_text": "Skater", "paragraph_index": 9}, {"url": "https://github.com/TeamHG-Memex/eli5", "anchor_text": "ELI5", "paragraph_index": 9}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP", "paragraph_index": 9}, {"url": "http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf", "anchor_text": "\u201cWhy Should I Trust You?\u201d Explaining the Predictions of Any Classifier", "paragraph_index": 17}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "\u201cInterpretable Machine Learning, A Guide for Making Black Box Models Explainable\u201d", "paragraph_index": 23}, {"url": "https://www.linkedin.com/in/mattmayo13", "anchor_text": "Matthew Mayo", "paragraph_index": 31}, {"url": "https://www.kdnuggets.com/2018/06/human-interpretable-machine-learning-need-importance-model-interpretation.html", "anchor_text": "KDNuggets", "paragraph_index": 31}, {"url": "https://www.datascience.com/", "anchor_text": "DataScience.com", "paragraph_index": 32}, {"url": "https://www.linkedin.com/in/pramitc/?lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_top%3Bi7sMwalBRG69UVr8ck4n%2BA%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_flagship3_search_srp_top-search_srp_result&lici=LV1csX2ATFSqPNbcebrjvQ%3D%3D", "anchor_text": "Pramit Choudhary", "paragraph_index": 32}, {"url": "https://www.datascience.com/resources/tools/skater", "anchor_text": "Skater", "paragraph_index": 32}, {"url": "https://github.com/dipanjanS/practical-machine-learning-with-python", "anchor_text": "\u201cPractical Machine Learning with Python\u201d", "paragraph_index": 33}], "all_paragraphs": ["This article is the first in my series of articles aimed at \u2018Explainable Artificial Intelligence (XAI)\u2019. The field of Artificial Intelligence powered by Machine Learning and Deep Learning has gone through some phenomenal changes over the last decade. Starting off as just a pure academic and research-oriented domain, we have seen widespread industry adoption across diverse domains including retail, technology, healthcare, science and many more. Rather than just running lab experiments to publish a research paper, the key objective of data science and machine learning in the 21st century has changed to tackling and solving real-world problems, automating complex tasks and making our life easier and better. More than often, the standard toolbox of machine learning, statistical or deep learning models remain the same. New models do come into existence like Capsule Networks, but industry adoption of the same usually takes several years. Hence, in the industry, the main focus of data science or machine learning is more \u2018applied\u2019 rather than theoretical and effective application of these models on the right data to solve complex real-world problems is of paramount importance.", "A machine learning model by itself consists of an algorithm which tries to learn latent patterns and relationships from data without hard-coding fixed rules. Hence, explaining how a model works to the business always poses its own set of challenges. There are some domains in the industry especially in the world of finance like insurance or banking where data scientists often end up having to use more traditional machine learning models (linear or tree-based). The reason being that model interpretability is very important for the business to explain each and every decision being taken by the model. However, this often leads to a sacrifice in performance. This is where complex models like ensembles and neural networks typically give us better and more accurate performance (since true relationships are rarely linear in nature). We, however, end up being unable to have proper interpretations for model decisions. To address and talk about these gaps, I will be writing a series of articles where we will explore some of these challenges in-depth about explainable artificial intelligence (XAI) and human interpretable machine learning.", "Some of the major areas we will be covering in this series of articles include the following.", "This content will be covered across several articles in this series as highlighted above to keep things concise and interesting, so that everyone can get some key takeaways from every article.", "Working as a Data Scientist in the industry and mentoring people in the field, I have seen that data science is still often perceived as a black box capable of performing magic or alchemy to give people what they want. However, the harsh reality is that without a reasonable understanding of how machine learning models or the data science pipeline works, real-world projects rarely succeed. Considering any data science project in the real world, you will typically have a business aspect and the technical or solution aspect. Now, data scientists typically work to build models and provide solutions for the business. However, the business may not know the intricate details of how a model might work. But since this very model will be making a lot of decisions for them in the end, they do have a right to pose the question, \u201cHow can I trust your model?\u201d or \u201cHow does your model really make its decisions?\u201d Answering these questions is something data science practitioners and researchers have been trying over several years now.", "Data Science practitioners will know that there exists a typical model interpretability vs. model performance trade-off. A point to remember here is that model performance is not the run-time or execution performance, but how accurate the model can be in making decisions. There are several models including simple linear models or even tree-based models, which can easily explain the decisions taken by the model to arrive at a particular insight or prediction, but you might need to sacrifice model performance since they always do not yield the best results due to inherent problems of high bias (linear models) or high variance, leading to overfitting (fully grown tree models). More complex models like ensemble models and the more recent deep learning family of models often yield better performance, but are perceived as black-box models, because it is extremely difficult to explain how the model might be really making its decisions under the hood.", "While some might argue that if something is working well (for the time being), why question how it works? However, being humans, logic and reasoning is something we adhere to for most of our decisions. Hence, the paradigm shift towards artificial intelligence (AI) making decisions will no doubt be questioned. There are a lot of real-world scenarios where biased models might have really adverse effects. This includes predicting potential criminals, judicial sentencing risk scores, credit scoring, fraud detection, health assessment, loan lending, self-driving and many more where model understanding and interpretation is of utmost importance. The same is highlighted by renowned Data Scientist and Author Cathy O\u2019 Neil in her acclaimed book, \u2018Weapons of Math Destruction\u2019.", "Renowned researcher and author, Kate Crawford, talked about these very aspects of the implications of bias in machine learning and it\u2019s effects on society in the NIPS 2017 Keynote, \u2018The Trouble with Bias\u2019.", "Interested readers should also definitely check out her famous article on the NY Times, \u2018Artificial Intelligence\u2019s White Guy Problem\u2019 where she shows us examples of machine learning applications including image categorization, criminal risk predictions, delivery service availability and many more were biased and yielded unfavorable outcomes for the black community. All these real-world scenarios are implications of how important model interpretation should be, and if we want to leverage machine learning to solve these problems.", "In the past year, I have seen the need for model interpretation while solving problems in the industry and also when I was writing my recent book \u2018Practical Machine Learning with Python\u2019. During this time, I have had the chance to interact with the wonderful folks at DataScience.com who are very much aware of the need and importance of human interpretability in machine learning models. They have been actively working on a solution and have open-sourced the popular python framework, Skater. We will be taking a deep-dive into Skater and also do some hands-on model interpretation in this series of articles. Besides this we will also do a comprehensive coverage of other model interpretation frameworks like ELI5 and SHAP!", "Machine Learning has seen widespread industry adoption only in the last couple of years. Hence, model interpretation as a concept is still mostly theoretical and subjective.", "Any machine learning model at its heart has a response function which tries to map and explain relationships and patterns between the independent (input) variables and the dependent (target or response) variable(s).", "When a model predicts or finds our insights, it takes certain decisions and choices. Model interpretation tries to understand and explain these decisions taken by the response function i.e., the what, why and how. The key to model interpretation is transparency, the ability to question, and the ease of understanding model decisions by humans. The three most important aspects of model interpretation are explained as follows.", "Interpretability also popularly known as human-interpretable interpretations (HII) of a machine learning model is the extent to which a human (including non-experts in machine learning) can understand the choices taken by models in their decision-making process (the how, why and what).", "When comparing models, besides model performance, a model is said to have a better interpretability than another model if its decisions are easier to understand by a human than the decisions from the other model.", "When tackling machine learning problems, data scientists often have a tendency to fixate on model performance metrics like accuracy, precision and recall and so on (This is important no doubt!). This is also prevalent in most online competitions around data science and machine learning. However, metrics only tell a part of the story of a model\u2019s predictive decisions. Over time, the performance might change due to model concept drift caused by various factors in the environment. Hence, it is of paramount importance to understand what drives a model to take certain decisions.", "Some of us might argue if a model is working great why bother digging deeper? Always remember that when solving data science problems in the real-world, for the business to trust your model predictions and decisions, they will keep asking the question, \u201cWhy should I trust your model?\u201d and this makes perfect sense. Would you be satisfied with a model just predicting and taking decisions (the what) like if a person has cancer or diabetes, if a person might be a risk to society or even if a customer will churn? Maybe not, we might prefer it more if we could know more about the model\u2019s decision process (the why and how). This gives us more transparency into why the model makes certain decisions, what might go wrong in certain scenarios and over time it helps us build a certain amount of trust on these machine learning models.", "The key takeaway from this section is that it is high time we stop seeing machine learning models as black boxes and try and analyze not just data, but how models make decisions. In-fact, some of the key steps towards this path was started by the famous paper, \u201cWhy Should I Trust You?\u201d Explaining the Predictions of Any Classifier by M. T. Ribeiro, S. Singh and C. Guestrin, SIGKDD 2016, where they introduce the concept of LIME (Local Interpretable Model-Agnostic Explanations) which we will be covering in the next article in detail.", "They mention some key points in their paper which are worth remembering.", "Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model.", "Whether humans are directly using machine learning classifiers as tools, or are deploying models within other products, a vital concern remains: if the users do not trust a model or a prediction, they will not use it.", "Interested people should also check out their talk in the KDD conference around their paper in model interpretation.", "This is something we have discussed several times in this article and is one of the key differentiators which determines the success of data science projects in the industry. This drives the urgency around the need and importance of model interpretation.", "There are specific criteria which can be used for categorizing model interpretation methods. An excellent guide to this is mentioned in \u201cInterpretable Machine Learning, A Guide for Making Black Box Models Explainable\u201d by Christoph Molnar, 2018", "This is not an exhaustive set of criteria for classifying interpretable methods since this is still an emerging field, but this can be a good yardstick to compare and contrast across multiple methods.", "How do we define the scope and boundaries of interpretability? Some useful aspects can be the transparency, fairness and accountability of a model. Global and Local model interpretations are clear ways to define the scope of model interpretation.", "This is all about trying to understand \u201cHow does the model make predictions?\u201d and \u201cHow do subsets of the model influence model decisions?\u201d. To comprehend and interpret the whole model at once, we need global interpretability. Global interpretability is all about being able to explain and understand model decisions based on conditional interactions between the dependent (response) variable(s) and the independent (predictor) features on the complete dataset. Trying to understand feature interactions and importances is always a good step towards understanding global interpretation. Of course, visualizing features after more than two or three dimensions becomes quite difficult when trying to analyze interactions. Hence, often looking at modular parts and subsets of features, which might influence model predictions on a global knowledge, helps. Complete knowledge of the model structure, assumptions and constraints are needed for a global interpretation.", "This is all about trying to understand \u201cWhy did the model make specific decisions for a single instance?\u201d and \u201cWhy did the model make specific decisions for a group of instances?\u201d. For local interpretability, we do not care about the inherent structure or assumptions of a model and we treat it as a black box. For understanding prediction decisions for a single datapoint, we focus specifically on that datapoint and look at a local subregion in our feature space around that point, and try to understand model decisions for that point based on this local region. Local data distributions and feature spaces might behave completely different and give more accurate explanations as opposed to global interpretations. The Local Interpretable Model-Agnostic Explanation (LIME) framework is an excellent method which can be used for model-agnostic local interpretation. We can use a combination of global and local interpretations to explain model decisions for a group of instances.", "This is all about trying to understand \u201cHow was a model created from algorithms and features?\u201d. We know that typically a machine learning model is all about leveraging an algorithm on top of data features to build a representation which maps inputs to potential outputs(responses). Transparency of a model can be trying to understand more technical details of how models are built and what might influence its decisions. This can be weights of a neural network, weights of a CNN filter, linear model coefficients, the nodes and splits of a decision tree. However, since the business may not be very well-versed in these technical details, trying to explain model decisions with agnostic local and global interpretation methods helps in showcasing model transparency.", "Model Interpretation is something which can make or break a real-world machine learning project in the industry and helps us come one step closer to explainable artificial intelligence (XAI). Let\u2019s try and work towards human-interpretable machine learning and XAI to demystify machine learning for everyone and help increase the trust in model decisions.", "In Part 2 of this series, we will be covering the following aspects of explainable artificial intelligence with regard to machine learning model interpretation.", "Thanks to Matthew Mayo for editing and featuring this article on KDNuggets.", "Thanks to all the wonderful folks at DataScience.com and especially Pramit Choudhary for building an amazing model interpretation framework, Skater, and helping me out with some excellent content for this series.", "I cover a lot of examples of machine learning model interpretation in my book, \u201cPractical Machine Learning with Python\u201d. The code is open-sourced for your benefit!", "If you have any feedback, comments or interesting insights to share about my article or data science in general, feel free to reach out to me on my LinkedIn social media channel.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2ed758f5f476&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://djsarkar.medium.com/?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": ""}, {"url": "https://djsarkar.medium.com/?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "Dipanjan (DJ) Sarkar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6278d12b0682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&user=Dipanjan+%28DJ%29+Sarkar&userId=6278d12b0682&source=post_page-6278d12b0682----2ed758f5f476---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ed758f5f476&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ed758f5f476&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Capsule_neural_network", "anchor_text": "Capsule Networks"}, {"url": "https://www.ncbi.nlm.nih.gov/pubmed/21554073", "anchor_text": "model interpretability vs. model performance trade-off"}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "predicting potential criminals"}, {"url": "https://www.propublica.org/article/making-algorithms-accountable", "anchor_text": "judicial sentencing risk scores"}, {"url": "https://weaponsofmathdestructionbook.com/", "anchor_text": "\u2018Weapons of Math Destruction\u2019"}, {"url": "https://weaponsofmathdestructionbook.com/", "anchor_text": "MainWeapons of Math Destruction has been Longlisted for the National Book Award! Book description: A former Wall Street\u2026weaponsofmathdestructionbook.com"}, {"url": "https://www.facebook.com/nipsfoundation/videos/1553500344741199", "anchor_text": "\u2018The Trouble with Bias\u2019"}, {"url": "https://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html", "anchor_text": "\u2018Artificial Intelligence\u2019s White Guy Problem\u2019"}, {"url": "https://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html", "anchor_text": "Opinion | Artificial Intelligence's White Guy ProblemACCORDING to some prominent voices in the tech world, artificial intelligence presents a looming existential threat to\u2026www.nytimes.com"}, {"url": "https://github.com/dipanjanS/practical-machine-learning-with-python", "anchor_text": "\u2018Practical Machine Learning with Python\u2019"}, {"url": "https://www.datascience.com/", "anchor_text": "DataScience.com"}, {"url": "https://github.com/datascienceinc/Skater", "anchor_text": "Skater"}, {"url": "https://github.com/TeamHG-Memex/eli5", "anchor_text": "ELI5"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf", "anchor_text": "\u201cWhy Should I Trust You?\u201d Explaining the Predictions of Any Classifier"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "\u201cInterpretable Machine Learning, A Guide for Making Black Box Models Explainable\u201d"}, {"url": "https://www.linkedin.com/in/mattmayo13", "anchor_text": "Matthew Mayo"}, {"url": "https://www.kdnuggets.com/2018/06/human-interpretable-machine-learning-need-importance-model-interpretation.html", "anchor_text": "KDNuggets"}, {"url": "https://www.datascience.com/", "anchor_text": "DataScience.com"}, {"url": "https://www.linkedin.com/in/pramitc/?lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_top%3Bi7sMwalBRG69UVr8ck4n%2BA%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_flagship3_search_srp_top-search_srp_result&lici=LV1csX2ATFSqPNbcebrjvQ%3D%3D", "anchor_text": "Pramit Choudhary"}, {"url": "https://www.datascience.com/resources/tools/skater", "anchor_text": "Skater"}, {"url": "https://github.com/dipanjanS/practical-machine-learning-with-python", "anchor_text": "\u201cPractical Machine Learning with Python\u201d"}, {"url": "https://www.linkedin.com/in/dipanzan/", "anchor_text": "Dipanjan Sarkar - Data Scientist - Intel Corporation | LinkedInView Dipanjan Sarkar's profile on LinkedIn, the world's largest professional community. Dipanjan has 5 jobs listed on\u2026www.linkedin.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2ed758f5f476---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2ed758f5f476---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2ed758f5f476---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----2ed758f5f476---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----2ed758f5f476---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2ed758f5f476&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&user=Dipanjan+%28DJ%29+Sarkar&userId=6278d12b0682&source=-----2ed758f5f476---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2ed758f5f476&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&user=Dipanjan+%28DJ%29+Sarkar&userId=6278d12b0682&source=-----2ed758f5f476---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ed758f5f476&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2ed758f5f476&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2ed758f5f476---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2ed758f5f476--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2ed758f5f476--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2ed758f5f476--------------------------------", "anchor_text": ""}, {"url": "https://djsarkar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://djsarkar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dipanjan (DJ) Sarkar"}, {"url": "https://djsarkar.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "10.4K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6278d12b0682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&user=Dipanjan+%28DJ%29+Sarkar&userId=6278d12b0682&source=post_page-6278d12b0682--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa34c887aa0f4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476&newsletterV3=6278d12b0682&newsletterV3Id=a34c887aa0f4&user=Dipanjan+%28DJ%29+Sarkar&userId=6278d12b0682&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}