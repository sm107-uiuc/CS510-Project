{"url": "https://towardsdatascience.com/model-compression-needs-and-importance-6e5913996e1", "time": 1683010552.4282188, "path": "towardsdatascience.com/model-compression-needs-and-importance-6e5913996e1/", "webpage": {"metadata": {"title": "Model Compression: needs and importance | by Sabina Pokhrel | Towards Data Science", "h1": "Model Compression: needs and importance", "description": "Whether you\u2019re new to computer vision or an expert, you\u2019ve probably heard about AlexNet winning the ImageNet challenge in 2012. That was the turning point in computer vision history because it showed\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.console.xailient.com/", "anchor_text": "Click here", "paragraph_index": 33}, {"url": "http://www.xailient.com", "anchor_text": "Xailient", "paragraph_index": 34}], "all_paragraphs": ["Whether you\u2019re new to computer vision or an expert, you\u2019ve probably heard about AlexNet winning the ImageNet challenge in 2012. That was the turning point in computer vision history because it showed that deep learning models can perform tasks which were considered very difficult for computers, with an unprecedented level of accuracy.", "But did you know that AlexNet had 62 million trainable parameters?", "Another popular model VGGNet which came out in 2014 had even more, 138 million trainable parameters.", "That\u2019s more than 2 times that of AlexNet.", "You might be thinking\u2026 I know that the deeper the model is, the better it will perform. So why are you highlighting the number of parameters? Deeper the network, it is obvious that there will be more parameters.", "Sure, these deep models have been benchmarks in the computer vision industry. But when you want to create a real-world application, would you choose these models?", "I guess the real question we should ask here is: CAN YOU USE THESE MODELS IN YOUR APPLICATION?", "Hold that thought for just a minute!", "Let me divert here for a bit, before I get to the answer. (But feel free to skip to the end.)", "The number of IoT devices is expected to reach 125\u2013500 Billion by 2030 and assuming that 20% of them will have cameras, IoT devices with cameras is a 13\u2013100 billion unit market. [9,10,11]", "IoT camera devices include home security cameras (such as Amazon Ring and Google Nest) that open the door when you reach home or notify you if it sees an unknown person, cameras on smart vehicles that assist your driving, or cameras at a parking lot that open the gate when you enter or exit, just to name a few! Some of these IoT devices are already using AI to some extent and others are catching up slowly.", "Many real-world applications demand real-time, on device processing capabilities. A self-driving car is a perfect example of this. In order for cars to drive down any road safely, they must observe the road in real-time and stop if a person walks in front of the car. In such a case, processing visual information and making a decision needs to be done in real-time, on device.", "So, returning to the earlier question: CAN YOU USE THESE MODELS IN YOUR APPLICATION?", "If you\u2019re using Computer Vision, there\u2019s a high chance your application requires an IoT device, and looking at the forecast for the IoT devices, you\u2019re in good company.", "The main challenge is that IoT devices are resource constrained; they have limited memory and low compute power. The more trainable parameters in a model, the bigger its size. Inference time of a deep learning model increases along with the increase in number of trainable parameters. Moreover, models with high parameters require more energy and space in comparison to a smaller network with fewer parameters. The end result is that when the size of the model is big, it\u2019s difficult to deploy on resource-constrained devices. While these models have been successful in achieving great results in a lab, they aren\u2019t usable in many real-world applications.", "In the lab, you have expensive and high-speed GPUs to get this level of performance [1], but when you deploy in the real-world the cost, power, heat and other issues preclude the \u201cjust throw more iron at it\u201d strategy.", "Deploying deep learning models on the cloud is an option as it can provide high computational and storage availability. However, it will have poor response times due to network latency, which is unacceptable in many real-time applications (and don\u2019t get me started on the network connectivity\u2019s impact on overall reliability, or privacy!).", "In short, AI needs to process close to the data source, preferably on the IoT device itself !", "That leaves us with one option: Reducing the size of the model.", "Making a smaller model that can run under the constraints of the edge-devices is a key challenge. And that too without compromising on accuracy. It is just not enough to have a small model that can run on resource constrained devices. It should perform well, both in terms of accuracy and inference speed.", "So how do you fit these models on limited devices? How do you make them usable in real-world applications?", "Here are a few techniques that can be used to reduce the model size so that you can deploy them on your IoT device.", "Pruning reduces the number of parameters by removing redundant, unimportant connections that are not sensitive to performance. This not only helps reduce the overall model size but also saves on computation time and energy.", "In DNN, weights are stored as 32-bit floating-point numbers. Quantization is the idea of representing these weights by reducing the number of bits. The weights can be quantized to 16-bit, 8-bit, 4-bit or even with 1-bit. By reducing the number of bits used, the size of the deep neural network can be significantly reduced.", "In knowledge distillation, a large, complex model is trained on a large dataset. When this large model can generalize and perform well on unseen data, it is transferred to a smaller network. The larger model is also known as the teacher model and the smaller network is also known as the student network.", "Selective attention is the idea of focusing on objects or elements of interest, while discarding the others (often background or other task-irrelevant objects). It is inspired by the biology of the human eye. When we look at something, we only focus on one or a few objects at a time, and other regions are blurred out.", "This requires adding a selective attention network upstream of your existing AI system or using it by itself if it serves your purpose. It depends on the problem you are trying to solve.", "Uses matrix/tensor decomposition to estimate the informative parameters. A weight matrix A with m x n dimension and having a rank r is replaced by smaller dimension matrices. This technique helps by factorizing a large matrix into smaller matrices.", "The best part is, all of the above techniques are complementary to each other. They can be applied as is or combined with one or multiple techniques. By using a three-stage pipeline; pruning, quantization and Huffman coding to reduce the size of the pre-trained model, VGG16 model trained on the ImageNet dataset was reduced from 550 to 11.3 MB.", "Most of the techniques discussed above can be applied to pre-trained models, as a post-processing step to reduce your model size and increase inference speed. But they can be applied during training time as well. Quantization is gaining popularity and has now been baked into machine learning frameworks. We can expect pruning to be baked into popular frameworks very soon.", "In this article, we looked at the motivation for deploying deep-learning based models to resource constrained devices such as IoT devices and the need to reduce model size so they fit without compromising accuracy. We also discussed the pros and cons of some modern techniques to compress deep-learning models . Finally, we touched on the idea that each of the techniques can either be applied individually or can be combined.", "Be sure to explore all the techniques for your model, post training as well as during training and figure out what works best for you.", "Which model compression techniques have worked best for you? Leave comments below.", "Want to train your own selective attention network? Click here.", "Sabina Pokhrel works at Xailient, a computer-vision start-up that has built the world\u2019s fastest Edge-optimized object detector.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI Specialist | Machine Learning Engineer | Writer and former Editorial Associate at Towards Data Science"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6e5913996e1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6e5913996e1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6e5913996e1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sabinaa.pokhrel?source=post_page-----6e5913996e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sabinaa.pokhrel?source=post_page-----6e5913996e1--------------------------------", "anchor_text": "Sabina Pokhrel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b40806ab7c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&user=Sabina+Pokhrel&userId=7b40806ab7c7&source=post_page-7b40806ab7c7----6e5913996e1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e5913996e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e5913996e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/Tumisu-148124/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4317139", "anchor_text": "Tumisu"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4317139", "anchor_text": "Pixabay"}, {"url": "https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3872063", "anchor_text": "Gerd Altmann"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3872063", "anchor_text": "Pixabay"}, {"url": "https://software.intel.com/content/www/us/en/develop/articles/compression-and-acceleration-of-high-dimensional-neural-networks.html", "anchor_text": "source"}, {"url": "https://software.intel.com/content/www/us/en/develop/articles/compression-and-acceleration-of-high-dimensional-neural-networks.html", "anchor_text": "source"}, {"url": "https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764", "anchor_text": "source"}, {"url": "http://www.xailient.com", "anchor_text": "source"}, {"url": "https://www.researchgate.net/figure/Diagram-of-the-low-rank-factorized-DNN_fig1_269295146", "anchor_text": "source"}, {"url": "http://www.console.xailient.com/", "anchor_text": "Click here"}, {"url": "https://www.xailient.com/post/model-compression-needs-and-importance", "anchor_text": "www.xailient.com/blog"}, {"url": "http://www.xailient.com", "anchor_text": "Xailient"}, {"url": "https://towardsdatascience.com/machine-learning-models-compression-and-quantization-simplified-a302ddf326f2", "anchor_text": "https://towardsdatascience.com/machine-learning-models-compression-and-quantization-simplified-a302ddf326f2"}, {"url": "http://mitchgordon.me/machine/learning/2020/01/13/do-we-really-need-model-compression.html", "anchor_text": "http://mitchgordon.me/machine/learning/2020/01/13/do-we-really-need-model-compression.html"}, {"url": "https://software.intel.com/content/www/us/en/develop/articles/compression-and-acceleration-of-high-dimensional-neural-networks.html", "anchor_text": "https://software.intel.com/content/www/us/en/develop/articles/compression-and-acceleration-of-high-dimensional-neural-networks.html"}, {"url": "https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96", "anchor_text": "https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96"}, {"url": "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/", "anchor_text": "https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/"}, {"url": "https://technology.informa.com/596542/number-of-connected-iot-devices-will-surge-to-125-billion-by-2030-ihs-markit-says", "anchor_text": "https://technology.informa.com/596542/number-of-connected-iot-devices-will-surge-to-125-billion-by-2030-ihs-markit-says"}, {"url": "https://www.cisco.com/c/dam/en/us/products/collateral/se/internet-of-things/at-a-glance-c45-731471.pdf", "anchor_text": "https://www.cisco.com/c/dam/en/us/products/collateral/se/internet-of-things/at-a-glance-c45-731471.pdf"}, {"url": "https://medium.com/tag/deeplearning?source=post_page-----6e5913996e1---------------deeplearning-----------------", "anchor_text": "Deeplearning"}, {"url": "https://medium.com/tag/machinelearning?source=post_page-----6e5913996e1---------------machinelearning-----------------", "anchor_text": "Machinelearning"}, {"url": "https://medium.com/tag/edge-computing?source=post_page-----6e5913996e1---------------edge_computing-----------------", "anchor_text": "Edge Computing"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6e5913996e1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6e5913996e1---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e5913996e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&user=Sabina+Pokhrel&userId=7b40806ab7c7&source=-----6e5913996e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e5913996e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&user=Sabina+Pokhrel&userId=7b40806ab7c7&source=-----6e5913996e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e5913996e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6e5913996e1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6e5913996e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6e5913996e1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6e5913996e1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6e5913996e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6e5913996e1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6e5913996e1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6e5913996e1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6e5913996e1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6e5913996e1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6e5913996e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sabinaa.pokhrel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sabinaa.pokhrel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sabina Pokhrel"}, {"url": "https://medium.com/@sabinaa.pokhrel/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b40806ab7c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&user=Sabina+Pokhrel&userId=7b40806ab7c7&source=post_page-7b40806ab7c7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4c2aaf61f107&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-compression-needs-and-importance-6e5913996e1&newsletterV3=7b40806ab7c7&newsletterV3Id=4c2aaf61f107&user=Sabina+Pokhrel&userId=7b40806ab7c7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}