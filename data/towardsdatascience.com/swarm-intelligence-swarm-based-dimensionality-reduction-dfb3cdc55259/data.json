{"url": "https://towardsdatascience.com/swarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259", "time": 1683003002.8877928, "path": "towardsdatascience.com/swarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259/", "webpage": {"metadata": {"title": "Swarm Intelligence \u2014 Swarm-Based Dimensionality Reduction | by Elie Zaccour | Towards Data Science", "h1": "Swarm Intelligence \u2014 Swarm-Based Dimensionality Reduction", "description": "Abstract \u2014 A swarm-based approach for dimensionality reduction, inspired by swarm intelligence (SI) and principal component analysis (PCA). It uses a vectorized implementation of particle swarm\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Abstract \u2014 A swarm-based approach for dimensionality reduction, inspired by swarm intelligence (SI) and principal component analysis (PCA). It uses a vectorized implementation of particle swarm optimization (PSO) for higher computational efficiency. The model is benchmarked against standard PCA.", "Technology has evolved tremendously over the years, with the technology access gap shrinking year by year as individuals and businesses are more capable of accessing higher processing and compute capabilities, larger memory capacities, smarter and more efficient data storage technologies, and so on, whether it\u2019s on-premise or in the cloud. Despite this, data volume is growing exponentially and this trend is expected to continue in the foreseeable future. Therefore, the need for reducing the dimensionality of massive data sets is one of the most important aspects of creating more efficient machine learning models.", "The goal is to produce a new data set with a lower dimensionality, yet without losing much of its original characteristics. As in PCA, we\u2019ll use the covariance matrix to determine variances and covariances.", "Consider a data set made up of N features and M observations. It can be described as a series of N-dimensional vectors, represented as an M*N matrix.", "where i \u2208 {0, \u2026, M} and j \u2208 {0, \u2026, N}. The covariance matrix of X is obtained by subtracting the mean from the data and multiplying it by its transpose, then dividing by the number of samples. This is crucial so that the features of different scales are interpreted equally. It is given by:", "If the mean over the features has been already deducted, the covariance matrix can be written as:", "Note that you may come across slightly different versions of the notation of C_x, especially that we\u2019re using row vectors to represent the data while most citations represent the data as column vectors, which permutes the dot product elements. Nonetheless, you get the same result using both approaches.", "The reason we are interested in the covariance matrix is that it describes the variance within the data set as well as the inter-element covariance. Visually, the main diagonal elements hold the variance while the covariance information spans across the off-diagonal elements. For example, given a 3-dimensional data set with features labeled {x, y, z}, we get the following representation:", "The purpose of PCA is to find a linear transformation that, given X, generates a lower-dimensional data set Y. Ultimately, we are looking for another basis that is linearly correlated with the original basis and can more efficiently represent the data. This can be expressed as:", "where P is the linear transformation matrix. Having this in mind, principal component analysis sets two main goals upon which to transform the data, which are:", "In practice, we need to optimize the linear transformation P such that the produced data set Y more efficiently represents the data, in terms of accentuating data signals and suppressing noisy or redundant signals. For this, we need to maximize the main diagonal elements and minimize the off-diagonal elements of the corresponding covariance matrix C_y.", "As it is clear by now, this is a maximization/minimization problem, which is a perfect fit for optimization algorithms, among which is the swarm intelligence model which we will use to fit the lower-dimensional data set Y into an optimal covariance matrix C_y.", "We will use a similar notation here as that described previously, with slight variations to adapt to swarm-based and vectorized computation. We define the following notation for the lower-dimensional data:", "where X is a batch of Np inputs and each input is of dimensions M*N as described previously.", "We define Y as a batch of Np outputs where each output is of dimensions M*K with K\u2208 R and K<N, and P a batch of Np transformation matrices of dimensions N*K. The set of transformation matrices are the particles to be trained and fitted to the solution.", "Following this pattern, and referring to the C_y definition, we conclude that the vectorized covariance matrix C_y would have dimensions Np*K*K.", "The fitness function must reflect the accuracy of our data set in terms of keeping as much as possible of the original data characteristics and eliminating redundant or noisy data. We will propose two approaches for fitness evaluation, one of which is taken from the literature, while the other has proven to outperform it on the Iris data set and thus will be used.", "We can define fitness as the signal-to-noise ratio (SNR) [1]:", "where \u03c3_signal represents the variance and \u03c3_noise represents the covariance. A high SNR (\u226b 1) indicates high precision data, while a low SNR indicates noise-contaminated data. Note that fitness in this context is a real positive number SNR\u22650 and not a percentage or a bounded number. To ensure the signal is maximized (variance \u2192+\u221e) and noise is canceled out (covariance \u21920), we define the SNR as:", "By using the SNR definition above as our fitness function, the model would punish low variances and high covariances. We\u2019re using a logarithmic scale for better fitness interpretability.", "Another approach that outperformed the SNR metric on the Iris data set prediction is by considering the fitness function as the weighted sum of the variances and covariances:", "where \u03b1_1 and \u03b1_2 are weighting coefficients that control the contribution of each term. For instance, to further optimize towards punishing low variances, you could use \u03b1_1=5 and \u03b1_2=1.", "Once fitness is evaluated, the particles are moved to scan for a better solution, i.e. one that achieves a higher fitness score. Particle movement is governed by the following equation, which moves the particles towards the directions of their personal best p and the global best g.", "where v[i] represents the velocity of the np-th N*K-dimensional particle for epoch i, with np \u2208 {0;Np}, v[i-1] the velocity in the previous epoch, R_1 and R_2 Np N*K-dimensional matrices of uniformly distributed random numbers, and finally \u03c9 a weighting coefficient controlling the contribution of the previous velocity to the new one.", "The above performs a vectorized computation of the velocities for Np particles. After that, we compute the new values for the particles knowing the velocity of each:", "Once particles are moved, we can reassess the fitness scores and update the personal best and global best. This is done several times until a termination criterion is met. The final global best solution is the optimal transformation matrix upon which we could retrieve a lower-dimensional representation Y of the original data set X.", "We\u2019ll evaluate the model by its data expressibility. The expressibility of the lower-dimensional data set will be measured in terms of the weighted variance and covariance summation, but it can also be measured in terms of the signal-to-noise ratio described previously.", "A sample test of 1000 runs of SBDR on the Iris data set, with 100 epochs and 40 particles each, achieved an average fitness score of 5.87, while standard PCA scored a fitness of 1.96. The graph below shows the performance of SBDR expressed in terms of the fitness score, showing it side by side with standard PCA.", "Additionally, the generated data set was used to train a Random Forest model on that data set and make predictions on a test set. Standard PCA achieved a prediction accuracy of 80% while SBDR achieved an average accuracy of 86.5% across the 1000 runs.", "If you made it this far, thank you for sticking around!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdfb3cdc55259&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@eliezaccour?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@eliezaccour?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "Elie Zaccour"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fad4b18dd16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&user=Elie+Zaccour&userId=5fad4b18dd16&source=post_page-5fad4b18dd16----dfb3cdc55259---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdfb3cdc55259&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdfb3cdc55259&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/b7MZ6iGIoSI", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----dfb3cdc55259---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dfb3cdc55259---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/swarm-intelligence?source=post_page-----dfb3cdc55259---------------swarm_intelligence-----------------", "anchor_text": "Swarm Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dfb3cdc55259---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/technology?source=post_page-----dfb3cdc55259---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdfb3cdc55259&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&user=Elie+Zaccour&userId=5fad4b18dd16&source=-----dfb3cdc55259---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdfb3cdc55259&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&user=Elie+Zaccour&userId=5fad4b18dd16&source=-----dfb3cdc55259---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdfb3cdc55259&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdfb3cdc55259&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dfb3cdc55259---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dfb3cdc55259--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@eliezaccour?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@eliezaccour?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Elie Zaccour"}, {"url": "https://medium.com/@eliezaccour/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fad4b18dd16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&user=Elie+Zaccour&userId=5fad4b18dd16&source=post_page-5fad4b18dd16--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F5fad4b18dd16%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fswarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259&user=Elie+Zaccour&userId=5fad4b18dd16&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}