{"url": "https://towardsdatascience.com/logistic-regression-explained-593e9ddb7c6c", "time": 1683004045.8956952, "path": "towardsdatascience.com/logistic-regression-explained-593e9ddb7c6c/", "webpage": {"metadata": {"title": "Logistic Regression \u2014 Explained. Detailed theoretical explanation and\u2026 | by Soner Y\u0131ld\u0131r\u0131m | Towards Data Science", "h1": "Logistic Regression \u2014 Explained", "description": "Logistic regression is a supervised learning algorithm which is mostly used for binary classification problems. Although \u201cregression\u201d contradicts with \u201cclassification\u201d, the focus here is on the word\u2026"}, "outgoing_paragraph_urls": [{"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/", "paragraph_index": 45}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14", "paragraph_index": 45}], "all_paragraphs": ["Logistic regression is a supervised learning algorithm which is mostly used for binary classification problems. Although \u201cregression\u201d contradicts with \u201cclassification\u201d, the focus here is on the word \u201clogistic\u201d referring to logistic function which does the classification task in this algorithm. Logistic regression is a simple yet very effective classification algorithm so it is commonly used for many binary classification tasks. Customer churn, spam email, website or ad click predictions are some examples of the areas where logistic regression offers a powerful solution.", "The basis of logistic regression is the logistic function, also called the sigmoid function, which takes in any real valued number and maps it to a value between 0 and 1.", "Logistic regression model takes a linear equation as input and use logistic function and log odds to perform a binary classification task. Before going in detail on logistic regression, it is better to review some concepts in the scope probability.", "Probability measures the likelihood of an event to occur. For example, if we say \u201cthere is a 90% chance that this email is spam\u201d:", "Odds is the ratio of the probabilities of positive class and negative class.", "Log odds is the logarithm of odds.", "All these concepts essentially represent the same measure but in different ways. In the case of logistic regression, log odds is used. We will see the reason why log odds is preferred in logistic regression algorithm.", "Probability of 0,5 means that there is an equal chance for the email to be spam or not spam. Please note that the log odds of probability 0,5 is 0. We will use that.", "Let\u2019s go back to the sigmoid function and show it in a different way:", "Taking the natural log of both sides:", "In equation (1), instead of x, we can use a linear equation z:", "Assume y is the probability of positive class. If z is 0, then y is 0,5. For positive values of z, y is higher than 0,5 and for negative values of z, y is less than 0,5. If the probability of positive class is more than 0,5 (i.e. more than 50% chance), we can predict the outcome as a positive class (1). Otherwise, the outcome is a negative class (0).", "Note: In binary classification, there are many ways to represent two classes such as positive/negative, 1/0, True/False.", "The table below shows some values of z with corresponding y (probability) values. All real numbers are mapped between 0 and 1.", "If we plot this function, we will get the famous s shaped graph of logistic regression:", "The classification problem comes down to solving a linear equation:", "Parameters of the function are determined in training phase with maximum-likelihood estimation algorithm. Then, for any given values of independent variables (x1, \u2026 xn), the probability of positive class can be calculated.", "We can use the calculated probability \u2018as is\u2019. For example, the output can be a probability that the email is spam is 95% or the probability that customer will click on this ad is 70%. However, in most cases, probabilities are used to classify data points. If the probability is greater than 50%, the prediction is positive class (1). Otherwise, the prediction is negative class (0).", "Everything seems ok up until now except for one issue. It is not always desired to choose positive class for all probability values higher than 50%. Regarding the spam email case, we have to be almost sure in order to classify an email as spam. Since emails detected as spam directly go to spam folder, we do not want the user to miss important emails. Emails are not classified as spam unless we are almost sure. On the other hand, when classification in a health-related issue requires us to be much more sensitive. Even if we are a little suspicious that a cell is malignant, we do not want to miss it. So the value that serves as a threshold between positive and negative class is problem-dependent. Good thing is that logistic regression allows us to adjust this threshold value.", "If we set a high threshold (i.e. 95%), almost all the predictions we made as positive will be correct. However, we will miss some of the positive class and label them as negative.", "If we set a low threshold (i.e. 30%), we will predict almost all the positive classes correctly. However, we will classify some of the negative classes as positive.", "Both of these cases will affect the accuracy of our model. The simplest way to measure accuracy is:", "However, this is usually not enough to evaluate classification models. In some binary classification tasks, there is an imbalance between positive and negative classes. Think about classifying tumors as malignant and benign. Most of the target values (tumors) in the dataset will be 0 (benign) because malignant tumors are very rare compared to benign ones. A typical set would include more than 90% benign (0) class. So if the model predicts all the examples as 0 without making any calculation, the accuracy is more than 90%. It sounds good but is useless in this case. Therefore, we need other measures to evaluate classification models. These measures are precision and recall.", "First, we need to define some terms:", "True positive: Correctly predict positive (1) class", "False positive: Predict negative (0) class as positive", "True negative: Correctly predict negative (0) class", "False negative: Predict positive class (0) as negative", "It is desired to make a prediction that is either TP or TN so the models aim to maximize TP and TN values.", "Precision measures how good our model is when the prediction is positive.", "Recall measures how good our model is at correctly predicting positive classes.", "We cannot try to maximize both precision and recall because there is a trade-off between them. The figures below clearly explain the trade-off:", "In both tables, there are 8 negative (0) classes and 11 positive (1) classes. The prediction of the model and hence precision and recall change according to the threshold values. The precision and recall values are calculated as below:", "Increasing precision decreases recall and vice versa. You can aim to maximize precision or recall depending on the task. For an email spam detection model, we try to maximize precision because we want to be correct when an email is detected as spam. We do not want to label a normal email as spam (i.e. false positive). If false positive is low, then precision is high.", "There is another measure that combines precision and recall into a single numbet: F1_score. It is the weighted average of precision and recall and calculated as:", "F1_score is a more useful measure than accuracy for problems with uneven class distribution because it takes into account both false positive and false negatives.", "Note: L2 regularization is used in logistic regression models by default (like ridge regression). The regularization is controlled by C parameter. Because of this regularization, it is important to normalize features (independent variables) in a logistic regression model.", "I will use one of the datasets available under datasets module of scikit-learn. I will import the dataset and dependencies:", "Then load the dataset and divide into train and test sets:", "Create a logistic regression object and fit train data to it.", "Then predict the target variable in test dataset:", "Scikit-learn provides classification_report function to calculate precision, recall and f1-score at the same time. It also shows the number of positive and negative classes in the support column.", "It is worth noting that data preparation, model creation and evaluation in real life projects are extremely complicated and time-consuming compared to this very simple example. I just wanted to show you the steps of model creation. In real-life cases, most of your time will be spent on data cleaning and preparation (assuming data collection is done by someone else). You will also need to spend a good amount of time on the accuracy of your model with hyperparameter tuning and re-evaluating many times.", "Thank you for reading. Please let me know if you have any feedback.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Top 10 Writer in AI and Data Science | linkedin.com/in/soneryildirim/ | twitter.com/snr14"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F593e9ddb7c6c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sonery.medium.com/?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----593e9ddb7c6c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F593e9ddb7c6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F593e9ddb7c6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/naive-bayes-classifier-explained-50f9723571ed", "anchor_text": "Naive Bayes Classifier \u2014 Explained"}, {"url": "https://towardsdatascience.com/support-vector-machine-explained-8d75fe8738fd", "anchor_text": "Support Vector Machine \u2014 Explained"}, {"url": "https://towardsdatascience.com/decision-tree-and-random-forest-explained-8d20ddabc9dd", "anchor_text": "Decision Trees and Random Forests \u2014 Explained"}, {"url": "https://towardsdatascience.com/gradient-boosted-decision-trees-explained-9259bd8205af", "anchor_text": "Gradient Boosted Decision Trees \u2014 Explained"}, {"url": "https://developers.google.com/machine-learning/crash-course/logistic-regression/calculating-a-probability", "anchor_text": "https://developers.google.com/machine-learning/crash-course/logistic-regression/calculating-a-probability"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----593e9ddb7c6c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----593e9ddb7c6c---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/data-science?source=post_page-----593e9ddb7c6c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/supervised-learning?source=post_page-----593e9ddb7c6c---------------supervised_learning-----------------", "anchor_text": "Supervised Learning"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----593e9ddb7c6c---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F593e9ddb7c6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----593e9ddb7c6c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F593e9ddb7c6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----593e9ddb7c6c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F593e9ddb7c6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F593e9ddb7c6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----593e9ddb7c6c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----593e9ddb7c6c--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://sonery.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21K Followers"}, {"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/"}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7cdf5377373a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-explained-593e9ddb7c6c&newsletterV3=2cf6b549448&newsletterV3Id=7cdf5377373a&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}