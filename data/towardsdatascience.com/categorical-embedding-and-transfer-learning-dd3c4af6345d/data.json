{"url": "https://towardsdatascience.com/categorical-embedding-and-transfer-learning-dd3c4af6345d", "time": 1683000885.5226638, "path": "towardsdatascience.com/categorical-embedding-and-transfer-learning-dd3c4af6345d/", "webpage": {"metadata": {"title": "Categorical Embedding and Transfer Learning | by Deepak Mishra | Towards Data Science", "h1": "Categorical Embedding and Transfer Learning", "description": "A lot of machine learning algorithms can not deal with categorical variables directly unless they are converted to numbers. However, the problem is that their performance varies significantly by the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Categorical_variable", "anchor_text": "categorical variable", "paragraph_index": 1}, {"url": "https://forums.fast.ai/t/embedding-layer-size-rule/50691", "anchor_text": "square root of N", "paragraph_index": 10}, {"url": "https://draup.com/", "anchor_text": "Draup", "paragraph_index": 15}], "all_paragraphs": ["A lot of machine learning algorithms can not deal with categorical variables directly unless they are converted to numbers. However, the problem is that their performance varies significantly by the way these categorical variables are encoded into numbers. This article explores the problem of categorical encoding and gives a glimpse of the old and new methods.", "A categorical variable is a variable that can take one of the possible fixed and mostly limited set of values. They are associated with features that are qualitative and thus cannot be measured. For example, the day of the week is a categorical variable that can take 7 discrete values. The words/tokens of any language are categorical variables. Machine Learning algorithms are devoted to working with numbers so we have to convert these categorical variables to numbers to please the algorithms. This process is full of pitfalls and we run the risk of losing a lot of information.", "Let\u2019s take a look at a couple of common ways to convert categories into numbers and the problems that are associated with them.", "In this process, we assign a discrete number to each unique category using some defined process. For example, we can sort the variables in order of the number of occurrences and number them in increasing order. Another way is to randomly assign a number to each unique category.", "In the above example, the days are labeled in the order of their appearance in the data. The major problems here are:-", "In this scheme, we split the categorical variable into separate binary variables (1 variable for each unique category) such that each new variable is set to 1 when the example belongs to a particular category and 0 otherwise. The below example will make things clear.", "The major problems here are similar to Label Encoding. The natural order is lost and so is the relationship between each unique category.", "The problem with losing the natural order is that the algorithm(linear models) tries to generalize by assuming an order in each variable, whereas tree-based algorithms have to do multiple splits to overcome the wrong ordering.", "An embedding is a vector representation of a categorical variable. For example, we could represent the days of the week with 4 floating-point numbers each.", "Here Monday and Tuesday are quite similar to each other yet both are very different from Sunday. This is a toy example but we get similar embeddings in practice which capture rich information and relationships between categories.", "An embedding matrix is an NxM matrix of floating-point numbers. Here N is the number of unique categories and M is the embedding dimension. We decide to choose the value of M, where I usually set the value of M equal to the square root of N to begin with and then increase or decrease it if the need be. In practice, an embedding matrix is a lookup table for a vector. Each row of an embedding matrix is a vector for a unique category.", "To learn embeddings we create a task that uses these embeddings as features and interact with other features to learn over a set of examples. Let me explain this with the example that started the era of embeddings; Word Vectors.", "Word Vectors are embedding vectors for each word of a language. The whole idea of word vectors is that words that appear closer in a sentence are closer to each other in general. The embeddings are n-dimensional vectors. Each dimension captures certain attributes/properties of each word, so closer the properties,d closer the words. To learn word vectors we create a set of pairs of words that occur within a small window of words (say 5 words) as positive examples and set of pairs of words that do not occur in that window as negative examples.", "When we train the above neural network on a large enough dataset, the model learns to predict if two words are related or not. However, the byproduct of this model is the embedding matrix which is an information-rich vector representation of each word in the vocabulary.", "The above section served as a primer to bring across the point that a neural network can learn meaningful vector representations for categorical variables if we define a meaningful task. However, the above example doesn\u2019t deal with a usual categorical dataset so let\u2019s look at some tabular data.", "At Draup, we analyze Job Descriptions(JDs) of various organizations. Each JD has the following fields:-", "Each JD is tagged to one of the 18 Business Functions defined internally. The dataset looks something like the below table.", "In the above dataset, all the columns have categorical values with a lot of unique values each. To build categorical embeddings, we need 2 things:-", "We built a deep learning model to predict the Business Function of a JD using the other 4 variables (Skill, Location, Company, Job Role).", "The below image shows the model built for the business function prediction task.", "We trained the above model on millions of JDs that reaches an accuracy of over 85%. However, squeezing maximum accuracy from the model was not the intent of this model (Not to mention that this model by itself is quite useful). We were more interested in the byproducts of this model. The embeddings of all categorical input variables. The below image visualizes the Job Role Embeddings learned by the model using t-SNE.", "I like to think of this process as a mutual information exchange between variables. Below, I present a discussion with a small subset of data.", "The above examples are oversimplified and are presented just to bring some intuition, thus should be taken with a grain of salt.", "Transfer learning is a technique where knowledge gathered from one task/model is used in another task of similar nature.", "The most obvious use-case of transfer learning is when we want to model task A but have a small dataset however we have a large dataset for a similar task B.", "We build a model for the task where we have an abundance of data and then reuse the model weights (in case of Embeddings) or a subset of the model (Usually seen in computer vision problems and more recently in NLP).", "Draup is an HR tech platform. The section of the platform shows demographic information segregated on various Job Roles.", "The task was to predict the number of people working in a Job Role at every particular location.", "The total Job Role \u2014 Location combinations total to around 300,000. However, the number of training examples were around 10,000. We built a deep learning model and reused the embeddings learned in the Business Function prediction task. Apart from embeddings, we also used a few other numeric features to train the model.", "The model performed incredibly well with the transferred embeddings and achieved an r2 score of over 0.9.", "We discussed that machine learning models feel at home with numeric variables but struggle with categorical variables. Traditional techniques for handling categorical variables kind of works but limits the capabilities of algorithms. However, under the right circumstances, we can use categorical embeddings learned from other tasks or learn entirely new embeddings to improve model performance. Categorical embeddings generally perform quite well as they have a sense of similarity and dissimilarity amongst themselves thus helping the models to generalize better.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I like to explore anything that interests me. Here is the fun part, I never know what might interest me."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdd3c4af6345d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://skilp4d.medium.com/?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": ""}, {"url": "https://skilp4d.medium.com/?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "Deepak Mishra"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbeb5f069b511&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&user=Deepak+Mishra&userId=beb5f069b511&source=post_page-beb5f069b511----dd3c4af6345d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd3c4af6345d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd3c4af6345d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Categorical_variable", "anchor_text": "categorical variable"}, {"url": "https://forums.fast.ai/t/embedding-layer-size-rule/50691", "anchor_text": "square root of N"}, {"url": "https://draup.com/", "anchor_text": "Draup"}, {"url": "https://arxiv.org/pdf/1604.06737.pdf", "anchor_text": "Entity Embedding Paper"}, {"url": "http://contrib.scikit-learn.org/categorical-encoding/", "anchor_text": "Common categorical encoders"}, {"url": "https://forums.fast.ai/t/embedding-layer-size-rule/50691", "anchor_text": "How to choose embedding dimension size"}, {"url": "https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf", "anchor_text": "Word2Vec Negative Sampling Paper"}, {"url": "http://ruder.io/transfer-learning/", "anchor_text": "Transfer Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dd3c4af6345d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/embedding?source=post_page-----dd3c4af6345d---------------embedding-----------------", "anchor_text": "Embedding"}, {"url": "https://medium.com/tag/transfer-learning?source=post_page-----dd3c4af6345d---------------transfer_learning-----------------", "anchor_text": "Transfer Learning"}, {"url": "https://medium.com/tag/classification?source=post_page-----dd3c4af6345d---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/regression?source=post_page-----dd3c4af6345d---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd3c4af6345d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&user=Deepak+Mishra&userId=beb5f069b511&source=-----dd3c4af6345d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd3c4af6345d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&user=Deepak+Mishra&userId=beb5f069b511&source=-----dd3c4af6345d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd3c4af6345d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdd3c4af6345d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dd3c4af6345d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dd3c4af6345d--------------------------------", "anchor_text": ""}, {"url": "https://skilp4d.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://skilp4d.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Deepak Mishra"}, {"url": "https://skilp4d.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "76 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbeb5f069b511&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&user=Deepak+Mishra&userId=beb5f069b511&source=post_page-beb5f069b511--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fbeb5f069b511%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-embedding-and-transfer-learning-dd3c4af6345d&user=Deepak+Mishra&userId=beb5f069b511&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}