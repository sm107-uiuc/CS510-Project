{"url": "https://towardsdatascience.com/i-built-a-music-sheet-transcriber-heres-how-74708fe7c04c", "time": 1683001619.543712, "path": "towardsdatascience.com/i-built-a-music-sheet-transcriber-heres-how-74708fe7c04c/", "webpage": {"metadata": {"title": "I Built a Music Sheet Transcriber \u2014 Here\u2019s How | by Haohui | Towards Data Science", "h1": "I Built a Music Sheet Transcriber \u2014 Here\u2019s How", "description": "The fields of machine learning and deep learning have undergone enormous transformations in the past few years and have brought about many useful applications in many areas. One area of interest is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.mdpi.com/2076-3417/8/4/606", "anchor_text": "End-to-End Neural Optical Music Recognition of Monophonic Scores", "paragraph_index": 3}, {"url": "https://mediatum.ub.tum.de/doc/1292048/file.pdf", "anchor_text": "Connectionist Temporal Classification (CTC) loss function", "paragraph_index": 4}, {"url": "https://www.mdpi.com/2076-3417/8/4/606/htm", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://github.com/liuhh02/web-omr", "anchor_text": "here", "paragraph_index": 7}, {"url": "https://github.com/calvozaragoza/tf-deep-omr", "anchor_text": "Github", "paragraph_index": 8}, {"url": "https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip", "anchor_text": "semantic model", "paragraph_index": 8}, {"url": "https://github.com/calvozaragoza/tf-deep-omr/blob/master/Data/vocabulary_semantic.txt", "anchor_text": "semantic vocabulary", "paragraph_index": 8}, {"url": "https://www.fontsquirrel.com/fonts/aaargh", "anchor_text": "Aaargh.ttf", "paragraph_index": 8}, {"url": "https://github.com/calvozaragoza/tf-deep-omr", "anchor_text": "Github repository", "paragraph_index": 8}, {"url": "https://grfia.dlsi.ua.es/primus/", "anchor_text": "PrIMuS dataset", "paragraph_index": 8}, {"url": "https://github.com/calvozaragoza/tf-deep-omr/blob/master/ctc_predict.py", "anchor_text": "predict.py", "paragraph_index": 12}, {"url": "http://flask.palletsprojects.com/en/1.1.x/", "anchor_text": "Flask documentation", "paragraph_index": 15}, {"url": "https://github.com/liuhh02/web-omr/blob/master/app.py", "anchor_text": "my code", "paragraph_index": 15}, {"url": "https://bulma.io/", "anchor_text": "bulma", "paragraph_index": 17}, {"url": "https://machinelearningtutorials.weebly.com/home/i-built-a-music-sheet-transcriber-heres-how", "anchor_text": "here", "paragraph_index": 22}], "all_paragraphs": ["The fields of machine learning and deep learning have undergone enormous transformations in the past few years and have brought about many useful applications in many areas. One area of interest is Optical Music Recognition (OMR). According to Wikipedia, OMR is a field of research that investigates how to computationally read music notation in documents. The goal of OMR is to teach the computer to read and interpret sheet music and produce a machine-readable version of the written music score. So let\u2019s do just that!", "Before I get into the code, I\u2019ll start off with a brief introduction on music notation. Many of us started music by going through the slow and painful process of learning how to read notes. In fact, many people convert the notes into the ABC notation by writing down the letter each note corresponds to on the music sheet.", "Having experienced this process myself, I decided it would be awesome if I could build a web app that could automatically translate the notes into the ABC notation, and annotate the ABC letters onto the sheet of music!", "Thus began my search for appropriate deep learning architectures that could perform this task. Prior to this, I did not have much experience with optical recognition models, so I wasn\u2019t sure if there would be any existing work done on this topic. To my surprise, I found a very wonderful research paper published by Calvo-Zaragoza et al. in 2018 under the title End-to-End Neural Optical Music Recognition of Monophonic Scores in the Applied Sciences Journal. They even curated a dataset: Printed Images of Music Staves (PrIMuS) containing more than 80,000 real scores in common western notation!", "The model proposed by Calvo-Zaragoza et al. consisted of a Convolutional Neural Network (CNN) for feature extraction from the input image, followed by a bidirectional Long Short Term Memory (BLSTM) Network to work with sequences, with a single staff considered one sequence. The output of the last layer of the CNN is connected to the input of the first layer of the BLSTM, forming a Convolutional Recurrent Neural Network (CRNN). The researchers used a special loss function, the Connectionist Temporal Classification (CTC) loss function, which provides a means to optimize the CRNN parameters so that it is likely to give the correct sequence y given an input x. Here, input x represents a single staff image and y is its corresponding sequence of music symbols.", "Note however that the model does not output information about the exact location of each note and only the sequence in which the notes appear. Nevertheless, this isn\u2019t really important because although music readers might not know which note corresponds to which letter, they will be able to follow based on the number of letters outputted.", "For more information about the CRNN architecture and experiment details, check out their paper here for more information.", "If you just want to get to the code, click here.", "Alright, so now that we have briefly gone through the model architecture, it is now time for the implementation! The researchers have uploaded their models, implemented in Tensorflow, and code onto Github. On the basis of that, I was able to quickly set up the model and get ready to deploy it on the web. Firstly, make sure you have tensorflow v1, flask and OpenCV installed. Then, download the semantic model trained by the researchers as well as the semantic vocabulary. Also download the font Aaargh.ttf as it is needed to annotate the image with the ABC notation. (If you want to train the model yourself, head over to the tensorflow model Github repository for instructions and download the PrIMuS dataset). The semantic vocabulary is basically a dictionary that maps the integer representation into the actual note, such as how index 348 gives you note-A2_quarter. However, because the vocabulary of the model contains way more information than needed (such as time signature, barline and so on) which do not have to be annotated since the player can simply see it on the score itself without requiring any musical background knowledge, I postprocessed the outputs of the model to only include the ABC letters with the following code:", "Luckily, all the notes were marked with \u201cnote-\u201d as the first 5 characters so it was easy to only grab those pertaining the ABC letters.", "Having obtained the array containing the relevant notes, I then used the PIL ( Python Imaging Library) library to annotate the notes onto the picture itself. This involved creating a new completely white image with the same width and 1.5 times the height of the original image to extend the original image. I then copied the original image onto the white image using the Image.paste() function. Having extended the original image with white space below, I could then print the ABC letters to go below the stave.", "As mentioned earlier, the model doesn\u2019t contain information about the exact location of each note and instead only prints out a sequence of letters, so I had to do some calculations to make the ABC letters line up quite nicely below the stave. It doesn\u2019t align perfectly, which is definitely an area for future improvement, but it isn\u2019t a huge problem since music players would know which letter corresponds to which note by virtue of the order of appearance.", "On the basis of the tensorflow predict.py code provided by the researchers, I implemented my web app using Flask. Flask is a really handy web application framework that enables everyone to port their python code onto a web app in the shortest time possible. All Flask requires is your main python code, the html files and css templates and you\u2019re good to go!", "The Flask python file only requires you to make some minor additions to your current machine learning python file. Firstly, you have to add the line", "to above your machine learning code after importing Flask to create an instance of the Flask class for the web app. Then, you add the following line to the back:", "When python runs the file, it assigns the name \"__main__\" to the script. Hence, __name == \"__main__\" is satisfied and app.run() executes. After this, you would have to define some functions and map them to some routes, such as defining how the user will be redirected to /predict containing the annotated music sheet after they upload the music sheet. Check out the Flask documentation and my code for more information.", "Now that the python file is set up nicely, all that is left are the html files and css files. The folder structure is typically as follows:", "In this project, the website is stylized with bulma, a great open source CSS framework that I highly recommend to everyone! It is simple to use, doesn\u2019t require much, if any, Javascript and looks really good.", "\u200bThere are some additional files required for this project \u2014 the deep learning model, semantic vocabulary file, font, and any images you have that you want to test. So if you have downloaded all the files, you should organize your folders as such:", "And that\u2019s it! Once everything has been set up as above, head over to your terminal / command prompt. Change the directory to the directory with your app.py file and run python app.py. Wait for a few seconds and you should receive a message on the link you should go to in order to view the web app. Go to the URL, upload your music sheet and get the result! The annotated sheet will be saved to the same directory as your app.py file.", "Do note that currently, the model is only able to work with monodic scores ( scores that consist of a single melodic line). So don\u2019t give it too complicated scores!", "Give this a shot! I hope you have fun with it, and tell me how it goes! If you have any other awesome ideas on how to use this model, do also share in the comments section!", "This article has also been published here in my blog.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine learning enthusiast working on the next big project"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F74708fe7c04c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@liuhh02?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@liuhh02?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "Haohui"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F500dff1f8d3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&user=Haohui&userId=500dff1f8d3b&source=post_page-500dff1f8d3b----74708fe7c04c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74708fe7c04c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74708fe7c04c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.mdpi.com/2076-3417/8/4/606", "anchor_text": "End-to-End Neural Optical Music Recognition of Monophonic Scores"}, {"url": "https://mediatum.ub.tum.de/doc/1292048/file.pdf", "anchor_text": "Connectionist Temporal Classification (CTC) loss function"}, {"url": "https://www.mdpi.com/2076-3417/8/4/606/htm", "anchor_text": "the paper"}, {"url": "https://www.mdpi.com/2076-3417/8/4/606/htm", "anchor_text": "here"}, {"url": "https://github.com/liuhh02/web-omr", "anchor_text": "here"}, {"url": "https://github.com/calvozaragoza/tf-deep-omr", "anchor_text": "Github"}, {"url": "https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip", "anchor_text": "semantic model"}, {"url": "https://github.com/calvozaragoza/tf-deep-omr/blob/master/Data/vocabulary_semantic.txt", "anchor_text": "semantic vocabulary"}, {"url": "https://www.fontsquirrel.com/fonts/aaargh", "anchor_text": "Aaargh.ttf"}, {"url": "https://github.com/calvozaragoza/tf-deep-omr", "anchor_text": "Github repository"}, {"url": "https://grfia.dlsi.ua.es/primus/", "anchor_text": "PrIMuS dataset"}, {"url": "https://github.com/calvozaragoza/tf-deep-omr/blob/master/ctc_predict.py", "anchor_text": "predict.py"}, {"url": "http://flask.palletsprojects.com/en/1.1.x/", "anchor_text": "Flask documentation"}, {"url": "https://github.com/liuhh02/web-omr/blob/master/app.py", "anchor_text": "my code"}, {"url": "https://bulma.io/", "anchor_text": "bulma"}, {"url": "https://machinelearningtutorials.weebly.com/home/i-built-a-music-sheet-transcriber-heres-how", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----74708fe7c04c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----74708fe7c04c---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----74708fe7c04c---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/ai?source=post_page-----74708fe7c04c---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/music?source=post_page-----74708fe7c04c---------------music-----------------", "anchor_text": "Music"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74708fe7c04c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&user=Haohui&userId=500dff1f8d3b&source=-----74708fe7c04c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74708fe7c04c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&user=Haohui&userId=500dff1f8d3b&source=-----74708fe7c04c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74708fe7c04c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F74708fe7c04c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----74708fe7c04c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----74708fe7c04c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----74708fe7c04c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----74708fe7c04c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@liuhh02?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@liuhh02?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Haohui"}, {"url": "https://medium.com/@liuhh02/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "210 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F500dff1f8d3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&user=Haohui&userId=500dff1f8d3b&source=post_page-500dff1f8d3b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F64817874ddcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-built-a-music-sheet-transcriber-heres-how-74708fe7c04c&newsletterV3=500dff1f8d3b&newsletterV3Id=64817874ddcf&user=Haohui&userId=500dff1f8d3b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}