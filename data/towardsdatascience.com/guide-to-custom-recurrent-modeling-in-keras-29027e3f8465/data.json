{"url": "https://towardsdatascience.com/guide-to-custom-recurrent-modeling-in-keras-29027e3f8465", "time": 1683016449.63697, "path": "towardsdatascience.com/guide-to-custom-recurrent-modeling-in-keras-29027e3f8465/", "webpage": {"metadata": {"title": "Guide to Custom Recurrent Modeling in Keras | by Mohit Mayank | Towards Data Science", "h1": "Guide to Custom Recurrent Modeling in Keras", "description": "The initial set of layers for recurrent neural operations universally begins with LSTM, GRU and RNN. But with an increase in the complexity of the task, we should use more complex models. That said\u2026"}, "outgoing_paragraph_urls": [{"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "excellent article", "paragraph_index": 2}, {"url": "https://stats.stackexchange.com/questions/222584/difference-between-feedback-rnn-and-lstm-gru#:~:text=We%20can%20say%20that%2C%20when,Inputs%20as%20per%20trained%20Weights.&text=So%2C%20LSTM%20gives%20us%20the,more%20Complexity%20and%20Operating%20Cost.", "anchor_text": "given way to \u201cbetter\u201d", "paragraph_index": 6}, {"url": "https://gist.github.com/imohitmayank/757a2d878a1510180f134a8c7f45d6dc", "anchor_text": "code here", "paragraph_index": 11}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb", "anchor_text": "IMDB sentiment classification datasets", "paragraph_index": 12}, {"url": "https://www.linkedin.com/in/imohitmayank/", "anchor_text": "LinkedIn", "paragraph_index": 18}, {"url": "http://mohitmayank.com", "anchor_text": "website.", "paragraph_index": 18}], "all_paragraphs": ["The initial set of layers for recurrent neural operations universally begins with LSTM, GRU and RNN. But with an increase in the complexity of the task, we should use more complex models. That said, before moving directly to different and relatively complex models like attention or transformers, we should first ask a simple question \u2014 can we still do something quickly with the basic recurrent layers? In this article, I will focus on the same philosophy that \u2014 we should first exhaust the simple solutions before going for the more complex ones. In the next sections, we will explore the same old set of recurrent layers (albeit with some interesting arrangements) to get better inference on the data. In total, we will discuss 12 such arrangements (including the original set). Finally, we will conclude with testing all of our models on a Text Sentiment Detection task to compare their performance. Let\u2019s get started!", "Before going further, let\u2019s discuss a few topics which we should know to completely appreciate this article. One more thing, I use arrangement and model interchangeably, because all the discussed models are nothing but compositions of basic recurrent layers, which acts as the smallest building blocks.", "Any recurrent layer has the option to return two types of outputs \u2014 (1) Last state output (1 output) and (2) All state output (N outputs). Actually, the 2nd type is more generic as it also contains the last state output (i.e. the 1st type), but usually, popular deep learning library\u2019s implementation provides options to return both the types of outputs. In case of Keras, the default is the 1st type and you can set the parameter return_sequence=True to shift to type 2. Note here, by \"state\" I mean hidden state of the recurrent layer and the N number of output is usually the number of time steps in your dataset. To know more about the internals of the recurrent layers and about the hidden states, I would suggest this excellent article. Now coming back to the topic, what's interesting is that while the 2nd type contains more info (which is usually a good thing), it could also be overwhelming as we don't know what exactly to do with it. As most of the downstream application still needs one output, we end up consolidating all state's output to a single final output (possible techniques \u2014 using AveragePooling or MaxPooling ). And in a way, LSTM or GRU does the same, they use the previous state's output (and current input) to create the next state's output. Then the interesting question is, \"What is better - trusting LSTM/GRU to consolidate the state outputs or applying our own logic?\". We will try to answer this in later sections, for now, let's move forward.", "A recurrent layer takes sequential input and processes them to return one or many outputs (state vectors). Now as the output (if we return all state\u2019s output) also follow the sense of sequence, they can be thought of as some transformed original input and can be passed on to another layer of LSTM/GRU to be further processed. This is called stacking and here the main intuition is that \u2014 just like vanilla Deep Neural Network where you add more dense layers or with CNNs where you add multiple convolution layers one after the another, in recurrent layering you can stack multiple layers one in top of another. Ideally more layers give you more tunable parameters hence more learning power. But be wary of adding too many stacks, as it may lead to overfitting (too complex network for too simple learning requirement). The main question we can ask here is \u201cDoes adding stacking layers results in better performance?\u201d.", "One interesting arrangement is when you have two recurrent layers (they are not stacked), and in one layer data is passed left-to-right for training and this direction is reversed for the other layer. This is the bidirectional recurrent layer and the intuition is that \u2014 in contrast to a normal layer with only forward training and left context, having both left and right context while preparing the state vector output could lead to higher performance. Usually, this is true for tasks where you expect the complete data (bidirectional context) to be present, so this is valid for sentiment detection \u2014 as we have the complete sentence string available, but not true for time-series forecasting \u2014 as we don\u2019t have future date\u2019s data if we want to today\u2019s value (say temperature). As bidirectional systems use 2 recurrent layers, we compare it against the stacking architectures and ask, \u201cWhich is better \u2014 a 2 layer stacked recurrent layer or a bi-directional recurrent layer?\u201d.", "Moving forward, now let\u2019s try to define and group the different arrangements we can create using the models we knew (basic recurrent layers) and the techniques we learned above. At the higher layer, we group all of our arrangements into two broad classes \u2014", "Also, as RNNs have given way to \u201cbetter\u201d recurrent layers, we will only consider LSTM and GRU in our analysis. Now in case of SS, we can use either LSTM or GRU, also we can add flavour by taking only 1 output or N outputs for each. This gives us 2x2=4 different arrangements we may want to consider. Moving forward, in case of MS (only 2 for this article), lets first start with 1 and N outputs. For each such setting, we can either use a 2 layer stacked or a bidirectional LSTM and GRU. This gives us 2x2x2=8 different arrangements. The grouping of all 12 arrangement is shown below. Note, by \"Return Sequence False\" I mean 1 output as you are only returning one output and not the complete sequence.", "Now let us see how we can code up the different arrangements in Keras. For the sake of brevity, I will only show the code for the LSTM recurrent layer. Shifting to GRU is as easy as replacing LSTM with GRU in the code (don\u2019t forget to import GRU though). I will also only cover 4 different varieties as rest can be easily built after minor modifications. Getting started with SS_RSF_LSTM i.e. single stacked \u2014 return sequence false \u2014 LSTM layer \ud83d\ude09", "The only difference here is that we return all state\u2019s output from LSTM. We can do this as follows,", "To have a bidirectional layer, all we need to do is add a Bidirectional function on top of LSTM.", "Note to move to MS_RST_biLSTM you need to do 2 things \u2014 (1) add return_sequence=True inside the LSTM layer, and (2) add the AveragePooling1D logic after the bidirectional LSTM layer as done above.", "The remaining arrangements can be coded up pretty easily by following the hints shared above. I leave this as an exercise and also share the complete code here for reference.", "For testing our models, I have selected IMDB sentiment classification datasets which contain 25,000 highly polar movie reviews with binary sentiment represented by labels 0 and 1. To be little easier on my laptop, I have further trimmed the data by considering only the top 5000 words by frequency and truncating sentence over 100 words. As the data API is exposed by Keras, all of this can be done by,", "Also, Keras has already transformed the words into integer representation, making it easier to be fed to our models. All that\u2019s remaining is to make sure all of the sentences are of the same size, as there could be some sentence with size less than maxlen. This can be done by padding the smaller sentences with a dummy number (say 0). You can add padding on the left or right of the short sentences, I have chosen left. The code to do so is,", "To compare the performance score across all models, we will train each model for a specified number of epochs on the prepared data and report accuracy. To handle variation in case of training, we will repeat the training process multiple times (runs) and also report the variation in accuracy score observed in each run along with max and min scores. Lastly, to make sure that the variation in our model performance is not introduced by random weight initialization, we will use the same initial weights for each run. Then the major difference introduced is in model fitting and its internal train-validation data split.", "Each experiment (for one model) ran 5 times and each time we ran for 5 epochs. In total, we ran 12 such experiments (for all of our models). The consolidated performance report card is shown below,", "Now, let us try to answer the questions we raised before,", "Let me start with a disclaimer \u2014 while I am (or rather the experiment results are) saying that one arrangement works better than another, I am not implying that you should only train \u201cgood\u201d models and ignore the rest. Please remember, every task and its data is different and may result in different result from the ones reported above. Take Bi-direction as an example, usually, I find bi-direction competing toe-to-toe with stacking layers and in some cases even perform better. This is in contrast to what we saw before and that\u2019s going on to prove that every data is different. That said, the purpose of this article was two folds \u2014 (1) to showcase the different varieties of layering arrangements that can be made by just using basic recurrent layers, and (2) based on experiments to help prioritize arrangements rather than ignoring them. So next time you have a text classification project, you can start with MS_RST_LSTM model and with time (if you have) experiments on others.", "Connect with me on LinkedIn or read more such articles on my website.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior Data Scientist | AI/ML Researcher | Creator of \u201cJaal\u201d | Author of \u201cLazy Data Science Guide\u201d | Linkedin & Twitter: @imohitmayank"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F29027e3f8465&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----29027e3f8465--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----29027e3f8465--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mohitmayank.medium.com/?source=post_page-----29027e3f8465--------------------------------", "anchor_text": ""}, {"url": "https://mohitmayank.medium.com/?source=post_page-----29027e3f8465--------------------------------", "anchor_text": "Mohit Mayank"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c8a84675e86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&user=Mohit+Mayank&userId=5c8a84675e86&source=post_page-5c8a84675e86----29027e3f8465---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F29027e3f8465&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F29027e3f8465&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@franki?utm_source=medium&utm_medium=referral", "anchor_text": "Franki Chamaki"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "excellent article"}, {"url": "https://stats.stackexchange.com/questions/222584/difference-between-feedback-rnn-and-lstm-gru#:~:text=We%20can%20say%20that%2C%20when,Inputs%20as%20per%20trained%20Weights.&text=So%2C%20LSTM%20gives%20us%20the,more%20Complexity%20and%20Operating%20Cost.", "anchor_text": "given way to \u201cbetter\u201d"}, {"url": "https://gist.github.com/imohitmayank/757a2d878a1510180f134a8c7f45d6dc", "anchor_text": "code here"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb", "anchor_text": "IMDB sentiment classification datasets"}, {"url": "https://www.linkedin.com/in/imohitmayank/", "anchor_text": "LinkedIn"}, {"url": "http://mohitmayank.com", "anchor_text": "website."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----29027e3f8465---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----29027e3f8465---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----29027e3f8465---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----29027e3f8465---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/keras?source=post_page-----29027e3f8465---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F29027e3f8465&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&user=Mohit+Mayank&userId=5c8a84675e86&source=-----29027e3f8465---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F29027e3f8465&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&user=Mohit+Mayank&userId=5c8a84675e86&source=-----29027e3f8465---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F29027e3f8465&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----29027e3f8465--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F29027e3f8465&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----29027e3f8465---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----29027e3f8465--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----29027e3f8465--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----29027e3f8465--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----29027e3f8465--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----29027e3f8465--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----29027e3f8465--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----29027e3f8465--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----29027e3f8465--------------------------------", "anchor_text": ""}, {"url": "https://mohitmayank.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mohitmayank.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mohit Mayank"}, {"url": "https://mohitmayank.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "930 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5c8a84675e86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&user=Mohit+Mayank&userId=5c8a84675e86&source=post_page-5c8a84675e86--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7840ae6d0ff6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fguide-to-custom-recurrent-modeling-in-keras-29027e3f8465&newsletterV3=5c8a84675e86&newsletterV3Id=7840ae6d0ff6&user=Mohit+Mayank&userId=5c8a84675e86&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}