{"url": "https://towardsdatascience.com/kafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0", "time": 1683014351.420369, "path": "towardsdatascience.com/kafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0/", "webpage": {"metadata": {"title": "Kafka in Action: Building a distributed multi-video processing pipeline with Python and Confluent Kafka | by Neeraj Krishna | Towards Data Science", "h1": "Kafka in Action: Building a distributed multi-video processing pipeline with Python and Confluent Kafka", "description": "Trying to learn any topic by building a project is a fun and intuitive way to reinforce our understanding. In this article we will explore kafka by doing just that. Imagine a scenario where we have\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/simplesteph/kafka-stack-docker-compose", "anchor_text": "kafka-stack-docker-compose", "paragraph_index": 2}, {"url": "https://github.com/wingedrasengan927/Distributed-Multi-Video-Streaming-and-Processing-with-Kafka", "anchor_text": "repo", "paragraph_index": 9}, {"url": "https://robomongo.org/download", "anchor_text": "Robo3T", "paragraph_index": 37}, {"url": "https://cloud.google.com/pubsub/?utm_source=google&utm_medium=cpc&utm_campaign=japac-IN-all-en-dr-bkws-all-all-trial-e-dr-1008074&utm_content=text-ad-crcloudmatrixver01ctr-none-DEV_c-CRE_308495403335-ADGP_Hybrid+%7C+AW+SEM+%7C+BKWS+~+T1+%7C+EXA+%7C+Big+Data+%7C+M:1+%7C+IN+%7C+en+%7C+Cloud+PubSub-KWID_43700029827958853-kwd-395094646964&userloc_1007740&utm_term=KW_google%20pub%20sub&ds_rl=1264446&gclid=EAIaIQobChMIh4zix7CC7AIVT9eWCh2g6Ak7EAAYASAAEgJ5j_D_BwE", "anchor_text": "Google Cloud Pub/Sub", "paragraph_index": 38}, {"url": "https://aws.amazon.com/kinesis/", "anchor_text": "Amazon Kinesis", "paragraph_index": 38}, {"url": "https://www.tensorflow.org/tfx/guide/serving", "anchor_text": "Tensorflow Serving API", "paragraph_index": 40}], "all_paragraphs": ["Trying to learn any topic by building a project is a fun and intuitive way to reinforce our understanding. In this article we will explore kafka by doing just that.", "Imagine a scenario where we have multiple sources generating video streams and we are required to process and store the data in near real-time (diagram above). Kafka is a perfect fit in this case.", "We\u2019ll be using Stephane Maarek\u2019s amazing project kafka-stack-docker-compose to run Kafka in Docker. First, you need to clone the repo:", "And then depending on the cluster configuration you can run the required docker-compose file. In this article we\u2019ll keep it simple and run a cluster with a single zookeeper and a single kafka server. Assuming you have started Docker, run:", "We have now started a Kafka cluster in two simple steps!", "We will be using MongoDB to store the processed data. Again, we will use Docker to run MongoDB. First, we need to create a docker volume which will help us to persist the data in our disk even if we stop and remove the container. To create a volume run:", "data-mongodb is the name of our volume. Next we will start the MongoDB server instance and mount data-mongodb volume to it. run:", "This will automatically pull the MongoDB image and start the container.", "Okay! Now that we have Kafka and MongoDB up and running, let\u2019s dive into the project.", "The code we\u2019ll be using can be found in this repo. Clone the repo into the workspace.", "Next install the necessary dependencies. It\u2019s better to create a separate virtual environment for the project and then install.", "The very first thing we need to do is create a Kafka Topic. To create a topic run:", "Here I\u2019ve created a topic called multi-video-stream with a replication factor of 1 and 3 partitions. You can experiment with the replication factor and number of partitions but remember to change the server configuration in the Admin Client (line 6) accordingly and also note that the number of replicas cannot exceed the number of servers in the cluster.", "The Producer Application reads frames from the videos and publishes them to the Kafka Topic. Let\u2019s walk through the code.", "In the beginning I\u2019ve mentioned that we\u2019ll be working with multiple sources generating video streams. We need a way to simulate this in our local environment. We can do this by using concurrency and processing each video in a thread.", "Kafka Producer is thread safe - we can create a single Producer Instance and share it across multiple threads.", "In the code above I\u2019ve wrapped all the functions into a class and we create a Kafka Producer when we instantiate this class.", "The method publishFrame is responsible for reading frames from the video and publishing them to the Kafka Topic. We are using opencv here for video manipulation. In the call to the produce method we are passing the following arguments:", "Also Note that we\u2019re publishing every 3rd frame and waiting for some time after every frame. This is because in real world we get the frames from the source at a certain fps and there\u2019s not much information difference between every consecutive frame especially in the context of machine learning. It also helps to reduce load on the Kafka server.", "The start method maps each video to a thread and runs the application concurrently.", "To start the Producer Application, put your videos into the video folder, change the extension accordingly in line 47, and then run:", "This will start publishing video frames to the Kafka Topic concurrently. You should see information about the produced message being logged.", "Now let\u2019s look at the other side.", "The consumer application subscribes to the Kafka Topic to recieve data. We run inference on the data through an Image classification model and then store results into a MongoDB database. Let\u2019s walk through the code.", "Consumers operate in a consumer group. Each consumer within a group reads data from exclusive partitions. If there are more consumers within a group than the number of partitions, some consumers will be left inactive.", "In our consumer application we have multiple consumers all belonging to the same group reading data from the Kafka Topic concurrently. Note that unlike Producer, Consumer is not thread safe, each thread needs to have a separate consumer instance.", "We do all the operations from recieving the data to processing and storing it in the method run . First we poll the data from the topic and if there\u2019s no error and the message is valid, we proceed for further processing.", "Note that the consumer polls a batch of messages at once from the topic and stores them in the internal buffer and reads from there.", "Once we recieve the message, we decode it, extract the timestamp and metadata from it and append it to an array.", "If you observe, we are not processing the message one-by-one, but instead we are batching the data and carrying out the operations on the data-batch. This increases efficiency and throughput.", "As soon as a data-batch is formed, we pass it to an Image Classification model which in our case is the ResNet50 model trained on ImageNet. The model outputs labels and their corresponding confidences per frame. We pick only the top label and its confidence and store it.", "Next, we take the results obtained and insert them into the MongoDB database. The way the data is structured in the database is that we have each video as a collection and in each collection, we have records or documents that contain information about the frame. The document has frame number, frame label and confidence as its fields, making it easy to query the data. Also, observe that we are performing a batch insertion into the database as we talked before.", "After this, we are done with the processing of data and we want to inform the same to Kafka. Kafka uses offsets to track the position of the data record polled by the consumer, so even if the consumer goes down, Kafka will be able to read back from where it left off. How we want to commit the offsets and which delivery semantic to follow is left to us. Here we are committing the offsets after the data processing is done. This follows the at least once delivery semantic.", "Note: Since we are committing the offsets manually, in the configuration file we have to set enable.auto.commit property to False", "Note: In at least once delivery semantic there is a chance that a message will be processed again if the consumer goes down or the processing goes wrong. To avoid duplicate messages we have to maintain Idempotent systems. For example, in our case we make sure that we insert a unique document into a collection so that there won\u2019t be any duplicates in the database even if a message is processed again.", "Alright, Let\u2019s get back to the code. To run the consumer application set the topic in line 108, change the video names in line 124 (Quick Note: These will have to match the video names we are publishing through the Producer and also these will be the collection names in the database), make sure the number of consumers do not exceed the number of partitions in line 128, and then run:", "If you launch the Producer Application and Consumer Application simultaneously, it would look something like this side-by-side:", "You can also visualize the data stored in MongoDB. Robo3T is a great tool for that:", "Things can get a lot more complicated in Production. Fortunately we have managed services in the cloud platform like Google Cloud Pub/Sub or Amazon Kinesis that make our jobs easier. It\u2019s preferable to use them in production.", "Also, in this article we didn\u2019t go through the Producer and Consumer Configuration, but it\u2019s really important to tune them based on the use-case. For example, in some cases latency might be a high priority and we might not care about data loss or data order, while in other cases data might be given high priority. The Producer and Consumer needs to be configured accordingly.", "For Machine Learning in Production the best practice is to use Tensorflow Serving API instead of initializing the model in the consumer application.", "Also it might be preferrable to use managed databases in the cloud for storing data.", "And this brings us to the end! Kafka is being used in a large number of projects and continues to grow. This makes it really important. Below I\u2019ve mentioned additional resources that\u2019ll help you deepen your knowledge on Kafka.", "Hope this article was helpful. If you have any feedback or want to get in touch in general, please drop me a note on ms.neerajkrishna@gmail.com.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I write about effective learning, technology, and deep learning | 2x top writer | senior data scientist @MakeMyTrip"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9f133858f5a0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ms-neerajkrishna.medium.com/?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": ""}, {"url": "https://ms-neerajkrishna.medium.com/?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "Neeraj Krishna"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8d6b9cde0656&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&user=Neeraj+Krishna&userId=8d6b9cde0656&source=post_page-8d6b9cde0656----9f133858f5a0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f133858f5a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f133858f5a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://docs.docker.com/engine/install/", "anchor_text": "docker"}, {"url": "https://github.com/simplesteph/kafka-stack-docker-compose", "anchor_text": "kafka-stack-docker-compose"}, {"url": "https://github.com/simplesteph/kafka-stack-docker-compose.git", "anchor_text": "https://github.com/simplesteph/kafka-stack-docker-compose.git"}, {"url": "https://github.com/wingedrasengan927/Distributed-Multi-Video-Streaming-and-Processing-with-Kafka", "anchor_text": "repo"}, {"url": "https://github.com/wingedrasengan927/Distributed-Multi-Video-Streaming-and-Processing-with-Kafka.git", "anchor_text": "https://github.com/wingedrasengan927/Distributed-Multi-Video-Streaming-and-Processing-with-Kafka.git"}, {"url": "https://www.confluent.io/blog/introduction-to-apache-kafka-for-python-programmers/?utm_medium=sem&utm_source=google&utm_campaign=ch.sem_br.brand_tp.prs_tgt.confluent-brand_mt.mbm_rgn.india_lng.eng_dv.all&utm_term=%2Bconfluent%20%2Bpython&creative=&device=c&placement=&gclid=EAIaIQobChMI3a-A2o_86wIVVz5gCh1yEAx2EAAYASAAEgLFIvD_BwE", "anchor_text": "Callbacks"}, {"url": "https://robomongo.org/download", "anchor_text": "Robo3T"}, {"url": "https://cloud.google.com/pubsub/?utm_source=google&utm_medium=cpc&utm_campaign=japac-IN-all-en-dr-bkws-all-all-trial-e-dr-1008074&utm_content=text-ad-crcloudmatrixver01ctr-none-DEV_c-CRE_308495403335-ADGP_Hybrid+%7C+AW+SEM+%7C+BKWS+~+T1+%7C+EXA+%7C+Big+Data+%7C+M:1+%7C+IN+%7C+en+%7C+Cloud+PubSub-KWID_43700029827958853-kwd-395094646964&userloc_1007740&utm_term=KW_google%20pub%20sub&ds_rl=1264446&gclid=EAIaIQobChMIh4zix7CC7AIVT9eWCh2g6Ak7EAAYASAAEgJ5j_D_BwE", "anchor_text": "Google Cloud Pub/Sub"}, {"url": "https://aws.amazon.com/kinesis/", "anchor_text": "Amazon Kinesis"}, {"url": "https://www.tensorflow.org/tfx/guide/serving", "anchor_text": "Tensorflow Serving API"}, {"url": "https://twitter.com/WingedRasengan", "anchor_text": "Twitter"}, {"url": "https://www.udemy.com/course/apache-kafka/", "anchor_text": "Udemy"}, {"url": "https://www.confluent.io/", "anchor_text": "Confluent"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9f133858f5a0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/distributed-systems?source=post_page-----9f133858f5a0---------------distributed_systems-----------------", "anchor_text": "Distributed Systems"}, {"url": "https://medium.com/tag/kafka?source=post_page-----9f133858f5a0---------------kafka-----------------", "anchor_text": "Kafka"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9f133858f5a0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/database?source=post_page-----9f133858f5a0---------------database-----------------", "anchor_text": "Database"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9f133858f5a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&user=Neeraj+Krishna&userId=8d6b9cde0656&source=-----9f133858f5a0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9f133858f5a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&user=Neeraj+Krishna&userId=8d6b9cde0656&source=-----9f133858f5a0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f133858f5a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9f133858f5a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9f133858f5a0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9f133858f5a0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9f133858f5a0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9f133858f5a0--------------------------------", "anchor_text": ""}, {"url": "https://ms-neerajkrishna.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ms-neerajkrishna.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Neeraj Krishna"}, {"url": "https://ms-neerajkrishna.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "664 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8d6b9cde0656&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&user=Neeraj+Krishna&userId=8d6b9cde0656&source=post_page-8d6b9cde0656--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F73b918378b68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkafka-in-action-building-a-distributed-multi-video-processing-pipeline-with-python-and-confluent-9f133858f5a0&newsletterV3=8d6b9cde0656&newsletterV3Id=73b918378b68&user=Neeraj+Krishna&userId=8d6b9cde0656&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}