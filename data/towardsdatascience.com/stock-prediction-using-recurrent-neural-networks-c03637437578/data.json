{"url": "https://towardsdatascience.com/stock-prediction-using-recurrent-neural-networks-c03637437578", "time": 1682999781.9834619, "path": "towardsdatascience.com/stock-prediction-using-recurrent-neural-networks-c03637437578/", "webpage": {"metadata": {"title": "Stock prediction using recurrent neural networks | by Joshua Wyatt Smith | Towards Data Science", "h1": "Stock prediction using recurrent neural networks", "description": "This type of post has been written quite a few times, yet many leave me unsatisfied. Recently, I read Using the latest advancements in deep learning to predict stock price movements, which, I think\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/aifortrading-2edd6fac689d", "anchor_text": "Using the latest advancements in deep learning to predict stock price movements", "paragraph_index": 0}, {"url": "https://www.interactivebrokers.co.uk/en/home.php", "anchor_text": "Interactive Brokers", "paragraph_index": 8}, {"url": "https://interactivebrokers.github.io/tws-api/introduction.html", "anchor_text": "their API", "paragraph_index": 9}, {"url": "https://gist.github.com/0575fc78f9d54a93988ad29300dfe4b7#file-downloadfromib-py", "anchor_text": "in this gist", "paragraph_index": 9}, {"url": "https://gist.github.com/jwsmithers/0575fc78f9d54a93988ad29300dfe4b7#file-downloadfromib-py-L38-L56", "anchor_text": "Create a \u201ccontract\u201d", "paragraph_index": 10}, {"url": "https://gist.github.com/jwsmithers/0575fc78f9d54a93988ad29300dfe4b7#file-downloadfromib-py-L60-L68", "anchor_text": "Request historical bars", "paragraph_index": 10}, {"url": "https://plot.ly/python/", "anchor_text": "Plotly", "paragraph_index": 13}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT", "paragraph_index": 16}, {"url": "https://finance.yahoo.com/news/goldman-sachs-reports-q1-earnings-112756222.html", "anchor_text": "mixed first quarter results", "paragraph_index": 17}, {"url": "https://gist.github.com/0d0caab9f1d5bb6a53fd063a6f726270#file-normalise-py", "anchor_text": "here", "paragraph_index": 19}, {"url": "https://towardsdatascience.com/data-science-in-algorithmic-trading-d21a46d1565d", "anchor_text": "Data Science For Algorithmic Trading", "paragraph_index": 22}, {"url": "https://simple.wikipedia.org/wiki/Occam%27s_razor", "anchor_text": "Occam can rest in peace", "paragraph_index": 26}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "a very nice article", "paragraph_index": 26}, {"url": "https://github.com/fmfn/BayesianOptimization", "anchor_text": "Bayesian Optimization", "paragraph_index": 30}, {"url": "https://towardsdatascience.com/selu-make-fnns-great-again-snn-8d61526802a9", "anchor_text": "Here\u2019s an interesting read", "paragraph_index": 31}, {"url": "https://www.backtrader.com/", "anchor_text": "backtrader", "paragraph_index": 38}], "all_paragraphs": ["This type of post has been written quite a few times, yet many leave me unsatisfied. Recently, I read Using the latest advancements in deep learning to predict stock price movements, which, I think was overall a very interesting article. It covers many topics and even gave me some ideas (it also nudged me into writing my first article \ud83d\ude42). But it doesn\u2019t actually say how well the network performed. My gut feeling says \u201cnot well\u201d given that this is usually the case, but maybe/hopefully I\u2019m wrong! For some time now I\u2019ve been developing my own trading algorithm, and so this article presents my (work-in-progress) approach, thoughts and some results.", "The overall challenge is to determine the gradient difference between one Close price and the next. Not the actual stock price. Why? It\u2019s easy to fool yourself into thinking you have a viable model when you are trying to predict something that could fluctuate marginally (|<0.01%|) and/or largely (|>5%|). The plot below gives an example of this. A basic model (nothing special) was trained to predict the (normalized) price of Goldman Sachs:", "The actual price of the stock is on the y-axis, while the predicted price is on the x-axis. There\u2019s clearly a nice linear trend there. And maybe a trading strategy can be developed from this. But what happens if we plot the gradient between two consecutive points?", "Uh oh. For predicting whether the price will go up or down for the next candlestick (the definition of gradient here), our model is essentially no better then guessing. That\u2019s a pretty large fundamental issue. The accuracy here (51.5%) is calculated by summing the values in the correct quadrants (top right and bottom left) and dividing by all points.", "Instead of telling you why this is a difficult problem (you probably already know), I\u2019ll mention two personal struggles I faced here.", "Can we train a model that accurately predicts the next gradient change, while mitigating the naive estimator effect?", "Spoiler alert: Yes, we can! (I think).", "Most of the time spent on this project was making sure the data was in the correct format, or aligned properly, or not too sparse etc. (Well, that and the GUI I built around this tool, but that\u2019s a different issue entirely \ud83d\ude44).", "My data comes from Interactive Brokers (IB). After signing up and depositing some minimum amount, you can then subscribe to various feeds. At present I pay ~15 euros a month for live data.", "My function that makes use of their API to download stock prices can be seen in this gist.", "1) Connect to IB 2) Create a \u201ccontract\u201d3) Request historical bars using that contract.", "All of this is put on a patched async loop (hence the package nest_asyncio), due to my code already being on a thread. The Usage in the above gist gives an example of how one would call this function.", "I now have a pandas dataframe of 1 hour candlesticks. From there it\u2019s easy to make plots:", "I use the pretty awesome Plotly library. The slightly more involved syntax is a sacrifice for interactive plots (although not interactive for this article). By zooming in on a section, the goal can be better highlighted:", "I will try predict the gradient from the latest Close price that I have, to the incoming Close price. This can be used to formulate strategies for trading. At a later stage the size of the gradient could also potentially be taken into account.", "The hypothesis is that news has a very large impact on how stock prices evolve. There are a couple of sources for news out there, newsapi.org for one, IB also has some options, Thomson Reuters etc.As for my sources, I\u2019m not quite ready to share them yet \ud83d\ude42.", "I currently use news sentiment in the most basic form: I count the number of positive/negative and neutral stories for a given time period and use them as features. I use my own home-rolled semi-supervised news classifier, but one could also use BERT or any other pre-trained library. There are other ways to include sentiment, such as injecting the embeddings directly into the network for example.", "For each stock, I chose certain keywords and retrieve the associated news articles. One hyper-parameter is \u201clag\u201d. A lag of 0 means that if I\u2019m predicting the Close price at 2pm, only stories before 2pm on the same day are used. A lag of 1 means to include news for an extra day back, and so on. The question here is: how long does it take for news to propagate through society and trading algorithms, and how long does it\u2019s effect have on the stock?Below shows the number of stories for Goldman Sachs for a given time period and a lag of 2 days. I believe the negative spike between April 15\u201318th has to do with the bank reporting mixed first quarter results.", "One problem with predicting stock prices is that there really is just a finite amount of data. Also, I don\u2019t want to go too far back as I believe the nature of trading has completely changed from say 2013 till now. I can train on many or few stocks concatenated together, with others used as features. By concatenating stocks I increase the number of data, as well as potentially learn new insights. The pseudocode for my dataset builder looks like this:", "During training, I normalize each feature and save the parameters to a scalar file. Then, when inferring, I read the file and apply the parameters to the variable. This speeds up the process of inferring when I can just ask for the latest point from my broker. A gist of how to normalize can be seen here. An interesting parameter is the norm_window_size. This specifies how many points in the feature should be normalized together. A window that is too big means your resolution is not fine grained enough. A larger variety of external factors that haven\u2019t been taken into account will play a bigger role. A window too small will essentially just look like noise. It\u2019s an interesting parameter to play with.", "The correlations between each variable are shown below. Remember, in the most broad sense, two highly correlated variables means that if one increases, so will the other. For anti-correlation, if one variable decreases, the other will increase.Higher, positive correlations are darker colors, lighter for lower/negative correlations. Currently, I do use Open, High, Low as features. They are extremely highly correlated with the Close price, but I have all that information at inference time, so hey, why not. Future training might see me remove those to see what happens. In general, it\u2019s not good to have \u201crepetitive\u201d variables.Other features that seem redundant are the indicators built with the Close price. But they give me an easy way to change the sequence length for just those variables so I left them in for now.", "But what \u201cexternal\u201d sources are there (i.e., not derived from the stock(s) we\u2019re trying to infer on)? These are the most important variables.High correlations between features such as the currencies, the indexes and an anti-correlation with the VIX are very promising. Some currencies could be eliminated to reduce the overall network size (i.e., the USD and South African Rand don\u2019t seem like they should influence each other, but who knows), and further trainings over different variables could eliminate some of them.", "It is important to remember that \u201c\u2026correlation is not the same thing as a trading prediction.\u201d as pointed out by Daniel Shapiro in Data Science For Algorithmic Trading, i.e. correlation is not causation. And so one filtering technique on the to-do list is to look at how correlations evolve over time for individual variables vs the Close price of a given stock. This will allow us to remove variables and reduce the number of dimensions.", "which shows 5 time steps, with 7 normalized features (for brevity).", "Then, we create the training, validation and testing datasets. Since this is a sequence prediction problem, we use a sliding window algorithm. The premise is shown in the figure below. X number of points (4 in the image) are used, with X+1 taken as the label and forming a new array. The window is then moved 1 point forward and the calculation repeated. This way you have a large array (X, which are your inputs) as well as your labels, Y.", "From here, and after splitting into train, validation and test sizes (80%,15%, 5%), the data can be fed into a neural network.", "I played around with a variety of architectures (including GANs), until finally settling on a simple recurrent neural network (RNN). And so Occam can rest in peace. In theory, an LSTM (a type of RNN) should be better, something I need to play with again.Christopher Olah provides a very nice article about RNN\u2019s and LSTMs.", "My model in Tensorflow (1.12) looks a little something like this (namespaces and histograms etc. removed):", "It\u2019s a fairly simple network, where a multi-layer RNN (with GRU layers) is fed into a dense layer (which includes a dropout layer). The number of layers, activations, and dropout percentage all are optimized during training.The \u201cAccuracy\u201d node is long convoluted set of TF operations that convert a prediction from the dense network into a binary gradient movement. As an experiment, this accuracy is actually currently used in my cost function as:", "where the label is the normalized price, and final_predictions are the normalized actual price predictions. I use the AdamOptimiser with a cyclic function learning rate. Is this the optimal/best way to do it? I\u2019m not entirely sure yet! \ud83d\ude42", "I too made use of Bayesian Optimization (BO) during the training stage. I think it\u2019s a fantastic library, BUT, am I convinced that it works well for this type of problem and actually saves a huge amount of time? Not really. I\u2019d like to create some plots to see how the training progresses and what the function(s) looks like. But with this many parameters it\u2019s tough. However, maybe it provides a slightly biased random number generator. With that being said, the parameters used for the results in this article are:", "Here\u2019s an interesting read on scaled exponential linear units (selus).", "The loss curve for train (orange) and validation (blue) data sets is shown below. The lines are very jumpy, and maybe using a larger batch size could help with that. There\u2019s also a some difference between the two datasets. This is not too surprising. Remember, I\u2019ve concatenated (and shuffled) multiple stocks with Goldman Sachs, and so what we\u2019re actually training is a model for a given \u201csector\u201d, or whatever you want to call it. In theory, it\u2019s more generalizable, and so more difficult to train (the trade-off to get more data). Thus, it could hint at some over-training; something to be further checked. However, one can see a trend of the validation loss decreasing as time goes on (up until a certain point) \ud83d\udc4d.", "How does this latest model perform? Below is the actual gradient vs the predicted gradient. 65% accuracy (with the same definition used before) isn\u2019t too bad.", "The figure below shows a confusion matrix for the actual gradient vs the predicted gradient. It shows that 59% of the time we correctly predict a negative gradient, while 71% of the time we correctly predict a positive gradient. This imbalance could come from the nature of the dataset and the model, i.e., maybe three small positive gradients proceed a single negative gradient. The model learns this, and thus quoting accuracy can be a bit misleading. This will become very important when actually developing trading strategies.", "The cover plot is shown again, focusing on just the validation and test datasets. Let\u2019s be honest, it\u2019s not that sexy. But there are times when trends of gradient changes are indeed followed. To me, anytime a plot like this is shown with seemingly perfect overlap, an alarm bell should go off inside the reader\u2019s head.Remember, the validation dataset is only used in the training steps to determine when to stop training (i.e. no improvement after x epochs, stop). The test dataset is not used anywhere. That means this plot shows around 600 hours of \u201csemi-unseen\u201d data, and just under 300 hours of completely unseen data.", "How stable was our result?In 114 training sessions the distribution of the accuracy for predicting the gradient is shown below (the histogram in green). The accuracy of each training session is plotted against run number in orange. This confirms my suspicion that BO isn\u2019t working too well here, but maybe it just needs more iterations and/or parameters tweaked.", "It turns out there was actually a better result I could have used. Whoops \ud83d\ude00. (The better result has a more even distribution for up/up vs down/down in the confusion matrix, which is nice).The take-away from the green histogram is that we are learning something. Also, it\u2019s good to see that there are some results that are no better than guessing, meaning we aren\u2019t always learning something when playing with parameters. Some models just suck. And if no models sucked that would be an alarm bell.", "In this article I highlighted my means of building a RNN that is able to predict the correct gradient difference between 2 Close prices around 65% of the time. I believe with more playing around and some tweaking this number can be improved. Also, plenty more checks and studies can be performed.Will it actually make money when backtesting? How about when trading live?There is a huge amount to consider. From using the pretty cool backtrader library, to plugging it into the IB API, these will be topics for the next article. \ud83d\ude42", "I hope you found the article interesting\u2026 I had fun writing it!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc03637437578&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c03637437578--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c03637437578--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@joshua.wyatt.smith?source=post_page-----c03637437578--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joshua.wyatt.smith?source=post_page-----c03637437578--------------------------------", "anchor_text": "Joshua Wyatt Smith"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdcc4b44d4533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&user=Joshua+Wyatt+Smith&userId=dcc4b44d4533&source=post_page-dcc4b44d4533----c03637437578---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc03637437578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc03637437578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/aifortrading-2edd6fac689d", "anchor_text": "Using the latest advancements in deep learning to predict stock price movements"}, {"url": "https://www.interactivebrokers.co.uk/en/home.php", "anchor_text": "Interactive Brokers"}, {"url": "https://interactivebrokers.github.io/tws-api/introduction.html", "anchor_text": "their API"}, {"url": "https://gist.github.com/0575fc78f9d54a93988ad29300dfe4b7#file-downloadfromib-py", "anchor_text": "in this gist"}, {"url": "https://gist.github.com/jwsmithers/0575fc78f9d54a93988ad29300dfe4b7#file-downloadfromib-py-L38-L56", "anchor_text": "Create a \u201ccontract\u201d"}, {"url": "https://gist.github.com/jwsmithers/0575fc78f9d54a93988ad29300dfe4b7#file-downloadfromib-py-L60-L68", "anchor_text": "Request historical bars"}, {"url": "https://plot.ly/python/", "anchor_text": "Plotly"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT"}, {"url": "https://finance.yahoo.com/news/goldman-sachs-reports-q1-earnings-112756222.html", "anchor_text": "mixed first quarter results"}, {"url": "https://gist.github.com/0d0caab9f1d5bb6a53fd063a6f726270#file-normalise-py", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/data-science-in-algorithmic-trading-d21a46d1565d", "anchor_text": "Data Science For Algorithmic Trading"}, {"url": "https://simple.wikipedia.org/wiki/Occam%27s_razor", "anchor_text": "Occam can rest in peace"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "a very nice article"}, {"url": "https://github.com/fmfn/BayesianOptimization", "anchor_text": "Bayesian Optimization"}, {"url": "https://towardsdatascience.com/selu-make-fnns-great-again-snn-8d61526802a9", "anchor_text": "Here\u2019s an interesting read"}, {"url": "https://www.backtrader.com/", "anchor_text": "backtrader"}, {"url": "https://medium.com/tag/trading?source=post_page-----c03637437578---------------trading-----------------", "anchor_text": "Trading"}, {"url": "https://medium.com/tag/quant?source=post_page-----c03637437578---------------quant-----------------", "anchor_text": "Quant"}, {"url": "https://medium.com/tag/recurrent-neural-network?source=post_page-----c03637437578---------------recurrent_neural_network-----------------", "anchor_text": "Recurrent Neural Network"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c03637437578---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/stock-market?source=post_page-----c03637437578---------------stock_market-----------------", "anchor_text": "Stock Market"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc03637437578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&user=Joshua+Wyatt+Smith&userId=dcc4b44d4533&source=-----c03637437578---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc03637437578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&user=Joshua+Wyatt+Smith&userId=dcc4b44d4533&source=-----c03637437578---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc03637437578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c03637437578--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc03637437578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c03637437578---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c03637437578--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c03637437578--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c03637437578--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c03637437578--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c03637437578--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c03637437578--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c03637437578--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c03637437578--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joshua.wyatt.smith?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joshua.wyatt.smith?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Joshua Wyatt Smith"}, {"url": "https://medium.com/@joshua.wyatt.smith/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "237 Followers"}, {"url": "http://www.linkedin.com/in/joshua-wyatt-smith", "anchor_text": "www.linkedin.com/in/joshua-wyatt-smith"}, {"url": "https://wyattai.com/", "anchor_text": "https://wyattai.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdcc4b44d4533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&user=Joshua+Wyatt+Smith&userId=dcc4b44d4533&source=post_page-dcc4b44d4533--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5a3d6b6728d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstock-prediction-using-recurrent-neural-networks-c03637437578&newsletterV3=dcc4b44d4533&newsletterV3Id=5a3d6b6728d6&user=Joshua+Wyatt+Smith&userId=dcc4b44d4533&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}