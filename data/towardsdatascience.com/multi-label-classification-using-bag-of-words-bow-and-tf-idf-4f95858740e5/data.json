{"url": "https://towardsdatascience.com/multi-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5", "time": 1683010044.044899, "path": "towardsdatascience.com/multi-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5/", "webpage": {"metadata": {"title": "Multi Label Classification using Bag-of-Words (BoW) and TF-IDF | by Snehal Nair | Towards Data Science", "h1": "Multi Label Classification using Bag-of-Words (BoW) and TF-IDF", "description": "For this study, we are using Kaggle data for Toxic Comment Classification Challenge. Lets load and inspect the data. This is a multilabel classification problem where comments are classified by the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data", "anchor_text": "Toxic Comment Classification Challenge", "paragraph_index": 0}, {"url": "https://pub.towardsai.net/imbalanced-data-real-time-bidding-6ee9c4ef957c", "anchor_text": "this", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model", "anchor_text": "In the BoW model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Tf\u2013idf", "anchor_text": "In information retrieval, tf\u2013idf or TFIDF, short for term frequency-inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.", "paragraph_index": 12}, {"url": "https://medium.com/vantageai/bringing-back-the-time-spent-on-hyperparameter-tuning-with-bayesian-optimisation-2e21a3198afb", "anchor_text": "post", "paragraph_index": 15}, {"url": "https://github.com/snehalnair/bow_tfidf", "anchor_text": "here", "paragraph_index": 23}], "all_paragraphs": ["For this study, we are using Kaggle data for Toxic Comment Classification Challenge. Lets load and inspect the data. This is a multilabel classification problem where comments are classified by the level of toxicity: toxic / severe_toxic / obscene / threat / insult / identity_hate", "To begin with let us add a label, \u2018non_toxic\u2019 for comments with no label. Also, explore how balanced the classes are.", "We can see that the data is highly imbalanced. Imbalanced data refers to classification problems where the classes are not represented equally for e.g., of 89% comments are classified under the newly built \u2018non_toxic\u2019 label.", "Any given linear model will handle class imbalance very badly if it uses squared loss for binary classification. We will not discuss the techniques to tackle the imbalance problem in this project. If you want to learn more about handling imbalanced data, please refer to this blog.", "Let's focus on pre-processing the text data before converting it to numeric data using BoW (Bag of Words) and tf-idf (term frequency and inverse document frequency).", "Let us take a closer look at one of the comments. Please note the text will vary for you since the dataset is split randomly. Please use the seed in the split if you aim to reproduce the results.", "From the above example, we can see that the text requires preprocessing, i.e., converting it into the same case (lower), removing symbols, numbers, and stop words before the text is converted into tokens. For preprocessing the text you will need to download specific libraries.", "For machine learning models, the textual data must be converted to numeric data. This can be done in various ways like BoW, tf-idf, Word embedding, etc. In this project, we will be focusing on BoW and tf-idf.", "In the BoW model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.", "We will restrict ourselves to N popular words to limit the size of the matrix. Moreover, including unpopular words will only introduce sparsity without adding too much information. For this project, let\u2019s work with 10000 popular words.", "For each comment in the corpora create a zero vector with N dimension and for the words found in the comment increase the values in the vector by 1 for e.g., If a word appears twice, that index in the vector will get 2.", "For efficient storage, we will convert this vector into a sparse vector, one that leverages sparsity and actually stores only nonzero entries.", "In information retrieval, tf\u2013idf or TFIDF, short for term frequency-inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.", "This method is an extension to Bag-of-Words where the total frequency of the word is divided by the total words in the document. This penalizes too frequent words by normalizing them over the entire document.", "We have the datasets prepared using two different techniques BoW and tf-idf. We can run classifiers on both datasets. Since this is a multi-label classification problem, we will be using a simple OneVsRestClassfier logistic regression.", "You can experiment with different regularization techniques, L1 and L2 with different coefficients (e.g. C equal to 0.1, 1, 10, 100) till you are happy with the result, this is called hyperparameter tuning. This can be achieved by cv grid search, random search, and bayesian optimization. We are not covering this topic in this article. If you would like to learn more about this, please refer to this post.", "We will use metrics like accuracy score and f1 score for evaluation.", "'F1 score micro': Calculate metrics globally by counting the total true positives, false negatives, and false positives.", "'F1 score macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.", "'F1 score weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters \u2018macro\u2019 to account for label imbalance; it can result in an F-score that is not between precision and recall.", "F1 score weighted and macro which accounts for data imbalance look good. Let us check the output, predicted label, and actual label. We will need to replace one-hot encoded labels with the actual label for interpretation. Next let\u2019s run prediction on tf-idf model.", "The results are not too bad, but it can do better. Please try to experiment with hyper-parameter tuning and different classifiers to check the performance of the model. Hope you enjoyed reading.", "I have left the code for building a word cloud image if you are interested.", "For jupyter notebook with codes, please click here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4f95858740e5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@snehalnair", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----4f95858740e5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4f95858740e5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@snehalnair?source=post_page-----4f95858740e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@snehalnair?source=post_page-----4f95858740e5--------------------------------", "anchor_text": "Snehal Nair"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8608717798b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&user=Snehal+Nair&userId=8608717798b8&source=post_page-8608717798b8----4f95858740e5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f95858740e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f95858740e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data", "anchor_text": "Toxic Comment Classification Challenge"}, {"url": "https://pub.towardsai.net/imbalanced-data-real-time-bidding-6ee9c4ef957c", "anchor_text": "this"}, {"url": "https://www.coursera.org/learn/language-processing", "anchor_text": "Coursera"}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model", "anchor_text": "In the BoW model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity."}, {"url": "https://en.wikipedia.org/wiki/Tf\u2013idf", "anchor_text": "In information retrieval, tf\u2013idf or TFIDF, short for term frequency-inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus."}, {"url": "https://medium.com/vantageai/bringing-back-the-time-spent-on-hyperparameter-tuning-with-bayesian-optimisation-2e21a3198afb", "anchor_text": "post"}, {"url": "https://github.com/snehalnair/bow_tfidf", "anchor_text": "here"}, {"url": "https://www.coursera.org/learn/language-processing/home/week/1", "anchor_text": "https://www.coursera.org/learn/language-processing/home"}, {"url": "https://medium.com/tag/bag-of-words?source=post_page-----4f95858740e5---------------bag_of_words-----------------", "anchor_text": "Bag Of Words"}, {"url": "https://medium.com/tag/bow?source=post_page-----4f95858740e5---------------bow-----------------", "anchor_text": "Bow"}, {"url": "https://medium.com/tag/tf-idf?source=post_page-----4f95858740e5---------------tf_idf-----------------", "anchor_text": "Tf Idf"}, {"url": "https://medium.com/tag/multilabel-classifier?source=post_page-----4f95858740e5---------------multilabel_classifier-----------------", "anchor_text": "Multilabel Classifier"}, {"url": "https://medium.com/tag/nlp?source=post_page-----4f95858740e5---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f95858740e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&user=Snehal+Nair&userId=8608717798b8&source=-----4f95858740e5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f95858740e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&user=Snehal+Nair&userId=8608717798b8&source=-----4f95858740e5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f95858740e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4f95858740e5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4f95858740e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4f95858740e5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4f95858740e5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4f95858740e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4f95858740e5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4f95858740e5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4f95858740e5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4f95858740e5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4f95858740e5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4f95858740e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@snehalnair?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@snehalnair?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Snehal Nair"}, {"url": "https://medium.com/@snehalnair/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "165 Followers"}, {"url": "https://www.linkedin.com/in/snehal-nair-5351998/", "anchor_text": "https://www.linkedin.com/in/snehal-nair-5351998/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8608717798b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&user=Snehal+Nair&userId=8608717798b8&source=post_page-8608717798b8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcf6738b778fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5&newsletterV3=8608717798b8&newsletterV3Id=cf6738b778fa&user=Snehal+Nair&userId=8608717798b8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}