{"url": "https://towardsdatascience.com/taking-a-machine-learning-white-paper-to-production-a25cfadcd16e", "time": 1683010249.794227, "path": "towardsdatascience.com/taking-a-machine-learning-white-paper-to-production-a25cfadcd16e/", "webpage": {"metadata": {"title": "Taking a Machine Learning White Paper to Production | by Peter Gaston | Towards Data Science", "h1": "Taking a Machine Learning White Paper to Production", "description": "As I read white papers I\u2019m usually going at this with a purpose in mind, i.e., a potential challenge at hand, usually a big challenge. Often, they\u2019ll really fit the bill. And sometimes, they\u2019ll even\u2026"}, "outgoing_paragraph_urls": [{"url": "http://fastdepth.mit.edu/", "anchor_text": "Fast Depth", "paragraph_index": 1}, {"url": "https://github.com/alibaba/MNN", "anchor_text": "Mobile Neural Networks", "paragraph_index": 7}, {"url": "https://towardsdatascience.com/machine-learning-at-the-edge-a751397e5a06", "anchor_text": "already written about this", "paragraph_index": 11}, {"url": "https://github.com/XiaoMi/mace", "anchor_text": "Mobile AI Compute Engine", "paragraph_index": 11}, {"url": "https://tvm.apache.org/", "anchor_text": "tvm.ai", "paragraph_index": 12}, {"url": "https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html", "anchor_text": "NYU Depth Dataset V2", "paragraph_index": 14}, {"url": "https://diode-dataset.org/", "anchor_text": "DIODE", "paragraph_index": 20}, {"url": "https://www.intelrealsense.com/stereo-depth/?utm_source=intelcom_website&utm_medium=button&utm_campaign=day-to-day&utm_content=D400_learn-more_button&elq_cid=6395200&erpm_id=7197935", "anchor_text": "RealSense sensor", "paragraph_index": 22}, {"url": "https://en.wikipedia.org/wiki/Pinhole_camera_model", "anchor_text": "Pinhole Camera Model", "paragraph_index": 26}, {"url": "http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html", "anchor_text": "calibration parameters", "paragraph_index": 30}], "all_paragraphs": ["As I read white papers I\u2019m usually going at this with a purpose in mind, i.e., a potential challenge at hand, usually a big challenge. Often, they\u2019ll really fit the bill. And sometimes, they\u2019ll even have source code on Github. So much the better.", "This is a short story on lessons learned on taking one, Fast Depth from MIT from white paper to production \u2014 actively running on a drone providing perception for autonomy.", "Note \u2014 In no way am I being critical of the Fast Depth paper, people, or the work. My communications with them have been very fruitful. The story of this paper is around the work it takes to go to \u2018production\u2019 from an interesting white paper/working proof of concept.", "Four things that can help out:", "Pick your Machine Learning language with an eye to deployment", "Research and development of an interesting machine learning model is often the focus of a white paper we\u2019d be interested in. Researchers tend to like PyTorch. It provides additional flexibility over Keras/Tensorflow, for example in dynamic graphs. Fine. However, Tensorflow seems to be dominant overall in usage and especially for run-time performance.", "There are really two ways to run your model in production:", "If your delivery allows CUDA you have many more options. However, I tend to get involved with the #2 above \u2014 that is embedded Linux and smartphone projects. For example, in the framework Mobile Neural Networks (from Alibaba), released to version 1.0 in April, \u201920, they focus on the backends such as the ARM CPU, OpenCL, OpenGL, Metal, and Vulkan. And it is deeply tuned for GPUs from the Adreno and Mali families. Right up my alley.", "Further, from a language standpoint \u201cMNN currently supports Tensorflow, Tensorflow Lite, Caffe and ONNX (PyTorch/MXNet); the latter optimizes graphs by operator fusion, operator substitution, and layout adjustment.\u201d That is, ONNX certainly seems to be a second class citizen. Going further, they support 86 Tensorflow ops and only 34 Caffe ops.", "The race may not always go to the fast, but it\u2019s a darn good bet. i.e., for deployment go with Tensorflow if possible.", "Find a deployment inference engine that works", "In a previous article, I\u2019ve already written about this in depth. The headline is that there are many options and it is long and painful to work through them. I found one called Mobile AI Compute Engine (MACE) that was the first to work well in my environment.", "Your mileage may vary. For optimal performance, I would also like to further explore MNN (mentioned above) and tvm.ai.", "Tune your model with focused training data", "Research papers need to show that they\u2019ve beaten previous work. The way they do this is by using benchmark data sets. In the case of depth estimation, the normal benchmark is NYU Depth Dataset V2. This dataset, from 2012 contains roughly 50+ training images (RGB-D, the D is for Depth) obtained with a Kinect camera. (A similar dataset for automotive perception is known as KITTI, also from the timeframe.)", "Here is a sample from the NYU DepthV2 dataset. Namely interiors of NYC apartments and offices.", "In contrast, our focus was on more gritty, industrial settings.", "Note the greater depth and \u2018different\u2019 type of scene composition.", "In short, the model trained on the NYU data failed us in two ways:", "Next Step \u2014 Find New Datasets", "Searching around we found DIODE, a similar dataset but that both had a larger data range, up to 350M as well as both indoors and outdoors scenes. This works much better.", "It still pays for highly specific scenes to train on images highly resembling that scene. Okay, you can say the word \u201ccheating\u201d, I\u2019ll keep to optimizing our results as we strive towards generalization. In short, we would capture roughly 5K images from a highly specific environment we would be tested on and train our model on that.", "These final images are captured using a RealSense sensor. This is more accurate than the Kinect but still suffers from a limited depth range of 10M (or less.)", "So in short, the training regimen that worked well was:", "This works, within the desired domain well.", "You might\u2019ve noticed that we\u2019ve used roughly several different cameras so far: (whatever Mobilenet used); Kinect; DIODE; RealSense; and don\u2019t forget the final camera on the drone. Cameras have calibration parameters that are different.", "Refer to the Pinhole Camera Model. This is high school math, and I won\u2019t drag you through it. But two key parameters for us are the focal length and principal point.", "The focal length is seen as f in the image above. The principal point isn\u2019t shown but represents where the center of the image is on the image plane \u2014 for cameras, this is often off.", "So what, you say. Well, it turns out that you really shouldn\u2019t mix and match images from cameras with different parameters in the same training data set.", "The good news is that it\u2019s easy to convert between cameras.", "Here\u2019s some code to help with the conversion. The camera calibration parameters used are from the ROS framework. In general, the path through is:", "Below is my Python code for #2 above:", "As always, a good approach is to proceed iteratively, with deep dives on technically unknown/unproven areas. The four things outlined above will help speed you through this process.", "As Thomas Edison said, \u201cGenius is one percent inspiration, ninety-nine percent perspiration.\u201d Or, in my words, a good idea is good, a proof of concept is great, having that work in the real world takes a lot of effort.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Consultant in AI covering Fashion Science, Perception, and Financial Services. Background includes McKinsey & Co. and MIT (SM/SB in Artificial Intelligence.)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa25cfadcd16e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@peter.gaston?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@peter.gaston?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "Peter Gaston"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F89126c3d969b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&user=Peter+Gaston&userId=89126c3d969b&source=post_page-89126c3d969b----a25cfadcd16e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa25cfadcd16e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa25cfadcd16e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://fastdepth.mit.edu/", "anchor_text": "Fast Depth"}, {"url": "https://unsplash.com/@nicolasthomas?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Nicolas Thomas"}, {"url": "https://unsplash.com/s/photos/engineering?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://github.com/alibaba/MNN", "anchor_text": "Mobile Neural Networks"}, {"url": "https://towardsdatascience.com/machine-learning-at-the-edge-a751397e5a06", "anchor_text": "already written about this"}, {"url": "https://github.com/XiaoMi/mace", "anchor_text": "Mobile AI Compute Engine"}, {"url": "https://tvm.apache.org/", "anchor_text": "tvm.ai"}, {"url": "https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html", "anchor_text": "NYU Depth Dataset V2"}, {"url": "https://unsplash.com/@jasonsung?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Jason Sung"}, {"url": "https://unsplash.com/@amyames?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Amy Elting"}, {"url": "https://unsplash.com/s/photos/factory?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://diode-dataset.org/", "anchor_text": "DIODE"}, {"url": "https://www.intelrealsense.com/stereo-depth/?utm_source=intelcom_website&utm_medium=button&utm_campaign=day-to-day&utm_content=D400_learn-more_button&elq_cid=6395200&erpm_id=7197935", "anchor_text": "RealSense sensor"}, {"url": "https://en.wikipedia.org/wiki/Pinhole_camera_model", "anchor_text": "Pinhole Camera Model"}, {"url": "http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html", "anchor_text": "calibration parameters"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a25cfadcd16e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----a25cfadcd16e---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/runtime?source=post_page-----a25cfadcd16e---------------runtime-----------------", "anchor_text": "Runtime"}, {"url": "https://medium.com/tag/python?source=post_page-----a25cfadcd16e---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/camera-calibration?source=post_page-----a25cfadcd16e---------------camera_calibration-----------------", "anchor_text": "Camera Calibration"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa25cfadcd16e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&user=Peter+Gaston&userId=89126c3d969b&source=-----a25cfadcd16e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa25cfadcd16e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&user=Peter+Gaston&userId=89126c3d969b&source=-----a25cfadcd16e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa25cfadcd16e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa25cfadcd16e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a25cfadcd16e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a25cfadcd16e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@peter.gaston?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@peter.gaston?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Peter Gaston"}, {"url": "https://medium.com/@peter.gaston/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "44 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F89126c3d969b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&user=Peter+Gaston&userId=89126c3d969b&source=post_page-89126c3d969b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb3317909b127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftaking-a-machine-learning-white-paper-to-production-a25cfadcd16e&newsletterV3=89126c3d969b&newsletterV3Id=b3317909b127&user=Peter+Gaston&userId=89126c3d969b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}