{"url": "https://towardsdatascience.com/creating-a-custom-classifier-for-text-cleaning-a2a1fc818935", "time": 1682994856.459616, "path": "towardsdatascience.com/creating-a-custom-classifier-for-text-cleaning-a2a1fc818935/", "webpage": {"metadata": {"title": "Creating a Custom Classifier for Text Cleaning | by Rodrigo Nader | Towards Data Science", "h1": "Creating a Custom Classifier for Text Cleaning", "description": "Recently I've been studying NLP more than other data science fields, and one challenge that I face more often than not is the cleaning part of the process. Building NLP models require many\u2026"}, "outgoing_paragraph_urls": [{"url": "https://machinelearningmastery.com/clean-text-machine-learning-python/", "anchor_text": "this", "paragraph_index": 8}, {"url": "https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/", "anchor_text": "this", "paragraph_index": 8}, {"url": "https://docs.python.org/2/library/re.html", "anchor_text": "regular expressions", "paragraph_index": 12}, {"url": "https://machinelearningmastery.com/gentle-introduction-bag-words-model/", "anchor_text": "bag-of-words", "paragraph_index": 23}], "all_paragraphs": ["Recently I've been studying NLP more than other data science fields, and one challenge that I face more often than not is the cleaning part of the process. Building NLP models require many pre-processing steps, and if the data is not properly treated, it could result in poor models, which is necessarily what we want to avoid.", "In this article, we're going to focus on PDF documents. The goal here is to open a PDF file, convert it to plain text, understand the need for data cleaning and build a machine learning model for that purpose.", "Some libraries we\u2019re going to use:", "As always, I\u2019ll try to explain the code used along the text, so feel free to skip the snippets if you'd like. Let's start by importing some modules:", "We are going to use pdfminer to build our PDF reader:", "Although this function seems long, it's just reading a PDF file and returning its text as a string. We'll apply it to a paper called \"A Hands-on Guide to Google Data\":", "By just looking at the first page, we quickly see that an article contains much more than simple sentences, including elements like dates, line counts, page numbers, titles and subtitles, section separators, equations, and so on. Let's check how those properties will come out when the paper is converted to plain text (primer.pdf is the name of the file, stored locally in my computer):", "It's clear here that we lost the all the text structure. Line counts and page numbers are spread as they were part of sentences, while titles and references can't be clearly distinguished from the text bodies. There are probably many ways out there for you to conserve the text structure while reading a PDF, but let's keep this messed up for the sake of explanation (as this is very often how raw text data looks like).", "A full cleaning pipeline has many steps, and to become familiar with them I suggest following some tutorials (this and this are great starting points). In general lines, the cleaning process chain would include:", "Our goal here isn't to replace any of those stages, but instead, build a more general tool to remove what's unwanted for us. Take it as a complementary step to help in the middle.", "Let's suppose we want to get rid of any sentence that does not look like human written. The idea is to classify those sentences as \"unwanted\" or \u201cweird\u201d and consider the remaining sentences \"normal\". For example:", "Those sentences are clearly messed up because of the text transformation and in case we're making, let's say, a PDF summarizer, they shouldn't be included.", "To remove them, we could manually analyze the text, figure out some patterns and apply regular expressions. But, in some cases, it might be better to build a model that find those patterns for us. This is what we're doing here. We'll create a classifier to recognize weird sentences so that we can easily remove them from the text body.", "Let's build a function to open the PDF file, split the text into sentences and save them into a data frame with columns label and sentence:", "Since we don't have the data labeled (in \"weird\" or \"normal\" ), we're going to do it manually to fill our label column. This data set will be updatable so that we can attach new documents to it and label their sentences.", "Let's first save the unlabelled dataset into a .pickle file:", "Now we'll create a user interaction function to manually classify the data points. For each sentence in the dataset, we'll display a text box for the user to type '1' or nothing. If the user types '1', the sentence is to be classified as \"weird\".", "I'm using a Jupyter Notebook so I've called the clear_output() function from IPython.display to improve the interaction.", "This is how the output looks like for each sentence:", "Since this sentence looks pretty normal, I won't type '1', but simply press enter and move on to the next one. This process will repeat until the dataset is fully labeled or when you interrupt. Every user input is being saved to the pickle file, so the dataset is being updated at each sentence. This easy interaction made it relatively fast to label the data. It took me 20 minutes to have about 500 data points labeled.", "Two other functions were written to keep things simple. One to attach another PDF file to our dataset and another one to reset all the labels (sets the label column values to np.nan).", "As we ended up with more \"normal\" than \"weird\" sentences, I built a function to undersample the dataset, otherwise, some machine learning algorithms wouldn't perform well:", "645 labeled data points. Not enough to make a decent model, but we'll use it as a playground example.", "Now we need to transform the sentences in a way the algorithm can understand. One form of doing that is counting the occurrence of each character inside the sentence. That would be something like a bag-of-words technique, but at the character level.", "Perfect! Now we're just left with a usual machine learning challenge. Many features and one target in a classification problem. Let's split the data into train and test sets:", "We're ready to choose an algorithm and check its performance. Here I'm using a Logistic Regression just to see what we can achieve:", "86 % accuracy. That's pretty good for a tiny dataset, a shallow model and a bag-of-chars approach. The only problem is that although we split into training and testing, we are evaluating the model with the same document that we trained on. A more appropriate approach would be using a new document as the test set.", "Let's make a function that enables us to predict any custom sentence:", "We just built a cool Machine Learning model", "And our model scores! Unfortunately, when I tried more sentences it showed bad performance classifying some of them. The bag-of-words (in this case chars) method isn't probably the best option, the algorithm itself could be highly improved and we should label many more data points for the model to become reliable. The point here is that you could use this same approach to perform a lot of different tasks, e.g. recognizing specific elements (e.g. links, dates, names, topics, titles, equations, references, and more). Used the right way, text classification can be a powerful tool to help in the cleaning process, and should not be taken for granted. Good cleaning!", "Thank you if you kept reading until the end. This was an article focused on text classification to handle cleaning problems. Please follow my profile for more on data science and feel free to let me any comments or concerns. See you next post!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa2a1fc818935&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rodrigonader?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rodrigonader?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "Rodrigo Nader"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fecc896893943&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&user=Rodrigo+Nader&userId=ecc896893943&source=post_page-ecc896893943----a2a1fc818935---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2a1fc818935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2a1fc818935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://machinelearningmastery.com/clean-text-machine-learning-python/", "anchor_text": "this"}, {"url": "https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/", "anchor_text": "this"}, {"url": "https://docs.python.org/2/library/re.html", "anchor_text": "regular expressions"}, {"url": "https://machinelearningmastery.com/gentle-introduction-bag-words-model/", "anchor_text": "bag-of-words"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a2a1fc818935---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a2a1fc818935---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----a2a1fc818935---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/text-classification?source=post_page-----a2a1fc818935---------------text_classification-----------------", "anchor_text": "Text Classification"}, {"url": "https://medium.com/tag/data-cleaning?source=post_page-----a2a1fc818935---------------data_cleaning-----------------", "anchor_text": "Data Cleaning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa2a1fc818935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&user=Rodrigo+Nader&userId=ecc896893943&source=-----a2a1fc818935---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa2a1fc818935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&user=Rodrigo+Nader&userId=ecc896893943&source=-----a2a1fc818935---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2a1fc818935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa2a1fc818935&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a2a1fc818935---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a2a1fc818935--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a2a1fc818935--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a2a1fc818935--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rodrigonader?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rodrigonader?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rodrigo Nader"}, {"url": "https://medium.com/@rodrigonader/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "728 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fecc896893943&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&user=Rodrigo+Nader&userId=ecc896893943&source=post_page-ecc896893943--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F574c34c0a484&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-custom-classifier-for-text-cleaning-a2a1fc818935&newsletterV3=ecc896893943&newsletterV3Id=574c34c0a484&user=Rodrigo+Nader&userId=ecc896893943&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}