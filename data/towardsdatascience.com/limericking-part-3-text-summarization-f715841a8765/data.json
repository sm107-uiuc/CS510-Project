{"url": "https://towardsdatascience.com/limericking-part-3-text-summarization-f715841a8765", "time": 1682997593.428176, "path": "towardsdatascience.com/limericking-part-3-text-summarization-f715841a8765/", "webpage": {"metadata": {"title": "Limericking part 3: text summarization | by Max Miller | Towards Data Science", "h1": "Limericking part 3: text summarization", "description": "Welcome to part 3 in my ongoing Limericking series, where I explore the great potential of Natural Language Processing to parse news text and write poetry. As I explained in part 1 of the series, I\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/limericking-part-1-context-and-haikus-3eb057c8154f", "anchor_text": "part 1 of the series", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/limericking-part-2-topic-modeling-with-lda-45476ab9af15", "anchor_text": "My last entry in this series", "paragraph_index": 2}, {"url": "https://spacy.io/", "anchor_text": "NLP package spaCy", "paragraph_index": 7}, {"url": "https://www.npr.org/sections/thesalt/2019/08/08/748416223/to-slow-global-warming-u-n-warns-agriculture-must-change", "anchor_text": "this article", "paragraph_index": 8}, {"url": "https://www.npr.org/2019/08/07/749224941/scientists-discover-prehistoric-giant-squawkzilla-parrot-as-big-as-small-child", "anchor_text": "enormous pre-historic parrot", "paragraph_index": 12}], "all_paragraphs": ["Welcome to part 3 in my ongoing Limericking series, where I explore the great potential of Natural Language Processing to parse news text and write poetry. As I explained in part 1 of the series, I am an avid fan of the Twitter account Limericking which digests the news and produces brilliant limericks.", "The only problem is that Limericking is but one account. The rest of the mainstream media has so far ignored my demands to report all news in rhyming verse, leaving most of our news consumption dangerously un-versified. I hope to help bridge the gap by bringing the great powers of automation to bear on the problem with the creation of an automatic-limericking-program. Can a function take in a news text, properly interpret it for meaning and re-craft it into a limerick? I believe the answer is yes, though it may take me a few more blog posts to work through all the kinks. I have auto-generated some surprisingly succesful haikus, however.", "The first big task is finding a way for the computer to \u2018read\u2019 a given news text and return some sort of summary or set of keywords. Later we\u2019ll have to think about how to get the computer generate its own text that scans properly and rhymes (and has a proper comedic turn), but for now, simply extracting the topic out of the text has proven hard enough. My last entry in this series discussed using Latent Dirichlet Allocation to try to group articles together into \u2018topics\u2019 and identify meaningful words associated with those topics. Results were not great.", "Perhaps I\u2019ve been overthinking this part of the challenge, though. For as difficult a problem as topic modeling is, one of the things that my initial haiku writing function from part 1 did surprisingly well was identifying what the news article was about. I simply reasoned that the article would likely be about a proper noun, like a person or company, and that the subject would likely occur multiple times in the text of the article. Simply finding the proper nouns and counting which ones occur most often goes a long way towards identifying what the article is about. One of the crucial things about a strategy like this is that it is entirely rules-based: it doesn\u2019t require a model to be trained on a well labeled example set of articles and it doesn\u2019t require the computer to \u2018understand\u2019 what a given word means or why it might be the subject of the article on a conceptual basis. What\u2019s more, the function simply identifies and returns an element of the original text, so you don\u2019t have to grapple with text generation just yet.", "Perhaps there\u2019s a way to do something similar but that would work on larger blocks of text: a function that would, say, compare the different sentences of a text on some set of easily countable features and then return a sentence that seemed most central in the way that the proper noun that was repeated most often seemed \u2018central\u2019. As it turns out, there is a way of going about this, it\u2019s pretty easy to implement and it works pretty well. The key insight is figuring out how to measure how \u2018central\u2019 or \u2018topical\u2019 a given sentence is. What is the sentence-sized analog to finding the proper noun that is used most often?", "One way to approach this is to try to compare how similar the sentences within the text are to each other based on which words they contain. Imagine, for instance, a local news story about the mayor of your town. Which words are likely to show up most in that story and across the most sentences? Certainly you\u2019d expect the name of the town and the name of the mayor would appear numerous times and in numerous different sentences. The article might have a more specific topic, such as a particular event or aspect of the mayor\u2019s work, and that would show up multiple times across the article as well. Other things might show up in the text less often, perhaps one sentence may mention the mayor\u2019s predecessor or what\u2019s going on in a neighboring town.", "How might you teach a computer to recognize which sentences seem most important given what we expect about the distribution of these words? Well, one way is to simply find the sentences that have most words in common with the other sentences in the piece. If the sentence has words like the mayor\u2019s name or the name of the town, it will look similar to the numerous other sentences in the piece that contain those words. If a sentence is talking about the next town over and the name of that town is only mentioned that one time, that sentence will look less similar to the other sentences in the article. For a concrete example, consider an article about the sorry state of the subway in New York. A sentence like \u201cNew Yorkers blame de Blasio for subway woes\u201d will probably look similar to other sentences in the piece just based on the word counts: \u2018New York\u2019, \u2018Subway\u2019, etc. A sentence like \u201cThings weren\u2019t as bad under Bloomberg\u201d will look less similar, containing a novel word like \u2018Bloomberg\u2019.", "To implement this strategy, first we\u2019ll need to convert each sentence into something the computer can more easily handle, like a vector where the values in different columns correspond to how many times a given word appears in the sentence. Then the computer can easily compare the vectors that correspond to any two given sentences with a method like cosine similarity. Luckily, sklearn easily handles both the vectorization and the similarity. Consider the following implementation, which is pretty straightforward save for two minor quirks: 1) I use the excellent NLP package spaCy o segment a large block of text into sentences, but then have to convert the sentences back into string objects (rather than spaCy tokens) and 2) I have a little loop in the first function which will exclude sentences that are repeated exactly. I included this because depending on where the text is scraped from, I found that I would have repeated phrases like \u201cClick here to subscribe\u201d which I wanted to exclude:", "How does this work in practice? Well. Maybe even surprisingly well, given the simplicity of it. For instance, this article about the agricultural impacts on climate change has 23 sentences. My function identifies these as the most useful 5:", "Not bad at all! There are a couple of odd holdovers from the complete text (like the sentence that begins \u201cat that time\u201d without a clear referent) but the main gist of the piece is easy to follow.", "I want to save the actual poetry generation for future posts in this series, but I think a simple system to condense the text into a summary like has some clear benefits. Our future limerick generator won\u2019t have to create text out of whole cloth, it will have important sentences identified for it and it will merely need to shape them properly into limerick form. It will be able to borrow whole blocks of text without needing to worry about morphology or word order.", "The implications for my haiku generator are also clear. This provides a very useful way to identify a subject to insert into the haiku (the literal, grammatical subject of one of the identified sentences) and a way to identify a set of words that should be selected (a vocabulary derived from the summary sentences, rather than the entire text itself). I applied those changes to my haiku generator, which promptly returned this brilliant piece derived from the climate change article:", "From this delightful story about the discovery an enormous pre-historic parrot, we get this rather apt nugget:", "But then, I suppose, when your starting point is the wonderful news of the discovery of an ancient, child sized parrot, the results are bound to be that fun.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist with a particular passion for limericks, policy and renewable energy."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff715841a8765&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f715841a8765--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f715841a8765--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----f715841a8765--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----f715841a8765--------------------------------", "anchor_text": "Max Miller"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332----f715841a8765---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff715841a8765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff715841a8765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/limericking-part-1-context-and-haikus-3eb057c8154f", "anchor_text": "part 1 of the series"}, {"url": "https://towardsdatascience.com/limericking-part-2-topic-modeling-with-lda-45476ab9af15", "anchor_text": "My last entry in this series"}, {"url": "https://spacy.io/", "anchor_text": "NLP package spaCy"}, {"url": "https://www.npr.org/sections/thesalt/2019/08/08/748416223/to-slow-global-warming-u-n-warns-agriculture-must-change", "anchor_text": "this article"}, {"url": "https://www.npr.org/2019/08/07/749224941/scientists-discover-prehistoric-giant-squawkzilla-parrot-as-big-as-small-child", "anchor_text": "enormous pre-historic parrot"}, {"url": "https://medium.com/tag/nlp?source=post_page-----f715841a8765---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/the-limericking-project?source=post_page-----f715841a8765---------------the_limericking_project-----------------", "anchor_text": "The Limericking Project"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f715841a8765---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff715841a8765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&user=Max+Miller&userId=dfd5ba1a8332&source=-----f715841a8765---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff715841a8765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&user=Max+Miller&userId=dfd5ba1a8332&source=-----f715841a8765---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff715841a8765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f715841a8765--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff715841a8765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f715841a8765---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f715841a8765--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f715841a8765--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f715841a8765--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f715841a8765--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f715841a8765--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f715841a8765--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f715841a8765--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f715841a8765--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Max Miller"}, {"url": "https://medium.com/@max.samuel.miller/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "409 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F930bd413e257&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flimericking-part-3-text-summarization-f715841a8765&newsletterV3=dfd5ba1a8332&newsletterV3Id=930bd413e257&user=Max+Miller&userId=dfd5ba1a8332&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}