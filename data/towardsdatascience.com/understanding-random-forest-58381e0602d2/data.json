{"url": "https://towardsdatascience.com/understanding-random-forest-58381e0602d2", "time": 1682996618.499669, "path": "towardsdatascience.com/understanding-random-forest-58381e0602d2/", "webpage": {"metadata": {"title": "Understanding Random Forest. How the Algorithm Works and Why it Is\u2026 | by Tony Yiu | Towards Data Science", "h1": "Understanding Random Forest", "description": "A big part of machine learning is classification \u2014 we want to know what class (a.k.a. group) an observation belongs to. The ability to precisely classify observations is extremely valuable for\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/understanding-logistic-regression-using-a-simple-example-163de52ea900", "anchor_text": "logistic regression", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Ensemble_learning", "anchor_text": "ensemble", "paragraph_index": 11}, {"url": "https://github.com/yiuhyuk/coin_flip_game", "anchor_text": "on my GitHub here", "paragraph_index": 21}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "If you liked this article and my writing in general, please consider supporting my writing by signing up for Medium via my referral link here. Thanks!", "paragraph_index": 35}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "https://tonester524.medium.com/membership", "paragraph_index": 37}], "all_paragraphs": ["A big part of machine learning is classification \u2014 we want to know what class (a.k.a. group) an observation belongs to. The ability to precisely classify observations is extremely valuable for various business applications like predicting whether a particular user will buy a product or forecasting whether a given loan will default or not.", "Data science provides a plethora of classification algorithms such as logistic regression, support vector machine, naive Bayes classifier, and decision trees. But near the top of the classifier hierarchy is the random forest classifier (there is also the random forest regressor but that is a topic for another day).", "In this post, we will examine how basic decision trees work, how individual decisions trees are combined to make a random forest, and ultimately discover why random forests are so good at what they do.", "Let\u2019s quickly go over decision trees as they are the building blocks of the random forest model. Fortunately, they are pretty intuitive. I\u2019d be willing to bet that most people have used a decision tree, knowingly or not, at some point in their lives.", "It\u2019s probably much easier to understand how a decision tree works through an example.", "Imagine that our dataset consists of the numbers at the top of the figure to the left. We have two 1s and five 0s (1s and 0s are our classes) and desire to separate the classes using their features. The features are color (red vs. blue) and whether the observation is underlined or not. So how can we do this?", "Color seems like a pretty obvious feature to split by as all but one of the 0s are blue. So we can use the question, \u201cIs it red?\u201d to split our first node. You can think of a node in a tree as the point where the path splits into two \u2014 observations that meet the criteria go down the Yes branch and ones that don\u2019t go down the No branch.", "The No branch (the blues) is all 0s now so we are done there, but our Yes branch can still be split further. Now we can use the second feature and ask, \u201cIs it underlined?\u201d to make a second split.", "The two 1s that are underlined go down the Yes subbranch and the 0 that is not underlined goes down the right subbranch and we are all done. Our decision tree was able to use the two features to split up the data perfectly. Victory!", "Obviously in real life our data will not be this clean but the logic that a decision tree employs remains the same. At each node, it will ask \u2014", "What feature will allow me to split the observations at hand in a way that the resulting groups are as different from each other as possible (and the members of each resulting subgroup are as similar to each other as possible)?", "Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model\u2019s prediction (see figure below).", "The fundamental concept behind random forest is a simple but powerful one \u2014 the wisdom of crowds. In data science speak, the reason that the random forest model works so well is:", "A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.", "The low correlation between models is the key. Just like how investments with low correlations (like stocks and bonds) come together to form a portfolio that is greater than the sum of its parts, uncorrelated models can produce ensemble predictions that are more accurate than any of the individual predictions. The reason for this wonderful effect is that the trees protect each other from their individual errors (as long as they don\u2019t constantly all err in the same direction). While some trees may be wrong, many other trees will be right, so as a group the trees are able to move in the correct direction. So the prerequisites for random forest to perform well are:", "The wonderful effects of having many uncorrelated models is such a critical concept that I want to show you an example to help it really sink in. Imagine that we are playing the following game:", "Which would you pick? The expected value of each game is the same:", "What about the distributions? Let\u2019s visualize the results with a Monte Carlo simulation (we will run 10,000 simulations of each game type; for example, we will simulate 10,000 times the 100 plays of Game 1). Take a look at the chart on the left \u2014 now which game would you pick? Even though the expected values are the same, the outcome distributions are vastly different going from positive and narrow (blue) to binary (pink).", "Game 1 (where we play 100 times) offers up the best chance of making some money \u2014 out of the 10,000 simulations that I ran, you make money in 97% of them! For Game 2 (where we play 10 times) you make money in 63% of the simulations, a drastic decline (and a drastic increase in your probability of losing money). And Game 3 that we only play once, you make money in 60% of the simulations, as expected.", "So even though the games share the same expected value, their outcome distributions are completely different. The more we split up our $100 bet into different plays, the more confident we can be that we will make money. As mentioned previously, this works because each play is independent of the other ones.", "Random forest is the same \u2014 each tree is like one play in our game earlier. We just saw how our chances of making money increased the more times we played. Similarly, with a random forest model, our chances of making correct predictions increase with the number of uncorrelated trees in our model.", "If you would like to run the code for simulating the game yourself you can find it on my GitHub here.", "So how does random forest ensure that the behavior of each individual tree is not too correlated with the behavior of any of the other trees in the model? It uses the following two methods:", "Bagging (Bootstrap Aggregation) \u2014 Decisions trees are very sensitive to the data they are trained on \u2014 small changes to the training set can result in significantly different tree structures. Random forest takes advantage of this by allowing each individual tree to randomly sample from the dataset with replacement, resulting in different trees. This process is known as bagging.", "Notice that with bagging we are not subsetting the training data into smaller chunks and training each tree on a different chunk. Rather, if we have a sample of size N, we are still feeding each tree a training set of size N (unless specified otherwise). But instead of the original training data, we take a random sample of size N with replacement. For example, if our training data was [1, 2, 3, 4, 5, 6] then we might give one of our trees the following list [1, 2, 2, 3, 6, 6]. Notice that both lists are of length six and that \u201c2\u201d and \u201c6\u201d are both repeated in the randomly selected training data we give to our tree (because we sample with replacement).", "Feature Randomness \u2014 In a normal decision tree, when it is time to split a node, we consider every possible feature and pick the one that produces the most separation between the observations in the left node vs. those in the right node. In contrast, each tree in a random forest can pick only from a random subset of features. This forces even more variation amongst the trees in the model and ultimately results in lower correlation across trees and more diversification.", "Let\u2019s go through a visual example \u2014 in the picture above, the traditional decision tree (in blue) can select from all four features when deciding how to split the node. It decides to go with Feature 1 (black and underlined) as it splits the data into groups that are as separated as possible.", "Now let\u2019s take a look at our random forest. We will just examine two of the forest\u2019s trees in this example. When we check out random forest Tree 1, we find that it it can only consider Features 2 and 3 (selected randomly) for its node splitting decision. We know from our traditional decision tree (in blue) that Feature 1 is the best feature for splitting, but Tree 1 cannot see Feature 1 so it is forced to go with Feature 2 (black and underlined). Tree 2, on the other hand, can only see Features 1 and 3 so it is able to pick Feature 1.", "So in our random forest, we end up with trees that are not only trained on different sets of data (thanks to bagging) but also use different features to make decisions.", "And that, my dear reader, creates uncorrelated trees that buffer and protect each other from their errors.", "Random forests are a personal favorite of mine. Coming from the world of finance and investments, the holy grail was always to build a bunch of uncorrelated models, each with a positive expected return, and then put them together in a portfolio to earn massive alpha (alpha = market beating returns). Much easier said than done!", "Random forest is the data science equivalent of that. Let\u2019s review one last time. What\u2019s a random forest classifier?", "The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.", "What do we need in order for our random forest to make accurate class predictions?", "Thanks for reading. I hope you learned as much from reading this as I did from writing it. Cheers!", "If you liked this article and my writing in general, please consider supporting my writing by signing up for Medium via my referral link here. Thanks!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist. Founder Alpha Beta Blog. Doing my best to explain the complex in plain English. Support my writing: https://tonester524.medium.com/membership"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F58381e0602d2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----58381e0602d2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----58381e0602d2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tonester524.medium.com/?source=post_page-----58381e0602d2--------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=post_page-----58381e0602d2--------------------------------", "anchor_text": "Tony Yiu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840a3210fbe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&user=Tony+Yiu&userId=840a3210fbe7&source=post_page-840a3210fbe7----58381e0602d2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58381e0602d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58381e0602d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.pexels.com/@skitterphoto?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Skitterphoto"}, {"url": "https://www.pexels.com/photo/bright-daylight-environment-forest-240040/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Pexels"}, {"url": "https://towardsdatascience.com/understanding-logistic-regression-using-a-simple-example-163de52ea900", "anchor_text": "logistic regression"}, {"url": "https://en.wikipedia.org/wiki/Ensemble_learning", "anchor_text": "ensemble"}, {"url": "https://github.com/yiuhyuk/coin_flip_game", "anchor_text": "on my GitHub here"}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "If you liked this article and my writing in general, please consider supporting my writing by signing up for Medium via my referral link here. Thanks!"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----58381e0602d2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----58381e0602d2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/technology?source=post_page-----58381e0602d2---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/programming?source=post_page-----58381e0602d2---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----58381e0602d2---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F58381e0602d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&user=Tony+Yiu&userId=840a3210fbe7&source=-----58381e0602d2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F58381e0602d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&user=Tony+Yiu&userId=840a3210fbe7&source=-----58381e0602d2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58381e0602d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----58381e0602d2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F58381e0602d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----58381e0602d2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----58381e0602d2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----58381e0602d2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----58381e0602d2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----58381e0602d2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----58381e0602d2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----58381e0602d2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----58381e0602d2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----58381e0602d2--------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tony Yiu"}, {"url": "https://tonester524.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "102K Followers"}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "https://tonester524.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840a3210fbe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&user=Tony+Yiu&userId=840a3210fbe7&source=post_page-840a3210fbe7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F78d3e392d884&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-random-forest-58381e0602d2&newsletterV3=840a3210fbe7&newsletterV3Id=78d3e392d884&user=Tony+Yiu&userId=840a3210fbe7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}