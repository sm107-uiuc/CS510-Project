{"url": "https://towardsdatascience.com/tinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec", "time": 1683002997.3099189, "path": "towardsdatascience.com/tinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec/", "webpage": {"metadata": {"title": "TinyBERT for Search: 10x faster and 20x smaller than BERT | by Jack Pertschuk | Towards Data Science", "h1": "TinyBERT for Search: 10x faster and 20x smaller than BERT", "description": "Recently, Google introduced a new method of understanding searches and deciding which results you see. This method, based on the popular open-source transformer BERT, uses language understanding to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.blog.google/products/search/search-language-understanding-bert/", "anchor_text": "Google introduced a new method of understanding searches and deciding which results", "paragraph_index": 0}, {"url": "https://github.com/koursaros-ai/nboost", "anchor_text": "NBoost", "paragraph_index": 1}, {"url": "https://cloud.google.com/blog/products/ai-machine-learning/cloud-tpu-pods-break-ai-training-records", "anchor_text": "Cloud TPUs", "paragraph_index": 3}, {"url": "https://nervanasystems.github.io/distiller/knowledge_distillation.html", "anchor_text": "knowledge distillation", "paragraph_index": 4}, {"url": "https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT", "anchor_text": "this repo", "paragraph_index": 5}, {"url": "http://www.msmarco.org/", "anchor_text": "MS Marco", "paragraph_index": 5}, {"url": "http://msmarco.org", "anchor_text": "MS Marco", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1904.07531", "anchor_text": "BERT Base was first used on MSMarco", "paragraph_index": 7}], "all_paragraphs": ["Recently, Google introduced a new method of understanding searches and deciding which results you see. This method, based on the popular open-source transformer BERT, uses language understanding to pick up on the meaning behind searches in a way that traditional keyword methods aren\u2019t able to.", "We built NBoost to make it easy for people who are not Google to also use advanced search ranking models, and in the process developed TinyBERT for search, which I introduce in this article.", "Particularly for longer, more conversational queries, or searches where prepositions like \u201cfor\u201d and \u201cto\u201d matter a lot to the meaning, Search will be able to understand the context of the words in your query. You can search in a way that feels natural for you.- Pandu Nayak, VP of Search @ Google", "BERT has been shown to improve search results, but there\u2019s a catch: it takes a huge number of computers to run these query understanding models. This is especially true when speed matters and millions of searches have to be processed. This challenge is so formidable that Google even built their own hardware (Cloud TPUs) to run the models on. And the code they use to run these TPUs in production is private, so anyone else who wants to run it is out of luck.", "In order to run these models on standard hardware, we use knowledge distillation, a process by which a larger teacher network is used to a train a smaller student network which maintains most of the accuracy but uses fewer, often smaller layers, making it smaller and faster.", "We used the code from this repo for knowledge distillation and modified it for training and evaluation on the MS Marco dataset. We initially trained a teacher bert-base-uncased network in PyTorch with the MS Marco training triples set. Then we used it as a teacher to train a smaller student BERT network with only 4 hidden layers instead of the standard 12. Additionally, each of these layers is only of size 312 instead of 768, making the model even more lightweight. We use a feedforward binary classification layer at the end of BERT to produce the scores for search ranking.", "The following is a sample bert_config.json for the tinyBERT architecture we use, with the notable differences from standard bert_config bolded.", "MS Marco is the largest publicly available source of real world search engine usage data, making it ideal for evaluating search and question answering models. It shows real world bing results and info about what users ultimately ended up clicking. When BERT Base was first used on MSMarco, it beat the state of the art by 0.05 MRR (a lot). BERT based solutions are still at the top of the leaderboard. Our goal was to find a way to achieve this boost from a model that was fast enough to use in the real world.", "Enter, TinyBERT. While not as effective as BERT Base for reranking, our experiments show that it retained 90% of the MRR score of BERT Base (0.26 vs 0.29 reranking top 50 from BM25) while making the model ~10x faster and ~20x smaller. However, results based on academic benchmarks such as MS Marco often lack real world generalizability and hence should be taken with a grain of salt.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F74cd1b6b5aec&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jackpertschuk?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jackpertschuk?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "Jack Pertschuk"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa97c68c557df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&user=Jack+Pertschuk&userId=a97c68c557df&source=post_page-a97c68c557df----74cd1b6b5aec---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74cd1b6b5aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74cd1b6b5aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/@colethienes", "anchor_text": "Cole Thienes"}, {"url": "https://www.blog.google/products/search/search-language-understanding-bert/", "anchor_text": "Google introduced a new method of understanding searches and deciding which results"}, {"url": "https://github.com/koursaros-ai/nboost", "anchor_text": "NBoost"}, {"url": "https://cloud.google.com/blog/products/ai-machine-learning/cloud-tpu-pods-break-ai-training-records", "anchor_text": "Cloud TPUs"}, {"url": "https://nervanasystems.github.io/distiller/knowledge_distillation.html", "anchor_text": "knowledge distillation"}, {"url": "https://nervanasystems.github.io/distiller/knowledge_distillation.html", "anchor_text": "https://nervanasystems.github.io/distiller/knowledge_distillation.html"}, {"url": "https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT", "anchor_text": "this repo"}, {"url": "http://www.msmarco.org/", "anchor_text": "MS Marco"}, {"url": "http://msmarco.org", "anchor_text": "MS Marco"}, {"url": "https://arxiv.org/abs/1904.07531", "anchor_text": "BERT Base was first used on MSMarco"}, {"url": "https://medium.com/tag/nlp?source=post_page-----74cd1b6b5aec---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----74cd1b6b5aec---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----74cd1b6b5aec---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/tag/google?source=post_page-----74cd1b6b5aec---------------google-----------------", "anchor_text": "Google"}, {"url": "https://medium.com/tag/search?source=post_page-----74cd1b6b5aec---------------search-----------------", "anchor_text": "Search"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74cd1b6b5aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&user=Jack+Pertschuk&userId=a97c68c557df&source=-----74cd1b6b5aec---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74cd1b6b5aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&user=Jack+Pertschuk&userId=a97c68c557df&source=-----74cd1b6b5aec---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74cd1b6b5aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F74cd1b6b5aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----74cd1b6b5aec---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----74cd1b6b5aec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jackpertschuk?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jackpertschuk?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jack Pertschuk"}, {"url": "https://medium.com/@jackpertschuk/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "64 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa97c68c557df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&user=Jack+Pertschuk&userId=a97c68c557df&source=post_page-a97c68c557df--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fa97c68c557df%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec&user=Jack+Pertschuk&userId=a97c68c557df&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}