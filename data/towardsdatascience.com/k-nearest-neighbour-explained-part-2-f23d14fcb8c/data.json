{"url": "https://towardsdatascience.com/k-nearest-neighbour-explained-part-2-f23d14fcb8c", "time": 1683006188.125636, "path": "towardsdatascience.com/k-nearest-neighbour-explained-part-2-f23d14fcb8c/", "webpage": {"metadata": {"title": "K-Nearest Neighbour Explained-Part 2 | by Paras Varshney | Towards Data Science", "h1": "K-Nearest Neighbour Explained-Part 2", "description": "In this story, we would be talking about the different types of distance measurement metrics used to calculate the distance between two vectors. The application of this metric is in finding the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Norm_(mathematics)", "anchor_text": "L1 Norm", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Richard_Hamming", "anchor_text": "Richard Hamming", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Hamming_code", "anchor_text": "Hamming codes", "paragraph_index": 10}, {"url": "https://medium.com/@pv009", "anchor_text": "Medium", "paragraph_index": 18}, {"url": "https://www.linkedin.com/in/pv009", "anchor_text": "LinkedIn", "paragraph_index": 18}, {"url": "https://parasvarshney.ml", "anchor_text": "https://parasvarshney.ml", "paragraph_index": 20}], "all_paragraphs": ["In this story, we would be talking about the different types of distance measurement metrics used to calculate the distance between two vectors. The application of this metric is in finding the nearest neighbors in the K-NN algorithm. We would look into the implementation of these distances in Python.", "This article is in continuation of the previously written Part 1 on K-NN. If you have not read it, give it a read and come back.", "This is a distance measurement technique to find the distance between two points in space by directly joining them end to end. Let us see we have a 2D plane as shown in the figure below, with points p(p1, p2) and q(q1, q2) on the plane. Now we need to find the distance between these points so we use the Pythagoras Theorem to calculate the distance between two points which is nothing but the Euclidean Distance.", "We have the vector with two dimensions for the points p(p1, p2) and q(q1, q2) so the distance is calculated using the formula,", "So if we have an n-dimensional vector in space (which we can not visualize directly) then going with the same pattern we will have the distance calculated between the two points is as,", "So as a conclusion, the distance between any two points in space is calculated by directly joining the points end to end using a straight line which is called the Euclidean Distance.", "The second amazing distance calculating methodology is the Manhattan Distance which is also called as \u201cTaxicab distance\u201d because like a taxi or a cab travels across the streets of a city to reach a point in the city, in the same way, manhattan distance is calculated by doing the sum of the absolute distances.", "So why is it called as Manhattan? Manhattan distance is given the name Manhattan because when we look at the city of New York for the region of Manhattan from the satellite view the roads and the lanes look like completely \u201csymmetric grid pattern\u201d so, for a taxi to travel from one point to another within the city, it has to follow the strategy of moving one move on the x-axis and one on the y-axis which is nothing but the absolute path traveled.", "Manhattan distance can be calculated using the concept for L1 Norm where p(p1, p2, \u2026, pn) and q(q1, q2, \u2026, qn) are the n-dimensional vectors.", "There is an amazing distance finding technique called as \u201cHamming Distance\u201d which is generally used to find the symmetric distance between the two strings which is calculated by finding the unequal characters at all the positions in two strings and then summing them up to calculate the total unequal character value.", "Why is it called Hamming Distance? The Hamming distance is named after Richard Hamming, who introduced the concept in his fundamental paper on Hamming codes.", "To find the distance between the two strings S1 and S2 we start exploring all the characters of both the strings one by one simultaneously from left to right and whenever a character in the first string is not equal to the character in the second string at the same position then we increase the count of distance by one which simply means that the count increases only when the character does not match in the two strings.", "\u201cHamming distance only works when we have both the strings of exactly the same length.\u201d", "For example, The distance between \u201ckarolin\u201d and \u201ckathrin\u201d is 3 because the characters at positions 3, 4, and 5 of the first string are different for the second string which increases the distance value by 1.", "Cosine Similarity is the angular distance measured between the two vectors X1 and X2 which means the cos of the angle between X1 and X2. The lesser the angle is higher is the cos(angle) of it and hence higher be its cosine similarity.", "\u201cCosine similarity tells about the directional similarity between two vectors\u201d", "For example, two vectors with angle 0\u00b0 have cos(0\u00b0)=1, which is the highest similarity whereas the vector with angle 90\u00b0 gives cos(90\u00b0)=0 giving a \u20180\u2019 similarity between the vectors. Also when the angle goes to 180\u00b0 between the two vectors then the similarity even becomes \u2018-1\u2019.", "Given two vectors X1 and X2, their Cos-Sim can be calculated as,", "For more Data Science and Machine Learning related articles follow me on Medium. Want to buy me a coffee? Connect with me on LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Ex-Data Scientist at LogicAI, IISc Banglore \u2022 Kaggle Master \u2022 Explorer \u2022 Writer \u2022 https://parasvarshney.ml"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff23d14fcb8c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://blurred-machine.medium.com/?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": ""}, {"url": "https://blurred-machine.medium.com/?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "Paras Varshney"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22b31444736c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&user=Paras+Varshney&userId=22b31444736c&source=post_page-22b31444736c----f23d14fcb8c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff23d14fcb8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff23d14fcb8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/k-nearest-neighbour-explained-part-1-5e5e9192050", "anchor_text": "KNN on U shaped Data"}, {"url": "https://medium.com/analytics-vidhya/k-nearest-neighbour-explained-part-1-5e5e9192050", "anchor_text": "K-Nearest Neighbour Explained-Part 1The science behind the KNN Algorithm Explained!medium.com"}, {"url": "https://en.wikipedia.org/wiki/Euclidean_distance", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Taxicab_geometry", "anchor_text": "Wikipedia"}, {"url": "https://www.google.com/maps/place/Manhattan,+New+York,+NY,+USA/@40.7460163,-73.9981217,14z/data=!4m5!3m4!1s0x89c2588f046ee661:0xa0b3281fcecc08c!8m2!3d40.7830603!4d-73.9712488", "anchor_text": "Google Map"}, {"url": "https://en.wikipedia.org/wiki/Norm_(mathematics)", "anchor_text": "L1 Norm"}, {"url": "https://en.wikipedia.org/wiki/Hamming_distance", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Richard_Hamming", "anchor_text": "Richard Hamming"}, {"url": "https://en.wikipedia.org/wiki/Hamming_code", "anchor_text": "Hamming codes"}, {"url": "https://www.oreilly.com/library/view/statistics-for-machine/9781788295758/eb9cd609-e44a-40a2-9c3a-f16fc4f5289a.xhtml", "anchor_text": "Oreilly"}, {"url": "https://medium.com/@pv009", "anchor_text": "Paras Varshney"}, {"url": "https://medium.com/@pv009/how-to-evaluate-machine-learning-model-performance-in-python-135b4ae27f7e", "anchor_text": "How to Evaluate Machine Learning Model Performance in Python?A Practical Approach to Compute the Model\u2019s Performance and Implementation in Python covering all Mathematical\u2026medium.com"}, {"url": "https://medium.com/datadriveninvestor/how-to-build-a-data-science-portfolio-that-can-get-you-a-job-9f8d113739b3", "anchor_text": "How to Build a Data Science Portfolio that can get you a Job?Learn to Make a Strong Portfolio that Speaks about you!medium.com"}, {"url": "https://medium.com/analytics-vidhya/the-powers-of-normal-distribution-4cbb06e4a955", "anchor_text": "The Powers of \u201cNormal Distribution\u201dUnderstanding the Science behind a Bell Curve!medium.com"}, {"url": "https://medium.com/@pv009", "anchor_text": "Medium"}, {"url": "https://www.linkedin.com/in/pv009", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f23d14fcb8c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f23d14fcb8c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----f23d14fcb8c---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----f23d14fcb8c---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----f23d14fcb8c---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff23d14fcb8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&user=Paras+Varshney&userId=22b31444736c&source=-----f23d14fcb8c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff23d14fcb8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&user=Paras+Varshney&userId=22b31444736c&source=-----f23d14fcb8c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff23d14fcb8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff23d14fcb8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f23d14fcb8c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f23d14fcb8c--------------------------------", "anchor_text": ""}, {"url": "https://blurred-machine.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://blurred-machine.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Paras Varshney"}, {"url": "https://blurred-machine.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "386 Followers"}, {"url": "https://parasvarshney.ml", "anchor_text": "https://parasvarshney.ml"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22b31444736c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&user=Paras+Varshney&userId=22b31444736c&source=post_page-22b31444736c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F703f6b2edfcb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-nearest-neighbour-explained-part-2-f23d14fcb8c&newsletterV3=22b31444736c&newsletterV3Id=703f6b2edfcb&user=Paras+Varshney&userId=22b31444736c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}