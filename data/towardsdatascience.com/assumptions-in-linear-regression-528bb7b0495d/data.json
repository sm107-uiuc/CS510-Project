{"url": "https://towardsdatascience.com/assumptions-in-linear-regression-528bb7b0495d", "time": 1683011020.9633448, "path": "towardsdatascience.com/assumptions-in-linear-regression-528bb7b0495d/", "webpage": {"metadata": {"title": "Assumptions in Linear Regression you might not know. | by Sparsh Gupta | Towards Data Science", "h1": "Assumptions in Linear Regression you might not know.", "description": "Linear Regression is a method of modelling the best linear relationship between the independent variables and dependent variables. The simplest form of Linear Regression can be defined by\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Linearity", "anchor_text": "linear", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Dependent_variable", "anchor_text": "dependent variable", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Explanatory_variable", "anchor_text": "explanatory variables", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Independent_variable", "anchor_text": "independent variables", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Linear_regression", "anchor_text": "Wikipedia", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/@imsparsh", "anchor_text": "Machine Learning related posts here", "paragraph_index": 21}, {"url": "https://www.linkedin.com/in/imsparsh/", "anchor_text": "LinkedIn", "paragraph_index": 22}], "all_paragraphs": ["\u2014 All the images (plots) are generated and modified by Author.", "At first, Linear Regression is a method of modelling the best linear relationship between the independent variables and dependent variables. The simplest form of Linear Regression can be defined by the following equation with one independent and one dependent variable:", "x is the independent variable, y is the dependent variable,\u03b21 is the coefficient of x, i.e. slope, \u03b20 is the intercept (constant) which tells the distance of the line from the origin on y-axis.", "Linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). \u2014 Wikipedia", "1. Simple Linear Regression \u2014 The simplest form of regression which involves one independent variable and one dependent variable, which is explained as above, where we fit a line to the model.", "2. Multiple Linear Regression \u2014 The complex form of regression which involves multiple independent variables and one dependent variable, which can be explained by the following equation:", "x1 to xn are the independent variable, y is the dependent variable,\u03b21 to \u03b2n are the coefficients of respective x features, and\u03b20 is the intercept (constant) which tells the distance of the line from the origin on y-axis.", "1. Linear Relationship \u2014 It is assumed and understood that the relation between the independent variables and dependent variables is linear, i.e. the coefficients must be linear, what we find out using the model building and prediction.", "The predictor variables are seen as fixed values and can be any complex function like polynomial, trigonometric, etc. But the coefficients will be strictly linear with the predictor variable.", "This assumption is used for implementing the Polynomial regression, which uses linear regression to fit the response variable as an arbitrary polynomial function of a predictor variable which also makes the linear relationship with the coefficients.", "2. Homoscedasticity (Constant Variance) \u2014 It is assumed that the residual terms (that is, the \u201cnoise\u201d or random disturbance in the relationship between the features and the target) must have the constant variance, i.e. the error term is same across different values of independent features, regardless of the values of the predictor variables.", "There should be no clear pattern in the distribution and if there is a specific pattern, the data is heteroscedastic. The leftmost graph shows no definite pattern among the error terms i.e the distribution is varied constantly, whereas the middle graph shows a pattern where the error decreases and then increases with the estimated values violating the constant variance rule and the rightmost graph also reveals a specific pattern where the error terms decrease with the predicted values representing heteroscedasticity. Two or more normal distributions are homoscedastic if they share a common covariance (or correlation) matrix.", "3. Multivariate Normality \u2014 It is assumed that the error terms are normally distributed, i.e. the mean of error terms is zero and the sum of error terms is also equal to zero. A less widely known fact is that, as the sample size goes high, the normality assumption for the residuals is not needed anymore.", "The above q-q plot shows that the errors or residuals are normally distributed. The error term can be seen as the composite of some minor residuals or errors. As the number of these minor residuals increases, the distribution of the error term tends to approach the normal distribution. This tendency is called the Central Limit Theorem where the t-test and F- test are only applicable if the error term is normally distributed.", "4. No Multicollinearity \u2014 Multicollinearity is defined as the degree of inter-correlations among the independent variables used in the model. It is assumed that the independent feature variables are not at all or very less correlated among each other, which makes them independent. So in practical implementation, the correlation between two independent features must not be greater than 30% as it weakens the statistical power of the model built. For identification of highly correlated features, pair plots (scatter plot) and heatmaps (correlation matrix) can be used.", "Highly correlated features should not be used in the model to maintain the strong relationship between the model and all its features present as the features tend to change in unison. Hence, with the change in one feature, the change in correlated feature does not make the latter constant as the model requires it while predicting the outcome using the weighted coefficients and the expected interpretation of regression coefficient does not conform.", "5. No Auto-correlation \u2014 It is assumed that there should be no auto-correlation among the features in the data. It mainly occurs when there is a dependency between residual errors, i.e. the residual error should not be correlated positively or negatively, and it should have a good spread all over. This usually occurs in time series models where the next instant is dependent on the previous instant. The presence of correlation in the residual terms also reduces the model\u2019s predictability.", "Autocorrelation can be tested with the help of the Durbin-Watson test. The Durbin-Watson test statistics is defined as:", "The Durbin-Watson test statistics will always have a value between 0 and 4. An exact value of 2.0 states that there is no autocorrelation detected in the sample. Values between 0 and 2 indicate positive autocorrelation and values between 2 and 4 indicates negative autocorrelation.", "6. No Extrapolation \u2014 Extrapolation is an estimation that can exist beyond the original observation range. It is assumed that the trained model will be able to predict the values for the dependent variable on independent feature values only for the data that lies within the range of the training data. Therefore, the model cannot guarantee the predicted values that are beyond the range of trained independent feature values.", "We have explained the most important assumptions which must be focussed before implementing a Linear Regression Model to a given set of data. These assumptions are just a formal measure to ensure that the predictability of the built linear regression model is good enough to give us the best possible results for a given data set. These assumptions if not satisfied will not stop a Linear regression model to be built but will provide good confidence to the predictability of the model.", "Thanks for reading. You can find my other Machine Learning related posts here.", "I hope this post has been useful. I appreciate feedback and constructive criticism. If you want to talk about this article or other related topics, you can drop me a text here or at LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI Technologist. Programmer. Musician. Explorer - Working in Machine Learning & AI. Otherways, a Singer-songwriter."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F528bb7b0495d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@imsparsh?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@imsparsh?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "Sparsh Gupta"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fda9091f87266&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&user=Sparsh+Gupta&userId=da9091f87266&source=post_page-da9091f87266----528bb7b0495d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F528bb7b0495d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F528bb7b0495d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jbcreate_?utm_source=medium&utm_medium=referral", "anchor_text": "Joseph Barrientos"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Linearity", "anchor_text": "linear"}, {"url": "https://en.wikipedia.org/wiki/Dependent_variable", "anchor_text": "dependent variable"}, {"url": "https://en.wikipedia.org/wiki/Explanatory_variable", "anchor_text": "explanatory variables"}, {"url": "https://en.wikipedia.org/wiki/Independent_variable", "anchor_text": "independent variables"}, {"url": "https://en.wikipedia.org/wiki/Linear_regression", "anchor_text": "Wikipedia"}, {"url": "https://unsplash.com/@tomrdesigns?utm_source=medium&utm_medium=referral", "anchor_text": "Tom Roberts"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/@imsparsh", "anchor_text": "Machine Learning related posts here"}, {"url": "https://www.linkedin.com/in/imsparsh/", "anchor_text": "LinkedIn"}, {"url": "https://towardsdatascience.com/what-makes-logistic-regression-a-classification-algorithm-35018497b63f", "anchor_text": "What makes Logistic Regression a Classification Algorithm?Log Odds, the baseline of Logistic Regression explained.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/most-common-loss-functions-in-machine-learning-c7212a99dae0", "anchor_text": "Most Common Loss Functions in Machine LearningEvery Machine Learning Engineer should know about these common Loss functions in Machine Learning and when to use\u2026towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----528bb7b0495d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----528bb7b0495d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----528bb7b0495d---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----528bb7b0495d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/optimization?source=post_page-----528bb7b0495d---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F528bb7b0495d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&user=Sparsh+Gupta&userId=da9091f87266&source=-----528bb7b0495d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F528bb7b0495d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&user=Sparsh+Gupta&userId=da9091f87266&source=-----528bb7b0495d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F528bb7b0495d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F528bb7b0495d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----528bb7b0495d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----528bb7b0495d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----528bb7b0495d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----528bb7b0495d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@imsparsh?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@imsparsh?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sparsh Gupta"}, {"url": "https://medium.com/@imsparsh/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "79 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fda9091f87266&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&user=Sparsh+Gupta&userId=da9091f87266&source=post_page-da9091f87266--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F12c138301578&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-in-linear-regression-528bb7b0495d&newsletterV3=da9091f87266&newsletterV3Id=12c138301578&user=Sparsh+Gupta&userId=da9091f87266&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}