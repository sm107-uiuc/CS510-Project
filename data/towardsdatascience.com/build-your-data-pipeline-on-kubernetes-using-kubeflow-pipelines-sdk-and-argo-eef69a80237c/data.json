{"url": "https://towardsdatascience.com/build-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c", "time": 1683004907.7051048, "path": "towardsdatascience.com/build-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c/", "webpage": {"metadata": {"title": "Build your Data Pipeline on Kubernetes using Kubeflow Pipelines SDK and Argo Workflows | by Lior Shkiller | Towards Data Science", "h1": "Build your Data Pipeline on Kubernetes using Kubeflow Pipelines SDK and Argo Workflows", "description": "For those of you who haven\u2019t seen the diagram above, I highly recommend reading the paper \u201cHidden Technical Debt in Machine Learning Systems\u201d. It covers best practices for building machine learning\u2026"}, "outgoing_paragraph_urls": [{"url": "https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf", "anchor_text": "\u201cHidden Technical Debt in Machine Learning Systems\u201d", "paragraph_index": 0}, {"url": "https://www.kubeflow.org/docs/pipelines/sdk/sdk-overview/", "anchor_text": "Kubeflow Pipelines SDK", "paragraph_index": 3}, {"url": "https://github.com/argoproj/argo", "anchor_text": "Argo Workflows", "paragraph_index": 3}, {"url": "https://argoproj.github.io/projects/argo", "anchor_text": "Argo", "paragraph_index": 4}, {"url": "https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/", "anchor_text": "Kubernetes CRD", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Directed_acyclic_graph", "anchor_text": "DAG", "paragraph_index": 4}, {"url": "https://argoproj.github.io/projects/argo/", "anchor_text": "and more", "paragraph_index": 4}, {"url": "https://www.kubeflow.org/", "anchor_text": "Kubeflow", "paragraph_index": 8}, {"url": "https://kubernetes.io/", "anchor_text": "Kubernetes", "paragraph_index": 8}, {"url": "https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/", "anchor_text": "Kubeflow Pipelines", "paragraph_index": 9}, {"url": "https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.html", "anchor_text": "KFP SDK", "paragraph_index": 13}, {"url": "https://kubeflow-pipelines.readthedocs.io/en/latest/_modules/kfp/components/_python_op.html#func_to_container_op", "anchor_text": "base_image", "paragraph_index": 16}, {"url": "https://argoproj.github.io/docs/argo/configure-artifact-repository.html", "anchor_text": "configure an Artifact Repository", "paragraph_index": 19}, {"url": "https://github.com/argoproj/argo/releases", "anchor_text": "Argo CLI", "paragraph_index": 21}, {"url": "http://deep-solutions.net", "anchor_text": "http://deep-solutions.net", "paragraph_index": 25}], "all_paragraphs": ["For those of you who haven\u2019t seen the diagram above, I highly recommend reading the paper \u201cHidden Technical Debt in Machine Learning Systems\u201d. It covers best practices for building machine learning systems. One of the sections in the paper is about ML-system anti-patterns and pipeline jungles:", "Pipeline Jungles. As a special case of glue code, pipeline jungles often appear in data preparation. These can evolve organically, as new signals are identified and new information sources added incrementally. Without care, the resulting system for preparing data in an ML-friendly format may become a jungle of scrapes, joins, and sampling steps, often with intermediate files output. Managing these pipelines, detecting errors and recovering from failures are all difficult and costly.", "There are a lot of workflow engines that help with pipeline orchestrations and building ETLs. I won\u2019t get into the pros and cons of each framework, because that would take a whole different blog post and actually, I don\u2019t think there is a clear winner.", "The purpose of this blog post is to show you how to use Kubeflow Pipelines SDK to run Argo Workflows.", "The simple answer is that it\u2019s cloud-native, which means that if you already have a Kubernetes cluster running, Argo is implemented as a Kubernetes CRD and allows you to run pipelines natively on your cluster. With Argo, each task executes in a pod and you can easily execute multiple tasks as a DAG. It contains many important features such as passing artifacts between tasks, parameterization, scheduling and more.", "The way you run Argo Workflows is by using a YAML configuration file.Here is an example of a running a simple \u201chello world\u201d task that runs a python docker image and prints \u201chello world\u201d.", "Argo Workflow engine has a user interface with the following features:", "YAML has its limitations, especially when you want to run pipelines with many tasks and do fast iterations. For this reason, various Argo SDKs are currently being built that will grant you the ability to programmatically define Argo Workflows in Python and translate your code to the Argo YAML specification.", "One of the most mature SDKs was built under the Kubeflow project. Kubeflow is an open, community-driven project to make it easy to deploy and manage an ML stack on Kubernetes. Companies including Google, Cisco, IBM, Microsoft, Red Hat, Amazon Web Services and Alibaba are among those using it in production. It has a loosely coupled, microservice architecture.", "One of those services is Kubeflow Pipelines (KFP), which is a platform for building and deploying portable, scalable machine learning (ML) workflows based on Docker containers. It has a user interface for managing and tracking experiments, jobs, and runs.", "There is a subtle distinction between Argo Workflows and KFP. Argo is the workflow engine behind KFP and KFP is meant mainly for ML- related usages.", "Unlike Argo, ML-related usages have been the only focus for Kubeflow Pipelines; it\u2019s not targeted for other data-processing tasks.", "Where do ML-related usages begin and end? I found Argo to be more natural for tasks like data-ingestion and general data-processing pipelines that are not meant to end with a running ML experiment.", "Since Argo is the workflow engine behind KFP, we can use the KFP python SDK to define Argo Workflows in Python. The KFP SDK provides a set of Python packages that you can use to specify and run your workflows. Those pipelines will be compiled to the Argo YAML specification. You can use it by simply installing the package withpip install kfp.", "In the following example, I would like to show you how to write a simple pipeline with KFP python SDK. The pipeline will receive a parameter, run a for-each loop and transfer data between tasks (The general building blocks of most data-processing pipelines). It\u2019s written using KFP python SDK and will be compiled to an Argo YAML configuration.", "Let\u2019s explain the different parts of the script", "Wrapping your python functions (tasks) with @func_to_container_op decorator will convert the function to a task component and return a task (ContainerOp) factory. The task will run inside a Docker container (the default image is tensorflow/tensorflow:1.13.2-py3). It\u2019s also possible to change the base_image.", "Wrapping your function with a @dsl.pipeline decorator will convert the function to a pipeline component that describes how the task components interact with each other. There are many different ways tasks can interact with each other (dags, loops, conditions, etc).", "In the above example, the pipeline receives a parameter that will specify the number of sub-tasks to run. list_func_op is a container component that runs list_func, for each item in the list that list_func returns, KFP will launch another container that will run print_func with the relevant list item as a parameter. Each task will run in parallel on Kubernetes pods.", "A sharp-eyed reader might ask: \u201cHow do different tasks transfer data between each other?\u201d. Well, to do that, you will need to configure an Artifact Repository for Argo (for example S3 or GCS). You can also configure a different artifact repository for each pipeline using kfp.dsl.ArtifactLocation. In our case, KFP takes care of saving and loading the data by wrapping our functions with JSON serializers which save the data to the artifact store.", "The final lines will compile the pipeline and output the Argo YAML.", "Once you get the YAML, you can run it using Argo CLI:", "Finally, this is how it looks like in Argo UI:", "You can view the full pipeline script, including artifact configuration, in the following gist:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Founder of http://deep-solutions.net Machine Learning Practitioner, passionate about data science and ML engineering"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Feef69a80237c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----eef69a80237c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eef69a80237c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@lior.shkiller?source=post_page-----eef69a80237c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lior.shkiller?source=post_page-----eef69a80237c--------------------------------", "anchor_text": "Lior Shkiller"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b7eda8e29cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&user=Lior+Shkiller&userId=5b7eda8e29cd&source=post_page-5b7eda8e29cd----eef69a80237c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feef69a80237c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feef69a80237c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf", "anchor_text": "\u201cHidden Technical Debt in Machine Learning Systems\u201d"}, {"url": "https://www.kubeflow.org/docs/pipelines/sdk/sdk-overview/", "anchor_text": "Kubeflow Pipelines SDK"}, {"url": "https://github.com/argoproj/argo", "anchor_text": "Argo Workflows"}, {"url": "https://argoproj.github.io/projects/argo", "anchor_text": "Argo"}, {"url": "https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/", "anchor_text": "Kubernetes CRD"}, {"url": "https://en.wikipedia.org/wiki/Directed_acyclic_graph", "anchor_text": "DAG"}, {"url": "https://argoproj.github.io/projects/argo/", "anchor_text": "and more"}, {"url": "https://www.kubeflow.org/", "anchor_text": "Kubeflow"}, {"url": "https://kubernetes.io/", "anchor_text": "Kubernetes"}, {"url": "https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/", "anchor_text": "Kubeflow Pipelines"}, {"url": "https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.html", "anchor_text": "KFP SDK"}, {"url": "https://kubeflow-pipelines.readthedocs.io/en/latest/_modules/kfp/components/_python_op.html#func_to_container_op", "anchor_text": "base_image"}, {"url": "https://argoproj.github.io/docs/argo/configure-artifact-repository.html", "anchor_text": "configure an Artifact Repository"}, {"url": "https://github.com/argoproj/argo/releases", "anchor_text": "Argo CLI"}, {"url": "https://twitter.com/liorshkiller", "anchor_text": "twitter"}, {"url": "https://medium.com/tag/kubeflow?source=post_page-----eef69a80237c---------------kubeflow-----------------", "anchor_text": "Kubeflow"}, {"url": "https://medium.com/tag/argo?source=post_page-----eef69a80237c---------------argo-----------------", "anchor_text": "Argo"}, {"url": "https://medium.com/tag/data-pipeline?source=post_page-----eef69a80237c---------------data_pipeline-----------------", "anchor_text": "Data Pipeline"}, {"url": "https://medium.com/tag/kubernetes?source=post_page-----eef69a80237c---------------kubernetes-----------------", "anchor_text": "Kubernetes"}, {"url": "https://medium.com/tag/data-science?source=post_page-----eef69a80237c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feef69a80237c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&user=Lior+Shkiller&userId=5b7eda8e29cd&source=-----eef69a80237c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feef69a80237c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&user=Lior+Shkiller&userId=5b7eda8e29cd&source=-----eef69a80237c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feef69a80237c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eef69a80237c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Feef69a80237c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----eef69a80237c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----eef69a80237c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----eef69a80237c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----eef69a80237c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----eef69a80237c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----eef69a80237c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----eef69a80237c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----eef69a80237c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----eef69a80237c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lior.shkiller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lior.shkiller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Lior Shkiller"}, {"url": "https://medium.com/@lior.shkiller/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "44 Followers"}, {"url": "http://deep-solutions.net", "anchor_text": "http://deep-solutions.net"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b7eda8e29cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&user=Lior+Shkiller&userId=5b7eda8e29cd&source=post_page-5b7eda8e29cd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8e13fe6f97bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c&newsletterV3=5b7eda8e29cd&newsletterV3Id=8e13fe6f97bf&user=Lior+Shkiller&userId=5b7eda8e29cd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}