{"url": "https://towardsdatascience.com/random-forest-3a55c3aca46d", "time": 1682994108.1664882, "path": "towardsdatascience.com/random-forest-3a55c3aca46d/", "webpage": {"metadata": {"title": "An Introduction to Random Forest | by Houtao Deng | Towards Data Science", "h1": "An Introduction to Random Forest", "description": "Random forests are popularly applied to both data science competitions and practical problems. They are often accurate, do not require feature scaling, categorical feature encoding, and need little\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/why-random-forests-outperform-decision-trees-1b0f175a0b5", "anchor_text": "why random forests outperform decision trees", "paragraph_index": 28}, {"url": "https://github.com/softwaredeng/inTrees", "anchor_text": "inTrees", "paragraph_index": 29}, {"url": "https://github.com/softwaredeng/RRF", "anchor_text": "RRF", "paragraph_index": 29}, {"url": "https://dataanalyticsbook.info/", "anchor_text": "dataanalyticsbook.info", "paragraph_index": 30}, {"url": "http://dataanalyticsbook.info", "anchor_text": "dataanalyticsbook.info", "paragraph_index": 32}], "all_paragraphs": ["Random forests are popularly applied to both data science competitions and practical problems. They are often accurate, do not require feature scaling, categorical feature encoding, and need little parameter tunning. They can also be more interpretable than other complex models such as neural networks.", "The content is organized as follows.", "A random forest consists of multiple random decision trees. Two types of randomnesses are built into the trees. First, each tree is built on a random sample from the original data. Second, at each tree node, a subset of features are randomly selected to generate the best split.", "We use the dataset below to illustrate how to build a random forest tree. Note Class = XOR(X1,X2). X3 is made identical as X2 (for illustrative purposes in later sections).", "The figure below demonstrates how to build a random forest tree.", "The same process is applied to build multiple trees. The figure below illustrates the flow of applying a random forest with three trees to a testing data instance.", "A feature\u2019s importance score measures the contribution from the feature. It is based on the impurity reduction of the class due to the feature.", "Let\u2019s add an irrelevant feature X4 to the illustrative dataset. The importance scores are plotted below. Clearly, X1 and X4, respectively, have the largest and smallest scores. X2 and X3 are identical and sort of split the importance scores.", "The importance score of a feature doesn\u2019t tell how a feature and the class are correlated. The partial dependency plot can visualize the marginal effect of a feature on the class probability.", "When a feature is correlated to the class, the plot looks like the left figure below, indicating that X1 \u2264 0.5 and X1>0.5 are associated with different classes.", "However, in our illustrative dataset, the partial dependence plot looks like the right figure \u2014 it does not indicate any relationship between X1 and the class, even though X1 has the largest importance score.", "The reason is that X1 has to interact with X2 or X3 to be predictive of the class. X1 alone is not predictive. Therefore, partial dependence plots can be misleading for this case.", "Neither importance scores nor partial dependency plots tell how multiple features interact with the class. The inTrees framework can be used to gain a clearer picture of what happens inside a random forest.", "For the illustrative dataset, the highly-predictive interactions and their associated classes can be extracted with inTrees and shown below. The frequency (0%-100%) measures the popularity of an interaction in the random forest, and accuracy (0\u20131) measures how accurate an interaction predicts the class.", "For the illustrative dataset, let\u2019s add a random feature X5 with 30 categories. Even the feature is irrelevant to the class, the importance score of X5 is larger than truly informative features X2 and X3, indicating an incorrect bias towards features with more categories.", "One solution is to perform feature selection. For example, in the randomForest R package, one can use features\u2019 impact on accuracy (importance$MeanDecreaseAccuracy) to evaluate features. The accuracy impact plot below shows X5\u2019s accuracy impact is quite small compared to the truly informative features, indicating the feature is confusing the model and should be removed before fitting a classifier.", "When features are similar to each other, the importance scores of these features can be misleading. In the illustrative dataset, X2 and X3 are identical and they \u201cshare\u201d the importance scores (shown the left figure below). When there are more redundant features, the importance of each feature becomes even smaller.", "This may not hurt the accuracy performance but could be misleading in interpretation. One solution would be the regularized random forest (RRF). In the tree building process, RRF memorizes the features used in previous tree nodes, and prefer these features in splitting future tree nodes, therefore avoiding redundant features in the trees. The right figure below shows the importance scores from RRF.", "Clustering with random forests can avoid the need of feature transformation (e.g., categorical features). In addition, some other random forest functions can also be used here, e.g., probability and interpretation. Here we demonstrate the method with a two-dimensional data set plotted in the left figure below.", "The idea is to generate a random data set that contrast with the original data. Here we randomly permute each feature. The two data sets are labeled with two classes (say, \u201cnormal\u201d and \u201crandom\u201d), respectively. The combined data set is shown in the right figure below.", "A random forest is built on the dataset. Then the classifier can be applied to test data instances. If the predicted class is \u201crandom\u201d, then it is identified as an outlier. The outliers identified are illustrated in the left figure below.", "We can get insights into which features contribute to the outlier detection by looking at the importance score. For illustration, we add a random feature X3 that is irrelevant to the classes. The importance scores are shown in the right figure below. X1 and X2 are identified as important features, while X3 is less important.", "Similar to outlier detection, clustering with random forests saves efforts in feature preprocessing.", "The procedure is similar to outlier detection. First, create a synthetic dataset of the same size as the original data. Then label the original data and synthetic class with two different classes. A random forest is then built for the classification problem.", "From the built random forest, a similarity score between each pair of data instances is extracted. The similarity of two data instances is measured by the percentage of trees where the two data instances appear in the same leaf node.", "With the similarity scores, clustering algorithms such as hierarchical clustering can then be used for clustering. The figures below show the clustering results with the number of cluster pre-defined as 2 and 4 respectively.", "Random forests are powerful not only in classification/regression but also for purposes such as outlier detection, clustering, and interpreting a data set (e.g., serving as a rule engine with inTrees).", "However, mistakes can be easily made when using random forests. Firstly, there can be a bias when multi-level categorical features exist in a data set. Secondly, importance scores can be misleading when features are redundant. This article provides solutions for the issues.", "You may be interested in reading a relevant article on why random forests outperform decision trees.", "You welcomed to contribute to the inTrees or RRF package on github.", "Find more content in my book freely available at dataanalyticsbook.info.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine learning @Instacart. Co-author of \u201cData Analytics: A Small Data Approach\u201d (dataanalyticsbook.info)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3a55c3aca46d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@deng?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@deng?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "Houtao Deng"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce81e5f7770b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&user=Houtao+Deng&userId=ce81e5f7770b&source=post_page-ce81e5f7770b----3a55c3aca46d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a55c3aca46d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a55c3aca46d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/why-random-forests-outperform-decision-trees-1b0f175a0b5", "anchor_text": "why random forests outperform decision trees"}, {"url": "https://github.com/softwaredeng/inTrees", "anchor_text": "inTrees"}, {"url": "https://github.com/softwaredeng/RRF", "anchor_text": "RRF"}, {"url": "https://dataanalyticsbook.info/", "anchor_text": "dataanalyticsbook.info"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3a55c3aca46d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/decision-tree?source=post_page-----3a55c3aca46d---------------decision_tree-----------------", "anchor_text": "Decision Tree"}, {"url": "https://medium.com/tag/data-science?source=post_page-----3a55c3aca46d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----3a55c3aca46d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3a55c3aca46d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&user=Houtao+Deng&userId=ce81e5f7770b&source=-----3a55c3aca46d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3a55c3aca46d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&user=Houtao+Deng&userId=ce81e5f7770b&source=-----3a55c3aca46d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a55c3aca46d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3a55c3aca46d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3a55c3aca46d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3a55c3aca46d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@deng?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@deng?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Houtao Deng"}, {"url": "https://medium.com/@deng/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "569 Followers"}, {"url": "http://dataanalyticsbook.info", "anchor_text": "dataanalyticsbook.info"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce81e5f7770b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&user=Houtao+Deng&userId=ce81e5f7770b&source=post_page-ce81e5f7770b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1a0a75ff8316&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-3a55c3aca46d&newsletterV3=ce81e5f7770b&newsletterV3Id=1a0a75ff8316&user=Houtao+Deng&userId=ce81e5f7770b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}