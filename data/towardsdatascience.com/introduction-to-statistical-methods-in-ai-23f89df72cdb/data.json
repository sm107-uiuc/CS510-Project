{"url": "https://towardsdatascience.com/introduction-to-statistical-methods-in-ai-23f89df72cdb", "time": 1683001354.588375, "path": "towardsdatascience.com/introduction-to-statistical-methods-in-ai-23f89df72cdb/", "webpage": {"metadata": {"title": "Introduction to Statistical Methods in AI | by Atul Agarwal | Towards Data Science", "h1": "Introduction to Statistical Methods in AI", "description": "Introduction to statistical methods in AI containing information about supervised and unsupervised learning including variance, bias, regression, knn, trees, random forest, bagging, boosting."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/support-vector-machine-formulation-and-derivation-b146ce89f28", "anchor_text": "article", "paragraph_index": 21}, {"url": "https://en.wikipedia.org/wiki/Odds", "anchor_text": "odds", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "maximum likelihood", "paragraph_index": 24}, {"url": "https://en.wikipedia.org/wiki/Decision_tree_pruning", "anchor_text": "tree pruning", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/introduction-to-artificial-neural-networks-5036081137bb", "anchor_text": "Introduction to Artificial Neural Nets", "paragraph_index": 44}, {"url": "https://www.linkedin.com/in/atul94", "anchor_text": "https://www.linkedin.com/in/atul94", "paragraph_index": 46}], "all_paragraphs": ["Statistical Learning is a set of tools for understanding data. These tools broadly come under two classes: supervised learning & unsupervised learning. Generally, supervised learning refers to predicting or estimating an output based on one or more inputs. Unsupervised learning, on the other hand, provides a relationship or finds a pattern within the given data without a supervised output.", "Let, suppose that we observe a response Y and p different predictors X = (X\u2081, X\u2082,\u2026., Xp). In general, we can say:", "Here f is an unknown function, and \u03b5 is the random error term.", "In essence, statistical learning refers to a set of approaches for estimating f.", "In cases where we have set of X readily available, but the output Y, not so much, the error averages to zero, and we can say:", "where \u0192 represents our estimate of f and \u00a5 represents the resulting prediction.", "Hence for a set of predictors X, we can say:", "Variables, Y, can be broadly be characterised as quantitative or qualitative( also known as categorical). Quantitative variables take on numerical values, e.g., age, height, income, price, and much more. Estimating qualitative responses is often termed as a regression problem. Qualitative variables take on categorical values, e.g., gender, brand, parts of speech, and much more. Estimating qualitative responses is often termed as a classification problem.", "There is no free lunch in statistics: no one method dominates all other over all possible data sets.", "Variance refers to the amount by which \u0192 would change if we estimated with different training data sets. In general, when we over-fit a model on a given training data set(reducible error in training set is very low but on test set is very high), we get a model that has higher variance since any change in the data points would results in a significantly different model.", "Bias refers to the error introduced by approximating a real-life problem, which may be extremely complicated by a much simpler model \u2014 for example, modeling non-linear problems with a linear model. In general, when we over-fit, a model on given data set it results in very less bias.", "This results in the variance bias trade-off.", "As we fit the model over a given data set, the bias tends to decrease faster than the variance increases initially. Consequently, the expected test error(reducible) declines. However, at some point, when over-fitting starts, there is a little impact on the bias, but variance starts to increase rapidly when this happens the test error increases.", "Linear regression is a statistical method belonging to supervised learning used for predicting quantitative responses.", "Simple Linear Regression approach predicts a quantitative response \u00a5 based on a single variable X assuming a linear relationship. We can say :", "Our job is now to estimate \u03b2\u2080 and \u03b2\u2081, the parameters/coefficients of our model based on the training data set, such that the hyperplane(in this case a line) is close to the training data set. Many criteria can estimate the closeness, the most common being least square.", "The sum of the square of the difference between all observed response and the predicted response formulates to Residual Sum Of Squares(RSS).", "KNN Regression is a non-parametric approach towards estimating or predicting values, which do not assume the form of \u0192(X). It estimates/predicts \u0192(x\u2080) where x\u2080 is a prediction point by averaging out all N\u2080 responses closest to x\u2080. We can say:", "Note: If K is small, the fit would be flexible and any change in the data would result in a different fit, hence for small K the variance would be high and bias low; conversely, if K is large, it might mask some structure in the data hence the bias would be high.", "The responses as we discussed till now, may not always be quantitative, it can be also qualitative, predicting these qualitative responses is called classification.", "We will discuss various statistical approaches to classification including:", "SVM or support vector machine is the classifier that maximizes the margin. The goal of a classifier in our example below is to find a line or (n-1) dimension hyper-plane that separates the two classes present in the n-dimensional space. I have written a detailed article explaining the derivation and formulation of SVM. In my opinion, it is one of the most powerful techniques in our tool box of statistical methods in AI.", "Logistic model models the probability of output response \u00a5 belonging to a particular category.", "which is nothing but the odds.", "For estimating the beta coefficients, we can use maximum likelihood. The basic idea is to estimate the betas such that the estimated value and observed value of the results are as close as possible. In a binary classification, with observed classes as 1 and 0, we can say the likelihood function would look like:", "KNN(K nearest neighbors) Classifier is a lazy learning technique, where the training data set is represented on a Euclidean hyperplane, and test data is assigned the labels based on the K Euclidean distance metrics.", "Note: Performance of KNN degrades when the data is high dimensional. This can be avoided by providing weights to the features itself.", "Effect Of K on the decision boundary", "GAM provides a generalized framework extending standard multivariable linear regression with the nonlinear function of each variable while maintaining its additive nature. Thus, all nonlinear functions can be independently calculated and added later.", "Note: GAM like linear regression can be applied to both quantitative and qualitative responses.", "Trees or decision trees are useful and straightforward methods for both regression and classification involving segmenting the predictor space into simple regions.", "Typically decision trees are drawn upside down meaning the leaves are at the bottom of the tree. The points where the predictor space is split are known as internal nodes, and the leaf nodes or terminal nodes are the ones which given the predictions. Segments joining the nodes are known as branches.", "For prediction, we take a top-down(at the first point all the observation belongs to just one region), greedy(best split is made in the particular step) approach known as recursive binary fitting.", "There are strategies like tree pruning that solves the over-fitting problem of trees by cutting some of the branches to get a small sub-tree.", "For a classification problem, we either use Gini index,", "to represent the purity of a node, where Pmk is the proportion of samples in the mth region from kth class.", "Decision trees still suffer from high variance and are not competitive with other supervised approaches. Therefore, we introduce random forest boosting and bagging.", "Bagging is a general-purpose method to reduce variance in a statistical learning method. The core idea is that averaging a set of observations reduces variance. Hence we do a random sampling of our data multiple times, and for each sample, we construct a tree and average out all the predictions to give a low variance result.", "When in the collection of bagged trees, a fix k predictors are chosen at random from each tree having total m predictors (k < m), then bagging becomes a random forest.", "This is done because most of the bagged trees would look more or less the same. Hence, the predictions of individual bag trees would be highly co-related. Therefore, there would not be much reduction in the variance of our inferences. Random forests can be thought of as the process of de-correlating bagged trees.", "Boosting approach is a slow learning statistical method, where classifiers are learned on modified data set sequentially. In the context of decision trees, each tree is grown using information from the previous trees. This way, we do not fit a single large tree.", "All the above methods had some form of annotated data set. But when we want to learn patterns in our data without any annotations unsupervised learning comes into the picture.", "The most widely used statistical method for unsupervised learning is K-Means Clustering. We take k random points in our data set and map all other points to one of the K regions based on their closeness to K chosen random points. Then we change the K random points to the centroid of the clusters thus formed. We do that until we observe a negligible change in the cluster formed after each iteration.", "There are other techniques like PCA in unsupervised learning that are used a lot, but for now, we end here.", "Next: Introduction to Artificial Neural Nets", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer @Google Zurich | Search | https://www.linkedin.com/in/atul94"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F23f89df72cdb&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@atul94?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@atul94?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "Atul Agarwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2de8b6ec3664&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&user=Atul+Agarwal&userId=2de8b6ec3664&source=post_page-2de8b6ec3664----23f89df72cdb---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23f89df72cdb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23f89df72cdb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@yogidan2012?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Daniele Levis Pelusi"}, {"url": "https://unsplash.com/s/photos/infinity?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/support-vector-machine-formulation-and-derivation-b146ce89f28", "anchor_text": "article"}, {"url": "https://brilliant.org/wiki/componendo-and-dividendo/", "anchor_text": "componendo dividendo"}, {"url": "https://en.wikipedia.org/wiki/Odds", "anchor_text": "odds"}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "maximum likelihood"}, {"url": "https://www.wiley.com/en-us/Pattern+Classification%2C+2nd+Edition-p-9780471056690", "anchor_text": "Pattern Classification"}, {"url": "https://www.wiley.com/en-us/search?pq=%7Crelevance%7Cauthor%3ARichard+O.+Duda", "anchor_text": "Richard O. Duda"}, {"url": "https://www.wiley.com/en-us/search?pq=%7Crelevance%7Cauthor%3APeter+E.+Hart", "anchor_text": "Peter E. Hart"}, {"url": "https://www.wiley.com/en-us/search?pq=%7Crelevance%7Cauthor%3ADavid+G.+Stork", "anchor_text": "David G. Stork"}, {"url": "https://en.wikipedia.org/wiki/Decision_tree_pruning", "anchor_text": "tree pruning"}, {"url": "https://towardsdatascience.com/introduction-to-artificial-neural-networks-5036081137bb", "anchor_text": "Introduction to Artificial Neural Nets"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----23f89df72cdb---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----23f89df72cdb---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----23f89df72cdb---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/statistics?source=post_page-----23f89df72cdb---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/learning?source=post_page-----23f89df72cdb---------------learning-----------------", "anchor_text": "Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F23f89df72cdb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&user=Atul+Agarwal&userId=2de8b6ec3664&source=-----23f89df72cdb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F23f89df72cdb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&user=Atul+Agarwal&userId=2de8b6ec3664&source=-----23f89df72cdb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23f89df72cdb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F23f89df72cdb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----23f89df72cdb---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----23f89df72cdb--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----23f89df72cdb--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----23f89df72cdb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@atul94?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@atul94?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Atul Agarwal"}, {"url": "https://medium.com/@atul94/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "148 Followers"}, {"url": "https://www.linkedin.com/in/atul94", "anchor_text": "https://www.linkedin.com/in/atul94"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2de8b6ec3664&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&user=Atul+Agarwal&userId=2de8b6ec3664&source=post_page-2de8b6ec3664--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff97e3dcbe202&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-statistical-methods-in-ai-23f89df72cdb&newsletterV3=2de8b6ec3664&newsletterV3Id=f97e3dcbe202&user=Atul+Agarwal&userId=2de8b6ec3664&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}