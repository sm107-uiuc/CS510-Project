{"url": "https://towardsdatascience.com/how-do-they-apply-bert-in-the-clinical-domain-49113a51be50", "time": 1682996083.577609, "path": "towardsdatascience.com/how-do-they-apply-bert-in-the-clinical-domain-49113a51be50/", "webpage": {"metadata": {"title": "How do they apply BERT in the clinical domain? | by Edward Ma | Towards Data Science", "h1": "How do they apply BERT in the clinical domain?", "description": "Contextual word embeddings is proven that have dramatically improved NLP model performance via ELMo (Peters et al., 2018), BERT (Devlin et al., 2018) and GPT-2 (Radford et al., 2019). Lots of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://dev.to/makcedward/how-do-they-apply-bert-in-the-clinical-domain-1ipd", "anchor_text": "Dev.to", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/elmo-helps-to-further-improve-your-word-embeddings-c6ed2c9df95f", "anchor_text": "ELMo", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/too-powerful-nlp-model-generative-pre-training-2-4cc6afb6655", "anchor_text": "GPT-2", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/how-to-apply-bert-in-scientific-domain-2d9db0480bd9", "anchor_text": "BioBERT and SciBERT", "paragraph_index": 1}, {"url": "https://arxiv.org/pdf/1904.03323.pdf", "anchor_text": "Publicly Available Clinical BERT Embeddings", "paragraph_index": 2}, {"url": "https://arxiv.org/pdf/1904.05342.pdf", "anchor_text": "ClinicalBert: Modeling Clinical Notes and Predicting Hospital Readmission", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "story", "paragraph_index": 2}, {"url": "https://mimic.physionet.org/gettingstarted/dbsetup/", "anchor_text": "MIMIC-III v1.4 database", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/1902.07669.pdf", "anchor_text": "ScispaCy", "paragraph_index": 4}, {"url": "https://github.com/naver/biobert-pretrained", "anchor_text": "BioBERT", "paragraph_index": 4}, {"url": "https://makcedward.github.io/", "anchor_text": "me", "paragraph_index": 12}, {"url": "https://www.linkedin.com/in/edwardma1026", "anchor_text": "LinkedIn", "paragraph_index": 12}, {"url": "http://medium.com/@makcedward/", "anchor_text": "Medium", "paragraph_index": 12}, {"url": "https://github.com/makcedward", "anchor_text": "Github", "paragraph_index": 12}, {"url": "https://makcedward.github.io/", "anchor_text": "https://makcedward.github.io/", "paragraph_index": 14}], "all_paragraphs": ["This story is published in both Dev.to and Medium.", "Contextual word embeddings is proven that have dramatically improved NLP model performance via ELMo (Peters et al., 2018), BERT (Devlin et al., 2018) and GPT-2 (Radford et al., 2019). Lots of researches intend to fine tune BERT model on domain specific data. BioBERT and SciBERT are introduced in last time. Would like to continue on this topic as there are another 2 research fine tune BERT model and applying in the clinical domain.", "This story will discuss about Publicly Available Clinical BERT Embeddings (Alsentzer et al., 2019) and ClinicalBert: Modeling Clinical Notes and Predicting Hospital Readmission (Huang et al., 2019) while it will go through BERT detail but focusing how researchers applying it in clinical domain. In case, you want to understand more about BERT, you may visit this story.The following are will be covered:", "Alsentzer et al. apply 2 millon notes in the MIMIC-III v1.4 database (Johnson et al., 2016). There are among 15 note types in total and Alsentzer et al. aggregate to either non-Discharge Summary type and Discharge Summary type. Discharge summary data is designed for downstream tasks training/ fine-tuning.", "Giving that those data, ScispaCy is leveraged to tokenize article to sentence. Those sentences will be passed to BERT-Base (Original BERT base model) and BioBERT respectively for additional pre-training.", "Clinical BERT is build based on BERT-base while Clinical BioBERT is based on BioBERT. Once the contextual word embeddings is trained, a signal linear layer classification model is trained for tacking named-entity recognition (NER), de-identification (de-ID) task or sentiment classification.", "These models achieves a better result in MedNLI by comparing to original BERT model. Meanwhile, you may notice that there are no improvement fro i2b2 2006 and i2b2 2014 which are de-ID tasks.", "In the same time, Huang et al. also focus on clinical notes. However, the major objective of Huang et al. research is building a prediction model by leveraging a good clinical text representation. Huang et al. researched that lower readmission rate is good for patients such as saving money.", "Same as Alsentzer et al., MIMIC-III dataset (Johnson et al., 2016) are used for evaluation. Following same BERT practice, contextual word embeddings is trained by predicting a masked token and next sentence prediction. In short, predicting a masked token is mask a token randomly and using surrounding words to predict masked token. Next sentence prediction is a binary classifier, output of this model is classifying whether second sentence is a next sentence of first sentence or not.", "After having a pre-trained contextual word embeddings, fine-tuned process is applied on readmission prediction. It is a binary classification model to predict whether patient need to be readmission within the next 30 days.", "One of the BERT model limitation is maximum length of token is 512. A long clinical note will be split to multiple parts and predicting it separately. Once all sub-part is predicted, a final probability will be aggregated. Due to the concern on using maximum or mean purely, Huang et al. combine both of them to have a accurate result.", "Finally, the experiment result demonstrated a fine-tuned ClinicalBERT is better than classical model.", "I am Data Scientist in Bay Area. Focusing on state-of-the-art in Data Science, Artificial Intelligence , especially in NLP and platform related. Feel free to connect with me on LinkedIn or following me on Medium or Github.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Focus in Natural Language Processing, Data Science Platform Architecture. https://makcedward.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F49113a51be50&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----49113a51be50--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----49113a51be50--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@makcedward?source=post_page-----49113a51be50--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=post_page-----49113a51be50--------------------------------", "anchor_text": "Edward Ma"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fba547bff904f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&user=Edward+Ma&userId=ba547bff904f&source=post_page-ba547bff904f----49113a51be50---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F49113a51be50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F49113a51be50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@makcedward?utm_source=medium&utm_medium=referral", "anchor_text": "Edward Ma"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://dev.to/makcedward/how-do-they-apply-bert-in-the-clinical-domain-1ipd", "anchor_text": "Dev.to"}, {"url": "https://towardsdatascience.com/elmo-helps-to-further-improve-your-word-embeddings-c6ed2c9df95f", "anchor_text": "ELMo"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT"}, {"url": "https://towardsdatascience.com/too-powerful-nlp-model-generative-pre-training-2-4cc6afb6655", "anchor_text": "GPT-2"}, {"url": "https://towardsdatascience.com/how-to-apply-bert-in-scientific-domain-2d9db0480bd9", "anchor_text": "BioBERT and SciBERT"}, {"url": "https://arxiv.org/pdf/1904.03323.pdf", "anchor_text": "Publicly Available Clinical BERT Embeddings"}, {"url": "https://arxiv.org/pdf/1904.05342.pdf", "anchor_text": "ClinicalBert: Modeling Clinical Notes and Predicting Hospital Readmission"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "story"}, {"url": "https://mimic.physionet.org/gettingstarted/dbsetup/", "anchor_text": "MIMIC-III v1.4 database"}, {"url": "https://arxiv.org/pdf/1902.07669.pdf", "anchor_text": "ScispaCy"}, {"url": "https://github.com/naver/biobert-pretrained", "anchor_text": "BioBERT"}, {"url": "https://makcedward.github.io/", "anchor_text": "me"}, {"url": "https://www.linkedin.com/in/edwardma1026", "anchor_text": "LinkedIn"}, {"url": "http://medium.com/@makcedward/", "anchor_text": "Medium"}, {"url": "https://github.com/makcedward", "anchor_text": "Github"}, {"url": "https://github.com/EmilyAlsentzer/clinicalBERT", "anchor_text": "Clinical BERT Embeddings GIT repository"}, {"url": "https://github.com/kexinhuang12345/clinicalBERT", "anchor_text": "ClinicalBERT"}, {"url": "https://mimic.physionet.org/gettingstarted/dbsetup/", "anchor_text": "MIMIC-III v1.4 database"}, {"url": "https://towardsdatascience.com/how-to-apply-bert-in-scientific-domain-2d9db0480bd9", "anchor_text": "BioBERT and SciBERT"}, {"url": "https://arxiv.org/pdf/1904.03323.pdf", "anchor_text": "Publicly Available Clinical BERT Embeddings"}, {"url": "https://arxiv.org/pdf/1904.05342.pdf", "anchor_text": "ClinicalBert: Modeling Clinical Notes and Predicting Hospital Readmission"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----49113a51be50---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----49113a51be50---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----49113a51be50---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/nlp?source=post_page-----49113a51be50---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/python?source=post_page-----49113a51be50---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F49113a51be50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&user=Edward+Ma&userId=ba547bff904f&source=-----49113a51be50---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F49113a51be50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&user=Edward+Ma&userId=ba547bff904f&source=-----49113a51be50---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F49113a51be50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----49113a51be50--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F49113a51be50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----49113a51be50---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----49113a51be50--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----49113a51be50--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----49113a51be50--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----49113a51be50--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----49113a51be50--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----49113a51be50--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----49113a51be50--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----49113a51be50--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Edward Ma"}, {"url": "https://medium.com/@makcedward/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.3K Followers"}, {"url": "https://makcedward.github.io/", "anchor_text": "https://makcedward.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fba547bff904f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&user=Edward+Ma&userId=ba547bff904f&source=post_page-ba547bff904f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fde3db5912a7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-do-they-apply-bert-in-the-clinical-domain-49113a51be50&newsletterV3=ba547bff904f&newsletterV3Id=de3db5912a7c&user=Edward+Ma&userId=ba547bff904f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}