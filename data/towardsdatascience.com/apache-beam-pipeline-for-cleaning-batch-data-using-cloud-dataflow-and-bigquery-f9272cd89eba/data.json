{"url": "https://towardsdatascience.com/apache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba", "time": 1683010750.704739, "path": "towardsdatascience.com/apache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba/", "webpage": {"metadata": {"title": "Building data processing pipeline with Apache beam, Dataflow and BigQuery | Towards Data Science", "h1": "Building Data Processing Pipeline With Apache Beam, Dataflow & BigQuery", "description": "Building data processing pipeline with Apache beam, which runs on google cloud dataflow and write the result in BigQuery."}, "outgoing_paragraph_urls": [{"url": "https://beam.apache.org/", "anchor_text": "Apache Beam", "paragraph_index": 1}, {"url": "https://cloud.google.com/dataflow", "anchor_text": "Google Cloud Dataflow", "paragraph_index": 1}, {"url": "https://cloud.google.com/free", "anchor_text": "free trial", "paragraph_index": 2}, {"url": "https://beam.apache.org/get-started/quickstart-py/", "anchor_text": "Python SDK", "paragraph_index": 3}, {"url": "https://www.kaggle.com/nickhould/craft-cans", "anchor_text": "Craft Beers Dataset", "paragraph_index": 8}, {"url": "https://cloud.google.com/dataflow/docs/concepts/regional-endpoints.", "anchor_text": "regional endpoints", "paragraph_index": 30}, {"url": "https://linkedin.com/in/aniket-ghole", "anchor_text": "https://linkedin.com/in/aniket-ghole", "paragraph_index": 36}], "all_paragraphs": ["There are various technologies related to big data in the market such as Hadoop, Apache Spark, Apache Flink, etc, and maintaining those is a big challenge for both developers and businesses. Which tool is the best for batch and streaming data? Are the performance and speed of one particular tool enough in our use case? How should you integrate different data sources? If these questions often appear in your business, you may want to consider Apache Beam.", "Apache Beam is an open-source, unified model for constructing both batch and streaming data processing pipelines. Beam supports multiple language-specific SDKs for writing pipelines against the Beam Model such as Java, Python, and Go and Runners for executing them on distributed processing backends, including Apache Flink, Apache Spark, Google Cloud Dataflow and Hazelcast Jet.", "We will be running this pipeline using Google Cloud Platform products so you need to avail your free offer of using these products up to their specified free usage limit, New users will also get $300 to spend on Google Cloud Platform products during your free trial.", "Here we are going to use Python SDK and Cloud Dataflow to run the pipeline.", "I have clipped some commonly used higher-level transforms (Ptransforms) below, we are going to use some of them in our pipeline.", "ParDo is a primary beam transform for generic parallel processing which is not in the above image. The ParDo processing paradigm is similar to the \u201cMap\u201d phase of a Map/Shuffle/Reduce-style algorithm: a ParDo transform considers each element in the input PCollection, performs some processing on that element, and emits zero, or multiple elements to an output PCollection.", "Pipe \u2018|\u2019 is the operator to apply transforms, and each transform can be optionally supplied with a unique label. Transforms can be chained, and we can compose arbitrary shapes of transforms, and at runtime, they\u2019ll be represented as DAG.", "The above concepts are core to create the apache beam pipeline, so let's move further to create our first batch pipeline which will clean the dataset and write it to BigQuery.", "Here we are going to use Craft Beers Dataset from Kaggle.", "abv: The alcoholic content by volume with 0 being no alcohol and 1 being pure alcoholibu: International bittering units, which specify how bitter a drink isname: The name of the beerstyle: Beer style (lager, ale, IPA, etc.)brewery_id: Unique identifier for a brewery that produces this beerounces: Size of beer in ounces", "We will upload this dataset to google cloud bucket.", "Before we run the pipeline, we need to enable Dataflow and Bigquery APIs. Type Dataflow API in GCP search box and enable it.", "Similarly, you need to enable BigQuery API.", "Dataflow will use cloud bucket as a staging location to store temporary files. We will create a cloud storage bucket and choose the nearest location (Region).", "For example\u2014 if you are in Asia, you must select Asia region for the speed and performance of computation (Dataflow Job).", "We will create BigQuery dataset and table with the appropriate schema as a data sink where our output from the dataflow job will reside in. The Dataset region will be your nearest location. It is Asia-south1 (Mumbai) in our case. You need to provide the output schema (already given in batch.py) while creating the table in BigQuery.", "Next open cloud shell editor and set your project property if it is not already set and will clone the GitHub repository which has all supported files and data.", "Once it is done, change into the directory where all files reside.", "Now copy the beer.csv file into our bucket using the command given below.", "Alternatively, you can upload that CSV file by going to the Storage Bucket.", "To run the pipeline, you need to have Apache Beam library installed on Virtual Machine.", "Now we will walk through the pipeline code to know how it works. Mostly we will look at the Ptransforms in the pipeline.", "We have filtered out the data which does not have information or null values in it.", "The above function will convert the string values to their appropriate data type.", "In the above function, we deleted unwanted columns which ended up in cleaned data.", "beam.io.ReadFromText \u2014 reads the data from external sources into the PCollection", "beam.map \u2014 works like ParDo, applied Map in multiple ways to transform every element in PCollection. The Map accepts a function that returns a single element for every input element in the PCollection.", "beam.Filter \u2014 accepts a function that keeps elements that return True, and filters out the remaining elements.", "beam.io.WriteToBigQuery \u2014 Write transform to a BigQuerySink accepts PCollections of dictionaries. It requires the following arguments", "Now we run pipeline using dataflow runner using the following syntax.", "Currently, Dataflow provides regional endpoints for some regions which do not include Asia-south1 hence I chose Asia-east1 in Region.", "Now go to Dataflow, you can see your job is running of batch type.", "Once it is completed and succeeded, you will see results in the BigQuery beer_data table.", "Now we can query out the data to get some insights.", "The main objective of this article is to demonstrate how we can create a cleaning pipeline using an apache beam. I have used only one dataset which has beers information while another dataset has breweries information which could have given more insights.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data architect and analyst @virtusa. Skilled in gcp big data stack. Reach me at https://linkedin.com/in/aniket-ghole"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff9272cd89eba&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@aniketghole88?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aniketghole88?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "Aniket Ghole"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F140bf6cddac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&user=Aniket+Ghole&userId=140bf6cddac9&source=post_page-140bf6cddac9----f9272cd89eba---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff9272cd89eba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff9272cd89eba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://beam.apache.org/", "anchor_text": "Apache Beam"}, {"url": "https://cloud.google.com/dataflow", "anchor_text": "Google Cloud Dataflow"}, {"url": "https://cloud.google.com/free", "anchor_text": "free trial"}, {"url": "https://beam.apache.org/get-started/quickstart-py/", "anchor_text": "Python SDK"}, {"url": "https://link.springer.com/chapter/10.1007/978-1-4842-4470-8_40", "anchor_text": "Key Concepts of Pipeline"}, {"url": "http://shzhangji.com/blog/2017/09/12/apache-beam-quick-start-with-python/", "anchor_text": "Common Transforms in Pipeline"}, {"url": "https://miro.medium.com/max/1250/1*2RSf9nVv6-MaLhVjW2F2tA.png", "anchor_text": "Pipeline Flow"}, {"url": "https://cloud.google.com/bigquery", "anchor_text": "BigQuery"}, {"url": "https://www.kaggle.com/nickhould/craft-cans", "anchor_text": "Craft Beers Dataset"}, {"url": "https://github.com/aniket-g/batch-pipeline-using-apache-beam-python", "anchor_text": "https://github.com/aniket-g/batch-pipeline-using-apache-beam-python"}, {"url": "https://cloud.google.com/dataflow/docs/concepts/regional-endpoints.", "anchor_text": "regional endpoints"}, {"url": "http://shzhangji.com/blog/2017/09/12/apache-beam-quick-start-with-python/", "anchor_text": "http://shzhangji.com/blog/2017/09/12/apache-beam-quick-start-with-python/"}, {"url": "https://beam.apache.org/documentation/programming-guide/", "anchor_text": "https://beam.apache.org/documentation/programming-guide/"}, {"url": "https://medium.com/tag/apache-beam?source=post_page-----f9272cd89eba---------------apache_beam-----------------", "anchor_text": "Apache Beam"}, {"url": "https://medium.com/tag/dataflow?source=post_page-----f9272cd89eba---------------dataflow-----------------", "anchor_text": "Dataflow"}, {"url": "https://medium.com/tag/bigquery?source=post_page-----f9272cd89eba---------------bigquery-----------------", "anchor_text": "Bigquery"}, {"url": "https://medium.com/tag/batch-processing?source=post_page-----f9272cd89eba---------------batch_processing-----------------", "anchor_text": "Batch Processing"}, {"url": "https://medium.com/tag/data-pipeline?source=post_page-----f9272cd89eba---------------data_pipeline-----------------", "anchor_text": "Data Pipeline"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff9272cd89eba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&user=Aniket+Ghole&userId=140bf6cddac9&source=-----f9272cd89eba---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff9272cd89eba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&user=Aniket+Ghole&userId=140bf6cddac9&source=-----f9272cd89eba---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff9272cd89eba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff9272cd89eba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f9272cd89eba---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f9272cd89eba--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f9272cd89eba--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f9272cd89eba--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aniketghole88?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aniketghole88?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Aniket Ghole"}, {"url": "https://medium.com/@aniketghole88/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "56 Followers"}, {"url": "https://linkedin.com/in/aniket-ghole", "anchor_text": "https://linkedin.com/in/aniket-ghole"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F140bf6cddac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&user=Aniket+Ghole&userId=140bf6cddac9&source=post_page-140bf6cddac9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd4e881b2c758&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-beam-pipeline-for-cleaning-batch-data-using-cloud-dataflow-and-bigquery-f9272cd89eba&newsletterV3=140bf6cddac9&newsletterV3Id=d4e881b2c758&user=Aniket+Ghole&userId=140bf6cddac9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}