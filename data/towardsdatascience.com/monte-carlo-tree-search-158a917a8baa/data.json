{"url": "https://towardsdatascience.com/monte-carlo-tree-search-158a917a8baa", "time": 1682993547.410109, "path": "towardsdatascience.com/monte-carlo-tree-search-158a917a8baa/", "webpage": {"metadata": {"title": "Monte Carlo Tree Search. MCTS For Every Data Science Enthusiast | by SAGAR SHARMA | Towards Data Science", "h1": "Monte Carlo Tree Search", "description": "The Games like Tic-Tac-Toe, Rubik\u2019s Cube, Sudoku, Chess, Go and many others have common property that lead to exponential increase in the number of possible actions that can be played. These possible\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@sagarsharma4244", "anchor_text": "Medium", "paragraph_index": 27}, {"url": "https://twitter.com/SagarSharma4244", "anchor_text": "Twitter", "paragraph_index": 27}], "all_paragraphs": ["The Games like Tic-Tac-Toe, Rubik\u2019s Cube, Sudoku, Chess, Go and many others have common property that lead to exponential increase in the number of possible actions that can be played. These possible steps increase exponentially as the game goes forward. Ideally if you can predict every possible move and its result that may occur in the future. You can increase your chance of winning.", "But since the moves increase exponentially \u2014 the computation power that is required to calculate the moves also goes through the roof.", "Monte Carlo Tree Search is a method usually used in games to predict the path (moves) that should be taken by the policy to reach the final winning solution.", "Before we discover the right path(moves) that will lead us for the win. We first need to arrange the moves of the present state of the game. These moves connected together will look like a tree. Hence the name Tree Search. See the diagram below to understand the sudden exponential increase in moves.", "It is a method used to search every possible move that may exist after a turn in the game. For Example: There are many different options for a player in the game of tic-tac-toe, which can be visualised using a tree representation. The move can be further increased for the next turn evolving the diagram into a tree.", "Brute forcing an exponential increasing tree to find the final solution for a problem by considering every children move/node requires alot of computational power. resulting in extremely slow output.", "\ud83d\udca1 Faster Tree Search can be achieved by making a policy \u2014 giving more importance to some nodes from others & allowing their children nodes to be searched first to reach the correct solution.", "But how to find that node which is most favourable to have the correct solution in their children nodes. Let\u2019s find out\u2026", "MCTS is an algorithm that figures out the best move out of a set of moves by Selecting \u2192 Expanding \u2192 Simulating \u2192 Updating the nodes in tree to find the final solution. This method is repeated until it reaches the solution and learns the policy of the game.", "Let\u2019s look at parts of the loop one-by-one.", "Selecting\ud83d\udc46| This process is used to select a node on the tree that has the highest possibility of winning. For Example \u2014 Consider the moves with winning possibility 2/3, 0/1 & 1/2 after the first move 4/6, the node 2/3 has the highest possibility of winning.", "The node selected is searched from the current state of the tree and selected node is located at the end of the branch. Since the selected node has the highest possibility of winning \u2014 that path is also most likely to reach the solution faster than other path in the tree.", "Expanding \u2014 After selecting the right node. Expanding is used to increase the options further in the game by expanding the selected node and creating many children nodes. We are using only one children node in this case. These children nodes are the future moves that can be played in the game.", "The nodes that are not expanded further for the time being are known are leaves.", "Simulating|Exploring \ud83d\ude80 Since nobody knows which node is the best children/ leaf from the group. The move which will perform best and lead to the correct answer down the tree. But,", "How do we find the best children which will lead us to the correct solution?", "We use Reinforcement Learning to make random decisions in the game further down from every children node. Then, reward is given to every children node \u2014 by calculating how close the output of their random decision was from the final output that we need to win the game.", "For example: In the game of Tic-Tac-Toe. Does the random decision to make cross(X) next to previous cross(X) in the game results in three consecutive crosses(X-X-X) that are needed to win the game?", "FYI: This can be considered as policy \u03c0 of RL algorithm. Learn more about Policy & Value Network\u2026", "The simulation is done for every children node is followed by their individual rewards.", "Let\u2019s say the simulation of the node gives optimistic results for its future and gets a positive score 1/1.", "Updating|Back-propagation \u2014 Due to the new nodes and their positive or negative scores in the environment. The total scores of their parent nodes must be updated by going back up the tree one-by-one. The new updated scores changes the state of the tree and may also change new future node of the selection process.", "After updating all the nodes, the loop again begins by selection the best node in the tree\u2192 expanding of the selected node \u2192 using RL for simulating exploration \u2192 back-propagating the updated scores \u2192 then finally selecting a new node further down the tree that is actual the required final winning result.", "For Example: Solved Rubik\u2019s Cube, Sudoku\u2019s correct solution, Killing the King in Chess or", "Instead of brute forcing from millions of possible ways to find the right path.", "Monte Carlo Tree Search algorithm chooses the best possible move from the current state of Game\u2019s Tree with the help of Reinforcement Learning.", "Thanks for reading the article. If you have any doubt or just wants to talk Data Science, write it in the comments below.", "Follow me on Medium and Twitter to get more content like this.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Freelance Writer. React developer. Deep learning/AI Electronics \ud83d\udce9 sagarsharma4244@gmail.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F158a917a8baa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----158a917a8baa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----158a917a8baa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sagarsharma4244?source=post_page-----158a917a8baa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sagarsharma4244?source=post_page-----158a917a8baa--------------------------------", "anchor_text": "SAGAR SHARMA"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F165370addbb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&user=SAGAR+SHARMA&userId=165370addbb5&source=post_page-165370addbb5----158a917a8baa---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F158a917a8baa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F158a917a8baa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://cse3521.artifice.cc/adversarial-search.html", "anchor_text": "Source"}, {"url": "https://towardsdatascience.com/policy-networks-vs-value-networks-in-reinforcement-learning-da2776056ad2", "anchor_text": "Policy Networks vs Value Networks in Reinforcement LearningIn Reinforcement Learning, the agents take random decisions in their environment and learns on selecting the right one\u2026towardsdatascience.com"}, {"url": "https://medium.com/@sagarsharma4244", "anchor_text": "Medium"}, {"url": "https://twitter.com/SagarSharma4244", "anchor_text": "Twitter"}, {"url": "https://twitter.com/SagarSharma4244", "anchor_text": ""}, {"url": "https://medium.com/@sagarsharma4244", "anchor_text": ""}, {"url": "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6", "anchor_text": "Activation Functions: Neural NetworksSigmoid, tanh, Softmax, ReLU, Leaky ReLU EXPLAINED !!!towardsdatascience.com"}, {"url": "https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9", "anchor_text": "Epoch vs Batch Size vs IterationsKnow your code\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/50-tensorflow-js-api-explained-in-5-minutes-tensorflow-js-cheetsheet-4f8c7f9cc8b2", "anchor_text": "50 TensorFlow.js API Explained in 5 Minutes | TensorFlow.js CheetsheetTensorFlow API Cheetsheettowardsdatascience.com"}, {"url": "https://towardsdatascience.com/tensorflow-on-mobile-tutorial-1-744703297267", "anchor_text": "TensorFlow on Mobile: TutorialOn Android and iOStowardsdatascience.com"}, {"url": "https://towardsdatascience.com/playing-atari-with-6-neurons-open-source-code-b94c764452ac", "anchor_text": "Playing ATARI with 6 Neurons | Open Source Code#2 Research Paper Explainedtowardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----158a917a8baa---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----158a917a8baa---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----158a917a8baa---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----158a917a8baa---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----158a917a8baa---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F158a917a8baa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&user=SAGAR+SHARMA&userId=165370addbb5&source=-----158a917a8baa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F158a917a8baa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&user=SAGAR+SHARMA&userId=165370addbb5&source=-----158a917a8baa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F158a917a8baa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----158a917a8baa--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F158a917a8baa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----158a917a8baa---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----158a917a8baa--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----158a917a8baa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----158a917a8baa--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----158a917a8baa--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----158a917a8baa--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----158a917a8baa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----158a917a8baa--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----158a917a8baa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sagarsharma4244?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sagarsharma4244?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "SAGAR SHARMA"}, {"url": "https://medium.com/@sagarsharma4244/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F165370addbb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&user=SAGAR+SHARMA&userId=165370addbb5&source=post_page-165370addbb5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8dc3f98660e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-158a917a8baa&newsletterV3=165370addbb5&newsletterV3Id=8dc3f98660e7&user=SAGAR+SHARMA&userId=165370addbb5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}