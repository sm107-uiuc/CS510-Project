{"url": "https://towardsdatascience.com/the-basics-linear-regression-2fc9f5124687", "time": 1683001118.27689, "path": "towardsdatascience.com/the-basics-linear-regression-2fc9f5124687/", "webpage": {"metadata": {"title": "The Basics: Linear Regression. Building an intuition for how linear\u2026 | by Max Miller | Towards Data Science", "h1": "The Basics: Linear Regression", "description": "Linear regression models are for many the first predictive models covered. While conceptually simple, they have some key features that make them flexible, powerful and explicable. While newer and\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Linear regression models are for many the first predictive models covered. While conceptually simple, they have some key features that make them flexible, powerful and explicable. While newer and more conceptually complicated models may outperform a linear regression, linear models continue to see wide usage, particularly in social science and policy spheres where data collection can be expensive and there is substantial value in highly interpretable models. Extensions of the linear regression like Ridge and Lasso can help avoid overfitting in feature-rich models and even perform feature selection. Logistic regression fits the linear framework to classification problems. First, let\u2019s look at how a plane-vanilla linear regression works.", "Linear regression models an output variable as a linear combination of input features. What does that mean exactly? Let\u2019s start with the simplest case and get a sense for how the model works and then think about how it scales it up to more complicated cases with more features.", "A linear model attempts to find the simplest relationship between a feature variable and the output as possible. Often this is described as \u2018fitting a line\u2019. You may remember from algebra class that any given line can be expressed as some form of the equation:", "Where y is your dependent variable/output, m is a slope and x is your input/independent variable. For each unit you increase x by, y increases by m units (or decreases if m is negative). The term b is an intercept term which shifts your line up or down without changing the slope. Linear regression tries find a similar relationship between an input feature and dependent variable, and ends up creating a similar formula:", "In one variable it looks just like a line, except we\u2019ve renamed the coefficient m to the greek letter beta. Let\u2019s visualize a simple example. Here\u2019s a collection of data points:", "This is, like every real world data set, a little noisy, but there\u2019s clearly a trend: as you increase x, y increases as well. Perhaps this relationship can be well estimated with a line. How do you choose which line though? Consider the following options:", "Which line seems to best capture the trend? It isn\u2019t necessarily clear. The orange line seems like it\u2019s closest to the points on the left hand side, but then, once you get towards the center of the distribution, it\u2019s not clear. On the right hand side, perhaps the orange line has overshot the mark and is too high.", "A linear regression model chooses the line by minimizing the vertical distance between the line and the individual points. Considering just the red line, and the vertical distances between the points and the line, now shown as purple segments:", "Your regression line represents your prediction for any given value of x. Those purple lines represent the prediction error for each of those points. Of course no straight line that you draw will be totally error free, but it seems like a reasonable goal to try and minimize this error. There\u2019s actually one more minor twist, which is that linear regression models typically don\u2019t simply find the line that minimizes the prediction errors, they find the line that minimizes the value of the prediction errors squared. For the more mathematically inclined, this is called the sum of squared errors or SSE and is represented with a formula like this:", "The fact that we minimize the square errors is what gives this method its name: Ordinary Least Squares or OLS. Let\u2019s include the value of square errors in our visualization. The red line has a coefficient of 40 and an intercept value of 10:", "Adjusting the intercept shifts the line up and down. If we changed the intercept to 30, the line moves up. Is the new line a better or worse predictor? It becomes closer to some points, but further away from the points already below the line. Looking at the sum of square errors, however, suggests that the new line is a worse predictor overall:", "We can, of course also adjust the coefficient, changing the slope of the line. It turns out our line had been too steep, reducing the coefficient to 30 improves the overall predictions:", "With the use of a bit of calculus we can find the values for the coefficient and the intercept that minimize the SSE and give us the best possible fitting line (or more accurately, your computer can use the calculus and find those values for you).", "While these examples have all been simple, with only one input feature, this method generalizes easily to multiple dimensions. For any given set of features, a multivariate OLS model will find a corresponding set of coefficients. These multivariate models are a little harder to visualize, but are conceptually identical. Instead of one coefficient beta, we\u2019ll have multiple betas, one for each input feature:", "You can maybe already see from these descriptions of a linear model\u2019s formula that one of the benefits of linear models is how easy it is to interpret how they work through the coefficients. If the value of X1 is increased by one, the model\u2019s estimate for y goes up by the value of beta one. It is easy to see what influences the value of your prediction and easy to tell how your prediction will change if you were to hypothetically alter one of the features.", "Linear regression models implicitly make certain assumptions about the feature variables and how they relate to the dependent variable. Part of what makes linear regression useful is that it has predictable features in situations where these assumptions are met. You can, for instance, create accurate margins of error for any given prediction. If the basic assumptions are not met, linear regression models will not be as accurate, though they might still be useful in the sense that they deliver usable predictions. What are these assumptions?", "1. Output variable is a linear combination of feature variables \u2014 linearity", "This is simply saying that the output variable is accurately described by some set of coefficients multiplied by the corresponding feature variables. Our formula with each input feature variable multiplied by its beta coefficient is technically called a \u201clinear combination\u201d. It\u2019s important to note that while this is called linearity, it doesn\u2019t mean that linear regressions are all simply straight lines, because the input feature variables don\u2019t need to be linear. Consider an example like this:", "These points are obviously not linear \u2014 I can confirm that they are quadratic in shape, created by generating a linear set of points and then simply squaring the y value. Certainly, no single straight line is going to capture the curve well! Linear regression can still handle a data set like this, however, because the input feature can be quadratic. Previously, our examples have been clearly linear, so our formulas have been linear as well:", "In this case, it looks like there\u2019s something quadratic going on, but we can still use a linear framework with a little bit of feature engineering. Let\u2019s add a new feature, which will be our original feature squared. Now we have a new formula:", "This formula is a linear combination of two features, X1 and the square of X1. It still has linearity! All our previous frameworks work basically the same and we can model the points and visualize the errors in the same ways:", "This is a fancy way of saying that the variance of the output variable stays the same as you move across the input variables. For instance, this set of points looks homoscedastic and a prime candidate for a linear regression:", "If we fit a line to this we\u2019ll notice that while the points may not always land exactly on the line, but the average distance between the prediction line and the points doesn\u2019t seem to grow or shrink as you go along:", "On the other hand, this distribution does not see constant variance, the technical term is heteroscedastic:", "A distribution like this looks less appropriate for a linear regression. Of course we can fit a line to it, but the predictions this line provides seem to get less and less accurate:", "Noticing heteroscedascity should give you a bit of pause about using a linear model, but it does not mean that OLS linear models are entirely invalidated. In real world data, heteroscedascity is often a sign that some feature \u2014 some explanatory variable, particularly an interaction term \u2014 with explanatory value has not yet been incorporated into the model. To illustrate what I mean by this, let\u2019s imagine a real world scenario that might give us data like the above example.", "Let\u2019s say you are an economic researcher and are conducting a study about the distribution of incomes. You want to create a model that will predict income based on some set of variables: incomes seem to vary depending on where you are, the level of education a person has, etc. One variable to include would be how long the person has been in the workforce. Barring economic downturns, people tend to make more as they progress in their careers. You ask your respondents how long they\u2019ve been working and plot the results on the x-axis against their level of income on the y-axis. You find you have a graph like the one above, with an ever widening cone of incomes. You\u2019ve been told be wary of heteroscedascity, does that mean you should throw this variable out or try a different type of model? Perhaps not.", "Before we do anything drastic, let\u2019s try to think through the relationships each of our variables have with each other. We see that incomes are rising with years in the workforce, but that the rate this happens doesn\u2019t seem to be the same for everyone. Let\u2019s try splitting our data up by one of other variables. Let\u2019s take level of education, for instance, and group our respondents by whether they have a high school degree, a college degree or a professional degree like a lawyer or doctor. Considering each of these groups separately, might give us a graph like this, where the different colors represent the different levels of education:", "Now the data looks more like three, homoscedastic distributions! Each level of education appears to be well estimated by a line, but the slopes of the lines are all a little different, which was what gave the overall distribution the appearance of heteroscadascity when we looked only at years on the job and income. Practically speaking, we can account for this in one model without splitting out data into three groups by including an interaction term: a new feature we\u2019ll create which is something like our value for the level education multiplied by the number of years on the job. Our regression formula will look something like this:", "The challenge with a situation like this is that it requires human input \u2014 the model can\u2019t perform feature engineering for you. In areas where you have domain knowledge and can make a reasonable guess at how the feature variables might interact, you can still use a linear model and get a good fitting and highly explicable model.", "The errors, that is the difference between the actual values in the data and the model\u2019s predicted values, should be uncorrelated with each. The error terms for any set of random points should essentially look like identically distributed, independant random variables. When this is not the case, it means that your model will be less predictive in some areas than in others. Again, this might be a sign of missing variable bias.", "While features can be created out of other features by squaring them or interacting multiple features together, no feature should be perfectly correlated with another (as in, having one feature measuring age in years and another measuring age in months) or be a linear combination of other features. For one thing, this creates interpretability problems where multiple coefficients can describe the same line \u2014 for instance y = 24* number_of_years = 12*number_of_years + 1*number_of_months = 2*number_of_months. It also creates an issue because statistical packages typically solve for the coefficients using linear algebra in a way that doesn\u2019t work if there is perfect multicollinearity. (In technical terms, the \u2018design matrix\u2019 representing the variable values for each sample must be invertible, which is not the case with multicollinearity.)", "Data scientist with a particular passion for limericks, policy and renewable energy."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2fc9f5124687&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Max Miller"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332----2fc9f5124687---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2fc9f5124687&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&user=Max+Miller&userId=dfd5ba1a8332&source=-----2fc9f5124687---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2fc9f5124687&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&source=-----2fc9f5124687---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2fc9f5124687---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----2fc9f5124687---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/data-science-ground-up?source=post_page-----2fc9f5124687---------------data_science_ground_up-----------------", "anchor_text": "Data Science Ground Up"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2fc9f5124687---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2fc9f5124687&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&user=Max+Miller&userId=dfd5ba1a8332&source=-----2fc9f5124687---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2fc9f5124687&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&user=Max+Miller&userId=dfd5ba1a8332&source=-----2fc9f5124687---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2fc9f5124687&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332----2fc9f5124687---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F930bd413e257&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&newsletterV3=dfd5ba1a8332&newsletterV3Id=930bd413e257&user=Max+Miller&userId=dfd5ba1a8332&source=-----2fc9f5124687---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Written by Max Miller"}, {"url": "https://medium.com/@max.samuel.miller/followers?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "409 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332----2fc9f5124687---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F930bd413e257&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-linear-regression-2fc9f5124687&newsletterV3=dfd5ba1a8332&newsletterV3Id=930bd413e257&user=Max+Miller&userId=dfd5ba1a8332&source=-----2fc9f5124687---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-basics-knn-for-classification-and-regression-c1e8a6c955?source=author_recirc-----2fc9f5124687----0---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=author_recirc-----2fc9f5124687----0---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=author_recirc-----2fc9f5124687----0---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Max Miller"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2fc9f5124687----0---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-basics-knn-for-classification-and-regression-c1e8a6c955?source=author_recirc-----2fc9f5124687----0---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "The Basics: KNN for classification and regressionBuilding an intuition for how KNN models work"}, {"url": "https://towardsdatascience.com/the-basics-knn-for-classification-and-regression-c1e8a6c955?source=author_recirc-----2fc9f5124687----0---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "\u00b711 min read\u00b7Oct 18, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc1e8a6c955&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-knn-for-classification-and-regression-c1e8a6c955&user=Max+Miller&userId=dfd5ba1a8332&source=-----c1e8a6c955----0-----------------clap_footer----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-basics-knn-for-classification-and-regression-c1e8a6c955?source=author_recirc-----2fc9f5124687----0---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc1e8a6c955&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-knn-for-classification-and-regression-c1e8a6c955&source=-----2fc9f5124687----0-----------------bookmark_preview----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2fc9f5124687----1---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2fc9f5124687----1---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2fc9f5124687----1---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2fc9f5124687----1---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2fc9f5124687----1---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2fc9f5124687----1---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2fc9f5124687----1---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----2fc9f5124687----1-----------------bookmark_preview----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2fc9f5124687----2---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----2fc9f5124687----2---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----2fc9f5124687----2---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2fc9f5124687----2---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2fc9f5124687----2---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2fc9f5124687----2---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----2fc9f5124687----2---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----2fc9f5124687----2-----------------bookmark_preview----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-basics-logistic-regression-and-regularization-828b0d2d206c?source=author_recirc-----2fc9f5124687----3---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=author_recirc-----2fc9f5124687----3---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=author_recirc-----2fc9f5124687----3---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Max Miller"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2fc9f5124687----3---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-basics-logistic-regression-and-regularization-828b0d2d206c?source=author_recirc-----2fc9f5124687----3---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "The Basics: Logistic Regression and RegularizationExtensions to the linear model"}, {"url": "https://towardsdatascience.com/the-basics-logistic-regression-and-regularization-828b0d2d206c?source=author_recirc-----2fc9f5124687----3---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": "\u00b79 min read\u00b7Nov 4, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F828b0d2d206c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-logistic-regression-and-regularization-828b0d2d206c&user=Max+Miller&userId=dfd5ba1a8332&source=-----828b0d2d206c----3-----------------clap_footer----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-basics-logistic-regression-and-regularization-828b0d2d206c?source=author_recirc-----2fc9f5124687----3---------------------b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F828b0d2d206c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-logistic-regression-and-regularization-828b0d2d206c&source=-----2fc9f5124687----3-----------------bookmark_preview----b6b18a0b_c3a4_4ce1_ad73_c9980551c9e1-------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "See all from Max Miller"}, {"url": "https://towardsdatascience.com/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----2fc9f5124687----0-----------------bookmark_preview----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/are-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://aaron-zhu.medium.com/?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://aaron-zhu.medium.com/?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Aaron Zhu"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/are-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Are the Error Terms Normally Distributed in a Linear Regression Model?Justification for the Normality Assumption"}, {"url": "https://towardsdatascience.com/are-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "\u00b78 min read\u00b7Nov 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F15e6882298a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4&user=Aaron+Zhu&userId=fbd30d6294e5&source=-----15e6882298a4----1-----------------clap_footer----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/are-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F15e6882298a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4&source=-----2fc9f5124687----1-----------------bookmark_preview----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "vinay"}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "What is the R2 score and adjusted R2The R2 score and adjusted R2 are two metrics used to evaluate the performance of a regression model. R2, also known as the coefficient of\u2026"}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "\u00b73 min read\u00b7Dec 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7661ee355566&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vinaychaudhari1996%2Fwhat-is-the-r2-score-and-adjusted-r2-7661ee355566&user=vinay&userId=6a7f4791df03&source=-----7661ee355566----0-----------------clap_footer----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----2fc9f5124687----0---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7661ee355566&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vinaychaudhari1996%2Fwhat-is-the-r2-score-and-adjusted-r2-7661ee355566&source=-----2fc9f5124687----0-----------------bookmark_preview----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Albers Uzila"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Wanna Break into Data Science in 2023? Think Twice!It won\u2019t be smooth sailing for you"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "\u00b711 min read\u00b7Dec 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&user=Albers+Uzila&userId=159e5ce51250&source=-----26842e9a87fe----1-----------------clap_footer----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----2fc9f5124687----1---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&source=-----2fc9f5124687----1-----------------bookmark_preview----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2fc9f5124687----2---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----2fc9f5124687----2---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----2fc9f5124687----2---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Erdogan Taskesen"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2fc9f5124687----2---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2fc9f5124687----2---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "From Data to Clusters; When is Your Clustering Good Enough?Sensible clusters and hidden gems can be found using clustering approaches but you need the right cluster evaluation method!"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2fc9f5124687----2---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "\u00b717 min read\u00b75 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----5895440a978a----2-----------------clap_footer----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----2fc9f5124687----2---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&source=-----2fc9f5124687----2-----------------bookmark_preview----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2fc9f5124687----3---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----2fc9f5124687----3---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----2fc9f5124687----3---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----2fc9f5124687----3---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2fc9f5124687----3---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2fc9f5124687----3---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----3-----------------clap_footer----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2fc9f5124687----3---------------------ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----2fc9f5124687----3-----------------bookmark_preview----ee68a0f5_12d4_4cfc_868b_94b20ebf9903-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----2fc9f5124687--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}