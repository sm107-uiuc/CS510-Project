{"url": "https://towardsdatascience.com/self-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa", "time": 1683004243.945227, "path": "towardsdatascience.com/self-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa/", "webpage": {"metadata": {"title": "SFM Self Supervised Depth Estimation: Breaking Down The Ideas | by Daryl Tan | Towards Data Science", "h1": "SFM Self Supervised Depth Estimation: Breaking Down The Ideas", "description": "This post is dedicated to exploring the idea of depth estimation via self supervise learning. Some conceptual ideas about depth estimation serve as a prerequisite. You can refer to this post which\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1", "anchor_text": "refer to this post", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1", "anchor_text": "motion parallax", "paragraph_index": 10}, {"url": "https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/cvpr17_sfm_final.pdf", "anchor_text": "Multiscale prediction", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula", "anchor_text": "Rodrigues\u2019 rotation formula", "paragraph_index": 16}, {"url": "https://www.mathworks.com/help/images/ref/ssim.html", "anchor_text": "Structural Similarity Index, SSIM", "paragraph_index": 24}, {"url": "https://arxiv.org/pdf/1806.01260.pdf", "anchor_text": "MonoDepth2, ICCV2019", "paragraph_index": 35}, {"url": "https://arxiv.org/pdf/1810.01849.pdf", "anchor_text": "SuperDepth ICRA2019", "paragraph_index": 39}, {"url": "https://arxiv.org/pdf/1609.05158.pdf", "anchor_text": "subpixel-convolutional", "paragraph_index": 39}, {"url": "https://arxiv.org/pdf/1905.02693.pdf", "anchor_text": "PackNet, CVPR2020", "paragraph_index": 41}, {"url": "https://arxiv.org/pdf/1901.02571.pdf", "anchor_text": "Neural RGB->D Sensing, CVPR2019", "paragraph_index": 43}, {"url": "https://arxiv.org/pdf/2003.13951.pdf", "anchor_text": "Discrete Disparity Volume, ECCV2020", "paragraph_index": 44}, {"url": "https://arxiv.org/pdf/1806.02446.pdf", "anchor_text": "DORN, CVPR2018", "paragraph_index": 44}, {"url": "https://arxiv.org/pdf/1803.02276.pdf", "anchor_text": "GeoNet, CVPR2018", "paragraph_index": 46}, {"url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Towards_Scene_Understanding_Unsupervised_Monocular_Depth_Estimation_With_Semantic-Aware_Representation_CVPR_2019_paper.pdf", "anchor_text": "SceneNet, CVPR2019", "paragraph_index": 46}, {"url": "https://arxiv.org/pdf/2002.12319.pdf", "anchor_text": "TRL, ICLR2020", "paragraph_index": 48}, {"url": "https://arxiv.org/pdf/1910.01765.pdf", "anchor_text": "Vitor Guizilin, et al, CoRL2019", "paragraph_index": 50}], "all_paragraphs": ["This post is dedicated to exploring the idea of depth estimation via self supervise learning. Some conceptual ideas about depth estimation serve as a prerequisite. You can refer to this post which discusses the relevant topics and associated problems.", "Self-supervision methods relax the hard requirement of having annotated ground truth which itself is cumbersome. It requires the use of expensive high-resolution Lidar which must be well-calibrated with the camera to get accurate, well-projected depth and synchronize data.", "This methodology has been gaining popularity among researchers for the above reason. It started with the seminal work of zhou [1] with accuracy largely falling behind supervised learning methods. Since then, there has been a proliferation of interest in this area. Many works have started to nail down and tackle systematically each component in this framework, rapidly closing the gap with supervised learning approaches.", "In this article, we will go through the following:", "This method is self-supervised in the sense that the ground truth comes from the input signal itself. In this case the RGB images. There is no need for any external data or signal to teach the network \u2192 The depth estimator itself is its own teacher!", "So we defined the goal as resynthesize the images based on some input images. In our context, the images are synthesized by exploiting 3D scene geometry. Which have grounded mathematical theory to model the relation between the 3D world and the image plane.", "On a big picture, when depth, together with ego-motion is provided, we can synthesize a new view (target) by applying a projective warping from the source camera point of view. From the figure above, the warping is achieved using a view synthesis module. Notice that depth is an input to the module and in our case, is predicted from a neural network.", "Then, learning is guided by minimizing a proxy photometric losses between the target and the predicted target, and gradients are derived and propagate through the bilinear sampler module and the depth network. So, if the target image and the predicted target is similar appearance-wise, this implies that depth is implicitly and correctly learning.", "Source images could be taken from video sequences or images captured from other cameras such as a binocular or trinocular setup. The former requires [R|t] to be estimated while the latter requires good calibration between cameras to obtain the extrinsic properties.", "We will focus on SFM based self-supervised depth estimation which requires pose to be estimated from a neural network.", "Depth estimation using SFM stems from the idea that we are able to perceive and structurally understand the 3D environment by moving around it. When the observer moves, objects around them move different amounts depending on their distance from the observer. This is known as motion parallax, and from this depth information can be used to generate an accurate 3D representation of the world around us.", "In computer vision, this is achieved by having a moving \ud83d\udcf7 capturing the scene and measuring the overlap between the change in view at each time step. A depth network is used to understand motion parallax. While a pose network is used to predict the change in observation between frames.", "Instead of directly regressing depth, the network predicts disparity with the output layer going through a sigmoid activation that gives a continuous value between 0-1.", "Hence, the value can be converted to depth using 1/(a*disp + b) where a,b controls the range of minimum and maximum depth value obtained.", "Multiscale prediction: this was adopted to cushion the effect of learning from low texture region which is often ambiguous when synthesizing. Hence, it was proposed to increase the spatial region in which gradient can be derived by using lower resolution features.", "To do that, intermediate outputs from the decoder will each pass through a sigmoid activation to predict disparity for each respective scale.", "The pose network is supposed to predict the 6-DoF relative change in camera pose [R|t] from I_t-1 / I_t+1 to I_t . The output of the final convolutional layer is scaled to 0.01 as in [5]. The rotational angles output by network follows the axis-angle representation and can be converted to a rotation matrix, R using the Rodrigues\u2019 rotation formula,", "Note that there is temporal consistency between inputs such that order is maintained. This simplifies the learning process.", "As discussed previously, the goal is to synthesis the target image given source images. We want to recreate the scene seen from a different camera view. This can be done by projecting the target pixel coordinate onto another camera viewpoint given depth and relative change in view (pose).", "With the predicted depth, depth_pred for each scale, and pose [R|t]_pred, the next step is to projectively warped image I_t-1, I_t+1 into I_t.", "If the pixel-wise intensity between the target image I_t and the warped image I_t_pred is similar, this implies the depth and pose network has indeed successfully learned to predict the depth and relative camera pose.", "The steps are summarised in the figure below.", "The weights are updated and learnt by computing proxy photometric loss between the target and synthesize view. There are several ways to measure the appearance between images. With the most common being a naive L1/MSE. Since then, several modifications have been proposed to better capture appearance and structure in images. We will discuss them here.", "Considering structural content: Since L1/MSE only considers the pixel-wise intensity difference, it does not have the notion of structural content. i.e. many distorted images might produce the same intensity error", "Structural Similarity Index, SSIM: This metric separates the task of similarity measurement into 3 comparisons; luminance, contrast, and structure between the 2 images. The idea is to place more emphasis on structure in the image by reducing the weights on luminance and contrast.", "By implementing the above pipeline, a depth estimation can be trained with, unfortunately, a varying degree of artefacts. Several problems still exists that needs to be tackled. In this section, we will discuss what are some of the shortfalls.", "In natural scene, it usually comprised of both static backgrounds such as walls, structures and buildings and moving entities such as people. By adopting SFM, we are assuming a static world assumption and only the static portion can be fulfilled.", "What does the static assumption mean?", "Besides violating the static world assumption, the framework also brought about many other consideration", "Appearance-based loss has been an effective proxy loss for depth. However, there are certain pitfalls with using image intensity as a measure.", "Taking the above factors into account, most depth model in the literature tend to produce results with the following artefacts:", "2. Flickering effect: The depth map produces over time is not geometrically consistent. Large change in depth can be observed in the figure below. Especially at thin structure and boundaries.", "This section will be constantly updated upon new findings.", "With a clearer understanding of the associated problems, let's move on to discuss what solutions have been proposed in the literature as an attempt to resolve the problems. I will highlight some of the papers here.", "Many of the ideas that have been proposed can be broadly categorised into solving the following tasks:", "This was heavily investigated and tackled in MonoDepth2, ICCV2019. Their idea is simple yet effective to improve performance.", "Auto masking Stationary Pixel between source and target: To prevent the static scene violation, they proposed to simply ignore these pixels when calculating the loss. This happens when other objects are moving at the same speed as the camera or when the camera is stationary between frames.", "Pick the minimum error pixel-wise against all predicted views: This condition tackles occlusion or out of view pixels in an adjacent view due to ego-motion. This simple method was able to sharpen occlusion boundaries and reduces artefacts.", "Here, we are looking at architecture design that in essence, should be able to best capture structure information from RGB images and distil continuous depth/disparity value. One direction of research mostly focuses on preserving spatial content by modifying the basic encoder-decoder architecture while another focuses on developing better representation of disparity output.", "Encoding-Decoding features: This line of work seeks to optimize information flow through the network. In SuperDepth ICRA2019, they proposed to use subpixel-convolutional layers to effectively and accurately super resolve disparities from their lower-resolution outputs, replacing the upsampling layers in the decoder.", "The operation is as follows: image is reshape using phase shift, termed as pixel shuffle, which rearranges the elements of H \u00d7 W \u00d7 C \u00b7 r\u00b2 tensor to form rH \u00d7 rW \u00d7 C tensor.", "In PackNet, CVPR2020, they argued that the standard downsampling stages in the encoder are spatially harmful to dense depth prediction. Similarly, upsampling strategies fail to propagate and preserve sufficient details at the decoder layers to recover accurate depth predictions. They proposed to preserve information by replacing the downsampling pooling and upsampling with packing and unpacking blocks. So, instead of performing 2x2 max pooling, where the max value in a 4-pixel region is chosen and the rest is discarded, the features are packed via the Space2Depthoperation into the depth dimension instead. This way, no information is decimated. In the paper, they mention convolution 2D are not designed to capture depth channel. Hence the feature space is expanded to 4D and feed through a convolution 3D. The unpacking blocks does the reverse and works in the same way as SuperDepth using subpixel convolution to recover the features.", "Looking at representing depth and disparity: Instead of predict per pixel depth, there are others that look at depth prediction that improves robustness and stability.", "In Neural RGB->D Sensing, CVPR2019, they decided to include uncertainty estimation into the disparity estimate and at the same time accumulating over time under a Bayesian filtering framework, generating a Disparity Probability Volume (DPV). Then reducing the depth uncertainty estimate and improve robustness.", "In this paper, they proposed to predict Discrete Disparity Volume, ECCV2020. Which is inspired by the well known supervised method DORN, CVPR2018 that choose to frame the regression task as an ordinal regression problem. DORN achieve excellent performance in monocular depth estimation.", "Surface normal, disparity and optical flow share many similarities to depth in terms of representing structure in images. Surface normal can be interpreted as the direction of depth gradient. Optical flow can be naturally linked to depth via ego-motion and object motion. Disparity shares an inverse relation with depth. Although semantics does not have any direct relation, many uses segmentation maps as guidance to learning finer depth. There are many works that investigate these joint complementary properties.", "Jointly learnt in multi-task learning framework: One direction of study is to jointly learn depth along with other tasks. Many of these works show positive result empirically and validate it as a promising direction. These tasks are strongly correlated and would mutually benefit one another in a multi-task setting where the backbone is shared. In GeoNet, CVPR2018, consider learning optical flow, together with depth and pose jointly while enforcing geometrical consistency while in another work SceneNet, CVPR2019 focus on learning depth and segmentation.", "Leveraging semantic segmentation: Semantics itself does not have any mathematical relation to depth. However, several works pursue this direction on the idea that semantic should guide depth estimation by providing certain cues. E.g. Sky should be located faraway and naturally with very high depth values. A change in pixel label would most likely indicate the boundary of an object and result in a significant change in depth.", "In this work by TRL, ICLR2020. They proposed to use semantic model to guide geometric representation learning. They design a well-crafted semantic guidance feature module that injects semantic information at different stages of the network.", "As discussed in the previous section, the predicted depth is ambiguous in terms of scale. In the same paper as PackNet, they show that weak supervision from displacement between predicted translation component of pose and ground truth pose can resolve the metric scale. By constraining the pose, it ensure the pose network predicts metrically accurate estimates.", "Suppose some form of depth is available from range sensors such as lidar, then one can create a sparse depth map, using it in a semi-supervised manner. This has been explored extensively in Vitor Guizilin, et al, CoRL2019. An interesting analysis in my opinion. They investigated the effect of depth improvement in relation to the number of lidar points that are available during training."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff212e4f05ffa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://daryl-tan.medium.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Daryl Tan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd5d47d10c0e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&user=Daryl+Tan&userId=d5d47d10c0e9&source=post_page-d5d47d10c0e9----f212e4f05ffa---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff212e4f05ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&user=Daryl+Tan&userId=d5d47d10c0e9&source=-----f212e4f05ffa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff212e4f05ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&source=-----f212e4f05ffa---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1", "anchor_text": "refer to this post"}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1", "anchor_text": "motion parallax"}, {"url": "https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/cvpr17_sfm_final.pdf", "anchor_text": "Multiscale prediction"}, {"url": "https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula", "anchor_text": "Rodrigues\u2019 rotation formula"}, {"url": "https://towardsdatascience.com/inverse-projection-transformation-c866ccedef1c", "anchor_text": "written an article"}, {"url": "https://www.mathworks.com/help/images/ref/ssim.html", "anchor_text": "Structural Similarity Index, SSIM"}, {"url": "https://arxiv.org/pdf/1806.01260.pdf", "anchor_text": "Source"}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1", "anchor_text": "post"}, {"url": "https://arxiv.org/pdf/1712.00175.pdf", "anchor_text": "Scale ambiguity causes shrinking depth"}, {"url": "https://arxiv.org/pdf/1903.09847.pdf", "anchor_text": "bleeding edge effect"}, {"url": "https://arxiv.org/pdf/1903.09847.pdf", "anchor_text": "Source"}, {"url": "https://arxiv.org/pdf/1806.01260.pdf", "anchor_text": "MonoDepth2, ICCV2019"}, {"url": "https://arxiv.org/pdf/1810.01849.pdf", "anchor_text": "SuperDepth ICRA2019"}, {"url": "https://arxiv.org/pdf/1609.05158.pdf", "anchor_text": "subpixel-convolutional"}, {"url": "https://arxiv.org/pdf/1609.05158.pdf", "anchor_text": "Subpixel convolution"}, {"url": "https://arxiv.org/pdf/1905.02693.pdf", "anchor_text": "PackNet, CVPR2020"}, {"url": "https://arxiv.org/pdf/1901.02571.pdf", "anchor_text": "Neural RGB->D Sensing, CVPR2019"}, {"url": "https://arxiv.org/pdf/2003.13951.pdf", "anchor_text": "Discrete Disparity Volume, ECCV2020"}, {"url": "https://arxiv.org/pdf/1806.02446.pdf", "anchor_text": "DORN, CVPR2018"}, {"url": "https://arxiv.org/pdf/1803.02276.pdf", "anchor_text": "GeoNet, CVPR2018"}, {"url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Towards_Scene_Understanding_Unsupervised_Monocular_Depth_Estimation_With_Semantic-Aware_Representation_CVPR_2019_paper.pdf", "anchor_text": "SceneNet, CVPR2019"}, {"url": "https://arxiv.org/pdf/1803.02276.pdf", "anchor_text": "GeoNet"}, {"url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Towards_Scene_Understanding_Unsupervised_Monocular_Depth_Estimation_With_Semantic-Aware_Representation_CVPR_2019_paper.pdf", "anchor_text": "SceneNet"}, {"url": "https://arxiv.org/pdf/2002.12319.pdf", "anchor_text": "TRL, ICLR2020"}, {"url": "https://arxiv.org/pdf/2002.12319.pdf", "anchor_text": "Source"}, {"url": "https://arxiv.org/pdf/1910.01765.pdf", "anchor_text": "Vitor Guizilin, et al, CoRL2019"}, {"url": "https://arxiv.org/pdf/1910.01765.pdf", "anchor_text": "Source"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----f212e4f05ffa---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f212e4f05ffa---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----f212e4f05ffa---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/structure-from-motion?source=post_page-----f212e4f05ffa---------------structure_from_motion-----------------", "anchor_text": "Structure From Motion"}, {"url": "https://medium.com/tag/python?source=post_page-----f212e4f05ffa---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff212e4f05ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&user=Daryl+Tan&userId=d5d47d10c0e9&source=-----f212e4f05ffa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff212e4f05ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&user=Daryl+Tan&userId=d5d47d10c0e9&source=-----f212e4f05ffa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff212e4f05ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd5d47d10c0e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&user=Daryl+Tan&userId=d5d47d10c0e9&source=post_page-d5d47d10c0e9----f212e4f05ffa---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa91ae4c3a6fd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&newsletterV3=d5d47d10c0e9&newsletterV3Id=a91ae4c3a6fd&user=Daryl+Tan&userId=d5d47d10c0e9&source=-----f212e4f05ffa---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Written by Daryl Tan"}, {"url": "https://daryl-tan.medium.com/followers?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "429 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd5d47d10c0e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&user=Daryl+Tan&userId=d5d47d10c0e9&source=post_page-d5d47d10c0e9----f212e4f05ffa---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa91ae4c3a6fd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-depth-estimation-breaking-down-the-ideas-f212e4f05ffa&newsletterV3=d5d47d10c0e9&newsletterV3Id=a91ae4c3a6fd&user=Daryl+Tan&userId=d5d47d10c0e9&source=-----f212e4f05ffa---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1?source=author_recirc-----f212e4f05ffa----0---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=author_recirc-----f212e4f05ffa----0---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=author_recirc-----f212e4f05ffa----0---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Daryl Tan"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f212e4f05ffa----0---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1?source=author_recirc-----f212e4f05ffa----0---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Depth Estimation: Basics and IntuitionUnderstanding how far things are relative to a camera remains difficult but absolutely necessary for exciting applications such as\u2026"}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1?source=author_recirc-----f212e4f05ffa----0---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "\u00b714 min read\u00b7Feb 14, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F86f2c9538cd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-estimation-1-basics-and-intuition-86f2c9538cd1&user=Daryl+Tan&userId=d5d47d10c0e9&source=-----86f2c9538cd1----0-----------------clap_footer----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1?source=author_recirc-----f212e4f05ffa----0---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86f2c9538cd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdepth-estimation-1-basics-and-intuition-86f2c9538cd1&source=-----f212e4f05ffa----0-----------------bookmark_preview----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f212e4f05ffa----1---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f212e4f05ffa----1---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f212e4f05ffa----1---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f212e4f05ffa----1---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f212e4f05ffa----1---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f212e4f05ffa----1---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f212e4f05ffa----1---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----f212e4f05ffa----1-----------------bookmark_preview----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f212e4f05ffa----2---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f212e4f05ffa----2---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f212e4f05ffa----2---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f212e4f05ffa----2---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f212e4f05ffa----2---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f212e4f05ffa----2---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f212e4f05ffa----2---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----f212e4f05ffa----2-----------------bookmark_preview----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/inverse-projection-transformation-c866ccedef1c?source=author_recirc-----f212e4f05ffa----3---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=author_recirc-----f212e4f05ffa----3---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=author_recirc-----f212e4f05ffa----3---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Daryl Tan"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f212e4f05ffa----3---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/inverse-projection-transformation-c866ccedef1c?source=author_recirc-----f212e4f05ffa----3---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "Inverse Projection TransformationDepth and Inverse Projection"}, {"url": "https://towardsdatascience.com/inverse-projection-transformation-c866ccedef1c?source=author_recirc-----f212e4f05ffa----3---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": "\u00b77 min read\u00b7Dec 15, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc866ccedef1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finverse-projection-transformation-c866ccedef1c&user=Daryl+Tan&userId=d5d47d10c0e9&source=-----c866ccedef1c----3-----------------clap_footer----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/inverse-projection-transformation-c866ccedef1c?source=author_recirc-----f212e4f05ffa----3---------------------2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc866ccedef1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finverse-projection-transformation-c866ccedef1c&source=-----f212e4f05ffa----3-----------------bookmark_preview----2c7f62e0_e2e9_431f_9e0c_468495f92bc1-------", "anchor_text": ""}, {"url": "https://daryl-tan.medium.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "See all from Daryl Tan"}, {"url": "https://towardsdatascience.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://just-merwan.medium.com/what-is-6d-object-pose-estimation-in-computer-vision-21e8acf9e3e2?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://just-merwan.medium.com/?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://just-merwan.medium.com/?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Merwansky"}, {"url": "https://just-merwan.medium.com/what-is-6d-object-pose-estimation-in-computer-vision-21e8acf9e3e2?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "What is 6D Object Pose Estimation in Computer Vision?How to do 6D object pose estimation?"}, {"url": "https://just-merwan.medium.com/what-is-6d-object-pose-estimation-in-computer-vision-21e8acf9e3e2?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "\u00b74 min read\u00b7Nov 4, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F21e8acf9e3e2&operation=register&redirect=https%3A%2F%2Fjust-merwan.medium.com%2Fwhat-is-6d-object-pose-estimation-in-computer-vision-21e8acf9e3e2&user=Merwansky&userId=9c57695a0a83&source=-----21e8acf9e3e2----0-----------------clap_footer----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://just-merwan.medium.com/what-is-6d-object-pose-estimation-in-computer-vision-21e8acf9e3e2?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21e8acf9e3e2&operation=register&redirect=https%3A%2F%2Fjust-merwan.medium.com%2Fwhat-is-6d-object-pose-estimation-in-computer-vision-21e8acf9e3e2&source=-----f212e4f05ffa----0-----------------bookmark_preview----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----f212e4f05ffa----1-----------------bookmark_preview----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----0-----------------clap_footer----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----f212e4f05ffa----0---------------------ef00cc53_f250_4154_8288_299437444ffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----f212e4f05ffa----0-----------------bookmark_preview----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----1-----------------clap_footer----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----f212e4f05ffa----1---------------------ef00cc53_f250_4154_8288_299437444ffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----f212e4f05ffa----1-----------------bookmark_preview----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/machine-learning-interview-computer-vision-897bc2928855?source=read_next_recirc-----f212e4f05ffa----2---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://medium.com/@marizombie?source=read_next_recirc-----f212e4f05ffa----2---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://medium.com/@marizombie?source=read_next_recirc-----f212e4f05ffa----2---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Maryna Klokova"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----f212e4f05ffa----2---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/machine-learning-interview-computer-vision-897bc2928855?source=read_next_recirc-----f212e4f05ffa----2---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "ML interview prep: Computer vision popular topicsComputer vision: tasks, libraries, networks, datasets, preprocessing, image transformations, augmentation, pipeline, metrics, edges and\u2026"}, {"url": "https://medium.com/mlearning-ai/machine-learning-interview-computer-vision-897bc2928855?source=read_next_recirc-----f212e4f05ffa----2---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "\u00b77 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2F897bc2928855&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fmachine-learning-interview-computer-vision-897bc2928855&user=Maryna+Klokova&userId=412d531a727c&source=-----897bc2928855----2-----------------clap_footer----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/machine-learning-interview-computer-vision-897bc2928855?source=read_next_recirc-----f212e4f05ffa----2---------------------ef00cc53_f250_4154_8288_299437444ffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F897bc2928855&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fmachine-learning-interview-computer-vision-897bc2928855&source=-----f212e4f05ffa----2-----------------bookmark_preview----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f212e4f05ffa----3---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----f212e4f05ffa----3---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----f212e4f05ffa----3---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----f212e4f05ffa----3---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f212e4f05ffa----3---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f212e4f05ffa----3---------------------ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----3-----------------clap_footer----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f212e4f05ffa----3---------------------ef00cc53_f250_4154_8288_299437444ffe-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----f212e4f05ffa----3-----------------bookmark_preview----ef00cc53_f250_4154_8288_299437444ffe-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----f212e4f05ffa--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}