{"url": "https://towardsdatascience.com/are-the-space-invaders-deterministic-or-stochastic-595a30becae2", "time": 1683014238.087086, "path": "towardsdatascience.com/are-the-space-invaders-deterministic-or-stochastic-595a30becae2/", "webpage": {"metadata": {"title": "Are the space invaders deterministic or stochastic? | by Nicolas Maquaire | Towards Data Science", "h1": "Are the space invaders deterministic or stochastic?", "description": "Google Deepmind achieved human-level performance on 49 Atari games using the Arcade Learning Environment (ALE). This article describes the methods I used to reproduce this performance and discusses\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.nature.com/articles/nature14236", "anchor_text": "Human-level control through deep reinforcement learning", "paragraph_index": 1}, {"url": "https://github.com/NicMaq/Reinforcement-Learning", "anchor_text": "https://github.com/NicMaq/Reinforcement-Learning", "paragraph_index": 2}, {"url": "https://colab.research.google.com/drive/1nzH8TZ8zFth0oLwXwIXbn9OuAaJ4mVXG?usp=sharing", "anchor_text": "Breakout explained", "paragraph_index": 4}, {"url": "https://colab.research.google.com/drive/1--qFcl5QuTuudC-yYcE1odKx_htui4h6?usp=sharing", "anchor_text": "e-greedy and softmax explained", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/best-practices-for-reinforcement-learning-1cf8c2d77b66", "anchor_text": "the best practices for RL", "paragraph_index": 5}, {"url": "https://github.com/openai/baselines-results/blob/master/dqn_results.ipynb", "anchor_text": "baselines DQN results", "paragraph_index": 9}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper", "paragraph_index": 10}, {"url": "https://arxiv.org/abs/1207.4708", "anchor_text": "2013 ALE paper", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper", "paragraph_index": 17}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper", "paragraph_index": 19}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper", "paragraph_index": 21}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper", "paragraph_index": 37}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper", "paragraph_index": 40}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper", "paragraph_index": 49}, {"url": "https://github.com/openai/baselines-results/blob/master/dqn_results.ipynb", "anchor_text": "results", "paragraph_index": 69}], "all_paragraphs": ["Google Deepmind achieved human-level performance on 49 Atari games using the Arcade Learning Environment (ALE). This article describes the methods I used to reproduce this performance and discusses the efficiency of the mechanisms used by Deepmind and Open AI for injecting stochasticity in the ALE.", "As a side project, I spent some time trying to achieve the same Deepmind\u2019s human-level performance on Breakout and Space Invaders. Although I understand there are many better performing architectures, my goal was to use the same network as the one presented in Deepmind\u2019s 2015 nature paper (Human-level control through deep reinforcement learning). I did this to better understand the challenges and performances Deepmind experienced while playing some iconic games from my childhood. One of the challenges Deepmind experienced is particularly interesting to me: Are the environments stochastic or deterministic? Did Deepmind and Open AI fight deterministic waves of Space Invaders? In this paper we discuss the efficiency of the mechanisms used by Deepmind and Open AI for injecting stochasticity in the ALE.", "The source code can be accessed at https://github.com/NicMaq/Reinforcement-Learning", "This repository contains the code I used to support my conclusions as well as the data of my tensorboard runs to encourage discussions and facilitate comparisons.", "Additionally, for readers who want to learn how my algorithm works, I published Breakout explained and e-greedy and softmax explained. These are two Google Colab notebooks where I explain expected sarsa and the implementation of the two policies, e-greedy and softmax.", "Last, Reinforcement learning is an exciting and promising field of artificial intelligence but be aware that it is cursed. Read my post on the best practices for RL to accelerate your path to success.", "In Deepmind\u2019s 2015 nature paper we find two tables presenting the results (Extended Data Table 2 and Extended Data Table 3). In table 2, Deepmind listed the highest average episode score reported over the first 50 million frames while evaluating every 250,000 frames for 135,000 frames. In table 3, they listed the highest average episode score reported over the first 10 million frames.", "I don\u2019t have the computing power of Deepmind so I compared my results with table 3. On the first ten million frames (used for training the agent) deepmind reported a highest average score of 316.8 for Breakout and 1088.9 for Space Invaders.", "The company, Open AI, open-sourced baselines, which was their internal effort to reproduce reinforcement learning algorithms with performance on par with published results.", "To the best of my knowledge, the baseline team did not publish results on the same network as Deepmind. The closest we can find is a network trained with double q-learning, which as its name indicates, is an improvement on q-learning. Nevertheless, it was interesting to read through the reports and check if my results were comparable. So, provided that Open AI used the same methodology as Deepmind and particularly a skip frame of 4, the score they obtained was between 360 and 410 over the first 10 million frames (see baselines DQN results).", "Finally, the score for Space Invaders reported in the 2017 ALE paper for a DQN was 673.", "The methodology I used is discussed in detail in a later chapter. I tried to rigorously follow Deepmind\u2019s methodology. Below are the results I got for Breakout and Space Invaders using almost the same evaluation procedure. I committed my Tensorflow runs in the GitHub:", "Congratulations, I successfully reproduced Deepmind\u2019s performance on Breakout and Space Invaders.", "One of the major differences between Deepmind\u2019s code and mine is that Deepmind uses the ALE directly while I am using OpenAI Gym. And, certainly the most significant difference is how we inject stochasticity into the games.", "The ALE is deterministic and therefore, OpenAI Gym implements different techniques for injecting stochasticity in the games. Let\u2019s discuss which techniques are the closest to Deepmind\u2019s methodology and their efficiency.", "While there is no reference to determinism in the first 2013 ALE paper, Machado, Bellemare & al. write in 2017 that one of the main concerns of the ALE is that \u201cin almost all games, the dynamics within Stella itself are deterministic given the agent\u2019s actions.\u201d", "The original Atari 2600 console had no feature for generating random numbers. As a consequence, the ALE is also fully deterministic. As such, it is possible to achieve high scores by simply memorizing a good sequence of actions rather than learning to make good decisions. Such an approach is not likely to be successful beyond the ALE. The stochasticity of the environment is a critical factor to encourage the robustness of RL\u2019s algorithm and their ability to transfer to other tasks.", "Various approaches have been developed to add forms of stochasticity to the ALE dynamics (often, at a later date than Deepmind\u2019s paper publication date). In the 2017 ALE paper we can find:", "Google deepmind uses a fixed frame skipping of 4, a maximum of 30 initial no-ops, and a random action noise.", "The ALE is deterministic. We can read in the 2017 ALE paper that \u201cGiven a state s and a joystick input a there is a unique next state s0, that is, p(s0 | s; a) = 1.\u201d So, if at each step of the game there is only one possible outcome, we should always achieve the same score with the same network and the same initial state.", "In the following paragraphs, we will study the variance of the scores we achieved to evaluate the level of stochasticity added by the different approaches. We will also support our conclusions by looking at the distribution of the results.", "In the 2017 ALE paper, Machado, Bellemare & al., recommend sticky actions to enforce stochasticity. Sticky actions add stickiness to the agent\u2019s actions. At every step, the environment executes either the previous action or the new agent\u2019s action.", "\u201cOur proposed solution, sticky actions, leverages some of the main benefits of other approaches without most of their drawbacks. It is free from researcher bias, it does not interfere with agent action selection, and it discourages agents from relying on memorization. The new environment is stochastic for the whole episode, generated results are reproducible.\u201d", "We conducted two experiments to learn how to differentiate a stochastic and a deterministic environment. Our deterministic environment is BreakoutNoFrameskip-v4. We can read about this environment in Open AI\u2019s source code: \u201cNo frameskip. (Atari has no entropy source, so these are deterministic environments)\u201d. Our stochastic environment is BreakoutNoFrameskip-v4 with sticky actions (BreakoutNoFrameskip-v0).", "Below and on the left, we can see the distribution of results we got for the deterministic environment, and on the right, for the stochastic environment.", "As expected, we have a very narrow distribution of results for the determinist environment and a broader distribution for the stochastic environment.", "It\u2019s also very interesting to look at the histogram of the results for both environments:", "We can see on the left that, for each of the 100 games of our evaluation phase, we achieved the same score. On the right, the stochasticity added by the sticky actions caused the agent to achieve a variety of scores.", "To measure the spread, we can compute the variance of the results. Below is a comparison of the variance of the deterministic and stochastic environments.", "The variance of the results for the deterministic environment is always zero and greater than 0 for the stochastic environment.", "Let\u2019s compare these first results with the distribution and variance of the other techniques.", "Frame skipping consists of repeating the last action decided by the agent for a random number of n consecutive frames. The agent only sees 1 in n+1 frames.", "In Open AI Gym, frame skipping can skip a random (2,3, or 4) number of frames. The environments which skip a fixed number of frames are the {}Deterministic-v4 and {}Deterministic-v0 environments. The environments which skip a random number of frames are the {}-v4 and {}-v0 environments.", "Deepmind used a fixed frame skipping. We will use BreakoutDeterministic-v4.", "Below is a comparison between the result distribution of BreakoutNoFrameskip-v4 on the left and BreakoutDeterministic-v4 on the right. BreakoutDeterministic-v4 is the same environment as BreakoutNoFrameSkipV4 (deterministic), but with the addition of a fixed frame skipping.", "Both distributions are very similar. For BreakoutDeterministic-v4, we obtained the distribution of a deterministic environment.", "If we compute the variance for the two experiments, all values are equal to zero.", "In the 2017 ALE paper, Bellmare and al\u2019s conclusion about the random frame skipping technique was that \u201cbeside injecting stochasticity, frame skipping results in a simpler reinforcement learning problem and speeds up execution.\u201d", "As per our experiments, a fixed frame technique does not inject stochasticity but clearly simplifies the learning problem and speeds up convergence (see the scores below).", "Below is the distribution of one of my experiments with breakout-v4 which uses a random frame skipping technique. We clearly see that this distribution is similar to those of our stochastic environments.", "A random frame skipping technique adds stochasticity but also adds complexity. We can read in the 2017 ALE paper : \u201cDiscounting must also be treated more carefully, as this makes the effective discount factor random.\u201d", "My code does not take the time distortion into consideration. Distorting time in a Time Difference reinforcement learning method would certainly prove challenging.", "As it simplifies the learning problem and speeds up convergence, we will use BreakoutDeterministic-v4 as our deterministic environment for the remaining part of this article.", "Another technique used by Deepmind was to change the initial state by executing k no-op actions (k=30). This technique is not implemented by Open AI Gym.", "My implementation of no-ops for Breakout encourages a diversity of initial states by randomly moving the spaceship before sending the \u201cFIRE\u201d action (for a random number k, I chose either the \u201cRIGHT\u201d or \u201cLEFT\u201d action).", "On the left, we can see the distribution of results for our deterministic environment (BreakoutDeterministic-v4) and on the right, the distribution of results when the agent executes k no-ops actions (k < 0).", "The comparison between the two charts is interesting. While we don\u2019t have the same pattern as a deterministic environment, the spread is definitely narrower than the spread of a deterministic environment.", "The number of distinct results is increased but remains lower than in a stochastic environment.", "When studying the variance, we can notice that the environment presents signs of a deterministic environment. The variance is close to zero for a few evaluation phases and significantly lower than the variance of our deterministic environment. The technique no-ops injects little stochasticity. It is less efficient than other techniques.", "This confirms what Machado et al state in the 2017 ALE paper: \u201cThe environment remains deterministic beyond the choice of starting state.\u201d", "Finally, we will observe the efficiency of a random action noise. A random action noise is keeping a small probability to replace the agent\u2019s selected action by a random action. This technique is used by Deepmind. During the evaluation phase, they keep a probability of 5% to execute a random action.", "On the left is BreakoutDeterministic-v4 with epsilon = 0 and on the right is BreakoutDeterministic-v4 with epsilon = 0.05.", "We can observe that keeping epsilon non-nul clearly injects stochasticity. The results obtained are really close to the ones we got with BreakoutNoFrameskip-v0. And, on the graph below, we can also see that the variance is increasing over the first 20 million frames.", "Injecting stochasticity with a random action noise is clearly effective. Although it comes with an important drawback as it biases the policy and decreases performance.", "This supports what Bellmare and al. wrote in the 2017 ALE paper: \u201cRandom action noise may significantly interfere with the agent\u2019s policy\u201d.", "Let\u2019s validate our previous conclusions on Space Invaders.", "First, let\u2019s validate that we have the same differences between SpaceInvadersDeterministic-v4 (deterministic) and SpaceInvadersDeterministic-v0 (stochastic).", "We observe on these two distributions the same patterns as for Breakout. Also, the variance of the distribution is zero for the deterministic environment and non zero for the stochastic environment.", "For Breakout, the initial no-ops were not injecting stochasticity.", "We can say that SpaceInvadersDeterministic-v4 with no-ops behaves the same as Breakout. It shows signs of a deterministic behaviour. We obtained a variance significantly lower than our stochastic environment.", "Let\u2019s compare SpaceInvadersDeterministic-v4 (left) with SpaceInvadersDeterministic-v4 with a random action noise (right).", "The two distributions below clearly validate that keeping epsilon to non-zero value injects stochasticity.", "And, the variance is almost the same as the variance of our stochastic environment.", "In this article, we proved that there are different, valid methods to inject a certain level of stochasticity in the ALE. However, some of the methods come with undesirable side effects: the random frame skips distorts time; the initial no-ops shows signs of determinism and sometimes has no effect on the game; and the random action noise penalizes the behaviour policy.", "This corroborates the conclusion of Machado, Bellemare & al. who write: \u201cOur recommendation is to use sticky actions, ultimately proposing sticky actions as a standard training and evaluation protocol.\u201d", "Therefore, my preference when training on Open AI GYM would go toward using {}deterministic-v0 where we have a good stochasticity and no time distortion.", "It\u2019s important to note, if you\u2019re training an RL algorithm, it\u2019s always of interest to check the distribution of your scores for signs of determinism.", "Now, to answer the question about Deepmind winning over deterministic space invaders, I would say that they used two methods to inject stochasticity (initial no-ops and a random action noise).", "Using both methods seems excessive as a random action noise is sufficient to ensure stochasticity. Perhaps, Deepmind started their experiments with no-ops and noticed they were overfitting in some games. It\u2019s unclear and only Deepmind can say.", "Although it is difficult to understand the Baselines methodology, it\u2019s clear from the results that they added no-ops. It\u2019s unclear if they used a random action noise. Was using no-ops sufficient to add enough stochasticity in the games to prevent overfitting?", "I was in the same performance range as Deepmind when using a stochastic Breakout environment. When transferring to Space Invaders with the same hyperparameters, my results were significantly lower. Maybe it\u2019s related to the differences in methodology or there is still some fine tuning to do with the hyperparameters to get good performances on other games.", "I hope you enjoyed seeing the differences between a deterministic and a stochastic environment! And, I hope this article accelerated the transfer of your networks on other tasks, aiding in your path to success.", "M. G. Bellemare, Y. Naddaf, J. Veness and M. Bowling. The Arcade Learning Environment: An Evaluation Platform for General Agents, Journal of Artificial Intelligence Research, Volume 47, pages 253\u2013279, 2013.", "M. C. Machado, M. G. Bellemare, E. Talvitie, J. Veness, M. J. Hausknecht, M. Bowling. Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents, Journal of Artificial Intelligence Research, Volume 61, pages 523\u2013562, 2018."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F595a30becae2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://nicolasmaquaire.medium.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Nicolas Maquaire"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9ce02232e5a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=post_page-9ce02232e5a2----595a30becae2---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F595a30becae2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=-----595a30becae2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F595a30becae2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&source=-----595a30becae2---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www.nature.com/articles/nature14236", "anchor_text": "Human-level control through deep reinforcement learning"}, {"url": "https://github.com/NicMaq/Reinforcement-Learning", "anchor_text": "https://github.com/NicMaq/Reinforcement-Learning"}, {"url": "https://colab.research.google.com/drive/1nzH8TZ8zFth0oLwXwIXbn9OuAaJ4mVXG?usp=sharing", "anchor_text": "Breakout explained"}, {"url": "https://colab.research.google.com/drive/1--qFcl5QuTuudC-yYcE1odKx_htui4h6?usp=sharing", "anchor_text": "e-greedy and softmax explained"}, {"url": "https://towardsdatascience.com/best-practices-for-reinforcement-learning-1cf8c2d77b66", "anchor_text": "the best practices for RL"}, {"url": "https://github.com/openai/baselines-results/blob/master/dqn_results.ipynb", "anchor_text": "baselines DQN results"}, {"url": "https://openai.com/blog/openai-baselines-dqn/", "anchor_text": "https://openai.com/blog/openai-baselines-dqn/"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://arxiv.org/abs/1207.4708", "anchor_text": "2013 ALE paper"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://github.com/openai/baselines-results/blob/master/dqn_results.ipynb", "anchor_text": "results"}, {"url": "https://www.nature.com/articles/nature14236", "anchor_text": "Deepmind\u2019s 2015 nature paper"}, {"url": "https://arxiv.org/abs/1207.4708", "anchor_text": "2013 ALE paper"}, {"url": "https://arxiv.org/abs/1709.06009", "anchor_text": "2017 ALE paper"}, {"url": "https://docs.google.com/document/d/e/2PACX-1vQVP3qsMYCQrchrfmr2zznL_lFt-bHGgbolr40VxdMKab3k3ksDapX7b_XqjZXmnXuZTVOhqR_QJy_n/pub", "anchor_text": "Methods and Hyperparameters"}, {"url": "https://medium.com/tag/openai-gym?source=post_page-----595a30becae2---------------openai_gym-----------------", "anchor_text": "Openai Gym"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----595a30becae2---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/dqn?source=post_page-----595a30becae2---------------dqn-----------------", "anchor_text": "Dqn"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----595a30becae2---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/atari?source=post_page-----595a30becae2---------------atari-----------------", "anchor_text": "Atari"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F595a30becae2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=-----595a30becae2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F595a30becae2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=-----595a30becae2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F595a30becae2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9ce02232e5a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=post_page-9ce02232e5a2----595a30becae2---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5103289c7b67&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&newsletterV3=9ce02232e5a2&newsletterV3Id=5103289c7b67&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=-----595a30becae2---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Written by Nicolas Maquaire"}, {"url": "https://nicolasmaquaire.medium.com/followers?source=post_page-----595a30becae2--------------------------------", "anchor_text": "101 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "http://Model.fit", "anchor_text": "Model.fit"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9ce02232e5a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=post_page-9ce02232e5a2----595a30becae2---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5103289c7b67&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fare-the-space-invaders-deterministic-or-stochastic-595a30becae2&newsletterV3=9ce02232e5a2&newsletterV3Id=5103289c7b67&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=-----595a30becae2---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/best-practices-for-reinforcement-learning-1cf8c2d77b66?source=author_recirc-----595a30becae2----0---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=author_recirc-----595a30becae2----0---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=author_recirc-----595a30becae2----0---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Nicolas Maquaire"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----595a30becae2----0---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/best-practices-for-reinforcement-learning-1cf8c2d77b66?source=author_recirc-----595a30becae2----0---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Best practices for Reinforcement LearningLifting the curses of time and cardinality."}, {"url": "https://towardsdatascience.com/best-practices-for-reinforcement-learning-1cf8c2d77b66?source=author_recirc-----595a30becae2----0---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "\u00b712 min read\u00b7Sep 27, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1cf8c2d77b66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-reinforcement-learning-1cf8c2d77b66&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=-----1cf8c2d77b66----0-----------------clap_footer----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/best-practices-for-reinforcement-learning-1cf8c2d77b66?source=author_recirc-----595a30becae2----0---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1cf8c2d77b66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbest-practices-for-reinforcement-learning-1cf8c2d77b66&source=-----595a30becae2----0-----------------bookmark_preview----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----595a30becae2----1---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----595a30becae2----1---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----595a30becae2----1---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----595a30becae2----1---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----595a30becae2----1---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----595a30becae2----1---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----595a30becae2----1---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----595a30becae2----1-----------------bookmark_preview----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----595a30becae2----2---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----595a30becae2----2---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----595a30becae2----2---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----595a30becae2----2---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----595a30becae2----2---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----595a30becae2----2---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----595a30becae2----2---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----595a30becae2----2-----------------bookmark_preview----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/inference-on-the-edge-21234ea7633?source=author_recirc-----595a30becae2----3---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=author_recirc-----595a30becae2----3---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=author_recirc-----595a30becae2----3---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Nicolas Maquaire"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----595a30becae2----3---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/inference-on-the-edge-21234ea7633?source=author_recirc-----595a30becae2----3---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "Inference on the edgeBuilding a deep neural network with Tensorflow for the Raspberry Pi"}, {"url": "https://towardsdatascience.com/inference-on-the-edge-21234ea7633?source=author_recirc-----595a30becae2----3---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": "\u00b714 min read\u00b7May 9, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F21234ea7633&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finference-on-the-edge-21234ea7633&user=Nicolas+Maquaire&userId=9ce02232e5a2&source=-----21234ea7633----3-----------------clap_footer----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/inference-on-the-edge-21234ea7633?source=author_recirc-----595a30becae2----3---------------------bf503665_5f85_4041_bfe4_4e4677f29a25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21234ea7633&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finference-on-the-edge-21234ea7633&source=-----595a30becae2----3-----------------bookmark_preview----bf503665_5f85_4041_bfe4_4e4677f29a25-------", "anchor_text": ""}, {"url": "https://nicolasmaquaire.medium.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "See all from Nicolas Maquaire"}, {"url": "https://towardsdatascience.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----595a30becae2----0-----------------bookmark_preview----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----595a30becae2----1-----------------bookmark_preview----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Piotr Krosniak"}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Vaccine Supply Chain Optimization with AI-Powered Capacitated Vehicle Routing Problem(CVRP)- Part 1The world is facing a global health crisis, and one of the most important challenges is to ensure an efficient and timely distribution of\u2026"}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "6 min read\u00b7Jan 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fca79519e9ad7&operation=register&redirect=https%3A%2F%2Fpiotrkrosniak.medium.com%2Fvaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7&user=Piotr+Krosniak&userId=b791abcfafd5&source=-----ca79519e9ad7----0-----------------clap_footer----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://piotrkrosniak.medium.com/vaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7?source=read_next_recirc-----595a30becae2----0---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca79519e9ad7&operation=register&redirect=https%3A%2F%2Fpiotrkrosniak.medium.com%2Fvaccine-supply-chain-optimization-with-ai-powered-capacitated-vehicle-routing-problem-cvrp-part-1-ca79519e9ad7&source=-----595a30becae2----0-----------------bookmark_preview----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://medium.com/@amaster_37400?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://medium.com/@amaster_37400?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Aaron Master"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Please Stop Drawing Neural Networks WrongThe Case for GOOD Diagrams"}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "12 min read\u00b7Mar 21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fffd02b67ad77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-stop-drawing-neural-networks-wrong-ffd02b67ad77&user=Aaron+Master&userId=31905cfe67ce&source=-----ffd02b67ad77----1-----------------clap_footer----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----595a30becae2----1---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "33"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffd02b67ad77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-stop-drawing-neural-networks-wrong-ffd02b67ad77&source=-----595a30becae2----1-----------------bookmark_preview----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----595a30becae2----2---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----595a30becae2----2---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----595a30becae2----2---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----595a30becae2----2---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----595a30becae2----2---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----595a30becae2----2---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----2-----------------clap_footer----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----595a30becae2----2---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----595a30becae2----2-----------------bookmark_preview----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----595a30becae2----3---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----595a30becae2----3---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----595a30becae2----3---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----595a30becae2----3---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----595a30becae2----3---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "Understanding NeRFsA massive breakthrough in scene representation"}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----595a30becae2----3---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": "\u00b711 min read\u00b73 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----2a082e13c6eb----3-----------------clap_footer----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----595a30becae2----3---------------------e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&source=-----595a30becae2----3-----------------bookmark_preview----e40312e7_0cf6_44e8_bc06_b2c84a1cb49f-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----595a30becae2--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----595a30becae2--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}