{"url": "https://towardsdatascience.com/tl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93", "time": 1683003408.562627, "path": "towardsdatascience.com/tl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93/", "webpage": {"metadata": {"title": "tl;dr: How having more SWAG can make for safer AI drivers | by Leon Chlon | Towards Data Science", "h1": "tl;dr: How having more SWAG can make for safer AI drivers", "description": "Autonomous vehicles were once only the subject of 20th century entertainment classics like Knight Rider. Today, Google has Waymo, Uber has the XC90 SUV and every modern Tesla is fitted with its very\u2026"}, "outgoing_paragraph_urls": [{"url": "https://waymo.com/", "anchor_text": "Waymo", "paragraph_index": 0}, {"url": "https://www.theverge.com/2019/6/12/18662626/uber-volvo-self-driving-car-safety-autonomous-factory-level", "anchor_text": "XC90 SUV", "paragraph_index": 0}, {"url": "https://www.tesla.com/en_GB/autopilot", "anchor_text": "autopilot", "paragraph_index": 0}, {"url": "https://www.coursera.org/lecture/machine-learning/stochastic-gradient-descent-DoRHJ", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1803.05407", "anchor_text": "Stochastic Weight Averagin", "paragraph_index": 7}, {"url": "https://arxiv.org/pdf/1902.02476.pdf", "anchor_text": "Maddox et al.", "paragraph_index": 8}, {"url": "https://www.jstor.org/stable/2676803?seq=1", "anchor_text": "Bayesian model averaging", "paragraph_index": 10}, {"url": "https://machinelearningmastery.com/monte-carlo-sampling-for-probability/", "anchor_text": "Monte Carlo sampling", "paragraph_index": 10}, {"url": "https://github.com/udacity/self-driving-car-sim", "anchor_text": "driving simulator", "paragraph_index": 12}, {"url": "https://towardsdatascience.com/deep-learning-for-self-driving-cars-7f198ef4cfa2", "anchor_text": "Manajit Pal", "paragraph_index": 12}, {"url": "https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip", "anchor_text": "dataset", "paragraph_index": 12}, {"url": "https://github.com/wjmaddox/swa_gaussian/", "anchor_text": "SWAG training repo", "paragraph_index": 13}, {"url": "https://arxiv.org/abs/1803.05407", "anchor_text": "Izmailov et al.", "paragraph_index": 15}, {"url": "https://colab.research.google.com/", "anchor_text": "Google\u2019s collaboratory", "paragraph_index": 20}, {"url": "https://www.linkedin.com/in/marcantoniomawada/", "anchor_text": "Dr. Marco Antonio Awada", "paragraph_index": 20}], "all_paragraphs": ["Autonomous vehicles were once only the subject of 20th century entertainment classics like Knight Rider. Today, Google has Waymo, Uber has the XC90 SUV and every modern Tesla is fitted with its very own, less chatty version of KITT called autopilot. Like a regular driver, the brain of an AI driver has to be experienced, quick and most importantly, confident. While we can improve experience with more data, and quickness with more powerful machines or faster algorithms, how do we measure and regulate our confidence?", "Notice that I said regulate and not necessarily improve. This is because an autonomous driver\u2019s decisions are usually powered by some flavor of deep learning model that is already an overconfident. Driving isn\u2019t really an activity where overconfidence pays off; rare mistakes can have devastating consequences. Nobody is calling deep learning models cocky, they\u2019re just mostly deterministic functions that can\u2019t represent uncertainty. This is where Bayesian methods win the day.", "DNNs extremely powerful models that demonstrate remarkable performance across a range of prediction tasks ranging from language translation to image classification. They often contain hundreds of thousands of parameters that can be tuned to learn complicated patterns from data. In supervised learning, the goal is to learn p(y|\u03b8,X); we search for model parameters \u03b8 that along with our feature data X, can be used to discriminate between or predict the observations in our target variable y. For any \u03b8, we can calculate how well our model represents the data by using an appropriate loss metric L, such as the mean-squared error (MSE) in the case of a regression model of negative log likelihood for classification tasks.", "If we plot L against \u03b8, we can visualize how the loss magnitude varies across parameter space:", "This beautiful illustration zooms into the highly non-convex loss surface of the RESNET-20 DNN trained on the CIFAR10 dataset. Each \u03b8 along the (x,y) axes essentially represents a new model, with its error tracked by the height of L along the z-axis; Ideally, we want to pick \u03b8 with the smallest value of L. Stochastic gradient descent (SGD) acts as a sort of GPS, leading us off from an initial starting location down the path of greatest descent until we hit one of the many local minima. For those unfamiliar with SGD, I highly recommend starting with Andrew NG\u2019s fantastic overview here.", "This method isn\u2019t without its drawbacks:", "How can we address these problems in a way that doesn\u2019t demand much additional computational overhead?", "The SWA in SWAG stands for Stochastic Weight Averaging, a method that specifically tackles the first two drawbacks. The idea is to start from a pre-trained solution \u03b8_{pre}, and then push the learning rate up to explore the local geometry using SGD. At each step i we move to a new position in weight space \u03b8_{i} at a constant or cyclical learning rate. The constant learning rate gives rise to a new solution which we successively average with our pre-trained solution to give the SWA solution \u03b8_{swa}. For the cyclical learning rate, the solver \u201cjumps\u201d out of a local minimum and converges to another solution nearby; the converged solution at the end of the learning cycle is averaged with the trained solution. The authors show that this new solution is more likely to be centered within a broad set of high performing networks, and highlight improved prediction accuracy across many residual and image classification networks.", "Maddox et al. wrap the approach in Bayesian magic, extending SWA to SWA(G) by approximating the local error surface using a multivariate Gaussian model of the form N(\u03b8_{swa}, \u03a3).", "\u03a3 is a covariance matrix that tracks the variation along the local geometry, and is updated using each new point \u03b8_{i} moved to along the SWA algorithm\u2019s path. Unfortunately, computing \u03a3 is expensive if we include every iteration i; DNNs contain millions of parameters. As a speed-hack, the authors use the full set of iterations to update only the diagonal elements in \u03a3, with the off-diagonals computed using the last T terms along the SGD iterates.", "Now for the best part: we no longer have just one choice for \u03b8, we have an entire distribution given by N(\u03b8_{swa}, \u03a3), that characterizes the geometry around \u03b8_{swa}. This lets us directly model the uncertainty into any given prediction using Bayesian model averaging. In principle this involves integrating \u03b8 out of p(y|\u03b8,X) to give us p(y|X). In practice this is computationally intractable, so we settle for an approximation by Monte Carlo sampling: sampling \u03b8_{k}~N(\u03b8_{swa}, \u03a3) K times and averaging 1/K (\u03a3 p(y|\u03b8_{k},X)).", "SWAG has demonstrated impressive performance on image classification, segmentation and regression tasks, but how will it fair on automated driving?", "Udemy dropped a great driving simulator back in 2016 that can be used to manually gather training data and handle I/O from a python API. The network architecture and data pre-processing steps used in this experiment come from a great tutorial by Manajit Pal, which also includes a link to the dataset used for one of two tracks.", "Essentially, the network is a modified convolutional neural network with linear layers predicting a single steering angle. The network takes as input the right, center and left views from the car driver\u2019s perspective. Since this is a regression task, the mean squared error is used as the loss criterion. All code was written in python, with inference done using pytorch and the SWAG training repo released by Maddox et al.", "The data was split into training and validation sets using a 80:20 seeded randomized assignment. First an initial network was trained using conventional SGD over 60 epochs, with a linearly decaying learning rate initially set to 0.1 for 30 epochs, decaying linearly to 0.00001 and staying fixed for the final 6 epochs. The momentum was set to constant 0.9 throughout training with L2 regularization achieved using a 0.0001 weight decay. Convergence was typically observed after 40 epochs.", "SWAG was then run for a further 60 epochs, updating the cyclical learning rate for each epoch i as outlined by Izmailov et al.,:", "using base learning rate parameters (\u03b11, \u03b12) ={(10\u22121 , 10\u22123 ) and c is the cycle length set to 5 epochs. I recorded the train/validation MSE and converted them to negative log likelihoods for easier interpretation. We can perform a Singular Value Decomposition (SVD) on the obtained covariance matrix to project our validation set loss surface onto a two-dimensional plane defined by the eigenvectors:", "Here, v1,v2 represent distances from the SWA-solution in a low dimensional plane spanned by the first two SVD eigenvectors. This is a very low-dimensional representation, but captures the loss surface geometry incredibly well!! We see that although our SGD solution is within the SWAG 3\u03c3 region (green dashed line), it is considerably distant from the SWAG mean solution which happens to sit at the very center of the broad loss boundary.", "The final verdict is in, our SGD model achieves a validation set NLL of 0.91 \u00b1 0.0115, whilst the SWAG construction has both a lower loss and a tighter confidence bound around the solution with 0.88 \u00b1 0.0094.", "Since this framework is extremely flexible, it can be extended to more complex autonomous driving networks that have memory-like components such as like LSTMs. But for now, I hope I have convinced you that Bayesian Networks really are amazing and have such great promise for the future.", "A big shoutout to Google\u2019s collaboratory environment who powered this project, they provide GPU hours for free so anyone can train their models! Also to Dr. Marco Antonio Awada for his great mentorship around information geometry and its applications to Deep Learning.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Research Data Scientist \u2014 Facebook; Past: McKinsey Analytics Consultant | Harvard Medical School Postdoc | University of Cambridge PhD, MPhil"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd23457ecdb93&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://chleon.medium.com/?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": ""}, {"url": "https://chleon.medium.com/?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "Leon Chlon"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fff2d21af7d63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&user=Leon+Chlon&userId=ff2d21af7d63&source=post_page-ff2d21af7d63----d23457ecdb93---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd23457ecdb93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd23457ecdb93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://waymo.com/", "anchor_text": "Waymo"}, {"url": "https://www.theverge.com/2019/6/12/18662626/uber-volvo-self-driving-car-safety-autonomous-factory-level", "anchor_text": "XC90 SUV"}, {"url": "https://www.tesla.com/en_GB/autopilot", "anchor_text": "autopilot"}, {"url": "https://www.coursera.org/lecture/machine-learning/stochastic-gradient-descent-DoRHJ", "anchor_text": "here"}, {"url": "https://arxiv.org/abs/1803.05407", "anchor_text": "argued"}, {"url": "https://arxiv.org/abs/1803.05407", "anchor_text": "Stochastic Weight Averagin"}, {"url": "https://arxiv.org/pdf/1902.02476.pdf", "anchor_text": "Maddox et al."}, {"url": "https://www.jstor.org/stable/2676803?seq=1", "anchor_text": "Bayesian model averaging"}, {"url": "https://machinelearningmastery.com/monte-carlo-sampling-for-probability/", "anchor_text": "Monte Carlo sampling"}, {"url": "https://github.com/udacity/self-driving-car-sim", "anchor_text": "driving simulator"}, {"url": "https://towardsdatascience.com/deep-learning-for-self-driving-cars-7f198ef4cfa2", "anchor_text": "Manajit Pal"}, {"url": "https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip", "anchor_text": "dataset"}, {"url": "https://github.com/wjmaddox/swa_gaussian/", "anchor_text": "SWAG training repo"}, {"url": "https://arxiv.org/abs/1803.05407", "anchor_text": "Izmailov et al."}, {"url": "https://colab.research.google.com/", "anchor_text": "Google\u2019s collaboratory"}, {"url": "https://www.linkedin.com/in/marcantoniomawada/", "anchor_text": "Dr. Marco Antonio Awada"}, {"url": "https://medium.com/tag/autonomous-cars?source=post_page-----d23457ecdb93---------------autonomous_cars-----------------", "anchor_text": "Autonomous Cars"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d23457ecdb93---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/bayesian-machine-learning?source=post_page-----d23457ecdb93---------------bayesian_machine_learning-----------------", "anchor_text": "Bayesian Machine Learning"}, {"url": "https://medium.com/tag/bayesian-neural-network?source=post_page-----d23457ecdb93---------------bayesian_neural_network-----------------", "anchor_text": "Bayesian Neural Network"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----d23457ecdb93---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd23457ecdb93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&user=Leon+Chlon&userId=ff2d21af7d63&source=-----d23457ecdb93---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd23457ecdb93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&user=Leon+Chlon&userId=ff2d21af7d63&source=-----d23457ecdb93---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd23457ecdb93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd23457ecdb93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d23457ecdb93---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d23457ecdb93--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d23457ecdb93--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d23457ecdb93--------------------------------", "anchor_text": ""}, {"url": "https://chleon.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://chleon.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Leon Chlon"}, {"url": "https://chleon.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "187 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fff2d21af7d63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&user=Leon+Chlon&userId=ff2d21af7d63&source=post_page-ff2d21af7d63--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F25471836b4f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftl-dr-how-having-more-swag-can-make-for-safer-ai-drivers-d23457ecdb93&newsletterV3=ff2d21af7d63&newsletterV3Id=25471836b4f1&user=Leon+Chlon&userId=ff2d21af7d63&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}