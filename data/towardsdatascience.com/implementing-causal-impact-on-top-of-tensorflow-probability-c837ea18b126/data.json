{"url": "https://towardsdatascience.com/implementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126", "time": 1683017923.399541, "path": "towardsdatascience.com/implementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126/", "webpage": {"metadata": {"title": "Implementing Causal Impact on Top of TensorFlow Probability | by Will Fuks | Towards Data Science", "h1": "Implementing Causal Impact on Top of TensorFlow Probability", "description": "One day a good friend and coworker of mine came to me and asked a question that would \u201chaunt me\u201d to this day. In fact, this post, written years after that question, is a derivation of that\u2026"}, "outgoing_paragraph_urls": [{"url": "https://gist.github.com/WillianFuks/bf1252db75e03029a1b67e3dfd67e07a", "anchor_text": "this dataset", "paragraph_index": 13}, {"url": "https://gist.github.com/WillianFuks/2b6f8093ac257f2ee53e038ea6db7855", "anchor_text": "dataset", "paragraph_index": 22}, {"url": "https://www.jmlr.org/papers/volume19/18-009/18-009.pdf", "anchor_text": "bsts", "paragraph_index": 42}, {"url": "https://towardsdatascience.com/demystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a", "anchor_text": "post", "paragraph_index": 46}, {"url": "https://github.com/google/CausalImpact", "anchor_text": "library", "paragraph_index": 54}, {"url": "https://github.com/WillianFuks/tfcausalimpact", "anchor_text": "tfcausalimpact", "paragraph_index": 54}, {"url": "https://github.com/WillianFuks/tfcausalimpact/blob/master/tests/fixtures/arma_data.csv", "anchor_text": "arma_data.csv", "paragraph_index": 55}, {"url": "https://github.com/statsmodels/statsmodels", "anchor_text": "statsmodels", "paragraph_index": 78}, {"url": "https://en.wikipedia.org/wiki/Variational_Bayesian_methods", "anchor_text": "Variational Inference", "paragraph_index": 84}, {"url": "https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo", "anchor_text": "Hamiltonian Monte Carlo", "paragraph_index": 84}, {"url": "https://github.com/WillianFuks/tfcausalimpact/issues", "anchor_text": "issue", "paragraph_index": 92}, {"url": "https://open.spotify.com/playlist/6DDVtTmNRo32PUGy3vsRCC", "anchor_text": "mission", "paragraph_index": 94}], "all_paragraphs": ["One day a good friend and coworker of mine came to me and asked a question that would \u201chaunt me\u201d to this day. In fact, this post, written years after that question, is a derivation of that conversation.", "-Hey man! We are trying to solve an interesting problem, maybe you can help us out! The challenge is, we want to run a marketing campaign on national television and we want a way to analyze the real impact that it had on our sales. How can we do that in a reliable way?", "To which I promptly answered: \u201cman\u2026without a control group I have no idea\u2026\ud83d\ude15\u201d.", "Well, as we came to learn later on, there\u2019s actually a set of techniques developed to solve this exact type of problem, also known as Causal Impact inference which will be addressed in this post.", "With my coworker question in mind, here\u2019s what we\u2019ll be covering in this article:", "We\u2019ll be able to fully analyze whether a given random variable causes impact on another one (given a degree of confidence) which will allow us to solve a huge amount of recurring problems in the data science field.", "The concept of causality is probably one of the most powerful in the field of data science as well as it\u2019s probably one of the most difficult and complex to understand and implement.", "Deriving causality is what could bring us new drugs to fight diseases, a deeper understanding of the human brain, better explanations to various observed phenomena and so on.", "In fact, it\u2019s by understanding causality that I could have helped my coworker on the television advertisement challenge: once we find the causal relationship between marketing investment on TV networks and sales revenue we can infer how both are expected to behave, even when manipulating one of them (by increasing investments in marketing for instance).", "Using a Bayesian perspective, here\u2019s a simple depiction of a causality relationship between two random variables X and Y:", "Working with this type of data should be straightforward. We know that X has a direct impact on Y so if one increases we already have an idea on how the other will behave. But let\u2019s imagine as an example that we have a model relating operational and marketing investments along with the company sales:", "Now, what are the causalities between the variables?", "Well, Operation does cause some effect on Sales. But, given this Bayesian graph, if we know the value of Marketing then how much was invested in operations isn\u2019t relevant on Sales anymore. The causal relationship of this graph implies that when we observed marketing then we can fully describe sales.", "We can actually see that in data; suppose we have this dataset with fictional numbers:", "Let\u2019s fit a linear regression on top of this data using Keras from TensorFlow. At first, we regress the response variable Sales with just the independent Operation variable (the bias is removed to simplify the discussion):", "So we see that our linear regression does find a relationship between Operation and Sales as expected. But let\u2019s see other scenarios. Now we regress with [[Operation, Marketing]] using the same code and the result is:", "Notice now that Operation is essentially irrelevant to the regression whereas Marketing has a linear weight of 1.41. Let\u2019s see what happens if we remove now the Operation variable from the regression:", "Results in 1.33. That means that on this graph structure the variable Operations becomes irrelevant if we also have Marketing. In other words, it no longer causes impact on Sales.", "In fact, here\u2019s the code used to build this simulated data:", "Notice that Sales is a distribution whose parent is Marketing and the relationship between both is a linear 1.4 combination, just as our regression found.", "We\u2019ve just seen one example of a graph structure explaining causality. Depending on how variables are connected and which data we observed then conclusions can vary wildly.", "We can go further and propose a new model to our sales data. Suppose now that we find that the following model is the one that actually generates our observed data:", "This is known as a collider; now the causality relationship between our variables have completely changed and what we discussed before no longer is true. Let\u2019s suppose that we obtained this dataset from our Marketing team:", "Once again we run the linear regression with each variable to see what happens. First, we use just Operation to explain Sales:", "And finally both Operation and Marketing:", "Now this is interesting. When we observed just one variable, they both led to the same results, that is, a linear regression of 2.3 to explain the data. Only when observing both is that we see that Operation has a weight of 1.22 and Marketing has 1.38. This is how this data was built:", "As we can see, in fact we have a 1.2 and a 1.4 linear relationship between both variables with Sales. But when we observed just one of them, the regression almost doubled the linear relationship in an attempt to explain the observed data. There\u2019s a causal relationship between variables regardless of which variables are observed or not but the predictive capability of the model is only precise when both variables are observed.", "Now we have an interesting problem. Let\u2019s say I told my coworker that we could create a model relating the advertisement investment to the sales of the company and extract some sort of correlation between both, following a structure like this one:", "That would make things easy right? We could just run the TV ads and extract some (possibly) linear relationship between costs and sales. Easy!", "But what if the real relationship that explains Sales is something like this:", "Where \u201c?\u201d is some unknown variable that might be influencing our sales and we are not even aware of. Or it could just as possible be the case that we had a direct chain structure like so:", "Again we would find wrong relationships between both variables which could potentially lead to disastrous decisions (like investing on campaigns that are not really profitable). If we mistakenly conclude that the relationship is twice of what it actually is, it might take a huge amount of time and money until the company finally realizes that something is wrong.", "Let\u2019s think about what the ideal solution would look like. It would probably involve running an A/B test of some sort and comparing results from control group against the test group. The reason is that a proper A/B test can properly eliminate sources of bias and lead to precise results. Graphically, it\u2019d be something like this:", "Where each \u03b1 represents some variable that might affect the sales of the company, such as investments on operations or marketing for instance.", "If we run the A/B test, all those \u03b1\u2019s are present on both groups except for the \u03b1i which represents the variable we want to investigate. As an example, in our TV advertisement challenge, we could track down sales on a control group where no advertisement is running against the test group where customers are being exposed to the television campaign.", "Mathematically, we compute the posterior distribution for the differences between performances on both groups and see how this random variable behaves. P(B- A) having most of its distribution weight above 0 (zero) means that we have an indication B is performing better than A.", "In theory, this would be the best approach for this challenge as we can isolate the causal effects of the advertisement variable on Sales. But this is not really feasible. Most of the time we simply can\u2019t separate variables into two distinct groups such as is the case for the TV commercial. There\u2019s no viable way to show the campaign to one group and not the other as both will be watching the same TV offerings.", "If we only had, somehow, the control group, things would be easier. Well, that\u2019s actually how we begin to solve the Causal Impact challenge. So here\u2019s what we\u2019re going to do: given that we can\u2019t create a control group, let\u2019s simulate one!", "Yeap, that\u2019s right. We\u2019ll simulate what the control group would look like had no advertisement (or more broadly speaking, had no intervention) taken place. For what\u2019s coming next, we\u2019ll need to learn some stuff on modeling time series data.", "Suppose we collected data of the company sales along with the investments made on operations throughout the month for each day and we start our television campaign on the 18th day of the month:", "If we somehow could come up with a model that explains how Sales evolves over time, we\u2019d be able to project what the revenue of the company would have been without the television ads running:", "Having our forecasts and their respective confidence intervals, we\u2019d be able to compare our expectations to what really happened and compute from the difference what impact the Advertisement variable might have caused on Sales. Our challenge then becomes a task of figuring out how to better model time series data so we can build the forecast points.", "There are several methods for building models on time series data, ranging from simpler methods that extracts various statistics such as auto-correlation or moving averages to more sophisticated algorithms that uses state-of-the-art deep learning nets. The one we\u2019ll be using is the Bayesian Structural Time Series, or bsts for short. The motivation is that this algorithm is flexible enough to model a wild range of possibilities while offering a Bayesian framework which allows us to add our own assumptions of the world (known as the Bayesian priors).", "In essence, it works by using latent variables that helps to describe the observed data. Such variables evolve through time by following certain rules, all of which tend to be quite simple and have a straightforward implementation. Here is the mathematical formulation: suppose that our time series we want to model is given by yt. It follows from bsts that:", "These equations seem scary but they are actually simple and powerful as they allow for the modeling of an extensive range of possibilities including auto-regressive and moving averages models among many others.", "First, the \u201calphas\u201d represent latent structural components. They work as hidden variables whose time dynamics we define in accordance to the observed data being modeled. We begin with the initial state given by equation 3 and use equation 2 to keep adapting the states for each step t. After the adaptation, a new linear transformation represented by Z is applied and a noise is added (the epsilon value) which models our observed time series yt.", "While we won\u2019t get into the details of the mathematics behind finding the posterior of the latent variables distribution, this post from Wei Yi does an excellent job at explaining what\u2019s happening behind the scenes on TensorFlow Probability implementation, which is the one we\u2019ll be using soon.", "Here\u2019s a list of the available structural models TensorFlow Probability offers us and which we can add or remove as we wish aiming to better explain the data:", "Implementing this concept on top of TensorFlow Probability is quite straightforward. Here\u2019s an example that combines a local level with a linear regression to run forecasts on observed simulated data:", "The overall idea is to keep building all structures that we want to represent our model and then combine them through the tfp.sts.Sum operation by sending the components inside a list container.", "After that, we just fit the model and use the Markov samples to run forecasts and extract confidence intervals.", "It\u2019ll be our job to model the observed data with the best set structural components possible; the better the model is the more precise we\u2019ll be when using a representation for a control group that describes what data would look like had our variable under investigation not assumed its current value.", "All ideas necessary for running this simulated A/B test have been implemented on tfcausalimpact so let\u2019s see now how to use this library.", "At this point, the necessary knowledge for helping my coworker to solve the TV advertisement challenge have already been introduced. What we need now is a framework to combine all those ideas and compute for us various statistical analyzes to help us in our decision process, such as estimating the impact of the ads and how confident we are in those estimations.", "Google implemented on top of R language a powerful library for running causal inference. For those also working with Python (main focus of this article), we now have tfcausalimpact which also fits a Bayesian structural model on past observed data and compares forecasts against the real response. Let\u2019s see some examples on how to use it.", "Let\u2019s run a simple simulated dataset to see what happens. We\u2019ll be using the simulated dataset arma_data.csv available in tests/fixtures folder:", "Running causal impact on this dataset uses just a few lines of code:", "Notice that on point 70 up to 77 we add a decreasing summation from 7 (seven) down to 0 (zero). This is to simulate what running a marketing campaign on TV probably would look like: at first, there\u2019s a pick of traffic on sales and it fades away with time (most interventions follow this pattern, that\u2019s why the default model is the local level).", "The package gives us a statistical summary with the results, just run:", "Let\u2019s focus on the bold numbers. First, we have the absolute effect which is an estimation of, on average, how much the impact added to y in comparison to the counter-factual series. In this case, it predicts that the difference between what really happened and the counter-factual is close to 1. In relative terms (normalized by counter-factual mean) it\u2019s an estimated increase of 0.7%. Finally, the statistical hypothesis test for whether the results are valid or not (usually we use the 95% threshold value correspondent to 5% of significance) is 98% which means results are reliable given a statistical point of view.", "Here is the plot that helps us visualize it:", "It\u2019s important to keep in mind: the covariates X cannot be affected by the intervention variable. That is, if in our previous example the response variable is Sales of the company and X is investments on the operations area then the intervention variable cannot affect the operations one; if it does, then the linear regression would also be affected and the counter-factual prediction wouldn\u2019t reproduce what would have been observed had no intervention taken place.", "Without being careful, one can conclude to have observed signal from the impact inference when in reality it\u2019s only noise being evaluated. Here\u2019s an interesting example that better illustrates this. The following code is used to generate random walk datasets:", "It\u2019s possible to sample data from this distribution and eventually find these results:", "These images reinforces why we need to be careful when running causal impact analyzes (or any other statistical study for that matter), using wrong models and assumptions can lead to quite costly conclusions.", "The default structural model that tfcausalimpact uses is a combination of a local level with a linear regression, or mathematically:", "This model is appropriate for impacts that are expected to last a few data points into the future and then fades away (that\u2019s why the definition \u201clocal\u201d level). There\u2019s a default Bayesian prior for the standard deviation \u03c3 of \u03bc whose value is 0.01 which means that \u201ca priori\u201d we have an expectation that the observed time series under investigation is well-behaved and can be well explained by the covariates being used. This is not always the case and for data that is less noisy (more random fluctuations) one can use a prior of 0.1 like so:", "One can also choose other structural models instead; we\u2019ll see more on that soon. Let\u2019s now use some real data to run causal impact inference and see how it unfolds.", "For those into technology and software development probably find Bitcoin quite an exciting framework. Not only does its implementation seem quite sophisticated and complex but also the concept has faced every sort of criticism one can imagine and still prevailed so far.", "Just recently the Bitcoin community received the news that PayPal would be accepting the cryptocurrency on its platform. So let\u2019s use this information and data to evaluate what expected impact this news had on Bitcoin prices. First, let\u2019s query some data:", "Preparing our dataset (data cleaning, removing duplicates, filling empty values, fixing indexes and so on):", "If we run Causal Impact with this input, here\u2019s what we get:", "We clearly see that the news did cause a positive (and considerable) impact on Bitcoin prices with the hypothesis testing being quite confident on results. Still, notice that the 95% interval is somewhat large (goes from 25% up to 60%. One way of improving this is finding more covariates that helps predicts Bitcoin prices).", "One interesting technique one may use to confirm everything is working is running some back-testing analyzes on data. For instance, let\u2019s select a random pre_period and post_period values where we know there was no known source of impact to see what happens:", "Notice that the p-value is 27% which indicates that there was no observable impact on those periods, as expected. This is one indication that the covariates are doing a good job on explaining the response. Still, a good practice is to run several back-tests on several pieces of the data (if there\u2019s enough points for doing so) to see the proportion on which it concludes there\u2019s no impact (if it\u2019s lower than 5% then it\u2019s working as expected).", "For plotting the decomposition of the contributions for each state component used in the structural model, this helper function does the trick:", "For our PayPal example, here\u2019s the result:", "It\u2019s interesting to observe that after March 2020 the linear predictors becomes less and less certain on the forecasts, as expected given the effects of the pandemic.", "Let\u2019s see now what happens if we try to improve upon the default model. Before doing so, we can use statsmodels decomposition to extract some ideas from data, like so:", "The data doesn\u2019t seem to indicate a clear linear trend component (it seems to be better modeled through the random walk of the local level model) and the seasonal component also is not big enough to better explain the data.", "Still, let\u2019s play around and use a customized model to test some suppositions. While this won\u2019t lead to much useful results, it still works to help us to understand about how to build your own structural model. Here\u2019s one way of doing so:", "Notice that the structural components (such as linear level and seasons) keeps being added and sent as input to tfp.sts.Sum(). The linear regression must contain the union of pre and post data as required by TensorFlow Probability.", "Building customized models is certainly a more advanced feature and will only be required when the default model doesn\u2019t do a good job at modeling the observed data. Here are the results for the above customized model:", "Thanks to the seasonal effects the uncertainty on predictions increases considerably which leads to those plots with wide uncertainty ranges at the beginning. Notice from the summary that this new model is less certain about the real impact; it still sees that something happened but its confidence intervals are wider as consequence of the wrong assumptions used when building the customized model.", "Another important approach when trying to improve results is changing the back-end algorithm for finding the posterior of each component. The default algorithm in tfcausalimpact uses Variational Inference methods which are fast but less precise. Another possibility is to use Hamiltonian Monte Carlo algorithm which is considered the State of the Art when it comes to Bayesian adaptation. But the price we pay is that it\u2019s really slow and demands a lot of hardware resources.", "An interesting approach is to use the default variational inference algorithm for the most part but when precision is highly required then after all tests have been performed then a final run is performed on top of the Hamiltonian technique. Still, keep in mind that running on a GPU the method can take in the range of hours to converge so it\u2019s that heavy. For our Bitcoin example, here\u2019s how to select the algorithm:", "As we can see, it\u2019s not a huge difference but the convergence is a bit more precise and certain. Running this on google colab with GPU activated took 20 minutes.", "As a final note, all results from the Bayesian processing happening on the back-end is available for later inspection in the ci object, including the samples for each component of the model. For printing the averages of the posterior for each component, just run:", "observation_noise_scale is the \u03b5 discussed on bsts. The local level is the standard deviation that sets how the random walk fluctuates over time. Despite the prior level being 0.01 it still converged to 0.13. Finally, the linear regression gives us an idea of the linear weights the optimization obtained between the tech companies (as well as gold) to Bitcoin prices.", "Working with TensorFlow Probability and building this framework for causal inference was quite fun and challenging. Feels like new machine learning powers have been acquired along the way.", "Analyzes that involves finding causal relationship between variables and their effects on each other can potentially be solved by using this simulated A/B test framework, such as the TV commercial as proposed by my colleague.", "In fact, in some cases, it may be quite expensive or even prohibitive to run an A/B test. As an example I remember we once had a challenge to optimize price values for each product on the catalog and setting an A/B test showed to be quite risk (mistakes on setting prices can have disastrous consequences) and so expensive that the only solution for assessing whether the new algorithms were working or not was to evaluate the causal impact that the new pricing strategy caused over time.", "Hopefully the new library will be helpful for those working in Python as it is for the R community. If you have any issues while using it please let us know by opening an issue on its official repository.", "Well, that\u2019s it for now. Time for some resting and preparing for a new adventure \ud83d\ude05!", "And, as always, see you next mission!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Mainly interested in data science and software development topics."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc837ea18b126&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c837ea18b126--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c837ea18b126--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://willian-fuks.medium.com/?source=post_page-----c837ea18b126--------------------------------", "anchor_text": ""}, {"url": "https://willian-fuks.medium.com/?source=post_page-----c837ea18b126--------------------------------", "anchor_text": "Will Fuks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe9c35a095d0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&user=Will+Fuks&userId=e9c35a095d0d&source=post_page-e9c35a095d0d----c837ea18b126---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc837ea18b126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc837ea18b126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/WillianFuks/tfcausalimpact", "anchor_text": "tfcausalimpact"}, {"url": "https://gist.github.com/WillianFuks/bf1252db75e03029a1b67e3dfd67e07a", "anchor_text": "this dataset"}, {"url": "https://gist.github.com/WillianFuks/2b6f8093ac257f2ee53e038ea6db7855", "anchor_text": "dataset"}, {"url": "https://www.jmlr.org/papers/volume19/18-009/18-009.pdf", "anchor_text": "bsts"}, {"url": "https://towardsdatascience.com/demystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a", "anchor_text": "post"}, {"url": "https://github.com/tensorflow/probability/blob/v0.11.1/tensorflow_probability/python/sts/autoregressive.py#L258", "anchor_text": "AutoRegressive"}, {"url": "https://github.com/tensorflow/probability/blob/v0.11.1/tensorflow_probability/python/sts/dynamic_regression.py#L230", "anchor_text": "Dynamic Regression"}, {"url": "https://github.com/tensorflow/probability/blob/v0.11.1/tensorflow_probability/python/sts/local_level.py#L254", "anchor_text": "LocalLevel"}, {"url": "https://github.com/WillianFuks/tfcausalimpact", "anchor_text": "tfcausalimpact"}, {"url": "https://github.com/tensorflow/probability/blob/v0.11.1/tensorflow_probability/python/sts/seasonal.py#L688", "anchor_text": "Seasonal"}, {"url": "https://github.com/tensorflow/probability/blob/v0.11.1/tensorflow_probability/python/sts/local_linear_trend.py#L222", "anchor_text": "LocalLinearTrend"}, {"url": "https://github.com/tensorflow/probability/blob/v0.11.1/tensorflow_probability/python/sts/semilocal_linear_trend.py#L294", "anchor_text": "SemiLocalLinearTrend"}, {"url": "https://github.com/tensorflow/probability/blob/v0.11.1/tensorflow_probability/python/sts/smooth_seasonal.py#L321", "anchor_text": "SmoothSeasonal"}, {"url": "https://github.com/google/CausalImpact", "anchor_text": "library"}, {"url": "https://github.com/WillianFuks/tfcausalimpact", "anchor_text": "tfcausalimpact"}, {"url": "https://github.com/WillianFuks/tfcausalimpact/blob/master/tests/fixtures/arma_data.csv", "anchor_text": "arma_data.csv"}, {"url": "https://github.com/statsmodels/statsmodels", "anchor_text": "statsmodels"}, {"url": "https://en.wikipedia.org/wiki/Variational_Bayesian_methods", "anchor_text": "Variational Inference"}, {"url": "https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo", "anchor_text": "Hamiltonian Monte Carlo"}, {"url": "https://github.com/WillianFuks/tfcausalimpact/issues", "anchor_text": "issue"}, {"url": "https://open.spotify.com/playlist/6DDVtTmNRo32PUGy3vsRCC", "anchor_text": "mission"}, {"url": "https://github.com/google/CausalImpact", "anchor_text": "https://github.com/google/CausalImpact"}, {"url": "https://www.jmlr.org/papers/volume19/18-009/18-009.pdf", "anchor_text": "https://www.jmlr.org/papers/volume19/18-009/18-009.pdf"}, {"url": "https://www.tensorflow.org/probability", "anchor_text": "https://www.tensorflow.org/probability"}, {"url": "https://towardsdatascience.com/demystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a", "anchor_text": "https://towardsdatascience.com/demystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a"}, {"url": "http://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html", "anchor_text": "http://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html"}, {"url": "https://towardsdatascience.com/structural-time-series-forecasting-with-tensorflow-probability-iron-ore-mine-production-897d2334c72b", "anchor_text": "https://towardsdatascience.com/structural-time-series-forecasting-with-tensorflow-probability-iron-ore-mine-production-897d2334c72b"}, {"url": "https://blog.tensorflow.org/2019/03/structural-time-series-modeling-in.html", "anchor_text": "https://blog.tensorflow.org/2019/03/structural-time-series-modeling-in.html"}, {"url": "http://krasserm.github.io/2019/03/14/bayesian-neural-networks", "anchor_text": "http://krasserm.github.io/2019/03/14/bayesian-neural-networks"}, {"url": "https://towardsdatascience.com/synthetic-instrumental-variables-968b12f68772", "anchor_text": "https://towardsdatascience.com/synthetic-instrumental-variables-968b12f68772"}, {"url": "https://towardsdatascience.com/youre-plotting-the-wrong-things-3914402a3653", "anchor_text": "https://towardsdatascience.com/youre-plotting-the-wrong-things-3914402a3653"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c837ea18b126---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----c837ea18b126---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/tag/causal-inference?source=post_page-----c837ea18b126---------------causal_inference-----------------", "anchor_text": "Causal Inference"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----c837ea18b126---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/python?source=post_page-----c837ea18b126---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc837ea18b126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&user=Will+Fuks&userId=e9c35a095d0d&source=-----c837ea18b126---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc837ea18b126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&user=Will+Fuks&userId=e9c35a095d0d&source=-----c837ea18b126---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc837ea18b126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c837ea18b126--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc837ea18b126&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c837ea18b126---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c837ea18b126--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c837ea18b126--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c837ea18b126--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c837ea18b126--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c837ea18b126--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c837ea18b126--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c837ea18b126--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c837ea18b126--------------------------------", "anchor_text": ""}, {"url": "https://willian-fuks.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://willian-fuks.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Will Fuks"}, {"url": "https://willian-fuks.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "229 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe9c35a095d0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&user=Will+Fuks&userId=e9c35a095d0d&source=post_page-e9c35a095d0d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa18136e4e9cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-causal-impact-on-top-of-tensorflow-probability-c837ea18b126&newsletterV3=e9c35a095d0d&newsletterV3Id=a18136e4e9cd&user=Will+Fuks&userId=e9c35a095d0d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}