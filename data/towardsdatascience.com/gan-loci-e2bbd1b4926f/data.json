{"url": "https://towardsdatascience.com/gan-loci-e2bbd1b4926f", "time": 1682997014.1759381, "path": "towardsdatascience.com/gan-loci-e2bbd1b4926f/", "webpage": {"metadata": {"title": "GAN Loci. Can neural nets reveal the tacit\u2026 | by Kyle Steinfeld | Towards Data Science", "h1": "GAN Loci", "description": "This project applies techniques in machine learning to produce synthetic images that seek to capture the predominant visual properties of urban places."}, "outgoing_paragraph_urls": [{"url": "https://books.google.com/books/about/Genius_loci.html?id=yioU0NqIJ9sC", "anchor_text": "Genius Loci", "paragraph_index": 0}, {"url": "https://github.com/NVlabs/stylegan", "anchor_text": "StyleGAN", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/1611.07004", "anchor_text": "Pix2Pix", "paragraph_index": 1}, {"url": "https://medium.com/@nocomputer/creating-point-clouds-with-google-street-view-185faad9d4ee", "anchor_text": "two-dimensional panoramas provided by this service also hold some rudimentary three-dimensional data", "paragraph_index": 9}, {"url": "http://paulbourke.net/miscellaneous/cubemaps/", "anchor_text": "Bourke, 2006", "paragraph_index": 12}, {"url": "https://phillipi.github.io/pix2pix/", "anchor_text": "Pix2Pix", "paragraph_index": 15}, {"url": "https://github.com/NVIDIA/pix2pixHD", "anchor_text": "a \u201chigh-definition\u201d version of this architecture implemented in Pytorch", "paragraph_index": 16}, {"url": "https://github.com/NVIDIA/pix2pixHD/issues/46", "anchor_text": "suggestions offered by the community of Pix2Pix users", "paragraph_index": 16}, {"url": "https://github.com/NVlabs/stylegan", "anchor_text": "StyleGAN", "paragraph_index": 18}, {"url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf", "anchor_text": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf", "paragraph_index": 31}, {"url": "http://dl.acm.org/citation.cfm?id=2980539.2980648", "anchor_text": "http://dl.acm.org/citation.cfm?id=2980539.2980648", "paragraph_index": 32}, {"url": "https://openreview.net/forum?id=rJWF0Fywf", "anchor_text": "https://openreview.net/forum?id=rJWF0Fywf", "paragraph_index": 35}, {"url": "http://www.ksteinfe.com", "anchor_text": "www.ksteinfe.com", "paragraph_index": 38}], "all_paragraphs": ["This project applies generative adversarial networks (or GANs) to produce synthetic images that capture the predominant visual properties of urban places. Imaging cities in this way represents the first computational attempt to documenting the Genius Loci of a city: those forms, spaces, and qualities of light that exemplify a particular location and that set it apart from similar places.", "Presented here are methods for the collection of urban image data, for the necessary processing and formatting of this data, and for the training of two known computational statistical models (StyleGAN and Pix2Pix) that identify visual patterns distinct to a given site and that reproduce these patterns to generate new images. These methods have been applied to image nine distinct urban contexts across six cities in the US and Europe, the results of which will be presented in our next post.", "When a town pleases us because of its distinct character, it is usually because a majority of its buildings are related to the earth and the sky in the same way; they seem to express a common form of life, a common way of being on the earth. Thus they constitute a genius loci which allows for human identification.- Christian Norberg-Schulz, Genius Loci: Towards a Phenomenology of Architecture, p 63", "While for many architects and urban designers design intent is a necessarily tacit concept, most CAD tools are made to support only the explicit articulation of the intention of their author. In contrast, this project represents a small step toward a new approach to CAD tools based on machine learning techniques that are made to better support tacit or difficult-to-articulate design intent. To clearly demonstrate the needs of design intent such as this, we consider here a scenario that offers an especially difficult to explicitly articulate quality of the built environment: the phenomenon of \u201cplace\u201d.", "In his seminal work that defines a phenomenological approach, \u201cGenius Loci: Towards a Phenomenology of Architecture\u201d, Christian Norberg-Schulz argues that the design of cities and buildings must center on the construction of \u201cplace\u201d, which he defines as a \u201cspace with a unique character\u201d (Norberg-Schulz 94). But how is this \u201cunique character\u201d defined, and how can it be captured using digital tools in manner that affords the advantages of a computational medium? In anticipation of a future tool that better supports the development of tacit design intent, we seek to leverage methods in machine learning to attempt to capture \u201cplace\u201d, as described by Norberg-Schulz.", "It is the ambition of this project to use a GAN as a tool for tacit design, and to apply the capacity of this technology for capturing the implicit yet salient visual properties of a set of images. We speculate that this capacity will prove useful in uncovering and encoding a phenomenological understanding of place. Presented in overview here are the steps required to train a generative adversarial network (GAN) to produce images that capture the predominant visual properties of an urban context. The work proceeds in three stages: data preparation, model training, and latent space exploration.", "In the data preparation stage, we first collect, clean, and curate a large number of images related to a selection of urban contexts that are significantly different sorts of places, and compile these into distinct sets. Then, each set of these images is processed to serve as training data for one of two ML models.", "To this end, a Python library has been developed that supports the collecting, curating, and processing panoramic images using Google\u2019s StreetView API. This section details this process, which includes: tasks related to the identification of a desired geographic location, the collection of a large and diverse set of images from this location, the curation of this set to define a relevant sub-set of valid images, and finally, the processing of these images such that they are appropriately formatted for training.", "The collection of data begins with the identification of a geographic location of interest. Since the images at which panoramas are taken are likely not coincident with the given geo-locations of interest, a number of failure scenarios must be accommodated. For example: not all locations of interest are related to a panorama, and not all panoramas depict the external urban environment (there are panoramas of interiors as well). For each of the nine urban contexts listed below, approximately 500 panoramas are sampled.", "Beyond the basic validation mentioned above, due to the structure of the data returned, even given a successful call to the API, a number of auxiliary processing steps are required. Most notable among these auxiliary processing steps is the collection of depth information related to each StreetView panorama. Although it is not made clear from the Google StreetView interface, many two-dimensional panoramas provided by this service also hold some rudimentary three-dimensional data that describes objects in the urban scene (typically building forms).", "In summary, the collection of data begins with the defining of a single geographic point of interest, and results in the compilation of several hundred samples that may be further processed for training.", "With a set of images related to a given urban place collected and curated, the task of the data processing step is to prepare this set of images for their role in training a GAN model. In summary, this training data is best described as pairs of related square-cropped raster images: one RGB image that represents a crop of a larger panorama image scene, and another greyscale image that represents the \u201cdepthmap\u201d of this scene, with the value of each pixel representing the minimum distance from the camera to any occluding objects.", "The production of the sceneographic images is largely straightforward, with just one process worthy of mention: The equalrectangular projection of the panoramic images must be transformed to arrive the cubic environment map that better approximates what we expect for the synthetic images we aim to produce. This is accomplished following previous work describing the relevant conversion (Bourke, 2006). It is noteworthy that the same panoramic image may be arbitrarily rotated along the z-axis (a transformation equivalent to a horizontal rotation of the cube) to produce slight variations of the same scene that may still be seamlessly tiled together. Expanding the breadth of training sets through slight transformations in this manner, a practice known as \u201cdata augmentation\u201d, is a common practice in ML.", "In summary, the data preparation step for any given urban place begins with a curated collection of panoramic equalrectangular images and related information (including a description of occluding planes), and results in two sets of cubemap projection images: one set of RGB images that describe an urban scene, and one set of greyscale images that describe the effective depth of objects in that scene.", "In the model training stage, we use the collected image sets to train GAN models capable of generating new images related to each selected urban context. To this end, two distinct GAN architectures are employed: StyleGAN and Pix2Pix, the particular implementations of which are discussed below. Once trained, each of these models prove valuable in their own way, as each offers a distinct interface for the production of synthetic urban images.", "Pix2Pix (Isola et al., 2016) is an architecture for a particular kind of GAN: a conditional adversarial network that learns a mapping from a given input image to a desired output image. From the perspective of a user of a trained Pix2Pix model, we offer an input image that conforms to some mapping convention (such as a color-coded diagram of a facade, or an edge drawing of a cat) and receive in return an image that results from the transformation of this input into some desired output (such as a photographic representation of a facade, or of a cat).", "The particulars that guide the training of a Pix2Pix model strongly depend upon the specifics of the implementation employed. This project relies upon a \u201chigh-definition\u201d version of this architecture implemented in Pytorch (Wang, 2019). Some modifications of this implementation were required: in particular, to correct problems with unwanted artifacts forming in cases of low-contrast source images (as seen in the figure below). Following suggestions offered by the community of Pix2Pix users, zero paddings were replaced with reflection paddings, and the learning rate was temporarily adjusted to 0.0008.", "Once trained, each model operates as implied by the nature of a conditional GAN and by the structure of the training data: given a greyscale depthmap image that describes a desired three-dimensional urban scene, a synthetic RGB sceneographic image is returned. Since these models are trained on subsets of data segregated by site, each model produces synthetic images specific to just one urban place: the Rotterdam model produces images that \u201cfeel\u201d like Rotterdam, while the San Francisco model generates ones that appear more like San Francisco. This feature allows for direct comparisons to be drawn.", "In contrast with a traditional GAN architecture, StyleGAN (Karras et al., 2018) draws from \u201cstyle transfer\u201d techniques to offer an alternative design for the generator portion of the GAN that separates coarse image features (such as head pose when trained on human faces) from fine or textural features (such as hair and freckles). Here, in comparison to the Pix2Pix model, the user experience is quite different: rather than operating by mapping an input image to a desired output, users select a pair of images from within the latent space of a trained model, and hybridize them. Rather than a simple interpolation between points in latent space, however, these hybrids correspond to the coarse and fine features of the given pair.", "As above, the particulars that guide the training of a StyleGAN model strongly depend upon the specifics of the implementation. This project relies on the official TensorFlow implementation of StyleGAN , which was employed without modification to train a single model on a combination of RGB sceneographic data drawn from all nine urban places. Once trained, the model may be queried either by sampling locations in latent space, or by providing coarse-fine pairs of locations in latent space to more precisely control different aspects of the synthetic image.", "Building upon the former technique of taking samples in latent space, linear sequences of samples may be combined to produce animations such as the ones discussed below.", "In the image generation stage, we develop methods for interfacing with the trained models in useful ways. This task is non-trivial, since each GAN model, once trained, is capable of producing a vast and overwhelming volume of synthetic images, which is described in terms of a high-dimensional latent space. The StyleGAN model offers a unique form of guiding the generation of images as combinations of features drawn from other images selected from latent space. The Pix2Pix model offers quite a different interface, with new synthetic images generated as transformations of arbitrary given source images: in our case, these are depth-maps of urban spaces. We present here a brief overview of these methods, and leave a more complete unpacking and visual analysis of the resulting images to a future post.", "Here, greyscale depthmap images are produced by sampling a scene described in a 3d CAD model. These depthmaps of constructed scenes are then used as the source image by which the Pix2Pix models for each urban place produces a synthetic photographic scene. By providing precisely the same input to models trained on different urban places, direct comparisons between the salient features picked up by the transformation models may be made.", "For example, while each of the synthetic images below were produced by sampling the same depthmap, we can clearly see those imagistic properties that characterize each of the urban places sampled. A large massing that appears in the depthmap is interpreted by the Rotterdam model as a large brick housing block, as is typical in the Dutch city, while the Pickwick Park model renders this massing in a manner typical of the Northern Florida flora, suggesting the mass of a mossy Live Oak. A long and receding urban wall is broken up by the Alamo Square model into a series of small scale forms, an interpretation that expresses the massing of a line of Edwardian townhouses that dominate this San Francisco neighborhood; this same urban form is understood as something resembling a red-brick industrial warehouse building by the model trained on images from the Bushwick area of Brooklyn.", "The other two image generation methods developed here rely on the StyleGAN models.", "Like the method discussed above, the first of these two offers opportunities for comparisons to be drawn between the urban places sampled. Using the StyleGAN interface as it was intended by its authors, it is possible to separately assert control over the fine and coarse aspects of generated images. The interface that results may be seen as the design of urban scenes \u201cby example\u201d: the user need only offer examples of images that contain desired features of a place, without explicitly stating what these are, where they came from, or how to construct them. In the context of this study, as above, this allows for comparisons between urban places to be conducted. For example, the nearby figure demonstrates how coarse features and fine features may be combined to form new scenes that hybridize aspects of existing scenes.", "Finally, a method for generating animations by sampling linear sequences of the latent space of images implied by the StyleGAN model is developed. While not directly supportive of a controlled comparative study of urban places, these animations do offer insight into the structure of the latent space of the StyleGAN model, including which features and scenes are similarly parameterized, and which are far from one another.", "As described above, a GAN instrumentalizes the competition between two related neural networks. Since the effective result of this competition is the encoding of the tacit properties held in common by the given set of images, this project proposes that an interrogation of the synthetic images generated by the GAN will reveal certain properties useful in uncovering the nature of urban places. Relying on Norberg-Schulz\u2019s characterization of a \u201cplace\u201d, which is understood to mean a \u201cspace with a unique character\u201d, and to include those forms, textures, colors, and qualities of light that exemplify a particular urban location, we can see that the immediate aim has been met, as the initial results documented above exhibit imagistic features unique to each of the sites studied. Much work remains, however, to realize the larger aim of this project to develop tools that support tacit intent in architectural design. Future work in this area includes the extension of the \u201cdesign by example\u201d paradigm from images of urban places, as demonstrated here, to more directly architectural representations, such as three-dimensional forms and spaces.", "Bechtel, William, and Adele Abrahamsen. Connectionism and the Mind: Parallel Processing, Dynamics, and Evolution in Networks. Wiley-Blackwell, 2002.", "Cheng, Chili, and June-Hao Hou. \u201cBiomimetic Robotic Construction Process: An Approach for Adapting Mass Irregular-Shaped Natural Materials.\u201d In Proceedings of the 34th ECAADe Conference. Oulu, Finland, 2016.", "Chung, Chia Chun, and Taysheng Jeng. \u201cInformation Extraction Methodology by Web Scraping for Smart Cities: Using Machine Learning to Train Air Quality Monitor for Smart Cities.\u201d In CAADRIA 2018\u201323rd International Conference on Computer-Aided Architectural Design Research in Asia, edited by Suleiman Alhadidi, Tomohiro Fukuda, Weixin Huang, Patrick Janssen, and Kristof Crolla, 2:515\u2013524. The Association for Computer-Aided Architectural Design Research in Asia (CAADRIA), 2018.", "Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. \u201cGenerative Adversarial Nets.\u201d In Advances in Neural Information Processing Systems 27, edited by Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, 2672\u20132680. Curran Associates, Inc., 2014. http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.", "Ng, Andrew Y., and Michael I. Jordan. \u201cOn Discriminative vs. Generative Classifiers: A Comparison of Logistic Regression and Naive Bayes.\u201d In Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic, 841\u2013848. NIPS\u201901. Cambridge, MA, USA: MIT Press, 2001. http://dl.acm.org/citation.cfm?id=2980539.2980648.", "Norberg-Schulz, Christian. Genius Loci: Towards a Phenomenology of Architecture. Academy Editions, 1980.", "Peng, Wenzhe, Fan Zhang, and Takehiko Nagakura. \u201cMachines\u2019 Perception of Space.\u201d In Proceedings of the 37th Annual Conference of the Association for Computer Aided Design in Architecture (ACADIA). Cambridge, MA: Association for Computer Aided Design in Architecture, 2017.", "Sculley, D., Jasper Snoek, Alex Wiltschko, and Ali Rahimi. \u201cWinner\u2019s Curse? On Pace, Progress, and Empirical Rigor.\u201d Vancouver, CA, 2018. https://openreview.net/forum?id=rJWF0Fywf.", "Steinfeld, Kyle. \u201cDreams May Come.\u201d In Proceedings of the 37th Annual Conference of the Association for Computer Aided Design in Architecture (ACADIA). Cambridge, MA: Association for Computer Aided Design in Architecture, 2017.", "Wang, Jason, and Luis Perez. \u201cThe Effectiveness of Data Augmentation in Image Classification Using Deep Learning.\u201d Convolutional Neural Networks Vis. Recognit, 2017.", "Associate Professor of Architecture at the University of California, Berkeley. www.ksteinfe.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe2bbd1b4926f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@ksteinfe?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ksteinfe?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Kyle Steinfeld"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa44d273e81e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=post_page-a44d273e81e----e2bbd1b4926f---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe2bbd1b4926f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=-----e2bbd1b4926f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2bbd1b4926f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&source=-----e2bbd1b4926f---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://books.google.com/books/about/Genius_loci.html?id=yioU0NqIJ9sC", "anchor_text": "Genius Loci"}, {"url": "https://github.com/NVlabs/stylegan", "anchor_text": "StyleGAN"}, {"url": "https://arxiv.org/abs/1611.07004", "anchor_text": "Pix2Pix"}, {"url": "https://www.google.com/maps/place/51%C2%B055'38.6%22N+4%C2%B027'58.3%22E/@51.9274137,4.4662052,3a,75y,90t/data=!3m4!1e1!3m2!1s*211m2*211y5171316202178896221*212y17851083259198634954*215m2*211x0*212x0!6s%2F%2Fgeo3.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEgldYRjkrzTERxHK-3Qopcm79yoKDQAAAAAVAAAAABoFCHgQ6AI%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d51.92738!4d4.466203", "anchor_text": "Blijdorp, Rotterdam, NL"}, {"url": "https://www.google.com/maps/place/30%C2%B012'25.6%22N+81%C2%B037'40.5%22W/@30.2068691,-81.6282694,3a,75y,59.09h,84.69t/data=!3m4!1e1!3m2!1s*211m2*211y9864511613807048521*212y16051689557954240538*215m2*211x0*212x0!6s%2F%2Fgeo3.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEglJN69fDMnliBEaoLWCmw7D3ioKDQAAAAAVAAAAABoECFYQVg%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d30.207098!4d-81.627929", "anchor_text": "Pickwick Park, Jacksonville, FL"}, {"url": "https://www.google.com/maps/place/40%C2%B042'56.2%22N+73%C2%B056'54.5%22W/@40.7155441,-73.9487997,3a,75y,90t/data=!3m4!1e1!3m2!1s*211m2*211y9926594771599410009*212y4942418715199128142*215m2*211x0*212x0!6s%2F%2Fgeo1.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEglZw272WVnCiRFOwq-qov-WRCoKDQAAAAAVAAAAABoECFYQVg%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d40.715607!4d-73.948484", "anchor_text": "Williamsburg, Brooklyn, NY"}, {"url": "https://www.google.com/maps/place/29%C2%B038'57.4%22N+82%C2%B020'08.2%22W/@29.6492916,-82.3358402,3a,75y,90t/data=!3m4!1e1!3m2!1s*211m2*211y9865314776326021231*212y5955640966679219282*215m2*211x0*212x0!6s%2F%2Fgeo3.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEglvIFM4haPoiBFSzK2k56-mUioKDQAAAAAVAAAAABoECFYQVg%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d29.649282!4d-82.335609", "anchor_text": "East Campus, Gainesville, FL"}, {"url": "https://www.google.com/maps/place/37%C2%B046'31.4%22N+122%C2%B025'58.1%22W/@37.7752163,-122.4327636,3a,75y,90t/data=!3m4!1e1!3m2!1s*211m2*211y9260949654923171901*212y12850982228471970350*215m2*211x0*212x0!6s%2F%2Fgeo3.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEgk92HgApYCFgBEu-u3WP9xXsioKDQAAAAAVAAAAABoECFYQVg%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d37.775383!4d-122.432817", "anchor_text": "Alamo Square, San Francisco, CA"}, {"url": "https://www.google.com/maps/place/37%C2%B048'38.1%22N+122%C2%B015'15.4%22W/@37.8106013,-122.254488,3a,75y,179.66h,90t/data=!3m7!1e1!3m5!1siAynKUQqMsdqj8SyRUHTsA!2e0!6s%2F%2Fgeo3.ggpht.com%2Fcbk%3Fpanoid%3DiAynKUQqMsdqj8SyRUHTsA%26output%3Dthumbnail%26cb_client%3Dsearch.TACTILE.gps%26thumb%3D2%26w%3D86%26h%3D86%26yaw%3D179.65723%26pitch%3D0%26thumbfov%3D100!7i16384!8i8192!4m5!3m4!1s0x0:0x0!8m2!3d37.810573!4d-122.254269", "anchor_text": "Adams Point, Oakland, CA"}, {"url": "https://www.google.com/maps/place/42%C2%B021'54.8%22N+71%C2%B005'46.0%22W/@42.3650867,-71.0962033,3a,75y,90t/data=!3m4!1e1!3m2!1s*211m2*211y9935909090226922999*212y14946996123325815429*215m2*211x0*212x0!6s%2F%2Fgeo0.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEgn35YzDrHDjiRGF2vkVyGVuzyoKDQAAAAAVAAAAABoECFYQVg%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d42.365222!4d-71.096106", "anchor_text": "Central Square, Cambridge, MA"}, {"url": "https://www.google.com/maps/place/37%C2%B051'42.6%22N+122%C2%B015'04.3%22W/@37.8618353,-122.2512115,3a,75y,90t/data=!3m4!1e1!3m2!1s*211m2*211y9260944767957832181*212y15251076096403678744*215m2*211x0*212x0!6s%2F%2Fgeo2.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEgn1kaMqM3yFgBEYppfw57Sm0yoKDQAAAAAVAAAAABoECFYQVg%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d37.861839!4d-122.251198", "anchor_text": "Clark Kerr Neighborhood, Berkeley, CA"}, {"url": "https://www.google.com/maps/place/40%C2%B042'19.5%22N+73%C2%B055'15.6%22W/@40.7054438,-73.9210136,3a,75y,90t/data=!3m4!1e1!3m2!1s*211m2*211y9926597811016014575*212y9550161167841897871*215m2*211x0*212x0!6s%2F%2Fgeo2.ggpht.com%2Fmaps%2Fphotothumb%2Ffd%2Fv1%3Fbpb%3DChAKDnNlYXJjaC5UQUNUSUxFEiAKEgnvmsehHVzCiRGPLfK0-_yIhCoKDQAAAAAVAAAAABoECFYQVg%26gl%3DUS!4m5!3m4!1s0x0:0x0!8m2!3d40.705412!4d-73.920998", "anchor_text": "Bushwick, Brooklyn, NY"}, {"url": "https://medium.com/@nocomputer/creating-point-clouds-with-google-street-view-185faad9d4ee", "anchor_text": "two-dimensional panoramas provided by this service also hold some rudimentary three-dimensional data"}, {"url": "http://paulbourke.net/miscellaneous/cubemaps/", "anchor_text": "Bourke, 2006"}, {"url": "https://phillipi.github.io/pix2pix/", "anchor_text": "Pix2Pix"}, {"url": "https://github.com/NVIDIA/pix2pixHD", "anchor_text": "a \u201chigh-definition\u201d version of this architecture implemented in Pytorch"}, {"url": "https://github.com/NVIDIA/pix2pixHD/issues/46", "anchor_text": "suggestions offered by the community of Pix2Pix users"}, {"url": "https://github.com/NVlabs/stylegan", "anchor_text": "StyleGAN"}, {"url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf", "anchor_text": "http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf"}, {"url": "http://arxiv.org/abs/1611.07004", "anchor_text": "http://arxiv.org/abs/1611.07004"}, {"url": "https://github.com/NVlabs/stylegan", "anchor_text": "https://github.com/NVlabs/stylegan"}, {"url": "http://arxiv.org/abs/1812.04948", "anchor_text": "http://arxiv.org/abs/1812.04948"}, {"url": "https://doi.org/10.1002/9781118653074.ch10", "anchor_text": "https://doi.org/10.1002/9781118653074.ch10"}, {"url": "https://doi.org/10.1109/CVPR.2017.19", "anchor_text": "https://doi.org/10.1109/CVPR.2017.19"}, {"url": "http://dl.acm.org/citation.cfm?id=2980539.2980648", "anchor_text": "http://dl.acm.org/citation.cfm?id=2980539.2980648"}, {"url": "https://openreview.net/forum?id=rJWF0Fywf", "anchor_text": "https://openreview.net/forum?id=rJWF0Fywf"}, {"url": "https://github.com/PaulWagener/Streetview-Explorer", "anchor_text": "https://github.com/PaulWagener/Streetview-Explorer"}, {"url": "https://github.com/NVIDIA/pix2pixHD", "anchor_text": "https://github.com/NVIDIA/pix2pixHD"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e2bbd1b4926f---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/pix2pix?source=post_page-----e2bbd1b4926f---------------pix2pix-----------------", "anchor_text": "Pix2pix"}, {"url": "https://medium.com/tag/stylegan?source=post_page-----e2bbd1b4926f---------------stylegan-----------------", "anchor_text": "Stylegan"}, {"url": "https://medium.com/tag/creativeai?source=post_page-----e2bbd1b4926f---------------creativeai-----------------", "anchor_text": "Creativeai"}, {"url": "https://medium.com/tag/architecture?source=post_page-----e2bbd1b4926f---------------architecture-----------------", "anchor_text": "Architecture"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe2bbd1b4926f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=-----e2bbd1b4926f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe2bbd1b4926f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=-----e2bbd1b4926f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2bbd1b4926f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@ksteinfe?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa44d273e81e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=post_page-a44d273e81e----e2bbd1b4926f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fa44d273e81e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=-----e2bbd1b4926f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@ksteinfe?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Written by Kyle Steinfeld"}, {"url": "https://medium.com/@ksteinfe/followers?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "55 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "http://www.ksteinfe.com", "anchor_text": "www.ksteinfe.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa44d273e81e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=post_page-a44d273e81e----e2bbd1b4926f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fa44d273e81e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-loci-e2bbd1b4926f&user=Kyle+Steinfeld&userId=a44d273e81e&source=-----e2bbd1b4926f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e2bbd1b4926f----0---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----e2bbd1b4926f----0---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----e2bbd1b4926f----0---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e2bbd1b4926f----0---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e2bbd1b4926f----0---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e2bbd1b4926f----0---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----0-----------------clap_footer----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----e2bbd1b4926f----0---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----e2bbd1b4926f----0-----------------bookmark_preview----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e2bbd1b4926f----1---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----e2bbd1b4926f----1---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----e2bbd1b4926f----1---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e2bbd1b4926f----1---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e2bbd1b4926f----1---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e2bbd1b4926f----1---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----e2bbd1b4926f----1---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----e2bbd1b4926f----1-----------------bookmark_preview----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----e2bbd1b4926f----2---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----e2bbd1b4926f----2---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----e2bbd1b4926f----2---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e2bbd1b4926f----2---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----e2bbd1b4926f----2---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----e2bbd1b4926f----2---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "15 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----e2bbd1b4926f----2---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----e2bbd1b4926f----2-----------------bookmark_preview----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----e2bbd1b4926f----3---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=author_recirc-----e2bbd1b4926f----3---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=author_recirc-----e2bbd1b4926f----3---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Nikos Kafritsas"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----e2bbd1b4926f----3---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----e2bbd1b4926f----3---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "Time-Series Forecasting: Deep Learning vs Statistics \u2014 Who Wins?A comprehensive guide on the ultimate dilemma"}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----e2bbd1b4926f----3---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": "\u00b714 min read\u00b7Apr 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc568389d02df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df&user=Nikos+Kafritsas&userId=bec849d9e1d2&source=-----c568389d02df----3-----------------clap_footer----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----e2bbd1b4926f----3---------------------eda06ba1_1a8f_4759_8c31_439ee553a4b7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc568389d02df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df&source=-----e2bbd1b4926f----3-----------------bookmark_preview----eda06ba1_1a8f_4759_8c31_439ee553a4b7-------", "anchor_text": ""}, {"url": "https://medium.com/@ksteinfe?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "See all from Kyle Steinfeld"}, {"url": "https://towardsdatascience.com/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----e2bbd1b4926f----0-----------------bookmark_preview----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://aleid-tw.medium.com/?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Aleid ter Weel"}, {"url": "https://medium.com/better-advice?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Better Advice"}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "10 Things To Do In The Evening Instead Of Watching NetflixDevice-free habits to increase your productivity and happiness."}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "\u00b75 min read\u00b7Feb 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-advice%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&user=Aleid+ter+Weel&userId=6ffe087f07e5&source=-----4e270e9dd6b9----1-----------------clap_footer----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/better-advice/10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "204"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e270e9dd6b9&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fbetter-advice%2F10-things-to-do-in-the-evening-instead-of-watching-netflix-4e270e9dd6b9&source=-----e2bbd1b4926f----1-----------------bookmark_preview----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/fashion-police/a-sense-of-things-8ad7a8a6198b?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/@kristinehornshoejharper?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/@kristinehornshoejharper?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Kristine Harper"}, {"url": "https://medium.com/fashion-police?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Fashion Police"}, {"url": "https://medium.com/fashion-police/a-sense-of-things-8ad7a8a6198b?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "A sense of thingsThe Japanese aesthetic philosophy: Mono no aware"}, {"url": "https://medium.com/fashion-police/a-sense-of-things-8ad7a8a6198b?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "\u00b74 min read\u00b75 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ffashion-police%2F8ad7a8a6198b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ffashion-police%2Fa-sense-of-things-8ad7a8a6198b&user=Kristine+Harper&userId=e9e65bb097d8&source=-----8ad7a8a6198b----0-----------------clap_footer----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/fashion-police/a-sense-of-things-8ad7a8a6198b?source=read_next_recirc-----e2bbd1b4926f----0---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ad7a8a6198b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ffashion-police%2Fa-sense-of-things-8ad7a8a6198b&source=-----e2bbd1b4926f----0-----------------bookmark_preview----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----1-----------------clap_footer----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----e2bbd1b4926f----1---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----e2bbd1b4926f----1-----------------bookmark_preview----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----e2bbd1b4926f----2---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----e2bbd1b4926f----2---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----e2bbd1b4926f----2---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Youssef Hosni"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----e2bbd1b4926f----2---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----e2bbd1b4926f----2---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Getting Started With Stable DiffusionStable Diffusion is a text-to-image latent diffusion model created by researchers and engineers from CompVis, Stability AI, and LAION. It\u2019s\u2026"}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----e2bbd1b4926f----2---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "\u00b712 min read\u00b7Nov 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Ff343639e4931&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fgetting-started-with-stable-diffusion-f343639e4931&user=Youssef+Hosni&userId=859af34925b7&source=-----f343639e4931----2-----------------clap_footer----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/getting-started-with-stable-diffusion-f343639e4931?source=read_next_recirc-----e2bbd1b4926f----2---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff343639e4931&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fgetting-started-with-stable-diffusion-f343639e4931&source=-----e2bbd1b4926f----2-----------------bookmark_preview----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-in-your-pocket/generative-modeling-using-pixelcnn-with-codes-explained-387c95405651?source=read_next_recirc-----e2bbd1b4926f----3---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/@mehulgupta_7991?source=read_next_recirc-----e2bbd1b4926f----3---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/@mehulgupta_7991?source=read_next_recirc-----e2bbd1b4926f----3---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Mehul Gupta"}, {"url": "https://medium.com/data-science-in-your-pocket?source=read_next_recirc-----e2bbd1b4926f----3---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Data Science in your pocket"}, {"url": "https://medium.com/data-science-in-your-pocket/generative-modeling-using-pixelcnn-with-codes-explained-387c95405651?source=read_next_recirc-----e2bbd1b4926f----3---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "Generative modeling using PixelCNN with codes explainedAutoregressive models for generating images"}, {"url": "https://medium.com/data-science-in-your-pocket/generative-modeling-using-pixelcnn-with-codes-explained-387c95405651?source=read_next_recirc-----e2bbd1b4926f----3---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": "7 min read\u00b7Jan 16"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-in-your-pocket%2F387c95405651&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fgenerative-modeling-using-pixelcnn-with-codes-explained-387c95405651&user=Mehul+Gupta&userId=d4ec90760d5b&source=-----387c95405651----3-----------------clap_footer----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-in-your-pocket/generative-modeling-using-pixelcnn-with-codes-explained-387c95405651?source=read_next_recirc-----e2bbd1b4926f----3---------------------862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F387c95405651&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Fgenerative-modeling-using-pixelcnn-with-codes-explained-387c95405651&source=-----e2bbd1b4926f----3-----------------bookmark_preview----862aeebb_bdb9_41f4_bacd_fd1a318c4e00-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----e2bbd1b4926f--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}