{"url": "https://towardsdatascience.com/predicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9", "time": 1683005841.6101382, "path": "towardsdatascience.com/predicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9/", "webpage": {"metadata": {"title": "Predicting California Wildfire Size with Neural Networks (Part 1) | by Ricky Cordero | Towards Data Science", "h1": "Predicting California Wildfire Size with Neural Networks (Part 1)", "description": "But, because of these natural factors and the presence of human activity that follows, the state also has over 2 million homes at high or extreme risk of wildfire damage. In 2018 alone, over 1.8\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.verisk.com/siteassets/media/campaigns/gated/underwriting/fireline-state-risk-report/2019-fireline-risk-report_california.pdf", "anchor_text": "over 2 million homes", "paragraph_index": 2}, {"url": "https://www.verisk.com/siteassets/media/campaigns/gated/underwriting/fireline-state-risk-report/2019-fireline-risk-report_california.pdf", "anchor_text": "1.8 million acres", "paragraph_index": 2}, {"url": "https://www.iii.org/fact-statistic/facts-statistics-wildfires", "anchor_text": "deadliest", "paragraph_index": 3}, {"url": "https://www.fire.ca.gov/incidents/2018/11/8/camp-fire/", "anchor_text": "destructive", "paragraph_index": 3}, {"url": "https://www.nwcg.gov/publications/pms437/cffdrs/fire-weather-index-system", "anchor_text": "fire indexes", "paragraph_index": 8}, {"url": "https://wildfire.cr.usgs.gov/arcgis/rest/services/geomac_dyn/MapServer", "anchor_text": "publicly accessible", "paragraph_index": 10}, {"url": "https://darksky.net/dev/docs#time-machine-request", "anchor_text": "Dark Sky\u2019s Time Machine API", "paragraph_index": 12}, {"url": "https://blog.darksky.net/dark-sky-has-a-new-home/", "anchor_text": "nor eternal", "paragraph_index": 12}, {"url": "https://www.mongodb.com/download-center/community", "anchor_text": "MongoDB Community Server 4.0", "paragraph_index": 19}, {"url": "https://nodejs.org/en/download/releases/", "anchor_text": "Node.js v8.11.3", "paragraph_index": 19}, {"url": "https://github.com/RickyCordero/predicting-wildfire-risk", "anchor_text": "project", "paragraph_index": 19}, {"url": "https://github.com/RickyCordero/predicting-wildfire-risk/tree/master/scripts", "anchor_text": "README", "paragraph_index": 19}, {"url": "https://www.reddit.com/r/ProgrammerHumor/comments/6s0wov/heaviest_objects_in_the_universe/", "anchor_text": "some time", "paragraph_index": 21}, {"url": "https://medium.com/@rickycordero19/predicting-california-wildfire-size-building-a-machine-learning-project-from-start-to-finish-1c76ddf54324", "anchor_text": "part 2", "paragraph_index": 40}, {"url": "http://linkedin.com/in/rickycordero19/", "anchor_text": "linkedin.com/in/rickycordero19/", "paragraph_index": 42}], "all_paragraphs": ["\u201cYou could travel the world, but nothing comes close to the golden coast.\u201d \u2014 Katy Perry", "It allows for some of the best outdoor activities given its dry, sunlit, Mediterranean climate.", "But, because of these natural factors and the presence of human activity that follows, the state also has over 2 million homes at high or extreme risk of wildfire damage. In 2018 alone, over 1.8 million acres burned from wildfire in California.", "When fire burns at this scale, it not only poses an immediate threat to those at the ignition site, but it can cause wide reaching effects several miles away like I experienced first hand with the 2018 Camp Fire: California\u2019s deadliest, most destructive wildfire.", "Heavy smoke blew from the northeast part of the state making its way down to the Bay Area, closing down schools and creating a local shortage of the pollutant-blocking N95 masks. For those affected it was at best two weeks of isolation from the outdoors, as was the case for me, but at worst it meant tragic death, forced homelessness, and the destruction of entire communities for the unfortunate.", "Having access to tools that can provide early indication of risk are important since they can allow officials to make more informed and proactive decisions to help prepare communities for these potentially devastating events.", "Thus, I\u2019d like to see if we can use historical wildfire data, statistics, and modern machine learning techniques to construct a model that can predict the approximate area of land burned in a wildfire event with the hope of productionizing such a system to aid officials in real time.", "Before I continue, I\u2019d like to mention this project currently represents the lone continuation of an undergraduate research study previously conducted alongside my former research partner Michael L. who helped in formulating the problem, designing the data schema, and guiding in model analysis while we built both decision tree based risk classification models and deep regression models (like those that will be explored in this series).", "Using only meteorological (climate) data bound to the time and space relevant to each event is a reasonable starting point for model inputs given that factors like temperature, wind speed, and humidity have been used for many years in occurrence forecasting via fire indexes. Having a tool based on inputs like these could give fire specialists a sense of how far-reaching a new fire event could be post-ignition. We\u2019ll discuss other potentially useful factors one might consider for model development and try to bring them in as we iterate on different model architectures later on.", "In order to come up with a preliminary dataset useful for training, we have to marry two different data sources: wildfire data and climate data.", "Through a bit of searching, I came across a REST API run by the United States Geological Survey (USGS), an organization dedicated to studying natural hazards in the United States. This API powers ArcGIS map systems used in tracking live wildfire events and exposes useful information about these events including each fire ignition\u2019s date of discovery, latitude, longitude, and burn area. The API is publicly accessible, spans incidents going back to the year 2002, and appears actively updated through 2019 as of this writing.", "Given that each wildfire event obtained by the USGS API contains a corresponding spatiotemporal (time and space) coordinate, we should be able to map each coordinate through some weather service to retroactively inspect the scene of the ignition site corresponding to each event.", "After searching and playing with different climate data sources with varying access limitations, I stumbled upon Dark Sky\u2019s Time Machine API. While not completely free (nor eternal \ud83d\ude22), this REST API allows users to query the hour by hour observed weather conditions including temperature, wind speed, and humidity for a given spatiotemporal coordinate described by a latitude, longitude, and historical date. So we can obtain the date of discovery, latitude, and longitude of a fire event by querying the USGS API, come up with a time range to represent the context and duration of the fire event, then feed that information in as inputs to requests made to the Dark Sky API.", "Great! Now that we have our data sources and know what we want to accomplish with them, let\u2019s see what tools we\u2019ll need to get our hands on the actual data.", "Because of the number of API requests we\u2019ll need to make, and given that each Dark Sky request incurs an actual dollar amount beyond a certain number of requests, I decided to go with my weapon of choice for web automation: Node.js. While a language like Python would work just as fine, creating chains of asynchronous tasks like web requests is something best accomplished in a Node environment as we\u2019ll see later when creating the data transformation pipeline.", "Great, so we\u2019ve established the tool to get the data we need, but where will we store the results of these API requests? We need a database!", "Since each API request may generate a JSON response object that varies by field names, i.e. has varying schema, a natural choice would be to use a document-based NoSQL solution. Also, since we don\u2019t anticipate knowing the structure of these response objects completely prior to making requests for them, it behooves us to use a schema-less solution so that we can dump all response objects then analyze and clean any unexpected attribute arrangements or degenerate responses. (Note: This is a choice of convenience, finding all theoretical attribute variations a priori is time consuming and not very rewarding since the cost of not using some data is minimal) Because of its ease of use, large community support, and strong integration with Node, MongoDB seems like the right choice.", "Data sources \u2714Automation tool \u2714 Database \u2714", "Let\u2019s set up our environment for using these tools.", "I happened to use MongoDB Community Server 4.0, Node.js v8.11.3, and Windows 10 from a desktop environment while working on this project, so you should be able to follow along with that setup without issues. Once you have those installed, we\u2019ll be working directly from the command line and following the README.", "First, we make sure to start the MongoDB server (this will take up a single terminal window).", "After cloning the project, in a new terminal inside the scripts folder, we\u2019ll install the project dependencies using npm. This could take some time.", "Now we\u2019ll set up an environment file so that we can abstract some commonly used variables from the rest of the code that will change depending on the deployment mode. Make sure to replace YOUR_MONGODB_URL with the URL of your local server instance, most likely \u201cmongodb://localhost:27017\u201d. If you choose to deploy to a remote MongoDB server, make sure to change this URL accordingly. Also, make sure to replace YOUR_DARKSKY_API_KEY with the API key obtained after registering for access to the Dark Sky API.", "Data sources \u2714Automation tool \u2714 Database \u2714 Environment \u2714", "We\u2019ll start by gathering a collection of historical wildfire events from the USGS REST API.", "Here\u2019s the base URL we\u2019ll be querying:", "The API distinguishes historical wildfire event datasets from each year via an integer id identifying the ArcGIS layer holding that data, starting with 10 representing the latest year, increasing until the earliest year of 2002. For example, as of this writing, the layer with id=10 holds 2019 fire data, the layer with id=11 holds 2018 fire data, \u2026 , the layer with id=27 holds 2002 fire data. We can hardcode these ids in an array, iterate through each entry replacing the ${yearId} parameter of the query URL with that id, then perform an API request on the new query URL, thus mapping each id to a response object and getting fire data for each year.", "We can now use the resultant array to populate our database. First, we connect to the database using the PRIMARY_MONGODB_URL field we set earlier, then we execute the above code upon successful connection. Once the API requests have completed, the resultant array of response objects will be in the array mapRes. We can store this array as a collection \u201craw\u201d in a database \u201carcgis\u201d using a function called saveToDBBuffer. This entire process gets wrapped in a Promise object and is returned by the downloadRaw function.", "Using Promises, we can encapsulate asynchronous operations, like processing network requests, into intuitive, synchronous blocks of code that we can then sequence to build out a data transformation pipeline that can be efficiently logged and tested. On successful processing we resolve the Promise, and on unsuccessful processing we reject the Promise, passing on an error status for the pipeline step that failed. The value in setting up such a structure will be manifest when adding additional stages to the data processing pipeline.", "What we\u2019ve done here is modularized asynchronous parts of the pipeline (e.g. constructed and exported the wildfireStages Promise) allowing any stage to then be imported from another script into an execution sequence (exports array) in pipeline.js.", "This array of Promises representing our pipeline can then be imported via require(./pipeline) and executed by our main script\u2026", "\u2026which can now be run automatically whenever we\u2019d like to reproduce a pipeline, e.g. whenever we need more data.", "As you can see in pipeline.js, we have two other Promises: climateStages and combineStages. These stages will make use of the updated state of our databases after processing the wildfireStages Promise, and thus are sequenced after in the exported array. They respectively download the climate data for each event and join the resulting datasets into a single training set.", "The result of executing the wildfireStages sequence is a few new collections in the arcgis database containing useful snapshots of the raw dataset as we transform it into a more useful working set. The final collection being the \u201ctraining\u201d collection. Now let\u2019s get the climate data.", "Similar to how we mapped years to fire event response objects with the USGS API, we are going to map attributes from fire event objects in the arcgis training collection to climate data response objects using the Dark Sky API, only now streaming the resultant response objects directly into the database instead of downloading to a buffer in memory. This is done to prevent data loss in case we get a lot of data back from the API and can\u2019t fit it all in memory.", "By creating a read stream for fire events from the training collection, we kick-start the streaming process by piping each fire event into a transform stream that executes a Dark Sky API request for that event then pipes the resultant response object into a transform stream that uploads the document to the climate database. The function getClimateDataEach starts this off by producing a transform stream object customized by the CLIMATE_CONFIG object. Inside this transform stream object, we execute the getHistoricalClimateDataEach function, produce the resultant climate response object \u201cres\u201d, then push it on to the next transform stream object in the pipe. The next transform stream object is customized by a database config object and is the result of saveToDBEach. Inside the returned stream object lies code that executes the database upload.", "Within the getHistoricalClimateDataEach function, a time window is constructed around the ignition time of a wildfire event using an hourly or daily interval as specified in the CLIMATE_CONFIG object. The resultant start and end dates then get passed through to the download function which executes API requests for each time unit starting from the start time and recurses toward the end time (base case) aggregating results into a result object.", "Cool! Now we have climate data for each fire event from the arcgis training collection saved in the \u201ctraining\u201d collection in the climate database. We just need to combine both training datasets from the two databases we\u2019ve created into one master dataset that\u2019ll be used for model development.", "We can load each fire event from the arcgis training collection, load each corresponding climate response object linked by the \u201cEvent\u201d attribute, then join the desired attributes and format the columns to fit a typical relational schema. Having a relational schema will allow the dataset to be easily interpretable and conveniently exportable into Python as we\u2019ll soon see.", "For each fire event, the column names are labeled with the climate property and an index string representing the hour relative to the ignition time of that fire event, e.g. temperature_336, temperature0, and temperature336 represent the temperature of the ignition site 336 hours prior to, at exactly, and 336 hours after the fire ignition time respectively. 14 days of hourly measurements around the ignition time gives 336 data points prior to and after ignition per climate property, with additional data points representing each climate property for the ignition hour.", "Okay, we got the data. Now let\u2019s see how we can use this dataset to build some regression models in part 2 of this series. (Coming soon!)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Mathematics & Computer Science Graduate | Researcher | Entrepreneur (linkedin.com/in/rickycordero19/)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdb0e57dce4c9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rickycordero19?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickycordero19?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "Ricky Cordero"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F912eed1f873b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&user=Ricky+Cordero&userId=912eed1f873b&source=post_page-912eed1f873b----db0e57dce4c9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb0e57dce4c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb0e57dce4c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.verisk.com/siteassets/media/campaigns/gated/underwriting/fireline-state-risk-report/2019-fireline-risk-report_california.pdf", "anchor_text": "over 2 million homes"}, {"url": "https://www.verisk.com/siteassets/media/campaigns/gated/underwriting/fireline-state-risk-report/2019-fireline-risk-report_california.pdf", "anchor_text": "1.8 million acres"}, {"url": "https://www.iii.org/fact-statistic/facts-statistics-wildfires", "anchor_text": "deadliest"}, {"url": "https://www.fire.ca.gov/incidents/2018/11/8/camp-fire/", "anchor_text": "destructive"}, {"url": "https://www.nwcg.gov/publications/pms437/cffdrs/fire-weather-index-system", "anchor_text": "fire indexes"}, {"url": "https://wildfire.cr.usgs.gov/arcgis/rest/services/geomac_dyn/MapServer", "anchor_text": "publicly accessible"}, {"url": "https://darksky.net/dev/docs#time-machine-request", "anchor_text": "Dark Sky\u2019s Time Machine API"}, {"url": "https://blog.darksky.net/dark-sky-has-a-new-home/", "anchor_text": "nor eternal"}, {"url": "https://www.mongodb.com/download-center/community", "anchor_text": "MongoDB Community Server 4.0"}, {"url": "https://nodejs.org/en/download/releases/", "anchor_text": "Node.js v8.11.3"}, {"url": "https://github.com/RickyCordero/predicting-wildfire-risk", "anchor_text": "project"}, {"url": "https://github.com/RickyCordero/predicting-wildfire-risk/tree/master/scripts", "anchor_text": "README"}, {"url": "https://www.reddit.com/r/ProgrammerHumor/comments/6s0wov/heaviest_objects_in_the_universe/", "anchor_text": "some time"}, {"url": "https://wildfire.cr.usgs.gov/ArcGIS/rest/services/geomac_dyn/MapServer/${yearId}/query?where=1%3D1&outFields=*&outSR=4326&f=json", "anchor_text": "https://wildfire.cr.usgs.gov/ArcGIS/rest/services/geomac_dyn/MapServer/${yearId}/query?where=1%3D1&outFields=*&outSR=4326&f=json"}, {"url": "https://medium.com/@rickycordero19/predicting-california-wildfire-size-building-a-machine-learning-project-from-start-to-finish-1c76ddf54324", "anchor_text": "part 2"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----db0e57dce4c9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----db0e57dce4c9---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/javascript?source=post_page-----db0e57dce4c9---------------javascript-----------------", "anchor_text": "JavaScript"}, {"url": "https://medium.com/tag/wildfires?source=post_page-----db0e57dce4c9---------------wildfires-----------------", "anchor_text": "Wildfires"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----db0e57dce4c9---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdb0e57dce4c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&user=Ricky+Cordero&userId=912eed1f873b&source=-----db0e57dce4c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdb0e57dce4c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&user=Ricky+Cordero&userId=912eed1f873b&source=-----db0e57dce4c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdb0e57dce4c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdb0e57dce4c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----db0e57dce4c9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----db0e57dce4c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickycordero19?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rickycordero19?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ricky Cordero"}, {"url": "https://medium.com/@rickycordero19/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "7 Followers"}, {"url": "http://linkedin.com/in/rickycordero19/", "anchor_text": "linkedin.com/in/rickycordero19/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F912eed1f873b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&user=Ricky+Cordero&userId=912eed1f873b&source=post_page-912eed1f873b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F912eed1f873b%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-california-wildfire-size-with-neural-networks-building-a-machine-learning-project-from-db0e57dce4c9&user=Ricky+Cordero&userId=912eed1f873b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}