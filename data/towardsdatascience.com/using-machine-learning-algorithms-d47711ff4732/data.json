{"url": "https://towardsdatascience.com/using-machine-learning-algorithms-d47711ff4732", "time": 1682997560.6974468, "path": "towardsdatascience.com/using-machine-learning-algorithms-d47711ff4732/", "webpage": {"metadata": {"title": "Using Machine Learning Algorithms | by Abhishek Kumar | Towards Data Science", "h1": "Using Machine Learning Algorithms", "description": "A good understanding of machine learning algorithms along with the knowledge of tools to debug and deploy them helps to develop efficient machine learning models. This articles discusses such tools."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["At this point in time, you must have a basic idea of the most commonly used machine learning algorithms such as linear regression, logistic regression and neural networks. However, there are a couple of pointers that you might want to read upon for effective application of these algorithms.", "It is evident that a good data set makes a good model. However, consider a scenario in which you are working for a computing firm and your new assignment is to predict how often does a server crashes. For the sake of building the model, the firm has provided you with server logs which look something like this.", "You cannot right away use the log file to start making predictions regarding the server\u2019s health. The task of converting raw data into a data set that can be manipulated by a computer is called feature engineering. Things such as the running time of a server, the downtime of a server, latency experienced by the client, type of error thrown by a server or anything measurable can be considered as a feature. The objective is to create features that would help the learning algorithm to make good predictions.", "Now, let\u2019s take a look at a few schemes used for feature engineering.", "Most of the learning algorithms work well with numeric values. But, there is a possibility of feature vectors being categorical. In such a scenario, we need to transform the categorical variable into numerical variables. Assume a categorical variable \u201cblood type\u201d which takes four possible values \u2014 A, B, AB and O. We may transform the \u201cblood type\u201d feature into numerical values using the following mapping.", "Notice, that the transformation has increased the dimensionality of the feature. One may argue to perform an encoding where, 1 corresponds to A, 2 corresponds to B, 3 corresponds to AB and 4 corresponds to O. But, this should be avoided, as it implies an ordering among the values. It may confuse the learning algorithm because the algorithm will try to find an order when there is none. This might also lead to overfitting.", "There may occur a rare situation of converting numerical values to categorical ones. Binning allows to perform such conversions. For example instead of representing \u201cmarks\u201d as a single continuous feature, one may divide it into bins: where marks between 100\u201390 are put into one bin, marks between 89\u201380 are placed into the second bin and so on.", "Binning tells the learning algorithm that, instead of a particular value (say 85 marks) it is the range of the value that matters (say 89\u201380). It helps in better generalisation of the learning algorithm.", "Let\u2019s say John has been assigned the task of training a machine learning model. He decides to train a linear regression model.", "However, he is having trouble in selecting the degree d, for his linear regression model. Variables, such as the degree that define the model itself are called as hyper parameters. Hyper parameters are set even before the training starts.", "A solution is to split the dataset into three subsets \u2014", "Before splitting the data set it is important to randomise that data set. Also the split should be representative of the original data set.", "After the splits have been made the training set is used for training, which gives us a model in return. The model obtained is then evaluated against the validation set.", "The data analyst might tune the hyper parameters, train the model on the training set, evaluate it on the validation set, and finally choose a model that performed best on the validation set. Once the best model has been selected, it is evaluated again on the test set for its performance and generalisation.", "The idea of having a test set is that the continuous usage of the training set and the validation set to tune the hyper parameters might \u201cwear them out\u201d and lead to an over fitted model instead of a generalised one.", "An algorithm is said to have a high bias if it is under fitted. Which is to say, that the algorithm has a strong preconception regarding the data, and does not want to adapt to the data set. On the other hand, an over fitted algorithm is said to have a high variance.", "A model is likely to under fit in case \u2014", "A model is likely to over fit in case \u2014", "One of the most commonly used method to prevent over fitting is regularisation.", "Regularisation helps to make the learning algorithms less complex. Observe the following equations \u2014", "Here J is the unregularised cost function. Our objective is to find values for the parameters w and b for the hypothesis function f(x) such that value the unregularised cost function is minimised.", "Now observe the regularisation term, it is simply an average of all the parameters of our hypothesis function f(x).", "The regularised cost function, J_{reg} is simply the summation of the two terms. Now the goal is to minimise the regularised cost function. Since J_{reg} is a sum of two terms therefore, minimising either of them will lead to its minimisation. The regularisation term has added an additional burden on the new cost function. Every iteration over the cost function is penalised by the regularisation term, thereby the parameter values are simplified with each subsequent iteration hence, preventing over fitting.", "\u03bb is a hyper parameter that controls the intensity by which you want to penalise the cost function. If \u03bb=0, the cost function is not penalised at all, leading to a high variance model. In case \u03bb is set to a very large value then the cost function is minimised by setting most of the parameters w_{i} to zero, which leads to a high bias model. Usually a range of values of \u03bb are tested and, the one that performs best on the validation set in chosen for the model.", "Learning curves also help to address the problem of high bias and high variance. A graph for the errors generated by the validation set and the training set is plotted against the number of training examples. The number of training examples are limited purposefully and the errors are plotted. Any standard error function such as mean squared error function can be used to compute the error on validation set and on the training set.", "The training error is initially small because the number of training examples are less or we may say that there is less variations in the data to deal with. However, as the number of training examples increase the variation within the data also increases, consequently the training error also increases.", "Initially, a small number of training examples are used to train the model therefore it fails to generalise well giving a higher error on the validation set. However, with the increase in number of training examples the model start to generalise and the error on validation set decreases.", "In case of a over fitted model the gap between the error of the training set and validation set is small, also both the errors take large values. So, if an algorithm shows this behaviour then getting more training data will be no help.", "On the other hand, in case of an under fitted model, the gap between the error of the training set and the validation set is relatively large, also the validation error remains higher because the model fails to generalise well. Such behaviour can be improved by collecting more training examples.", "Once we have our model we use the test set to access the performance of our model and decide how generalised the model is. There are certain evaluation metrics that help us to analyse the performance of our model \u2014", "A confusion matrix summarises the prediction results of a classification problem. Consider the following confusion matrix \u2014", "From the table one may conclude that out of the total 25 actual spam emails the model correctly predicted 20 to be spam (True Positive) however misclassified 5 emails to be not spam (False Negative). Similarly, out of the total 510 not spam emails, the model correctly labelled 500 emails to be not spam (True Negative) but misclassified 10 not spam emails to be spam (False Positive).", "Confusion matrix gives us an idea about the mistake patterns made by the learning algorithm. Let\u2019s say a model has a higher false negative rate, which implies that the model often predicts spam emails as not spam. In such a case training the model with more spam examples sounds like a reasonable choice.", "In case of multi-class classification one versus all approach is used in which all the classes other than the class of interest are grouped into a single class thereby, converting our problem to a binary classification problem. A n-class multi-classifier gives us n confusion matrices.", "Precision is the measure of a models false alarm rate.", "Considering the above confusion matrix \u2014 out of 30 emails classified as spam by the model, 20 emails were actually email whereas, the remaining 10 emails were wrongly labelled to be spam, giving us an precision of 66% and the false alarm rate of 33%.", "Recall reflects onto how sensitive the model is. It tells about the true positive rate. For the above confusion matrix, out of the total 25 actual spam emails the model correctly labelled 20 emails but misclassified 5 emails as being not spam, thereby making the model 80% sensitive towards flagging emails as spam.", "Specificity is a related measure which tells us how many emails classified as not spam are actually not spam. It measures the true negative rate. The above confusion matrix has specificity of of 98%.", "As an analyst one wants to control the trade off between precision and recall. Most of the time it depends on the problem in hand \u2014 consider a case of a model trying to classify patients as being cancerous or non-cancerous. In such a case one may want to have a higher recall, which is to say, that you do not want to misclassify an actual cancer suffering patient as being healthy (avoiding false negatives). Anyways, a lower precision rate is acceptable, implying that, it would not harm to classify a healthy person as being cancerous and have him tested for the disease (willing to accept false positives). However, it would be really helpful if we somehow combined precision and recall into a single term . It would give us an easier way to evaluate and compare models using a single metric and F-measure does exactly that.", "Mathematically F-measure is the harmonic mean of Precision and Recall. It gives a higher weight to the lower value. If either, the precision or the recall attains a lower value then F-measure drops thereby, forcing us to tune our model to a give better value of F-measure.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I enjoy to read, write, develop, and listen to music."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd47711ff4732&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d47711ff4732--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d47711ff4732--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://abhieshekumar.medium.com/?source=post_page-----d47711ff4732--------------------------------", "anchor_text": ""}, {"url": "https://abhieshekumar.medium.com/?source=post_page-----d47711ff4732--------------------------------", "anchor_text": "Abhishek Kumar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1245ce379ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&user=Abhishek+Kumar&userId=e1245ce379ff&source=post_page-e1245ce379ff----d47711ff4732---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd47711ff4732&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd47711ff4732&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d47711ff4732---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd47711ff4732&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&user=Abhishek+Kumar&userId=e1245ce379ff&source=-----d47711ff4732---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd47711ff4732&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&user=Abhishek+Kumar&userId=e1245ce379ff&source=-----d47711ff4732---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd47711ff4732&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d47711ff4732--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd47711ff4732&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d47711ff4732---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d47711ff4732--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d47711ff4732--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d47711ff4732--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d47711ff4732--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d47711ff4732--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d47711ff4732--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d47711ff4732--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d47711ff4732--------------------------------", "anchor_text": ""}, {"url": "https://abhieshekumar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://abhieshekumar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Abhishek Kumar"}, {"url": "https://abhieshekumar.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "143 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1245ce379ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&user=Abhishek+Kumar&userId=e1245ce379ff&source=post_page-e1245ce379ff--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F919dadc87f64&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-algorithms-d47711ff4732&newsletterV3=e1245ce379ff&newsletterV3Id=919dadc87f64&user=Abhishek+Kumar&userId=e1245ce379ff&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}