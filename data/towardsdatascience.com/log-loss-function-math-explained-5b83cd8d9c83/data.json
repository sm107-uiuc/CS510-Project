{"url": "https://towardsdatascience.com/log-loss-function-math-explained-5b83cd8d9c83", "time": 1683002617.362991, "path": "towardsdatascience.com/log-loss-function-math-explained-5b83cd8d9c83/", "webpage": {"metadata": {"title": "Log loss function math explained. Have you ever worked on a\u2026 | by Harshith | Towards Data Science", "h1": "Log loss function math explained", "description": "Have you ever worked on a classification problem in Machine Learning? If yes, then you might have come across cross-entropy or log loss function in Logistic regression. Before we start delving into\u2026"}, "outgoing_paragraph_urls": [{"url": "https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html", "anchor_text": "cross-entropy", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "Logistic regression", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Loss_function", "anchor_text": "Detailed definition", "paragraph_index": 4}, {"url": "https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probability-density-functions", "anchor_text": "probability density function", "paragraph_index": 9}, {"url": "http://mathworld.wolfram.com/MonotonicFunction.html", "anchor_text": "monotonic", "paragraph_index": 14}, {"url": "http://mathworld.wolfram.com/BernoulliDistribution.html", "anchor_text": "Bernoulli distribution", "paragraph_index": 16}, {"url": "https://www.linkedin.com/in/saiharshithreddygaddam/", "anchor_text": "LinkedIn", "paragraph_index": 23}], "all_paragraphs": ["Have you ever worked on a classification problem in Machine Learning? If yes, then you might have come across cross-entropy or log loss function in Logistic regression.", "What\u2019s that function used for? What\u2019s the significance of the function in classification problems?", "Let\u2019s find out in detail by looking at the math behind the function.", "Before we start delving into the math behind the function and see how it has been derived we should know what a loss function is.", "In simple terms, Loss function: A function used to evaluate the performance of the algorithm used for solving a task. Detailed definition", "In a binary classification algorithm such as Logistic regression, the goal is to minimize the cross-entropy function.", "Cross-entropy is a measure of the difference between two probability distributions for a given random variable or set of events \u2014 Jason Brownlee", "Let\u2019s consider we have data of patients, and the task is to find which patients have cancer. In our example, as we do not have the entire population\u2019s data, we try to predict the likelihood of a person having cancer from a sample of data. We only need to predict for the malignant class i.e P(y=1 | x ) = p\u0302 because the probability for the negative class can be derived from it i.e P(y=0 | x ) =1-P(y=1 | x ) = 1-p\u0302.", "A good binary classification algorithm should produce a high value of p\u0302 ( probability of predicting the malignant class for a sample S) which is the closest estimate to P (probability of predicting the malignant class of the total population).", "In probability theory, a probability density function, or density of a continuous random variable, is a function whose value at any given sample in the sample space can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample \u2014 Wikipedia", "The idea is to find the maximum of the likelihood function for a particular value of \u03b8", "To find a maximize of a function means to differentiate the function (dL/d\u03b8= 0)", "As Likelihood function L is a product of the probability distribution function of each Xi, we have to use the product rule in differentiation to differentiate such a function, which will become a complicated task.", "This is where the Logarithms come to the rescue. Log(xy) = Logx + Logy", "Applying log to the likelihood function simplifies the expression into a sum of the log of probabilities and does not change the graph with respect to \u03b8. Moreover, differentiating the log of the likelihood function will give the same estimated \u03b8 because of the monotonic property of the log function.", "This transformation of the likelihood function helps in finding the value of \u03b8, which maximizes the likelihood function.", "The expression is also called a Bernoulli distribution.", "In the case of our example, the probability of the cancer being malignant is P. The probability of the cancer being benign will be1-P.", "In a circumstance of N observations, a probability density function f is given as a product of individual probability density functions. The joint probability is defined as follows", "For maximum likelihood estimation, we have to compute for what value of P is dL/dP = 0, so for that as discussed earlier; the likelihood function is transformed into a log-likelihood function.", "As you can see we have derived an equation that is almost similar to the log-loss/cross-entropy function only without the negative sign. In Logistic Regression, gradient descent is used to find the optimum value instead of gradient ascent because it is considered as a minimization of loss problem, so this is where we add the negative sign to the equation which results in the Binary Cross-Entropy Loss function.", "Also, notice that maximizing the log-likelihood function is the same as minimizing the negative log-likelihood function.", "The loss function computes the error for a single training example; the cost function is the average of the loss funcitons of the entire training set \u2014 Andrew Ng", "If you liked the article please support me and I would appreciate any sort of feedback. Also, I would like to connect with people from the data science community. Connect with me on LinkedIn", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "SDE II @ Amazon, and Machine Learning enthusiast in a quest to reach the global maxima."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5b83cd8d9c83&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@shrshthreddy?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shrshthreddy?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "Harshith"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F76536d1553e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&user=Harshith&userId=76536d1553e2&source=post_page-76536d1553e2----5b83cd8d9c83---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b83cd8d9c83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b83cd8d9c83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html", "anchor_text": "cross-entropy"}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "Logistic regression"}, {"url": "https://en.wikipedia.org/wiki/Loss_function", "anchor_text": "Detailed definition"}, {"url": "https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probability-density-functions", "anchor_text": "probability density function"}, {"url": "http://mathworld.wolfram.com/MonotonicFunction.html", "anchor_text": "monotonic"}, {"url": "http://mathworld.wolfram.com/BernoulliDistribution.html", "anchor_text": "Bernoulli distribution"}, {"url": "https://www.linkedin.com/in/saiharshithreddygaddam/", "anchor_text": "LinkedIn"}, {"url": "https://en.wikipedia.org/wiki/Loss_function", "anchor_text": "https://en.wikipedia.org/wiki/Loss_function"}, {"url": "https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probability-density-functions", "anchor_text": "https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probability-density-functions"}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation"}, {"url": "http://mathworld.wolfram.com/MonotonicFunction.html", "anchor_text": "http://mathworld.wolfram.com/MonotonicFunction.html"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5b83cd8d9c83---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5b83cd8d9c83---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/loss-function?source=post_page-----5b83cd8d9c83---------------loss_function-----------------", "anchor_text": "Loss Function"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----5b83cd8d9c83---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----5b83cd8d9c83---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5b83cd8d9c83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&user=Harshith&userId=76536d1553e2&source=-----5b83cd8d9c83---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5b83cd8d9c83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&user=Harshith&userId=76536d1553e2&source=-----5b83cd8d9c83---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b83cd8d9c83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5b83cd8d9c83&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5b83cd8d9c83---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5b83cd8d9c83--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shrshthreddy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shrshthreddy?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Harshith"}, {"url": "https://medium.com/@shrshthreddy/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "440 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F76536d1553e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&user=Harshith&userId=76536d1553e2&source=post_page-76536d1553e2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3f043432988b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flog-loss-function-math-explained-5b83cd8d9c83&newsletterV3=76536d1553e2&newsletterV3Id=3f043432988b&user=Harshith&userId=76536d1553e2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}