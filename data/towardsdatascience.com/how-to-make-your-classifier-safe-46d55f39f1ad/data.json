{"url": "https://towardsdatascience.com/how-to-make-your-classifier-safe-46d55f39f1ad", "time": 1683008666.901048, "path": "towardsdatascience.com/how-to-make-your-classifier-safe-46d55f39f1ad/", "webpage": {"metadata": {"title": "How to Make Your Classifier Safe. A story about the accuracy estimation\u2026 | by Koorosh Aslansefat | Towards Data Science", "h1": "How to Make Your Classifier Safe", "description": "A story about the accuracy estimation of Machine Learning/Deep Learning classifiers based on statistical distance measures. It will explain the SafeML idea and its applications for safety-critical systems."}, "outgoing_paragraph_urls": [{"url": "https://www.google.com/search?rlz=1C1CHBD_en-GBGB877GB877&sxsrf=ALeKk03ALt8gLtDnn4rboINnHhj6V0MSMw:1591081899154&q=Keinosuke+Fukunaga&stick=H4sIAAAAAAAAAOPgE-LVT9c3NMwwTKuMN6_MVYJw03JMzCtys3O0ZLKTrfST8vOz9cuLMktKUvPiy_OLsq0SS0sy8osWsQp5p2bm5ReXZqcquJVml-YlpifuYGUEAG9AE8xWAAAA&sa=X&ved=2ahUKEwjoh6H7yeLpAhVTu3EKHT2QAHkQmxMoATARegQIEhAD", "anchor_text": "Fukunaga", "paragraph_index": 15}, {"url": "https://colab.research.google.com/drive/1pfATDDr98PJg8S-nRpnF85nJxYaijeMF?usp=sharing", "anchor_text": "Google Colab", "paragraph_index": 29}, {"url": "https://github.com/cdowd/twosamples", "anchor_text": "twosamples library", "paragraph_index": 29}, {"url": "https://uk.mathworks.com/matlabcentral/fileexchange/75282-ecdf-based-distance-measure-algorithms", "anchor_text": "ECDF-based distance measures functions", "paragraph_index": 29}, {"url": "https://arxiv.org/abs/2005.13166v1", "anchor_text": "arXiv", "paragraph_index": 31}, {"url": "https://www.researchgate.net/publication/341699548_SafeML_Safety_Monitoring_of_Machine_Learning_Classifiers_through_Statistical_Difference_Measure", "anchor_text": "ResearchGate", "paragraph_index": 31}, {"url": "https://deepai.org/publication/safeml-safety-monitoring-of-machine-learning-classifiers-through-statistical-difference-measure", "anchor_text": "DeepAI", "paragraph_index": 31}, {"url": "https://paperswithcode.com/paper/safeml-safety-monitoring-of-machine-learning", "anchor_text": "PaperWithCode", "paragraph_index": 31}, {"url": "https://spectrum.ieee.org/the-human-os/biomedical/imaging/hospitals-deploy-ai-tools-detect-covid19-chest-scans", "anchor_text": "IEEE Spectrum", "paragraph_index": 34}, {"url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17155", "anchor_text": "Link", "paragraph_index": 35}, {"url": "https://github.com/ISorokos/SafeML", "anchor_text": "SafeML Project:", "paragraph_index": 36}, {"url": "https://github.com/dependable-ai/nn-dependability-kit", "anchor_text": "NN-Dependability-KIT Project:", "paragraph_index": 37}, {"url": "https://github.com/cfinlay/confident-nn", "anchor_text": "Confident-NN Project:", "paragraph_index": 38}, {"url": "https://eth-sri.github.io/research/safeai", "anchor_text": "SafeAI Project:", "paragraph_index": 39}, {"url": "https://github.com/eth-sri/diffai", "anchor_text": "DiffAI", "paragraph_index": 39}, {"url": "https://github.com/eth-sri/dl2", "anchor_text": "DL2", "paragraph_index": 39}, {"url": "https://github.com/eth-sri/eran", "anchor_text": "ERAN", "paragraph_index": 39}, {"url": "http://www.koorosh-aslansefat.com", "anchor_text": "www.koorosh-aslansefat.com", "paragraph_index": 42}], "all_paragraphs": ["Nowadays, artificial intelligence (AI) is growing rapidly and its applications dominating many different subjects. In parallel with this rapid growth, the concerns about AI safety is also raising. For safety-critical systems where human life, environment, money and privacy is under risk, the AI safety cannot be ignored. (Amodei et al., 2016) have discussed different existing issues of certifying the modern machine learning systems operating in the field. As shown in the following figure, safety issues can be categorised into five categories including A) Safe exploration, B) Robustness to distributional shift, C) Avoiding negative side effects, D) Avoiding \u201creward hacking\u201d and \u201cwire heading\u201d, E) Scalable oversight.", "The topic of this story can be considered as \u201crobustness to distributional shift\u201d issue in AI safety. Based on the following figure, the SafeML approach that we are going to explain includes Safe Machine Learning (SafeML) and Safe Deep Learning (SafeDL).", "There are different existing approaches for increasing the safety and robustness of ML algorithms. Some papers investigate the uncertainty evaluation of results in a classifier while others focus on the improvement of robustness against uncertainties. As an example, the following figure shows the ETH Robustness Analyzer for Neural Networks (ERAN) that uses possible perturbations for input \u201c8\u201d and tries to create a shape that abstracts all possible outputs. If the created shape violates the defined boundary and the results cannot be certified. Otherwise, the outputs will be guaranteed. For more details please check (Gehr, T., et al. 2018 and Balunovic, M., et al. 2019).", "In section 2, the idea of SafeML is discussed briefly, and section three addresses the application of statistical difference measures with some python example. A short conclusion is provided in section 5. Some of the related medium posts and Github projects are suggested at the end of the story.", "SafeML idea has been proposed by (Aslansefat et al., 2020-b), and the goal was to somehow monitor the decisions of the classifiers when there is no available label.", "The following figure demonstrates the flowchart of the SafeML idea. In this flowchart, there are two main sections including training phase and application phase.", "A) The training phase is an offline procedure in which a trusted or certified dataset will be used to train the intelligent algorithm that can be a machine learning or deep learning algorithm. Thus, using a trusted dataset the classifier will be trained and its performance will be measured with existing KPIs (e.g. ROC, Accuracy and Kappa). Meanwhile, the statistical parameters and distributions of each class will be estimated and stored to be used for comparison (e.g. Mean values, Variance Values, and the Empirical Cumulative Distribution Functions (ECDFs)).", "B) The application phase is an online procedure in which real-time and unlabelled data is going to be feed to the system. For example, consider a security attack detector that has been trained to detect different security attacks and it should filter the attacker IPs. Therefore, in the application phase, the trained classifier should distinguish between the normal network traffic and the security attacks (classification task). One important and critical issue in the application phase is that the data does not have any label. So, it cannot be assured that the classifier can operate as accurate as of the training phase.", "In the application phase, the buffered data will be separated based on classifier decision (that is not certified) and the statistical parameters of each class will be stored to be compared with the one in trained phased. Using the statistical distance measures that will be explained in the next section, the distance between features for each class in the trained phase and application phase will be compared. If the calculated distance and expected confidence (defined by an expert) difference was very low, the classifier results and its accuracy can be trusted (the system is acting autonomously), if the difference was low, the system can ask for more data and re-evaluation to make sure about the distance. In case of larger difference, the classifier results and accuracy are no longer valid, and the system should use an alternative approach or notify a human agent (In this example, the system will ask the responsible security agent to check the network traffic manually and make a decision).", "There are countless applications of Machine Learning and Deep Learning for early detection or diagnosis in various kinds of disease. For example, (Scudellari, S. (2020)) wrote about \u201cHospitals Deploy AI Tools to Detect COVID-19 on Chest Scans\u201d. Can this AI tools be fully autonomous in detection or diagnosis? Are they Safe? What is our definition of their safety? It is believed that SafeML or similar approaches can be a possible answer for those questions. The following figure illustrates the application of SafeML in medical diagnosis (e.g. COVID-19 diagnosis using lung scans).", "Another example can be a traffic sign detector in an autonomous car or self-driving vehicle that uses Machine Learning or Deep Learning to detect the traffic sign and generate the required action(s). The following block diagram shows how SafeML can be used in this case study. This can be used also for autonomous platoon systems (Kabir, S., et al. (2020)).", "Each of the above-mentioned applications will be implemented using SafeML with some well-known case studies in our next stories (Part II, Part III and Part IV).", "A threshold line can be considered as the simplest version of a classifier. Consider the following figure; in this simple classifier any point bellow the threshold line (Xtp) will be considered as class 1 and any point above the threshold line will be counted as class 2. Assume that we know that the points between time 0 to 20 are class 1 and other points are class 2. As can be seen in this simple example, x and v points are misclassified.", "If we estimate the probability density function of each class (the following figure), then the probability of error can be calculated as:", "The classifier accuracy can be easily obtained using 1-P(error). In this simple classifier, the area that two probability density function merge causes the error.", "Fukunaga, K. (1990) showed that the upper bound error can be calculated using probability density function (PDF)-based distances like Bhattacharyya distance. The PDF-based distance measures usually rely on mean and variance distance as shown in the following figure. However, some exiting advanced methods can also compare the shape of different PDFs.", "The following figure shows four well-known PDF-based distance measure methods.", "The following python example of upper bound error probability estimation based on Chernoff method is provided. In this code, if one considers \u201cs = 0.5\u201d, then it will be the Bhattacharyya upper bound error estimation.", "It can be proved that the probability of error is correlated with the distance between the cumulative distribution functions (CDFs) (Aslansefat, K. et al. 2020-b). Some of the well-known CDF-based distance measures can be listed as follows:", "Sometimes it can be easier to use the empirical cumulative distribution function (ECDF) of features. Python examples of ECDF-based distance measures are provided as follows.", "Consider we have a dataset with two classes and one feature. The following figure shows the ECDF of the feature for class 1 (blue) and class 2 (red). The Kolmogorov-Smirnov simply finds the maximum exiting distance between two ECDFs.", "As an example, you can check the following python code for Kolmogorov-Smirnov distance measure:", "The Kuiper distance has similar functionality to the Kolmogorov-Smirnov distance. However, this method considers two maximum distance as shown below; a) when blue ECDF has a larger value than red ECDF and b) when red ECDF has a larger value than blue ECDF. The Kuiper distance can be obtained by adding two maximum values.", "An example of Kuiper distance measure in python is provided as follows.", "ECDF is formed by many small steps. Consider the absolute difference of two steps in the same interval as height. If we calculate the summation of all calculated height values for all steps, then we have the Cramer-Von Mises Distance.", "You can check the sample python code for Cramer-Von Mises Distance as follows:", "The Anderson-Darling distance is similar to the Cramer-Von Mises Distance. The only difference is that Anderson-Darling normalizes height values by their standard deviation (SD). Please check the following python example for Anderson-Darling distance.", "Wasserstein distance has been used in many applications. For example, it has been used as a loss function in generative adversarial neural networks (GANs) (Gulrajani, I. 2017). The Wasserstein distance we consider both height values and width values for all steps. This method somehow measures the area between two ECDFs when we consider power equal to one. When the power factor is one, Wasserstein distance is equal to Earth Mover Distance.", "You can check the following python example of Wasserstein distance.", "The above python codes are also available on Google Colab. If one uses R for Programming the twosamples library is suggested. The above Python codes have been rewritten from this library. For MATLAB users, a set of ECDF-based distance measures functions are recommended.", "To see some examples and case studies with SafeML idea please check the following GitHub project:", "More details about SafeML is available in our recent paper [arXiv][ResearchGate][DeepAI][PaperWithCode].", "In this story, the topic of AI safety has briefly introduced and the idea of SafeML has explained with some possible applications. Some of the well-known ECDF-based distance measures algorithms have been provided with their simple python example. In our next stories, the above-mentioned applications of SafeML will be provided with code implementation. Each of the above-mentioned ECDF-based approaches works well for a certain class of system. Thus, the relation between the system\u2019s characteristics and ECDF-based distance measures will be discussed in the next stories.", "The SafeML is still in an early stage of development and it is aimed to extend it for dealing with time-series data, prediction and regression algorithms (i.e. Schulam, P., et al. (2019)) and domain adaptation (i.e. Shen, J., et al. (2018)). It is also possible to use SafeML as Explainable AI that will be discussed later. It should be mentioned that in parallel with \u201cAI Safety\u201d research, there are some other research works focusing on the application of AI for improving safety models (Gheraibia, Y., et al. (2019)).", "Scudellari, S. (2020) Hospitals Deploy AI Tools to Detect COVID-19 on Chest Scans, IEEE Spectrum.", "Shen, J., Qu, Y., Zhang, W., & Yu, Y. (2018, April). Wasserstein distance guided representation learning for domain adaptation. In Thirty-Second AAAI Conference on Artificial Intelligence [Link].", "SafeML Project: The idea that has been briefly explained in this story.", "NN-Dependability-KIT Project: Toolbox for software dependability engineering of artificial neural networks.", "Confident-NN Project: Toolbox for empirical confidence estimation in neural networks-based classification.", "SafeAI Project: Different toolboxes like DiffAI, DL2 and ERAN from SRILab ETH Z\u00fcrich focusing on robust, safe and interpretable AI.", "I would like to thank contributors of SafeML project:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD student at the University of Hull working on data-driven reliability-centred evolutionary and automated Maintenance. www.koorosh-aslansefat.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F46d55f39f1ad&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@koo.ec2008?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@koo.ec2008?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "Koorosh Aslansefat"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F41e7b477247e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&user=Koorosh+Aslansefat&userId=41e7b477247e&source=post_page-41e7b477247e----46d55f39f1ad---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46d55f39f1ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46d55f39f1ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/ISorokos/SafeML", "anchor_text": "https://github.com/ISorokos/SafeML"}, {"url": "https://github.com/eth-sri/eran", "anchor_text": "https://github.com/eth-sri/eran"}, {"url": "https://spectrum.ieee.org/the-human-os/biomedical/imaging/hospitals-deploy-ai-tools-detect-covid19-chest-scans", "anchor_text": "Lung Scans"}, {"url": "http://www.freepik.com", "anchor_text": "www.freepik.com"}, {"url": "https://www.google.com/search?rlz=1C1CHBD_en-GBGB877GB877&sxsrf=ALeKk03ALt8gLtDnn4rboINnHhj6V0MSMw:1591081899154&q=Keinosuke+Fukunaga&stick=H4sIAAAAAAAAAOPgE-LVT9c3NMwwTKuMN6_MVYJw03JMzCtys3O0ZLKTrfST8vOz9cuLMktKUvPiy_OLsq0SS0sy8osWsQp5p2bm5ReXZqcquJVml-YlpifuYGUEAG9AE8xWAAAA&sa=X&ved=2ahUKEwjoh6H7yeLpAhVTu3EKHT2QAHkQmxMoATARegQIEhAD", "anchor_text": "Fukunaga"}, {"url": "https://colab.research.google.com/drive/1pfATDDr98PJg8S-nRpnF85nJxYaijeMF?usp=sharing", "anchor_text": "Google Colab"}, {"url": "https://github.com/cdowd/twosamples", "anchor_text": "twosamples library"}, {"url": "https://uk.mathworks.com/matlabcentral/fileexchange/75282-ecdf-based-distance-measure-algorithms", "anchor_text": "ECDF-based distance measures functions"}, {"url": "https://github.com/ISorokos/SafeML", "anchor_text": "https://github.com/ISorokos/SafeML"}, {"url": "https://arxiv.org/abs/2005.13166v1", "anchor_text": "arXiv"}, {"url": "https://www.researchgate.net/publication/341699548_SafeML_Safety_Monitoring_of_Machine_Learning_Classifiers_through_Statistical_Difference_Measure", "anchor_text": "ResearchGate"}, {"url": "https://deepai.org/publication/safeml-safety-monitoring-of-machine-learning-classifiers-through-statistical-difference-measure", "anchor_text": "DeepAI"}, {"url": "https://paperswithcode.com/paper/safeml-safety-monitoring-of-machine-learning", "anchor_text": "PaperWithCode"}, {"url": "https://arxiv.org/abs/1606.06565v2", "anchor_text": "arXiv:1606.06565"}, {"url": "https://doi.org/10.1016/j.isatra.2019.08.015", "anchor_text": "https://doi.org/10.1016/j.isatra.2019.08.015"}, {"url": "https://arxiv.org/abs/2005.13166v1", "anchor_text": "arXiv:2005.13166"}, {"url": "http://papers.nips.cc/paper/9666-certifying-geometric-robustness-of-neural-networks", "anchor_text": "Link"}, {"url": "https://doi.org/10.1109/SP.2018.00058", "anchor_text": "https://doi.org/10.1109/SP.2018.00058"}, {"url": "http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans", "anchor_text": "Link"}, {"url": "https://doi.org/10.1109/ACCESS.2019.2941566", "anchor_text": "https://doi.org/10.1109/ACCESS.2019.2941566"}, {"url": "https://doi.org/10.1007/978-3-030-32872-6_22", "anchor_text": "https://doi.org/10.1007/978-3-030-32872-6_22"}, {"url": "https://spectrum.ieee.org/the-human-os/biomedical/imaging/hospitals-deploy-ai-tools-detect-covid19-chest-scans", "anchor_text": "IEEE Spectrum"}, {"url": "https://arxiv.org/abs/1901.00403v2", "anchor_text": "arXiv:1901.00403"}, {"url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17155", "anchor_text": "Link"}, {"url": "https://github.com/ISorokos/SafeML", "anchor_text": "SafeML Project:"}, {"url": "https://github.com/dependable-ai/nn-dependability-kit", "anchor_text": "NN-Dependability-KIT Project:"}, {"url": "https://github.com/cfinlay/confident-nn", "anchor_text": "Confident-NN Project:"}, {"url": "https://eth-sri.github.io/research/safeai", "anchor_text": "SafeAI Project:"}, {"url": "https://github.com/eth-sri/diffai", "anchor_text": "DiffAI"}, {"url": "https://github.com/eth-sri/dl2", "anchor_text": "DL2"}, {"url": "https://github.com/eth-sri/eran", "anchor_text": "ERAN"}, {"url": "https://medium.com/@deepmindsafetyresearch/building-safe-artificial-intelligence-52f5f75058f1", "anchor_text": "Building safe artificial intelligence: specification, robustness, and assuranceBy Pedro A. Ortega, Vishal Maini, and the DeepMind safety teammedium.com"}, {"url": "https://towardsdatascience.com/ai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d", "anchor_text": "AI Safety \u2014 How Do you Prevent Adversarial Attacks?A quick chat with IBM researchers Pin-Yu and Sijia about their recent papers with the two concepts of \u2018Pruning\u2019 and\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/ai-safety-ai-ethics-and-the-agi-debate-d5ffaaca2c8c", "anchor_text": "AI safety, AI ethics and the AGI debateAlayna Kennedy on the TDS podcasttowardsdatascience.com"}, {"url": "https://medium.com/@AssuringAutonomy/zen-and-the-art-of-safety-assurance-for-machine-learning-in-autonomous-driving-77ebb4c0a302", "anchor_text": "Zen and the art of safety assurance for machine learning in autonomous drivingBy Dr Simon Burtonmedium.com"}, {"url": "https://ai-alignment.com/ai-safety-vs-control-vs-alignment-2a4b42a863cc", "anchor_text": "AI \u201csafety\u201d vs \u201ccontrol\u201d vs \u201calignment\u201dDefining what I mean by \u201cAI safety,\u201d \u201cAI control,\u201d and \u201cvalue alignment.\u201dai-alignment.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----46d55f39f1ad---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----46d55f39f1ad---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----46d55f39f1ad---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/statistical-analysis?source=post_page-----46d55f39f1ad---------------statistical_analysis-----------------", "anchor_text": "Statistical Analysis"}, {"url": "https://medium.com/tag/safeml-project?source=post_page-----46d55f39f1ad---------------safeml_project-----------------", "anchor_text": "Safeml Project"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46d55f39f1ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&user=Koorosh+Aslansefat&userId=41e7b477247e&source=-----46d55f39f1ad---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46d55f39f1ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&user=Koorosh+Aslansefat&userId=41e7b477247e&source=-----46d55f39f1ad---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46d55f39f1ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F46d55f39f1ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----46d55f39f1ad---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----46d55f39f1ad--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@koo.ec2008?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@koo.ec2008?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Koorosh Aslansefat"}, {"url": "https://medium.com/@koo.ec2008/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "16 Followers"}, {"url": "http://www.koorosh-aslansefat.com", "anchor_text": "www.koorosh-aslansefat.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F41e7b477247e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&user=Koorosh+Aslansefat&userId=41e7b477247e&source=post_page-41e7b477247e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F41e7b477247e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-make-your-classifier-safe-46d55f39f1ad&user=Koorosh+Aslansefat&userId=41e7b477247e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}