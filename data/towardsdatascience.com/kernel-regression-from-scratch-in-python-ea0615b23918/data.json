{"url": "https://towardsdatascience.com/kernel-regression-from-scratch-in-python-ea0615b23918", "time": 1683012768.024256, "path": "towardsdatascience.com/kernel-regression-from-scratch-in-python-ea0615b23918/", "webpage": {"metadata": {"title": "Kernel Regression from Scratch | Kunj Mehta | Towards Data Science", "h1": "Kernel Regression from Scratch in Python", "description": "Everyone knows Linear Regression, but do you know Kernel Regression?"}, "outgoing_paragraph_urls": [{"url": "https://github.com/kunjmehta/Medium-Article-Codes/blob/master/gaussian-kernel-regression-from-scratch.ipynb", "anchor_text": "GitHub", "paragraph_index": 15}, {"url": "https://www.kaggle.com/kunjmehta/gaussian-kernel-regression-from-scratch", "anchor_text": "Kaggle", "paragraph_index": 15}, {"url": "https://www.linkedin.com/in/kunjmehta", "anchor_text": "Linkedin", "paragraph_index": 17}, {"url": "http://themlbook.com/", "anchor_text": "The Hundred-Page Machine Learning Book", "paragraph_index": 18}, {"url": "http://linkedin.com/in/kunjmehta", "anchor_text": "linkedin.com/in/kunjmehta", "paragraph_index": 20}], "all_paragraphs": ["Every beginner in Machine Learning starts by studying what regression means and how the linear regression algorithm works. In fact, the ease of understanding, explainability and the vast effective real-world use cases of linear regression is what makes the algorithm so famous. However, there are some situations to which linear regression is not suited. In this article, we will see what these situations are, what the kernel regression algorithm is and how it fits into the scenario. Finally, we will code the kernel regression algorithm with a Gaussian kernel from scratch. Basic knowledge of Python and numpy is required to follow the article.", "Given data in the form of N feature vectors x=[x\u2081, x\u2082, \u2026, x\u2099] consisting of n features and the corresponding label vector y, linear regression tries to fit a line that best describes the data. For this, it tries to find the optimal coefficients c\u1d62, i\u2208{0, \u2026, n} of the line equation y = c\u2080 + c\u2081x\u2081+c\u2082x\u2082+\u2026+c\u2099x\u2099 usually by gradient descent with the model accuracy measured on the RMSE metric. The equation obtained is then used to predict the target y\u209c for new unseen input vector x\u209c.", "Linear regression is a simple algorithm that cannot model very complex relationships between the features. Mathematically, this is because well, it is linear with the degree of the equation being 1, which means that linear regression will always model a straight line. Indeed, this linearity is the weakness of the linear regression algorithm. Why?", "Well, let\u2019s consider a situation where our data doesn\u2019t have the form of a straight line: let\u2019s take data generated using the function f(x) = x\u00b3. If we use linear regression to fit a model to this data, we will never get anywhere close to the true cubic function because the equation for which we are finding the coefficients does not have a cubic term! So, for any data not generated using a linear function, linear regression is very likely to underfit. So, what do we do?", "We can use another type of regression called polynomial regression which tries to find optimal coefficients of a (as the name suggests) polynomial equation with the degree of the equation being n, n\u2a881. However, with polynomial regression another problem arises: as a data analyst, you cannot know what the degree of the equation should be so that the resulting equation fits best to the data. This can only be determined by trial and error which is made more difficult by the fact that above degree 3, the model built using polynomial regression is difficult to visualize.", "This is where kernel regression can come to the rescue!", "Seeing the name, you may ask that if \u2018linear\u2019 in linear regression meant a linear function and \u2018polynomial\u2019 in polynomial regression meant a polynomial function, what does \u2018kernel\u2019 mean? Turns out, it means a kernel function! So, what is a kernel function? Simply, it is a similarity function that takes two inputs and spits out how similar they are. We will see shortly how a kernel function is used in kernel regression.", "Now about kernel regression. Unlike linear and polynomial regression in which the optimal parameter vector c=[c\u2081, c\u2082, \u2026, c\u2099] needs to be learnt, kernel regression is non-parametric, meaning that it calculates the target y\u209c by performing computations directly on the input x\u209c.", "Given data points (x\u1d62, y\u1d62) Kernel Regression goes about predicting by first constructing a kernel k for each data point x\u1d62. Then for a given new input x\u209c, it computes a similarity score with each x\u1d62 (given by x\u1d62-x\u209c) using the kernel ; the similarity score acts as a weight w\u1d62 that represents the importance of that kernel (and corresponding label y\u1d62) in predicting the target y\u209c. The prediction is then obtained by multiplying the weight vector w= [w\u2081, w\u2082, \u2026, w\u2099] with the label vector y= [y\u2081, y\u2082, \u2026, y\u2099].", "Now, there can be different kernel functions which give rise to different types of kernel regressions. One such type is the Gaussian Kernel Regression in which the shape of the constructed kernel is the Gaussian curve also known as the bell-shaped curve. In the context of Gaussian Kernel Regression, each constructed kernel can also be viewed as a normal distribution with mean value x\u1d62 and standard deviation b. Here, b is a hyperparameter that controls the shape (in particular, the width of the Gaussian curve in Gaussian kernels) of the curve. The equation for the Gaussian kernel k is given below. Notice the similarity between this equation and that of the Gaussian (also called normal) distribution.", "We will code this type of kernel regression next.", "We will first look at the case of a one-dimensional feature vector and then extend it to n dimensions.", "We define a class for Gaussian Kernel Regression which takes in the feature vector x, the label vector y and the hyperparameter b during initialization. Inside the class, we define a function gaussian_kernel() that implements the Gaussian kernel. You can see that we just write out the mathematical equation as code. Next, we define the function predict() that takes in the feature vector x\u209c (referred to in code as X) whose target value has to be predicted. Inside the function, we construct kernels for each x\u1d62, calculate the weights and return the prediction, again by plugging in the mathematical equations into code as-is.", "Now, let\u2019s pass in some dummy data and see the prediction that is output. We predict the value for x\u209c = 50 (by ignoring for demonstration purposes that it is already present in training data)", "Now, let\u2019s extend the code for the case of n dimensional feature vectors. The only modification we need to make is in the similarity score calculation. Instead of obtaining the difference between x\u1d62 and x\u209c, we calculate the similarity score in the n dimensional case as the Euclidean distance ||x\u1d62-x\u209c|| between them. Note that for the purposes of handling n dimensional vectors, we use numpy wherever needed.", "The extended code (including for visualizations) for this article can be found on GitHub and Kaggle.", "We saw where and why linear regression and polynomial regression cannot be used and with that background understood the intuition behind and the working of kernel regression and how it can be used as an alternative. We went into the details of the Gaussian kernel regression and coded it from scratch in Python by simply plugging in the mathematical equations to code.", "I would love to connect with you on Linkedin!", "[1] A. Burkov, The Hundred-Page Machine Learning Book (2019), Published by Andriy Burkov.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "MS @ Rutgers 2023 | Writing on AI transformation, AI in finance, climate and logistics. linkedin.com/in/kunjmehta"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fea0615b23918&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ea0615b23918--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ea0615b23918--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kunjmehta10.medium.com/?source=post_page-----ea0615b23918--------------------------------", "anchor_text": ""}, {"url": "https://kunjmehta10.medium.com/?source=post_page-----ea0615b23918--------------------------------", "anchor_text": "Kunj Mehta"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fab5f9f992f70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&user=Kunj+Mehta&userId=ab5f9f992f70&source=post_page-ab5f9f992f70----ea0615b23918---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea0615b23918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea0615b23918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@herfrenchness?utm_source=medium&utm_medium=referral", "anchor_text": "Clarisse Croset"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/kunjmehta/Medium-Article-Codes/blob/master/gaussian-kernel-regression-from-scratch.ipynb", "anchor_text": "GitHub"}, {"url": "https://www.kaggle.com/kunjmehta/gaussian-kernel-regression-from-scratch", "anchor_text": "Kaggle"}, {"url": "https://www.linkedin.com/in/kunjmehta", "anchor_text": "Linkedin"}, {"url": "http://themlbook.com/", "anchor_text": "The Hundred-Page Machine Learning Book"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ea0615b23918---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ea0615b23918---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/regression?source=post_page-----ea0615b23918---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----ea0615b23918---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea0615b23918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&user=Kunj+Mehta&userId=ab5f9f992f70&source=-----ea0615b23918---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea0615b23918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&user=Kunj+Mehta&userId=ab5f9f992f70&source=-----ea0615b23918---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea0615b23918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ea0615b23918--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fea0615b23918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ea0615b23918---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ea0615b23918--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ea0615b23918--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ea0615b23918--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ea0615b23918--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ea0615b23918--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ea0615b23918--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ea0615b23918--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ea0615b23918--------------------------------", "anchor_text": ""}, {"url": "https://kunjmehta10.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kunjmehta10.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kunj Mehta"}, {"url": "https://kunjmehta10.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "87 Followers"}, {"url": "http://linkedin.com/in/kunjmehta", "anchor_text": "linkedin.com/in/kunjmehta"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fab5f9f992f70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&user=Kunj+Mehta&userId=ab5f9f992f70&source=post_page-ab5f9f992f70--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe67f9b3db8bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkernel-regression-from-scratch-in-python-ea0615b23918&newsletterV3=ab5f9f992f70&newsletterV3Id=e67f9b3db8bd&user=Kunj+Mehta&userId=ab5f9f992f70&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}