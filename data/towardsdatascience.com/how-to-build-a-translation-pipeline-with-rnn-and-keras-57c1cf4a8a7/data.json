{"url": "https://towardsdatascience.com/how-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7", "time": 1683009439.514978, "path": "towardsdatascience.com/how-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7/", "webpage": {"metadata": {"title": "How to build a translation pipeline with RNN and Keras | by Nechu BM | Towards Data Science", "h1": "How to build a translation pipeline with RNN and Keras", "description": "In the previous article we saw the limits of a FFNN when referring to gain context. A better approach for those situations is RNN, which can manage context and generate state for a better\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/swlh/introduction-to-recurrent-neural-networks-rnn-c2374305a630", "anchor_text": "In the previous article", "paragraph_index": 0}, {"url": "http://www.manythings.org/bilingual/", "anchor_text": "manythings.org", "paragraph_index": 3}, {"url": "https://tatoeba.org/spa", "anchor_text": "Tatoeba", "paragraph_index": 3}, {"url": "http://www.manythings.org/anki/spa-eng.zip", "anchor_text": "Spanish-English", "paragraph_index": 3}, {"url": "https://github.com/NechuBM/rnn_tutorial/tree/feature/simple-rnn/tutorials/simple_rnn", "anchor_text": "following link", "paragraph_index": 30}, {"url": "https://bit.ly/36vajnu", "anchor_text": "https://bit.ly/36vajnu", "paragraph_index": 36}], "all_paragraphs": ["In the previous article we saw the limits of a FFNN when referring to gain context. A better approach for those situations is RNN, which can manage context and generate state for a better understanding of the data across time steps. In this article we will put in practice what we learnt by creating a translation model with keras.", "More precisely we will develop a many-to-many type of RNN also known as sequence to sequence or Seq2Seq. More advanced Seq2Seq structure includes encoder-decoder or attention model. The model we will build looks as follows.", "The input layer receives English sentences, each word is a time step. Then the hidden layer (RNN) calculates per each time step the state that will be used for the next time step and the output to be used in the dense layer.", "The sample data can be downloaded at manythings.org and comes from Tatoeba. It is composed of sentences pairs in the language you need. In our case we will work with Spanish-English pairs.", "The first thing we need to do is import the libraries:", "Then we will read the file and parse the data.", "To not make the computer struggle with a big quantity of pairs and keep the example light we will just work with a smaller amount of data. Let\u2019s have a look at some pairs.", "Sentences contain words with capital letters and punctuations so let\u2019s clear it. Over the article we will see snippets of code for every step with examples. At the end everything will be merged into one file.", "It will print \u2018i will surf today\u2019.", "Machine learning models are not able to read words but just numbers then in order to feed the model with data we need to convert words into numbers. We import Tokenizer from Keras and apply two methods. First we instantiate the class and then with the full text we call the method fit_on_texts. Thanks to this we will create a dictionary where we mapped a word to an index, each unique word having a unique index. We have created a list of examples named text_examples, we have 3 sentences. Those 3 sentences are our full dataset so when we call the method it will create for each word a new index. Let\u2019s see what we created by printing word_index.items().", "Each word has its own index, for example the word \u2018beach\u2019 even though it appears twice is just created once with index 5, the same for \u2018to\u2019 with index 3. We have created the mapping, but we have not converted the sentences into those indexes yet. For that we need to call the method texts_to_sequences, its role is no longer to create the mapping but to apply it. It takes the sentence \u2018i will surf today\u2019 and changes \u2018i\u2019 by 1, \u2018will\u2019 by 2, \u2018surf\u2019 by 6 and \u2018today\u2019 by 7. Consequently, the sentence \u2018I will surf today\u2019 becomes [1, 2, 6, 7].", "It seems weird that computers are more comfortable reading numbers, because it loses all the meaning of the words. What happens when two words are synonym? How does a model know if 234 and 67 have similar meanings? There it comes embedding, instead of mapping a word to an index it maps a word to a vector. Calculating these vectors allows to retain the meaning of the words and create a spatial representation. When we represent those vectors, words with similar meaning will have also similar coordinates. This technique is known as embedding and will be covered in the next article.", "We create a function that returns the vectors and the mapping.", "Let\u2019s apply what we have seen so far to the pairs of sentences instead of the examples and explore the results.", "There are 7198 unique Spanish words while in English there are just 3736. Also, another difference is the maximum length of the sentences, while for Spanish is composed of 12 words for English the maximum length is of 6 words. Wait a second, we have seen so far that both sentences should be the same length to fit the RNN structure, how do we deal with different lengths?", "In order to make all the sentences the same length we use pad_sequences from Keras. The role of this class is very straightforward, for those sentences where the length is lower than the maximum it adds a 0. Coming back to our list text_examples, the maximum length is 8 while the length of the first sentence is 4 then when we apply padding we have [1 2 6 7 0 0 0 0]. 4 zeros have been added to make it a length of 8. The other 2 sentences have already a length of 8 then no changes are applied.", "A more visual example would be as follows. For a RNN with a time step of 8 where we want to translate the sentence \u2018birds sing.\u2019 it becomes \u2018los p\u00e1jaros est\u00e1n cantando\u2019", "We will refer to this image when building the model. We apply the same code to the Spanish English pairs.", "We are ready to go, sentences have been cleaned, they have also become vectors and thanks to padding they are of the same length. Our training data is ready.", "The first layer we need to define is the input layer, the blue one in the image \u2018RNN Structure\u2019. From Keras the input shape for an RNN is 3D (batch_size, timestep, features). Input layer takes two elements (timestep, features) we already know time step from our maximum sentence length 12, and features is the number of observations at the time step, in our case just one. Then batch_size is defined as an argument of the method fit of the object model, Keras assume it to be 1 or more.", "The second layer we add is the RNN, more precisely in this case we work with Long short-term memory (LSTM). One important argument to pay attention is return_sequences, by default is set to False and the output of this layer would be just a vector at the last time step as in the following image.", "We don\u2019t need to get the output at each time step but just at the end so the dense layer can make a prediction. But in our case, as we saw in the image \u2018RNN Structure\u2019 there is a prediction at each time step so the RNN layer will not output one vector at the end but one vector at each time step.", "Following this explanation is the moment to introduce TimeDistributed. Even though conceptually is very simple, when you face it for the first time it can cause some confusions. We have just set in the RNN layer return_sequences=True so we have at every step an output vector. What should we do then? Apply a dense layer, so finally with an activation layer we can make a prediction. How does this dense layer look like?", "The input layer receives a vector of shape 256 which is equivalent to the 256 units in the LSTM layer. The output layer has a shape of 7198, which represents the total number of unique Spanish words in our vocabulary (spanish_vocab). The predicted word would be the unit in the 7198 which has been activated. So, if the final vector is all zeros except the unit 324 where we have a one, we map the index 324 to the tokenizer and get the translated word. This is done at every time step in isolation.", "We have just seen how to apply the Dense layer, but what is TimeDistributed used for? It just means that we apply the previous explained layer at every time step. Because we are using return_sequence=True, RNN layer outputs a vector at every time step consequently we need to apply the same dense layer at every time step. If we zoom in the output layer of our model it would look like as follows.", "To sum up to create the model we apply the following code.", "The summary of the model is:", "Finally, we train our model. The parameters have not been optimized, the objective of the article is to understand and create the pipeline.", "Once we are done with our training let\u2019s do some predictions. As we have seen before the output of the model at every time step is a vector of shape 7198 where the activated unit is the predicted word, so for example if after out first prediction we have as output 324 we need to map the index to the Spanish word. The following function will do the work for us.", "To check the final prediction, we use the following code.", "You can find a jupyter notebook with the full code in the following link", "In this article we have put in practice the concepts learnt about RNN.", "We have cleaned the data, created an index to map each word to a vector and transform all the sentences into those vectors thanks to Tokenizer. Then we have use pad_sequences to make all the sentences the same length.", "To create the model, we have defined the input shape, we have created a LSTM layer with return_sequences=True and then applied a Dense layer at every time step thanks to TimeDistributed.", "In the next article we will elaborate more on the model architecture to create a better performing translation. From the theoretical point of view, we will be talking about the different types of RNN architecture like LSTM and analysed terms introduced previously like Embedding.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist & Entrepreneur! Learn Artificial Intelligence and Machine Learning to become a Linchpin \u279c https://bit.ly/36vajnu"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F57c1cf4a8a7&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dbenzaquenm?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dbenzaquenm?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "Nechu BM"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F56da16d481ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&user=Nechu+BM&userId=56da16d481ba&source=post_page-56da16d481ba----57c1cf4a8a7---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57c1cf4a8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57c1cf4a8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/swlh/introduction-to-recurrent-neural-networks-rnn-c2374305a630", "anchor_text": "In the previous article"}, {"url": "http://www.manythings.org/bilingual/", "anchor_text": "manythings.org"}, {"url": "https://tatoeba.org/spa", "anchor_text": "Tatoeba"}, {"url": "http://www.manythings.org/anki/spa-eng.zip", "anchor_text": "Spanish-English"}, {"url": "https://github.com/NechuBM/rnn_tutorial/tree/feature/simple-rnn/tutorials/simple_rnn", "anchor_text": "following link"}, {"url": "https://medium.com/tag/python?source=post_page-----57c1cf4a8a7---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----57c1cf4a8a7---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----57c1cf4a8a7---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----57c1cf4a8a7---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/keras?source=post_page-----57c1cf4a8a7---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57c1cf4a8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&user=Nechu+BM&userId=56da16d481ba&source=-----57c1cf4a8a7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57c1cf4a8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&user=Nechu+BM&userId=56da16d481ba&source=-----57c1cf4a8a7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57c1cf4a8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F57c1cf4a8a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----57c1cf4a8a7---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----57c1cf4a8a7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dbenzaquenm?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dbenzaquenm?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nechu BM"}, {"url": "https://medium.com/@dbenzaquenm/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "153 Followers"}, {"url": "https://bit.ly/36vajnu", "anchor_text": "https://bit.ly/36vajnu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F56da16d481ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&user=Nechu+BM&userId=56da16d481ba&source=post_page-56da16d481ba--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4f6c9f72bf01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-translation-pipeline-with-rnn-and-keras-57c1cf4a8a7&newsletterV3=56da16d481ba&newsletterV3Id=4f6c9f72bf01&user=Nechu+BM&userId=56da16d481ba&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}