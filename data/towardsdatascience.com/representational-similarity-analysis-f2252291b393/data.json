{"url": "https://towardsdatascience.com/representational-similarity-analysis-f2252291b393", "time": 1682996700.491606, "path": "towardsdatascience.com/representational-similarity-analysis-f2252291b393/", "webpage": {"metadata": {"title": "Representational Similarity Analysis | by Robert Lange | Towards Data Science", "h1": "Representational Similarity Analysis", "description": "TL;DR: In today\u2019s blog post we discuss Representational Similarity Analysis (RSA), how it might improve our understanding of the brain as well as recent efforts by Samy Bengio\u2019s and Geoffrey Hinton\u2019s\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.frontiersin.org/articles/10.3389/neuro.06.004.2008/full?utm_source=FWEB&utm_medium=NBLOG&utm_campaign=ECO_10YA_top-research", "anchor_text": "Kriegeskorte et al. (2008)", "paragraph_index": 2}, {"url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003963", "anchor_text": "Cadieu et al. (2014)", "paragraph_index": 3}, {"url": "https://www.nature.com/articles/srep27755", "anchor_text": "Cichy et al. (2016)", "paragraph_index": 3}, {"url": "https://science.sciencemag.org/content/sci/364/6439/eaav9436.full.pdf?casa_token=7zJXfxcBvFUAAAAA:ny4nImzhBu3z8hUnzH-0lFyhw5cA37e_bVWFmTa4czuZkGHufYWKleOUhkCcoTY_MSnKRIApIk4cLxc", "anchor_text": "Bashivan et al. (2019)", "paragraph_index": 6}, {"url": "https://www.sciencedirect.com/science/article/pii/S0092867419303915", "anchor_text": "Ponce et al. (2019)", "paragraph_index": 6}, {"url": "https://www.sciencedirect.com/science/article/pii/S0092867419303915", "anchor_text": "Ponce et al. (2019)", "paragraph_index": 6}, {"url": "http://papers.nips.cc/paper/7815-insights-on-representational-similarity-in-neural-networks-with-canonical-correlation.pdf", "anchor_text": "Morcos et al., 2018", "paragraph_index": 7}, {"url": "https://arxiv.org/pdf/1905.00414.pdf?source=post_page---------------------------", "anchor_text": "Kornblith et al., 2019", "paragraph_index": 8}, {"url": "https://medium.com/@RobertTLange/membership", "anchor_text": "https://medium.com/@RobertTLange/membership", "paragraph_index": 11}], "all_paragraphs": ["TL;DR: In today\u2019s blog post we discuss Representational Similarity Analysis (RSA), how it might improve our understanding of the brain as well as recent efforts by Samy Bengio\u2019s and Geoffrey Hinton\u2019s group to systematically study representations in Deep Learning architectures. So let\u2019s get started!", "The brain processes sensory information in a distributed and hierarchical fashion. The visual cortex (the most studied object in neuroscience) for example sequentially extracts low-to-high level features. Photoreceptors by the way of bipolar + ganglion cells project to the lateral geniculate nucleus (LGN). From there on a cascade of computational stages sets in. Throughout the different stages of the ventral (\u201cwhat\u201d vs dorsal \u2014 \u201chow\u201d/\u201dwhere\u201d) visual stream (V1 \u2192 V2 \u2192 V4 \u2192 IT) the activity patterns become more and more tuned towards the task of object recognition. While neuronal tuning in V1 is mostly associated with rough edges and lines, IT demonstrates more abstract conceptual representational power. This modulatory hierarchy has been a big inspiration to the field of computer vision and the development of Convolutional Neural Networks (CNNs).", "In the neurosciences, on the other hand, there has been a long lasting history of spatial filter bank models (Sobel, etc.) which have been used to study activation patterns in the visual cortex. Until recently, these have been the state-of-the-art models of visual perception. This was mainly due to the fact that the computational model had to be somehow compared to brain recordings. Therefore, the model space to investigate was severely restricted. Enter: RSA. RSA was first introduced by Kriegeskorte et al. (2008) to bring together the cognitive and computational neuroscience community. It provides a simple framework to compare different activation patterns (not necessarily in the visual cortex; see figure below). More specifically, fMRI voxel-based GLM estimates or multi-unit recordings can be compared between different conditions (e.g. the stimulus presentation of a cat and a truck). These activation measures are then represented as vectors and we can compute distance measures between such vectors under different conditions. This can be done for many different stimuli and each pair allows us to fill one entry of the so-called representational dissimilarity matrix.", "Since the original introduction of RSA, it has got a lot of press and many popular neuroscientists such as James DiCarlo, David Yamins, Niko Kriegeskorte and Radek Cichy have been combining RSA with Convolutional Neural Networks in order to study the ventral visual system. The beauty of this approach is that the dimensionality of the feature vector does not matter, since it is reduced to a single distance value which is then compared between different modalities (i.e. brain and model). Cadieu et al. (2014) for example claim that the CNNs are the best model of the ventral stream. In order to do so they extract features from the penultimate layer of an ImageNet-pretrained AlexNet and compare the features with multi-unit recordings of IT in two macaques. In a decoding exercise they find that the AlexNet features have more predictive power than simultaneously recorded V4 activity. Quite an amazing result. (In terms of prediction.) Another powerful study by Cichy et al. (2016) combined fMRI and MEG to study visual processing through time and space. A CNN does not know the notion of time nor tissue. A layer of artificial neurons can hardly be viewed as analogous to a layer in the neocortex. However, the authors found that sequence of extracted features mirrored the measured neural activation patterns in space (fMRI) and time (MEG).", "These results are spectacular not because CNNs \u201care so similar\u201d to the brain, but because of the complete opposite. CNNs are trained by minimizing a normative cost function via backprop and SGD. Convolutions are biologically implausible operations and CNNs process millions of image arrays during training. The brain, on the other hand, exploits inductive biases through genetic manipulation as well as unsupervised learning in order to detect patterns in naturalistic images. However, backprop + SGD and thousands of years of evolution seem to have come up with with similar solutions. But ultimately, we as researchers are interested in understanding the causal mechanisms underlying the dynamics of the brain and deep architectures. How much can RSA help us with that?", "All measures computed within RSA are correlational. The RDM entries are based on correlational distances. The R-squared captures the variation of the neural RDM explained by the variation in the model RDM. Ultimately, it is hard to interpret any causal insights. The claim that information in CNNs is the best model for how the visual cortex works is cheap. This really does not help a lot. CNNs are trained via backpropagation and encapsule a huge inductive bias in the form of kernel weight sharing across all neurons involved in a single processing layer. But the brain cannot implement these exact algorithmic details (and has probably found smarter solutions than Leibniz\u2019s chain rule). However, there has been a bunch of recent work (e.g. by Blake Richards, Walter Senn, Tim Lillicrap, Richard Naud and others) to explore the capability of neural circuits to approximate a normative-gradient-driven cost function optimization. So ultimately, we might not be that far off.", "Until then, I firmly believe that one has to combine RSA with the scientific method of experimental intervention. As in economics, we are in the need for quasi-experimental causality by the means of controlled manipulation. And that is exactly what has been done two recent studies by Bashivan et al. (2019) and Ponce et al. (2019)! More specifically, they use generative procedures based on Deep Learning to generate a set of stimuli. The ultimate goal thereby is to provide a form of neural control (i.e. drive firing rates of specific neural sites). Specifically, Ponce et al. (2019) show how to close the loop between generating a stimulus from a Generative Adversarial Network, reading out neural activity and altering the input noise to the GAN in order to drive the activity of single units as well as populations. The authors were able to identify replicable abstract tuning behavior of the recording sites. The biggest strength of using flexible function approximations lies in their capability to articulate patterns which we as experimenters are not able to put in words.", "For many Deep Learning architectures weight initialization is crucial for successful learning. Furthermore, we still don\u2019t really understand inter-layer repesentational differences. RSA provides an efficient and easy-to-compute quantity that can measure robustness to such hyperparameters. At the last NeuRIPS conference Sami Bengio\u2019s group (Morcos et al., 2018) introduced projected weighted canonical correlation analysis (PWCCA) to study differences in generalization as well as narrow and wide networks. Based on a large Google-style empirical analysis the came up with the following key insights:", "A recent extension by Geoffrey Hinton\u2019s Google Brain group (Kornblith et al., 2019) uses centered kernel alignment (CKA) in order to scale CCA to larger vector dimensions (numbers of artificial neurons). Personally, I really enjoy this work since computational models give us scientists the freedom to to turn all the nobs. And there are quite a few in DL (architecture, initialization, learning rate, optimizer, regularizers). Networks are white boxes like Kriegeskorte says. So if we can\u2019t succeed in understanding the dynamics of a simple Multi-Layer Perceptron, how are we ever going to succeed in the brain?", "All in all, I am a huge fan of every scientific development trying to shine some light on approximations of Deep Learning in the brain. However, Deep Learning is not a causal model of computation in the brain. Arguing that the brain as well as CNNs perform similar sequential operations in time and space is a limited conclusion. In order to gain true insights, the loop has to be closed. Using generative models to design stimuli is therefore an exciting new endeavour in neuroscience. But if we want to understand the dynamics of learning, we have to go further than that. How are loss functions and gradients represented? How does the brain overcome the necessity of requiring to separate training and prediction phases? Representations are only a very indirect peephole to answering these fundamental questions. Going forward I there is a lot to gain (from the modeller\u2019s perspective) from skip and recurrent connections as well as Bayesian DL via dropout sampling. But that is the story of another blog post.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Deep RL PhD Student@TU Berlin. Intelligence. \u270d\ufe0f Support my writing: https://medium.com/@RobertTLange/membership"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff2252291b393&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f2252291b393--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f2252291b393--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@RobertTLange?source=post_page-----f2252291b393--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@RobertTLange?source=post_page-----f2252291b393--------------------------------", "anchor_text": "Robert Lange"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F638b9cae9933&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&user=Robert+Lange&userId=638b9cae9933&source=post_page-638b9cae9933----f2252291b393---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff2252291b393&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff2252291b393&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.frontiersin.org/articles/10.3389/neuro.06.004.2008/full?utm_source=FWEB&utm_medium=NBLOG&utm_campaign=ECO_10YA_top-research", "anchor_text": "Kriegeskorte et al. (2008)"}, {"url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003963", "anchor_text": "Cadieu et al. (2014)"}, {"url": "https://www.nature.com/articles/srep27755", "anchor_text": "Cichy et al. (2016)"}, {"url": "https://science.sciencemag.org/content/sci/364/6439/eaav9436.full.pdf?casa_token=7zJXfxcBvFUAAAAA:ny4nImzhBu3z8hUnzH-0lFyhw5cA37e_bVWFmTa4czuZkGHufYWKleOUhkCcoTY_MSnKRIApIk4cLxc", "anchor_text": "Bashivan et al. (2019)"}, {"url": "https://www.sciencedirect.com/science/article/pii/S0092867419303915", "anchor_text": "Ponce et al. (2019)"}, {"url": "https://www.sciencedirect.com/science/article/pii/S0092867419303915", "anchor_text": "Ponce et al. (2019)"}, {"url": "http://papers.nips.cc/paper/7815-insights-on-representational-similarity-in-neural-networks-with-canonical-correlation.pdf", "anchor_text": "Morcos et al., 2018"}, {"url": "https://arxiv.org/pdf/1905.00414.pdf?source=post_page---------------------------", "anchor_text": "Kornblith et al., 2019"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----f2252291b393---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f2252291b393---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neuroscience?source=post_page-----f2252291b393---------------neuroscience-----------------", "anchor_text": "Neuroscience"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f2252291b393---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----f2252291b393---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff2252291b393&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&user=Robert+Lange&userId=638b9cae9933&source=-----f2252291b393---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff2252291b393&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&user=Robert+Lange&userId=638b9cae9933&source=-----f2252291b393---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff2252291b393&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f2252291b393--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff2252291b393&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f2252291b393---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f2252291b393--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f2252291b393--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f2252291b393--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f2252291b393--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f2252291b393--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f2252291b393--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f2252291b393--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f2252291b393--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@RobertTLange?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@RobertTLange?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Robert Lange"}, {"url": "https://medium.com/@RobertTLange/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4.2K Followers"}, {"url": "https://medium.com/@RobertTLange/membership", "anchor_text": "https://medium.com/@RobertTLange/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F638b9cae9933&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&user=Robert+Lange&userId=638b9cae9933&source=post_page-638b9cae9933--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa35dbfb4005a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frepresentational-similarity-analysis-f2252291b393&newsletterV3=638b9cae9933&newsletterV3Id=a35dbfb4005a&user=Robert+Lange&userId=638b9cae9933&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}