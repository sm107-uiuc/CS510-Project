{"url": "https://towardsdatascience.com/sentence-classification-using-bi-lstm-b74151ffa565", "time": 1682995567.759039, "path": "towardsdatascience.com/sentence-classification-using-bi-lstm-b74151ffa565/", "webpage": {"metadata": {"title": "Sentence classification using Bi-LSTM | by akshay uppal | Towards Data Science", "h1": "Sentence classification using Bi-LSTM", "description": "So there are various ways for sentence classification like a bag of words approach or neural networks etc. In this article, I would be discussing mainly the sentence classification task using deep\u2026"}, "outgoing_paragraph_urls": [{"url": "https://emoclassifier.github.io/", "anchor_text": "dataset", "paragraph_index": 7}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "glove-twitter embeddings", "paragraph_index": 9}], "all_paragraphs": ["So there are various ways for sentence classification like a bag of words approach or neural networks etc. In this article, I would be discussing mainly the sentence classification task using deep learning model (specifically Bi-LSTM)", "This article mainly is concerned with some basic introduction and jumps right into implementation. If you need in-depth information, I have included the links in the references.", "I have organized the articles in various categories,", "Feel free to jump in a specific category.", "For sentence classification we have mainly two ways:", "The BOW model works by treating each word separately and encoding each of the words. For BOW approach we can use TF-IDF methods but it doesn\u2019t preserve the context of each word in the sentences.", "So to achieve better performance for the task like named entity extraction, sentiment analysis, we use deep neural networks.", "In this article I have used the Reddit -dataset[2] which is based on four emotion categories like rage, happy, gore and creepy.", "For the deep neural models, we need embeddings for the text. Embeddings capture the representation of the word in higher dimensional plane. Through embeddings, we create a vector representation of the word which is learned by understanding the context of words. We can either use pre-trained embeddings like the glove, fasttext which are trained on billion of documents or we can create our own embeddings (trained on our own corpus) using gensim package etc.", "In this article, I have used pre-trained glove-twitter embeddings which is suitable in our context of the social network data. Also, I choose 100-Dimensional embeddings which performs pretty good without taking too much time to train. You can choose other (25, 50, 300 D as well).", "So their data has four files representing four different emotions so we need to merge the files for the multi-category classification task.", "To break the sentences into simpler tokens or words we tokenize the text. In here we will be using nltk Tweet tokenizer as it works great with social network data.", "Splitting the data to training and testing", "Before getting the scores with the LSTM model I have got some metrics from our baseline models:", "For the baseline models, we can calculate simply the mean of the word2vec embeddings.", "For baselines, you can further apply other classifiers (like random forest etc)but I got the best F1 score with SVM.", "For the neural models in the language context, most popular are LSTMs (Long short term memory) which are a type of RNN (Recurrent neural network), which preserve the long term dependency of text. I have included the links in references which seem to explain LSTM\u2019s in great detail.", "For the bidirectional LSTM we have an embedding layer and instead of loading random weight we will load the weights from our glove embeddings", "We also want to calculate the vocab size for neural model.", "The max_len above have to be fixed for our neural model, which could be the sentence with max no of words or could be a static value. I defined it as 60.", "So in the paper for neral architecture for ner model [1] they use a CRF layer on top of Bi-LSTM but for simple multi categorical sentence classification, we can skip that.", "Fit the training data to the model:", "So we saw for the neural models that preserve the sequence of text and their context, we get better scores as compared BOW models but it depends on the context and application. So in some cases, it might be beneficial to have simple models as compared to complex neural models. Also, we had a smaller dataset so the training time was quite low but for larger datasets ( > 100k ), it might take more than 1 hour of training.", "Hope you enjoyed, if you have any doubts or comments please feel free to add to the comment section. Thanks.", "[1]: Lample, Guillaume, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer. \u201cNeural architectures for named entity recognition.\u201d arXiv preprint arXiv:1603.01360 (2016).", "[2] Duong, Chi Thang, Remi Lebret, and Karl Aberer. \u201cMultimodal Classification for Analysing Social Media.\u201d The 27th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), 2017", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb74151ffa565&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b74151ffa565--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b74151ffa565--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@akshayuppal3?source=post_page-----b74151ffa565--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@akshayuppal3?source=post_page-----b74151ffa565--------------------------------", "anchor_text": "akshay uppal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fab7c069437ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&user=akshay+uppal&userId=ab7c069437ca&source=post_page-ab7c069437ca----b74151ffa565---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb74151ffa565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb74151ffa565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://emoclassifier.github.io/", "anchor_text": "dataset"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "glove-twitter embeddings"}, {"url": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Understanding LSTM Networks -- colah's blogThese loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that\u2026colah.github.io"}, {"url": "https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/", "anchor_text": "How to Develop a Bidirectional LSTM For Sequence Classification in Python with KerasBidirectional LSTMs are an extension of traditional LSTMs that can improve model performance on sequence classification\u2026machinelearningmastery.com"}, {"url": "https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture", "anchor_text": "Embeddings | Machine Learning Crash Course | Google DevelopersAn embedding is a relatively low-dimensional space into which you can translate high-dimensional vectors. Embeddings\u2026developers.google.com"}, {"url": "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/", "anchor_text": "Text Classification With Word2VecIn the previous post I talked about usefulness of topic models for non-NLP tasks, it's back to NLP-land this time. I\u2026nadbordrozd.github.io"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b74151ffa565---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----b74151ffa565---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b74151ffa565---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb74151ffa565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&user=akshay+uppal&userId=ab7c069437ca&source=-----b74151ffa565---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb74151ffa565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&user=akshay+uppal&userId=ab7c069437ca&source=-----b74151ffa565---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb74151ffa565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b74151ffa565--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb74151ffa565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b74151ffa565---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b74151ffa565--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b74151ffa565--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b74151ffa565--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b74151ffa565--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b74151ffa565--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b74151ffa565--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b74151ffa565--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b74151ffa565--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@akshayuppal3?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@akshayuppal3?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "akshay uppal"}, {"url": "https://medium.com/@akshayuppal3/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "33 Followers"}, {"url": "https://www.linkedin.com/in/akshay-uppal/", "anchor_text": "https://www.linkedin.com/in/akshay-uppal/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fab7c069437ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&user=akshay+uppal&userId=ab7c069437ca&source=post_page-ab7c069437ca--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9fa7ae5df2b2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentence-classification-using-bi-lstm-b74151ffa565&newsletterV3=ab7c069437ca&newsletterV3Id=9fa7ae5df2b2&user=akshay+uppal&userId=ab7c069437ca&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}