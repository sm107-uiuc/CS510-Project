{"url": "https://towardsdatascience.com/mining-and-classifying-medical-text-documents-1876462f73bc", "time": 1683001065.940274, "path": "towardsdatascience.com/mining-and-classifying-medical-text-documents-1876462f73bc/", "webpage": {"metadata": {"title": "Mining and Classifying Medical Documents | by Georgi Ivanov | Towards Data Science", "h1": "Mining and Classifying Medical Documents", "description": "In the medical world, a lot of (digital) text documents from several specialities are generated, be it patient health records, letters, or documentation of clinical studies. In fact, text data, which\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Unstructured_data", "anchor_text": "unstructured", "paragraph_index": 0}, {"url": "http://ml-ml.herokuapp.com/", "anchor_text": "Medical Language Model Learner (MLML)", "paragraph_index": 2}, {"url": "https://www.kaggle.com/tboyle10/medicaltranscriptions", "anchor_text": "kaggle", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Linguistics", "anchor_text": "linguistics", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Computer_science", "anchor_text": "computer science", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Information_engineering_(field)", "anchor_text": "information engineering", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Artificial_intelligence", "anchor_text": "artificial intelligence", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Natural_language", "anchor_text": "natural language", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/String_(computer_science)", "anchor_text": "strings", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Seq2seq", "anchor_text": "sequence-to-sequence models", "paragraph_index": 4}, {"url": "http://An important consideration is the fact that text consists of strings, but mathematical models rely on numbers.", "anchor_text": "text-to-speech", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "recurrent neural networks", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Embedding", "anchor_text": "embeddings", "paragraph_index": 4}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "Global Vectors for Word Representation", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Latent_variable", "anchor_text": "latent variables", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model", "anchor_text": "bag-of-words", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Plain_text", "anchor_text": "text", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/N-gram", "anchor_text": "n-grams", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "term frequency-inverse document frequency", "paragraph_index": 9}, {"url": "https://link.springer.com/article/10.1007%2Fs00799-015-0156-0", "anchor_text": "83% of text-based recommender systems in digital libraries use tf\u2013idf", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Sparse_matrix", "anchor_text": "sparse matrix", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Singular_value_decomposition#Truncated_SVD", "anchor_text": "truncated singular value decomposition", "paragraph_index": 18}, {"url": "https://altair-viz.github.io/index.html", "anchor_text": "Altair", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Random_forest", "anchor_text": "random forest", "paragraph_index": 21}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "logistic regression", "paragraph_index": 21}, {"url": "https://en.wikipedia.org/wiki/Precision_and_recall", "anchor_text": "precision and recall", "paragraph_index": 25}, {"url": "https://en.wikipedia.org/wiki/F1_score", "anchor_text": "F1 score", "paragraph_index": 25}, {"url": "https://en.wikipedia.org/wiki/Confusion_matrix", "anchor_text": "confusion matrix", "paragraph_index": 25}, {"url": "http://heroku.com", "anchor_text": "Heroku", "paragraph_index": 30}, {"url": "https://git-scm.com/", "anchor_text": "git", "paragraph_index": 30}], "all_paragraphs": ["In the medical world, a lot of (digital) text documents from several specialities are generated, be it patient health records, letters, or documentation of clinical studies. In fact, text data, which is usually unstructured, contributes to the huge increase of data volume globally \u2014 social media alone. Hence, retrieving information from texts becomes a more and more important task.", "The aim of this post is two-fold:", "The final product will look like this application with the name Medical Language Model Learner (MLML). (Raw data is available on kaggle.)", "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.", "An important consideration is that text consists of strings, but mathematical models rely on numbers, and there are different ways to convert words to numeric vectors. Addtionally, there are different possibilities to model a language \u2014 depending on the problem definition. A common task is mapping sequences (e.g. text/speech in some language) from some domain to sequences in another domain (e.g. text/speech in another languague), known as sequence-to-sequence models. For instance, in order to generate speech from text (text-to-speech), recurrent neural networks together with pretrained word embeddings (for example Global Vectors for Word Representation, GloVe) are used. In that case, a word becomes a vector in a n-dimensional space, similar to data points in a space with n principal components.", "The different dimensions (also known as latent variables) can be thought as properties/attributes that describe the words, e.g. the property \u201cedible\u201d for words like bread, fruit, and apple; words like chair, car, and animal would be found on the opposite direction. Hence, \u201capple\u201d and \u201cchair\u201d would be farther apart in this dimension, but \u201capple\u201d and \u201cfruit\u201d much closer. As for the word \u201canimal\u201d, this would be somewhere in the middle, because some animals are eaten. Note that it is generally not possible to extract the meaning of the different latent variables.", "Due to these embeddings, the dimensionality is reduced compared to a 1-out-of-K encoded approach. For instance, a dictionary with K words has K dimensions in a 1-out-of-K space (every word is a vector orthogonal to all other words), but an embedding can reduce the dimension down to 100, and hence decrease computational complexity. (If K=10.000 and n=100, the compression factor is 100.)", "Pretrained embeddings can be downloaded and do not have to be constructed first. However, every possible word has to be available in the embedding already \u2014 or the embedding has to be trained first. The embeddings are context-free, i.e. the word \u201cbank\u201d is treated similar in expressions like \u201cbank account\u201d or \u201che sat on a bank\u201d.", "Alternatively, there is the possibility to ignore the sequential aspect of a language and model a text as a collection of words (bag-of-words approach). This is the most frequent representation in text mining, which is the process of deriving high-quality information from text. To describe a text in this manner, a dictionary is constructed by using the most frequent words or n-grams (raw count or normalized by the total amount of words in a text), but such a dictionary might not very discriminative as every text contains expressions like \u201ca\u201d, \u201cthe\u201d, \u201cis\u201d, and so on.", "To account for this issue, a solution called term frequency-inverse document frequency (tf-idf or TFIDF) was developed; tf-idf is a numerical statistic that is intended to reflect how important a word is to a document in a collection of documents. The tf-idf value increases proportionally to the number of times a word appears in the document and is modified by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. tf-idf is one of the most popular term-weighting schemes today; 83% of text-based recommender systems in digital libraries use tf\u2013idf.", "The term frequency (calculated for each document) is usually just the count of a specific word i (e.g. \u201ccervix\u201d) divided by the total amount of words in a text L, hence adjusting for document length.", "Inverse document frequency is obtained by calculating the inverse fraction of documents (N/ni) which contain the word i and applying a log transformation. Words that occur in almost every document will have a value close to one before the logarithmic transformation, and hence close to zero after logarithmic transformation.", "The tf-idf is defined for each word i in each document k in a collection of N documents. It is calculated by multiplying tf and idf. This way, a word i that occurs in almost every document k lowers the tf-idf value. For text mining, it does not make sense to keep words in the dictionary with low tf-idf values since they are not discriminative for a specific document class.", "Imagine a data scientist who wants to build a model that distinguishes between biological and legal documents; what words should (s)he focus on? Ubiquitous words like \u201cis\u201d or \u201ca\u201d do not help at all, but terms like \u201cprotein\u201d or \u201ccontract\u201d do \u2014 these are the interesting ones. If the model should distinguish even further between subclasses of biological documents (higher resolution), it needs to refine the dictionary. For instance, words like \u201cDNA\u201d, \u201cenzyme\u201d, or \u201cpathway\u201d are used more frequently in microbiology than in ecology, whereas the opposite is true for words like \u201cbiodiversity\u201d, \u201chabitat\u201d, or \u201cpopulation\u201d. If said higher resolution is desired, bigger dictionaries might be needed. Or, one has to be more selective in which maximum and minimum tf-idf values one wants to include in the dictionary of size D.", "The result of the tf-idf computation is a matrix with dimensions NxD, i.e. number of documents times dictionary size, filled with tf-idf values that serve as features. Note that this is likely a sparse matrix. Additionally, there are tunable parameters in the matrix construction process, and it is evident that the tf-idf transformation has some influence with respect to the model performance.", "Scikit-Learn as a built-in transformer for text documents.", "Since there are several free parameters, Streamlit can be used to build sliders to change the values and try out different combinations manually; this way, many different options can be evaluated quickly.", "The final product looks should look like this.", "One possible application is the classification of medical documents according to their medical speciality. Once the document-word matrix is constructed and the texts are transformed into mathematical representations, they can be visualized using dimensionality reduction methods, e.g. truncated singular value decomposition, and a charting library, e.g. Altair.", "The figure shows the different documents in the space of the two principal components explaining the highest variance in the original tf-idf space. It can already be seen that there is a lot of overlap between the classes \u2014 at least with the constructed dictionary \u2014 and a low classifier performance is to be expected.", "The data set contains 40 classes. However, it is not (yet) known how frequent a particular class is in the data set. For example, one can expect classes of low abundance to be misclassified more frequently in a skewed data set, so it might be reasonable to discard or merge rare classes.", "To build the text model, any algorithm for classification can be used, e.g. a random forest; compared to logistic regression, a random forest has the advantage that it can construct decision boundaries of any shape without basis expansion. To find the best random forest hyperparameters, a grid search can be performed.", "It could be again interesting to tune these hyperparameters manually. (In the current version, there is only a text input container, so one has to convert the strings to integers.)", "To interpret the model, feature importances obtained from the random forest should be evaluated after training with a bar chart.", "It can be seen that most importances are of similar magnitude. The overall performance as determined by the out-of-bag score is low (0.41). It is likely that there is too much overlap between the classes, which is supported by the dimensionality reduction.", "To evaluate the model with respect to precision and recall, F1 score and confusion matrix are computed.", "The F1 score is 0.49, so precision and/or recall are low. From the confusion matrix, one can see that the model has difficulties in distinguishing the medical documents. It seems that the used words between the documents are too similar at the moment, i.e. many identical words are used in the different medical specialities \u2014 or there are just no patterns to be found.", "Obviously, the model can now be used for prediction. In that case, a sample has to be provided as input, transformed into tf-idf format, and fed to the classifier, which will then return a probability prediction that this sample belongs to any of the classes.", "The code inside the app should look something like this:", "To test it locally, the terminal is opened and rooted to the location with the \u201capp.py\u201d file. Typing the following code start a local testing session.", "To deploy the application on a Cloud provider such as Heroku, an account and git are needed. First, a shell script with file name \u201csetup.sh\u201d and the following content is created.", "Next, a requirements.txt file is created. Its content should look like this.", "For Heroku, a so-called Procfile with the following line of code has to be written \u2014 assuming the app is called \u201capp.py\u201d. Note that the Procfile has no type specification.", "The app can be deployed in the terminal (here on a Unix/Mac operating system). For this, the shell is rooted to the director with all files.", "Next, an app on Heroku has to be created (here named \u201cmyapp\u201d). After that, a git repository is initialized in the directory with the \u201capp.py\u201d file.", "The code is commited to the repository and deployed on Heroku.", "Finally, the application should be online.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1876462f73bc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1876462f73bc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1876462f73bc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://g-ivanov.medium.com/?source=post_page-----1876462f73bc--------------------------------", "anchor_text": ""}, {"url": "https://g-ivanov.medium.com/?source=post_page-----1876462f73bc--------------------------------", "anchor_text": "Georgi Ivanov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F54224776d918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&user=Georgi+Ivanov&userId=54224776d918&source=post_page-54224776d918----1876462f73bc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1876462f73bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1876462f73bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/clinical-data-science", "anchor_text": "Clinical Data Science"}, {"url": "https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral", "anchor_text": "Annie Spratt"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Unstructured_data", "anchor_text": "unstructured"}, {"url": "https://en.wikipedia.org/wiki/Text_mining", "anchor_text": "text mining"}, {"url": "https://en.wikipedia.org/wiki/Natural_language_processing", "anchor_text": "natural languague processing (NLP)"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "Scikit-Learn"}, {"url": "https://streamlit.io/", "anchor_text": "Streamlit"}, {"url": "http://ml-ml.herokuapp.com/", "anchor_text": "Medical Language Model Learner (MLML)"}, {"url": "https://www.kaggle.com/tboyle10/medicaltranscriptions", "anchor_text": "kaggle"}, {"url": "https://en.wikipedia.org/wiki/Linguistics", "anchor_text": "linguistics"}, {"url": "https://en.wikipedia.org/wiki/Computer_science", "anchor_text": "computer science"}, {"url": "https://en.wikipedia.org/wiki/Information_engineering_(field)", "anchor_text": "information engineering"}, {"url": "https://en.wikipedia.org/wiki/Artificial_intelligence", "anchor_text": "artificial intelligence"}, {"url": "https://en.wikipedia.org/wiki/Natural_language", "anchor_text": "natural language"}, {"url": "https://en.wikipedia.org/wiki/String_(computer_science)", "anchor_text": "strings"}, {"url": "https://en.wikipedia.org/wiki/Seq2seq", "anchor_text": "sequence-to-sequence models"}, {"url": "http://An important consideration is the fact that text consists of strings, but mathematical models rely on numbers.", "anchor_text": "text-to-speech"}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "recurrent neural networks"}, {"url": "https://en.wikipedia.org/wiki/Embedding", "anchor_text": "embeddings"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "Global Vectors for Word Representation"}, {"url": "https://en.wikipedia.org/wiki/Latent_variable", "anchor_text": "latent variables"}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model", "anchor_text": "bag-of-words"}, {"url": "https://en.wikipedia.org/wiki/Plain_text", "anchor_text": "text"}, {"url": "https://en.wikipedia.org/wiki/N-gram", "anchor_text": "n-grams"}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "term frequency-inverse document frequency"}, {"url": "https://link.springer.com/article/10.1007%2Fs00799-015-0156-0", "anchor_text": "83% of text-based recommender systems in digital libraries use tf\u2013idf"}, {"url": "https://en.wikipedia.org/wiki/Sparse_matrix", "anchor_text": "sparse matrix"}, {"url": "https://en.wikipedia.org/wiki/Singular_value_decomposition#Truncated_SVD", "anchor_text": "truncated singular value decomposition"}, {"url": "https://altair-viz.github.io/index.html", "anchor_text": "Altair"}, {"url": "https://en.wikipedia.org/wiki/Random_forest", "anchor_text": "random forest"}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "logistic regression"}, {"url": "https://en.wikipedia.org/wiki/Precision_and_recall", "anchor_text": "precision and recall"}, {"url": "https://en.wikipedia.org/wiki/F1_score", "anchor_text": "F1 score"}, {"url": "https://en.wikipedia.org/wiki/Confusion_matrix", "anchor_text": "confusion matrix"}, {"url": "http://heroku.com", "anchor_text": "Heroku"}, {"url": "https://git-scm.com/", "anchor_text": "git"}, {"url": "https://unsplash.com/@cdr6934?utm_source=medium&utm_medium=referral", "anchor_text": "Chris Ried"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1876462f73bc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1876462f73bc---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/health?source=post_page-----1876462f73bc---------------health-----------------", "anchor_text": "Health"}, {"url": "https://medium.com/tag/visualization?source=post_page-----1876462f73bc---------------visualization-----------------", "anchor_text": "Visualization"}, {"url": "https://medium.com/tag/clinical-data-science?source=post_page-----1876462f73bc---------------clinical_data_science-----------------", "anchor_text": "Clinical Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1876462f73bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&user=Georgi+Ivanov&userId=54224776d918&source=-----1876462f73bc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1876462f73bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&user=Georgi+Ivanov&userId=54224776d918&source=-----1876462f73bc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1876462f73bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1876462f73bc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1876462f73bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1876462f73bc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1876462f73bc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1876462f73bc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1876462f73bc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1876462f73bc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1876462f73bc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1876462f73bc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1876462f73bc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1876462f73bc--------------------------------", "anchor_text": ""}, {"url": "https://g-ivanov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://g-ivanov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Georgi Ivanov"}, {"url": "https://g-ivanov.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "325 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F54224776d918&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&user=Georgi+Ivanov&userId=54224776d918&source=post_page-54224776d918--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4e7dcd411990&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmining-and-classifying-medical-text-documents-1876462f73bc&newsletterV3=54224776d918&newsletterV3Id=4e7dcd411990&user=Georgi+Ivanov&userId=54224776d918&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}