{"url": "https://towardsdatascience.com/an-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a", "time": 1683001784.743145, "path": "towardsdatascience.com/an-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a/", "webpage": {"metadata": {"title": "An overview of model explainability in modern machine learning | by Rui Aguiar | Towards Data Science", "h1": "An overview of model explainability in modern machine learning", "description": "How we can understand black box machine learning models, and why it matters"}, "outgoing_paragraph_urls": [{"url": "https://scikit-learn.org/stable/modules/partial_dependence.html", "anchor_text": "Here\u2019s an implementation with with scikit-learn", "paragraph_index": 12}, {"url": "https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html", "anchor_text": "Here\u2019s an implementation with the eli5 model in Python.", "paragraph_index": 22}, {"url": "https://github.com/blent-ai/ALEPython", "anchor_text": "Here\u2019s a library that provides an ALE implementation.", "paragraph_index": 38}, {"url": "http://savvastjortjoglou.com/intrepretable-machine-learning-nfl-combine.html", "anchor_text": "Here\u2019s an overview of interpretability with an ICE implementation.", "paragraph_index": 47}, {"url": "http://savvastjortjoglou.com/intrepretable-machine-learning-nfl-combine.html", "anchor_text": "Here\u2019s an overview of interpretability with a surrogate model implementation.", "paragraph_index": 59}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Interpretable Machine Learning", "paragraph_index": 65}], "all_paragraphs": ["Model explainability is one of the most important problems in machine learning today. It\u2019s often the case that certain \u201cblack box\u201d models such as deep neural networks are deployed to production and are running critical systems from everything in your workplace security cameras to your smartphone. It\u2019s a scary thought that not even the developers of these algorithms understand why exactly the algorithms make the decisions they do \u2014 or even worse, how to prevent an adversary from exploiting them.", "While there are many challenges facing the designer of a \u201cblack box\u201d algorithm, it\u2019s not completely hopeless. There are actually many different ways to illuminate the decisions a model makes. It\u2019s even possible to understand which features are the most salient in a model\u2019s predictions.", "In this article, I give a comprehensive overview of model explainability for deeper models in machine learning. I hope to explain how deeper models more traditionally considered \u201cblack boxes\u201d can actually be surprisingly explainable. We use model-agnostic methods to apply interpretability to all different kinds of black box models.", "A partial dependence plot shows the effect of a feature on the outcome of a ML model.", "Partial dependence works by marginalizing the machine learning model output over the distribution of the features we are not interested in (denoted by features in set C). This makes it such that the partial dependence function shows the relationship between the features we do care about (which we denote by buying in set S) and the predicted outcome. By marginalizing over the other features, we get a function that depends only on features in S. This makes it easy to understand how varying a specific feature influences model predictions. For example, here are 3 PDP plots for Temperature, Humidity and Wind Speed as relating to predicted bike sales by a linear model.", "PDP\u2019s can even be used for categorical features. Here\u2019s one for the effect of season on bike rental.", "For classification, the partial dependence plot displays the probability for a certain class given different values for features. A good way to deal with multi-class problems is to have one PDP per class.", "The partial dependence plot method is useful because it is global. It makes a point about the global relationship between a certain feature and a target outcome across all values of that feature.", "Partial Dependence Plots are highly intuitive. The partial dependence function for a feature at a value represents the average prediction if we have all data points assume that feature value.", "You can really only model a maximum of two features using the partial dependence function.", "Assumption of independence: You are assuming the features that you are plotting are not correlated with any other features. For example, if you are predicting blood pressure off of height and weight, you have to assume that height is not correlated with weight. The reason this is the case is that you have to average over the marginal distribution of weight if you are plotting height (or vice-versa). This means, for example, that you can have very small weights for someone who is quite tall, which you probably not see in your actual dataset.", "Great! I want to implement a PDP for my model. Where do I start?", "Here\u2019s an implementation with with scikit-learn.", "Permutation feature importance is a way to measure the importance of a feature by calculating change in a model\u2019s prediction error after permuting the feature. A feature is \u201cimportant\u201d if permuting its values increases the model error, and \u201cunimportant\u201d if permuting the values leaves the model error unchanged.", "After you have sorted the features by descending FI, you can plot the results. Here is the permutation feature importance plot for the bike rentals problem.", "Interpretability: Feature importance is just how much the error increases when a feature is distorted. This is easy to explain and visualize.", "Permutation feature importance provides global insight into the model\u2019s behavior.", "Permutation feature importance does not require training a new model or retraining an existing model, simply shuffling features around.", "It\u2019s not clear whether you should use training or test data for your plot.", "If features are correlated, you can get unrealistic samples after permuting features, biasing the outcome.", "Adding a correlated feature to your model can decrease the importance of another feature.", "Great! I want to implement Permutation Feature Importance for my model. Where do I start?", "Here\u2019s an implementation with the eli5 model in Python.", "ALE plots are a faster and unbiased alternative to partial dependence plots. They measure how features influence the prediction of a model. Because they are unbiased, they handle correlated features much better than PDP\u2019s do.", "If features of a machine learning model are correlated, the partial dependence plot cannot be trusted, because you can generate samples that are very unlikely in reality by varying a single feature. ALE plots solve this problem by calculating \u2013 also based on the conditional distribution of the features \u2013 differences in predictions instead of averages. One way to interpret this is by thinking of the ALE as saying", "\u201cLet me show you how the model predictions change in a small \u201cwindow\u201d of the feature.\u201d", "Here\u2019s a visual interpretation of what is going on in an ALE plot.", "This can also be done with two features.", "Once you have computed the differences in predictions over each window, you can generate an ALE plot.", "ALE plots can also be done for categorical features.", "ALE plots are unbiased, meaning they work with correlated features.", "ALE plots are computationally fast to compute.", "The interpretation of the ALE plot is clear.", "The implementation of ALE plots is complicated and difficult to understand.", "Interpretation still remains difficult if features are strongly correlated.", "Second-order or 2D ALE plots can be hard to interpret.", "Generally, it is better to use ALE\u2019s over PDP\u2019s, especially if you expect correlated features.", "Great! I want to implement ALE\u2019s for my model. Where do I start?", "Here\u2019s a library that provides an ALE implementation.", "Individual Conditional Expectation (ICE) plots display one line per data point. It produces a plot that shows how the model\u2019s prediction for a data point changes as a feature varies across all data points in a set. For the plot below, you can see the ICE plots for varying temperature, humidity and wind speed across all instances in the training set bike rental data.", "Looking at this plot, you may ask yourself: what is the point of looking at an ICE plot instead of a PDP? It seems much less interpretable.", "PDPs can only show you what the average relationship between what a feature and a prediction looks like. This only works well if the interactions between the features for which the PDP is calculated and the other features are uncorrelated, but in the case of strong, correlated interactions, the ICE plot will be more insightful.", "Like PDP plots, ICE plots are very intuitive to understand.", "ICE plots can uncover heterogeneous relationships better than PDP plots can.", "ICE curves can only display one feature at a time.", "The plots generated by this method can be hard to read and overcrowded.", "Great! I want to implement ICE for my model. Where do I start?", "Here\u2019s an overview of interpretability with an ICE implementation.", "A surrogate model is an interpretable model (such as a decision tree or linear model) that is trained to approximate the predictions of a black box. We can understand the black box better by interpreting the surrogate model\u2019s decisions.", "The algorithm for generating a surrogate model is straightforward.", "One way to measure how well the surrogate replicates the black box through the R-squared metric:", "The R-squared metric is a way to measure the variance captured by the surrogate model. An R-squared value close to 1 implies the surrogate model captures the variance well, and close to 0 implies that it is capturing very little variance, and not explaining the black box model well.", "This approach is intuitive: you are learning what the black box model thinks is important by approximating it.", "Easy to measure: It\u2019s clear how well the interpretable model performs in approximating the black box through the R-squared metric.", "The linear model may not approximate the black box model well.", "You are drawing conclusions about the black box model and not the actual data, as you are using the black box\u2019s model predictions as labels without seeing the ground truth.", "Even if you do approximate the black box model well, the explainability of the \u201cinterpretable\u201d model may not actually represent what the black box model has learned.", "It may be difficult to explain the interpretable model.", "Great! I want to implement a surrogate model.Where do I start?", "Here\u2019s an overview of interpretability with a surrogate model implementation.", "As machine learning becomes more prominent in daily life, the future of interpretability is more important than ever before. I believe a few trends will categorize the future of interpretability, and this will shape how we interact with AI models in the future.", "All the trends in deep learning research point to the fact that deep networks are not saturating with our current computing and data limits. It\u2019s important to realize that as our models get deeper and deeper in everything from image recognition to text generation, there is a need for methods that can provide interpretability across all types of models. The generalizability aspect will become more and more useful the more machine learning takes a hold in different fields. The methods I discussed in this blog post are a start, but we need to take interpretability more seriously as a whole to better understand why the machine learning systems powering our day-to-day are making the decisions they do.", "One trend that I have not seen take hold in most ML systems that I believe will exist in the future is the idea of a self-explainable model. Most systems today simply make a decision with reasons that are opaque to the user. In the future, I believe that will change. If a self-driving car makes a decision to stop, we will know why. If Alexa cannot understand our sentence, it will tell us in specific detail what went wrong and how we can phrase our query more clearly. With models that explain themselves, we can better understand how the ML systems in our lives work.", "Finally, I believe that we as a society have pushed black-box model scrutiny under the rug. We do not understand the decisions that our models are making, and that doesn\u2019t seem to be bothering anyone in particular. This will have to change in the future. Engineers and Data Scientists will be held accountable as models start to make mistakes, and this will lead to a trend where we examine the decisions our model makes with the same rigor we would a dataset that the model is trained on.", "I hope you enjoyed this post. I certainly found it illuminating to write, and I hope it helps you with your studies or research in the field of machine learning.", "Most of the examples here inspired from the excellent Interpretable Machine Learning book.", "(Molnar, Christoph. \u201cInterpretable machine learning. A Guide for Making Black Box Models Explainable\u201d, 2019. https://christophm.github.io/interpretable-ml-book/)", "I highly encourage you to buy it if you wish to further your knowledge in the topic.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Interested in technology, humans and the hard problems in life."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffc0f22c8c29a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@raguiar2?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@raguiar2?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "Rui Aguiar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F82e0b7141d5c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&user=Rui+Aguiar&userId=82e0b7141d5c&source=post_page-82e0b7141d5c----fc0f22c8c29a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc0f22c8c29a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc0f22c8c29a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@cdr6934?utm_source=medium&utm_medium=referral", "anchor_text": "Chris Ried"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://scikit-learn.org/stable/modules/partial_dependence.html", "anchor_text": "Here\u2019s an implementation with with scikit-learn"}, {"url": "https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html", "anchor_text": "Here\u2019s an implementation with the eli5 model in Python."}, {"url": "https://github.com/blent-ai/ALEPython", "anchor_text": "Here\u2019s a library that provides an ALE implementation."}, {"url": "http://savvastjortjoglou.com/intrepretable-machine-learning-nfl-combine.html", "anchor_text": "Here\u2019s an overview of interpretability with an ICE implementation."}, {"url": "http://savvastjortjoglou.com/intrepretable-machine-learning-nfl-combine.html", "anchor_text": "Here\u2019s an overview of interpretability with a surrogate model implementation."}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Interpretable Machine Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----fc0f22c8c29a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/black-box?source=post_page-----fc0f22c8c29a---------------black_box-----------------", "anchor_text": "Black Box"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----fc0f22c8c29a---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----fc0f22c8c29a---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----fc0f22c8c29a---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc0f22c8c29a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&user=Rui+Aguiar&userId=82e0b7141d5c&source=-----fc0f22c8c29a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc0f22c8c29a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&user=Rui+Aguiar&userId=82e0b7141d5c&source=-----fc0f22c8c29a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc0f22c8c29a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffc0f22c8c29a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fc0f22c8c29a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fc0f22c8c29a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@raguiar2?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@raguiar2?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rui Aguiar"}, {"url": "https://medium.com/@raguiar2/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "68 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F82e0b7141d5c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&user=Rui+Aguiar&userId=82e0b7141d5c&source=post_page-82e0b7141d5c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F82e0b7141d5c%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a&user=Rui+Aguiar&userId=82e0b7141d5c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}