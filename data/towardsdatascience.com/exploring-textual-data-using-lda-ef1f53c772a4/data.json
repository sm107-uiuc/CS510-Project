{"url": "https://towardsdatascience.com/exploring-textual-data-using-lda-ef1f53c772a4", "time": 1683001460.698542, "path": "towardsdatascience.com/exploring-textual-data-using-lda-ef1f53c772a4/", "webpage": {"metadata": {"title": "Exploring Textual Data using LDA. Introduction | by emakpati | Towards Data Science", "h1": "Exploring Textual Data using LDA", "description": "I recently completed my first machine learning project at work and decided to apply the methods used in that project to a project of my own. The project I completed at work revolved around\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation", "anchor_text": "Latent Dirichlet Allocation", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/N-gram", "anchor_text": "n-grams", "paragraph_index": 2}, {"url": "https://www.independent.co.uk/news/world/europe/beluga-whale-catch-hvaldimir-russian-spy-programme-video-a9197106.html", "anchor_text": "very smart aquatic mammal", "paragraph_index": 2}, {"url": "https://pyldavis.readthedocs.io/en/latest/", "anchor_text": "pyLDAvis", "paragraph_index": 3}, {"url": "https://www.nltk.org", "anchor_text": "nltk", "paragraph_index": 4}, {"url": "https://pypi.org/project/gensim/", "anchor_text": "gensim", "paragraph_index": 4}, {"url": "https://pyldavis.readthedocs.io/en/latest/", "anchor_text": "pyLDAvis", "paragraph_index": 4}, {"url": "https://drive.google.com/drive/folders/1ebI3pEkrz3JbyF_aZF4DVPX2LSG1hVn_?usp=sharing", "anchor_text": "here", "paragraph_index": 7}, {"url": "http://tweepy.readthedocs.org", "anchor_text": "tweepy API", "paragraph_index": 8}, {"url": "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html", "anchor_text": "lemmatize and stem", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Stochastic_process", "anchor_text": "stochastic process", "paragraph_index": 14}, {"url": "https://www.geeksforgeeks.org/python-lemmatization-with-nltk/", "anchor_text": "examples", "paragraph_index": 19}, {"url": "https://www.geeksforgeeks.org/python-stemming-words-with-nltk/", "anchor_text": "examples", "paragraph_index": 19}, {"url": "https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.filter_extremes", "anchor_text": "gensim\u2019s dictionary documentation", "paragraph_index": 24}, {"url": "https://twitter.com/cenkuygur", "anchor_text": "Cenk Uygur", "paragraph_index": 29}, {"url": "https://twitter.com/AnaKasparian", "anchor_text": "Ana Kasparian", "paragraph_index": 29}, {"url": "https://tyt.com", "anchor_text": "The Young Turks", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Saugus_High_School_shooting", "anchor_text": "school shooting at Saugus High School", "paragraph_index": 30}, {"url": "https://www.cnn.com/2019/11/14/us/california-school-shooting/index.html", "anchor_text": "media coverage", "paragraph_index": 30}, {"url": "https://join.tyt.com/nevernra/", "anchor_text": "campaign called #NeverNRA", "paragraph_index": 30}, {"url": "https://youtu.be/m4mspXXNiqg", "anchor_text": "public endorsement", "paragraph_index": 33}, {"url": "https://twitter.com/BernieSanders/status/1194415544214196224", "anchor_text": "publicly thanked them for the endorsement", "paragraph_index": 33}, {"url": "http://qpleple.com/topic-coherence-to-evaluate-topic-models/", "anchor_text": "coherence scores", "paragraph_index": 36}, {"url": "https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/", "anchor_text": "article", "paragraph_index": 37}, {"url": "https://stackoverflow.com/questions/54762690/coherence-score-0-4-is-good-or-bad", "anchor_text": "thread", "paragraph_index": 37}], "all_paragraphs": ["I recently completed my first machine learning project at work and decided to apply the methods used in that project to a project of my own. The project I completed at work revolved around automatically classifying textual data using Latent Dirichlet Allocation (LDA).", "LDA is an unsupervised machine learning model in the natural language processing arena. Because of its unsupervised nature, LDA does not require a labelled training set. This makes it ideal for certain use cases or when large, labelled textual data-sets are not readily available.", "LDA is used chiefly for topic modeling, clustering text documents by similarity. Document size can range from as small as a single word (not ideal) to as large as an entire publication. The content of the LDA clusters is determined using the terms (words) in each document and the frequency, and sometimes even order (using n-grams), in which they appear. Documents that are deemed similar to each other are clustered together and we assume that each cluster is representative of a topic, although we do not know per se what that topic is until after the cluster has been created. It\u2019s important to point out that the model understands neither the content nor context of the documents in these clusters and therefore cannot actually give the clusters a topic label. It instead \u201clabels\u201d each cluster using an index integer from (0, n); n being the number of topics we tell the model to look for. A human, or very smart aquatic mammal, is required to analyze the clusters and determine how each cluster should be labeled.", "In this post, we\u2019ll clean some Twitter data and write an LDA model to cluster that data. We\u2019ll then use pyLDAvis to generate an interactive visualization of the clusters.", "Key dependencies: pandas, nltk, gensim, numpy, pyLDAvis", "Here are some definitions to be familiar with beforehand:", "Earlier this year, I began collecting a couple hundred thousand political tweets, the end goal being to run various analyses on the tweets and their metadata leading up to the 2020 U.S. presidential election.", "This post\u2019s dataset will consist of 3,500 tweets that mention at least one of the following: \u201c@berniesanders\u201d, \u201c@kamalaharris\u201d, \u201c@joebiden\u201d, \u201c@ewarren\u201d (the Twitter handles for Bernie Sanders, Kamala Harris, Joe Biden, and Elizabeth Warren respectively). I collected these tweets in early November 2019 and have made them available for download here. We\u2019ll explore this data and attempt to figure out what people were tweeting about in early November.", "I won\u2019t delve into how to collect the tweets but I\u2019ve included the code I used below. Successfully running the code requires access to the tweepy API. I did not collect retweets, nor did I collect tweets that were not written in English (the model requires much more tuning to accommodate for multiple languages).", "This passes the tweet text data along with its metadata (id, created date, name, username, follower count, and location) to a csv named tweet_data.", "Now that we have our data packed into a neat csv we can begin prepping the data for our LDA machine learning model. Text data is typically considered unstructured, and requires cleaning before meaningful analysis can be conducted. Tweets are particularly messy due to their inconsistent nature. For example, any given Twitter user may tweet in full sentences one day and then single words and hashtags the next. Another user may only tweet links, and another user may only tweet hashtags. On top of that, there are grammatical and spelling errors that users may overlook intentionally. There are also terms that are used colloquially that would not appear in a standard English dictionary.", "We\u2019ll remove all punctuation marks, special characters and url links and then apply lower() to each tweet. This brings some level of consistency to our documents (remember each tweet is treated as a document). I\u2019ve also removed instances of \u201cberniesanders\u201d, \u201ckamalaharris\u201d, \u201cjoebiden\u201d, and \u201cewarren\u201d as they will skew our term frequencies since each document will contain at least one of these items.", "Below are the packages we need to import to prepare our data before feeding it to our model. I\u2019ll include these imports when writing the code for the data prep as well.", "We\u2019ve already cleaned our documents a bit, but now we need to lemmatize and stem them. Lemmatization converts the words in our documents to first person and converts all verbs to present tense. Stemming returns the words in our documents to their root format. Luckily, nltk has both a lemmatizer and a stemmer that we can leverage.", "LDA involves a stochastic process, meaning our model requires the ability to produce random variables, hence the numpy import. Adding numpy.random.seed(0) allows our model to be reproducible as it will generate and use the same random variables instead of generating new ones every time the code is run.", "Gensim\u2019s STOPWORDS is a list of terms deemed irrelevant or likely to fuddle our bag-of-words. In NLP, \u201cstopwords\u201d refers to a collection of terms we do not want our model to pick up. This list will be used to remove these irrelevant terms from our documents. We can print(stopwords) to view the terms that will be removed.", "Here are the terms in stopwords.", "For this model, we\u2019ll leave the stopwords list untouched but in some cases, it may be necessary to add specific terms we want our model to ignore. The below code is one way to add terms to stopwords.", "Let\u2019s write some code for our data prep.", "Write a function that will both lemmatize and stem our documents. GeeksforGeeks has examples regarding using nltk for lemmatizing and examples regarding using nltk for stemming.", "Write a function that will remove stopwords from our documents while also applying lemm_stemm().", "Assign our cleaned and prepared documents to a new variable.", "Now that we\u2019ve prepared our data, we can begin writing our model.", "As mentioned in the Introduction, a dictionary (in LDA) is a list of all unique terms that occur throughout our collection of documents. We\u2019ll be going with gensim\u2019s corpora package to construct our dictionary.", "The filter_extremes() parameters serves as a second line of defense against stopwords or other commonly-used terms that add little substance to the meaning of a sentence. Playing around with these parameters can help fine-tune the model. I won\u2019t go into detail regarding this but have included the screenshot below from gensim\u2019s dictionary documentation explaining the parameters.", "Our dictionary has 972 unique tokens (terms).", "As stated in the Introduction, a bag-of-words (in LDA) is a collection of all our documents broken down into matrices. Matrices consist of a term\u2019s identifier and the number of times it occurs in the document.", "Let\u2019s see how our clusters are forming by looking at the key terms that define them.", "Looking at each topic cluster we can get an idea of what they represent. Take a look at Topic 1 and Topic 4.", "Regarding Topic 1: In Topic 1, the key terms \u201ccenkuygur\u201d and \u201canakasparian\u201d refer to Cenk Uygur and Ana Kasparian, co-hosts of The Young Turks (a political commentary firm and show). Topic 1 also includes the key terms \u201cright\u201d, \u201ctrump\u201d, and \u201cnra\u201d.", "On November 15, there was a school shooting at Saugus High School near Santa Clarita, California. There was significant media coverage and online buzz regarding this tragic event. The Young Turks (TYT) is a vocal proponent of stricter gun laws and regularly butts heads with the NRA and other gun-groups. TYT has even spearheaded a pledge campaign called #NeverNRA.", "This topic cluster can be labelled as \u201cTYT vs the NRA\u201d, or something similar.", "Regarding Topic 4: The terms \u201ccenkuygur\u201d and \u201canakasparian\u201d are repeated in Topic 4. Topic 4 also includes \u201ctheyoungturk\u201d, referring to The Young Turks, and \u201cberni\u201d, referring to Bernie Sanders.", "On November 12, Cenk Uygur put out a public endorsement for candidate Bernie Sanders. This endorsement was repeated by TYT\u2019s Twitter account. Bernie Sanders then publicly thanked them for the endorsement. Also, on November 14, Mr. Uygur announced he was running for Congress. Both these developments garnered notable attention on Twitter.", "This topic cluster can be labelled as \u201cTYT & Bernie Sanders\u201d, or something similar.", "There are similar explanations for the other topic clusters as well.", "Most good machine learning models and applications have a feedback loop. This is a way to evaluate the model\u2019s performance, scalability, and overall quality. In the topic modeling space, we use coherence scores to determine how \u201ccoherent\u201d our model is. As I mentioned in the Introduction, coherence is a float value between 0 and 1. We\u2019ll use gensim for this as well.", "We\u2019ve received a coherence score of 0.44. This isn\u2019t the best, but actually isn\u2019t too bad. This score was achieved without any fine-tuning. Really digging into our parameters and testing outcomes should yield a higher score. There really isn\u2019t an official threshold for scoring. My coherence score goal is typically around a 0.65. See this article and this Stack Overflow thread for more on coherence scoring.", "Lastly, we can visualize our clusters using pyLDAvis. This package creates a distance map of clusters with the clusters plotted along an x and y axis. This distance map can be opened in Jupiter by calling pyLDAvis.display() but can also be opened in the web by calling pyLDAvis.show().", "Here is a screenshot of our pyLDAvis distance map.", "Hovering over each cluster brings up the relevance of the key terms within that cluster (in red) and the relevance of those same key terms across the entire collection of documents (in blue). This is an effective way of displaying findings to stakeholders.", "Here\u2019s all the code I used above, including the code I used to generate the word cloud and the code I used to collect the tweet data.", "LDA is a great model for exploring textual data although it requires a good amount of optimization (depending on use-case) to be used in production. The gensim, nltk, and pyLDAvis packages are priceless when writing, evaluating, and displaying models.", "Thanks a bunch for allowing me to share, more to come. \ud83d\ude03", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data and things that stand out"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fef1f53c772a4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://emakpati.medium.com/?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": ""}, {"url": "https://emakpati.medium.com/?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "emakpati"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F29ff62f2d2b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&user=emakpati&userId=29ff62f2d2b0&source=post_page-29ff62f2d2b0----ef1f53c772a4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fef1f53c772a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fef1f53c772a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation", "anchor_text": "Latent Dirichlet Allocation"}, {"url": "https://en.wikipedia.org/wiki/N-gram", "anchor_text": "n-grams"}, {"url": "https://www.independent.co.uk/news/world/europe/beluga-whale-catch-hvaldimir-russian-spy-programme-video-a9197106.html", "anchor_text": "very smart aquatic mammal"}, {"url": "https://pyldavis.readthedocs.io/en/latest/", "anchor_text": "pyLDAvis"}, {"url": "https://www.nltk.org", "anchor_text": "nltk"}, {"url": "https://pypi.org/project/gensim/", "anchor_text": "gensim"}, {"url": "https://pyldavis.readthedocs.io/en/latest/", "anchor_text": "pyLDAvis"}, {"url": "https://radimrehurek.com/gensim/corpora/dictionary.html", "anchor_text": "dictionary"}, {"url": "https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/", "anchor_text": "bag-of-words"}, {"url": "https://kite.com/python/docs/gensim.corpora.Dictionary.doc2bow", "anchor_text": "doc2bow"}, {"url": "https://drive.google.com/drive/folders/1ebI3pEkrz3JbyF_aZF4DVPX2LSG1hVn_?usp=sharing", "anchor_text": "here"}, {"url": "http://tweepy.readthedocs.org", "anchor_text": "tweepy API"}, {"url": "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html", "anchor_text": "lemmatize and stem"}, {"url": "https://en.wikipedia.org/wiki/Stochastic_process", "anchor_text": "stochastic process"}, {"url": "https://www.geeksforgeeks.org/python-lemmatization-with-nltk/", "anchor_text": "examples"}, {"url": "https://www.geeksforgeeks.org/python-stemming-words-with-nltk/", "anchor_text": "examples"}, {"url": "https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.filter_extremes", "anchor_text": "gensim\u2019s dictionary documentation"}, {"url": "https://twitter.com/cenkuygur", "anchor_text": "Cenk Uygur"}, {"url": "https://twitter.com/AnaKasparian", "anchor_text": "Ana Kasparian"}, {"url": "https://tyt.com", "anchor_text": "The Young Turks"}, {"url": "https://en.wikipedia.org/wiki/Saugus_High_School_shooting", "anchor_text": "school shooting at Saugus High School"}, {"url": "https://www.cnn.com/2019/11/14/us/california-school-shooting/index.html", "anchor_text": "media coverage"}, {"url": "https://join.tyt.com/nevernra/", "anchor_text": "campaign called #NeverNRA"}, {"url": "https://youtu.be/m4mspXXNiqg", "anchor_text": "public endorsement"}, {"url": "https://twitter.com/BernieSanders/status/1194415544214196224", "anchor_text": "publicly thanked them for the endorsement"}, {"url": "http://qpleple.com/topic-coherence-to-evaluate-topic-models/", "anchor_text": "coherence scores"}, {"url": "https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/", "anchor_text": "article"}, {"url": "https://stackoverflow.com/questions/54762690/coherence-score-0-4-is-good-or-bad", "anchor_text": "thread"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ef1f53c772a4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----ef1f53c772a4---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/text-analytics?source=post_page-----ef1f53c772a4---------------text_analytics-----------------", "anchor_text": "Text Analytics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ef1f53c772a4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----ef1f53c772a4---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fef1f53c772a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&user=emakpati&userId=29ff62f2d2b0&source=-----ef1f53c772a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fef1f53c772a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&user=emakpati&userId=29ff62f2d2b0&source=-----ef1f53c772a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fef1f53c772a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fef1f53c772a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ef1f53c772a4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ef1f53c772a4--------------------------------", "anchor_text": ""}, {"url": "https://emakpati.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://emakpati.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "emakpati"}, {"url": "https://emakpati.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "32 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F29ff62f2d2b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&user=emakpati&userId=29ff62f2d2b0&source=post_page-29ff62f2d2b0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcd34fa355e20&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-textual-data-using-lda-ef1f53c772a4&newsletterV3=29ff62f2d2b0&newsletterV3Id=cd34fa355e20&user=emakpati&userId=29ff62f2d2b0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}