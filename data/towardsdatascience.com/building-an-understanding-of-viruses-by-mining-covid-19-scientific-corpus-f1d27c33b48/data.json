{"url": "https://towardsdatascience.com/building-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48", "time": 1683014039.9349551, "path": "towardsdatascience.com/building-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48/", "webpage": {"metadata": {"title": "Building an understanding of viruses by mining COVID-19 scientific corpus | by Tom Drabas | Towards Data Science", "h1": "Building an understanding of viruses by mining COVID-19 scientific corpus", "description": "This series is an attempt to better the understanding of COVID-19 by building a deep learning BERT-EM-SOM model on coronavirus scientific papers corpus."}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge", "anchor_text": "Kaggle competition", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/building-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-bdd7427d6a8a", "anchor_text": "this series", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/building-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-bdd7427d6a8a", "anchor_text": "post that announced this series", "paragraph_index": 2}, {"url": "https://rapids.ai", "anchor_text": "NVIDIA RAPIDS", "paragraph_index": 6}, {"url": "https://blazingsql.com", "anchor_text": "BlazingSQL", "paragraph_index": 6}, {"url": "https://www.nvidia.com/en-us/deep-learning-ai/products/titan-rtx/", "anchor_text": "TITAN RTX", "paragraph_index": 6}, {"url": "https://www.lenovo.com/us/en/laptops/thinkpad/thinkpad-p/P53/p/22WS2WPWP53", "anchor_text": "Lenovo P53 Mobile Workstation with NVIDIA Quadro RTX 5000 GPU", "paragraph_index": 6}, {"url": "https://github.com/drabastomek/rapids-notebooks", "anchor_text": "github", "paragraph_index": 8}, {"url": "https://www.linkedin.com/posts/tomekd_blazingsql-notebooks-private-preview-activity-6710308422451126272-wXCb", "anchor_text": "https://www.linkedin.com/posts/tomekd_blazingsql-notebooks-private-preview-activity-6710308422451126272-wXCb", "paragraph_index": 15}, {"url": "https://www.cdc.gov/sars/about/fs-sars.html", "anchor_text": "SARS pandemic", "paragraph_index": 20}, {"url": "https://docs.rapids.ai/api/cudf/stable/api.html#cudf.core.column.string.StringMethods.subword_tokenize", "anchor_text": "subword_tokenizer", "paragraph_index": 39}, {"url": "https://app.blazingsql.com/", "anchor_text": "https://app.blazingsql.com/", "paragraph_index": 40}], "all_paragraphs": ["At the time I publish this, we are entering the 9th month since COVID-19 froze the world. Since early January we all experienced it differently: some of us were lucky and got locked up in our houses, able to do our work remotely and live relatively unchanged lives, some of us were left without such luxury, some, sadly, passed away.", "Coronaviruses have been around for decades but few to none such deadly and easily spreading as the COVID-19 thus far. Earlier this year, Allen Institute for AI (AI2) and a consortium of research institutes along with the White House curated a corpus of scientific papers on coronaviruses published since 19th century and offered a Kaggle competition to analyze it and answer some questions about different aspects of the virus, like how it spreads, or how it affects living organisms.", "And while I did not directly compete in the challenge itself, this series is an attempt to better the understanding of the coronaviruses by building a deep learning BERT-EM-SOM model (BERT EMbedding layer tied to a Self-Organizing Map). As mentioned in the post that announced this series, in this installment we will focus on understanding the papers\u2019 corpus and will clean the metadata so we can work off of a clean base.", "The data can be downloaded from the AI2 S3 repository that is being refreshed almost daily. The code snippet below downloads the data and extracts it into the data directory.", "In this example we\u2019re using the dataset published on 8/24/2020. Reading the metadata from this day shows that there should be 233,539 papers discussing topics related to coronaviruses. We will test the hypothesis that the dataset is clean i.e. all the 233,539 are found in the JSON files that are part of the archive, we do not have any duplicates and there are no missing information.", "But first things first \u2014 let\u2019s get familiar with the basics about the dataset.", "In the remainder of this story we will be switching routinely between using native cuDF from NVIDIA RAPIDS and SQL using BlazingSQL. Most of the time I am using TITAN RTX card. However, I was lucky to still being in the possession of the loaner Lenovo P53 Mobile Workstation with NVIDIA Quadro RTX 5000 GPU so when I was recently camping with my kids (properly socially distanced and wearing masks!) I was still able to work on this story. It is another fantastic piece of hardware that I highly recommend for all the GPU enthusiasts who want to use RAPIDS, BlazingSQL or CUDA while traveling or presenting work to a client or a friend. Just look at this beauty!", "As a full disclosure \u2014 this article is not sponsored nor am I being paid by either NVIDIA or Lenovo \u2014 I am simply testing the gear they were kind enough to loan to me for this research. And for this I am super grateful!", "All the code in this and my other stories can be found on github.", "There are 19 columns in the metadata.csv file; an example you can see below.", "Most of the columns are IDs like cord_uid, or doi among others. However, of the more interesting to us, we will focus on", "First, let\u2019s check what were the most common sources the researchers from AI2 collected these articles from.", "The above snippet simply takes the metadata cuDF DataFrame, groups by the source_x column, and prints out a table.", "So, most often the source was WHO, followed by Medline and PMC. Next we see articles distributed thru Elsevier, MedRxiv, ArXiv and BioRxiv. These would account for the majority of all the papers in the corpus.", "As an aside, the same table could be created with SQL using BlazingSQL.", "This shows the beauty of the RAPIDS ecosystem: if you are familiar with pandas or SQL \u2014 you have all the tools you need to unleash the enormous power of GPUs on your data and not even think twice (as you won\u2019t have time to\u2026 see this: https://www.linkedin.com/posts/tomekd_blazingsql-notebooks-private-preview-activity-6710308422451126272-wXCb!).", "Let\u2019s now check where the papers were published.", "So, many of the articles were pre-published on the bioRxiv, but we also see a lot of them in the BMJ, PLoS One, Journal of Virology, Lancet and Nature. In other words \u2014 as expected.", "Alright, how about time? Let\u2019s see when the papers were published.", "The above snippet produces the following chart.", "Interestingly but not unsurprisingly, the is an uptick in the number of papers published around 2002/2003 as this is most likely related to the SARS pandemic.", "You may wonder why I excluded 2020\u2026 Well, I initially had it on the chart but it was literally dwarfing the rest of the time series. I think the below chart should explain why.", "The total number of papers published and reported as part of this corpus since 1816 till 2019 (inclusive) was around 90 thousands. In the almost 9 months of 2020 the world researchers published over 140 thousand papers and other information on coronaviruses. Hence I decided that excluding the count of reported papers for the 2020 would make the time series chart above more legible.", "It is now time for us to have a look at the data itself. What I like to do first to any dataset is to check for the missing observations.", "Every dataset has some. These can be simple omissions or telemetry issues (we can then either impute or remove them) or it can be, what I call, a valid missing value i.e. a value that simply should not be there. An example of a valid missing observation would be, in this particular dataset, and arxiv_id when the paper was not published on ArXiv.", "It is quite easy to create a table with the percentage of missing values using SQL. Here\u2019s how I do it.", "In lieu of explanation what\u2019s happening here: I am using the two SQL queries that get created in lines 3\u20137 in the gist above. These queries, if you were to print them out, would read as follows.", "The final SQL query simply returns the list of columns with their corresponding missing values percentage.", "As expected, many of the ID columns have a lot of missing observations but we won\u2019t be using these much later in our analysis so no worries. However, missing pdf_json_files column has almost 60% missing values\u2026 That definitely is a worry since we need to be able to find the body of the paper. Thus, we should remove these missing observations.", "After the above operation we end up with roughly 94 thousand papers in the corpus. Rerunning the previous query yields the following breakdown of percent missing values per column.", "We still miss some of the titles, authors or abstracts but that\u2019s fine \u2014 this should not hinder our approach. What is more important is that we can find the file and later link it with the cord_uid to return the relevant paper.", "Next, we will turn our eye to finding duplicates, another common problem with any dataset (I am yet to find one raw dataset that had none). Querying the metadata table I get the following number of duplicated records in each column.", "So, we have over 1,200 duplicated titles, 282 duplicated abstracts and 6 duplicated links in the pdf_json_files column. Let\u2019s start with those.", "Looking at the table above we can clearly tell that the first 3 papers are not duplicates \u2014 they simply mistakenly point to the same json file. However, the remaining files are definitely duplicates. Since there\u2019s only 6 of the duplicates total in this column\u2014 we will drop all of them using the .dropna() functionality from cuDF.", "Next, let\u2019s look at the duplicated titles. A query that allows us to create a quick list of duplicated rows is presented below as well as the top 10 records with the duplicated title.", "You can see that these are truly duplicated records: somehow they differ with doi identifier but the titles, abstracts and authors mostly match. However, since there are over 1200 of duplicated records we would not like to drop all of these and will use the .drop_duplicated() method from to retain one record from each duplicate.", "Final check: let\u2019s see if we can really find all the files listed in the metadata.csv files physically in the data folder. The approach we\u2019ll take to be as efficient as possible will be to list all the files in the data/2020\u201308\u201324/document_parses/pdf_json directory, create a cuDF/BlazingSQL table from these, and then join them with the de-duped dataset we already have.", "So, actually quite surprisingly, we have 12.5k files that we have links to in the metadata.csv file but cannot be found on disk, and 5k files that are present on disk but cannot be referenced in the metadata.csv file. Well, in this case, I decided to drop all the missing files thus keeping only the 87,438 files I can find in both, the metadata.csv file, and on disk.", "This concludes this part. As I alluded to in the introduction to this series \u2014 I always treat every dataset I am given with suspicions until I prove to myself that it is clean enough to be used for doing analysis or building an ML or DL model.", "In the next installment we will be looking at reading the files from the disk and using the subword_tokenizer from RAPIDS to tokenize the text and get ready for training BERT in part 3.", "Also, if you want to try any code presented in this series go to https://app.blazingsql.com/ and launch a free cluster!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist, math lover, computer geek, tube-amps designer and builder, die-hard TOOL fan. Working for Blazing SQL. Ex Microsoft."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff1d27c33b48&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tomekdrabas.medium.com/?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": ""}, {"url": "https://tomekdrabas.medium.com/?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "Tom Drabas"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F44003e7498c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&user=Tom+Drabas&userId=44003e7498c6&source=post_page-44003e7498c6----f1d27c33b48---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1d27c33b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1d27c33b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/EAgGqOiDDMg/download?force=true", "anchor_text": "https://unsplash.com/photos/EAgGqOiDDMg/download?force=true"}, {"url": "https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge", "anchor_text": "Kaggle competition"}, {"url": "https://towardsdatascience.com/building-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-bdd7427d6a8a", "anchor_text": "this series"}, {"url": "https://towardsdatascience.com/building-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-bdd7427d6a8a", "anchor_text": "post that announced this series"}, {"url": "https://rapids.ai", "anchor_text": "NVIDIA RAPIDS"}, {"url": "https://blazingsql.com", "anchor_text": "BlazingSQL"}, {"url": "https://www.nvidia.com/en-us/deep-learning-ai/products/titan-rtx/", "anchor_text": "TITAN RTX"}, {"url": "https://www.lenovo.com/us/en/laptops/thinkpad/thinkpad-p/P53/p/22WS2WPWP53", "anchor_text": "Lenovo P53 Mobile Workstation with NVIDIA Quadro RTX 5000 GPU"}, {"url": "https://github.com/drabastomek/rapids-notebooks", "anchor_text": "github"}, {"url": "https://www.linkedin.com/posts/tomekd_blazingsql-notebooks-private-preview-activity-6710308422451126272-wXCb", "anchor_text": "https://www.linkedin.com/posts/tomekd_blazingsql-notebooks-private-preview-activity-6710308422451126272-wXCb"}, {"url": "https://www.cdc.gov/sars/about/fs-sars.html", "anchor_text": "SARS pandemic"}, {"url": "https://docs.rapids.ai/api/cudf/stable/api.html#cudf.core.column.string.StringMethods.subword_tokenize", "anchor_text": "subword_tokenizer"}, {"url": "https://app.blazingsql.com/", "anchor_text": "https://app.blazingsql.com/"}, {"url": "https://medium.com/tag/covid-19?source=post_page-----f1d27c33b48---------------covid_19-----------------", "anchor_text": "Covid-19"}, {"url": "https://medium.com/tag/gpu-computing?source=post_page-----f1d27c33b48---------------gpu_computing-----------------", "anchor_text": "Gpu Computing"}, {"url": "https://medium.com/tag/rapids-ai?source=post_page-----f1d27c33b48---------------rapids_ai-----------------", "anchor_text": "Rapids Ai"}, {"url": "https://medium.com/tag/blazingsql?source=post_page-----f1d27c33b48---------------blazingsql-----------------", "anchor_text": "Blazingsql"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff1d27c33b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&user=Tom+Drabas&userId=44003e7498c6&source=-----f1d27c33b48---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff1d27c33b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&user=Tom+Drabas&userId=44003e7498c6&source=-----f1d27c33b48---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1d27c33b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff1d27c33b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f1d27c33b48---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f1d27c33b48--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f1d27c33b48--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f1d27c33b48--------------------------------", "anchor_text": ""}, {"url": "https://tomekdrabas.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tomekdrabas.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tom Drabas"}, {"url": "https://tomekdrabas.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "84 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F44003e7498c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&user=Tom+Drabas&userId=44003e7498c6&source=post_page-44003e7498c6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F44003e7498c6%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-understanding-of-viruses-by-mining-covid-19-scientific-corpus-f1d27c33b48&user=Tom+Drabas&userId=44003e7498c6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}