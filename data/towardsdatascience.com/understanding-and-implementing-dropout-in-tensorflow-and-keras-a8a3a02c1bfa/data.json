{"url": "https://towardsdatascience.com/understanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa", "time": 1683007599.402527, "path": "towardsdatascience.com/understanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa/", "webpage": {"metadata": {"title": "Understanding And Implementing Dropout In TensorFlow And Keras | by Richmond Alake | Towards Data Science", "h1": "Understanding And Implementing Dropout In TensorFlow And Keras", "description": "This article covers the concept of the dropout technique, a technique that is leveraged in deep neural networks such as recurrent neural networks and convolutional neural network. The Dropout\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1207.0580.pdf", "anchor_text": "Improving neural networks by preventing co-adaptation of feature detectors", "paragraph_index": 2}, {"url": "https://arxiv.org/pdf/1207.0580.pdf", "anchor_text": "paper", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/CIFAR-10", "anchor_text": "CIFAR-10 dataset", "paragraph_index": 18}, {"url": "https://github.com/RichmondAlake/tensorflow_2_tutorials/blob/master/10_dropout.ipynb", "anchor_text": "Here\u2019s a GitHub repository for the code presented in this article.", "paragraph_index": 32}], "all_paragraphs": ["This article covers the concept of the dropout technique, a technique that is leveraged in deep neural networks such as recurrent neural networks and convolutional neural network.", "The Dropout technique involves the omission of neurons that act as feature detectors from the neural network during each training step. The exclusion of each neuron is determined randomly.", "G.E Hinton proposed this simple technique in 2012 in the published paper: \u201cImproving neural networks by preventing co-adaptation of feature detectors\u201d.", "In this article, we will uncover the concept of dropout in-depth and look at how this technique can be implemented within neural networks using TensorFlow and Keras.", "Neural networks have hidden layers in between their input and output layers, these hidden layers have neurons embedded within them, and it\u2019s the weights within the neurons along with the interconnection between neurons is what enables the neural network system to simulate the process of what resembles learning.", "The general idea is that the more neurons and layers within a neural network architecture, the greater the representational power it has. This increase in representational power means that the neural network can fit more complex functions and generalize well to training data.", "Simply kept, there are more configurations for the interconnections between the neurons within the neural network layers.", "The disadvantage of utilizing deeper neural networks is that they are highly prone to overfitting.", "Overfitting is a common problem that is defined as the inability for a trained machine learning model to generalized well to unseen data, but the same model performs well on the data it was trained on.", "The primary purpose of dropout is to minimize the effect of overfitting within a trained network.", "Dropout technique works by randomly reducing the number of interconnecting neurons within a neural network. At every training step, each neuron has a chance of being left out, or rather, dropped out of the collated contribution from connected neurons.", "This technique minimizes overfitting because each neuron becomes independently sufficient, in the sense that the neurons within the layers learn weight values that are not based on the cooperation of its neighbouring neurons.", "Hence, we reduce the dependence on a large number of interconnecting neurons to generate a decent representational power from the trained neural network.", "Supposedly you trained 7,000 different neural network architecture, to select the best one you simply take the average of all 7,000 trained neural network.", "Well, the dropout technique actually mimics this scenario.", "If the probability of a neuron getting dropped out in a training step is set to 0.5; we are actually training a variety of different network at each training step as it\u2019s highly impossible that the same neurons are excluded at any two training steps. Therefore a neural network that has been trained utilizing the dropout technique is an average of all the different neurons connection combinations that have occurred at each training step.", "In practical scenarios, or when testing the performance of the trained neural network that utilized dropout on unseen data, certain items are considered.", "The first being the fact that dropout technique is actually not implemented on every single layer within a neural network; it\u2019s commonly leveraged within the neurons in the last few layers within the network.", "In the experiments conducted in the published paper, it was reported that when testing on the CIFAR-10 dataset, there was an error rate of 15.6% when dropout was utilized in the last hidden layer. This was an improvement from the error rate of 16.6% that was reported when the same dataset was tested on the same convolutional neural network but with no dropout technique included in any of the layers.", "The second item is that within practical scenarios dropout isn\u2019t utilized when evaluating a trained neural network. As a result of dropout not used during the evaluation or testing phase, the full potential of the neural network is realized. This means that all neurons within the network are active, and each neuron has more input connections than it had been trained with.", "Therefore it\u2019s expected to divide the weights of the neurons by one minus the dropout hyperparameter value(dropout rate that\u2019s used during training). So if the dropout rate was 0.5 during training, then in test time the results of the weights from each neuron is halved.", "Using TensorFlow and Keras, we are equipped with the tools to implement a neural network that utilizes the dropout technique by including dropout layers within the neural network architecture.", "We only need to add one line to include a dropout layer within a more extensive neural network architecture. The Dropout class takes a few arguments, but for now, we are only concerned with the \u2018rate\u2019 argument. The dropout rate is a hyperparameter that represents the likelihood of a neuron activation been set to zero during a training step. The rate argument can take values between 0 and 1.", "From this point onwards, we will go through small steps taken to implement, train and evaluate a neural network.", "2. Load the FashionMNIST dataset, normalize images and partition dataset into test, training and validation data.", "3. Create a custom model that includes a dropout layer using the Keras Model Class API.", "4. Load the implemented model and initialize both optimizers and hyperparameters.", "5. Train the model for a total of 60 epochs", "6. Evaluate the model on the test dataset", "The result of the evaluation will look similar to the example evaluation result below:", "The accuracy shown in the evaluation result example corresponds to the accuracy of our model of 88%.", "With some fine-tuning and training with more significant epoch numbers, the accuracy could be increased by a few percentages.", "Here\u2019s a GitHub repository for the code presented in this article.", "Dropout is a common regularization technique that is leveraged within the state of the art solutions to computer vision tasks such as pose estimation, object detection or semantic segmentation. The concept is simple to understand and easier to implement through its inclusion in many standard machine/deep learning libraries such as PyTorch, TensorFlow and Keras.", "If you are interested in other regularization techniques and how they are implemented, have a read of the articles below.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Content Creator with 1M+ views\u2014 Computer Vision Engineer. Interested in gaining and sharing knowledge on Technology and Finance"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa8a3a02c1bfa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://richmondalake.medium.com/?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": ""}, {"url": "https://richmondalake.medium.com/?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "Richmond Alake"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F88797ba3f2f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&user=Richmond+Alake&userId=88797ba3f2f6&source=post_page-88797ba3f2f6----a8a3a02c1bfa---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8a3a02c1bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8a3a02c1bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@john_matychuk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "John Matychuk"}, {"url": "https://unsplash.com/s/photos/stop?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1207.0580.pdf", "anchor_text": "Improving neural networks by preventing co-adaptation of feature detectors"}, {"url": "https://playground.tensorflow.org/", "anchor_text": "https://playground.tensorflow.org/"}, {"url": "https://playground.tensorflow.org/", "anchor_text": "https://playground.tensorflow.org/"}, {"url": "https://arxiv.org/pdf/1207.0580.pdf", "anchor_text": "paper"}, {"url": "https://en.wikipedia.org/wiki/CIFAR-10", "anchor_text": "CIFAR-10 dataset"}, {"url": "https://arxiv.org/pdf/1207.0580.pdf", "anchor_text": "Comparison of error rates between models with dropout and models without dropout on the TIMIT benchmark"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "https://www.tensorflow.org/", "anchor_text": "TensorFlow"}, {"url": "https://github.com/RichmondAlake/tensorflow_2_tutorials/blob/master/10_dropout.ipynb", "anchor_text": "Here\u2019s a GitHub repository for the code presented in this article."}, {"url": "https://towardsdatascience.com/how-to-implement-custom-regularization-in-tensorflow-keras-4e77be082918", "anchor_text": "How To Implement Custom Regularization in TensorFlow(Keras)Learn how to implement a custom neural network regularization technique using TensorFlow and Keras with relative ease.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/batch-normalization-in-neural-networks-code-d7c9b88da9f5", "anchor_text": "Batch Normalization In Neural Networks (Code)Implemented With TensorFlow (Keras)towardsdatascience.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----a8a3a02c1bfa---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a8a3a02c1bfa---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a8a3a02c1bfa---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----a8a3a02c1bfa---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/programming?source=post_page-----a8a3a02c1bfa---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8a3a02c1bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&user=Richmond+Alake&userId=88797ba3f2f6&source=-----a8a3a02c1bfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8a3a02c1bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&user=Richmond+Alake&userId=88797ba3f2f6&source=-----a8a3a02c1bfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8a3a02c1bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa8a3a02c1bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a8a3a02c1bfa---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a8a3a02c1bfa--------------------------------", "anchor_text": ""}, {"url": "https://richmondalake.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://richmondalake.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Richmond Alake"}, {"url": "https://richmondalake.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "7.3K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F88797ba3f2f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&user=Richmond+Alake&userId=88797ba3f2f6&source=post_page-88797ba3f2f6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F366f35b0b39b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa&newsletterV3=88797ba3f2f6&newsletterV3Id=366f35b0b39b&user=Richmond+Alake&userId=88797ba3f2f6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}