{"url": "https://towardsdatascience.com/working-with-hdf5-files-and-creating-csv-files-1a7d212d970f", "time": 1683012633.348532, "path": "towardsdatascience.com/working-with-hdf5-files-and-creating-csv-files-1a7d212d970f/", "webpage": {"metadata": {"title": "Working with HDF5 files and creating CSV files | by Karan Bhanot | Towards Data Science", "h1": "Working with HDF5 files and creating CSV files", "description": "In my last article, I discussed the steps to download NASA data from GES DISC. The data files downloaded are in the HDF5 format. HDF5 is a file format, a technology, that enables the management of\u2026"}, "outgoing_paragraph_urls": [{"url": "http://docs.h5py.org/en/stable/", "anchor_text": "documentation", "paragraph_index": 2}, {"url": "https://disc.gsfc.nasa.gov/", "anchor_text": "GES DISC website", "paragraph_index": 3}], "all_paragraphs": ["In my last article, I discussed the steps to download NASA data from GES DISC. The data files downloaded are in the HDF5 format. HDF5 is a file format, a technology, that enables the management of very large data collections. Thus, it is quite popular for storing information. For getting NASA\u2019s data, please check the below article first:", "Whenever I work with datasets, I\u2019m most comfortable with CSV files. Thus, once I got the HDF5 files, I decided to look for ways to change them to CSV files. I found the package h5py in Python, which enables the reading in of HDF5 files. Thus, this article articulates the steps to use h5py and convert HDF5 to CSV. You can follow along by referring to the complete notebook at the link below.", "For this work, we\u2019ll require two libraries. The first library is h5py which has the option to read and work with HDF5 files (documentation). The second package we need is numpy to work with arrays. Finally, we will import pandas so we can create a dataframe and later save it as a CSV file.", "The next step is to load in the HDF5 file. Note that for this example, I\u2019m working with GPM data collected from GES DISC for January, 2020 for the whole world. It\u2019s located inside the data folder in the GitHub repo (downloaded from GES DISC website).", "I\u2019ll use the File method from the h5py library to read the HDF5 file and save it to the variable called dataset. I specify the name of the file along with the full path as the first argument and set the second argument as r indicating that I\u2019m working with this file in the read only mode.", "Now that the file is all loaded in, we can get started with exploring the dataset. The elements of this file are similar to a Python dictionary. Thus, it comprises of key-value pairs. So, I started by looking at the various keys in this file.", "As we see in the result above, there is just one key called Grid. As we do not see any data, the data might be inside the value of this key; so that\u2019s what I do, I read its value using dataset[\u2019Grid\u2019] into grid and look at its keys.", "Finally, we see the data. We have several features that we can use. All of these represent keys and they will have their corresponding values, which is what we\u2019re looking for. For this work, I\u2019m only interested in latitude, longitude and the precipitation at that latitude-longitude combination.", "Let\u2019s take a look at each of these features one by one.", "I print the longitude key and its attributes. We find that there are 3600 values for longitude. In the attributes, the units and standard_name are the two things I would like to use.", "Similar to longitude, I check the key and its attributes. There are 1800 latitude values and units and standard_name are useful to me.", "I print the key and attributes for precipitation.", "The precipitation data is a 3-dimensional array with the precipitation values stored as a 2-d matrix. It has the shape (3600, 1800) meaning it has precipitation values across all combinations of longitude and latitude. Further, the units of precipitation are found in the units attribute as mm/hr.", "As we now know all the things we want to capture in the final CSV file, we\u2019ll directly proceed with capturing that.", "Our dataset will have 6,480,000 rows (3600x1800). Each of these rows has a unique combination of longitude and latitude. Thus, for each longitude, we have a latitude and the corresponding precipitation value.", "To create the list of longitude values for all precipitation values, we need to repeat each value of the longitude list 1800 times. This is saved as longitude_values with a total length of 6,480,000 values (3600 longitude values, each repreated 1800 times) using np.repeat().", "For each longitude value, we need all latitude values. So, to create the final latitude_values list, we multiply the complete list by 3600, creating a 6,480,000 long list with latitude list repeated over and over again 3600 times.", "Finally, to convert the matrix of precipitation values, I used the flatten() function to convert it into a long list.", "I then saved these lists as columns of the dataset dataframe with labels lon, lat and precipitation. I rename the columns with the labels and the units we extracted above. Note that the strings are saved with a b due to byte encoding, so I append these attributes with decode() to get the string values.", "Some precipitation values are not captured or are missing and are denoted by -9999.900391 in the dataset, so I mask them with a value 0.", "As the last step, I saved the dataframe as a CSV file precipitation_jan_2020.csv inside the data folder.", "And that\u2019s it! We have our CSV file.", "In this article, I described the steps to load a HDF5 file in Python, read its elements and finally create a dataframe that can be saved as a CSV file. The same steps can be replicated for any other HDF5 file as well.", "Hope you liked this article. If you have any questions, suggestions or ideas, please mention them in the comments.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data science and Machine learning enthusiast. Technical Writer. Passionate Computer Science Engineer."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1a7d212d970f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@bhanotkaran22?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bhanotkaran22?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "Karan Bhanot"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F10df94b13417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&user=Karan+Bhanot&userId=10df94b13417&source=post_page-10df94b13417----1a7d212d970f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a7d212d970f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a7d212d970f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@iammrcup?utm_source=medium&utm_medium=referral", "anchor_text": "Mr Cup / Fabien Barral"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/getting-nasa-data-for-your-next-geo-project-9d621243b8f3", "anchor_text": "Getting NASA data for your next geo-projectAccessing GES DISC data filestowardsdatascience.com"}, {"url": "https://github.com/kb22/NASA-data-exploration/blob/master/Coverting%20HDF5%20to%20CSV.ipynb", "anchor_text": "kb22/NASA-data-explorationPermalink Dismiss GitHub is home to over 50 million developers working together to host and review code, manage\u2026github.com"}, {"url": "http://docs.h5py.org/en/stable/", "anchor_text": "documentation"}, {"url": "https://disc.gsfc.nasa.gov/", "anchor_text": "GES DISC website"}, {"url": "https://medium.com/tag/data?source=post_page-----1a7d212d970f---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1a7d212d970f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1a7d212d970f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----1a7d212d970f---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/technology?source=post_page-----1a7d212d970f---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a7d212d970f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&user=Karan+Bhanot&userId=10df94b13417&source=-----1a7d212d970f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a7d212d970f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&user=Karan+Bhanot&userId=10df94b13417&source=-----1a7d212d970f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a7d212d970f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1a7d212d970f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1a7d212d970f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1a7d212d970f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1a7d212d970f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1a7d212d970f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bhanotkaran22?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bhanotkaran22?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Karan Bhanot"}, {"url": "https://medium.com/@bhanotkaran22/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F10df94b13417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&user=Karan+Bhanot&userId=10df94b13417&source=post_page-10df94b13417--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb37e4ce06e02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-hdf5-files-and-creating-csv-files-1a7d212d970f&newsletterV3=10df94b13417&newsletterV3Id=b37e4ce06e02&user=Karan+Bhanot&userId=10df94b13417&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}