{"url": "https://towardsdatascience.com/reinforcement-learning-for-everyone-9c1163f61440", "time": 1683007368.1448069, "path": "towardsdatascience.com/reinforcement-learning-for-everyone-9c1163f61440/", "webpage": {"metadata": {"title": "Reinforcement Learning for everyone | by Mauricio Fadel Argerich | Towards Data Science", "h1": "Reinforcement Learning for everyone", "description": "If you work in technology, and even more so in AI/Machine Learning (ML), you are probably used to people not understanding what you do for a living. This has been my life, and I have to say I feel a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Classical_conditioning", "anchor_text": "Wikipedia", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Q-learning#Algorithm", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://www.linkedin.com/in/maufadel/", "anchor_text": "https://www.linkedin.com/in/maufadel/", "paragraph_index": 13}], "all_paragraphs": ["If you work in technology, and even more so in AI/Machine Learning (ML), you are probably used to people not understanding what you do for a living. This has been my life, and I have to say I feel a bit proud of it: because it means that I have learnt many things that most people don\u2019t know of, and I am deep enough in the topic to be able to understand things that are very complex for most. However, it is also a bit frustrating whenever you want to share an accomplishment with the people you care, because they won\u2019t be able to understand what\u2019s all the fuzz about.", "This is why I\u2019ve decided to write this article, in the hope that I can get my point across to anyone who\u2019s interested in ML and in particular Reinforcement Learning (RL), no matter your background.", "Even though when you think of AI you think about the future, our story starts more than a 100 years ago, in the 1890s in the laboratory of Ivan Pavlov. He was studying salivation in dogs and to do this, he was measuring how much dogs were salivating when they would see food, before eating it. He was already excited with these experiments but he realised something unexpected: the dogs would salivate even before seeing any food. They would start salivating when they would notice Pavlov\u2019s assistant was walking to them. After noticing this, he tested what happened if before feeding the dogs, he would ring a bell (or actually a metronome according to Wikipedia), and probably you guessed it: they started salivating too, because they had learnt that after the bell, food would come. This bell is called a conditional stimulus because the dog does not salivate because the bell is ringing, but because it knows food will follow the bell.", "Well, as it turns out, RL is based on this basic principle of psychology. In RL, an agent learns how to behave based on a \u201cconditioning stimulus\u201d called a reward. The setting of RL is the following:", "We have an agent that is situated in and interacts with an environment, in which he can execute actions, while observing the state of the environment and receiving a reward for its actions. In addition, we solve our problem in discrete time, so our timeline is structured in steps; in each step, the agent observes the state of the environment, executes an action on the environment that changes the environment state and receives a reward for its action.", "To make it simpler, let\u2019s think about an example: our agent will be a robot and we want it to learn to walk until a goal area, so when it arrives to this area we will give it some nice reward. To get to this goal area, the robot can use different actions such as: turn right, turn left, move forward and move back. The robot will start trying random combinations of actions in each step, until it arrives to the location we want it to arrive. Once this has happened, we change its location and start again, it\u2019s like a \u201cgame over\u201d because the robot has achieved its goal and no other actions are possible. This period that starts with the robot in a random position until it arrives to the goal area, it\u2019s called an episode, and we will repeat these episodes until the robot learns what it needs to do to get a good reward. After this, the robot will always do the same: navigate to the goal area because it knows that by doing so, it will get a good reward.", "You might be thinking in the right direction already: math! The agent\u2019s behavior is defined by its policy, which can be represented in different ways according to the method we use: a table, a function or even Neural Networks.", "In the most basic case of RL, called Tabular Q-learning, the agent keeps a table in which there is one row per state and one column per action, like in the figure. This table tells the agent what\u2019s the expected result of performing an action in a given state, so when the state of the environment changes, the agent checks the row corresponding to the given state and can choose the action that in the past returned the highest reward. The values for each action and state are called Q-values.", "This table is a policy in Tabular Q-learning. Each Q-value is initialised to 0 and then its value is updated after each step with an update rule which is based on the reward received after taking an action and \u201chow good\u201d is the new state. I skip the math for this article to avoid technicalities that might not interest many of you, but if you\u2019d like to see the math and all the gritty details of how these values are updated, you can see them here.", "The agent will repeat the episode several times, updating its policy in each step with its new experience (state, action, new state, reward). After some time, the agent will have learnt a policy that yields a good reward over the episode, just as a person would learn how to play a video game obtaining a good score.", "In fact, video games are very good environments to try RL agents, and this is why they are one of the most common use cases for RL. However, the state of a video game is usually defined as each frame of the game, so we are dealing with state spaces that are too big to be managed with Tabular Q-learning so this is where neural networks are used instead of a Q-table. This is what we call Deep RL or Deep Q-learning, because deep neural networks are used. In the next video, from Two Minute Papers, you can see Google\u2019s DeepMind\u2019s Deep Q-learning\u2019s agent playing Atari games.", "It wasn\u2019t too awful, right? I hope you now have a (very) broad idea of what RL is and how it works. If you\u2019re still interested and want to go deeper in RL, there are amazing materials online that can help you to understand it properly and implement it in code! These are some of my favorite resources:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Information Systems Engineer. Research Scientist of AI. More about me on https://www.linkedin.com/in/maufadel/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9c1163f61440&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c1163f61440--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c1163f61440--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mauriciofadelargerich?source=post_page-----9c1163f61440--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=post_page-----9c1163f61440--------------------------------", "anchor_text": "Mauricio Fadel Argerich"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3931df7d193&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=post_page-b3931df7d193----9c1163f61440---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c1163f61440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c1163f61440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.publicdomainpictures.net/en/view-image.php?image=107453&picture=terminator", "anchor_text": "PublicDomainPictures"}, {"url": "https://en.wikipedia.org/wiki/Classical_conditioning", "anchor_text": "Wikipedia"}, {"url": "https://www.flickr.com/photos/frotzed/279854096", "anchor_text": "Flickr"}, {"url": "https://en.wikipedia.org/wiki/Q-learning#Algorithm", "anchor_text": "here"}, {"url": "https://amzn.to/33r3cLM", "anchor_text": "US"}, {"url": "https://amzn.to/2RkYI3V", "anchor_text": "UK"}, {"url": "https://amzn.to/2GMyyor", "anchor_text": "DE"}, {"url": "https://amzn.to/3khE0ON", "anchor_text": "IT"}, {"url": "https://amzn.to/3miY4lG", "anchor_text": "FR"}, {"url": "https://amzn.to/33rlLzl", "anchor_text": "ES"}, {"url": "https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/", "anchor_text": "Tutorial of how to implement RL with Python and OpenAI Gym"}, {"url": "https://medium.com/swlh/when-to-use-reinforcement-learning-and-when-not-to-919557dd34a", "anchor_text": "I might be able to help you out"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----9c1163f61440---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----9c1163f61440---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9c1163f61440---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9c1163f61440---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9c1163f61440---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c1163f61440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=-----9c1163f61440---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c1163f61440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=-----9c1163f61440---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c1163f61440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c1163f61440--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9c1163f61440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9c1163f61440---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c1163f61440--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9c1163f61440--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9c1163f61440--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9c1163f61440--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9c1163f61440--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9c1163f61440--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9c1163f61440--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9c1163f61440--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mauricio Fadel Argerich"}, {"url": "https://medium.com/@mauriciofadelargerich/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "298 Followers"}, {"url": "https://www.linkedin.com/in/maufadel/", "anchor_text": "https://www.linkedin.com/in/maufadel/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3931df7d193&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=post_page-b3931df7d193--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9d5b675a4898&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-for-everyone-9c1163f61440&newsletterV3=b3931df7d193&newsletterV3Id=9d5b675a4898&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}