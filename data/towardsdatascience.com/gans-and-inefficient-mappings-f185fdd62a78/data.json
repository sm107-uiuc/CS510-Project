{"url": "https://towardsdatascience.com/gans-and-inefficient-mappings-f185fdd62a78", "time": 1683003353.488737, "path": "towardsdatascience.com/gans-and-inefficient-mappings-f185fdd62a78/", "webpage": {"metadata": {"title": "GANs and Inefficient Mappings. How GANs tie themselves in knots and\u2026 | by Conor Lazarou | Towards Data Science", "h1": "GANs and Inefficient Mappings", "description": "Generative Adversarial Networks (GANs) are being hailed as the Next Big Thing\u2122\ufe0f in generative art, and with good reason. New technology has always been a driving factor in art \u2014 from the invention of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1706.07068.pdf", "anchor_text": "paper", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/this-will-change-the-way-you-look-at-gans-9992af250454", "anchor_text": "this article", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/training-a-gan-to-sample-from-the-normal-distribution-4095a11e78de", "anchor_text": "this article", "paragraph_index": 6}, {"url": "http://flatland.ai", "anchor_text": "flatland.ai", "paragraph_index": 21}], "all_paragraphs": ["A warning to mobile users: this article has some chunky gifs in it.", "Generative Adversarial Networks (GANs) are being hailed as the Next Big Thing\u2122\ufe0f in generative art, and with good reason. New technology has always been a driving factor in art \u2014 from the invention of paints to the camera to Photoshop \u2014 and GANs are a natural next step. For instance, consider the following images, published in a 2017 paper by Elgammal et al.", "If you\u2019re unfamiliar with GANs, this article includes a succinct overview of the training process. In short, GANs take random noise as input and (if training goes well) produce output that is indiscernible from the real data, where the real data can be practically anything (a set of abstract paintings, photos of celebrity faces, handwritten digits, etc.).", "It is a well-documented problem in GAN literature, as in variational autoencoders before it, that the input values often have no clear relationship with the output. As I mentioned before, GANs accept random noise (canonically 100 random, normally-distributed values) as input, and each of these random numbers can be thought of as a lever of control for the output. Ideally, each lever would correspond to one feature \u2014 in the case of generating faces, there would be one lever for smile vs. frown, one for skin colour, one for hair length, etc; this is rarely the case, and makes using GANs for art something of a crapshoot. As a visualization of this problem, consider the following animation:", "Here, I trained a GAN on the MNIST handwritten digit dataset using a latent space of 16 dimensions. I generated a random sample using this GAN, then illustrated how the output changes as one of the input values is adjusted while the rest are fixed in place. As you can see, neither lever in question changes the output in a way that a human might find intuitive or useful; the first lever controls whether the digit is a 7 or a 9 as well as stroke angle, while the second lever controls whether it\u2019s a 7 or a 9 as well as stroke thickness. Stupid, right? One can imagine what an ideal tool for generating \u201chandwritten\u201d digits might look like: the first lever controls which digit to generate, from zero to nine; the second lever controls thickness of the stroke; the third controls stroke angle; the fourth, loopiness\u2026 you get the idea. Instead, we see several of these traits being controlled by a single lever, and one of these traits being controlled by multiple levers. Imagine how frustrating it would be if Photoshop\u2019s rotate tool also rotated an image\u2019s hues through the colour wheel!", "The obvious problem here is that this makes for an inefficient and downright confusing interface for image generation. However, there is another, less obvious problem: the twisted and complex relationship between input and output also impedes training and limits the overall quality of the output.", "As I explain in this article, GANs are essentially a tool for modelling some data distribution, be it the normal distribution or the distribution of human faces. The GAN, therefore, is a transformation or mapping from some latent space to some sample space. This point is often overlooked as students of GANs dive headlong into high-dimensional problem like image generation. Here, I intend to demonstrate the inefficient mapping problem using simple, 2-dimensional problems, the first of which is illustrated here:", "This is a fairly straightforward function which maps the x-axis in the input space to the position along the spiral in the sample space (angle and radius) and the y-axis to the position laterally within the spiral. For the purposes of visualization, the x-axis is also mapped to hue and the y-axis is mapped to value (colourful vs. black). To further clarify this function, consider the following animation:", "The problem, then, is to train a GAN that is capable of sampling points from this spiral distribution in such a way that a batch from the GAN and a batch from the true function are indiscernible. Note that the GAN doesn\u2019t have to learn the original mapping; any mapping will do, so long as the output distributions are the same.", "The GAN was trained for 60k training steps using typical GAN training techniques (code available at the end of the article). As you can see, the GAN successfully learned a spiral distribution. However, it has several issues:", "All four of these problems are illustrated in this animation:", "As you can see, all four of these problems are, in fact, the same problem. Comparing figure 6 to figure 4, we see that the GAN has learned an inefficient mapping. First of all, consider the tear in the top-right corner of the latent space; the region of the latent space above the tear is mapped to the outermost section of the spiral, while the region immediately below the tear is mapped to the centre of the spiral. This tearing behaviour explains the messiness (issue 2); any point that lies on the tear is mapped to some place between those two extremes, typically falling in the negative space of the spiral. It also explains the artifact at (0.60, -0.63) (issue 3), since points generated in this region were mapped from distant points in the latent space, which is also why the hues and values of the colours also don\u2019t line up (issue 4). Finally, the skinniness of the learned distribution (issue 1) is explained by the complexity of the mapping; the majority of the variance of the distribution comes from the position along the spiral, with the position within the spiral\u2019s width being less significant. Therefore, the GAN first learned how to create a spiral. Whenever it tried to broaden out, the complexity of the mapping caused some other region to break, not unlike a novice developer\u2019s spaghetti code (we\u2019ve all been there). The GAN has essentially trapped itself in a local minimum from which it can\u2019t escape. If you\u2019re curious (if not, respectfully, why are you reading this article?), this is what the GAN looks like while training:", "Figure 7 shows that the GAN quickly learned incompatible mappings for the outermost and innermost regions, and the rest of the distribution was forced to reconcile between them.", "This function maps a 2.5-dimensional space to 2-dimensional space. The first two dimensions in the latent space are independent, standard normally-distributed values. The remaining \u201c0.5\u201d is a discrete dimension with eight possible values, encoded as a vector of length eight where one value is set to one while the rest are zero. In figure 8, a random sample in the latent space is illustrated by plotting the two continuous dimensions on the x- and y-axes while the discrete dimension is represented by the colour. The target function maps this latent space to the sample space by rescaling the normal distribution by a factor of 0.2 and shifting it to one of eight points, based on the value of the latent dimension. The process is animated here:", "The problem, then, is to train a GAN that is capable of sampling points from this eight gaussian distribution in such a way that a batch from the GAN and a batch from the true function are indiscernible. Note that just as in the above spiral problem the GAN doesn\u2019t have to learn the original mapping, but there is a simple mapping that is obviously preferable.", "It\u2019s bad. The GAN completely failed to generate samples in two of the modes (mode collapse), it produces a substantial number of points between modes, it failed to produce normally distributed modes, and there is clearly no reasonable relationship between the latent space and the sample space. This is even more clear in the following animation:", "It\u2019s immediately obvious that different regions within the two continuous latent values are cut and mapped to six of the sample space modes. This presents the same problem that the tear did in the spiral problem; points that land on the tear are mapped to the negative space between modes. Despite the simple solution (namely, scale down the continuous dimensions and map each value in the discrete dimension to a different mode), the GAN settled into a local minimum and was unable to dig itself back out.", "The eight gaussians problem was clearly too difficult, so here is an even simpler problem: convert 2-dimensional uniform noise to 2-dimensional standard normal noise. As in the spiral problem, points are coloured by rotating hue along the x-axis and varying value along the y-axis of the latent space. The simplest mapping is straightforward: stretch out each dimension independently. This is illustrated here:", "As you can see, even when it comes to sampling from something as simple as a 2-dimensional normal distribution, the GAN still ties itself in knots. Most notably, the GAN seems to have folded the latent space over itself, resulting in a kink, gap, and protrusion in the bottom-right of the sample space. Here is the interpolation, animated:", "It\u2019s possible I\u2019ve belaboured the point. However, I hope that the above visualizations have made it clear that the fuzzy relationships between input and output features are more than a simple inconvenience, and are instead a symptom of a much more fundamental problem. If you\u2019re interested in the code used to train the above GANs or the visualization code, both are available at the following github repo:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data science and ML consultant, generative artist, writer. flatland.ai"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff185fdd62a78&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://conor-lazarou.medium.com/?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "Conor Lazarou"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdeb461dc9d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&user=Conor+Lazarou&userId=deb461dc9d26&source=post_page-deb461dc9d26----f185fdd62a78---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff185fdd62a78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff185fdd62a78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://commons.wikimedia.org/wiki/File:Complex_ceiling_architecture_(9330887903).jpg", "anchor_text": "Wikimedia Commons"}, {"url": "https://arxiv.org/pdf/1706.07068.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1706.07068.pdf", "anchor_text": "arXiv:1706.07068v1"}, {"url": "https://towardsdatascience.com/this-will-change-the-way-you-look-at-gans-9992af250454", "anchor_text": "this article"}, {"url": "https://towardsdatascience.com/training-a-gan-to-sample-from-the-normal-distribution-4095a11e78de", "anchor_text": "this article"}, {"url": "https://github.com/ConorLazarou/medium/tree/master/12020/visualizing_gan_mapping", "anchor_text": "ConorLazarou/mediumTraining code and visualizations of inefficient GAN mappingsgithub.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f185fdd62a78---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f185fdd62a78---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f185fdd62a78---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/visualization?source=post_page-----f185fdd62a78---------------visualization-----------------", "anchor_text": "Visualization"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----f185fdd62a78---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff185fdd62a78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&user=Conor+Lazarou&userId=deb461dc9d26&source=-----f185fdd62a78---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff185fdd62a78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&user=Conor+Lazarou&userId=deb461dc9d26&source=-----f185fdd62a78---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff185fdd62a78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff185fdd62a78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f185fdd62a78---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f185fdd62a78--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f185fdd62a78--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f185fdd62a78--------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://conor-lazarou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Conor Lazarou"}, {"url": "https://conor-lazarou.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "http://flatland.ai", "anchor_text": "flatland.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdeb461dc9d26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&user=Conor+Lazarou&userId=deb461dc9d26&source=post_page-deb461dc9d26--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F51220adfabae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgans-and-inefficient-mappings-f185fdd62a78&newsletterV3=deb461dc9d26&newsletterV3Id=51220adfabae&user=Conor+Lazarou&userId=deb461dc9d26&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}