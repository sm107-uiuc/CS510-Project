{"url": "https://towardsdatascience.com/analyzing-chicago-court-data-with-python-8a4bae330dfd", "time": 1683007937.12229, "path": "towardsdatascience.com/analyzing-chicago-court-data-with-python-8a4bae330dfd/", "webpage": {"metadata": {"title": "Analyzing Chicago Court Data with Python | by Amber Teng | Towards Data Science", "h1": "Analyzing Chicago Court Data with Python", "description": "During my first semester in grad school, I worked on a machine learning project with my teammates Karmen Hutchinson, Kelsey Markey, and Alene Rhea in our Introduction to Data Science course. This was\u2026"}, "outgoing_paragraph_urls": [{"url": "https://datacatalog. Cookcountyil.gov)", "anchor_text": "datasets", "paragraph_index": 1}, {"url": "https://datacatalog.cookcountyil.gov/", "anchor_text": "Cook County Open Data Portal", "paragraph_index": 1}, {"url": "https://github.com/angelaaaateng/dsga1001_project", "anchor_text": "https://github.com/angelaaaateng/dsga1001_project", "paragraph_index": 36}, {"url": "https://github.com/angelaaaateng/dsga1001_project/blob/master/TERM%20PROJECT%20FINAL%20PAPER.pdf", "anchor_text": "https://github.com/angelaaaateng/dsga1001_project/blob/master/TERM%20PROJECT%20FINAL%20PAPER.pdf", "paragraph_index": 36}, {"url": "https://github.com/akrhea/mental-health-court-outcomes", "anchor_text": "https://github.com/akrhea/mental-health-court-outcomes", "paragraph_index": 37}, {"url": "http://www2.centerforhealthandjustice.org/", "anchor_text": "http://www2.centerforhealthandjustice.org/", "paragraph_index": 40}, {"url": "http://knowledgecenter.csg.org/kc/system/files/Haneberg", "anchor_text": "http://knowledgecenter.csg.org/kc/system/files/Haneberg", "paragraph_index": 42}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843483/", "anchor_text": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843483/", "paragraph_index": 43}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "anchor_text": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "paragraph_index": 45}, {"url": "https://www.cyberdriveillinois.com/", "anchor_text": "https://www.cyberdriveillinois.com/", "paragraph_index": 47}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5807488/", "anchor_text": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5807488/", "paragraph_index": 48}], "all_paragraphs": ["During my first semester in grad school, I worked on a machine learning project with my teammates Karmen Hutchinson, Kelsey Markey, and Alene Rhea in our Introduction to Data Science course. This was one of the first data science projects I worked on with a team, and I am grateful for the opportunity to work with the aforementioned individuals. It was a great experience, and the findings for this blogpost were discovered as a collaborative group effort. Through this article, I hope to share what I\u2019ve learned with the rest of the data science community. In particular, even though our team did not find conclusive results, I learned a lot from the process of finding datasets, building a model, evaluating that model, and communicating our findings to our peers. Let\u2019s dive right in!", "For this project, our team used datasets that came from the December 2, 2019 updates of the Initiation, Dispositions, and Sentencing datasets available on the Cook County Open Data Portal.It was interesting to be able to deal with government data and understand the different methods with which government entities track mental health. The goal of this project was to better understand and detect people who are likely to be suffering from mental illnesses, based on the Cook County dataset. Interestingly, we see that in this dataset, the number of individuals with mental illness in jail has been reported to be as high as 30%, exceeding the national average by nearly 10% (Behavioral Health Innovations, 2015). Cook County is also at the forefront of specialty treatment courts and programs that identify eligible individuals early and link them to community-based services so as to increase successful probation and community reentry (Center for Health and Justice at TASC, 2019). However, induction into the Mental Health Court program requires a current case with the Health Department and happens relatively late in the legal process.", "An important reason why this project is relevant is because people living with mental illness are especially likely to have encounters with the law. Thus, they often need dedicated resources and thoughtful treatment as they make their way through the criminal justice system. Specifically, while we were working on this project, our team aimed to predict mental health-related dispositions and sentences from a set of judicial and case-based features available only at initiation. Early detection of people who are likely to be suffering from mental illnesses will enable governments and other institutions to provide appropriate support to these people as early as possible. Mental health disorders are three to six times more common among individuals involved in the criminal justice system compared to the general population (Blandford & Osher, 2012). It has also been shown that individuals with mental health disorders spend significantly more time in jail and are nearly twice as likely to be reincarcerated within one year of release (Haneberg & Watts 2016; Eno Louden & Skeem 2011). This creates a detrimental environment for individuals with mental health disorders and creates a problematic cycle where they are released into the community only to likely be returned to the justice system in the future. The goal of this project is to lessen the harmful effects of movement through the legal system on individuals with mental health disorders, while also minimizing the cost incurred by the county. To do this we aim to predict the likelihood that an individual is suffering from a mental health disorder, as soon as they are initiated into the legal system (without the need for medical records or personnel). Identifying individuals pre-trial allows for swift and appropriate interventions (i.e. jail-diversion interventions) and resources (i.e. intensive case management programs, see Loveland et al., 2007) so as to avoid a continued involvement with the legal system. Overall, our project underscores the need for disparate impact tracking in such systems.", "First, let\u2019s take a look at the datasets that our team used. The Cook County datasets contain multiple identification numbers that link the records between them. Because we wanted to make predictions at the level of the individual, we used case_participant_id. Case_participant_id is a unique internal identifier assigned by Cook County to each person associated with a case. Each case_participant_id can be linked to multiple charges, with each charge appearing as a separate row in the datasets. A single charge can appear as multiple rows in the sentencing dataset if re-sentencing has occurred. Additionally, our team also wanted to limit our training data to the 27 columns present in Initiation\u00b9, in order to simulate the use case. 14 of these columns are categorical, and 6 are time-based.", "Because of the nature of the problem and the dataset, we actually created our own target variable. Since we wanted to classify individuals based on mental health, we created a binary target variable \u201cMental Health Indicator (MHI)\u201d to indicate whether or not an individual was identified to have a mental health disability. We looked through all the possible values in Sentencing and Disposition which might indicate a mental health-related outcome, and identified 15 relevant values in 6 columns\u00b2. We put together the sentencing and disposition datasets to identify which rows contained a proxy for MHI. If such an instance was found, for example, the individual had a sentence_type = \u201cInpatient Mental Health Services\u201d, the row was assigned an MHI of 1, otherwise it was assigned a 0. Since there may be multiple rows pertaining to a case_participant_id, we created a separate dataset that contained one row for each unique case_participant_id, along with the corresponding MHI. Each unique ID was assigned a 1 if any rows corresponding to that ID had an MHI of 1. Ultimately we were able to assign an MHI of 1 to 2212 unique case_participant_id\u2019s.", "Since protected classes such as age, race, and gender could potentially introduce bias into the model, we examined their distribution in both positive and negative label instances. We found that age skewed higher in positive cases, women were almost four times as likely to have an MHI =1 than were men, people whose race was labeled \u2018biracial\u2019 or \u2018asian\u2019 had the highest rates of positive MHI across races, and people whose race was labeled \u2018hispanic\u2019 had the lowest rates of positive MHI across races.", "Next, we cleaned our dataset. During data cleaning, we changed a couple of data types, filling in missing information, verifying that inputs within a column are uniform, applying scaling methods like StandardScaler(), and one hot encoding categorical variables. Specifically, we did the following:", "We converted all categorical variables to binary dummy variables to allow for the use of parametric models and to prepare for the aggregation of rows. This resulted in a sparse, high-dimensional dataset.", "Because the dataset we used was extremely class imbalanced, we applied downsampling. In order to help our models learn to identify positive classes in our dataset, we downsampled the negative cases in our training set using random stratified sampling. Given access to greater computing resources, we would have liked to also experiment with upsampling. Specifically, we used 100% of the positive instances, and sampled without replacement from the negative instances. Initially, we downsampled the negative instances such that the positive instances comprised 50% of the training set population, hypothesizing that this would be the ideal ratio for our data and use case. However, the validation and test sets were not downsampled, to replicate deployment.", "Next, we split our dataset into training, testing, and validation sets. In particular, we chose to split the dataset into a training set with 70% of the data, a static validation set with 15% of the data, and a test set with 15% of the data, a ratio endorsed by many data scientists (Shah, 2017). To simulate the deployment environment, in which our model will be used to predict forward in time, we partitioned our training, validation, and test sets based on received_date. The cases with the earliest received_date became our training set, and the lastest cases were our test set. One reason why we wanted to use a time-based partition was to prevent data leakage.", "To reduce the dimensionality of the data, which grew to almost 5000 features after implementation of dummy variables, we used PCA because of its simplicity, efficiency and non-parametric applications for extracting relevant information from datasets (Shlens, 2014). We used the classic application of PCA on our scaled training set (although sparse PCA should be investigated in future efforts), which yielded explained variance ratios. Given greater computational resources, we would have liked to perform a test using 500 principal components, as we see a sharp elbow at that point.", "We focused on two performance metrics in the evaluation of our models: (1) area under the receiver operating curve (AUC), and (2) sensitivity. Our reasoning for this was because we thought that the cost of a false negative in our use case to be significantly higher than the cost of a false positive; to miss an instance of mental illness could be detrimental to that individual, but to offer support and services to an individual without a particular need for them is likely to incur only a marginal operational cost to the county. However, without specific knowledge of Cook County\u2019s available resources and budgetary constraints surrounding mental health, we sought to provide a model which could perform well at various thresholds. So, we optimized our models with respect to AUC, paying close attention to the effects on sensitivity at each iteration. This choice is bolstered by the knowledge that due to our low base rate, accuracy would be a poor metric since it could be very high even if the minority class was not well predicted. AUC on the other hand is more appropriate for our business goal since it is sensitive to class imbalance in the sense that it treats the minority class with as much weight as the majority class.", "Optimizing for AUC provides a natural baseline, as an AUC of 0.5 represents a model which assigns class probabilities randomly (Brownlee, 2019). The expected sensitivity of such a model, using a 50% probability cutoff, would also be 0.5. Bringing that threshold down to 0% (i.e., assigning every case to the positive class) would be the easiest way to maximize sensitivity; indeed the sensitivity of such a model would be 1. This further illustrates the reason it is better in this case to optimize for AUC rather than for sensitivity: our goal is not simply to identify positive instances, but to do so with minimal type I errors.", "The first model we ran was a random forest model with out-of-the-box parameters, fit on our cleaned and downsampled training set. We call this a \u201cpseudo-baseline,\u201d because at this stage we had already invested significant time into data munging. An ensemble tree-based method was chosen as a baseline because they are known to perform well on categorical variables (Tutz & Berger, 2017). We treated this model as a baseline from which to start, before feature engineering and hyperparameter tuning. This unrefined model yielded an AUC of 0.78 and a sensitivity of 0.78.", "The feature importances demonstrated in our pseudo-baseline random forest guided much of our initial feature engineering. For example, \u2018Section 402(c)\u2019 was within the top fifteen feature importances and further research indicated that this corresponds to legal sections related to narcotics or possession of narcotics (Illinois Secretary of State). As such, the researchers engineered a new indicator variable to encode if the section column contains other \u2018402\u2019 sections outside of just 402(c). In order to associate nearby regions, we geocoded incident city to latitude and longitude. Geocoding also ensures that our proxies for location are uniform throughout the dataset. A number of datetime features were also engineered in an attempt to better represent what we postulated might be relevant relationships between mental health incidents and time. Finally, since age at incident had nearly 4% missing values and approximately 40 (unrealistic) outlying ages that were over 100, we created a binary feature for whether age at incident was null and another for whether age was over 100.", "In terms of algorithms that we wanted to apply to this problem, we identified five algorithms to explore: logistic regression, decision trees, random forest, gradient boosting, and support vector machine. Initial performance for each of these models was established using out-of-the-box parameters on cleaned, scaled, and downsampled data, after all feature engineering was complete.", "We chose not to experiment with a k-nearest neighbors model (kNN) because of the high dimensionality of the dataset. In such cases, instances which may in fact be similar can have very large distances, and so kNN is likely to perform poorly (Brownlee, 2016). We also decided not to implement a Naive Bayes Classifier, because the use of dummy variables to encode categorical data explicitly violates the algorithm\u2019s assumption of conditional independence.", "We chose not to experiment with a k-nearest neighbors model (kNN) because of the high dimensionality of the dataset. In such cases, instances which may in fact be similar can have very large distances, and so kNN is likely to perform poorly (Brownlee, 2016). We also decided not to implement a Naive Bayes Classifier, because the use of dummy variables to encode categorical data explicitly violates the algorithm\u2019s assumption of conditional independence.", "Support Vector MachineOften viewed as the general-purpose algorithm for machine learning, we chose an SVM as one of our exploratory models because of its ability to capture complex relationships through linear or non-linear kernels. However, the SVM took significantly longer to train than any of our other models, likely because of our high number of features and the constrained optimization problem that backs SVM (Ragnar, 2016). Moreover, it did not yield results that justified the long training time. The researchers determined that the run-time and the extremely low sensitivity (0.46) of the out-of-the-box SVM model meant that it would not be a candidate for hyperparameter tuning.", "Logistic RegressionLogistic regression was chosen for its robustness, reliability, and intuitive interpretation. Moreover, logistic models are relatively easy to update with new data, using the method of stochastic gradient descent, and can easily be regularized to avoid overfitting (Li, 2017). After making appropriate transformations and prior to tuning, the model failed to converge when using all ~4800 features. Increasing max iterations, testing different solvers, and testing different non-linear feature transformations all failed to get the model to converge. Assuming that multicollinearity may be an issue, we reduced the number of columns to the top ten feature importances from our random forest and found that the model (with solver = \u2018liblinear\u2019 and C = 1e30) was able to fit the data with an AUC of 0.72. We ultimately decided not to pursue logistic regression due to the difficulty in fitting a logistic regression to our dummy variables and the impressive results we were already getting using tree methods.", "Decision TreeDecision trees are easily scalable and are able to model non-linear and categorical variables relatively well. Although ensemble methods usually outperform decision trees on key metrics, singular decision trees can provide valuable transparency. We decided to experiment with creating interpretable decision trees because transparency is especially important in the context of the problem at hand\u2074.", "Models employed by governments to aid decision making are subject to scrutiny by the public, so the ability to extract an intuitive set of rules to explain their decisions may be worth a decrease in performance metrics. Trees were trained on unscaled data so that numerical values would be interpretable. The researchers iterated through values of max_depth (2, 3, 4), min_samples_leaf (1, 10, 100, 500), and max_features (10, 5, 3, None). The best combination of hyperparameters turned out to be max_depth=4, min_samples_leaf=10, and max_features=None, with an AUC of 0.75 and a sensitivity of 0.86.", "Random ForestAfter feature engineering, we evaluated a random forest model with default parameters and found that the AUC rose to 0.79 and sensitivity lowered to 0.75. Considering the high performance of the model, we decided to continue tuning the random forest model, both with hyperparameter tuning and feature extraction. We began with tuning of hyperparameters and tested a range of max_depths (None, 3, 10, 30), min_samples_leaf (2, 50, 100, 200), and n_estimators (10, 100, 500, 1000). We found that under these conditions AUC was optimized at 0.82 with sensitivity = 0.78 (Table A4). We then decided to tune with various PCA components and tested each of the same tree parameters with PCA components of 1, 3, 100, and 1000, as well as without PCA. Ultimately, no combination of PCA components and hyperparameters could beat the model performance without PCA.", "Gradient BoostingConsidering how well our tree ensemble methods performed, we decided to include gradient boosting as one of our exploratory algorithms. We found that the out-of-the-box gradient boosting model had an AUC of 0.82, with a sensitivity of 0.76 and thus was a logical candidate for further hyperparameter tuning. Tuning tree-based and learning-based hyperparameters at the same time proved too costly, so we chose to optimize tree-based parameters first, and then use the selected parameters to tune learning-based parameters. We began by tuning our tree-based hyperparameters by looping through all possible combinations of max_depth = [None, 3, 10, 30] and min_samples_leafs = [1, 2, 10, 500] (Table A5). We optimized AUC under these conditions at max_depth = 3 and min_samples_leafs = 10 with an AUC = 0.82 and a sensitivity = 0.78. We then used these parameters to iterate through n_estimators = [10, 100, 500, 1000] and learning_rates = [0.25, 0.1, 0.01, 0.0001]. We felt comfortable employing such a large number of estimators because this is known not to cause gradient boosting ensemble methods to overfit. We found that AUC was optimized here with AUC = 0.82 and sensitivity = 0.79 when learning_rate = 0.01 and n_estimators = 1000. This sensitivity was slightly better than the one we had achieved using a tuned random forest, so we decided to tune the gradient-boosted model further.", "We decided to explore how various numbers of PCA components affected the performance of our gradient boosting model. We again looped through all hyperparameters also varying number of components between 1, 3 and 100. In evaluating models using fewer components, we were able to create one large loop to optimize the number of principal components, tree-based hyperparameters, and learning-based hyperparameters. All hyperparameters remained the same, except for adding an additional min_samples_leafs of 100 to improve granularity of analysis between 10 and 500. Optimal AUC was found at AUC = 0.81 and sensitivity = 0.73 at 100 principal components. Sensitivity was optimized at 0.91 with 1 component, however that model only had a 0.55 AUC.", "We selected as our final model a gradient-boosting ensemble algorithm with {max_depth = 3, min_samples_leafs = 10, learning_rate = 0.01, and n_estimators = 1000}", "The final step in the tuning of our gradient boosting model was to experiment with various levels of downsampling. All previous tests relied on a downsampling ratio of 50% so that our training set had equal positive and negative label occurrences. First we tested the optimized gradient boosting model with a downsampling ratio of 20% (meaning 20% of the training set was comprised of positive instances) and found that AUC remained nearly the same but with an extremely low sensitivity of 0.28. When the model was run again with a downsampling ratio of 10% the sensitivity worsened again to 0.10, so we concluded that ratios less than 50% worsened our model performance and that downsampling ratio was optimized at 50%. These results were consistent with our hypothesis about downsampling\u2019s effect on sensitivity.", "During this round of evaluation, we chose not to scale any of our features, as scaling should not affect tree models (Li, Ting, et al. 2017). To test this assumption, we reran the final model with a 50% downsample ratio on the unscaled dataset. This produced the same AUC and sensitivity that we had found for scaled data, confirming that scaling was an unnecessary use of computing power.", "Using the results of our previous tuning experimentation, we trained the final gradient boosting model without PCA or scaling, and with a downsampling ratio of 50%. We used the highest performing hyperparameters of max_depth = 3, min_samples_leaf = 10, learning_rate = 0.01, and n_estimator = 1000, and evaluated the model on the combined test and validation data. Our final model achieved an AUC of 0.84 while still maintaining a high sensitivity of 0.76. The Receiver Operating Characteristic Curve demonstrates that the model achieves a recall of over 90% fairly quickly, and then flattens out. The false positive rate at that point is just over 40%. This point represents the classification threshold best suited to the business case.", "There are a number of bias-related issues that need addressing prior to deployment of this model. First and foremost, we must address the societal bias that our model has learned from the data. Our feature importances are brimming with discriminatory features, which is unsurprising given the distribution of MHI across these classes. Discrimination unit tests could be employed to identify where the problem lies (d\u2019Alessandro et al., 2019). Verifying which features are correlated directly and indirectly with protected attributes would allow researchers to identify which features to remove from the model.", "Because our model can only learn from cases of mental illnesses that have been identified by the courts, it effectively gives the court full control over what is considered a mental health disability. In this way, MHI is only a loose proxy for mental illness and it is possible that there exists bias towards certain types or presentations of mental illness within those records. There may also be a disadvantage for demographics that either cannot generally afford mental healthcare or are systematically misdiagnosed by healthcare providers, as they will not have documented disabilities. Prior research shows that certain demographics are less likely to be taken seriously by healthcare professionals (Hoffman, et al., 2016), and thus some individuals belonging to a protected group may not be linked to mental health issues that they indeed have. In order to capture these effects of implicit bias, the entries for race were altered as little as possible. We did not combine groups or filter particular entries, as how an individual\u2019s race is perceived may give insight into how that individual is able to navigate the judicial system (Maryfield, 2018), especially in terms of their mental health.", "We were surprised to see that features related to domestic violence were not reflected in our models, since research has shown a strong relationship between domestic violence and mental health disorders in Cook County (Tsirigotis & Luczak, 2017; Behavioral Health Innovations, 2015). It is possible that domain-informed feature engineering could capture this relationship; it is also possible that these cases of mental illness commonly go without identification by the courts.", "Our model was developed using only publically available data. If Cook County becomes interested in pursuing this project, we could work with them to develop a fair and unbiased early identification system for mental illness. Such a system could make use of information which is not publically available, such as an individual\u2019s history within the Cook County judicial system and their Health Department records. Additionally, our model still holds promise for non-governmental organizations looking to offer services to individuals within the legal system. The data used here is specific to Cook County, so directly exporting a model to another jurisdiction will not be possible; however, this project could easily serve as a blueprint for similar projects elsewhere.", "Furthermore, concept drift is likely to be an issue in deployment. As the Cook County mental health court program continues to expand, we can expect an increase in base rate over time, which could eventually degrade model performance. Hence, there ought to be careful monitoring of the MHI base rate and of the legal and policy factors which may influence it. Periodic re-training may be necessary as models become out of date. Model custodians may also decide to exclude older data from training to mitigate concept drift \u2014 this could be tested empirically, and would need to be considered in conjunction with the effects of censoring bias. Type-1 censoring bias is likely to have the opposite effect on our model, and mitigating it would require developing a heuristic cut-off point for the age of cases to be included in training. Monitoring model sensitivity in deployment may prove challenging under censoring, but developing the aforementioned heuristic would give custodians a set time at which to evaluate an individual\u2019s MHI.", "Our model is not currently implementable because of its reliance on protected classes (race, age, gender) for prediction. Further efforts need to be put into testing model performance while removing these protected classes and the features able to predict them. We decided to keep the sensitive features in our final model in order that the model not be misconstrued as fair, and to underscore the need for disparate impact tracking.", "I learned a lot from working on this project with my team, and I\u2019m excited to apply these new ideas to my upcoming projects! Thanks for reading!", "[1] The full table of features used in this project can be viewed on our team Github here: https://github.com/angelaaaateng/dsga1001_project[2] The full list can be viewed on our team Github and team report[3] For more details on our data cleaning process, please see our final paper as well as our team repo[4] For the full decision tree, see the appendix of our final report here https://github.com/angelaaaateng/dsga1001_project/blob/master/TERM%20PROJECT%20FINAL%20PAPER.pdf", "Upon request of Alene Rhea and Kelsey Markey, I\u2019m including the link to a separate study they did about this project https://github.com/akrhea/mental-health-court-outcomes.", "Blandford, A. & Osher, F. (2012). A checklist for implementing evidence-based practices and programs (EBPs) for justice-involved adults with behavioral health disorders. Delmar, NY: SAMHSA\u2019s GAINS Center for Behavioral Health and Justice Transformation.", "Behavioral Health Innovations. Mental Health and Justice in Cook County Bond Courts An Examination of the Management of Persons with Mental Illness in Felony Bond Court. Report prepared for the Administrative Office of the Illinois Courts, July 2015.", "\u201cCenter for Health and Justice at TASC: Connecting Policy, Research, and Practice.\u201d Center for Health and Justice at TASC | Connecting Policy, Research, and Practice., http://www2.centerforhealthandjustice.org/.", "Eno Louden, J., & Skeem, J. (2011). Parolees with mental disorder: Toward evidence-based practice. Bulletin of the Center for Evidence-Based Corrections, 7(1), 1\u20139.", "Haneberg, R., & Watts, K. \u201cStepping Up\u201d to beat the mental health crisis in U.S. jails. Criminal Justice/Corrections. New York, NY: Council of State Governments Justice Center. Retrieved from http://knowledgecenter.csg.org/kc/system/files/Haneberg Watts 2016.pdf", "Hoffman, Kelly M, et al. \u201cRacial Bias in Pain Assessment and Treatment Recommendations, and False Beliefs about Biological Differences between Blacks and Whites.\u201d Proceedings of the National Academy of Sciences of the United States of America, National Academy of Sciences, 19 Apr. 2016, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843483/.", "Maryfield, Bailey. \u201cImplicit Racial Bias.\u201d Justice Research and Statistics Association, 2018.", "Parikh, Rajul, et al. \u201cUnderstanding and Using Sensitivity, Specificity and Predictive Values.\u201d Indian Journal of Ophthalmology, Medknow Publications, 2008, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/.", "Shah, Tarang. \u201cAbout Train, Validation and Test Sets in Machine Learning.\u201d Medium, Towards Data", "State, Illinois Secretary of. \u201cOnline Services.\u201d The Official Website for the Illinois Secretary of State, https://www.cyberdriveillinois.com/.", "Tsirigotis, Konstantinos, and Joanna \u0141uczak. \u201cResilience in Women Who Experience Domestic Violence.\u201d The Psychiatric Quarterly, Springer US, Mar. 2018, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5807488/.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A writer, learner, and explorer, Angela Teng spends most of her time thinking about how interdisciplinary collaboration can galvanize innovations in technology."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8a4bae330dfd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@angelamarieteng?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@angelamarieteng?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "Amber Teng"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a58d8e73e5a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&user=Amber+Teng&userId=2a58d8e73e5a&source=post_page-2a58d8e73e5a----8a4bae330dfd---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a4bae330dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a4bae330dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/data-for-change", "anchor_text": "Data for Change"}, {"url": "https://unsplash.com/@carlesrgm?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Carles Rabada"}, {"url": "https://unsplash.com/s/photos/jail?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://datacatalog. Cookcountyil.gov)", "anchor_text": "datasets"}, {"url": "https://datacatalog.cookcountyil.gov/", "anchor_text": "Cook County Open Data Portal"}, {"url": "https://github.com/angelaaaateng/dsga1001_project", "anchor_text": "https://github.com/angelaaaateng/dsga1001_project"}, {"url": "https://github.com/angelaaaateng/dsga1001_project/blob/master/TERM%20PROJECT%20FINAL%20PAPER.pdf", "anchor_text": "https://github.com/angelaaaateng/dsga1001_project/blob/master/TERM%20PROJECT%20FINAL%20PAPER.pdf"}, {"url": "https://github.com/akrhea/mental-health-court-outcomes", "anchor_text": "https://github.com/akrhea/mental-health-court-outcomes"}, {"url": "https://www.geeksforgeeks.org/decision-tree-introduction-example/", "anchor_text": "https://www.geeksforgeeks.org/decision-tree-introduction-example/"}, {"url": "https://machinelearningmastery.com/k-nearest-neighbors-for-machine-learning/", "anchor_text": "https://machinelearningmastery.com/k-nearest-neighbors-for-machine-learning/"}, {"url": "https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/", "anchor_text": "https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/"}, {"url": "http://www2.centerforhealthandjustice.org/", "anchor_text": "http://www2.centerforhealthandjustice.org/"}, {"url": "https://arxiv.org/abs/1907.09013", "anchor_text": "https://arxiv.org/abs/1907.09013"}, {"url": "http://knowledgecenter.csg.org/kc/system/files/Haneberg", "anchor_text": "http://knowledgecenter.csg.org/kc/system/files/Haneberg"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843483/", "anchor_text": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843483/"}, {"url": "https://www.chicagotribune.com/suburbs/skokie/ct-skr-mental-health-court-tl-0526-20160523-story.html", "anchor_text": "https://www.chicagotribune.com/suburbs/skokie/ct-skr-mental-health-court-tl-0526-20160523-story.html"}, {"url": "https://blogs.sas.com/content/subconsciousmusings/2017/04/12/machine-learning-algorithm-use/#prettyPhoto", "anchor_text": "https://blogs.sas.com/content/subconsciousmusings/2017/04/12/machine-learning-algorithm-use/#prettyPhoto"}, {"url": "https://elitedatascience.com/machine-learning-algorithms", "anchor_text": "https://elitedatascience.com/machine-learning-algorithms"}, {"url": "https://towardsdatascience.com/principal-component-analysis-intro-61f236064b38", "anchor_text": "https://towardsdatascience.com/principal-component-analysis-intro-61f236064b38"}, {"url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "anchor_text": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/", "anchor_text": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/"}, {"url": "https://en.wikipedia.org/wiki/Upsampling#cite_note-1", "anchor_text": "https://en.wikipedia.org/wiki/Upsampling#cite_note-1"}, {"url": "https://datascience.stackexchange.com/questions/9736/what-kinds-of-learning-problems-are-suitable-for-support-vector-machines", "anchor_text": "https://datascience.stackexchange.com/questions/9736/what-kinds-of-learning-problems-are-suitable-for-support-vector-machines"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html", "anchor_text": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"}, {"url": "https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7", "anchor_text": "https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7"}, {"url": "https://arxiv.org/pdf/1404.1100.pdf", "anchor_text": "https://arxiv.org/pdf/1404.1100.pdf"}, {"url": "https://www.cyberdriveillinois.com/", "anchor_text": "https://www.cyberdriveillinois.com/"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5807488/", "anchor_text": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5807488/"}, {"url": "https://towardsdatascience.com/understanding-random-forest-58381e0602d2", "anchor_text": "https://towardsdatascience.com/understanding-random-forest-58381e0602d2"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----8a4bae330dfd---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8a4bae330dfd---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8a4bae330dfd---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----8a4bae330dfd---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-for-change?source=post_page-----8a4bae330dfd---------------data_for_change-----------------", "anchor_text": "Data For Change"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8a4bae330dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&user=Amber+Teng&userId=2a58d8e73e5a&source=-----8a4bae330dfd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8a4bae330dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&user=Amber+Teng&userId=2a58d8e73e5a&source=-----8a4bae330dfd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a4bae330dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8a4bae330dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8a4bae330dfd---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8a4bae330dfd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@angelamarieteng?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@angelamarieteng?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Amber Teng"}, {"url": "https://medium.com/@angelamarieteng/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "524 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a58d8e73e5a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&user=Amber+Teng&userId=2a58d8e73e5a&source=post_page-2a58d8e73e5a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5b473ebbfa29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyzing-chicago-court-data-with-python-8a4bae330dfd&newsletterV3=2a58d8e73e5a&newsletterV3Id=5b473ebbfa29&user=Amber+Teng&userId=2a58d8e73e5a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}