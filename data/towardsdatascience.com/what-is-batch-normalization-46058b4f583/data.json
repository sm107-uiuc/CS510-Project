{"url": "https://towardsdatascience.com/what-is-batch-normalization-46058b4f583", "time": 1683014064.8568199, "path": "towardsdatascience.com/what-is-batch-normalization-46058b4f583/", "webpage": {"metadata": {"title": "What is batch normalization?. How does it help? | by NVS Yashwanth | Towards Data Science", "h1": "What is batch normalization?", "description": "Batch normalization was introduced by Sergey Ioffe\u2019s and Christian Szegedy\u2019s 2015 paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. Batch\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1502.03167.pdf", "anchor_text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "paragraph_index": 0}], "all_paragraphs": ["Batch normalization was introduced by Sergey Ioffe\u2019s and Christian Szegedy\u2019s 2015 paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.", "Batch normalization scales layers outputs to have mean 0 and variance 1. The outputs are scaled such a way to train the network faster. It also reduces problems due to poor parameter initialization.", "We know that normalization or feature scaling can speed up the learning process. The intuition behind batch normalization is similar. Batch normalization does the same for hidden units.", "Why the word batch? Because it normalized the values in the current batch. These are sometimes called the batch statistics.", "Specifically, batch normalization normalizes the output of a previous layer by subtracting the batch mean and dividing by the batch standard deviation.", "This is much similar to feature scaling which is done to speed up the learning process and converge to a solution.", "You might have heard a fancy word thrown around when talking about batch normalization, it is the internal covariance shift. Consider a network that learns a function that maps x to y. The internal covariance shift refers to the change in the distribution of the input x. If a change occurs, our network will not be efficient enough and cant generalize. Thus we will have to train all over.", "Consider this example to understand the covariance shift. If we train a network to detect brown dog images and later you end applying this network to data with colored dog images it would not be able to perform well and we would have to train again. This change in the distribution of input is the covariance shift. So how does batch normalization help here?", "If the distribution of the inputs to every layer is the same, the network is efficient. Batch normalization standardizes the distribution of layer inputs to combat the internal covariance shift. It controls the amount by which the hidden units shift.", "We take the average value out of each layer called \u03bcB. This is called calculated as the sum of all values of layer x_i divided by average on all m values.", "We then calculate the variance \u03c3\u00b2B as follows:1. Subtracting the \u03bcB from every value which is the deviation of every value and ake the square for squared deviation2. Sum up the results of doing that for each of the values, then divide by the number of values m, to get the average, or mean squared deviation.", "We then find the standard deviation as the sum of mean squared deviation and epsilon under root. The epsilon is a constant value as small as 0.001. This is added to avoid cases of division by zero and also to increase variance.", "How is the increase in variance helpful? The variance of a population is typically more than the variance for any sample taken from that population, especially in cases of small sample size where values are near the peak of the population distribution, so increasing the variance a little bit for each batch helps take that into account.", "Now that we calculated mean and standard deviation, we can normalize as follows.", "The normalized values are then multiplied by \u03b3 and added with \u03b2. These are the learnable parameters which serve in further scaling the normalized values. The final batch normalized value is as follows:", "The batch normalization can be applied before and after the activation function. However, research shows its best when applied before the activation function.", "In PyTorch, you can use BatchNorm1d to implement batch normalization on linear outputs and BatchNorm2d for 2D outputs in the case of filtered images from convolutional layers.", "Batch normalization when applied to neural networks produces better results by normalizing the inputs to hidden layers. Fun fact is that batch normalization was introduced after VGG, so VGG can be improved with batch normalization for better results on ImageNet. The ability to use higher learning rates without vanishing or exploding gradients is promising as well. Having noted the issues that batch normalization solves, I hope you now have a better understanding of the same.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A decision analyst with a keen interest in AI. When I don\u2019t code, I try to understand the math behind neural nets."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F46058b4f583&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----46058b4f583--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46058b4f583--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nvsyashwanth?source=post_page-----46058b4f583--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nvsyashwanth?source=post_page-----46058b4f583--------------------------------", "anchor_text": "NVS Yashwanth"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7bd459d521f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&user=NVS+Yashwanth&userId=7bd459d521f3&source=post_page-7bd459d521f3----46058b4f583---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46058b4f583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46058b4f583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jrarce?utm_source=medium&utm_medium=referral", "anchor_text": "Ricardo Arce"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1502.03167.pdf", "anchor_text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----46058b4f583---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/batch-normalization?source=post_page-----46058b4f583---------------batch_normalization-----------------", "anchor_text": "Batch Normalization"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----46058b4f583---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----46058b4f583---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/covariate-shift?source=post_page-----46058b4f583---------------covariate_shift-----------------", "anchor_text": "Covariate Shift"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46058b4f583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&user=NVS+Yashwanth&userId=7bd459d521f3&source=-----46058b4f583---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46058b4f583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&user=NVS+Yashwanth&userId=7bd459d521f3&source=-----46058b4f583---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46058b4f583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46058b4f583--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F46058b4f583&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----46058b4f583---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----46058b4f583--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----46058b4f583--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----46058b4f583--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----46058b4f583--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----46058b4f583--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----46058b4f583--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----46058b4f583--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----46058b4f583--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nvsyashwanth?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nvsyashwanth?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "NVS Yashwanth"}, {"url": "https://medium.com/@nvsyashwanth/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "87 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7bd459d521f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&user=NVS+Yashwanth&userId=7bd459d521f3&source=post_page-7bd459d521f3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F70d9f149410&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-batch-normalization-46058b4f583&newsletterV3=7bd459d521f3&newsletterV3Id=70d9f149410&user=NVS+Yashwanth&userId=7bd459d521f3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}