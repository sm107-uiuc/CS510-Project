{"url": "https://towardsdatascience.com/deep-learning-explainability-hints-from-physics-2f316dc07727", "time": 1682995511.747045, "path": "towardsdatascience.com/deep-learning-explainability-hints-from-physics-2f316dc07727/", "webpage": {"metadata": {"title": "Deep Learning Explainability: Hints from Physics | by Marco Tavora Ph.D. | Towards Data Science", "h1": "Deep Learning Explainability: Hints from Physics", "description": "Nowadays, artificial intelligence is present in almost every part of our lives. Smartphones, social media feeds, recommendation engines, online ad networks, and navigation tools are some examples of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://beebom.com/examples-of-artificial-intelligence/", "anchor_text": "examples", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Speech_recognition", "anchor_text": "speech recognition", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Self-driving_car", "anchor_text": "autonomous driving", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Machine_translation", "anchor_text": "machine translation", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Object_detection", "anchor_text": "visual object recognition", "paragraph_index": 0}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "heuristically", "paragraph_index": 1}, {"url": "https://arxiv.org/pdf/1608.08225.pdf\\", "anchor_text": "understood", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Renormalization", "anchor_text": "renormalization group", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine", "anchor_text": "restricted Boltzmann machine", "paragraph_index": 1}, {"url": "https://books.google.com.br/books?id=n8Mmbjtco78C&printsec=frontcover&dq=Zee,+A..+Quantum+Field+Theory+in+a+Nutshell&hl=en&sa=X&ved=0ahUKEwiM7MvZ3ObgAhUOH7kGHW9xCB0Q6AEIKjAA#v=onepage&q=Zee%2C%20A..%20Quantum%20Field%20Theory%20in%20a%20Nutshell&f=false", "anchor_text": "putting on blurry glasses", "paragraph_index": 2}, {"url": "https://books.google.com.br/books?id=oElbxFaL2dIC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false", "anchor_text": "to compute the trajectory of a satellite orbiting the Earth", "paragraph_index": 5}, {"url": "https://books.google.com.br/books?id=oElbxFaL2dIC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false", "anchor_text": "true theory", "paragraph_index": 6}, {"url": "http://www.nyu.edu/classes/tuckerman/stat.mech/lectures/lecture_28/node1.html", "anchor_text": "fixed points", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Critical_point_(thermodynamics)", "anchor_text": "critical point", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Self-similarity", "anchor_text": "exactly or approximately similar to a part of itself", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Fractal", "anchor_text": "fractals", "paragraph_index": 8}, {"url": "https://www.quantamagazine.org/deep-learning-relies-on-renormalization-physicists-find-20141204/", "anchor_text": "words", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Geoffrey_Hinton", "anchor_text": "Geoffrey Hinton", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Deep_learning", "anchor_text": "deep learning", "paragraph_index": 10}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "keep only features that are considered relevant, deemphasizing irrelevant ones", "paragraph_index": 10}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "article published in 2014", "paragraph_index": 12}, {"url": "http://physics.bu.edu/~pankajm/", "anchor_text": "Pankaj Mehta", "paragraph_index": 12}, {"url": "http://www.physics.northwestern.edu/people/personalpages/DavidSchwab.html", "anchor_text": "David Schwab", "paragraph_index": 12}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "In their words", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine", "anchor_text": "restricted Boltzmann machines", "paragraph_index": 12}, {"url": "https://arxiv.org/abs/1503.02406", "anchor_text": "work", "paragraph_index": 13}, {"url": "http://naftali-tishby.strikingly.com/", "anchor_text": "Naftali Tishby", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Information_bottleneck_method", "anchor_text": "information bottleneck method", "paragraph_index": 13}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab", "paragraph_index": 13}, {"url": "https://arxiv.org/abs/1605.05775", "anchor_text": "exists", "paragraph_index": 13}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "original paper", "paragraph_index": 13}, {"url": "https://www.quantamagazine.org/deep-learning-relies-on-renormalization-physicists-find-20141204/", "anchor_text": "this article", "paragraph_index": 14}, {"url": "https://link.springer.com/article/10.1007/BF01011765", "anchor_text": "Kadanoff, Houghton and Yalabik", "paragraph_index": 15}, {"url": "https://www.springer.com/br/book/9783642132896", "anchor_text": "quantum spin systems", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Hand-waving", "anchor_text": "hand waving", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Spin_(physics)", "anchor_text": "spin", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Spin_(physics)", "anchor_text": "defined", "paragraph_index": 17}, {"url": "https://en.wikipedia.org/wiki/Magnetism", "anchor_text": "magnetism", "paragraph_index": 17}, {"url": "https://en.wikipedia.org/wiki/Thermal_equilibrium", "anchor_text": "thermal equilibrium", "paragraph_index": 21}, {"url": "https://en.wikipedia.org/wiki/Boltzmann_distribution", "anchor_text": "Boltzmann distribution", "paragraph_index": 22}, {"url": "https://en.wikipedia.org/wiki/Hamiltonian_(quantum_mechanics)", "anchor_text": "can be defined as", "paragraph_index": 22}, {"url": "https://en.wikipedia.org/wiki/Partition_function_(statistical_mechanics)", "anchor_text": "partition function", "paragraph_index": 22}, {"url": "https://en.wikipedia.org/wiki/Coupling_constant", "anchor_text": "coupling constants", "paragraph_index": 24}, {"url": "https://en.wikipedia.org/wiki/Thermodynamic_free_energy", "anchor_text": "free energy", "paragraph_index": 25}, {"url": "https://en.wikipedia.org/wiki/Thermodynamic_free_energy\\", "anchor_text": "the energy in a physical system that can be converted to do work", "paragraph_index": 25}, {"url": "https://en.wikipedia.org/wiki/Trace_(linear_algebra)", "anchor_text": "trace", "paragraph_index": 26}, {"url": "https://en.wikipedia.org/wiki/Renormalization_group#Relevant_and_irrelevant_operators_and_universality_classes", "anchor_text": "relevant operators", "paragraph_index": 31}, {"url": "https://towardsdatascience.com/neural-quantum-states-4793fdf67b13", "anchor_text": "previous article", "paragraph_index": 39}, {"url": "http://www.iro.umontreal.ca/~bengioy/ift6266/H14/ftml-sec5.pdf", "anchor_text": "energy-based models", "paragraph_index": 40}, {"url": "https://scikit-learn.org/stable/modules/neural_networks_unsupervised.html'", "anchor_text": "nonlinear unsupervised feature learning", "paragraph_index": 40}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler (KL) divergence or relative entropy", "paragraph_index": 47}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab", "paragraph_index": 48}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "quickly prove", "paragraph_index": 49}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab", "paragraph_index": 53}, {"url": "https://en.wikipedia.org/wiki/Ising_model", "anchor_text": "Ising spin model", "paragraph_index": 53}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "from their paper", "paragraph_index": 56}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab", "paragraph_index": 57}, {"url": "https://www.quantamagazine.org/deep-learning-relies-on-renormalization-physicists-find-20141204/", "anchor_text": "suggested", "paragraph_index": 59}, {"url": "https://cnl.salk.edu/", "anchor_text": "Terrence Sejnowski", "paragraph_index": 61}, {"url": "https://en.wikipedia.org/wiki/Critical_point_(thermodynamics)", "anchor_text": "critical points", "paragraph_index": 61}, {"url": "https://github.com/marcotav", "anchor_text": "Github", "paragraph_index": 63}, {"url": "https://marcotavora.me/", "anchor_text": "www.marcotavora.me", "paragraph_index": 63}], "all_paragraphs": ["Nowadays, artificial intelligence is present in almost every part of our lives. Smartphones, social media feeds, recommendation engines, online ad networks, and navigation tools are some examples of AI-based applications that already affect us every day. Deep learning in areas such as speech recognition, autonomous driving, machine translation, and visual object recognition has been systematically improving the state of the art for a while now.", "However, the reasons that make deep neural networks (DNN) so powerful are only heuristically understood, i.e. we know only from experience that we can achieve excellent results by using large datasets and following specific training protocols. Recently, one possible explanation was proposed, based on a remarkable analogy between a physics-based conceptual framework called renormalization group (RG) and a type of neural network known as a restricted Boltzmann machine (RBM).", "Renormalization is a technique used to investigate the behavior of physical systems when information about its microscopic parts is unavailable. It is a \u201ccoarse-graining\u201d method which shows how physical laws change as we zoom out and examine objects at different length scales, \u201cputting on blurry glasses\u201d.", "The great importance of the RG theory comes from the fact that it provides a robust framework that essentially explains why physics itself is possible.", "RG theory provides a robust framework that explains why physics itself is possible.", "For example, to compute the trajectory of a satellite orbiting the Earth we merely need to apply Newton\u2019s laws of motion. We don\u2019t need to take into account the overwhelmingly complex behavior of the satellite\u2019s microscopic constituents to explain its motion. What we do in practice is a sort of \u201caveraging\u201d of the detailed behavior of the fundamental components of the system (in this case the satellite). RG theory explains why this procedure works so remarkably well.", "Furthermore, RG theory seems to suggest that all our current theories of the physical world are just approximations to some yet unknown \u201ctrue theory\u201d (in more technical terms, this true theory \u201clives\u201d in the neighborhood of what physicists call fixed points of the scale transformations).", "RG theory seems to suggest that all our current theories of the physical world are just approximations to some yet unknown \u201ctrue theory\u201d.", "RG works well when the system under investigation is at a critical point and displays self-similarity. A self-similar system is \u201cexactly or approximately similar to a part of itself\u201d in whatever length scale it is being observed. Examples of systems displaying self-similarity are fractals.", "Systems at critical points display strong correlations between parts of it that are extremely far apart from each other. All subparts influence the whole system and the physical properties of the system become fully independent of its microscopic structure.", "Artificial neural networks can also be viewed as a coarse-graining iterative process. ANNs are composed of several layers, and as illustrated below, earlier layers learn only lower-level features from the input data (such as edges and colors) while deeper layers combine these lower-level features (fed by the earlier ones) into higher-level ones. In the words of Geoffrey Hinton, one of the leading figures in the deep learning community: \u201cYou first learn simple features and then based on those you learn more complicated features, and it goes in stages.\u201d Furthermore, as in the case of the RG process, deeper layers keep only features that are considered relevant, deemphasizing irrelevant ones.", "Both physics and machine learning deal with systems with many constituents. Physics investigates systems containing many (interacting) bodies. Machine learning studies complex data comprising a large number of dimensions. Furthermore, similarly to RG in physics, neural networks manage to categorize data such as, e.g. pictures of animals regardless of their component parts (such as size and color).", "In an article published in 2014, two physicists, Pankaj Mehta and David Schwab, provided an explanation for the performance of deep learning based on renormalization group theory. They showed that DNNs are such powerful feature extractors because they can effectively \u201cmimic\u201d the process of coarse-graining that characterizes the RG process. In their words \u201cDNN architectures [\u2026] can be viewed as an iterative coarse-graining scheme, where each new high-level layer of the NN learns increasingly abstract higher-level features from the data\u201d. In fact, in their paper, they manage to prove that there is indeed an exact map between RG and restricted Boltzmann machines (RBM), two-layered neural networks that constitute building blocks of DNN.", "There are many other works in the literature connecting renormalization and deep learning, following different strategies and having distinct goals. In particular, the work of Naftali Tishby and collaborators based on the information bottleneck method is fascinating. Also, Mehta and Schwab explained the map for only one type of neural network, and subsequent work already exists. However, for conciseness, I will focus here on their original paper, since their insight was responsible for giving rise to a large volume of relevant subsequent work on the topic.", "Before giving a relatively detailed description (see this article for a great, though much less technical, description) of this relationship I will provide some of the nitty-gritty of both RG theory of and RBMs.", "As mentioned above, renormalization involves the application of coarse-graining techniques to physical systems. RG theory is a general conceptual framework so one needs methods to operationalize those concepts. Variational Renormalization group (VRG) is one such scheme which was proposed by Kadanoff, Houghton and Yalabik in 1976.", "For clarity of exposition, I chose to focus on one specific type of system to illustrate how RG works, namely, quantum spin systems, instead of proceeding in full generality. But before delving into the mathematical machinery, I will give a \u201chand waving\u201d explanation of the meaning of spin in physics.", "In physics, spin can be defined as \u201can intrinsic form of angular momentum carried by elementary particles, composite particles, and atomic nuclei.\u201d Though spin is by definition a quantum mechanical concept having no classical counterpart, particles with spin are often (though incorrectly) depicted as small tops rotating around their own axis. Spins are closely related to the phenomenon of magnetism.", "Let us consider a system or ensemble of N spins. For visualization purposes suppose they can be put on a lattice, as illustrated in the figure below.", "Since spins can be up or down, they are associated with binary variables", "The index i can be used to label the position of the spin in the lattice. For convenience, I will represent a configuration of spins by a vector v.", "For systems in thermal equilibrium, the probability distribution associated with a spin configuration v has the following form:", "This is the ubiquitous Boltzmann distribution (with the temperature set to 1 for convenience). The object H(v) is the so-called Hamiltonian of the system, which can be defined as \u201can operator corresponding to the sum of the kinetic [and] potential energies for all the particles in the system\u201d. The denominator Z is a normalization factor known as the partition function", "The Hamiltonian of the system can be expressed as a sum of terms corresponding to interactions between spins:", "are called coupling constants and they determine the strength of the interactions between spins (second term) or between spins and external magnetic fields (first term).", "Another important quantity we will need to consider is the free energy. Free energy is a concept originally from thermodynamics where it is defined as \u201cthe energy in a physical system that can be converted to do work\u201d. Mathematically, it is given in our case by:", "The symbol \u201ctr\u201d stands for trace (from linear algebra). In the present context, it represents the sum over all possible configurations of visible spins v.", "At each step of the renormalization procedure, the behavior of the system at small length scales is averaged out. The Hamiltonian of the coarse-grained system is expressed in terms of new coupling constants", "and new, coarse-grained variables are obtained. In our case, the latter are block spins h and the new Hamiltonian is:", "To better understand what are block spins, consider the two-dimensional lattice below. Each arrow represents a spin. Now divide the lattice into square blocks each containing 2\u00d72 spins. The block spins are the average spins corresponding to each of these blocks.", "Note that the new Hamiltonian has the same structure as the original one, only with configurations of blocks of spins in place of physical spins.", "In other words, the form of the model does not change but as we zoom out the parameters of the model change. The full renormalization of the theory is obtained by systematically repeating these steps. After several RG iterations, some of the parameters will be dropped out and some will remain. The ones that remain are called relevant operators.", "A connection between these Hamiltonians is obtained by the requirement that the free energy (described a few lines above) does not change after an RG-transformation.", "As mentioned above, to implement the RG mappings one can use the variational renormalization group (VRG) scheme. In this scheme, the mappings are implemented by an operator", "where \u03bb is a set of parameters. This operator encodes the couplings between hidden and input (visible) spins and satisfies the following relation:", "which defines the new Hamiltonian given above. Though in an exact RG transformation, the coarse-grained system would have exactly the same free energy as the original system i.e.", "which is equivalent to the following condition", "in practice, this condition cannot be satisfied exactly and variational schemes are used to find \u03bb that minimizes the difference between the free energies", "or equivalently, to approximate the exact RG transformation.", "I have described in some detail the internal workings of restricted Boltzmann machines in a previous article. Here I will provide a more condensed explanation.", "Restricted Boltzmann Machines (RBMs) are generative, energy-based models. used for nonlinear unsupervised feature learning. Their simplest version consists of two layers only:", "Again I will consider a binary visible dataset v with n elements extracted from some probability distribution", "The hidden units in the RBM (represented by the vector h) are coupled to the visible units with interaction energy given by", "The energy sub-index \u03bb represents the set of variational parameters {c, b, W}. where the first two elements are vectors and the third one is a matrix. The goal of RBMs is to output a \u03bb-dependent probability distribution that is as close as possible to the distribution of the input data P(v).", "The probability associated with a configuration (v,h) and parameters \u03bb is a function of this energy functional:", "From this joint probability, one can easily obtain the variational (marginalized) distribution of visible units by summing over the hidden units. Likewise, the marginalized distribution of hidden units is obtained by summing over the visible units:", "We can define an RBM Hamiltonian as follows:", "The \u03bb parameters can be chosen to optimize the so-called Kullback-Leibler (KL) divergence or relative entropy which measures how different two probability distributions are. In the present case, we are interested in the KL divergence between the true data distribution and the variational distribution of the visible units produced by the RBM. More specifically:", "Mehta and Schwab showed that to establish the exact mapping between RG and RBMs, one can choose the following expression for the variational operator:", "Recall that the Hamiltonian H(v) contains encoded inside it the probability distribution of the input data. With this choice of variational operator, one can quickly prove the RG Hamiltonian and the RBM Hamiltonian on the hidden layer are the same:", "Also, when an exact RG transformation can be implemented, the true and variational Hamiltonian are identical:", "Hence we see that one step of the renormalization group with spins v and block-spins h can be exactly mapped into a two-layered RBM made of visible units v and hidden units h.", "As we stack increasingly more layers of RBMs we are in effect performing more and more rounds of the RG transformation.", "Following this rationale, we conclude that RBMs, a type of unsupervised deep learning algorithm, implements the variational RG process. This is a remarkable correspondence and Mehta and Schwab demonstrate their idea by implementing stacked RBMs on a well-understood Ising spin model. They fed, as input data, spin configurations sampled from an Ising model into the DNN. Their results show that, remarkably, DNNs seem to be performing (Kadanoff) block spin renormalization.", "In the authors\u2019 words \u201cSurprisingly, this local block spin structure emerges from the training process, suggesting the DNN is self-organizing to implement block spin renormalization\u2026 I was astounding to us that you don\u2019t put that in by hand, and it learns\u201d.", "Their results show that, remarkably, DNNs seem to be performing block spin renormalization.", "In the figure below from their paper, A shows the architecture of the DNN. In B the learning parameters W are plotted to show the interaction between hidden and visible units. In D we see the gradual formation of block spins (the blob in the picture) as we move from along the layers of the DNN. In E the RBM reconstructions reproducing the macroscopic structure of three data samples are shown.", "In 2014 it was shown by Mehta and Schwab that a Restricted Boltzmann Machine (RBM), a type of neural network, is connected to the renormalization group, a concept originally from physics. In the present article, I reviewed part of their analysis. As previously recognized, both RG and deep neural networks bear a remarkable \u201cphilosophical resemblance\u201d: both distill complex systems into their relevant parts. This RG-RBM mapping is a kind of formalization of this similarity.", "Since deep learning and biological learning processes have many similarities, it is not too much of a stretch to hypothesize that our brains may also use some kind of \u201crenormalization on steroids\u201d to make sense of our perceived reality.", "As one of the authors suggested, \u201cMaybe there is some universal logic to how you can pick out relevant features from data, I would say this is a hint that maybe something like that exists.\u201d", "It is not too much of a stretch to hypothesize that our brains may also use some kind of \u201crenormalization on steroids\u201d to make sense of our perceived reality.", "The problem with this is that in contrast to self-similar systems (with fractal-like behavior) where RG works well, systems in nature generally are not self-similar. A possible way out of this limitation, as pointed out by the neuroscientist Terrence Sejnowski, would be if our brains somehow operated at critical points with all neurons influencing the whole network. But that is a topic for another article!", "Thanks for reading and see you soon! As always, constructive criticism and feedback are always welcome!", "My Github and personal website www.marcotavora.me have (hopefully) some other interesting stuff both about data science and about physics.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Theoretical physicist, data scientist, and scientific writer."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2f316dc07727&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2f316dc07727--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2f316dc07727--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://concerningphysicsandmath.com/?source=post_page-----2f316dc07727--------------------------------", "anchor_text": ""}, {"url": "https://concerningphysicsandmath.com/?source=post_page-----2f316dc07727--------------------------------", "anchor_text": "Marco Tavora Ph.D."}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9bfccc40b00d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&user=Marco+Tavora+Ph.D.&userId=9bfccc40b00d&source=post_page-9bfccc40b00d----2f316dc07727---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2f316dc07727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2f316dc07727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/fr/users/realworkhard-23566/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=199054", "anchor_text": "Ralf Kunze"}, {"url": "https://pixabay.com/fr/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=199054", "anchor_text": "Pixabay"}, {"url": "https://medium.com/towards-data-science/inside-ai/home", "anchor_text": "Inside AI"}, {"url": "https://beebom.com/examples-of-artificial-intelligence/", "anchor_text": "examples"}, {"url": "https://en.wikipedia.org/wiki/Speech_recognition", "anchor_text": "speech recognition"}, {"url": "https://en.wikipedia.org/wiki/Self-driving_car", "anchor_text": "autonomous driving"}, {"url": "https://en.wikipedia.org/wiki/Machine_translation", "anchor_text": "machine translation"}, {"url": "https://en.wikipedia.org/wiki/Object_detection", "anchor_text": "visual object recognition"}, {"url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "anchor_text": "heuristically"}, {"url": "https://arxiv.org/pdf/1608.08225.pdf\\", "anchor_text": "understood"}, {"url": "https://en.wikipedia.org/wiki/Renormalization", "anchor_text": "renormalization group"}, {"url": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine", "anchor_text": "restricted Boltzmann machine"}, {"url": "https://books.google.com.br/books?id=n8Mmbjtco78C&printsec=frontcover&dq=Zee,+A..+Quantum+Field+Theory+in+a+Nutshell&hl=en&sa=X&ved=0ahUKEwiM7MvZ3ObgAhUOH7kGHW9xCB0Q6AEIKjAA#v=onepage&q=Zee%2C%20A..%20Quantum%20Field%20Theory%20in%20a%20Nutshell&f=false", "anchor_text": "putting on blurry glasses"}, {"url": "https://books.google.com.br/books?id=oElbxFaL2dIC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false", "anchor_text": "navigate the space"}, {"url": "https://books.google.com.br/books?id=oElbxFaL2dIC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false", "anchor_text": "source"}, {"url": "https://www.shutterstock.com/g/3Dsculptor", "anchor_text": "3Dsculptor"}, {"url": "https://www.shutterstock.com", "anchor_text": "Shutterstock.com"}, {"url": "https://books.google.com.br/books?id=oElbxFaL2dIC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false", "anchor_text": "to compute the trajectory of a satellite orbiting the Earth"}, {"url": "https://books.google.com.br/books?id=oElbxFaL2dIC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false", "anchor_text": "true theory"}, {"url": "http://www.nyu.edu/classes/tuckerman/stat.mech/lectures/lecture_28/node1.html", "anchor_text": "fixed points"}, {"url": "https://en.wikipedia.org/wiki/Critical_point_(thermodynamics)", "anchor_text": "critical point"}, {"url": "https://en.wikipedia.org/wiki/Self-similarity", "anchor_text": "exactly or approximately similar to a part of itself"}, {"url": "https://en.wikipedia.org/wiki/Fractal", "anchor_text": "fractals"}, {"url": "https://en.wikipedia.org/wiki/Mandelbrot_set", "anchor_text": "source"}, {"url": "https://www.quantamagazine.org/deep-learning-relies-on-renormalization-physicists-find-20141204/", "anchor_text": "words"}, {"url": "https://en.wikipedia.org/wiki/Geoffrey_Hinton", "anchor_text": "Geoffrey Hinton"}, {"url": "https://en.wikipedia.org/wiki/Deep_learning", "anchor_text": "deep learning"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "keep only features that are considered relevant, deemphasizing irrelevant ones"}, {"url": "http://web.eecs.umich.edu/~honglak/cacm2011-researchHighlights-convDBN.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "article published in 2014"}, {"url": "http://physics.bu.edu/~pankajm/", "anchor_text": "Pankaj Mehta"}, {"url": "http://www.physics.northwestern.edu/people/personalpages/DavidSchwab.html", "anchor_text": "David Schwab"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "In their words"}, {"url": "https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine", "anchor_text": "restricted Boltzmann machines"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "2014 paper by Mehta and Schwab"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "source"}, {"url": "https://arxiv.org/abs/1503.02406", "anchor_text": "work"}, {"url": "http://naftali-tishby.strikingly.com/", "anchor_text": "Naftali Tishby"}, {"url": "https://en.wikipedia.org/wiki/Information_bottleneck_method", "anchor_text": "information bottleneck method"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab"}, {"url": "https://arxiv.org/abs/1605.05775", "anchor_text": "exists"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "original paper"}, {"url": "https://www.quantamagazine.org/deep-learning-relies-on-renormalization-physicists-find-20141204/", "anchor_text": "this article"}, {"url": "https://link.springer.com/article/10.1007/BF01011765", "anchor_text": "Kadanoff, Houghton and Yalabik"}, {"url": "https://www.springer.com/br/book/9783642132896", "anchor_text": "quantum spin systems"}, {"url": "https://en.wikipedia.org/wiki/Hand-waving", "anchor_text": "hand waving"}, {"url": "https://en.wikipedia.org/wiki/Spin_(physics)", "anchor_text": "spin"}, {"url": "https://en.wikipedia.org/wiki/Spin_(physics)", "anchor_text": "defined"}, {"url": "https://en.wikipedia.org/wiki/Magnetism", "anchor_text": "magnetism"}, {"url": "https://en.wikipedia.org/wiki/Spin_(physics)", "anchor_text": "source"}, {"url": "https://quantumoptics.at/en/research/2darrays.html", "anchor_text": "source"}, {"url": "https://en.wikipedia.org/wiki/Thermal_equilibrium", "anchor_text": "thermal equilibrium"}, {"url": "https://en.wikipedia.org/wiki/Boltzmann_distribution", "anchor_text": "Boltzmann distribution"}, {"url": "https://en.wikipedia.org/wiki/Hamiltonian_(quantum_mechanics)", "anchor_text": "can be defined as"}, {"url": "https://en.wikipedia.org/wiki/Partition_function_(statistical_mechanics)", "anchor_text": "partition function"}, {"url": "https://en.wikipedia.org/wiki/Coupling_constant", "anchor_text": "coupling constants"}, {"url": "https://en.wikipedia.org/wiki/Thermodynamic_free_energy", "anchor_text": "free energy"}, {"url": "https://en.wikipedia.org/wiki/Thermodynamic_free_energy\\", "anchor_text": "the energy in a physical system that can be converted to do work"}, {"url": "https://en.wikipedia.org/wiki/Trace_(linear_algebra)", "anchor_text": "trace"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "source"}, {"url": "https://en.wikipedia.org/wiki/Renormalization_group#Relevant_and_irrelevant_operators_and_universality_classes", "anchor_text": "relevant operators"}, {"url": "https://towardsdatascience.com/neural-quantum-states-4793fdf67b13", "anchor_text": "previous article"}, {"url": "https://towardsdatascience.com/neural-quantum-states-4793fdf67b13", "anchor_text": "Neural Quantum StatesHow neural networks can solve highly complex problems in quantum mechanicstowardsdatascience.com"}, {"url": "http://www.iro.umontreal.ca/~bengioy/ift6266/H14/ftml-sec5.pdf", "anchor_text": "energy-based models"}, {"url": "https://scikit-learn.org/stable/modules/neural_networks_unsupervised.html'", "anchor_text": "nonlinear unsupervised feature learning"}, {"url": "https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-i-6df5c4918c15", "anchor_text": "source"}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler (KL) divergence or relative entropy"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "quickly prove"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab"}, {"url": "https://en.wikipedia.org/wiki/Ising_model", "anchor_text": "Ising spin model"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "from their paper"}, {"url": "https://arxiv.org/pdf/1410.3831.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/abs/1410.3831", "anchor_text": "Mehta and Schwab"}, {"url": "https://www.quantamagazine.org/deep-learning-relies-on-renormalization-physicists-find-20141204/", "anchor_text": "suggested"}, {"url": "https://cnl.salk.edu/", "anchor_text": "Terrence Sejnowski"}, {"url": "https://en.wikipedia.org/wiki/Critical_point_(thermodynamics)", "anchor_text": "critical points"}, {"url": "https://github.com/marcotav", "anchor_text": "Github"}, {"url": "https://marcotavora.me/", "anchor_text": "www.marcotavora.me"}, {"url": "https://medium.com/tag/inside-ai?source=post_page-----2f316dc07727---------------inside_ai-----------------", "anchor_text": "Inside Ai"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2f316dc07727---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2f316dc07727---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2f316dc07727---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/science?source=post_page-----2f316dc07727---------------science-----------------", "anchor_text": "Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2f316dc07727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&user=Marco+Tavora+Ph.D.&userId=9bfccc40b00d&source=-----2f316dc07727---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2f316dc07727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&user=Marco+Tavora+Ph.D.&userId=9bfccc40b00d&source=-----2f316dc07727---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2f316dc07727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2f316dc07727--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2f316dc07727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2f316dc07727---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2f316dc07727--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2f316dc07727--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2f316dc07727--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2f316dc07727--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2f316dc07727--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2f316dc07727--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2f316dc07727--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2f316dc07727--------------------------------", "anchor_text": ""}, {"url": "https://concerningphysicsandmath.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://concerningphysicsandmath.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marco Tavora Ph.D."}, {"url": "https://concerningphysicsandmath.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9bfccc40b00d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&user=Marco+Tavora+Ph.D.&userId=9bfccc40b00d&source=post_page-9bfccc40b00d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F329b50c18616&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-explainability-hints-from-physics-2f316dc07727&newsletterV3=9bfccc40b00d&newsletterV3Id=329b50c18616&user=Marco+Tavora+Ph.D.&userId=9bfccc40b00d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}