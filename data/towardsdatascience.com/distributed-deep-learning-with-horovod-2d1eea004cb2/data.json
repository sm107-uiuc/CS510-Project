{"url": "https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2", "time": 1683017276.019906, "path": "towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2/", "webpage": {"metadata": {"title": "Distributed Deep Learning with Horovod | by Jordi TORRES.AI | Towards Data Science", "h1": "Distributed Deep Learning with Horovod", "description": "[This post will be used in the master course Supercomputers Architecture at UPC Barcelona Tech with the support of the BSC] In the previous post we explored how we can scale the training on Multiple\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.fib.upc.edu/en/studies/masters/master-innovation-and-research-informatics/curriculum/syllabus/SA-MIRI", "anchor_text": "Supercomputers Architecture", "paragraph_index": 0}, {"url": "https://www.upc.edu/en?set_language=en", "anchor_text": "UPC Barcelona Tech", "paragraph_index": 0}, {"url": "https://bsc.es/", "anchor_text": "BSC", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af", "anchor_text": "the previous post", "paragraph_index": 1}, {"url": "http://eng.uber.com/michelangelo", "anchor_text": "Michelangelo", "paragraph_index": 2}, {"url": "https://arxiv.org/pdf/1802.05799.pdf", "anchor_text": "Horovod", "paragraph_index": 2}, {"url": "https://github.com/uber/horovod", "anchor_text": "is available under the Apache 2.0 license", "paragraph_index": 2}, {"url": "https://web.archive.org/web/20180128132031/http://research.baidu.com/bringing-hpc-techniques-deep-learning/", "anchor_text": "Baidu\u2019s", "paragraph_index": 6}, {"url": "http://www.cs.fsu.edu/~xyuan/paper/09jpdc.pdf", "anchor_text": "paper by Patarasuk and Yuan", "paragraph_index": 6}, {"url": "https://developer.nvidia.com/nccl", "anchor_text": "NCCL-2", "paragraph_index": 6}, {"url": "https://arxiv.org/pdf/1802.05799.pdf", "anchor_text": "paper by Sergeev and Balso", "paragraph_index": 7}, {"url": "https://towardsdatascience.com/visual-intuition-on-ring-allreduce-for-distributed-deep-learning-d1f34b4911da", "anchor_text": "Visual intuition on ring-allreduce for distributed Deep Learning", "paragraph_index": 8}, {"url": "http://www.cs.fsu.edu/~xyuan/paper/09jpdc.pdf", "anchor_text": "Patarasuk and Yuan", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Message_Passing_Interface", "anchor_text": "MPI", "paragraph_index": 10}, {"url": "https://developer.nvidia.com/nccl", "anchor_text": "NCCL-2", "paragraph_index": 10}, {"url": "https://github.com/facebookincubator/gloo", "anchor_text": "Gloo", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1706.02677.pdf", "anchor_text": "this Facebook\u2019s paper", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af", "anchor_text": "the previous post", "paragraph_index": 22}, {"url": "https://slurm.schedmd.com", "anchor_text": "SLURM workload manager", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/using-supercomputers-for-deep-learning-training-3f9cc3f51d3", "anchor_text": "Post 2", "paragraph_index": 30}, {"url": "https://www.fib.upc.edu/en/studies/masters/master-innovation-and-research-informatics/curriculum/syllabus/SA-MIRI", "anchor_text": "the master course", "paragraph_index": 33}, {"url": "https://github.com/horovod/horovod/blob/master/docs/benchmarks.rst", "anchor_text": "literature on the subject shows", "paragraph_index": 40}, {"url": "https://towardsdatascience.com/tagged/supercomputing-for-a-i", "anchor_text": "this series", "paragraph_index": 54}, {"url": "https://www.upc.edu/en?set_language=en", "anchor_text": "UPC Barcelona Tech", "paragraph_index": 54}, {"url": "https://www.upc.edu/en?set_language=en", "anchor_text": "Barcelona Supercomputing Center", "paragraph_index": 54}, {"url": "https://towardsdatascience.com", "anchor_text": "Towards Data Science", "paragraph_index": 54}, {"url": "https://www.bsc.es/dominguez-bermudez-juan-luis", "anchor_text": "Juan Luis Dom\u00ednguez", "paragraph_index": 55}, {"url": "https://www.bsc.es/aranda-llorens-oriol", "anchor_text": "Oriol Aranda", "paragraph_index": 55}, {"url": "https://www.bsc.es/tripiana-carlos", "anchor_text": "Carlos Tripiana", "paragraph_index": 55}, {"url": "https://www.bsc.es/gonzalez-carrillo-francisco-jose", "anchor_text": "Francisco Gonzalez", "paragraph_index": 55}, {"url": "https://www.bsc.es/jover-alvarez-alvaro", "anchor_text": "Alvaro Jover Alvarez", "paragraph_index": 55}, {"url": "https://www.bsc.es/escobar-castells-miquel", "anchor_text": "Miquel Escobar Castells", "paragraph_index": 55}, {"url": "https://www.bsc.es/garcia-fuentes-raul", "anchor_text": "Raul Garcia Fuentes", "paragraph_index": 55}, {"url": "https://torres.ai", "anchor_text": "https://torres.ai", "paragraph_index": 56}], "all_paragraphs": ["[This post will be used in the master course Supercomputers Architecture at UPC Barcelona Tech with the support of the BSC]", "In the previous post we explored how we can scale the training on Multiple GPUs in one Server with TensorFlow using tf.distributed.MirroredStrategy(). Now, in this post, we will use Horovod API to scale the training on multiple servers following data parallelism strategies.", "Uber Engineering introduced Michelangelo, an internal ML-as-a-service platform that makes it easy to build and deploy these systems at scale. Horovod, a component of Michelangelo, is an open-source distributed training framework for TensorFlow, PyTorch, and MXNet. Its goal is to make distributed Deep Learning fast and easy to use via ring-allreduce and requires only a few lines of modification to user code. Horovod is available under the Apache 2.0 license.", "Conceptually, the data-parallel distributed training paradigm under Horovod is straightforward:", "1. Run multiple copies of the training script and each copy:", "2. Average gradients among those multiple copies", "Horovod applies Baidu\u2019s algorithm for averaging gradients and communicating those gradients to all nodes (steps 2 and 3 above) that follows the ring-allreduce decentralized scheme. The algorithm was based on the approach introduced in the 2009 paper by Patarasuk and Yuan. Horovod replaced the Baidu ring-allreduce implementation with NCCL-2, which is NVIDIA\u2019s library for collective communication that provides a highly optimized version of ring-allreduce across multiple machines.", "The following figure from the paper by Sergeev and Balso shows the ring-allreduce algorithm that allows workers nodes to average gradients and disperses them to all nodes without the need for a centralized scheme with a parameter server.", "A more clear and visual explanation can be obtained in this post from Medium: \u201cVisual intuition on ring-allreduce for distributed Deep Learning\u201d.", "In this ring-allreduce algorithm, each of N nodes communicates with two of its peers 2\u2217(N\u22121) times. During this communication, a node sends and receives chunks of the data buffer. In the first N-1 iterations, received values are added to the values in the node\u2019s buffer. In the second N-1 iterations, received values replace the values held in the node\u2019s buffer. Patarasuk and Yuan suggest that this algorithm is bandwidth-optimal, meaning that if the buffer is large enough, it will optimally utilize the available network.", "Horovod is a python package installed using pip, and in general it assumes installation of MPI for worker discovery and reduction coordination and Nvidia\u2019s NCCL-2 libraries to support inter-GPU communication. This is because MPI is used extensively in the supercomputing community for high-performance parallel computing.", "However, if MPI is not installed, Horovod includes Gloo, an open-source collective communications library developed by Facebook. You can choose to use Gloo at runtime by passing the --gloo argument to horovodrun:", "Horovod introduces an hvdobject that has to be initialized and has to wrap the optimizer (Horovod averages the gradients using allreduce or allgather). A GPU is bound to this process using its local rank, and we broadcast variables from rank 0 to all other processes during initialization.", "A Horovod Python program is launched using the mpiruncommand. It takes as parameters the hostname of each server as well as the number of GPUs to be used on each server.", "To use Horovod in Tensorflow, you must make the following additions to your program:", "2. Horovod must be initialized before starting using:", "3. Pin each GPU to a process.We will be employing local rank for that, such that, the first process in the server will be pinned to the first GPU; the second process to the second GPU, and so forth:", "4. Scale the learning rate by the number of workers. Effective batch size in synchronous distributed training is scaled by the number of workers. An increase in learning rate compensates for the increased batch size. You can know more about this in this Facebook\u2019s paper.", "5. Wrap optimizer in hvd.DistributedOptimizer. The distributed optimizer delegates gradient computation to the original optimizer, averages gradients using allreduce or allgather, and then applies those averaged gradients.", "6. Specify experimental_run_tf_function=False to ensure TensorFlow uses Horovod\u2019s distributed optimizer to compute gradients.", "7. Add hvd.callbacks.BroadcastGlobalVariablesCallback(0) to broadcast initial variable states from rank 0 to all other processes. This is necessary to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.", "8. If you need to save checkpoints, do it only on worker 0 to prevent other workers from corrupting them. Or if you want to run evaluation or to print information to the standard output, it is recommended to do it on worker 0. This can be accomplished with hvd.rank() = 0.", "To show how to use Horovod, we will use the same example presented in the previous post, that trains a classifier of CIFAR10 dataset based in a ResNet50, and train it on the CTE-POWER machine.", "Following the steps presented in the above section on how to use Horovod API, below we present the resulting parallel code:", "After modifying your sequential python script with the inclusion of Horovod API calls, you must write your job script (.sh file) to submit the job to the SLURM workload manager as we did in the previous section.", "For this concrete example, presented in the previous section, the SLURM script to send the jobs to run on a server with 4GPUs looks like this:", "If we take a look at this SLURM script, we can find the following variables that will determine how our model will be distributed:", "Detailed information about the possible flags for horovodrun command can be obtained executing the command horovodrun --help.", "In the example from above we are using one server with 4 GPUs. If we would like to employ 8 GPUs to do our computation we would need 2 servers, as each server in the CTE-POWER has 4GPUs. To run on more than one server (for example, on two), we need to use the following SLURM script:", "Where we employ 2 servers, each server using 4 GPUs, therefore we will be using 8 GPUs in total.", "Remember that in Post 2 of this series, the reader can find more detailed information about all the #SBATCH commands we usually use in our supercomputer.", "The previous listing shows different names, than the previous one for the #SBATCH options. It is done deliberately with the purpose of showing that SLURM has some \u201cflexibility\u201d with the names used.", "In this section we are going to present an experiment that will help us show how the Horovod API works and, at the same time, be able to experiment with its scalability.", "The reader will surely think that the canonical test that would be more suitable to evaluate the scalability of Horovod is to perform a set of tests where the same number of epochs are executed with different GPUs: 1,2,4,8,16 and 32. But this is not feasible given the availability of the resources that we have assigned in the master course.", "To begin with, a larger problem than that of classifying the CIFAR10 would be required to show results that exhibit that take advantage of the computing power of 32 V100 NVIDIA GPUs.", "Also, it will be required to run a minimum number of epochs per execution to be able to dampen the required initialization. Let\u2019s assume that with the test of 32 GPUs, for example, we would perform a minimum number of 8 epochs. In the ideal canonical comparison test, this would involve running 256 epochs on 1 GPU (32x8) in order to compare. Even in this small problem of classifying the CIFAR40 dataset with a ResNet50, each epoch takes about 40 seconds. That means about 3 hours to train the model with 1 GPU \u2014 something totally unfeasible given the resources available for this master course.", "Likewise, it must be taken into account that a hyperparameter tuning should be performed, which requires many tests. And finally, remember that we should carry out several executions to give statistical validity to the tests given the innate randomness in the behavior of the software stack or the initializations of the system\u2019s initializations.", "In short, a huge amount of computing resources is required, and, as we have explained, we do not have them available in this master course.", "Given these constraints, we have thought of a hands-on that performs a specific test, very guaranteeing, for example with a deliberately low learning-rate so that it does not explode in tests with many GPUs.", "This hands-on designed allows us to show how the throughput of the system increases (images per unit of time) and to focus on the scaling metric. This means that we must completely forget about the Accuracy metric, since to make correct tests at the Accuracy level we should do a more detailed work of the tunning hyperparameters that we cannot do.", "For this reason, we cannot make any comparisons in the results of this hands-on at the Accuracy level. The literature on the subject shows, that if we do a correct hyperparameter tuning, the loss of Accuracy in the scale is reasonably when using the Horovod API in supercomputers such as CTE-POWER.", "In summary, we have designed a simple synthetic test where each GPU performs the same number of epochs, and therefore with 32 GPUs, we will perform 32 times more epochs than with 1 GPU. In this scenario, the measurement of time of the training process of each test can serve as a metric of the quality of scaling at the throughput level. That is, if we had a linear speedup, the time should always be the same in all tests.", "Remember that we focus our hands-on on the computational speed of the process rather than the model\u2019s accuracy, and we will only compare the time required to execute the .fitmethod with the different tests. For this purpose, we will use the following simple code to measure the time:", "Once we run the previous python code, in the file .output that has stored the standard output, we find the execution time required to execute the method .fit().", "There are different ways to design the experiment, but a simple way seems to be to send a job to SLURM for each test: 1,2,4,8,16 and, 32 GPUs. For example, in our case, we created:", "And each of these SLURM jobs generated a .output file like:", "where the last line indicates the required to execute the method .fit().", "In summary, in the .output files, we have all the times that interest us. The following graph plots the time required for executing 10 epoch using up to 64 GPUs:", "We can see that the more GPUs we have, despite having the same job per GPU (epochs = 10 * num GPUs), there is more overhead time to add. It should be noted that these times come from a single execution and can vary between several executions. It is evident that if we want to do a good study, we should carry out several tests and then take the averages of the times obtained in each one of them. But given the purpose of this post (and the cost of resources, which we have to save!), it is enough only one execution.", "Finally, as we already mentioned in previous posts, the speedup is a popular metric in our community. The following graph plots the speedup in blue and in white what is missing to reach the optimal linear speed up.", "Each column n is obtained by, first, dividing the time required to execute 10 epoch with 1 GPU by the time required when we execute the same workload with n GPU. And finally, multiplying the resulting value by n (the number of GPUs used).", "We can conclude that the training really scales with regard to images per second processed, which does not mean that in terms of Accuracy it happens the same, since in this example we have ignored the hyperparameter tunning stage and therefore we cannot draw conclusions from the Accuracy we get.", "If you want to learn more and consolidate the knowledge acquired, now it\u2019s your turn to get your hands dirty to reproduce the above results for the ResNET152V2. Explain why you think these results come out and compare the results with those obtained with ResNET50V2.", "In this post, we have presented how to distribute the training of a single Deep Neural Network over many servers using Horovod. We only proposed a toy experiment due to the limitations of the resources available. However, from my point of view, It serves the purpose of bringing the reader closer to the Horovod API.", "This is the last post of this series that I wrote to support my classes in my master course SA-MIRI at UPC Barcelona Tech (with the support of Barcelona Supercomputing Center). I share it at Towards Data Science just in case it can be useful for other readers.", "Acknowledgment: Many thanks to Juan Luis Dom\u00ednguez and Oriol Aranda from BSC-CNS, who wrote the first version of the codes that appear in this series of posts, and to Carlos Tripiana and Francisco Gonzalez for the essential support with the deployment of the software stack of POWER-CTE Supercomputer. Also many thanks to Alvaro Jover Alvarez, Miquel Escobar Castells and Raul Garcia Fuentes for their contributions to the proofreading of this document.", "Professor at UPC Barcelona Tech & Barcelona Supercomputing Center. Research focuses on Supercomputing & Artificial Intelligence https://torres.ai @JordiTorresAI"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2d1eea004cb2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/supercomputing-for-a-i", "anchor_text": "SUPERCOMPUTING FOR ARTIFICIAL INTELLIGENCE \u2014 05"}, {"url": "https://torres-ai.medium.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Jordi TORRES.AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F497013a3c715&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&user=Jordi+TORRES.AI&userId=497013a3c715&source=post_page-497013a3c715----2d1eea004cb2---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d1eea004cb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&user=Jordi+TORRES.AI&userId=497013a3c715&source=-----2d1eea004cb2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d1eea004cb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&source=-----2d1eea004cb2---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://bsc.es/", "anchor_text": "BSC"}, {"url": "https://www.fib.upc.edu/en/studies/masters/master-innovation-and-research-informatics/curriculum/syllabus/SA-MIRI", "anchor_text": "Supercomputers Architecture"}, {"url": "https://www.upc.edu/en?set_language=en", "anchor_text": "UPC Barcelona Tech"}, {"url": "https://bsc.es/", "anchor_text": "BSC"}, {"url": "https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af", "anchor_text": "the previous post"}, {"url": "http://eng.uber.com/michelangelo", "anchor_text": "Michelangelo"}, {"url": "https://arxiv.org/pdf/1802.05799.pdf", "anchor_text": "Horovod"}, {"url": "https://github.com/uber/horovod", "anchor_text": "is available under the Apache 2.0 license"}, {"url": "https://web.archive.org/web/20180128132031/http://research.baidu.com/bringing-hpc-techniques-deep-learning/", "anchor_text": "Baidu\u2019s"}, {"url": "http://www.cs.fsu.edu/~xyuan/paper/09jpdc.pdf", "anchor_text": "paper by Patarasuk and Yuan"}, {"url": "https://developer.nvidia.com/nccl", "anchor_text": "NCCL-2"}, {"url": "https://arxiv.org/pdf/1802.05799.pdf", "anchor_text": "paper by Sergeev and Balso"}, {"url": "https://arxiv.org/abs/1802.05799", "anchor_text": "Sergeev, A., & Del Balso, M. Horovod: fast and easy distributed deep learning in TensorFlow"}, {"url": "https://towardsdatascience.com/visual-intuition-on-ring-allreduce-for-distributed-deep-learning-d1f34b4911da", "anchor_text": "Visual intuition on ring-allreduce for distributed Deep Learning"}, {"url": "http://www.cs.fsu.edu/~xyuan/paper/09jpdc.pdf", "anchor_text": "Patarasuk and Yuan"}, {"url": "https://en.wikipedia.org/wiki/Message_Passing_Interface", "anchor_text": "MPI"}, {"url": "https://developer.nvidia.com/nccl", "anchor_text": "NCCL-2"}, {"url": "https://github.com/facebookincubator/gloo", "anchor_text": "Gloo"}, {"url": "https://arxiv.org/pdf/1706.02677.pdf", "anchor_text": "this Facebook\u2019s paper"}, {"url": "https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af", "anchor_text": "the previous post"}, {"url": "https://slurm.schedmd.com", "anchor_text": "SLURM workload manager"}, {"url": "https://towardsdatascience.com/using-supercomputers-for-deep-learning-training-3f9cc3f51d3", "anchor_text": "Post 2"}, {"url": "https://www.fib.upc.edu/en/studies/masters/master-innovation-and-research-informatics/curriculum/syllabus/SA-MIRI", "anchor_text": "the master course"}, {"url": "https://github.com/horovod/horovod/blob/master/docs/benchmarks.rst", "anchor_text": "literature on the subject shows"}, {"url": "https://towardsdatascience.com/tagged/supercomputing-for-a-i", "anchor_text": "this series"}, {"url": "https://www.upc.edu/en?set_language=en", "anchor_text": "UPC Barcelona Tech"}, {"url": "https://www.upc.edu/en?set_language=en", "anchor_text": "Barcelona Supercomputing Center"}, {"url": "https://towardsdatascience.com", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/artificial-intelligence-is-a-supercomputing-problem-4b0edbc2888d", "anchor_text": "Artificial Intelligence is a Supercomputing problem"}, {"url": "https://towardsdatascience.com/using-supercomputers-for-deep-learning-training-3f9cc3f51d3", "anchor_text": "Using Supercomputers for Deep Learning Training"}, {"url": "https://towardsdatascience.com/scalable-deep-learning-on-parallel-and-distributed-infrastructures-e5fb4a956bef", "anchor_text": "Scalable Deep Learning on Parallel and Distributed Infrastructures"}, {"url": "https://towardsdatascience.com/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af", "anchor_text": "Train a Neural Network on multi-GPU with TensorFlow"}, {"url": "https://towardsdatascience.com/distributed-deep-learning-with-horovod-2d1eea004cb2", "anchor_text": "Distributed Deep Learning with Horovod"}, {"url": "https://www.bsc.es/dominguez-bermudez-juan-luis", "anchor_text": "Juan Luis Dom\u00ednguez"}, {"url": "https://www.bsc.es/aranda-llorens-oriol", "anchor_text": "Oriol Aranda"}, {"url": "https://www.bsc.es/tripiana-carlos", "anchor_text": "Carlos Tripiana"}, {"url": "https://www.bsc.es/gonzalez-carrillo-francisco-jose", "anchor_text": "Francisco Gonzalez"}, {"url": "https://www.bsc.es/jover-alvarez-alvaro", "anchor_text": "Alvaro Jover Alvarez"}, {"url": "https://www.bsc.es/escobar-castells-miquel", "anchor_text": "Miquel Escobar Castells"}, {"url": "https://www.bsc.es/garcia-fuentes-raul", "anchor_text": "Raul Garcia Fuentes"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2d1eea004cb2---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/horovod?source=post_page-----2d1eea004cb2---------------horovod-----------------", "anchor_text": "Horovod"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----2d1eea004cb2---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/supercomputing-for-a-i?source=post_page-----2d1eea004cb2---------------supercomputing_for_a_i-----------------", "anchor_text": "Supercomputing For A I"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----2d1eea004cb2---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d1eea004cb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&user=Jordi+TORRES.AI&userId=497013a3c715&source=-----2d1eea004cb2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d1eea004cb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&user=Jordi+TORRES.AI&userId=497013a3c715&source=-----2d1eea004cb2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d1eea004cb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F497013a3c715&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&user=Jordi+TORRES.AI&userId=497013a3c715&source=post_page-497013a3c715----2d1eea004cb2---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9fb911e344f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&newsletterV3=497013a3c715&newsletterV3Id=9fb911e344f9&user=Jordi+TORRES.AI&userId=497013a3c715&source=-----2d1eea004cb2---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Written by Jordi TORRES.AI"}, {"url": "https://torres-ai.medium.com/followers?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "2.1K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://torres.ai", "anchor_text": "https://torres.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F497013a3c715&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&user=Jordi+TORRES.AI&userId=497013a3c715&source=post_page-497013a3c715----2d1eea004cb2---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9fb911e344f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdistributed-deep-learning-with-horovod-2d1eea004cb2&newsletterV3=497013a3c715&newsletterV3Id=9fb911e344f9&user=Jordi+TORRES.AI&userId=497013a3c715&source=-----2d1eea004cb2---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7?source=author_recirc-----2d1eea004cb2----0---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=author_recirc-----2d1eea004cb2----0---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=author_recirc-----2d1eea004cb2----0---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Jordi TORRES.AI"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2d1eea004cb2----0---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7?source=author_recirc-----2d1eea004cb2----0---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "The Bellman EquationV-function and Q-function Explained"}, {"url": "https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7?source=author_recirc-----2d1eea004cb2----0---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "\u00b712 min read\u00b7Jun 11, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F59258a0d3fa7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-bellman-equation-59258a0d3fa7&user=Jordi+TORRES.AI&userId=497013a3c715&source=-----59258a0d3fa7----0-----------------clap_footer----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7?source=author_recirc-----2d1eea004cb2----0---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F59258a0d3fa7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-bellman-equation-59258a0d3fa7&source=-----2d1eea004cb2----0-----------------bookmark_preview----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2d1eea004cb2----1---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2d1eea004cb2----1---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----2d1eea004cb2----1---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2d1eea004cb2----1---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2d1eea004cb2----1---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2d1eea004cb2----1---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----2d1eea004cb2----1---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----2d1eea004cb2----1-----------------bookmark_preview----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2d1eea004cb2----2---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----2d1eea004cb2----2---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----2d1eea004cb2----2---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2d1eea004cb2----2---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2d1eea004cb2----2---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2d1eea004cb2----2---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----2d1eea004cb2----2---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----2d1eea004cb2----2-----------------bookmark_preview----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/deep-q-network-dqn-ii-b6bf911b6b2c?source=author_recirc-----2d1eea004cb2----3---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=author_recirc-----2d1eea004cb2----3---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=author_recirc-----2d1eea004cb2----3---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Jordi TORRES.AI"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----2d1eea004cb2----3---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/deep-q-network-dqn-ii-b6bf911b6b2c?source=author_recirc-----2d1eea004cb2----3---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "Deep Q-Network (DQN)-IIExperience Replay and Target Networks"}, {"url": "https://towardsdatascience.com/deep-q-network-dqn-ii-b6bf911b6b2c?source=author_recirc-----2d1eea004cb2----3---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": "\u00b714 min read\u00b7Aug 15, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb6bf911b6b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-q-network-dqn-ii-b6bf911b6b2c&user=Jordi+TORRES.AI&userId=497013a3c715&source=-----b6bf911b6b2c----3-----------------clap_footer----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/deep-q-network-dqn-ii-b6bf911b6b2c?source=author_recirc-----2d1eea004cb2----3---------------------57ec3e7d_605e_41d1_ad31_8f41f5797e01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb6bf911b6b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-q-network-dqn-ii-b6bf911b6b2c&source=-----2d1eea004cb2----3-----------------bookmark_preview----57ec3e7d_605e_41d1_ad31_8f41f5797e01-------", "anchor_text": ""}, {"url": "https://torres-ai.medium.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "See all from Jordi TORRES.AI"}, {"url": "https://towardsdatascience.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@weiyunna91?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@weiyunna91?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "YUNNA WEI"}, {"url": "https://medium.com/trigger-ai?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Efficient Data+AI Stack"}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "MLOps in Practice \u2014 Machine Learning (ML) model deployment patterns (Part 1)Machine Learning (ML) model serving and deployment is one of the most critical components of any solid ML solution architecture. This\u2026"}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "\u00b711 min read\u00b7Jan 26"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftrigger-ai%2Fce7cb575feda&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ftrigger-ai%2Fmlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda&user=YUNNA+WEI&userId=4b47aa84fc4&source=-----ce7cb575feda----0-----------------clap_footer----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce7cb575feda&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ftrigger-ai%2Fmlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda&source=-----2d1eea004cb2----0-----------------bookmark_preview----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----2d1eea004cb2----1-----------------bookmark_preview----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----2d1eea004cb2----0---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----2d1eea004cb2----0-----------------bookmark_preview----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://alessandroai.medium.com/?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://alessandroai.medium.com/?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Alessandro Lamberti"}, {"url": "https://medium.com/artificialis?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Artificialis"}, {"url": "https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Maximizing Model Performance with Knowledge Distillation in PyTorchBoost your model\u2019s accuracy and save on resources with knowledge distillation in PyTorch"}, {"url": "https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "\u00b75 min read\u00b7Dec 8, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificialis%2F12b3960a486a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fartificialis%2Fmaximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a&user=Alessandro+Lamberti&userId=7fc4b5ed0ad1&source=-----12b3960a486a----1-----------------clap_footer----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/artificialis/maximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a?source=read_next_recirc-----2d1eea004cb2----1---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F12b3960a486a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fartificialis%2Fmaximizing-model-performance-with-knowledge-distillation-in-pytorch-12b3960a486a&source=-----2d1eea004cb2----1-----------------bookmark_preview----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----2d1eea004cb2----2---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin?source=read_next_recirc-----2d1eea004cb2----2---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin?source=read_next_recirc-----2d1eea004cb2----2---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Nitin Kishore"}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----2d1eea004cb2----2---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "How to solve CUDA Out of Memory error**Freeze frame, scratch that record and cue \u2014 \u2018The Who\u2019 intro**"}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----2d1eea004cb2----2---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "\u00b77 min read\u00b7Nov 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F850bb247cfb2&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40snk.nitin%2Fhow-to-solve-cuda-out-of-memory-error-850bb247cfb2&user=Nitin+Kishore&userId=ef6a1cf849e2&source=-----850bb247cfb2----2-----------------clap_footer----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@snk.nitin/how-to-solve-cuda-out-of-memory-error-850bb247cfb2?source=read_next_recirc-----2d1eea004cb2----2---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F850bb247cfb2&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40snk.nitin%2Fhow-to-solve-cuda-out-of-memory-error-850bb247cfb2&source=-----2d1eea004cb2----2-----------------bookmark_preview----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2d1eea004cb2----3---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----2d1eea004cb2----3---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----2d1eea004cb2----3---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----2d1eea004cb2----3---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2d1eea004cb2----3---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2d1eea004cb2----3---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----3-----------------clap_footer----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----2d1eea004cb2----3---------------------d6fbae04_b840_4cb8_bc14_b64c83f63445-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----2d1eea004cb2----3-----------------bookmark_preview----d6fbae04_b840_4cb8_bc14_b64c83f63445-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----2d1eea004cb2--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}