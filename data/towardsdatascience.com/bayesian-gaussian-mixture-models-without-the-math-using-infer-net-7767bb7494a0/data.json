{"url": "https://towardsdatascience.com/bayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0", "time": 1683013634.447239, "path": "towardsdatascience.com/bayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0/", "webpage": {"metadata": {"title": "Bayesian Gaussian mixture models (without the math) using Infer.NET | by Jaco du Toit | Towards Data Science", "h1": "Bayesian Gaussian mixture models (without the math) using Infer.NET", "description": "This post provides a brief introduction to Bayesian Gaussian mixture models and share my experience of building these types of models in Microsoft\u2019s Infer.NET probabilistic graphical model framework\u2026"}, "outgoing_paragraph_urls": [{"url": "https://dotnet.github.io/infer/default.html", "anchor_text": "Microsoft\u2019s Infer.NET", "paragraph_index": 0}, {"url": "https://pythonnet.github.io/", "anchor_text": "pythonnet", "paragraph_index": 0}, {"url": "http://www.mbmlbook.com/", "anchor_text": "Model-based machine learning", "paragraph_index": 0}, {"url": "https://github.com/dotnet/infer", "anchor_text": "Infer.NET documentation", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Normal_distribution", "anchor_text": "parameterised", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Conjugate_prior", "anchor_text": "conjugate prior", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Gamma_distribution", "anchor_text": "Gamma distribution", "paragraph_index": 7}, {"url": "https://dotnet.github.io/infer/userguide/Working%20with%20different%20inference%20algorithms.html", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Variational_message_passing", "anchor_text": "Variational message passing", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Dirichlet_distribution", "anchor_text": "Dirichlet distribution", "paragraph_index": 16}, {"url": "https://github.com/jacowp357/bayesian-gaussian-mixtures", "anchor_text": "here", "paragraph_index": 19}], "all_paragraphs": ["This post provides a brief introduction to Bayesian Gaussian mixture models and share my experience of building these types of models in Microsoft\u2019s Infer.NET probabilistic graphical model framework. Being comfortable and familiar with k-means clustering and Python, I found it challenging to learn c#, Infer.NET and some of the underlying Bayesian principles used in probabilistic inference. That being said, there is a way for Python programmers to integrate .NET components and services using pythonnet, which I will cover in a follow-up post. My hope is that the content of this post will save you time, remove any intimidation that the theory may bring and demonstrate some of the advantages of what is known as the Model-based machine learning (MBML) approach. Please follow the guidelines provided in the Infer.NET documentation to get set up with the Infer.NET framework.", "Bayesian Gaussian mixture models constitutes a form of unsupervised learning and can be useful in fitting multi-modal data for tasks such as clustering, data compression, outlier detection, or generative classifiers. Each Gaussian component is usually a multivariate Gaussian with a mean vector and covariance matrix, but for the sake of demonstration we will consider a less complicated univariate case.", "We begin by sampling data from a univariate Gaussian distribution and store the data in a .csv file using Python code:", "This is what our data looks like:", "Let us pretend for a moment we did not know the distribution that generated our data set. We visualise the data and make the assumption that the data was generated by a Gaussian distribution. In other words, we hope that a Gaussian distribution can sufficiently describe our data set. However, we do not know the location or the spread of this Gaussian distribution. A Gaussian distribution can be parameterised by a mean and variance parameter. Sometimes it is easier mathematically to use a mean and precision, where precision is simply the inverse of variance. We will stick with precision for which the intuition is that the higher the precision the narrower (or more \u201ccertain\u201d) the spread of the Gaussian distribution.", "Firstly, we are interested in finding the mean parameter of this Gaussian distribution, and will pretend that we know the value of its precision (we set the precision=1). In other words, we think our data is Gaussian distributed and we are unsure what its mean parameter is, but we feel confident that it has a precision=1. Can we learn its mean parameter from the data? It turns out we need a second Gaussian distribution to depict the mean of our first Gaussian distribution. This is known as a conjugate prior. Here is a graphical representation of learning the unknown mean (using a Gaussian prior with parameters mean=0, precision=1):", "Notice the difference between the mean random variable and the known precision in the graph. Here is the code in Infer.NET:", "After observing only 100 data points we now have a posterior Gaussian distribution, which depicts the mean of our data x. We have learned something useful from the data! But wait\u2026 we can also learn something about its precision, without having to pretend it is fixed at 1. How? We do the same thing we did to the mean and place a distribution over the precision (effectively removing our \u201cinfinitely confident\u201d knowledge that it was equal to 1 by replacing it with something resembling our \u201cuncertainty\u201d). The conjugate prior for precision is the Gamma distribution. We update our graphical representation of the model by including the Gamma distribution (with prior parameters shape=2, rate=1) over a new precision random variable:", "Here is the code in Infer.NET:", "A recap of our assumptions up to this point (referring to the figures below):", "Infer.NET can produce a Factor graph of our model when setting ShowFactorGraph = true. Factor nodes are shown in black boxes and variable nodes are shown in white boxes. This graph shows our data x (the observed variable array at the bottom), which depends on a Gaussian factor. The Gaussian factor depends on a random variable called mean, and a random variable called precision. These random variables depend on a Gaussian prior and a Gamma prior respectively. The parameter values of both prior distributions are shown at the top of the graph.", "We made certain assumptions in order to learn what the mean and precision of the Gaussian distribution are. In MBML, learning and inference is essentially the same. You can read more on the supported Infer.NET inference techniques and their differences here. The examples in this article make use of Variational message passing (VMP). In order to learn more complex distributions (i.e., multi-modal densities) this model will not be expressive enough and should be extended by introducing more assumptions. Ready to mix things up?", "As with many things in life if one Gaussian is good, more should be better, right! First, we need a new data set and use the same Python code introduced at the start of the post. The only difference is that we set p=[0.4, 0.2, 0.4]. This means that 80% of the data should be sampled from the first and third Gaussian distribution, while 20% of the data should be sampled from the second. The data can be visualised:", "To create the model we will use k=3 number of Gaussian distributions, also known as components, to fit our data set. In other words, we have three mean random variables and three precision random variables that we need to learn, but we also need a latent random variable z. This random variable has a discrete distribution and is responsible for selecting the components that best describe its associated observed x value. For example, more weight should be assigned to state one of z\u2080 if the observed x\u2080 is best explained by Gaussian component one. In this example, we will pretend to know the mixture weights responsible for all data points and use a uniform assignment (w\u2080=1/3, w\u2081=1/3, w\u2082=1/3) as shown in the graph below.", "Here is the code in Infer.NET:", "The three Gaussian distributions/components learned from the data are plotted below:", "Hold on\u2026we claimed to have full knowledge of the component weights, but what if we do not? Can we also learn the weights from the data? Indeed, but we need a prior! A Dirichlet distribution is the conjugate prior for the discrete/categorical distribution. The graph below is updated showing a random variable for the unknown weights with its accompanying Dirichlet prior.", "Here is the code in Infer.NET:", "The three Gaussian distributions/components learned from the data and their learned weights are illustrated below:", "In summary, we started this journey by assuming our first data set can sufficiently be described by the Gaussian distribution. We were able to learn the mean parameters and the precision parameters of the Gaussian distribution using the observed data and VMP inference in Infer.NET. Our second data set used a more complex generating mechanism, which requires a more expressive model. We then introduced a latent variable z and Dirichlet prior, which allows us to learn mixtures of Gaussian distributions and their mixture weights. All steps are provided in c# code using Infer.NET and can be accessed here.", "For a more formal treatment the following books and links come recommended:", "Important concepts that were not mentioned in this post:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Part-time PhD on channel coding and practicing machine learning individual. Passionate to learn and share."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7767bb7494a0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jacowp357?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jacowp357?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "Jaco du Toit"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F815098f8de27&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&user=Jaco+du+Toit&userId=815098f8de27&source=post_page-815098f8de27----7767bb7494a0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7767bb7494a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7767bb7494a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://dotnet.github.io/infer/default.html", "anchor_text": "Microsoft\u2019s Infer.NET"}, {"url": "https://pythonnet.github.io/", "anchor_text": "pythonnet"}, {"url": "http://www.mbmlbook.com/", "anchor_text": "Model-based machine learning"}, {"url": "https://github.com/dotnet/infer", "anchor_text": "Infer.NET documentation"}, {"url": "https://en.wikipedia.org/wiki/Normal_distribution", "anchor_text": "parameterised"}, {"url": "https://en.wikipedia.org/wiki/Conjugate_prior", "anchor_text": "conjugate prior"}, {"url": "https://en.wikipedia.org/wiki/Gamma_distribution", "anchor_text": "Gamma distribution"}, {"url": "https://dotnet.github.io/infer/userguide/Working%20with%20different%20inference%20algorithms.html", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Variational_message_passing", "anchor_text": "Variational message passing"}, {"url": "https://en.wikipedia.org/wiki/Dirichlet_distribution", "anchor_text": "Dirichlet distribution"}, {"url": "https://github.com/jacowp357/bayesian-gaussian-mixtures", "anchor_text": "here"}, {"url": "https://dotnet.github.io/infer/InferNet101.pdf", "anchor_text": "https://dotnet.github.io/infer/InferNet101.pdf"}, {"url": "http://mbmlbook.com/index.html", "anchor_text": "http://mbmlbook.com/index.html"}, {"url": "http://www.jmlr.org/papers/volume6/winn05a/winn05a.pdf", "anchor_text": "http://www.jmlr.org/papers/volume6/winn05a/winn05a.pdf"}, {"url": "https://en.wikipedia.org/wiki/Exponential_family", "anchor_text": "https://en.wikipedia.org/wiki/Exponential_family"}, {"url": "https://medium.com/tag/gaussian-mixture-model?source=post_page-----7767bb7494a0---------------gaussian_mixture_model-----------------", "anchor_text": "Gaussian Mixture Model"}, {"url": "https://medium.com/tag/probabilistic-programming?source=post_page-----7767bb7494a0---------------probabilistic_programming-----------------", "anchor_text": "Probabilistic Programming"}, {"url": "https://medium.com/tag/bayesian-inference?source=post_page-----7767bb7494a0---------------bayesian_inference-----------------", "anchor_text": "Bayesian Inference"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7767bb7494a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&user=Jaco+du+Toit&userId=815098f8de27&source=-----7767bb7494a0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7767bb7494a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&user=Jaco+du+Toit&userId=815098f8de27&source=-----7767bb7494a0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7767bb7494a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7767bb7494a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7767bb7494a0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7767bb7494a0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7767bb7494a0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7767bb7494a0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jacowp357?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jacowp357?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jaco du Toit"}, {"url": "https://medium.com/@jacowp357/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "40 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F815098f8de27&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&user=Jaco+du+Toit&userId=815098f8de27&source=post_page-815098f8de27--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F564ac53e910f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-gaussian-mixture-models-without-the-math-using-infer-net-7767bb7494a0&newsletterV3=815098f8de27&newsletterV3Id=564ac53e910f&user=Jaco+du+Toit&userId=815098f8de27&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}