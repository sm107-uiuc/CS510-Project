{"url": "https://towardsdatascience.com/a-big-of-tricks-for-image-classification-fec41eb28e01", "time": 1682994257.080607, "path": "towardsdatascience.com/a-big-of-tricks-for-image-classification-fec41eb28e01/", "webpage": {"metadata": {"title": "A Bag of Tricks for Image Classification | by George Seif | Towards Data Science", "h1": "A Bag of Tricks for Image Classification", "description": "When was the last time that you saw theory 100% matched practice in Deep Learning? It very rarely happens! The research paper says one thing, but the results in the real-world are often quite\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.superquotes.co/?utm_source=mediumtech&utm_medium=web&utm_campaign=sharing", "anchor_text": "Super Quotes newsletter", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1812.01187v2.pdf", "anchor_text": "Recent research", "paragraph_index": 3}, {"url": "https://www.pyimagesearch.com/2017/10/30/how-to-multi-gpu-training-with-keras-python-and-deep-learning/", "anchor_text": "Keras", "paragraph_index": 6}, {"url": "https://arxiv.org/pdf/1708.04552.pdf", "anchor_text": "Cutout Regularisation", "paragraph_index": 20}, {"url": "https://twitter.com/GeorgeSeif94", "anchor_text": "twitter", "paragraph_index": 21}], "all_paragraphs": ["Want to be inspired? Come join my Super Quotes newsletter. \ud83d\ude0e", "When was the last time that you saw theory 100% matched practice in Deep Learning? It very rarely happens! The research paper says one thing, but the results in the real-world are often quite different.", "It\u2019s not entirely the fault of the research. Much of the point of scientific research is experimentation \u2014 based on these specific circumstances, with this dataset, we got these results. Once you actually try and apply the models, the challenge of dealing with noisy and wild data comes into play. The theory doesn\u2019t always line up with what actually happens in the real-world, but it does provide a decent baseline.", "So what\u2019s the cause of this gap between theory and practice? It\u2019s not entirely coming from the new data! Much of the difference comes from the \u201ctricks\u201d that deep learning experts use to give their models that extra boost. These are the hidden tricks of the trade that you only get by extensive experimentation with the models, or just learning from someone who has. Recent research from Amazon\u2019s research group has quantified this, showing that these tricks can get you as much as a 4% accuracy boost on the same model.", "In this post, you\u2019ll learn about that research and the most prominent bag of tricks experts use to give their deep learning models that extra boost. I\u2019ll give you the practical viewpoint on things aimed at actually using these tricks in an application setting.", "In theory, a larger mini-batch size should help the network converge to a better minimum and therefore better final accuracy. People usually get stuck here because of GPU memory, since the biggest consumer GPUs one can buy only go up to 12GB (for the Titan X) and 16GB on the cloud (for the V100). There are 2 ways we can get around that challenge:", "(1) Distributed training: Split up your training over multiple GPUs. on each training step, your batch will be split up across the available GPUs. For example, if you have a batch size of 8 and 8 GPUs, then each GPU will process one image. You\u2019ll then combine all the gradients and outputs at the end. You do take a small hit from the data transfer between GPUs, but still gain a big speed boost from the parallel processing. This functionality is supported right out of the box in many deep learning libraries, including Keras.", "(2) Changing the batch and image size during training: Part of the reason why many research papers are able to report the use of such large batch sizes is that many standard research datasets have images that aren\u2019t very big. When training networks on ImageNet for example, most state-of-the-art network used crops between 200 and 350; of course they can have large batches with such small image sizes! In practice, due to current camera technology, most of the time we are working with images that are 1080p or at least not too far off from it.", "To get around this small bump in the road, you can start off your training with smaller images and larger batch size. Do this by downsampling your training images. You\u2019ll then be able to fit many more of them into one batch. With the large batch size + small images you should be able to already get some decent results. To complete the training of your network, fine tune it with a smaller learning rate and large images with a smaller batch size. This will get the network to re-adapt to the higher resolution and the lower learning rate keeps the network from jumping away from the good minimum found from the large batch. As a result, your network is able to get to a good minimum from the large batch training and works well on your high-resolution images from the fine tuning.", "The research paper doesn\u2019t always tell you the full story. Authors will often have links to their official code in the paper and that can be an even better resource for learning about the algorithm than the paper itself! When you read the code, you may find that they left out a couple of small model details that actually made a big accuracy difference.", "I encourage all to look at the official code of the research paper so that you can see the exact code the researchers used to get their results. Doing this will also give you a nice template to work off of such that you can quickly make your own little tweaks and alterations to see if they improve the model. It\u2019s also helpful to explore some of the public re-implementations of the models as these may have code that others have experimented with that ended up improving on the original model. Check out the ResNet architecture below and the 3 alterations that were found in some public code. They look tiny but each of them gave a non-negligible accuracy boost with virtually no change in run-time; ResNet-D gave a full 1% boost in Top-1 accuracy.", "How a deep network is trained often varies according to both the application at hand and the research team actually setting up the training! Knowing how to properly train your network can get you as much as a 3\u20134% boost in accuracy! It\u2019s a skill acquired from both knowledge of deep networks and simply a bit of practice. Unfortunately, most people don\u2019t pay much attention to the training and expect the network to magically get them great results!", "Try to pay attention to the specific training strategies used in state-of-the-art research. You\u2019ll often see that most of them won\u2019t just default to a single learning rate with an adaptive method like Adam or RMSProp. They use things like warm-up training, rate-decays, and a combination of optimisation methods to get the tip top accuracy they can possibly squeeze out.", "The Adam optimiser is super easy to use and tends to settle at a good learning rate all on its own. SGD on the other hand usually gets you a nice 1\u20132% boost over Adam but is much harder to tune. So, start off with Adam: just set a learning rate that\u2019s not absurdly high, commonly defaulted at 0.0001 and you\u2019ll usually get some very good results. Then, once your model starts to saturate with Adam, fine tune with SGD at a smaller learning rate to squeeze in that last bit of accuracy!", "Unless you\u2019re doing cutting edge research and trying to break the fundamental state-of-the-art, transfer learning should be the default method of practice. Training networks from scratch on new data is challenging, time consuming, and can sometimes require some extra domain expertise to really get it right.", "Transfer learning offers an easy way to both speed up training and boost accuracy. There has been a substantial amount of research and practical evidence that consistently shows transfer learning making models much easier to train and boosting accuracy over that of training from scratch. It will totally simplify things and make it much easier for you to get some decent baseline results.", "In general, models with higher accuracy (relative to each other on the same dataset) will be better for transfer learning and get you better final results. The only other thing to be aware of is to choose your pre-trained network for transfer learning in accordance with your target task. For example, using a network pre-trained for self-driving cars on a dataset for medical imaging wouldn't be such a great idea; it\u2019s a huge gap between the domains as the data itself is quite different. You\u2019d be better off training from scratch and not starting your network off with a bias towards data that is totally different from medical imaging!", "Data augmentation is another big accuracy booster. Most people stick with the classic rotation and flipping, which is fine. If you have the time to wait for training on those extra images, they can potentially give you a few percentage-points of extra accuracy boost pretty much for free!", "But the state-of-the-art goes beyond that.", "Once you start reading more deeply into the research you\u2019ll discover the more advanced data augmentations that give deep networks that final push. Scaling, i.e multiplying the colours or brightness values of image pixels will expose the network to training images that are of a much wider variety than your original dataset. It helps to account for such variations, especially, for example, different lighting conditions based on the room or weather, which change quite frequently in the real-world.", "Another technique which is now commonly used on the very latest ImageNet models is Cutout Regularisation. Despite the name, cutout can be really seen as a form of augmenting your data to handle occlusion. Occlusion is an extremely common challenge in real-world applications, especially in the hot computer vision areas of robotics and self-driving cars. By quite literally applying a form of occlusion to the training data, we effectively adapt our network to be more robust to it.", "Follow me on twitter where I post all about the latest and greatest AI, Technology, and Science!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffec41eb28e01&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@george.seif94?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@george.seif94?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "George Seif"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2af5c8737ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&user=George+Seif&userId=e2af5c8737ec&source=post_page-e2af5c8737ec----fec41eb28e01---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffec41eb28e01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffec41eb28e01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.superquotes.co/?utm_source=mediumtech&utm_medium=web&utm_campaign=sharing", "anchor_text": "Super Quotes newsletter"}, {"url": "https://arxiv.org/pdf/1812.01187v2.pdf", "anchor_text": "Recent research"}, {"url": "https://www.pyimagesearch.com/2017/10/30/how-to-multi-gpu-training-with-keras-python-and-deep-learning/", "anchor_text": "Keras"}, {"url": "https://arxiv.org/pdf/1711.07240.pdf", "anchor_text": "MegDet paper"}, {"url": "https://arxiv.org/pdf/1812.01187.pdf", "anchor_text": "Bag of Tricks paper"}, {"url": "https://arxiv.org/pdf/1812.01187.pdf", "anchor_text": "Bag of Tricks paper"}, {"url": "https://www.slideshare.net/xavigiro/transfer-learning-d2l4-insightdcu-machine-learning-workshop-2017", "anchor_text": "original"}, {"url": "https://arxiv.org/pdf/1708.04552.pdf", "anchor_text": "Cutout Regularisation"}, {"url": "https://twitter.com/GeorgeSeif94", "anchor_text": "twitter"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----fec41eb28e01---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----fec41eb28e01---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----fec41eb28e01---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/technology?source=post_page-----fec41eb28e01---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/innovation?source=post_page-----fec41eb28e01---------------innovation-----------------", "anchor_text": "Innovation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffec41eb28e01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&user=George+Seif&userId=e2af5c8737ec&source=-----fec41eb28e01---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffec41eb28e01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&user=George+Seif&userId=e2af5c8737ec&source=-----fec41eb28e01---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffec41eb28e01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffec41eb28e01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fec41eb28e01---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fec41eb28e01--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fec41eb28e01--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fec41eb28e01--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@george.seif94?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@george.seif94?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "George Seif"}, {"url": "https://medium.com/@george.seif94/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2af5c8737ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&user=George+Seif&userId=e2af5c8737ec&source=post_page-e2af5c8737ec--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc78596234267&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-big-of-tricks-for-image-classification-fec41eb28e01&newsletterV3=e2af5c8737ec&newsletterV3Id=c78596234267&user=George+Seif&userId=e2af5c8737ec&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}