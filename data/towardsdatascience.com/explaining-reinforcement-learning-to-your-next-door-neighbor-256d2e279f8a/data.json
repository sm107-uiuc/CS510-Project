{"url": "https://towardsdatascience.com/explaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a", "time": 1683011543.328251, "path": "towardsdatascience.com/explaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a/", "webpage": {"metadata": {"title": "Explaining Reinforcement Learning to your next-door-neighbor | by Kartik Chaudhary | Towards Data Science", "h1": "Explaining Reinforcement Learning to your next-door-neighbor", "description": "Reinforcement Learning (RL) is a very interesting sub-field of Machine Learning(ML). While other ML techniques rely on static input-output pairs to learn the hidden rules and then apply those rules\u2026"}, "outgoing_paragraph_urls": [{"url": "https://dropsofai.com", "anchor_text": "https://dropsofai.com", "paragraph_index": 28}], "all_paragraphs": ["Reinforcement Learning (RL) is a very interesting sub-field of Machine Learning(ML). While other ML techniques rely on static input-output pairs to learn the hidden rules and then apply those rules on the unseen data to get the possible outcomes. A Reinforcement Learning algorithm tends to learn the best decisions automatically over time.", "RL techniques are widely used in solving puzzles and developing smart agents capable of defeating humans in hundreds of different games. Apart from this, there are multiple practical applications of RL like \u2014", "Let\u2019s learn how RL works \u2014", "Machine Learning techniques like \u2014 supervised learning, unsupervised learning, learn from given latent historical data, and then are deployed to produce results on the unseen(future) data. The goodness of such models depends upon the quality of training data given. These models fail abruptly when/if some new unseen(new variety of data which was not present in the training set) examples come into the picture.", "Reinforcement learning-based algorithms are able to address such issues. RL models are designed in such a way that they learn the variations of the data with time and keep the performance high. Let\u2019s learn more about RL \u2014", "An RL based algorithm learns to make the best decisions automatically over time. It learns from the mistakes done in the past and attempts to make the best decisions at each point in time in the future. This approach of learning from experience is very similar to how humans learn and grow. This idea draws RL closer to the purpose of Artificial Intelligence. Let\u2019s dive into more details of RL \u2014", "Hope everyone can recollect memories of old snake-feeding games, if not, then the following video will definitely remind you \u2014", "Now let\u2019s write down five magic words, whole RL thing will circle around these five terms \u2014", "Let\u2019s understand these five terms while relating to the snake-feeding game.", "Every RL problem can be broken into two major blocks \u2014 1.Agent 2.Environment. An agent is something that can do a few things(a set of well-defined things) and the goal of our RL algorithm is to teach this agent to do those things in such a way that a particular objective(defined by solver) is achieved. Apart from the agent, everything else is called the environment. Agents perform all their activities in the environments and keep changing the states of environments at each step.", "Here \u2014 Snake is the agent and the entire green playground along with the bait/food is the environment. This snake can do things, it can walk-straight, turn-left, turn-right. The solver can define an objective like \u2014 eat as many baits as possible \u2018or\u2019 eat 100 baits. Now our trained and working RL algorithm should instruct this snake to take appropriate actions such that the solver\u2019s objective is achieved.", "As discussed, RL agents do certain things and can change the state of the environment at each step. A well-defined set of those things is called the action space of the given agent. At each step, the agent picks one action from the action space(Randomly \u2014 if no RL algorithm is implemented) and performs it.", "This action might change the environment in a certain way, and this change in the environment by the performed action is called the Observation. Each action step is associated with some reward (ie. a scalar value- 2, 5, 100\u2026 anything) and observation. The reward is defined by the problem-solver, such that more reward takes the agent closer to the objective.", "Summing up:- At each step, the agent will perform an action and get some reward and record the observation. Here \u2014 the primary goal of our RL algorithm is to help the agent pick the best action at each step so that it gets a good reward every time and eventually completes the objective.", "Observations and Rewards collected(from past actions) help the RL algorithm understand the environment and decide the next best move for the agent. Most of the time some supervised learning algorithm is used to decide the best move. Usually, the observations from games are screenprints of the environment, thus Deep Learning algorithms(Convolutional Neural Networks) are used very frequently.", "In our snake feeding game, the RL algorithm is supposed to give the snake instructions(one of the \u2014 go straight, turn left, turn right) at each step. These commands should help the snake eat sufficient baits so that our objective is completed. RL model needs to keep one thing in mind that \u2014 snake mustn\u2019t die before completing the objective, otherwise \u2014 Game Over. Once our game is over, episode completes and we need to start over.", "Just another term used in RL-vocabulary to define the end of the task. If your episode ends before completing the objective then your RL algorithm needs more tweaking/training/enhancements.", "Why don\u2019t we apply RL in all our ML problems?", "I guess now everyone has a fair understanding of how this whole RL thing works. The concept seems pretty simple and intuitive, but truly there are few hurdles we encounter while implementing such algorithms. Let\u2019s learn more about them \u2014", "Listed are a few things which make the development of RL based models complicated \u2014", "I. Suppose our agent keeps making mistakes and doesn\u2019t gather any reward. Now observations from such mistakes are not fruitful and may not show the agent how to earn reward going further. The agent may suffer in such situations and RL might fail to solve such scenarios.", "II. Imagine you are writing an RL algorithm to play and win Chess. Now chess is a different kind of challenging game where your moves might not make sense at the start but they might make a big difference going deep into the game. In such problems, you can\u2019t decide the reward for each step. You can\u2019t write a reward function here. There is only one reward \u2014 win the game and you get it only when the game is finished. This makes it difficult for RL agents to choose the best action at each step.", "Before jumping into the third complication, let me first introduce two more important terms \u2014", "Imagine you have recently moved to a new city and you have thousands of dinner places around your house. Every evening, you have a choice to make like \u2014 Should I explore a new place today? or Eat Freddy\u2019s delicious chicken wings? Now as you already know that Freddy\u2019s is good, it\u2019s never a bad idea to eat there again. But if you don\u2019t explore newer restaurants you will never discover more interesting places and even the best ones. Again at a cost \u2014 you might need to go through many bad places before finding a good place and also you might actually not find a single good place. This kind of situation may arrive very frequently in real life. For example \u2014 changing jobs, changing smartphone brands\u2026etc.", "RL agents also face such situations, exploring is necessary as a good reward might be waiting somewhere un-explored, and exploiting the already studied behavior(through observations) is necessary otherwise your agent is as good as random. Solver always needs to find a balance between these two in order to design an efficient RL agent.", "Yes, these complications have always been there and still are. But as researchers are stubborn, RL based algorithms have seen drastic improvements over time. Reinforcement Learning is becoming more and more interesting and active as a field of research. It\u2019s time to find a few relevant business problems and start solving them efficiently using RL based algorithms.", "Thanks for reading! Kindly share your feedback/comments.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI/ML @ Google | personal blog: https://dropsofai.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F256d2e279f8a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kartikgill96?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "Kartik Chaudhary"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3fd5a49d1e91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=post_page-3fd5a49d1e91----256d2e279f8a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F256d2e279f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F256d2e279f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Neural_architecture_search", "anchor_text": "Neural Architecture Search"}, {"url": "https://gfycat.com/wildunevenhackee", "anchor_text": "https://gfycat.com/wildunevenhackee"}, {"url": "https://itnext.io/reinforcement-learning-with-q-tables-5f11168862c8", "anchor_text": "https://itnext.io/reinforcement-learning-with-q-tables-5f11168862c8"}, {"url": "https://gfycat.com/wildunevenhackee", "anchor_text": "https://gfycat.com/wildunevenhackee"}, {"url": "https://itnext.io/reinforcement-learning-with-q-tables-5f11168862c8", "anchor_text": "https://itnext.io/reinforcement-learning-with-q-tables-5f11168862c8"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----256d2e279f8a---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----256d2e279f8a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----256d2e279f8a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F256d2e279f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=-----256d2e279f8a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F256d2e279f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=-----256d2e279f8a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F256d2e279f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F256d2e279f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----256d2e279f8a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----256d2e279f8a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----256d2e279f8a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----256d2e279f8a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kartik Chaudhary"}, {"url": "https://medium.com/@kartikgill96/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "196 Followers"}, {"url": "https://dropsofai.com", "anchor_text": "https://dropsofai.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3fd5a49d1e91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=post_page-3fd5a49d1e91--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fca74cfd61cd8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-reinforcement-learning-to-your-next-door-neighbor-256d2e279f8a&newsletterV3=3fd5a49d1e91&newsletterV3Id=ca74cfd61cd8&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}