{"url": "https://towardsdatascience.com/15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6", "time": 1683018363.889003, "path": "towardsdatascience.com/15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6/", "webpage": {"metadata": {"title": "15 Lesser-Known Useful SkLearn Models You Should Use Now | by Emma Boudreau | Towards Data Science", "h1": "15 Lesser-Known Useful SkLearn Models You Should Use Now", "description": "Sk Learn is likely one of the most popular machine-learning modules for Python. This is for good reason, as SkLearn has a fantastic catalog of usable models, scalers, tools, and even encoders! While\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Sk Learn is likely one of the most popular machine-learning modules for Python. This is for good reason, as SkLearn has a fantastic catalog of usable models, scalers, tools, and even encoders! While there are some rather popular models that are very well-known, SkLearn is such a large library that it can be easy to forget all of the functions and classes that come with it. While documentation is a great place to start, another great way to expand your modeling capabilities is to get more familiar with is to just use different models.", "With that in mind, I have come to enjoy a lot of different models from the SkLearn. There are a lot of great models that go severely under-used. Today I wanted to bring some of my favorite models from SkLearn to your attention, so maybe next time you\u2019re facing a unique problem, you\u2019ll know the model and its corresponding application!", "Today, we are going to be fitting models in order to demonstrate the usage of said models. Of course, to do this we are going to need some one-dimensional arrays to pass in order to predict features. In simpler terms,", "we need data to train off of.", "Given that we are working in a notebook, I figured it should be open-source, so if you would like to see these models fit in a notebook you can see the source here:", "Since we are going to be reviewing classification models as well as continuous models, we are going to require targets that facilitate those feature types respectively. I am going to be using an old .CSV file that I have lying around called weatherHistory.csv:", "Since we are going to be using both classification and continuous models, I am going to need both a categorical and continuous Y. For the continuous target, I decided to use temperature. For classification, I went ahead and used the Precipitation Type feature. For my predicting features, I am going to use the Humidity feature:", "Now we will train test split that data accordingly into two dataframes:", "Of course, I am not going to be doing much processing to this data just to fit some models for an example. That in mind, those models can\u2019t be fit to data with missing values, so let\u2019s get a summation of the missing value counts in our dataframe.", "Wanna hear something funny? I could have sworn it was is_null() instead of isnull().", "It is clear that I might have gotten a bit ahead of myself, let\u2019s drop some bad observations:", "Now let\u2019s put that into 1-dimensional arrays:", "SkLearn often requires these arrays to be reshaped to vertical, as it prefers features in columns of matrices as opposed to rows of matrices. Let\u2019s reshape these puppies, and then we will be ready to fit some models. In order to do this, we\u2019re going to need to turn these one dimensional arrays into NumPy arrays. This is because SkLearn is far more integrated with NumPy, though it does like Pandas Series in a lot of cases NumPy arrays are much more dynamic and commonly used:", "Among the two different types of models typically used for supervised models are continuous models. These models predict values that are quantitative, rather than qualitative. That being said, many of these models are going to utilize regression in order to estimate continuous values.", "Isotonic, or monotonic regression is an awesome form of regression that many machine-learning engineers have never even heard of. isotonic regression can be a very accurate model for predicting continuous targets, but also has its own limitations in that regard. A great example of this is that this model is often prone to over-fit, and often getting the model to work well is going to be balancing the bias and trying to increase accuracy.", "Another significant problem with this model is that the data must be non-decreasing. This means that typical applications of this model are often going to be involved in economical and business scenarios. So with that in mind, while this model might be a very useful one for someone working with economic data, for a lot of scientific work it isn\u2019t necessarily the greatest model.", "However, isotonic regression in the proper application and balanced bias can be an incredibly powerful predictive model! If you would like to learn more about isotonic regression, you can check out these two articles I wrote, one where I compose an isotonic regressor from scratch in C++, and the other I elaborate on how exactly the model works:", "In order to fit this model, we are going to first need to use the make_regressor function which will give us a basic regression model at which we can build isotonic regression on top of. Let\u2019s do that:", "Another very useful tool that only applies to certain data characteristics is Orthagonal Matching Pursuit. This model is used to take sparse-coded signals and remove noise and abnormalities in said data. This means that these machine-learning algorithms are utilized to fix certain incoming signals based on data, which I think is a pretty great application for machine-learning.", "While the primary use of Orthagonal Matching Pursuit might be relatively straightforward, the uses of this model could be potentially much further. Given that this is quite a unique model on the spectrum, how does it work?", "Orthagonal Matching Pursuit forms the exact operation described in its name. To dissect this definition, let\u2019s look at the words individually:", "So basically, we are searching for perfect matches to our data for where it relies on a multi-dimensional span of data, D, which would likely be a dictionary type inside of the programming world. In Wikipedia\u2019s words,", ".The idea is to create an approximate signal (f) from Hilbert space (H) as a weighted sum of statistical functions \u2014 meaning PDFs/CDFs/Gamma.", "Although the data that we have certainly would not be a great application for this particular model, so instead for this example I am going to create some sparse signals to pass as data:", "Now we will distort our target data:", "If you\u2019ve been using machine-learning for any extended period of time, it is likely that you have heard of Lasso regression. Lasso regression is a fantastic and quite standardized tool that has been used frequently in machine-learning for an extended period of time now. Most of the time when predicting continuous targets, this is most certainly my first choice of model.", "However, the LARS lasso model is not your normal Lasso regressor. The LARS in \u201c LARS lasso model\u201d is short for Least Angle regression. Least Angle regression is a machine-learning algorithm for predicting continuous features. It is most useful for working with data with incredibly high dimensions. This model works by a linear subset of covariates.", "One great thing about this model is that while the ceilings in terms of dimensional are dramatically raised from a traditional model, it really isn\u2019t all that slow compared to a model that might typically be used in this way. That being said, it is important to remember that while this model is derived from Least Angle regression, that does not make it linear \u2014 and that is where the lasso part of the model comes in. Of course, if a linear model is what you\u2019re looking for, you can utilize the same concepts on a traditional linear regression model using Least Angle regression, which is also in SkLearn.", "As discussed in the similar application of Least Angle regression to a lasso model, Least Angle regression is a model used for predicting continuous features that typically work by using a linear subset of covariates. This is the most significant difference between Least Angle regression and LARS Lasso regression. Least Angle regression will be referring to the linear version of that model.", "Computationally, Least Angle regression has the advantage of being just as fast as forward selection. While that is a monsterous benefit, its biggest strength is in scenarios where p >> n. If two variables are equally correlated, then their coefficients should increase at the same rate.", "Another great implementation of a concept in SkLearn is stochastic gradient descent. Stochastic gradient descent is a method that is used iteratively to optimize mathematical functions and build cost. It is likely that you have heard of gradient descent, which is similar \u2014 however, the stochastic in this model\u2019s name means that we only use a single training example for epoch. This is high-end of the two extremes, starting with batch gradient descent, which will use the whole batch per epoch and mini-batch in the middle being a combination of the two.", "The gradient of the loss in stochastic gradient descent is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule, also known as learning-rate in typical machine-learning terms.", "With regressive learning methods, there can often be short-comings to models that are difficult to overcome. This can certainly be said for linear models, which might have a hard time perfectly fitting to sparse data, or data with multiple dimensions to it. Fortunately, SkLearn has a decent implementation of Huber regression.", "This form of regression can be used to work with outliers and avoid modeling errors that might be easy to make using the typical models that are available in the SkLearn package. This can be useful because while this model is useful and fits well, it is also relatively simple, meaning that over-fitting and over-sampling aren\u2019t typically problems that are encountered when working with this model.", "Huber regression optimizes the squared loss (mean squared error) and is considerably robust to outliers compared to models like simple linear regression. There is actually a very interesting paper published by Art B. Owen at Stanford University that might be worth checking out for those uninitiated or unfamiliar with this method of modeling. You can check it out if you\u2019re interested:", "Here is the remark I found the most valid for analyzing what exactly this model is going to do with this data mathematically:", "\u201c The least squares criterion is well suited to yi with a Gaussian distribution but can give poor performance when yi has a heavier tailed distribution or what is almost the same, when there are outliers. Huber (1981) describes a robust estimator employing a loss function that is less affected by very large residual values\u201d", "Needless to say, this model is incredibly cool! I think it definitely has its use in knocking out outliers as a contributing problem to the difficulty of predicting continuous problems \u2014 which is often understating, but seems obvious in the realm of elementary statistics.", "Now that we\u2019re familiar with this model somewhat mathematically, we can actually consider fitting it in Sklearn (that was a joke.)", "While this \u201c model\u201d might be more of concept to utilize with other models, it is certainly going to be incredibly useful! A very common pattern with machine-learning is to use non-linear functions to create linear predictions. This will maintain a lot of the speed of the model while not wasting any of the prediction power. A great example of this is polynomial regression over simple linear regression.", "In examples where polynomial regression is used, it is fit with a higher dimension of data built with functions. Thanks to the use of polynomial features, this model can be fit on and used to solve a wide-range of continuous problems easily.", "In order to actually use polynomial regression in sklearn, we are actually going to use Polynomial Features:", "Ordinary least squares is another really cool mathematical machine-learning model for predicting continuous features. Ordinary least squares is also a linear model, and fits to coefficients that are created to minimize the sum of squares between points in the data.", "The weights for ordinary least squares rely heavily on the independence of features for predicting the target. That being said, this model is incredibly useful for implementations with a single feature. Furthermore, it can be used with multiple features but will certainly require the features to be weighted well towards the target. Looking into this description, it is easy to see the exact niche that a model like ordinary least squares is going to fit into in our machine-learning arsenal.", "The SkLearn implementation of OLS, unfortunately is not as straightforward as most. The OLS coefficients are actually contained beneath LinearRegression classes as .coef_:", "Going back to the magic of support vector machines, allow me to introduce you to NuSVR. NuSVR is of course the same model and machine implementation as NuSVC. Both of these models utilize libsvm and uses a parameter, nu, to control the number of support vectors in the machine. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.", "The advantage of using this model is that parameters are provided for adjustment of the vector machine that is used to assist in estimation of this regression problem. That being said, this model is great for predicting continuous features with a lot of features that may or may not be incredibly important to our target.", "As with the LARS lasso, it is likely that you have heard of lasso regression. As a refresher, it is a fantastic non-linear model for predicting continuous features that is very commonly used. The difference in the multi-task lasso is that that the multi-task lasso is going to use the L1/L2 norm as regularize.", "To demonstrate this, let\u2019s look at the optimization objective for Lasso regression:", "In this example, ||W||_21 would be modified to fit this formula for a multi-task lasso:", "Essentially what this means is that we are getting the summation of each row.", "In machine-learning, there might be a lot of continuous problems, but", "LinearSVC is a support vector machine type of model. The SkLearn implementation of the model was created using libsvm. While the kernel can be non-linear, its SMO does typically not scale very well to a large number of samples. This is where the Linear Support Vector Classifier comes in handy.", "That being said, while there are some other great SVC implementations in Sklearn that might even be more well-known, LinearSVC is certainly a model that is well-worth being aware of! SVC typically works in a multi-class mode implemented with one class weighted against one other class. In the case of LinearSVC, all of those classes are weighted against each other class \u2014 making the model more comprehensive than many of the SVC competitors.", "As for the SkLearn class, it is an awesome and nearly flawless implementation. It supports both dense and sparse data incredibly well, and can be an incredible model \u2014 easily one of the best for linear classification in Python in my opinion!", "As discussed when we briefly discussed the SGDRegressor, stochastic gradient descent is where each batch is used to weigh features at each iteration in cost. The SGDClassifier of course is the exact same concept now being applied to a classification problem.", "Like the SGDRegressor, this model is a great implementation that can be valuable when working with a large set of features in particular. While it might take a dramatic drop to performance, it might need to be weighed whether or not the resulting predictions are worth those particular efforts.", "Fitting the SGDRegressor is quite straightforward, and as with many on this list will follow the typical SkLearn convention of", "The Bernoulli naive Bayes classification model can be used just as any Bayesian classification model is used, however does have a trick up its sleeve:", "You might be familiar with this distribution, as its CDF often appears near logistic classification models. I would say that this model\u2019s usage is very similar to that of MultinomialNB. However, while MultinomialNB works significantly better with counts and occurrence, BernoulliNB uses the Bernoulli distribution and is designed for bool-type features. This of course brings back recollection of my initial statement, where Bernoulli is used for LogisticRegression, that being said, this model has essentially the same use \u2014 so it makes sense that it uses the same distribution.", "Although this model is typically used for predicting binary features, today we are just going to be passing some typical categorical data that might be more applicable to MultinomialNB. That being said, it is important to remember the use-cases for both of these models because they are very powerful, but should be used for their appropriate feature types. There is not a point in using a model if you don\u2019t understand the target that you are trying to predict, and I think the difference between these models highlights the need for data scientists to understand that different models require different types of features to work well. A great lesson to learn from just an import, but regardless it follows the typical convention we have come to expect from SkLearn:", "If you\u2019ve been working with machine-learning models, especially continuous models, it\u2019s likely you\u2019ve heard of ridge regression. Ridge regression is a popular model used for predicting continuous features. RidgeClassification is of course the classification equivalent of this exact model for classification problems.", "The classification version of the model converts the target into {-1, 1} and then models it into a regression problem with the typical ridge regression. I think this is a really cool concept because applying regression and other continuous methods of solving problems to an entirely different problem like classification is really cool in my opinion.", "Fortunately, even though this model is really awesome and seems like an advanced concept, the wonderful SkLearn has made it incredibly easy to use with typical convention for the library:", "Probably one of the coolest models on this list is CalibratedClassifierCV. This model uses cross-validation both to estimate parameters of a classifier. The model can be used with a logistic regressor as a base, which will make it a great model for classifying boolean types.", "However, since this model can actually take different base estimators, a commonly used model is actually isotonic regression. Isotonic regression is a really cool model, but in my opinion becomes a lot cooler when combined with a classification problem. This means that the thresholds are now attached to classes, rather than arbitrary quantile amounts inside of continuous data.", "Unlike many of the other solutions for predicting targets on this list, this is another one that is going to be an additive for other models. In other words, we can calibrate essentially any classifier by simply building one for it. In this example I am going to be building one using Gaussian Naive Bayes, another classification model in SkLearn similar to Multinomial Naive Bayes.", "\u201c By the way, in my opinion this is a really cool methodology, I really think that SkLearn hit the mark on the way that objects are used and the convention that they use as classes.\u201d", "SkLearn is such an awesome library that machine-learning engineers these days might take for granted. There are lot of models in the library that are absolutely incredible and might go mostly ignored because of the champions that are already available. How many of these models have you used? I hope that these descriptions and introductions to these awesome models was entertaining and perhaps even helpful in the model selection for your next project.", "Thank you very much for reading, and happy new year! I think these models will be very valuable assets in the future. Maybe if you run into a good binary classification problem, or a linear modeling problem, you will think back to this article I wrote in my first year. Hopefully this article inspires deeper digging and research to learn more about modeling, because it really is a lot of fun to learn about.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa1a566e680a6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://emmettgb.medium.com/?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": ""}, {"url": "https://emmettgb.medium.com/?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "Emma Boudreau"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea170050148c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&user=Emma+Boudreau&userId=ea170050148c&source=post_page-ea170050148c----a1a566e680a6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa1a566e680a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa1a566e680a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/emmettgb/Emmetts-DS-NoteBooks/blob/master/Python3/15%20sklearn%20models.ipynb", "anchor_text": "notebook"}, {"url": "https://towardsdatascience.com/building-and-using-an-isotonic-regression-model-in-c-f6789d46ab07", "anchor_text": "Building And Using An Isotonic Regression Model In C++Implementing isotonic regression from scratch in C++.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/isotonic-regression-is-the-coolest-machine-learning-model-you-might-not-have-heard-of-3ce14afc6d1e", "anchor_text": "Isotonic Regression is THE Coolest Machine-Learning Model You Might Not Have Heard OfThe term \u201c Isotonic\u201d originates from the Greek root words \u201c iso\u201d and \u201c tonos.\u201d The root \u201c iso\u201d isn\u2019t just a file\u2026towardsdatascience.com"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.OrthogonalMatchingPursuit.html#sklearn.linear_model.OrthogonalMatchingPursuit", "anchor_text": "OrthogonalMatchingPursuit"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_coded_signal.html#sklearn.datasets.make_sparse_coded_signal", "anchor_text": "make_sparse_coded_signal"}, {"url": "https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html#numpy.random.randn", "anchor_text": "np.random.randn"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.OrthogonalMatchingPursuit.html#sklearn.linear_model.OrthogonalMatchingPursuit", "anchor_text": "OrthogonalMatchingPursuit"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR", "anchor_text": "NuSVR"}, {"url": "https://medium.com/tag/programming?source=post_page-----a1a566e680a6---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a1a566e680a6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----a1a566e680a6---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a1a566e680a6---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----a1a566e680a6---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa1a566e680a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&user=Emma+Boudreau&userId=ea170050148c&source=-----a1a566e680a6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa1a566e680a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&user=Emma+Boudreau&userId=ea170050148c&source=-----a1a566e680a6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa1a566e680a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa1a566e680a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a1a566e680a6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a1a566e680a6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a1a566e680a6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a1a566e680a6--------------------------------", "anchor_text": ""}, {"url": "https://emmettgb.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://emmettgb.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Emma Boudreau"}, {"url": "https://emmettgb.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4.6K Followers"}, {"url": "https://twitter.com/emmettboudgie", "anchor_text": "https://twitter.com/emmettboudgie"}, {"url": "https://github.com/emmettgb", "anchor_text": "https://github.com/emmettgb"}, {"url": "https://ems.computer/", "anchor_text": "https://ems.computer/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea170050148c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&user=Emma+Boudreau&userId=ea170050148c&source=post_page-ea170050148c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff16bf42bb45f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-lesser-known-useful-sklearn-models-you-should-use-now-a1a566e680a6&newsletterV3=ea170050148c&newsletterV3Id=f16bf42bb45f&user=Emma+Boudreau&userId=ea170050148c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}