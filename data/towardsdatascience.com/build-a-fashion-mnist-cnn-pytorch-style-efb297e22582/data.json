{"url": "https://towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582", "time": 1683001032.5115352, "path": "towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582/", "webpage": {"metadata": {"title": "Let\u2019s Build a Fashion-MNIST CNN, PyTorch Style | by Michael Li | Towards Data Science", "h1": "Let\u2019s Build a Fashion-MNIST CNN, PyTorch Style", "description": "A detailed instruction on how to build a Fashion MNIST convolution neural networks with PyTorch, Google Colab and Tensor Board."}, "outgoing_paragraph_urls": [{"url": "https://github.com/tensorflow/tensorflow", "anchor_text": "TensorFlow", "paragraph_index": 1}, {"url": "https://github.com/pytorch/pytorch", "anchor_text": "PyTorch", "paragraph_index": 1}, {"url": "https://legacy.python.org/dev/peps/pep-0020/", "anchor_text": "pythonic", "paragraph_index": 1}, {"url": "https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/", "anchor_text": "The Gradient", "paragraph_index": 2}, {"url": "https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/", "anchor_text": "The Gradient", "paragraph_index": 3}, {"url": "https://pytorch.org/blog/pytorch-1-dot-3-adds-mobile-privacy-quantization-and-named-tensors/", "anchor_text": "PyTorch 1.3", "paragraph_index": 4}, {"url": "https://pytorch.org/tutorials/beginner/nn_tutorial.html", "anchor_text": "fantastic PyTorch official tutoria", "paragraph_index": 7}, {"url": "https://medium.com/u/34ab754f8c5e?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Jeremy Howard", "paragraph_index": 7}, {"url": "https://jobs.zalando.com/tech/", "anchor_text": "Zalando", "paragraph_index": 14}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST dataset", "paragraph_index": 14}, {"url": "https://github.com/zalandoresearch/fashion-mnist", "anchor_text": "From Github", "paragraph_index": 14}, {"url": "https://www.geeksforgeeks.org/ordereddict-in-python/", "anchor_text": "OrderedDict", "paragraph_index": 25}, {"url": "https://www.youtube.com/watch?v=GfxJYp9_nJA", "anchor_text": "named tuple", "paragraph_index": 29}, {"url": "https://towardsdatascience.com/hidden-gem-a-great-pytorch-youtube-tutorial-series-by-deeplizard-8de677411bc5", "anchor_text": "deeplizard\u2019s PyTorch video series on YouTube", "paragraph_index": 56}, {"url": "https://medium.com/u/72c98619a048?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Michael Li", "paragraph_index": 57}, {"url": "https://twitter.com/lymenlee", "anchor_text": "@lymenlee", "paragraph_index": 57}, {"url": "https://wayofnumbers.com", "anchor_text": "wayofnumbers.com", "paragraph_index": 57}, {"url": "https://www.linkedin.com/in/michael-li-dfw", "anchor_text": "https://www.linkedin.com/in/michael-li-dfw", "paragraph_index": 59}], "all_paragraphs": ["When it comes to frameworks in technology, one interesting thing is that from the very beginning, there always seems to be a variety of choices. But over time, the competitions will evolve into having only two strong contenders left. Cases in point being \u2018PC vs Mac\u2019, \u2018iOS vs Android\u2019, \u2018React.js vs Vue.js\u2019, etc. And now, we have \u2018PyTorch vs TensorFlow\u2019 in machine learning.", "TensorFlow, backed by Google, is undoubtedly the front-runner here. Released in 2015 as an open-source machine learning framework, it quickly gained a lot of attention and acceptance, especially in industries where production readiness and deployment is key. PyTorch is introduced much later by Facebook in 2017 but quickly gaining a lot of love from practitioners and researchers because of its dynamic computational graph and \u2018pythonic\u2019 style.", "Recent research by The Gradient shows that PyTorch is doing great with researchers and TensorFlow is dominating the industry world:", "In 2019, the war for ML frameworks has two remaining main contenders: PyTorch and TensorFlow. My analysis suggests that researchers are abandoning TensorFlow and flocking to PyTorch in droves. Meanwhile in industry, Tensorflow is currently the platform of choice, but that may not be true for long. \u2014 The Gradient", "The recent release of PyTorch 1.3 introduced PyTorch Mobile, quantization and other goodies that are all in the right direction to close the gap. If you are somewhat familiar with neural network basics but want to try PyTorch as a different style, then please read on. I\u2019ll try to explain how to build a Convolutional Neural Network classifier from scratch for the Fashion-MNIST dataset using PyTorch. The code here can be used on Google Colab and Tensor Board if you don\u2019t have a powerful local environment. Without further ado, let\u2019s get started. You can find the Google Colab Notebook and GitHub link below:", "First, let\u2019s import the necessary modules.", "PyTorch modules are quite straight forward.", "torch is the main module that holds all the things you need for Tensor computation. You can build a fully functional neural network using Tensor computation alone, but this is not what this article is about. We\u2019ll make use of the more powerful and convenient torch.nn, torch.optim and torchvision classes to quickly build our CNN. For those of you interested in knowing how to do this from \u2018scratch scratch\u2019, visit this fantastic PyTorch official tutorial by Jeremy Howard.", "The torch.nnmodule provides many classes and functions to build neural networks. You can think of it as the fundamental building blocks of neural networks: models, all kinds of layers, activation functions, parameter classes, etc. It allows us to build the model like putting some LEGO set together.", "torch.optim offers all the optimizers like SGD, ADAM, etc., so you don\u2019t have to write it from scratch.", "torchvision contains a lot of popular datasets, model architectures, and common image transformations for computer vision. We get our Fashion MNIST dataset from it and also use its transforms.", "SummaryWriter enables PyTorch to generate the report for Tensor Board. We\u2019ll use Tensor Board to look at our training data, compare results and gain intuition. Tensor Board used to be TensorFlow\u2019s biggest advantage over PyTorch, but it is now officially supported by PyTorch from v1.2.", "We also imported some other utility modules like time, json, pandas, etc.", "torchvision already has the Fashion MNIST dataset. If you\u2019re not familiar with Fashion MNIST dataset:", "Fashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. \u2014 From Github", "This doesn\u2019t need much explanation. We specified the root directory to store the dataset, snatch the training data, allow it to be downloaded if not present at the local machine, and then apply the transforms.ToTensor to turn images into Tensor so we can directly use it with our network. The dataset is stored in the dataset class named train_set.", "Building the actual neural network in PyTorch is fun and easy. I assume you have some basic concept of how a Convolutional Neural Network works. If you don\u2019t, you can refer to this video from deeplizard:", "The Fashion MNIST is only 28x28 px in size, so we actually don\u2019t need a very complicated network. We can just build a simple CNN like this:", "We have two convolution layers, each with 5x5 kernels. After each convolution layer, we have a max-pooling layer with a stride of 2. This allows us to extract the necessary features from the images. Then we flatten the tensors and put them into a dense layer, pass through a Multi-Layer Perceptron (MLP) to carry out the task of classification of our 10 categories.", "Now that we are clear about the structure of the network, let\u2019s see how we can use PyTorch to build it:", "First of all, all network classes in PyTorch expand on the base class: nn.Module. It packs all the basics: weights, biases, forward method and also some utility attributes and methods like .parameters() and .zero_grad()which we will be using too.", "The structure of our network is defined in the __init__ dunder function.", "nn.Conv2d and nn.Linear are two standard PyTorch layers defined within the torch.nn module. These are quite self-explanatory. One thing to note is that we only defined the actual layers here. The activation and max-pooling operations are included in the forward function that is explained below.", "Once the layer is defined, we can then use the layer itself to compute the forward results of each layer, coupled with the activation function(ReLu) and Max Pooling operations, we can easily write the forward function of our network as above. Notice that on fc1(Fully Connect layer 1), we used PyTorch\u2019s tensor operation t.reshape to flatten the tensor so it can be passed to the dense layer afterward. Also, we didn\u2019t add the softmax activation function at the output layer since PyTorch\u2019s CrossEntropy function will take care of that for us.", "Normally, we can just handpick one set of hyperparameters and do some experiments with them. In this example, we want to do a bit more by introducing some structuring. We\u2019ll build a system to generate different hyperparameter combinations and use them to carry out training \u2018runs\u2019. Each \u2018run\u2019 uses one set of hyperparameter combinations. Export the training data/results of each run to Tensor Board so we can directly compare and see which hyperparameters set performs the best.", "We store all our hyperparameters in an OrderedDict:", "batch_size: Batch Size to speed up the training process. We\u2019ll use 100 and 1000.", "shuffle: Shuffle toggle, whether we shuffle the batch before training.", "Once the parameters are down. We use two helper classes: RunBuilder and RunManager to manage our hyperparameters and training process.", "The main purpose of the class RunBuilder is to offer a static method get_runs. It takes the OrderedDict (with all hyperparameters stored in it) as a parameter and generates a named tuple Run, each element of runrepresent one possible combination of the hyperparameters. This named tuple is later consumed by the training loop. The code is easy to understand.", "There are four main purposes of the RunManager class.", "As you can see, it helps us take care of the logistics which is also important for our success in training the model. Let\u2019s look at the code. It\u2019s a bit long so bear with me:", "__init__: Initialize necessary attributes like count, loss, number of correct predictions, start time, etc.", "begin_run: Record run start time so when a run is finished, the duration of the run can be calculated. Create a SummaryWriter object to store everything we want to export into Tensor Board during the run. Write the network graph and sample images into the SummaryWriter object.", "end_run: When run is finished, close the SummaryWriter object and reset the epoch count to 0 (getting ready for next run).", "begin_epoch: Record epoch start time so epoch duration can be calculated when epoch ends. Reset epoch_loss and epoch_num_correct.", "end_epoch: This function is where most things happen. When an epoch ends, we\u2019ll calculate the epoch duration and the run duration(up to this epoch, not the final run duration unless for the last epoch of the run). We\u2019ll calculate the total loss and accuracy for this epoch, then export the loss, accuracy, weights/biases, gradients we recorded into Tensor Board. For ease of tracking within the Jupyter Notebook, we also created an OrderedDict object results and put all our run data(loss, accuracy, run count, epoch count, run duration, epoch duration, all hyperparameters) into it. Then we\u2019ll use Pandas to read it in and display it in a neat table format.", "track_loss, track_num_correct, _get_num_correct: These are utility functions to accumulate the loss, number of correct predictions of each batch so the epoch loss and accuracy can be calculated later.", "save: Save all run data (a list of results OrderedDict objects for all runs) into csv and json format for further analysis or API access.", "There is a lot to take in for this RunManager class. Congrats on coming to this far! The hardest part is already behind you. From now on everything will start to come together and make sense.", "Finally, we are ready to do some training! With the help of our RunBuilder and RunManager classes, the training process is a breeze:", "First, we use RunBuilder to create an iterator of hyperparameters, then loop through each hyperparameter combination to carry out our training:", "Then, we create our network object from the Network class defined above. network = Network() . This network objects hold all our weights/biases we need to train.", "We also need to create a DataLoader object. It is a PyTorch class that holds our training/validation/test dataset, and it will iterate through the dataset and gives us training data in batches equal to the batch_size specied.", "After that, we\u2019ll create an optimizer using torch.optim class. The optim class gets network parameters and learning rate as input and will help us step through the training process and updates the gradients, etc. We\u2019ll use Adam as our optimization algorithm here.", "OK. Now we have our network created, data loader prepared and optimizer chosen. Let\u2019s get the training rolling!", "We will loop through all the epochs we want (3 here) to train, so we wrap everything in an \u2018epoch\u2019 loop. We also use the begin_run method of our RunManager class to start tracking run training data.", "For each epoch, we\u2019ll loop through each batch of images to carry out the training.", "The above code is where real training happens. We read in the images and labels from the batch, use network class to do the forward propagation (remember the forward method above?) and get the predictions. With predictions, we can calculate the loss of this batch using cross_entropy function. Once the loss is calculated, we reset the gradients (otherwise PyTorch will accumulate the gradients which is not what we want) with .zero_grad(), do one back propagation use loss.backward()method to calculate all the gradients of the weights/biases. Then, we use the optimizer defined above to update the weights/biases. Now that the network is updated for the current batch, we\u2019ll calculate the loss and number of correct predictions and accumulate/track them using track_loss and track_num_correct methods of our RunManager class.", "Once all is finished, we\u2019ll save the results in files usingm.save('results').", "The output of the runs in the notebook looks like this:", "Tensor Board is a TensorFlow visualization tool now also supported by PyTorch. We\u2019ve already taken the efforts to export everything into the \u2018./runs\u2019 folder where Tensor Board will be looking into for records to consume. What we need to do now is just to launch the Tensor Board and check. Since I\u2019m running this model on Google Colab, we\u2019ll use a service called ngrok to proxy and access our Tensor Board running on Colab virtual machine. Install ngrok first:", "Then, specify the folder we want to run Tensor Board from and launch the Tensor Board web interface (./runs is the default):", "Generate an URL so we can access our Tensor Board from within the Jupyter Notebook:", "As we can see below, TensorBoard is a very convenient visualization tool for us to get insights into our training and can help greatly with the hyperparameter tuning process. We can easily spot which hyperparameter comp performs the best and then using it to do our real training.", "As you can see, PyTorch as a machine learning framework is flexible, powerful and expressive. You just write Python code. Since the main focus of this article is to showcase how to use PyTorch to build a Convolutional Neural Network and training it in a structured way, I didn\u2019t finish the whole training epochs and the accuracy is not optimum. You can try it yourself and see how well the model performs.", "This article is heavily inspired by deeplizard\u2019s PyTorch video series on YouTube. Even most of the code snippets are directly copied from it. I\u2019d like to thank them for the great content and if you feel the need to delve down deeper, feel free to go check it out and subscribe to their channel.", "Found this article useful? Follow me (Michael Li) on Medium or you can find me on Twitter @lymenlee or my blog site wayofnumbers.com. You could also check out my most popular articles below!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Blogger | Product Manager | Developer | Pentester | https://www.linkedin.com/in/michael-li-dfw"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fefb297e22582&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----efb297e22582--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lymenlee.medium.com/?source=post_page-----efb297e22582--------------------------------", "anchor_text": ""}, {"url": "https://lymenlee.medium.com/?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Michael Li"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F72c98619a048&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&user=Michael+Li&userId=72c98619a048&source=post_page-72c98619a048----efb297e22582---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefb297e22582&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefb297e22582&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/tensorflow/tensorflow", "anchor_text": "TensorFlow"}, {"url": "https://github.com/pytorch/pytorch", "anchor_text": "PyTorch"}, {"url": "https://legacy.python.org/dev/peps/pep-0020/", "anchor_text": "pythonic"}, {"url": "https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/", "anchor_text": "The Gradient"}, {"url": "https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/", "anchor_text": "The Gradient"}, {"url": "https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/", "anchor_text": "The Gradient"}, {"url": "https://pytorch.org/blog/pytorch-1-dot-3-adds-mobile-privacy-quantization-and-named-tensors/", "anchor_text": "PyTorch 1.3"}, {"url": "https://colab.research.google.com/drive/1YWzAjpAnLI23irBQtLvDTYT1A94uCloM", "anchor_text": "\ud83d\udcd9 Google Colab Notebook"}, {"url": "https://github.com/wayofnumbers/SideProjects/blob/master/PyTorch_Tutorial_Basic_v1.ipynb", "anchor_text": "GitHub"}, {"url": "https://pytorch.org/tutorials/beginner/nn_tutorial.html", "anchor_text": "fantastic PyTorch official tutoria"}, {"url": "https://medium.com/u/34ab754f8c5e?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Jeremy Howard"}, {"url": "https://unsplash.com/@duck58cth?utm_source=medium&utm_medium=referral", "anchor_text": "Alphacolor"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://jobs.zalando.com/tech/", "anchor_text": "Zalando"}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST dataset"}, {"url": "https://github.com/zalandoresearch/fashion-mnist", "anchor_text": "From Github"}, {"url": "https://github.com/zalandoresearch/fashion-mnist", "anchor_text": "From GitHub"}, {"url": "https://www.geeksforgeeks.org/ordereddict-in-python/", "anchor_text": "OrderedDict"}, {"url": "https://www.youtube.com/watch?v=GfxJYp9_nJA", "anchor_text": "named tuple"}, {"url": "https://towardsdatascience.com/hidden-gem-a-great-pytorch-youtube-tutorial-series-by-deeplizard-8de677411bc5", "anchor_text": "deeplizard\u2019s PyTorch video series on YouTube"}, {"url": "https://medium.com/u/72c98619a048?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Michael Li"}, {"url": "https://twitter.com/lymenlee", "anchor_text": "@lymenlee"}, {"url": "https://wayofnumbers.com", "anchor_text": "wayofnumbers.com"}, {"url": "https://towardsdatascience.com/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a", "anchor_text": "\u201cThis is CS50\u201d: A Pleasant Way to Kick Off Your Data Science EducationWhy CS50 is especially good to solidify your software engineering foundationtowardsdatascience.com"}, {"url": "https://towardsdatascience.com/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133", "anchor_text": "Two Sides of the Same Coin: Jeremy Howard\u2019s fast.ai vs Andrew Ng\u2019s deeplearning.aiHow Not to \u2018Overfit\u2019 Your AI Learning by Taking Both fast.ai and deeplearning.ai coursestowardsdatascience.com"}, {"url": "https://medium.com/datadriveninvestor/thoughts-on-andrew-ngs-machine-learning-course-7724df76320f", "anchor_text": "I finished Andrew Ng\u2019s Machine Learning Course and I Felt Great!The good, the bad, and the beautifulmedium.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----efb297e22582---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----efb297e22582---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/education?source=post_page-----efb297e22582---------------education-----------------", "anchor_text": "Education"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----efb297e22582---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----efb297e22582---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fefb297e22582&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&user=Michael+Li&userId=72c98619a048&source=-----efb297e22582---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fefb297e22582&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&user=Michael+Li&userId=72c98619a048&source=-----efb297e22582---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefb297e22582&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----efb297e22582--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fefb297e22582&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----efb297e22582---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----efb297e22582--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----efb297e22582--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----efb297e22582--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----efb297e22582--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----efb297e22582--------------------------------", "anchor_text": ""}, {"url": "https://lymenlee.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lymenlee.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Michael Li"}, {"url": "https://lymenlee.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.5K Followers"}, {"url": "https://www.linkedin.com/in/michael-li-dfw", "anchor_text": "https://www.linkedin.com/in/michael-li-dfw"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F72c98619a048&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&user=Michael+Li&userId=72c98619a048&source=post_page-72c98619a048--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F95661b899f04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-fashion-mnist-cnn-pytorch-style-efb297e22582&newsletterV3=72c98619a048&newsletterV3Id=95661b899f04&user=Michael+Li&userId=72c98619a048&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}