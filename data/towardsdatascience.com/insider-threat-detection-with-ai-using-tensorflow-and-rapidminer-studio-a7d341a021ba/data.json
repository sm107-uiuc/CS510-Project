{"url": "https://towardsdatascience.com/insider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba", "time": 1683007798.510728, "path": "towardsdatascience.com/insider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba/", "webpage": {"metadata": {"title": "Insider Threat Detection with AI Using Tensorflow and RapidMiner Studio | by Dennis Chow | Towards Data Science", "h1": "Insider Threat Detection with AI Using Tensorflow and RapidMiner Studio", "description": "An A-Z tutorial of using US-CERT insider threat data in neural network creation and modeling in tensorflow and rapidminer studio for cybersec professionals."}, "outgoing_paragraph_urls": [{"url": "https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099", "anchor_text": "US-CERT\u2019s simulated insider threat dataset", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1911.05879.pdf", "anchor_text": "Image-Based Feature Representation for Insider Threat Classification", "paragraph_index": 8}, {"url": "https://www.splunk.com/en_us/blog/security/event-correlation.html", "anchor_text": "SIEM", "paragraph_index": 13}, {"url": "https://www.epochconverter.com/", "anchor_text": "Unix Epoch Time", "paragraph_index": 27}, {"url": "https://my.rapidminer.com/nexus/account/index.html#downloads", "anchor_text": "Rapidminer Studio", "paragraph_index": 31}, {"url": "https://docs.rapidminer.com/latest/studio/installation/license-limits.html", "anchor_text": "limited", "paragraph_index": 34}, {"url": "https://rapidminer.com/educational-program/", "anchor_text": "educational license", "paragraph_index": 34}, {"url": "https://www.tensorflow.org/tutorials/text/text_classification_rnn", "anchor_text": "here", "paragraph_index": 45}, {"url": "https://statisticsbyjim.com/regression/overfitting-regression-models/", "anchor_text": "overfit", "paragraph_index": 55}, {"url": "https://docs.rapidminer.com/latest/studio/guided/deployments/", "anchor_text": "https://docs.rapidminer.com/latest/studio/guided/deployments/", "paragraph_index": 63}, {"url": "https://raw.githubusercontent.com/dc401/tensorflow-insiderthreat/master/scenario2-training-dataset-transformed-tf.csv", "anchor_text": "intermediate dataset", "paragraph_index": 66}, {"url": "https://github.com/jivoi/awesome-ml-for-cybersecurity", "anchor_text": "Github", "paragraph_index": 78}, {"url": "https://www.tensorflow.org/tutorials/text/text_classification_rnn", "anchor_text": "appropriately sized neural network", "paragraph_index": 78}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle", "paragraph_index": 79}, {"url": "https://www.kaggle.com/bogorodvo/lightgbm-baseline-model-using-sparse-matrix", "anchor_text": "LightGBM", "paragraph_index": 80}, {"url": "https://arxiv.org/pdf/1911.05879.pdf", "anchor_text": "Image-Based Feature Representation for Insider Threat Classificatio", "paragraph_index": 83}, {"url": "http://users.umiacs.umd.edu/~sarit/data/articles/TCSS-submission-insider-threat%20-%20Final-Revision.pdf", "anchor_text": "BAIT", "paragraph_index": 84}, {"url": "https://www.edx.org/professional-certificate/berkeleyx-foundations-of-data-science?source=aw&utm_source=aw&utm_medium=affiliate_partner&utm_content=text-link&utm_term=85386_VigLink+Content", "anchor_text": "Data8x Courseware", "paragraph_index": 85}, {"url": "https://www.inferentialthinking.com/", "anchor_text": "book", "paragraph_index": 85}, {"url": "https://www.scissecurity.com/", "anchor_text": "www.scissecurity.com", "paragraph_index": 86}], "all_paragraphs": ["This technical article will teach you how to pre-process data, create your own neural networks, and train and evaluate models using the US-CERT\u2019s simulated insider threat dataset. The methods and solutions are designed for non-domain experts; particularly cyber security professionals. We will start our journey with the raw data provided by the dataset and provide examples of different pre-processing methods to get it \u201cready\u201d for the AI solution to ingest. We will ultimately create models that can be re-used for additional predictions based on security events. Throughout the article, I will also point out the applicability and return on investment depending on your existing Information Security program in the enterprise.", "Note: To use and replicate the pre-processed data and steps we use, prepare to spend 1\u20132 hours on this page. Stay with me and try not to fall asleep during the data pre-processing portion. What many tutorials don\u2019t state is that if you\u2019re starting from scratch; data pre-processing takes up to 90% of your time when doing projects like these.", "At the end of this hybrid article and tutorial, you should be able to:", "The author provides these methods, insights, and recommendations *as is* and makes no claim of warranty. Please do not use the models you create in this tutorial in a production environment without sufficient tuning and analysis before making them a part of your security program.", "If you wish to follow along and perform these activities yourself, please download and install the following tools from their respective locations:", "It\u2019s important for newcomers to any data science discipline to know that the majority of your time spent will be in data pre-processing and analyzing what you have which includes cleaning up the data, normalizing, extracting any additional meta insights, and then encoding the data so that it is ready for an AI solution to ingest it.", "Examining the raw US-CERT data requires you to download compressed files that must be extracted. Note just how large the sets are compared to how much we will use and reduce at the end of the data pre-processing.", "In our article, we saved a bunch of time by going directly to the answers.tar.bz2 that has the insiders.csv file for matching which datasets and individual extracted records of are value. Now, it is worth stating that in the index provided there has correlated record numbers in extended data such as the file, and psychometric related data. We didn\u2019t use the extended meta in this tutorial brief because of the extra time to correlate and consolidate all of it into a single CSV in our case.", "To see a more comprehensive set of feature sets extracted from this same data, consider checking out this research paper called \u201cImage-Based Feature Representation for Insider Threat Classification.\u201d We\u2019ll be referring to that paper later in the article when we examine our model accuracy.", "Before getting the data encoded and ready for a function to read it; we need to get the data extracted and categorized into columns that we need to predict one. Let\u2019s use good old Excel to insert a column into the CSV. Prior to the screenshot we took and added all the rows from the referenced datasets in \u201cinsiders.csv\u201d for scenario 2.", "The scenario (2) is described in scenarios.txt: \u201cUser begins surfing job websites and soliciting employment from a competitor. Before leaving the company, they use a thumb drive (at markedly higher rates than their previous activity) to steal data.\u201d", "Examine our pre-processed data that includes its intermediary and final forms as shown in the following below:", "Intermediate composite true positive records for scenario 2", "In the above photo, this is a snippet of all the different record types essentially appended to each other and properly sorted by date. Note that different vectors (http vs. email vs. device) do not all align easily have different contexts in the columns. This is not optimal by any means but since the insider threat scenario includes multiple event types; this is what we\u2019ll have to work with for now. This is the usual case with data that you\u2019ll get trying to correlate based on time and multiple events tied to a specific attribute or user like a SIEM does.", "Comparison of different data types that have to be consolidated", "In the aggregation set; we combined the relevant CSV\u2019s after moving all of the items mentioned from the insiders.csv for scenario 2 into the same folder. To formulate the entire \u2018true positive\u2019 only dataset portion; we\u2019ve used powershell as shown below:", "Using powershell to merge the CSV\u2019s together", "Right now we have a completely imbalanced dataset where we only have true positives. We\u2019ll also have to add true negatives and the best approach is to have an equal amount of record types representing in a 50/50 scenario of non-threat activity. This is almost never the case with security data so we\u2019ll do what we can as you\u2019ll find below. I also want to point out, that if you\u2019re doing manual data processing in an OS shell \u2014 whatever you import into a variable is in memory and does not get released or garbage collected by itself as you can see from my PowerShell memory consumption after a bunch of data manipulation and CSV wrangling, I\u2019ve bumped up my usage to 5.6 GB.", "Memory isn\u2019t released automatically. We also count the lines in each CSV file.", "Let\u2019s look at the R1 dataset files. We\u2019ll need to pull from that we know are confirmed true negatives (non-threats) for each of the 3 types from filenames we used in the true positive dataset extracts (again, it\u2019s from the R1 dataset which have benign events).", "We\u2019ll merge a number of records from all 3 of the R1 true negative data sets from logon, http, and device files. Note, that in the R1 true negative set, we did not find an emails CSV which adds to the imbalance for our aggregate data set.", "Using PowerShell we count the length of lines in each file. Since we had about ~14K of rows from the true positive side, I arbitrarily took from the true negative side the first 4500 applicable rows from each subsequent file and appended them to the training dataset so that we have both true positives, and true negatives mixed in. We\u2019ll have to add a column to mark which is a insider threat and which aren\u2019t.", "Extracting records of true negatives from 3 complementing CSV\u2019s", "In pre-processing our data we\u2019ve already added all the records of interest below and selected various other true-negative non-threat records from the R1 dataset. Now we have our baseline of threats and non-threats concatenated in a single CSV. To the left, we\u2019ve added a new column to denote a true/false or (1 or 0) in a find and replace scenario.", "Label encoding the insider threat True/False Column", "Above, you can also see we started changing true/false strings to numerical categories. This is us beginning on our path to encode the data through manual pre-processing which we could save ourselves the hassle as we see in future steps in RapidMiner Studio and using the Pandas Dataframe library in Python for Tensorflow. We just wanted to illustrate some of the steps and considerations you\u2019ll have to perform. Following this, we will continue processing our data for a bit. Let\u2019s highlight what we can do using excel functions before going the fully automated route.", "Calculating Unix Epoch Time from the Date and Time Provided", "We\u2019re also manually going to convert the date field into Unix Epoch Time for the sake of demonstration and as you seen it becomes a large integer with a new column. To remove the old column in excel for rename, create a new sheet such as \u2018scratch\u2019 and cut the old date (non epoch timestamp) values into that sheet. Reference the sheet along with the formula you see in the cell to achieve this effect. This formula is: \u201c=(C2-DATE(1970,1,1))*86400\u201d without quotes.", "Encoding the vector column and feature set column map", "In our last manual pre-processing work example you need to format the CSV in is to \u2018categorize\u2019 by label encoding the data. You can automate this as one-hot encoding methods via a data dictionary in a script or in our case we show you the manual method of mapping this in excel since we have a finite set of vectors of the records of interest (http is 0, email is 1, and device is 2).", "You\u2019ll notice that we have not done the user, source, or action columns as it has a very large number of unique values that need label encoding and it\u2019s just impractical by hand. We were able to accomplish this without all the manual wrangling above using the \u2018turbo prep\u2019 feature of RapidMiner Studio and likewise for the remaining columns via Python\u2019s Panda in our script snippet below. Don\u2019t worry about this for now, we will show case the steps in each different AI tool and up doing the same thing the easy way.", "The above snippet is the using python\u2019s panda library example of manipulating and label encoding the columns into numerical values unique to each string value in the original data set. Try not to get caught up in this yet. We\u2019re going to show you the easy and comprehensive approach of all this data science work in Rapidminer Studio", "Important step for defenders: Given that we\u2019re using the pre-simulated dataset that has been formatted from US-CERT, not every SOC is going to have access to the same uniform data for their own security events. Many times your SOC will have only raw logs to export. From an ROI perspective \u2014 before pursuing your own DIY project like this, consider the level of effort and if you can automate exporting meta of your logs into a CSV format, an enterprise solution as Splunk or another SIEM might be able to do this for you. You would have to correlate your events and add as many columns as possible for enriched data formatting. You would also have to examine how consistent and how you can automate exporting this data in a format that US-CERT has to use similar methods for pre-processing or ingestion. Make use of your SIEM\u2019s API features to export reports into a CSV format whenever possible.", "It\u2019s time use to some GUI based and streamlined approaches. The desktop edition of RapidMiner is Studio and the latest editions as of 9.6.x have turbo prep and auto modeling built in as part of your workflows. Since we\u2019re not domain experts, we are definitely going to take advantage of using this. Let\u2019s dig right in.", "Note: If your trial expired before getting to this tutorial and use community edition, you will be limited to 10,000 rows. Further pre-processing is required to limit your datasets to 5K of true positives, and 5K of true negatives including the header. If applicable, use an educational license which is unlimited and renewable each year that you enrolled in a qualifying institution with a .edu email.", "Upon starting we\u2019re going to start a new project and utilize the Turbo Prep feature. You can use other methods or the manual way of selecting operators via the GUI in the bottom left for the community edition. However, we\u2019re going to use the enterprise trial because it\u2019s easy to walk through for first-time users.", "Import the Non-Processed CSV Aggregate File", "We\u2019ll import our aggregate CSV of true positive only data non-processed; and also remove the first row headers and use our own because the original row relates to the HTTP vector and does not apply to subsequent USB device connection and Email related records also in the dataset as shown below.", "Note: Unlike our pre-processing steps which includes label encodings and reduction, we did not do this yet on RapidMiner Studio to show the full extent of what we can easily do in the \u2018turbo prep\u2019 feature. We\u2019re going to enable the use of quotes as well and leave the other defaults for proper string escapes.", "Next, we set our column header types to their appropriate data types.", "Stepping through the wizard we arrive at the turbo prep tab for review and it shows us distribution and any errors such as missing values that need to be adjusted and which columns might be problematic. Let\u2019s start with making sure we identify all of these true positives as insider threats to begin with. Click on generate and we\u2019re going to transform this dataset by inserting a new column in all the rows with a logical \u2018true\u2019 statement like so below", "We\u2019ll save the column details and export it for further processing later or we\u2019ll use it as a base template set for when we begin to pre-process for the Tensorflow method following this to make things a little easier.", "After the export as you can see above, don\u2019t forget we need to balance the data with true negatives. We\u2019ll repeat the same process of importing the true negatives. Now we should see multiple datasets in our turbo prep screen.", "In the above, even though we\u2019ve only imported 2 datasets, remember transformed the true positive by adding a column called insiderthreat which is a true/false boolean logic. We do the same with true negatives and you\u2019ll eventually end up with 4 of these listings.", "We\u2019ll need to merge the true positives and true negatives into a \u2018training set\u2019 before we get to do anything fun with it. But first, we also need to drop columns that we don\u2019t think are relevant our useful such as the transaction ID and the description column of the website keywords scraped as none of the other row data have these; and and would contain a bunch of empty (null) values that aren\u2019t useful for calculation weights.", "Important thought: As we\u2019ve mentioned regarding other research papers, choosing columns for calculation aka \u2018feature sets\u2019 that include complex strings have to be tokenized using natural language processing (NLP). This adds to your pre-processing requirements in additional to label encoding in which in the Tensorflow + Pandas Python method would usually require wrangling multiple data frames and merging them together based on column keys for each record. While this is automated for you in RapidMiner, in Tensorflow you\u2019ll have to include this in your pre-processing script. More documentation about this can be found here.", "Take note that we did not do this in our datasets because you\u2019ll see much later in an optimized RapidMiner Studio recommendation that heavier weight and emphasis on the date and time are were more efficient feature sets with less complexity. You on other hand on different datasets and applications may need to NLP for sentiment analysis to add to the insider threat modeling.", "Finishing your training set: Although we do not illustrate this, after you have imported both true negatives and true positives within the Turbo prep menu click on the \u201cmerge\u201d button and select both transformed datasets and select the \u201cAppend\u201d option since both have been pre-sorted by date.", "Within RapidMiner Studio we continue to the \u2018Auto Model\u2019 tab and utilize our selected aggregate \u2018training\u2019 data (remember training data includes true positives and true negatives) to predict on the insiderthreat column (true or false)", "We also notice what our actual balance is. We are still imbalanced with only 9,001 records of non-threats vs. threats of ~14K. It\u2019s imbalanced and that can always be padded with additional records should you choose. For now, we\u2019ll live with it and see what we can accomplish with not-so-perfect data.", "Here the auto modeler recommends different feature columns in green and yellow and their respective correlation. The interesting thing is that it is estimating date is of high correlation but less stability than action and vector.", "Important thought: In our head, we would think as defenders all of the feature set applies in each column as we\u2019ve already reduced what we could as far as relevance and complexities. It\u2019s also worth mentioning that this is based off a single event. Remember insider threats often take multiple events as we saw in the answers portion of the insiders.csv . What the green indicators are showing us are unique record single event identification.", "We\u2019re going to use all the columns anyways because we think it\u2019s all relevant columns to use. We also move to the next screen on model types, and because we\u2019re not domain experts we\u2019re going to try almost all of them and we want the computer to re-run each model multiple times finding the optimized set of inputs and feature columns.", "Remember that feature sets can include meta information based on insights from existing columns. We leave the default values of tokenization and we want to extract date and text information. Obviously the items with the free-form text are the \u2018Action\u2019 column with all the different URLs, and event activity that we want NLP to be applied. And we want to correlate between columns, the importance of columns, and explain predictions as well.", "Note that in the above we\u2019ve pretty much selected bunch of heavy processing parameters in our batch job. On an 8 core single threadded processor running Windows 10, 24 GB memory and a GPU of a Radeon RX570 value series with SSD\u2019s all of these models took about 6 hours to run total with all the options set. After everything was completed we have 8000+ models and 2600+ feature set combinations tested in our screen comparison.", "According to RapidMiner Studio; the deep learning neural network methods aren\u2019t the best ROI fit; compared to the linear general model. There are no errors though- and that\u2019s worrisome which might mean that we have poor quality data or an overfit issue with the model. Let\u2019s take a look at deep learning as it also states a potential 100% accuracy just to compare it.", "In the Deep Learning above it\u2019s tested against 187 different combinations of feature sets and the optimized model shows that unlike our own thoughts as to what features would be good including the vector and action mostly. We see even more weight put on the tokens in Action interesting words and the dates. Surprisingly; we did not see anything related to \u201cemail\u201d or the word \u201cdevice\u201d in the actions as part of the optimized model.", "Not to worry, as this doesn\u2019t mean we\u2019re dead wrong. It just means the feature sets it selected in its training (columns and extracted meta columns) provided less errors in the training set. This could be that we don\u2019t have enough diverse or high quality data in our set. In the previous screen above you saw an orange circle and a translucent square.", "The orange circle indicates the models suggested optimizer function and the square is our original selected feature set. If you examine the scale, our human selected feature set was an error rate of 0.9 and 1% which gives our accuracy closer to the 99% mark; but only at a much higher complexity model (more layers and connections in the neural net required) That makes me feel a little better and just goes to show you that caution is needed when interpreting all of these at face value.", "Let\u2019s say you don\u2019t fully trust such a highly \u201c100% accurate model\u201d. We can try to re-run it using our feature sets in vanilla manner as a pure token label. We\u2019re *not* going extract date information, no text tokenization via NLP and we don\u2019t want it to automatically create new feature set meta based on our original selections. Basically, we\u2019re going to use a plain vanilla set of columns for the calculations.", "So in the above let\u2019s re-run it looking at 3 different models including the original best fit model and the deep learning we absolutely no optimization and additional NLP applied. So it\u2019s as if we only used encoded label values only in the calculations and not much else.", "In the above, we get even worse results with an error rate of 39% is a 61% accuracy across pretty much all the models. Our selection and lack of complexity without using text token extraction is so reduced that even a more \u201cprimitive\u201d Bayesian model (commonly used in basic email spam filter engines) seems to be just as accurate and has a fast compute time. This all looks bad but let\u2019s dig a little deeper:", "When we select the details of the deep learning model again we see the accuracy climb in linear fashion as more of the training set population is discovered and validated against. From an interpretation stand point this shows us a few things:", "While this section does not show screenshots, the last step in the RapidMiner studio is to deploy the optimized or non-optimized model of your choosing. Deploying locally in the context of studio won\u2019t do much for you other than to re-use a model that you really like and to load new data through the interactions of the Studio application. You would need RapidMiner Server to make local or remote deployments automated to integrate with production applications. We do not illustrate such steps here, but there is great documentation on their site at: https://docs.rapidminer.com/latest/studio/guided/deployments/", "Maybe RapidMiner Studio wasn\u2019t for us and everyone talks about Tensorflow (TF) as one of the leading solutions. But, TF does not have a GUI. The new TF v2.0 has Keras API part of the installation which makes interaction in creating the neural net layers much easier along getting your data ingested from Python\u2019s Panda Data Frame into model execution. Let\u2019s get started.", "As you recall from our manual steps we start data pre-processing. We re-use the same scenario 2 and data set and will use basic label encoding like we did with our non-optimized model in RapidMiner Studio to show you the comparison in methods and the fact the it\u2019s all statistics at the end of the day based on algorithmic functions converted into libraries. Reusing the screenshot, remember that we did some manual pre-processing work and converted the insiderthreat, vector, and date columns into category numerical values already like so below:", "I\u2019ve placed a copy of the semi-scrubbed data on the Github if you wish to review the intermediate dataset prior to us running Python script to pre-process further:", "Let\u2019s examine the python code to help us get to the final state we want which is:", "The code can be copied below:", "In our scenario we\u2019re going to ingest the data from Github. I\u2019ve included in the comment the method of using the os import to do so from a file local to your disk. One thing to point out is that we use the Pandas dataframe construct and methods to manipulate the columns using label encoding for the input. Note that this is not the optimized manner as which RapidMiner Studio reported to us.", "We\u2019re still using our same feature set columns in the second round of modeling we re-ran in the previous screens; but this time in Tensorflow for method demonstration.", "Note in the above there is an error in how vector still shows \u2018object\u2019 in the DType. I was pulling my hair out looking and I found I needed to update the dataset as I did not capture all the values into the vector column as a category numerical like I originally thought. Apparently, I was missing one. Once this was all corrected and errors gone, the model training was ran without a problem.", "Unlike RapidMiner Studio, we don\u2019t just have one large training set and let the system do it for us. We must divide the training set into smaller pieces that must be ran through a batch based on the following as a subset for the model to be trained using known correct data of true/false insider threats and a reserved portion that is split which is the remaining being validation only.", "Next we need to choose our feature columns, which again is the \u2018non optimized\u2019 columns of our 5 columns of data encoded. We use a sampling batch size of 32 in each round of validation (epoch) for the pipeline as we define it early on.", "Keep note that we did not execute anything related to the tensor or even create a model yet. This is all just data prep and building the \u2018pipeline\u2019 that feeds the tensor. Below is when we create the model using the layers in sequential format using Keras, we compile the model using Google TF\u2019s tutorial demo optimizer and loss functions with an emphasis on accuracy. We try to fit and validate the model with 5 rounds and then print the display.", "Welcome to the remaining 10% of your journey in applying AI to your insider threat data set!", "Let\u2019s run it again and well \u2014 now we see accuracy of around 61% like last time! So again, this just proves that a majority of your outcome will be in the data science process itself and the quality surrounding the pre-processing, tuning, and data. Not so much about which core software solution you go with. Without the optimizing and testing multiple model experimenting simulating in varying feature sets; our primitive models will only be at best 10% better than random chance sampling that a human analyst may or may not catch reviewing the same data.", "For simple project tasks that can be accomplished on individual events as an alert vs. an incident using non-domain experts; AI enabled defenders through SOC\u2019s or threat hunting can better achieve ROI faster on things that are considered anomalous or not using baseline data. Examples include anomalies user agent strings that may show C2 infections, or K-means or KNN clustering based on cyber threat intelligence IOC\u2019s that may show specific APT similarities.", "There\u2019s some great curated lists found on Github that may give your team ideas on what else they can pursue with some simple methods as we\u2019ve demonstrated in this article. Whatever software solution you elect to use, chances are that our alert payloads really need NLP applied and an appropriately sized neural network created to engage in more accurate modeling. Feel free to modify our base python template and try it out yourself.", "I have to admit, I was pretty disappointed in myself at first; even if we knew this was not a tuned model with the labels and input selection I had. But when we cross compare it with other more complex datasets and models in the communities such as Kaggle: It really isn\u2019t as bad as we first thought.", "Microsoft hosted a malware detection competition to the community and provided enriched datasets. The competition highest scores show 67% prediction accuracy and this was in 2019 with over 2400 teams competing. One member shared their code which had a 63% score and was released free and to the public as a great template if you wanted to investigate further. He titles LightGBM.", "Compared to the leaderboard points the public facing solution was only 5% \u201cworse.\u201d Is a 5% difference a huge amount in the world of data science? Yes (though it depends also how you measure confidence levels). So out of 2400+ teams, the best model achieved a success accuracy of ~68%. But from a budgeting ROI stand point when a CISO asks for their next FY\u2019s CAPEX \u2014 68% isn\u2019t going to cut it for most security programs.", "While somewhat discouraging, it\u2019s important to remember that there are dedicated data science and dev ops professionals that spend their entire careers doing this to get models u to the 95% or better range. To achieve this, tons of model testing, additional data, and additional featureset extraction is required (as we saw in RapidMiner Studio doing this automatically for us).", "Obviously, this is a complex task. Researchers at the Deakin University in published a paper called \u201cImage-Based Feature Representation for Insider Threat Classification\u201d which was mentioned briefly in the earlier portion of the article. They discuss the measures that they have had to create a feature set based on an extended amount of data provided by the same US-CERT CMU dataset and they created \u2018images\u2019 out of it that can be used for prediction classification where they achieved 98% accuracy.", "Within the paper the researchers also discussed examination of prior models such as \u2018BAIT\u2019 for insider threat which at best a 70% accuracy also using imbalanced data. Security programs with enough budget can have in-house models made from scratch with the help of data scientists and dev ops engineers that can use this research paper into applicable code.", "Focus less on the solution and more on the data science and pre-processing. I took the EdX Data8x Courseware (3 in total) and the book referenced (also free) provides great details and methods anyone can use to properly examine data and know what they\u2019re looking at during the process. This course set and among others can really augment and enhance existing cyber security skills to prepare us to do things like:", "I hope you\u2019ve enjoyed this article and tutorial brief on cyber security applications of insider threats or really any data set into a neural network using two different solutions. If you\u2019re interested in professional services or an MSSP to bolster your organization\u2019s cyber security please feel free to contact us at www.scissecurity.com", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Security Practitioner and Veteran | GSE #288, GXPN, GREM *Opinions are my own"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa7d341a021ba&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://dwchow.medium.com/?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": ""}, {"url": "https://dwchow.medium.com/?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "Dennis Chow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc39d46e3d1c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&user=Dennis+Chow&userId=c39d46e3d1c6&source=post_page-c39d46e3d1c6----a7d341a021ba---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7d341a021ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7d341a021ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099", "anchor_text": "US-CERT\u2019s simulated insider threat dataset"}, {"url": "https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099", "anchor_text": "full dataset"}, {"url": "http://ftp//ftp.sei.cmu.edu/pub/cert-data/", "anchor_text": "ftp://ftp.sei.cmu.edu/pub/cert-data"}, {"url": "https://github.com/dc401/tensorflow-insiderthreat", "anchor_text": "Github"}, {"url": "https://github.com/dc401/tensorflow-insiderthreat", "anchor_text": "https://github.com/dc401/tensorflow-insiderthreat"}, {"url": "https://visualstudio.microsoft.com/vs/", "anchor_text": "Visual Studio 2019 Community Edition"}, {"url": "https://rapidminer.com/get-started/", "anchor_text": "Rapidminer Studio Trial"}, {"url": "https://www.python.org/downloads/windows/", "anchor_text": "Python 3.8.3 x64"}, {"url": "https://docs.python.org/3/installing/index.html", "anchor_text": "Install python packages"}, {"url": "https://www.tensorflow.org/install", "anchor_text": "tensorflow"}, {"url": "https://arxiv.org/pdf/1911.05879.pdf", "anchor_text": "Image-Based Feature Representation for Insider Threat Classification"}, {"url": "https://www.splunk.com/en_us/blog/security/event-correlation.html", "anchor_text": "SIEM"}, {"url": "https://www.epochconverter.com/", "anchor_text": "Unix Epoch Time"}, {"url": "https://my.rapidminer.com/nexus/account/index.html#downloads", "anchor_text": "Rapidminer Studio"}, {"url": "https://docs.rapidminer.com/latest/studio/installation/license-limits.html", "anchor_text": "limited"}, {"url": "https://rapidminer.com/educational-program/", "anchor_text": "educational license"}, {"url": "https://www.tensorflow.org/tutorials/text/text_classification_rnn", "anchor_text": "here"}, {"url": "https://statisticsbyjim.com/regression/overfitting-regression-models/", "anchor_text": "overfit"}, {"url": "https://positivepsychology.com/big-five-personality-theory/", "anchor_text": "OCEAN"}, {"url": "https://docs.rapidminer.com/latest/studio/guided/deployments/", "anchor_text": "https://docs.rapidminer.com/latest/studio/guided/deployments/"}, {"url": "https://raw.githubusercontent.com/dc401/tensorflow-insiderthreat/master/scenario2-training-dataset-transformed-tf.csv", "anchor_text": "intermediate dataset"}, {"url": "https://github.com/jivoi/awesome-ml-for-cybersecurity", "anchor_text": "Github"}, {"url": "https://www.tensorflow.org/tutorials/text/text_classification_rnn", "anchor_text": "appropriately sized neural network"}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/bogorodvo/lightgbm-baseline-model-using-sparse-matrix", "anchor_text": "LightGBM"}, {"url": "https://arxiv.org/pdf/1911.05879.pdf", "anchor_text": "Image-Based Feature Representation for Insider Threat Classificatio"}, {"url": "http://users.umiacs.umd.edu/~sarit/data/articles/TCSS-submission-insider-threat%20-%20Final-Revision.pdf", "anchor_text": "BAIT"}, {"url": "https://www.edx.org/professional-certificate/berkeleyx-foundations-of-data-science?source=aw&utm_source=aw&utm_medium=affiliate_partner&utm_content=text-link&utm_term=85386_VigLink+Content", "anchor_text": "Data8x Courseware"}, {"url": "https://www.inferentialthinking.com/", "anchor_text": "book"}, {"url": "https://www.scissecurity.com/", "anchor_text": "www.scissecurity.com"}, {"url": "https://medium.com/tag/cybersecurity?source=post_page-----a7d341a021ba---------------cybersecurity-----------------", "anchor_text": "Cybersecurity"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----a7d341a021ba---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/ai?source=post_page-----a7d341a021ba---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/threat-hunting?source=post_page-----a7d341a021ba---------------threat_hunting-----------------", "anchor_text": "Threat Hunting"}, {"url": "https://medium.com/tag/information-security?source=post_page-----a7d341a021ba---------------information_security-----------------", "anchor_text": "Information Security"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa7d341a021ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&user=Dennis+Chow&userId=c39d46e3d1c6&source=-----a7d341a021ba---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa7d341a021ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&user=Dennis+Chow&userId=c39d46e3d1c6&source=-----a7d341a021ba---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7d341a021ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa7d341a021ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a7d341a021ba---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a7d341a021ba--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a7d341a021ba--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a7d341a021ba--------------------------------", "anchor_text": ""}, {"url": "https://dwchow.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://dwchow.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dennis Chow"}, {"url": "https://dwchow.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "353 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc39d46e3d1c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&user=Dennis+Chow&userId=c39d46e3d1c6&source=post_page-c39d46e3d1c6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6d4ca21846c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finsider-threat-detection-with-ai-using-tensorflow-and-rapidminer-studio-a7d341a021ba&newsletterV3=c39d46e3d1c6&newsletterV3Id=6d4ca21846c0&user=Dennis+Chow&userId=c39d46e3d1c6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}