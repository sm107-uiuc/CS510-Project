{"url": "https://towardsdatascience.com/web-scraping-and-pre-processing-for-nlp-2e78810b40f1", "time": 1683007015.245985, "path": "towardsdatascience.com/web-scraping-and-pre-processing-for-nlp-2e78810b40f1/", "webpage": {"metadata": {"title": "Web-Scraping and Pre-Processing for NLP | by James Briggs | Towards Data Science", "h1": "Web-Scraping and Pre-Processing for NLP", "description": "For Natural Language Processing, clean data is important. Even more so when that data is coming from the web. In this article we will go through a real example of web scraping and data pre-processing\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikisource.org/wiki/Moral_letters_to_Lucilius", "anchor_text": "WikiSource here", "paragraph_index": 2}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data/Dataset", "anchor_text": "tf.data.Dataset", "paragraph_index": 19}, {"url": "https://www.youtube.com/c/jamesbriggs", "anchor_text": "https://www.youtube.com/c/jamesbriggs", "paragraph_index": 30}], "all_paragraphs": ["For Natural Language Processing, clean data is important. Even more so when that data is coming from the web. In this article we will go through a real example of web scraping and data pre-processing for a Stoic philosophy text generator.", "The data we will be using is Epistulae Morales Ad Lucilium (Moral Letters to Lucilius) written by exiled Roman senator Seneca during the late Stoa.", "The letters are sourced from WikiSource here. This page consists of a list of all 124 letters. Where each letter is contained in it\u2019s own page.", "First, we must extract the HTML from this contents page. For this we use Python\u2019s requests and BeautifulSoup libraries.", "This gives us a BeautifulSoup object, which contains the raw html we have given via html. Let\u2019s take a look what this looks like.", "In this, we must extract the local paths to each letter. The BeautifulSoup object allows us to extract all <a> elements with soup.find_all('a'). However, this returns all <a> elements, so we then need to filter for just those which link to the letters.", "We do this using regular expressions, which is incredibly simple, we build our regex to search for anything that begins with Letter followed by one or more spaces \\s+ and finally ending with one to three digits \\d{1,3}. This gives us re.compile(r\"^Letter\\s+\\d{1,3}$\").", "By applying this regex to the list of <a> elements provided by BeautifulSoup, we will get the following.", "Now we need to define a function to parse the HTML from each page. This is actually very straight-forward, as the letter text is all contained in the only <p> elements on the page.", "So, similar to before, we extract all <p> elements. We then do a small amount of formatting to make the text more readable, before returning the letter text.", "With our pull_letter function and letters_regex, we can read all letters, which we will place in moral_letters.", "At this point we have all the data we need, neatly stored in moral_letters.", "Formatting our data into a NLP friendly format is much simpler to write, albeit much more abstracted.", "We will need to convert the text we have at the moment into numbers, creating a numeric representation of our data, which we will call data_idx.", "To do this we will create a char2idx dictionary, which stands for character-to-index. This, as is given away by the name, converts characters 'a', 'b', 'c' to indices 0, 1, 2.", "Every character in char2idx must also map to a unique index. For this we must create a set of all characters in the data (a set is simply list unique values). This set of characters is known as a vocabulary, which we will define as vocab.", "So now, let\u2019s read the first letter from Seneca in our new format.", "Although it seems like nonsense, this is exactly what we want when formatting text data for NLP.", "Now all that remains is slicing and shuffling our data, then it is ready to be input into a model. In our case we are using tensorflow.", "TensorFlow allows us to to use tf.data.Dataset, an API we can use to simplify the dataset transformation process. To create a dataset from our Numpy array data_idx, we use tf.data.Dataset.from_tensor_slices.", "During training, we will only look at one segment of text at once. To split the data into sequences we use the Dataset .batch method.", "As this is a text generator, our target data will simply consist of the input data, shifted one character forward. For this we will define a function called split_xy.", "Finally, we create batches of 64 sequences, again using .batch, which are then shuffled using .shuffle.", "Inside dataset, we have 175 batches (due to len(txt) / (SEQLEN * BATCHSIZE)). Every single batch contains an input and target array, built by the split_xy function.", "This data is now fully prepared, ready to be input into a model for training.", "Despite the outward appearance of complexity. The implementation of machine learning is no longer an gargantuan task, reserved for the brightest minds of our time.", "We are now living in an age where we can teach a computer to reproduce philosophy from some of the greatest minds in human history. Not only can we do it, but it is incredibly easy to do.", "It is a fascinating time, and one which I hope we all make the most of.", "I\u2019ve written about designing neural networks to reproduce Stoic philosophy before. If you\u2019re interested, you can read about it here:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Freelance ML engineer learning and writing about everything. I post a lot on YT https://www.youtube.com/c/jamesbriggs"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2e78810b40f1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jamescalam.medium.com/?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "James Briggs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb9d77a4ca1d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&user=James+Briggs&userId=b9d77a4ca1d1&source=post_page-b9d77a4ca1d1----2e78810b40f1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e78810b40f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e78810b40f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/the-meditations", "anchor_text": "The Meditations Project"}, {"url": "https://unsplash.com/@the_roaming_platypus?utm_source=medium&utm_medium=referral", "anchor_text": "timJ"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikisource.org/wiki/Moral_letters_to_Lucilius", "anchor_text": "WikiSource here"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data/Dataset", "anchor_text": "tf.data.Dataset"}, {"url": "https://towardsdatascience.com/stoic-philosophy-built-by-algorithms-9cff7b91dcbd", "anchor_text": "Stoic Philosophy \u2014 Built by AlgorithmsReproducing Stoic philosophy written by one of the most powerful men in historytowardsdatascience.com"}, {"url": "https://medium.com/tag/programming?source=post_page-----2e78810b40f1---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2e78810b40f1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2e78810b40f1---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2e78810b40f1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/the-meditations?source=post_page-----2e78810b40f1---------------the_meditations-----------------", "anchor_text": "The Meditations"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e78810b40f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&user=James+Briggs&userId=b9d77a4ca1d1&source=-----2e78810b40f1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e78810b40f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&user=James+Briggs&userId=b9d77a4ca1d1&source=-----2e78810b40f1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e78810b40f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2e78810b40f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2e78810b40f1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2e78810b40f1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2e78810b40f1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2e78810b40f1--------------------------------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "James Briggs"}, {"url": "https://jamescalam.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.6K Followers"}, {"url": "https://www.youtube.com/c/jamesbriggs", "anchor_text": "https://www.youtube.com/c/jamesbriggs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb9d77a4ca1d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&user=James+Briggs&userId=b9d77a4ca1d1&source=post_page-b9d77a4ca1d1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F75e31c56d187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-and-pre-processing-for-nlp-2e78810b40f1&newsletterV3=b9d77a4ca1d1&newsletterV3Id=75e31c56d187&user=James+Briggs&userId=b9d77a4ca1d1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}