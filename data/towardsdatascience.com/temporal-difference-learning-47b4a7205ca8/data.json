{"url": "https://towardsdatascience.com/temporal-difference-learning-47b4a7205ca8", "time": 1683000383.179549, "path": "towardsdatascience.com/temporal-difference-learning-47b4a7205ca8/", "webpage": {"metadata": {"title": "Temporal-Difference (TD) Learning | by Baijayanta Roy | Towards Data Science", "h1": "Temporal-Difference (TD) Learning", "description": "In this article, I will cover Temporal-Difference Learning methods. Temporal-Difference(TD) method is a blend of the Monte Carlo (MC) method and the Dynamic Programming (DP) method. To understand\u2026"}, "outgoing_paragraph_urls": [{"url": "https://baijayanta.medium.com/membership", "anchor_text": "https://baijayanta.medium.com/membership", "paragraph_index": 14}], "all_paragraphs": ["In this article, I will cover Temporal-Difference Learning methods. Temporal-Difference(TD) method is a blend of the Monte Carlo (MC) method and the Dynamic Programming (DP) method.", "Below are key characteristics of Monte Carlo (MC) method:", "To understand this better, consider a real-life analogy; if Monte Carlo learning is like an annual examination where student completes its episode at the end of the year. Similarly, we have TD learning, which can be thought like a weekly or monthly examination (student can adjust their performance based on this score (reward received) after every small interval and the final score is the accumulation of all weekly tests (total rewards)).", "TD(0) is the simplest form of TD learning. In this form of TD learning, after every step value function is updated with the value of the next state and along the way reward obtained. This observed reward is the key factor that keeps the learning grounded and algorithm converges after a sufficient number of sampling (in the limit of infinity). Below is the backup diagram of TD(0) and an example of TD(0) for our gem collection and examination example.", "TD(0) can be represented with the equation in the below diagram. Equation 1 is generally shown in literature but I find the same equation written as per Equation 2 is more intuitive. We have \u03b1 as a learning factor, \u03b3 as a discount factor. Here the value of a state S is getting updated in the next time step (t+1) based on the reward r t+1 observed after the time step t with the expected value of S in time step t+1. So its the bootstrap of S at time step t using the estimation from time step t+1 while r t+1 is the observed reward (real thing that makes the algorithm grounded) TD target and TD error as shown below are two important components of the equation which are used in many other areas of RL.", "One of the TD algorithms for control or improvement is SARSA. SARSA name came from the fact that agent takes one step from one state-action value pair to another state-action value pair and along the way collect reward R (so its the S t, A t, R t+1, S t+1 & A t+1 tuple that creates the term S,A,R,S,A). SARSA is an on-policy method. SARSA use action-value function Q and follow the policy \u03c0. GPI (Generalized Policy Iteration as described in blog-2) is used to take action based on policy \u03c0 ( \u03b5-greedy to ensure exploration as well as greedy to improve the policy).", "SARSA can be represented with the equation as shown in the below diagram. Equation 1 is generally shown in literature but I find the same equation written as per Equation 2 is more intuitive. We have \u03b1 as a learning factor, \u03b3 as a discount factor. Action value version of TD target and TD error is shown as well.", "Q-learning is an off-policy algorithm. In Off-policy learning, we evaluate target policy (\u03c0) while following another policy called behavior policy (\u03bc) (this is like a robot following a video or agent learning based on experience gained by another agent). DQN (Deep Q-Learning) which made a Nature front page entry, is a Q-learning based algorithm (with few additional tricks) that surpassed human-level expertise in Atari game (I will cover DQN in details in a future post). In the Q-learning, target policy is a greedy policy and behavior policy is the \u03b5-greedy policy (this ensures exploration).", "Refer to the below diagram for the Q-learning algorithm written in two different ways. Look how target and behavior policy actions are represented in the equation.", "Expected SARSA is just like Q-learning except that instead of the maximum over next state-action pairs it uses the expected value, taking into account how likely each action is under the current policy. Given the next state, the Q-learning algorithm moves deterministically in the same direction while SARSA follows as per expectation, and accordingly, it is called Expected SARSA. Its backup diagram is shown below.", "Refer to the below diagram for the Expected SARSA algorithm written in two different ways. The difference with Q-learning is highlighted.", "TD Methods have below advantages :", "But it has below limitations as well:", "Here we have covered one step TD methods but there are multi-step TD methods as well as a combination of TD & MC, like TD(\u03bb) algorithms. TD was a breakthrough innovation in Reinforcement Learning and every practitioner needs to have it in their tool kit.", "For only $5/month, get unlimited access to the most inspiring and uplifting content\u2026 Click on the link below to become a Medium member and support my writing. Thank you!https://baijayanta.medium.com/membership", "Data Science | Machine Learning | Deep Learning | Artificial Intelligence | Quantum Computing"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F47b4a7205ca8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://baijayanta.medium.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Baijayanta Roy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F583a83b12a79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&user=Baijayanta+Roy&userId=583a83b12a79&source=post_page-583a83b12a79----47b4a7205ca8---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F47b4a7205ca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&user=Baijayanta+Roy&userId=583a83b12a79&source=-----47b4a7205ca8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F47b4a7205ca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&source=-----47b4a7205ca8---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "http://www.linkedin.com/in/baijayantaroy", "anchor_text": "LinkedIn"}, {"url": "https://baijayanta.medium.com/membership", "anchor_text": "https://baijayanta.medium.com/membership"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----47b4a7205ca8---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----47b4a7205ca8---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----47b4a7205ca8---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----47b4a7205ca8---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/temporal-difference?source=post_page-----47b4a7205ca8---------------temporal_difference-----------------", "anchor_text": "Temporal Difference"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F47b4a7205ca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&user=Baijayanta+Roy&userId=583a83b12a79&source=-----47b4a7205ca8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F47b4a7205ca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&user=Baijayanta+Roy&userId=583a83b12a79&source=-----47b4a7205ca8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F47b4a7205ca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F583a83b12a79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&user=Baijayanta+Roy&userId=583a83b12a79&source=post_page-583a83b12a79----47b4a7205ca8---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff205a028dace&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&newsletterV3=583a83b12a79&newsletterV3Id=f205a028dace&user=Baijayanta+Roy&userId=583a83b12a79&source=-----47b4a7205ca8---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Written by Baijayanta Roy"}, {"url": "https://baijayanta.medium.com/followers?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "1.3K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F583a83b12a79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&user=Baijayanta+Roy&userId=583a83b12a79&source=post_page-583a83b12a79----47b4a7205ca8---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff205a028dace&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-difference-learning-47b4a7205ca8&newsletterV3=583a83b12a79&newsletterV3Id=f205a028dace&user=Baijayanta+Roy&userId=583a83b12a79&source=-----47b4a7205ca8---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35?source=author_recirc-----47b4a7205ca8----0---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=author_recirc-----47b4a7205ca8----0---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=author_recirc-----47b4a7205ca8----0---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Baijayanta Roy"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----47b4a7205ca8----0---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35?source=author_recirc-----47b4a7205ca8----0---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "All about Feature ScalingScale data for better performance of Machine Learning Model"}, {"url": "https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35?source=author_recirc-----47b4a7205ca8----0---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "\u00b710 min read\u00b7Apr 6, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbcc0ad75cb35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-feature-scaling-bcc0ad75cb35&user=Baijayanta+Roy&userId=583a83b12a79&source=-----bcc0ad75cb35----0-----------------clap_footer----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35?source=author_recirc-----47b4a7205ca8----0---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbcc0ad75cb35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-feature-scaling-bcc0ad75cb35&source=-----47b4a7205ca8----0-----------------bookmark_preview----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----47b4a7205ca8----1---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----47b4a7205ca8----1---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----47b4a7205ca8----1---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----47b4a7205ca8----1---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----47b4a7205ca8----1---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----47b4a7205ca8----1---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----47b4a7205ca8----1---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----47b4a7205ca8----1-----------------bookmark_preview----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----47b4a7205ca8----2---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----47b4a7205ca8----2---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----47b4a7205ca8----2---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----47b4a7205ca8----2---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----47b4a7205ca8----2---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----47b4a7205ca8----2---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----47b4a7205ca8----2---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----47b4a7205ca8----2-----------------bookmark_preview----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02?source=author_recirc-----47b4a7205ca8----3---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=author_recirc-----47b4a7205ca8----3---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=author_recirc-----47b4a7205ca8----3---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Baijayanta Roy"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----47b4a7205ca8----3---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02?source=author_recirc-----47b4a7205ca8----3---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "All about Categorical Variable EncodingMost of the Machine learning algorithms can not handle categorical variables unless they are converted to numerical values and many\u2026"}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02?source=author_recirc-----47b4a7205ca8----3---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": "\u00b715 min read\u00b7Jul 16, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&user=Baijayanta+Roy&userId=583a83b12a79&source=-----305f3361fd02----3-----------------clap_footer----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02?source=author_recirc-----47b4a7205ca8----3---------------------c0211427_bbc0_4dd9_82d4_37af4e1235ee-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F305f3361fd02&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-about-categorical-variable-encoding-305f3361fd02&source=-----47b4a7205ca8----3-----------------bookmark_preview----c0211427_bbc0_4dd9_82d4_37af4e1235ee-------", "anchor_text": ""}, {"url": "https://baijayanta.medium.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "See all from Baijayanta Roy"}, {"url": "https://towardsdatascience.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----47b4a7205ca8----0-----------------bookmark_preview----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----47b4a7205ca8----1-----------------bookmark_preview----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://aniruddhamukh.medium.com/?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://aniruddhamukh.medium.com/?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Aniruddha Mukherjee"}, {"url": "https://medium.com/dsckiit?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "GDSC KIIT"}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Reinforcement Learning: An Introduction and Guide to its FundamentalsPolicies, Rewards, the Bellman Equation, and the Markov Decision Process (MDP)"}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "5 min read\u00b7Apr 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdsckiit%2F467c6a2ed25e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdsckiit%2Freinforcement-learning-guide-and-introduction-467c6a2ed25e&user=Aniruddha+Mukherjee&userId=68f97387c191&source=-----467c6a2ed25e----0-----------------clap_footer----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----47b4a7205ca8----0---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F467c6a2ed25e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdsckiit%2Freinforcement-learning-guide-and-introduction-467c6a2ed25e&source=-----47b4a7205ca8----0-----------------bookmark_preview----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----1-----------------clap_footer----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----47b4a7205ca8----1---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----47b4a7205ca8----1-----------------bookmark_preview----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----47b4a7205ca8----2---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----47b4a7205ca8----2---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----47b4a7205ca8----2---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Anand Mishra"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----47b4a7205ca8----2---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Deep reinforcement learning \u2014 current state of artCurrent"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----47b4a7205ca8----2---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "5 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&user=Anand+Mishra&userId=86f86a9a5573&source=-----383190b14464----2-----------------clap_footer----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----47b4a7205ca8----2---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&source=-----47b4a7205ca8----2-----------------bookmark_preview----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----47b4a7205ca8----3---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://rahulbhadani.medium.com/?source=read_next_recirc-----47b4a7205ca8----3---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://rahulbhadani.medium.com/?source=read_next_recirc-----47b4a7205ca8----3---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Rahul Bhadani"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----47b4a7205ca8----3---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----47b4a7205ca8----3---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "Foundational RL: Solving Markov Decision ProcessRoad to Reinforcement Learning"}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----47b4a7205ca8----3---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": "\u00b711 min read\u00b7Dec 12, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd90b7e134c0b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffoundational-rl-solving-markov-decision-process-d90b7e134c0b&user=Rahul+Bhadani&userId=5d4d67138803&source=-----d90b7e134c0b----3-----------------clap_footer----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b?source=read_next_recirc-----47b4a7205ca8----3---------------------26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd90b7e134c0b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffoundational-rl-solving-markov-decision-process-d90b7e134c0b&source=-----47b4a7205ca8----3-----------------bookmark_preview----26fb758d_cc0c_4deb_a9e7_ce1fc8786577-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----47b4a7205ca8--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}