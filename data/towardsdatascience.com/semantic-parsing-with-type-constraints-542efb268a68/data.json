{"url": "https://towardsdatascience.com/semantic-parsing-with-type-constraints-542efb268a68", "time": 1682997452.835822, "path": "towardsdatascience.com/semantic-parsing-with-type-constraints-542efb268a68/", "webpage": {"metadata": {"title": "Neural Semantic Parsing with Type Constraints for Semi-Structured Tables | by Nathaniel Watkins | Towards Data Science", "h1": "Neural Semantic Parsing with Type Constraints for Semi-Structured Tables", "description": "NLP that doesn\u2019t pay attention to semantics is just statistics on words. The authors created a novel encoder-decoder semantic parser using type constraints to teach the logical structure of semantics."}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/jayant-krishnamurthy-134035188/", "anchor_text": "Jayant Krishnamurthy", "paragraph_index": 1}, {"url": "https://www.linkedin.com/in/pradeepdasigi/", "anchor_text": "Pradeep Dasigi", "paragraph_index": 1}, {"url": "https://www.linkedin.com/in/matt-gardner-34292bbb/", "anchor_text": "Matt Gardner", "paragraph_index": 1}, {"url": "https://skymind.ai/wiki/lstm", "anchor_text": "LSTM", "paragraph_index": 5}, {"url": "https://medium.com/explore-artificial-intelligence/word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba", "anchor_text": "input word vectors", "paragraph_index": 5}, {"url": "https://medium.com/@devnag/seq2seq-the-clown-car-of-deep-learning-f88e1204dac3", "anchor_text": "seq2seq approach", "paragraph_index": 5}, {"url": "https://nlp.stanford.edu/blog/wikitablequestions-a-complex-real-world-question-understanding-dataset/", "anchor_text": "WikiTableQuestions dataset", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/two-is-better-than-one-ensembling-models-611ee4fa9bd8", "anchor_text": "https://towardsdatascience.com/two-is-better-than-one-ensembling-models-611ee4fa9bd8", "paragraph_index": 21}], "all_paragraphs": ["Neural Semantic Parsing with Type Constraints for Semi-Structured Tables", "By Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner found here:", "Natural Language Processing (NLP) that doesn\u2019t pay attention to the semantics of the language, just results in basic statistics of what words are more/less common and what might correlate with those words; so true Natural Language Understanding (NLU) cannot be achieved without Type constraints because the structure (essential to understand the meaning) of language is not conveyed to the model.", "To overcome this hurdle, the authors have implemented a novel encoder-decoder parser using constraints to ensure that their NLU model understands the logic of how language is structured, and thus it is able to learn how different entities relate to each other, pushing forward the state of the art in neural semantic parsers.", "Previously this problem has been approached via a variety of methods, and the authors have taken the good aspects from them while avoiding most of the downsides. These include:", "Krishnamurthy et al.\u2019s model addresses these limitations by tying an Encoder-Decoder framework into their LSTM to convert the input word vectors into logical forms (similar to the venerable seq2seq approach), but crucially they also assign type constraints on the grammar. This approach achieves the precision of the former approaches previously mentioned, encoding entity links automatically, while also scaling without the need for manual labeling.", "The real key to their work comes from enforcing type constraints on the decoded grammar: a constraint being a required condition for the parameter. Using automatically assigned type constraints, they\u2019re able to derive every valid logical form using just the following 4 categories of rules:", "Application \u2013 \u201crewrites a nonterminal of type \u03c4 by applying a function from \u03b2 to \u03c4 to an argument of type \u03b2. We also permit applications with more than one argument.\u201d", "Constant \u2013 \u201cwhere constant const has type \u03c4. This rule generates both table-independent operations such as argmax and table-specific entities such as united_states.\u201d", "Lambda \u2013 \u201cgenerates a lambda expression where the argument has type \u03b1. x represents a fresh variable name. The right hand side of this rule extends the scope \u0393 with a binding for x then generates an expression of type \u03c4.\u201d", "Variable \u2013 \u201cThis rule generates a variable bound in a previously-generated lambda expression that is currently in scope.\u201d", "Basically, the name of the largest lake is found by sorting a list of all lakes from largest to smallest by the type constraint of area in km, and using type constraints again to return the name instead of another data point, such as the area.", "A simpler example could be finding the result of the equation: `35 x 1.2 =` which would be achieved by applying the following type constraints:", "In addition to their core model trained to parse the semantics of the question-answer pair, they trained a separate LSTM model to handle entity linking in parallel with the main model. Instead of relying on tedious entity linking for each word embedding (a numerical representation of words) done manually, or a generic, immutable entity linking lexicon created outside the context of the task at hand, the researchers have created a separate model to map a context-aware entity linking matrix that is created and updated as their main semantic parser learns more, thus reinforcing the semantic parser in a virtuous cycle.", "The links are created partly based on word similarities, and partly based on how the words are used together. So the word \u201cBoatswain\u201d would be more strongly linked to \u201cBoathouse\u201d than \u201cCummerbund\u201d, but if parsing a corpus that describes all the different ways and quantities that \u201ccummerbunds\u201d could be stored in a \u201cboathouse\u201d, those two words would start to develop a strong link within this context. This ability to learn how terms relate to each other within the context of the subject at hand is what allows their semantic parser to achieve impressive performance; it can build expertise in niche fields in a similar way to how humans learn, making connections not just within what it is currently \u201creading\u201d, but how it relates to other things it has \u201cread\u201d, and this effect compounds as it \u201creads\u201d more.", "Tying all these improvements together they used DPD on each table/corpus/subject, computing all logically consistent combinations of constraints that would result in an answer. Normally, the results/progress from a parser are relatively easy to evaluate if the number of possible predictions is relatively small, but as that number increases, the difficulty/cost of evaluating those options in a conventional way (by processing them through the network architecture) increases exponentially, very quickly becoming unfeasible to do for complex subjects.", "Krishnamurthy, et al. solve this problem by restricting their evaluation to a limit of the most likely best predictions. Previous approaches either needed to use a prohibitively high limit when choosing their marginal loglikelihood best predictions. Or previous attempts used a reinforcement learning technique which is not appropriate for complex subjects due to a poor signal-to-noise ratio. This novel approach works within a reasonable limit size because they first restricted the set of possible options using DPD so only valid options are possible. This allowed them to get better results at a lower cost.", "The researchers chose to test their results on the WikiTableQuestions dataset, due to its complexity (depth) and the wide scope of information (breadth). This dataset is populated with tables of data from a large variety of topics on Wikipedia: 2108 tables specifically. Plus, it contains 22033 questions of varying complexities to dive deep into the specifics, requiring a semantic parser to truly understand the data and how it all relates in order to perform well. Additionally, this dataset has a hidden test set of questions based on fresh tables allowing models to be challenged with unseen data to prove its ability to generalize to new topics and show that it isn\u2019t just memorizing the question-answer pairs.", "The immense breadth and depth of the information here presents several opportunities for semantic understanding machines to demonstrate competency by overcoming the following challenges:", "Previous attempts at QA datasets tended to either focus strongly on depth with a pretty narrow breadth (ex. \u201cwhat states border texas and have a major river?\u201d but is focused exclusively on geography) or they covered a wide breadth of questions without going deep into any topics (ex. \u201cwhat countries around the world speak french?\u201d).", "Using type constrained decoding, entity linking trained with the semantic parser and DPD, Krishnamurthy et al. were able to surpass the prior state of the art on the WikiTableQuestions dataset, proving that their methods are practical in addition to theoretical. Since this dataset is so deep and vast, these aren\u2019t simple yes/no questions; thus 45.9% is a very impressive result.", "They trained versions of a semantic parser that used a single model vs an ensemble of models to show that these methods work across a variety of implementations. An ensemble is basically a set of different (sometimes very different, sometimes only slightly different) models all trained together who each make a prediction and they compare their answers to come up with a better choice most of the time. For a better explanation, read this: https://towardsdatascience.com/two-is-better-than-one-ensembling-models-611ee4fa9bd8", "In addition to testing a variety of implementations, they also experimented with measuring the 3 contributions by selective turning down (or off) specific modules to see the impact on overall performance.", "These results show that all 3 methods go together to produce a significant advance to the state of the art for Semantic Parsing and Natural Language Processing as a whole. While there\u2019s room for improvement, these contributions solve a lot of the challenges necessary for a parser to be practically implemented on a real-world use case.", "I look forward to hearing any feedback or questions you have on this article or the topics discussed, either in the responses here or on social media. Feel free to connect with me (just let me know that you saw this article) \u2192", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A dedicated manager turned Data Scientist, enthusiastic for the innovative ways technology can impact people."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F542efb268a68&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----542efb268a68--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----542efb268a68--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@theNathanielW?source=post_page-----542efb268a68--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@theNathanielW?source=post_page-----542efb268a68--------------------------------", "anchor_text": "Nathaniel Watkins"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F98746e78b8a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&user=Nathaniel+Watkins&userId=98746e78b8a8&source=post_page-98746e78b8a8----542efb268a68---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F542efb268a68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F542efb268a68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@startaeteam?utm_source=medium&utm_medium=referral", "anchor_text": "Starta\u00ea Team"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.linkedin.com/in/jayant-krishnamurthy-134035188/", "anchor_text": "Jayant Krishnamurthy"}, {"url": "https://www.linkedin.com/in/pradeepdasigi/", "anchor_text": "Pradeep Dasigi"}, {"url": "https://www.linkedin.com/in/matt-gardner-34292bbb/", "anchor_text": "Matt Gardner"}, {"url": "http://ai2-website.s3.amazonaws.com/publications/wikitables.pdf", "anchor_text": "http://ai2-website.s3.amazonaws.com/publications/wikitables.pdf"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://en.wikipedia.org/wiki/Formal_grammar", "anchor_text": "grammar formalisms"}, {"url": "https://en.wikipedia.org/wiki/Combinatory_categorial_grammar", "anchor_text": "CCG"}, {"url": "https://skymind.ai/wiki/lstm", "anchor_text": "LSTM"}, {"url": "https://medium.com/explore-artificial-intelligence/word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba", "anchor_text": "input word vectors"}, {"url": "https://medium.com/@devnag/seq2seq-the-clown-car-of-deep-learning-f88e1204dac3", "anchor_text": "seq2seq approach"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://nlp.stanford.edu/blog/wikitablequestions-a-complex-real-world-question-understanding-dataset/", "anchor_text": "WikiTableQuestions dataset"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://towardsdatascience.com/two-is-better-than-one-ensembling-models-611ee4fa9bd8", "anchor_text": "https://towardsdatascience.com/two-is-better-than-one-ensembling-models-611ee4fa9bd8"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "authors\u2019 slide deck on this paper"}, {"url": "https://github.com/allenai/allennlp/blob/master/allennlp/models/semantic_parsing/wikitables/wikitables_mml_semantic_parser.py", "anchor_text": "allenai/allennlpAn open-source NLP research library, built on PyTorch. - allenai/allennlpgithub.com"}, {"url": "https://vimeo.com/238234920", "anchor_text": "https://vimeo.com/238234920"}, {"url": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf", "anchor_text": "https://nlp.stanford.edu/seminar/details/jkrishnamurthy.pdf"}, {"url": "https://twitter.com/theNathanielW", "anchor_text": "twitter.com/theNathanielW"}, {"url": "https://www.linkedin.com/in/theNathanielWatkins/", "anchor_text": "linkedin.com/in/theNathanielWatkins"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----542efb268a68---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----542efb268a68---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----542efb268a68---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/semantics?source=post_page-----542efb268a68---------------semantics-----------------", "anchor_text": "Semantics"}, {"url": "https://medium.com/tag/research?source=post_page-----542efb268a68---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F542efb268a68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&user=Nathaniel+Watkins&userId=98746e78b8a8&source=-----542efb268a68---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F542efb268a68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&user=Nathaniel+Watkins&userId=98746e78b8a8&source=-----542efb268a68---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F542efb268a68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----542efb268a68--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F542efb268a68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----542efb268a68---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----542efb268a68--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----542efb268a68--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----542efb268a68--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----542efb268a68--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----542efb268a68--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----542efb268a68--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----542efb268a68--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----542efb268a68--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@theNathanielW?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@theNathanielW?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nathaniel Watkins"}, {"url": "https://medium.com/@theNathanielW/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "23 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F98746e78b8a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&user=Nathaniel+Watkins&userId=98746e78b8a8&source=post_page-98746e78b8a8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fdb07dded9455&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-parsing-with-type-constraints-542efb268a68&newsletterV3=98746e78b8a8&newsletterV3Id=db07dded9455&user=Nathaniel+Watkins&userId=98746e78b8a8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}