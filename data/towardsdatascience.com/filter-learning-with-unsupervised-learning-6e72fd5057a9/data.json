{"url": "https://towardsdatascience.com/filter-learning-with-unsupervised-learning-6e72fd5057a9", "time": 1683014461.848984, "path": "towardsdatascience.com/filter-learning-with-unsupervised-learning-6e72fd5057a9/", "webpage": {"metadata": {"title": "Learning Filters with Unsupervised Learning | by Tekin Evrim Ozmermer | Towards Data Science", "h1": "Learning Filters with Unsupervised Learning", "description": "Data is everything. Especially in deep learning, the amount of data, type of data, and quality of data are the most important factors. Sometimes the amount of labeled data that we have is not enough\u2026"}, "outgoing_paragraph_urls": [{"url": "https://link.medium.com/e4a4kTmYvab", "anchor_text": "LINK", "paragraph_index": 26}], "all_paragraphs": ["Data is everything. Especially in deep learning, the amount of data, type of data, and quality of data are the most important factors. Sometimes the amount of labeled data that we have is not enough or the problem domain that we work on does not make sense to use a big amount of data such as in few-shot learning. The important factors in those situations are the algorithms. In deep metric learning, the loss functions that we use are the most important factors. What we try to do in DML is to learn a set of features that can distinguish different image samples from each other while matches similar ones to each other.", "In my work, I have started working on a project where we need to leverage deep metric learning methods. We needed to extract meaningful features out of images so that we can classify thousands of image samples accurately. While DML is the problem domain for the system that we build, I was thinking about other methods that can extract meaningful features out of images. I looked back at the human brain.", "I believe that the human brain is neither a classification model nor an autoencoder model. The human brain is a DML system where each object, each scene, and each input is represented with a set of embedding. But, when we are babies, does someone comes and shows each object to us and say", "\u201cHey kid, look, this object and this object are different while these are the same.\u201d?", "Well\u2026 they don\u2019t. Just when we can speak, we, curious brats, ask questions to parents non-stop.", "Learning each embedding of everything we see does happen before we learn to classify those embedding in our brains, and this process happens unsupervised, just when we are on our own. So, this learning mechanism is not a DML algorithm. So, what is it?", "I have come up with one basic solution to this problem: Feature Distinguishment.", "In this method, we need to build a neural network where each convolution layer is as different as possible from each other at the same level. So, when we apply a convolution operation on a gray image with 32 5x5 filters, those 32 layers should differ from each other. How can we do that? The answer is cosine similarity. We can easily calculate cosine similarity by the matrix multiplication of two flattened layers where one of them is transposed. And how many times do we need to apply this operation? The answer is as many as the combinations of the convolution layers.", "Let\u2019s start coding then, I know this is the part you like.", "So, now we need to build two networks where one of them includes convolution layers for each level, while the other one includes all levels of convolution layers.", "You may ask here, \u201chey Evrim, why did you use two convolution layers in each layer?\u201d The answer is they catch more features and this one worked better than single convolution layers. Plus, the ReLU that I apply at the end of the single convolution layer causes nan in the loss after some time. When I put ReLU between two convolution layers, I do not get nan value in the loss. I haven\u2019t explained it so \u201cscientific\u201d, I know. But, if you are looking for scientific articles, Medium is most probably not the place for a \u201cscientific\u201d article, isn\u2019t it?\u00a0:D", "Anyways, let\u2019s go on. Now, we need to build the main, the mother class that contains each level of the convolution operations. As you see in the class below, each convolution layer is called a child and they are appended to a \u201cchildren\u201d Python list. If you ask about the star just before the \u201cchildren\u201d list in the \u201cSequential\u201d function\u2019s input, that star is to interpret each element in the children list without a list encircling them.", "I know you are thinking about this \u201cqueue\u201d thing in the forward function. Do you remember that we need to distinguish each feature map in one level of the convolution layer? We will do this for several layers, and that queue thing works for that. The rest is up to you, read the code, and try to understand please, we cannot live a life of ease all the time, right?", "Okay, now we have our classes. Let\u2019s call them somewhere. But first, we need data to train the network and also to do some tests.", "Holly molly, Evrim this learning rate is so high! I know, I know. I determined this learning rate by try and error. The less learning rate was learning slow. When I say slow, I mean it.", "We take each sample from the dataset and feed it to the model. If we are in the first epoch, the model learns to distinguish the feature maps on the first level. If we are in the second epoch, the model learns to distinguish the feature maps on the second level, and this goes on like that. Easy right?", "What about those commented parts? They are to freeze the learning process for levels which already were able to distinguish the filters. You can activate that part and try, but I found that freezing them does not make it easier for the network to learn at the next levels.", "So, in each epoch, our similarity vector gets fewer values as it is aimed at first. If the observed loss (this is different than mean squared loss and it is not used for backpropagation) is less than 0.4 on an average of the last 10 loss values, then the training of that convolution level is finished. So, we jump to the next one.", "As you recognize, we do not need any labels here. We just try to get the most different features maps at the end of the feedforward process.", "Besides, the network has reached to 300th sample max in the dataset until it finishes the learning process at each level.", "What happens here? We give a sample index as input. This sample index is the anchor that we will compare with other samples. Then we feed each sample to the neural network, we get embedding out and compare those embedding with the embedding of the anchor sample. The testing samples are never the same as the anchor sample as you can see in the \u201cif\u201d condition.", "When we compared a sample that has the label \u201c5\u201d, most similar samples that we have found have the label \u201c6\u201d which is kind of logical since 5 and 6 are visually similar digits.", "When we compared a sample that has the label \u201c8\u201d, most similar samples that we have found have the label \u201c8\u201d, yeeyyy!", "For the sample with label \u201c4\u201d, the most similar sample we found is 9, but we also found similar samples which have label \u201c4\u201d as well, there is a significant number of them.", "For the sample with label \u201c2\u201d, the network is successful again.", "We see that the network has learned to distinguish the feature maps, and it helped it to create embedding that helps us classify the samples accurately. I know it is not so high accuracy. But remember, this is just the feature extraction process of a baby. The baby is still not grown enough to classify the embedding that it extracts from the visuals. That will be the next step that I need to continue with.", "Link to next article for this subject: LINK", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI Developer In \u201c>\u201d, Interested in Artificial Intelligence, Human Intelligence, Economical inequality, and all other interesting stuff."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6e72fd5057a9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tekinevrim.medium.com/?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": ""}, {"url": "https://tekinevrim.medium.com/?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "Tekin Evrim Ozmermer"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feb684b71256e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&user=Tekin+Evrim+Ozmermer&userId=eb684b71256e&source=post_page-eb684b71256e----6e72fd5057a9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e72fd5057a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e72fd5057a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/evrimozmermer/filter_distinguisher", "anchor_text": "LINK"}, {"url": "https://link.medium.com/e4a4kTmYvab", "anchor_text": "LINK"}, {"url": "https://medium.com/tag/unsupervised-learning?source=post_page-----6e72fd5057a9---------------unsupervised_learning-----------------", "anchor_text": "Unsupervised Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----6e72fd5057a9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----6e72fd5057a9---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/self-supervised-learning?source=post_page-----6e72fd5057a9---------------self_supervised_learning-----------------", "anchor_text": "Self Supervised Learning"}, {"url": "https://medium.com/tag/feature-extraction?source=post_page-----6e72fd5057a9---------------feature_extraction-----------------", "anchor_text": "Feature Extraction"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e72fd5057a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&user=Tekin+Evrim+Ozmermer&userId=eb684b71256e&source=-----6e72fd5057a9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e72fd5057a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&user=Tekin+Evrim+Ozmermer&userId=eb684b71256e&source=-----6e72fd5057a9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e72fd5057a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6e72fd5057a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6e72fd5057a9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6e72fd5057a9--------------------------------", "anchor_text": ""}, {"url": "https://tekinevrim.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tekinevrim.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tekin Evrim Ozmermer"}, {"url": "https://tekinevrim.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "119 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feb684b71256e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&user=Tekin+Evrim+Ozmermer&userId=eb684b71256e&source=post_page-eb684b71256e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3519630afba3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffilter-learning-with-unsupervised-learning-6e72fd5057a9&newsletterV3=eb684b71256e&newsletterV3Id=3519630afba3&user=Tekin+Evrim+Ozmermer&userId=eb684b71256e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}