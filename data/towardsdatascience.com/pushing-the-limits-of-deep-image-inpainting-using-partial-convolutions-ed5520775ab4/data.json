{"url": "https://towardsdatascience.com/pushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4", "time": 1683016241.1076422, "path": "towardsdatascience.com/pushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4/", "webpage": {"metadata": {"title": "Pushing the Limits of Deep Image Inpainting Using Partial Convolutions | by Chu-Tak Li | Towards Data Science", "h1": "Pushing the Limits of Deep Image Inpainting Using Partial Convolutions", "description": "Hi. Today, I would like to talk about a good deep image inpainting paper which has broken some limitations on previous inpainting work. In short, most of the previous papers assume that the missing\u2026"}, "outgoing_paragraph_urls": [{"url": "https://lichutak.medium.com/", "anchor_text": "my previous posts", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/a-milestone-in-deep-image-inpainting-review-globally-and-locally-consistent-image-completion-505413c300df", "anchor_text": "GLCIC", "paragraph_index": 27}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "Contextual Attention", "paragraph_index": 27}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper", "paragraph_index": 30}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper", "paragraph_index": 32}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "Image Inpainting for Irregular Holes Using Partial Convolution", "paragraph_index": 35}, {"url": "https://chutakcode.wixsite.com/website", "anchor_text": "https://chutakcode.wixsite.com/website", "paragraph_index": 38}], "all_paragraphs": ["Hi. Today, I would like to talk about a good deep image inpainting paper which has broken some limitations on previous inpainting work. In short, most of the previous papers assume that the missing region(s) is/are regular (i.e. a center missing rectangular hole or multiple small rectangular holes) and this paper proposes a Partial Convolutional (PConv) layer to deal with irregular holes. Figure 1 shows some inpainting results using the proposed PConv. Are they good? Let\u2019s grasp the main idea of PConv together!", "First of all, previous deep image inpainting approaches treat missing pixels and valid pixels the same in the sense that they fill a fixed pixel value (255 or 1 before/after normalization) to all the missing pixels in an image and apply standard convolutions to the input image for the task of inpainting. There are two problems here. i) Is it appropriate to fix the pixel values of the missing pixels to a pre-defined value? ii) Is it suitable for convolving the input image regardless of the validness of the pixels? So, it may be a good option to perform operations only on valid pixels.", "Secondly, existing approaches assume that the missing region(s) is/are regular/rectangular. Some of them employ local discriminator to distinguish generated content from real content. For the case of a fixed size center missing hole, they input the filled center hole to the local discriminator for enhancing the local texture details. But how about irregular missing areas? Is it possible to have fine local details without the employment of a discriminator? If you have tried using the existing approaches for handling irregular masked images, you can find that the inpainting results are not satisfactory as shown in Figure 2. For practical inpainting methods, they should be able to handle irregular masked images.", "Similar to my previous posts, I assume that readers have a basic understanding of deep image inpainting such as network architecture, loss function (i.e. L1 and Adversarial losses), and related terminology (i.e. valid pixels, missing pixels, etc.). If you need or want, please have a quick recall of my previous posts. In this section, I will briefly go through the things that I think are less important, hence we can have more time to dive into the most important idea of this paper, Partial Convolution, in the following sections.", "The authors of this paper employ a U-Net like network with skip connections in which all standard convolutional layers are replaced by the proposed partial convolutional layers. If you are interested in their network architecture, you may refer to the paper and they provide detailed tables of their model.", "Interestingly, no discriminator is used in this work. Apart from standard L1 loss and total variation loss (TV loss), the authors adopt two high-level feature losses to complete the masked images with fine textures. I will introduce these two losses in detail later on.", "As mentioned in Motivation, the key idea is to separate the missing pixels from the valid pixels during convolutions such that the results of convolutions only depend on the valid pixels. This is the reason why the proposed convolution is named partial convolution. The convolution is partially performed on the input based on a binary mask image that can be updated automatically.", "Let us define W and b be the weights and bias of the convolution filter. X represents the pixel values (or feature activation values) being convolved and M is the corresponding binary mask which indicates the validness of each pixel/feature value (0 for missing pixels and 1 for valid pixels). The proposed partial convolution is computed,", "where \u29bf means element-wise multiplication and 1 is a matrix of ones that has the same shape as M. From this equation, you can see that the results of the partial convolution only depend on the valid input values (as X \u29bf M). sum(1)/sum(M) is a scaling factor to adjust the results as the number of valid input values for each convolution is varying.", "Update the binary mask after each partial convolutional layer. The proposed rule to update the binary mask is quite easy. If the result of the current convolution is conditioned on at least one valid input value, the corresponding location will be regarded as valid for the next partial convolutional layer.", "as you can see above, the updating rule is simple to understand.", "Figure 3 shows a simple example to illustrate the proposed partial convolution. We consider a simple 5\u00d75 input with its corresponding 5\u00d75 binary mask image (1 for valid pixels and 0 for hole pixels) and a 3\u00d73 W with fixed weights. Assume that we want to keep the same output size as the input size 5\u00d75, hence we perform zero paddings before doing the convolution. Let\u2019s consider the top-left corner (orange-bounded) first. X and M for this convolution are clearly shown in the figure and the number of valid input values is 3. Hence, the output of this location is -9+b. Also, the value of the corresponding location in the updated binary mask is 1 as there are 3 valid input values.", "Considering the middle (purple-bounded) box, this time, as you can see, there is no valid input value for this convolution, so the result is 0+b and the updated mask value is also 0. The bottom-right (blue-bounded) box is another convolution example for showing the role of the scaling factor. By the scaling factor, the network can distinguish -3 computed by 3 valid input values from -3 computed by 5 valid input values.", "For readers\u2019 information, the updated binary mask after this partial convolutional layer is shown in the top-right corner of Figure 3. You can see that there are fewer zeros in the updated binary mask. When we perform more and more partial convolutions, the binary mask will be eventually updated to have all ones. This means that we can control the information to be passed inside the network regardless of the size and the shape of the missing regions.", "In total, there are 4 loss terms in their final loss function, namely L1 loss, Perceptual loss, Style loss, and TV loss.", "This loss is for ensuring the pixel-wise reconstruction accuracy.", "where I_out and I_gt are the output of the network and the ground truth respectively. M is the binary mask, 0 for holes, and 1 for valid pixels. N_I_gt is the total number of pixel values in an image, which equals C\u00d7H\u00d7W, C is the channel size (3 for RGB image), H and W are the height and width of the image I_gt. You can see that L_hole and L_valid are the L1 loss of the hole pixels and valid pixels respectively.", "The perceptual loss is proposed by Gatys et al. [2] and we have introduced this loss previously. Simply speaking, we want the filled image and the ground truth image to have similar feature representations computed by a pre-trained network like VGG-16. Specifically, we feed the ground truth image and the filled image to a pre-trained VGG-16 to extract features. Then, we calculate the L1 distance between their feature values at all or several layers.", "For the above equation, I_comp is the same as I_out except the valid pixels are directly replaced by the ground truth pixels. \u03a8^I_p is the feature maps of the p-th layer computed by a pre-trained VGG-16 given the input I. N_\u03a8^I_p is the number of elements in \u03a8^I_p. According to Gatys et al. [2], this perceptual is small when the completed image is semantically close to its ground truth image. Perhaps, it is because deeper layers (higher level) provide more semantic information of an image and similar high-level feature representations represent better semantic correctness of the completion. For readers\u2019 information, VGG-16 pool1, pool2, and pool3 layers are used to compute the perceptual loss.", "Apart from the perceptual loss, the authors also adopt the style loss as shown in the above. You can see that the style loss is also computed using the feature maps given by a pre-trained VGG-16. This time, we first calculate the auto-correlation of each feature map and it is called Gram matrix in [2]. According to [2], the Gram matrix contains the style information of an image such as textures and colours. This is also the reason why this loss is named Style loss. Thus, we compute the L1 distance between the Gram matrices of the completed image and the ground truth image. Note that \u03a8^I_p is with size of (H_p\u00d7W_p)\u00d7C_p and its Gram matrix is with shape of C_p\u00d7C_p. K_p is a normalizing factor which depends on the spatial size of the feature maps at p-th layer.", "The last loss term in their final loss function is the TV loss. We have talked about this loss in my previous posts. Simply speaking, this loss is adopted to ensure the smoothness of the completed images. This is also a common loss in many image processing tasks.", "where N_I_comp is the total number of pixel values in I_comp.", "This is the final loss function to train the proposed model. The hyper-parameters used to control the importance of each loss term are set based on experiments on 100 validation images.", "The authors did experiments to show the effects of different loss terms. The results are shown in Figure 4 in the above. First of all, Figure 4(b) shows the inpainting result without using style loss. They found that the use of the style loss is necessary in their model to generate fine local textures. However, the hyper-parameter for the style loss has to be carefully selected. As you can see in Figure 4(f), small weight for the style loss would cause some obvious artifacts as compared to the result using the full loss (Figure 4(g)). Apart from the style loss, the perceptual loss is also important. They also found that the employment of the perceptual loss can reduce the grid-shaped artifacts. Please see Figure 4(j) and (k) for the effect of the use of the perceptual loss.", "In fact, the use of the high-level feature loss has not been fully studied. We cannot 100% say that the perceptual loss or the style loss must be useful for image inpainting. So, we have to do our own experiments to check the effectiveness of different loss terms for our desired applications.", "In their experiments, all the mask, training, and testing images are with the size of 512\u00d7512. The authors divided the testing images into two groups, i) mask with holes close to border. ii) mask without holes close to border. Images with all the holes with distance of at least 50 pixels from the border are classified into the second group. Figure 5 shows some examples of these two groups of masks. Furthermore, the authors generate 6 types of masks according to the hole-to-image area ratios: (0.01, 0.1], (0.1, 0.2], (0.2, 0.3], (0.3, 0.4], (0.4, 0.5], and (0.5, 0.6]. This means that the largest mask would mask out 60% of the original image content.", "Training data. Similar to previous work, the authors evaluated their model on 3 publicly available datasets, namely, ImageNet, Places2 and CelebA-HQ datasets.", "Figure 6 and 7 show the visual comparisons of different approaches on ImageNet and Places2 respectively. PatchMatch is the state-of-the-art conventional approach. GLCIC and Contextual Attention are two state-of-the-art deep learning approaches we have introduced before. As you can see, GLCIC (c) and Contextual Attention (d) cannot offer inpainting results with good visual quality. It may due to the fact that these two previous deep learning approaches are trained for regular masked images instead of irregular masked images. If you are interested, please zoom in for a better view of the inpainting results.", "Figure 8 shows the inpainting results on CelebA-HQ dataset. You may zoom in for a better view of the results.", "Table 1 lists out several objective evaluation metric numbers for readers\u2019 information. Clearly, the proposed PConv offers the best numbers in nearly all the cases. Note that IScore is the inception score which is used as an estimation of the visual quality, and the lower the better estimated visual quality.", "Apart from the qualitative and quantitative comparisons, the authors also conducted a human subjective study to evaluate the visual quality of different approaches. Interested readers may refer to the paper for the study.", "At the end of this paper, the authors also mention some limitations of the current deep image inpainting approaches. First, it is difficult to complete an image with a large missing area as shown in the right of Figure 9. Second, when the image contains complex structure, it is also difficult to complete the image with good visual quality as shown in Figure 10. There is still no a comprehensive method to handle extreme large masked and complicated images. So, you may try to propose a good solution to this extreme image inpainting problem. :)", "Obviously, Partial Convolution is the main idea of this paper. I hope that my simple example can explain clearly to you how the partial convolution is performed and how a binary mask is updated after each partial convolution layer. By using Partial Convolution, the results of convolution would only depend on valid pixels, hence we can have the control of the information pass inside the network and this may be useful for the task of image inpainting (at least the authors provide evidence that partial convolution is useful in their case). Apart from image inpainting, the authors have also tried to extend the partial convolution to the task of super-resolution as it shares similarity with image inpainting. Interested readers are highly recommended to refer to their paper.", "Without a doubt, I hope you can understand what is partial convolution. Starting from this paper, the later deep image inpainting methods can deal with both regular and irregular masks. Together with my previous posts related to image inpainting, I also hope that you can have better understanding of the field of image inpainting. You should know some common techniques and remaining challenges in image inpainting. For example, dilation convolution, contextual attention layer, etc. It is also difficult to fill in an image when the hole(s) in an image is/are too large and the image is with complex structure.", "Next time, we will look at another paper which makes use of additional information to help filling in the masked images. Hope you enjoy! Let\u2019s learn together! :)", "[1] Guilin Liu, Fitsum A. Reda, Kevin J. Shih, Ting-Chun Wang, Andrew Tao, and Bryan Catanzaro, \u201cImage Inpainting for Irregular Holes Using Partial Convolution,\u201d Proc. European Conference on Computer Vision (ECCV), 2018.", "Thanks for reading my post! If you have any questions, please feel free to send my an email or leave comments here. Any suggestions are welcome. Thank you very much again and hope to see you next time! :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "DO IT FIRST. ONLY U CAN DEFINE YOURSELF. I have started my PhD journey accidentally. To know more about me at: https://chutakcode.wixsite.com/website"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fed5520775ab4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lichutak.medium.com/?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": ""}, {"url": "https://lichutak.medium.com/?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "Chu-Tak Li"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4c07943b642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&user=Chu-Tak+Li&userId=f4c07943b642&source=post_page-f4c07943b642----ed5520775ab4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed5520775ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed5520775ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://lichutak.medium.com/", "anchor_text": "my previous posts"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://towardsdatascience.com/a-milestone-in-deep-image-inpainting-review-globally-and-locally-consistent-image-completion-505413c300df", "anchor_text": "GLCIC"}, {"url": "https://towardsdatascience.com/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0", "anchor_text": "Contextual Attention"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1804.07723.pdf", "anchor_text": "Image Inpainting for Irregular Holes Using Partial Convolution"}, {"url": "https://arxiv.org/pdf/1508.06576.pdf", "anchor_text": "A Neural Algorithm of Artistic Style"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----ed5520775ab4---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/image-processing?source=post_page-----ed5520775ab4---------------image_processing-----------------", "anchor_text": "Image Processing"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----ed5520775ab4---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/image-inpainting?source=post_page-----ed5520775ab4---------------image_inpainting-----------------", "anchor_text": "Image Inpainting"}, {"url": "https://medium.com/tag/image?source=post_page-----ed5520775ab4---------------image-----------------", "anchor_text": "Image"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed5520775ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&user=Chu-Tak+Li&userId=f4c07943b642&source=-----ed5520775ab4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed5520775ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&user=Chu-Tak+Li&userId=f4c07943b642&source=-----ed5520775ab4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed5520775ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fed5520775ab4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ed5520775ab4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ed5520775ab4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ed5520775ab4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ed5520775ab4--------------------------------", "anchor_text": ""}, {"url": "https://lichutak.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lichutak.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Chu-Tak Li"}, {"url": "https://lichutak.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "122 Followers"}, {"url": "https://chutakcode.wixsite.com/website", "anchor_text": "https://chutakcode.wixsite.com/website"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff4c07943b642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&user=Chu-Tak+Li&userId=f4c07943b642&source=post_page-f4c07943b642--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd59b7e8b1294&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpushing-the-limits-of-deep-image-inpainting-using-partial-convolutions-ed5520775ab4&newsletterV3=f4c07943b642&newsletterV3Id=d59b7e8b1294&user=Chu-Tak+Li&userId=f4c07943b642&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}