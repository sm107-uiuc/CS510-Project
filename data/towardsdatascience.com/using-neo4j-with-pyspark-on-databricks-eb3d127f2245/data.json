{"url": "https://towardsdatascience.com/using-neo4j-with-pyspark-on-databricks-eb3d127f2245", "time": 1683016554.1960351, "path": "towardsdatascience.com/using-neo4j-with-pyspark-on-databricks-eb3d127f2245/", "webpage": {"metadata": {"title": "Using Neo4j with PySpark on Databricks | by Lukas B\u00f6hres | Towards Data Science", "h1": "Using Neo4j with PySpark on Databricks", "description": "With the recent release of the official Neo4j Connector for Apache Spark leveraging the Spark DataSource API, there has been a fundamental change in the way that Neo4j data can be queried from within\u2026"}, "outgoing_paragraph_urls": [{"url": "https://neo4j.com/blog/announcing-neo4j-connector-for-apache-spark/", "anchor_text": "recent release of the official Neo4j Connector for Apache Spark", "paragraph_index": 0}, {"url": "https://neo4j.com/developer/apache-spark/", "anchor_text": "previous Neo4j Spark Connector was marked as deprecated", "paragraph_index": 0}, {"url": "https://azure.microsoft.com/en-us/services/databricks/", "anchor_text": "Azure Databricks", "paragraph_index": 1}, {"url": "https://github.com/neo4j-contrib/neo4j-spark-connector", "anchor_text": "Neo4j Connector for Apache Spark", "paragraph_index": 1}, {"url": "https://bitnami.com/stacks/containers", "anchor_text": "Bitnami", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Bolt_(network_protocol)", "anchor_text": "Bolt port", "paragraph_index": 4}, {"url": "https://neo4j.com/developer/cypher/", "anchor_text": "the Cypher query language", "paragraph_index": 8}, {"url": "https://neo4j.com/developer/spark/overview/", "anchor_text": "Neo4j does not support a connector for Spark 3.0", "paragraph_index": 11}, {"url": "https://docs.databricks.com/notebooks/notebooks-use.html#mix-languages", "anchor_text": "magic command", "paragraph_index": 26}, {"url": "https://neo4j.com/developer/spark/overview/", "anchor_text": "Neo4j Connector for Apache Spark documentation", "paragraph_index": 30}, {"url": "https://neo4j.com/developer/spark/reading/", "anchor_text": "reading", "paragraph_index": 30}, {"url": "https://neo4j.com/developer/spark/writing/", "anchor_text": "writing", "paragraph_index": 30}, {"url": "https://github.com/utnaf/neo4j-connector-apache-spark-notebooks", "anchor_text": "Zeppelin notebook example repository", "paragraph_index": 30}, {"url": "https://neo4j.com/developer/cypher/", "anchor_text": "official Cypher page", "paragraph_index": 30}], "all_paragraphs": ["With the recent release of the official Neo4j Connector for Apache Spark leveraging the Spark DataSource API, there has been a fundamental change in the way that Neo4j data can be queried from within an Apache Spark environment. Alongside this change, the previous Neo4j Spark Connector was marked as deprecated. In this article, I\u2019d like to share an updated end-to-end workflow of setting up a fully interconnected pairing of Neo4j and Spark that makes use of the new connector\u2019s capabilities.", "In the process, we will first set up a Neo4j cloud instance using an Azure virtual machine. Afterwards, we will set up an Azure Databricks instance running Spark before finally establishing a connection between both resources using the new Neo4j Connector for Apache Spark. If you already have an up-and-running instance of Neo4j or Databricks, you might of course want to skip the respective steps. However, please note the compatibility information at the top of each step.", "First, a quick word on compatibility: The connector we are going to use supports Neo4j versions 3.5 and above. Versions prior to 3.5 are not supported. It does however support both Neo4j Enterprise and Community as well as single instance VMs, Causal Clusters and Neo4j Aura. This article is going to focus on the workflow for a single instance VM.", "As our Neo4j instance, we will use the official Neo4j Enterprise VM image. The latest version is listed as Neo4j Enterprise VM version 4.1 in the Azure marketplace. If you don\u2019t have an Enterprise license, there are images of the Community version offered by Websoft9 as well as Container Images by Bitnami:", "After the VM is deployed, navigate to it\u2019s Networking tab to make sure that its port settings are correct: In order to query it from Spark, a Bolt port must allow inbound traffic. By default, this is port 7687. Additionally, we will use the Neo4j Web interface to populate the database, for which we need an open HTTP or HTTPS port. By default, they are mapped to port numbers 7474 and 7473. If any of these port rules are missing, add them by clicking the Add Inbound Port Rule button.", "Once you verified the port settings, grab the VM\u2019s public IP from its Overview tab and connect to it via HTTP by navigating to http://YOUR.VM.IP.ADDRESS:7474 in your browser. With a freshly started VM, it might take a few minutes before Neo4j has started up and accepts inbound connections. If you use VPN or Proxies, make sure they are configured accordingly, otherwise you might receive a \u201cThis site can\u2019t be reached\u201d error.", "If all settings are correct, the Neo4j Browser Web UI will pop up:", "You will be prompted for login credentials. Enter the default username and password to log in to your database:", "On your first access, you will immediately have to change the default password for security reasons. After choosing a solid password and logging in, you can populate the database. In this guide, we will use the Cypher query language to create a simple dummy dataset by typing the following into the command line:", "As a result, a data structure similar to the following will be created, where each Person node is tagged with an ID and each KNOWS relation has an additional (arbitrary) attribute years that describes how long the two parties have known each other:", "That\u2019s it! Our Neo4j graph database is up and running and can\u2019t wait to be queried from Spark. We will now move on to setting up an appropriate Spark environment.", "Again, an important note on compatibility: At the time of writing, Neo4j does not support a connector for Spark 3.0. As such, we will have to fall back to a Spark 2.4 environment in order to communicate with Neo4j.", "For our setup, we will use an Azure Databricks instance. Search for databricks on the Azure marketplace and create a new resource. Apart from the usual settings (resource group, name, location and pricing tier), no special configuration settings are required.", "Once deployed, open up your Databricks workspace by navigating to your Azure resource\u2019s overview tab and clicking the Launch Workspace button.", "First, we will need a cluster to work with. Navigate to the Clusters tab and click the Create Cluster button to display the cluster configuration tool:", "Choose a cluster name and availability mode and configure the size and amount of worker nodes to your liking. Now, remember that we are forced to use a Spark 2 setup \u2014 luckily, Databricks still offers a variety of Spark 2.4.5 distributions. Make sure to select one of them in the Databricks Runtime Version field, e.g. Runtime Version 6.6 running Spark 2.4.5 and Scala 2.11.", "Start your cluster and you\u2019re good to go!", "Since we now have both Neo4j and Databricks up and running, it\u2019s time to focus on the connection between them. In order to do so, we will need to add the Neo4j Connector for Apache Spark to our Databricks cluster.", "In Databricks, navigate to the cluster tab. Select the previously created cluster and access its libraries options:", "Now, add the Neo4j Connector for Apache Spark by clicking the Install New button, select Maven and clicking Search Packages. Type \u2018neo4j\u2019 to see all available options. At the time of writing, there are three packages coming up in the search:", "According to the developers, the split in two separate connectors is necessary due to API differences:", "Because of the differences in the APIs, different JAR files are needed depending on your scala version. Ensure that you have the appropriate JAR file for your environment.", "After the connector is installed, create a new Jupyter notebook in the Workspace tab (right click \u2192 Create New). Try reading the node data of your Neo4j database by running the following command after inserting your Neo4j VM\u2019s IP, username and password:", "In case you receive an Unable to connect error, make sure your Neo4j VM is still running and its Bolt port accepts inbound traffic. If the query returns", "you most likely installed the connector for the wrong Scala version \u2014 make sure you select the Scala 2.11 version (see above).", "If all worked out, the query will return a DataFrame similar to this:", "As an alternative to Python, you can also use Scala for your queries by adding the %scala magic command at the top of your Notebook cells:", "Writing to your Graph Database works similar in a similar way. In the following query, we will update our original data to include names for the first two nodes:", "Note that we use the \u201cOverwrite\u201d mode along with setting the node.keys option to the DataFrame\u2019s id column in order to append the new values to our existing nodes. In fact, running the read query again returns our previous result updated with a name property for the first two nodes:", "And that\u2019s it! \ud83c\udf89 You have successfully set up a fully cloud-based and interconnected pair of Apache Spark and Neo4j, allowing you to leverage the full potential of \u201ctraditional\u201d Big Data and Graph Databases working hand in hand.", "For more query examples and syntax overview, take a deep dive into the official Neo4j Connector for Apache Spark documentation or check the quick guides on reading and writing from/to Neo4j. Additional examples can be found in the Zeppelin notebook example repository. The connector also supports Cypher queries, allowing you to re-use existing queries from Neo4j Desktop / Web applications. Examples for Cypher queries can be found on the official Cypher page.", "Data Science Consultant & Tech Fan based in Germany \ud83d\udc31\u200d\ud83d\udc64"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Feb3d127f2245&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/making-sense-of-big-data", "anchor_text": "Making Sense of Big Data"}, {"url": "https://medium.com/@lukas.boehres?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@lukas.boehres?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Lukas B\u00f6hres"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51b4e53db6c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=post_page-51b4e53db6c7----eb3d127f2245---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feb3d127f2245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=-----eb3d127f2245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feb3d127f2245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&source=-----eb3d127f2245---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@fernanddecanne", "anchor_text": "Fernand De Canne"}, {"url": "https://unsplash.com/?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://neo4j.com/blog/announcing-neo4j-connector-for-apache-spark/", "anchor_text": "recent release of the official Neo4j Connector for Apache Spark"}, {"url": "https://neo4j.com/developer/apache-spark/", "anchor_text": "previous Neo4j Spark Connector was marked as deprecated"}, {"url": "https://azure.microsoft.com/en-us/services/databricks/", "anchor_text": "Azure Databricks"}, {"url": "https://github.com/neo4j-contrib/neo4j-spark-connector", "anchor_text": "Neo4j Connector for Apache Spark"}, {"url": "https://bitnami.com/stacks/containers", "anchor_text": "Bitnami"}, {"url": "https://en.wikipedia.org/wiki/Bolt_(network_protocol)", "anchor_text": "Bolt port"}, {"url": "https://neo4j.com/developer/cypher/", "anchor_text": "the Cypher query language"}, {"url": "https://neo4j.com/developer/spark/overview/", "anchor_text": "Neo4j does not support a connector for Spark 3.0"}, {"url": "https://neo4j.com/developer/apache-spark/", "anchor_text": "deprecated connector version (2.4)"}, {"url": "https://docs.databricks.com/notebooks/notebooks-use.html#mix-languages", "anchor_text": "magic command"}, {"url": "https://neo4j.com/developer/spark/overview/", "anchor_text": "Neo4j Connector for Apache Spark documentation"}, {"url": "https://neo4j.com/developer/spark/reading/", "anchor_text": "reading"}, {"url": "https://neo4j.com/developer/spark/writing/", "anchor_text": "writing"}, {"url": "https://github.com/utnaf/neo4j-connector-apache-spark-notebooks", "anchor_text": "Zeppelin notebook example repository"}, {"url": "https://neo4j.com/developer/cypher/", "anchor_text": "official Cypher page"}, {"url": "https://medium.com/tag/spark?source=post_page-----eb3d127f2245---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/databricks?source=post_page-----eb3d127f2245---------------databricks-----------------", "anchor_text": "Databricks"}, {"url": "https://medium.com/tag/neo4j-spark-connector?source=post_page-----eb3d127f2245---------------neo4j_spark_connector-----------------", "anchor_text": "Neo4j Spark Connector"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----eb3d127f2245---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/making-sense-of-big-data?source=post_page-----eb3d127f2245---------------making_sense_of_big_data-----------------", "anchor_text": "Making Sense Of Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feb3d127f2245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=-----eb3d127f2245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feb3d127f2245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=-----eb3d127f2245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feb3d127f2245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@lukas.boehres?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51b4e53db6c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=post_page-51b4e53db6c7----eb3d127f2245---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F51b4e53db6c7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=-----eb3d127f2245---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@lukas.boehres?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Written by Lukas B\u00f6hres"}, {"url": "https://medium.com/@lukas.boehres/followers?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "18 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51b4e53db6c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=post_page-51b4e53db6c7----eb3d127f2245---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F51b4e53db6c7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-neo4j-with-pyspark-on-databricks-eb3d127f2245&user=Lukas+B%C3%B6hres&userId=51b4e53db6c7&source=-----eb3d127f2245---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----eb3d127f2245----0---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----eb3d127f2245----0---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----eb3d127f2245----0---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----eb3d127f2245----0---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----eb3d127f2245----0---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----eb3d127f2245----0---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----0-----------------clap_footer----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----eb3d127f2245----0---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----eb3d127f2245----0-----------------bookmark_preview----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----eb3d127f2245----1---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----eb3d127f2245----1---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----eb3d127f2245----1---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----eb3d127f2245----1---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----eb3d127f2245----1---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----eb3d127f2245----1---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----1-----------------clap_footer----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----eb3d127f2245----1---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----eb3d127f2245----1-----------------bookmark_preview----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----eb3d127f2245----2---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----eb3d127f2245----2---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----eb3d127f2245----2---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----eb3d127f2245----2---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----eb3d127f2245----2---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----eb3d127f2245----2---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----eb3d127f2245----2---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----eb3d127f2245----2-----------------bookmark_preview----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----eb3d127f2245----3---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=author_recirc-----eb3d127f2245----3---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=author_recirc-----eb3d127f2245----3---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Nikos Kafritsas"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----eb3d127f2245----3---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----eb3d127f2245----3---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "Time-Series Forecasting: Deep Learning vs Statistics \u2014 Who Wins?A comprehensive guide on the ultimate dilemma"}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----eb3d127f2245----3---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": "\u00b714 min read\u00b7Apr 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc568389d02df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df&user=Nikos+Kafritsas&userId=bec849d9e1d2&source=-----c568389d02df----3-----------------clap_footer----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df?source=author_recirc-----eb3d127f2245----3---------------------ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc568389d02df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df&source=-----eb3d127f2245----3-----------------bookmark_preview----ce96c0b1_b6c3_44e0_a6c0_984006c26b8a-------", "anchor_text": ""}, {"url": "https://medium.com/@lukas.boehres?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "See all from Lukas B\u00f6hres"}, {"url": "https://towardsdatascience.com/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://medium.com/@lgsoliveira?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://medium.com/@lgsoliveira?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Lu\u00eds Oliveira"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "How to Run Spark With DockerTutorial with Pyspak"}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "\u00b76 min read\u00b7Dec 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fc6287a11a437&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-to-run-spark-with-docker-c6287a11a437&user=Lu%C3%ADs+Oliveira&userId=6bd0a8d7aa96&source=-----c6287a11a437----0-----------------clap_footer----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/how-to-run-spark-with-docker-c6287a11a437?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc6287a11a437&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-to-run-spark-with-docker-c6287a11a437&source=-----eb3d127f2245----0-----------------bookmark_preview----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Yifeng Jiang"}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Build an Open Data Lakehouse with Spark, Delta and Trino on S3Combining the strength of data lake and warehouse in a way that is open, simple, and runs anywhere"}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "\u00b76 min read\u00b7Nov 7, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fbd60521a12dd&operation=register&redirect=https%3A%2F%2Fuprush.medium.com%2Fbuild-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd&user=Yifeng+Jiang&userId=98df5da871eb&source=-----bd60521a12dd----1-----------------clap_footer----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd60521a12dd&operation=register&redirect=https%3A%2F%2Fuprush.medium.com%2Fbuild-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd&source=-----eb3d127f2245----1-----------------bookmark_preview----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Josue Luzardo Gebrim"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Data Quality in Python Pipelines!Discover What It Is And How To Achieve Data Quality In Your Data Streams!"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "\u00b714 min read\u00b7Mar 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&user=Josue+Luzardo+Gebrim&userId=9f59dfc0edf7&source=-----4ad1e8eb6603----0-----------------clap_footer----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----eb3d127f2245----0---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&source=-----eb3d127f2245----0-----------------bookmark_preview----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/incremental-data-load-using-auto-loader-and-merge-function-in-databricks-184bb054cbc3?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://iamstevegeorge.medium.com/?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://iamstevegeorge.medium.com/?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Steve George"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/incremental-data-load-using-auto-loader-and-merge-function-in-databricks-184bb054cbc3?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Incremental Data load using Auto Loader and Merge function in DatabricksData loading is a term that we come across often while performing ETL operation. This article would focus on incremental data load using\u2026"}, {"url": "https://medium.datadriveninvestor.com/incremental-data-load-using-auto-loader-and-merge-function-in-databricks-184bb054cbc3?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "\u00b76 min read\u00b7Jan 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F184bb054cbc3&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fincremental-data-load-using-auto-loader-and-merge-function-in-databricks-184bb054cbc3&user=Steve+George&userId=73955688ba37&source=-----184bb054cbc3----1-----------------clap_footer----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/incremental-data-load-using-auto-loader-and-merge-function-in-databricks-184bb054cbc3?source=read_next_recirc-----eb3d127f2245----1---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F184bb054cbc3&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fincremental-data-load-using-auto-loader-and-merge-function-in-databricks-184bb054cbc3&source=-----eb3d127f2245----1-----------------bookmark_preview----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----eb3d127f2245----2---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----eb3d127f2245----2---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----eb3d127f2245----2---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Pier Paolo Ippolito"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----eb3d127f2245----2---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----eb3d127f2245----2---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Apache Spark Optimization TechniquesA review of some of the most common Spark performance problems and how to address them"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----eb3d127f2245----2---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=-----fa7f20a9a2cf----2-----------------clap_footer----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----eb3d127f2245----2---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&source=-----eb3d127f2245----2-----------------bookmark_preview----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----eb3d127f2245----3---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----eb3d127f2245----3---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----eb3d127f2245----3---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----eb3d127f2245----3---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----eb3d127f2245----3---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----eb3d127f2245----3---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----3-----------------clap_footer----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----eb3d127f2245----3---------------------b4224035_3f9e_4945_8c72_8d64d70cc8ce-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----eb3d127f2245----3-----------------bookmark_preview----b4224035_3f9e_4945_8c72_8d64d70cc8ce-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----eb3d127f2245--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}