{"url": "https://towardsdatascience.com/generate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e", "time": 1682995506.979316, "path": "towardsdatascience.com/generate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e/", "webpage": {"metadata": {"title": "Generate Piano Instrumental Music by Using Deep Learning | by Haryo Akbarianto Wibowo | Towards Data Science", "h1": "Generate Piano Instrumental Music by Using Deep Learning", "description": "Hello everyone! Finally, I can write again on my Medium and have free time to do some experiments on Artificial Intelligence (AI). This time, I am going to write and share about how to generate music\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/generating-indonesian-lyric-using-deep-learning-first-part-2c7634237475", "anchor_text": "previous article about generating lyrics", "paragraph_index": 0}, {"url": "https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf", "anchor_text": "realistic face generator by using GAN", "paragraph_index": 5}, {"url": "https://magenta.tensorflow.org/research", "anchor_text": "GAN", "paragraph_index": 5}, {"url": "https://medium.com/tensorflow/effective-tensorflow-2-0-best-practices-and-whats-changed-a0ca48767aff", "anchor_text": "best practice", "paragraph_index": 8}, {"url": "http://jalammar.github.io/illustrated-transformer/", "anchor_text": "this awesome article", "paragraph_index": 10}, {"url": "https://magenta.tensorflow.org/datasets/maestro", "anchor_text": "dataset", "paragraph_index": 12}, {"url": "https://www.pcmag.com/encyclopedia/term/47014/midi", "anchor_text": "pcmag", "paragraph_index": 16}, {"url": "https://github.com/craffel/pretty-midi", "anchor_text": "pretty_midi", "paragraph_index": 19}, {"url": "https://github.com/CyberZHG/keras-self-attention", "anchor_text": "this", "paragraph_index": 43}], "all_paragraphs": ["Hello everyone! Finally, I can write again on my Medium and have free time to do some experiments on Artificial Intelligence (AI). This time, I am going to write and share about how to generate music notes by using Deep Learning. Unlike my previous article about generating lyrics, this time we will generate the notes of the musics and also generate the file (in MIDI format).", "The theme of the music is Piano. This article will generate piano notes by using a variant of Recurrent Neural Network (RNN), Gated Recurrent Unit (GRU) with the help of Self Attention. Not only this article will tell how to generate the notes, this article will also tell how to generate it into a proper MIDI files and can also be played in the computer.", "This article is targeted for the one who is interested in AI, especially who want to practice on using Deep Learning. I hope that my writing skill will increase by publishing this article and the content benefits you \ud83d\ude03.", "There is a Github link at the end of this article if you want to know about the complete source code. For now, I will give the python notebook and the Colaboratory link in the repository,.", "(That music is generated by the model that we will create in this article)", "One of the current hot topic in the Artificial Intelligence is how to generate something by only using the data (unsupervised). In Computer Vision domain, there are many researchers out there researching some advanced techniques on generating images using Generative Advesarial Network (GAN). For example NVIDIA create realistic face generator by using GAN. There are also some research on generating music by using GAN.", "If we talk about the value of the music generator, it can be used to help the musician on creating their music. It can enhance the creativity of people. I think in the future, if there are a lot of high attention on this field, most of musicians will create its music assisted by AI.", "This article will be focused on how to generate music by generating sequential of notes in a music. We will know how to preprocess the data and transform them to be input of neural network to generate the music.", "The experiment will also use Tensorflow v2.0 (still on alpha phase) as the Deep Learning Framework. What I want to show is to test and use Tensorflow v2.0 by following some of their best practice. One of the feature that I like in Tensorflow v2.0 is that it really accelerates the training of the model by using their AutoGraph. It can be used by defining our function using @tf.function. Moreover, there are no \u201ctf.session\u201d anymore and no global initialization. These efeatures are one of the reason that I moved from Tensorflow to PyTorch. Tensorflow usability was not good for me. Nevertheless, In my opinion Tensorflow v2.0 change it all and increase their usability to make it comfortable to do some experiment.", "This experiment also use self-attention layer . The self-attention layer will tell us, given a sequential instance (for example in the music note \u201c C D E F G\u201d), each token will learn how much the influence on other token to that token. Here\u2019s some example (for an NLP task):", "For further information about self-attention, especially about transformer, you can see this awesome article.", "Without any further ado, let\u2019s go on generating the music", "For the Data, we use MAESTRO (MIDI and Audio Edited for Synchronous TRacks and Organization) from Magenta as the dataset. This dataset only contains piano instruments. We will take 100 musics randomly from around 1000 musics to make our training time faster.", "Here is the pipeline on how our music generator will works:", "We will see each of the process. To make it simpler, we will divide each of the processes as follow:", "Before we go into how to preprocess the midi files, we need to know what Midi format file is.", "From pcmag , the definition of MIDI:", "(Musical Instrument Digital Interface) A standard protocol for the interchange of musical information between musical instruments, synthesizers and computers. MIDI was developed to allow the keyboard of one synthesizer to play notes generated by another. It defines codes for musical notes as well as button, dial and pedal adjustments, and MIDI control messages can orchestrate a series of synthesizers, each playing a part of the musical score. MIDI Version 1.0 was introduced in 1983.", "In summary, MIDI files contains a series of instruments which has notes in it. For example the combination of Piano and Guitar. Each of music instruments usually have different notes to play.", "For preprocess the MIDI files, there are some libraries that can be used to do it in Python. One of them is pretty_midi. It can manipulate MIDI files and also create a new one. In this article, we will use that library.", "For pretty_midi the format of midi files is as follow:", "Start is the start of a note played in second. End is the end of a note played in a second. There can be a overlap multi notes in a time. Pitch is the MIDI number of the Note played. Velocity is the force which the note is played.", "For the reference of the relation between MIDI number and note name, you can see the picture below:", "We will read midi files in a batch. This is how we read it using pretty_midi :", "We will get the PrettyMidi object.", "For this article, we need to extract all the notes of the music from an instrument. Many MIDI files have multiple instruments in their music. In our dataset, the MIDI files only contains one instrument, which is Piano. We will extract the notes from the piano instruments. To make it easier, we will extract the notes for desired frame per second. pretty_midi has a handy function get_piano_roll to get the notes in binary 2D numpy.array in (notes, time) dimension array. The notes length is 128 and time follow the duration of the music divided by FPS.", "The source code how we do it:", "After we get the array of piano roll, we convert them into dictionary. The dictionary will start from the time where the note is played. For example, in the picture above, we start from 28 (If we convert to second, assume we convert to piano_roll at 5 fps, the music start playing its notes at 5.6 s which we can get by 28 divided by 5).", "After we create the dictionary, we will convert the values of the dictionary into string. For example:", "To do it, we should loop all the keys of the dictionary and change its value:", "After we get the dictionary, we will convert it into sequential of notes which will be used to be input of neural network. Then we get the next timestep to be the target of the input of neural network.", "In this article, the length of the sequence list is 50. That means that if our fps is 5, we will get a sequence that contains 10 (50 / 5) seconds playtime.", "\u2018e\u2019 in the list means that there are no notes are played in that time. Since there are time where there is a jump or no notes are played between each played notes. In the example in Image 7, we can see that there is a jump from 43 to 46. If we convert that sequence, The list of sequence would be:", "How we do it ? We will process the note in a batch of musics.", "We use a 50 length sliding window. For the first note in a music, we will append \u2018e\u2019 to the list 49 times. Then set the start time to the first timestep in the dictionary. In the example in Image 7, it is 28. Then we append the first note in that music (In the example \u201877\u2019).", "Then for the next instance, we slide the window by one and append \u2018e\u2019 to the list 48 times and append the note played in timestep 28 and append the note in timestep 29 and repeat until the end of the music.", "For the next music, we repeat the process above.", "Before we dive into the neural network, we must create the tokenizer to change the sequential notes into sequential index of the notes. First we should map the note into an index representing the id of the note.", "So if our previous input is as below:", "This is how we do it.", "To summarize our Preprocessing function, here are functions that we will use:", "Before we get to know how to train with the new feature of Tensorflow v2.0, we will see the architecture as follow:", "So, the Deep Learning architecture will use 3 layers of Gated Recurrent Unit (GRU, a variant of Recurrent Neural Network) and some Self Attention Layers. The dropout is used so that the neural network will not overfit so fast.", "For the Self Attention Layers, we will use this repository and edit it a little so that we can use it on Tensorflow v2.0.", "We will update the weight of the model by iterating a number of musics in the dataset and preprocess the data as stated above. Then we take a number of instances in a batch to be input and the target of the neural network.", "We will use GradientTape on updating the weight of the neural network. First we compute the loss and apply the back propagation using apply_gradients on it. If you are familiar on using PyTorch, this is how Pytorch works on training its neural network model.", "Be sure to use @tf.function on the function. This will convert the function into autograph and make our training faster. One of the downside of tf.function cannot use different size of batches as the input of neural network. For example, our batch size is 64. If the size of datasets is 70, the last batch will contains 6 instances. This will throw exception to the program as the graph will have an input with different size from the initial graph. Maybe it works by creating placeholders by seeing the first input when using the function.", "In this article, we will use 16 BATCH_SONG andd 96 BATCH_NNET_SIZE. That means we will take 16 musics from the list of all musics, then extract its sequence. Then for every step in the neural network, we take 96 sequences from the extracted sequence instances to be input and target of neural network.", "There are two ways on generating a MIDI file using our trained neural network model:", "We need to choose at the start:", "After we choose the seed of our music generator, we predict the next note based on the 50 random notes using our trained model. We use the predicted value as the probability distribution on how to choose the note randomly. We do it until the designated maximum sequences length that we want. Then we drop the first 50 notes.", "After we generate a list sequence of notes, we will convert it again to piano roll array. Then transform it into the PrettyMidi object.", "After that, we tweak the velocity and tempo of the music and finally we generate the MIDI file.", "This is how to write the midi files from the generated notes:", "When I did it, the training took 1 hour for 1 epoch. When I did it, I decided to run the training for 4 epochs (4 hours).", "From the model that have been trained for 4 epochs, here are the results:", "( Note that these are the mp3 file converted from MIDI files. I use online converter to do it. The notes seems a bit miss from the original. I will upload the original MIDI in the repository if you want to hear it. )", "There is a visible difference between these generated notes. If we generate it from a note, it will have a slow tempo start on playing the notes . It is different from when we generate it from a 50 random notes. It does not have a slow start.", "This is the visualization of the self attention block on last sequence of the music on choosing start with random 50 notes:", "As you can see, the first self attention block learn what note to focus for every note in a sequence instances. Yet, there are no result on what to focus in the second attention block. We can also tell that if the others note\u2019s position is very far from the current note, it will not focus to it (The black color in the Image 12 and Image 13).", "We have built a tool to generate musics with MAESTRO dataset that contains piano music. We preprocess it, train our neural network model, then generate the music with it. The musics are in MIDI format. We use Tensorflow v2.0 to do it. I think Tensorflow v2.0 User Experience (UX) is better than its previous version.", "The music generated by our model is also coherent and good to hear. It can adjust how it play its notes. For example : When the generator From a note (means it is a start of the music), it start with a slow tempo start.", "There are some things that we can try for the music generator. In this article, we have experimented on generating a single instrument. What if the music have multiple instruments? There need to be a better architecture to do it. There are multiple things that we can try on experimenting music data.", "That\u2019s it for this article about generating piano music notes. Actually, I got inspired to write this by looking my first article about Deep Learning, which is generating music\u2019s lyric. \u201cHow about generate the music notes?\u201d. I experiment it and well\u2026 it works.", "There are some struggle for me to experiment this. First, I need to search what file format that is easy to preprocess and to be input of neural network. I found that MIDI is easy and have small size of file. Then, I need to know are there any libraries that can preprocess the file in Python. I found two, there are music21 and pretty_midi where their repository is not outdated. I choose pretty_midi. Maybe because it has \u2018pretty\u2019 in its name \ud83d\ude1d. Finally, I need to think how to preprocess the note. Thankfully, pretty_midi has a handy function get_piano_roll to make it easier.", "I also haven\u2019t read many research papers about music. Maybe there are research papers that can be reproduced and visible to be done in Colaboratory.", "I\u2019m sorry for the lack of the visualization on the Self Attention Layer.", "I welcome any feedback that can improve myself and this article. I\u2019m in the process of learning on writing and learning about Deep Learning. I apreciate a feedback to make me become better. Make sure to give feedback in a proper manner \ud83d\ude04.", "See ya in my next article!", "Note names, MIDI numbers and frequenciesnewt.phys.unsw.edu.au", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Mad AI Enthusiast. I write mostly about Artificial Intelligence and Self Development. I also love to read Engineering, Psychology and Startup. Love to share!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F80ac35cdbd2e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://haryoaw.medium.com/?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "Haryo Akbarianto Wibowo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d82e5d56c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=post_page-6d82e5d56c2----80ac35cdbd2e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F80ac35cdbd2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F80ac35cdbd2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@marius?utm_source=medium&utm_medium=referral", "anchor_text": "Marius Masalar"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/generating-indonesian-lyric-using-deep-learning-first-part-2c7634237475", "anchor_text": "previous article about generating lyrics"}, {"url": "https://unsplash.com/@maltewingen?utm_source=medium&utm_medium=referral", "anchor_text": "Malte Wingen"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf", "anchor_text": "realistic face generator by using GAN"}, {"url": "https://magenta.tensorflow.org/research", "anchor_text": "GAN"}, {"url": "https://unsplash.com/@akshar_dave?utm_source=medium&utm_medium=referral", "anchor_text": "Akshar Dave"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tensorflow/effective-tensorflow-2-0-best-practices-and-whats-changed-a0ca48767aff", "anchor_text": "best practice"}, {"url": "http://jalammar.github.io/illustrated-transformer/", "anchor_text": "http://jalammar.github.io/illustrated-transformer/"}, {"url": "http://jalammar.github.io/illustrated-transformer/", "anchor_text": "this awesome article"}, {"url": "https://magenta.tensorflow.org/datasets/maestro", "anchor_text": "dataset"}, {"url": "https://www.pcmag.com/encyclopedia/term/47014/midi", "anchor_text": "pcmag"}, {"url": "https://github.com/craffel/pretty-midi", "anchor_text": "pretty_midi"}, {"url": "https://newt.phys.unsw.edu.au/jw/notes.html", "anchor_text": "https://newt.phys.unsw.edu.au/jw/notes.html"}, {"url": "https://towardsdatascience.com/generating-drake-rap-lyrics-using-language-models-and-lstms-8725d71b1b12", "anchor_text": "https://towardsdatascience.com/generating-drake-rap-lyrics-using-language-models-and-lstms-8725d71b1b12"}, {"url": "https://github.com/CyberZHG/keras-self-attention", "anchor_text": "this"}, {"url": "https://unsplash.com/@chzenan?utm_source=medium&utm_medium=referral", "anchor_text": "Alan Chen"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://cdn.pixabay.com/photo/2017/07/10/16/07/thank-you-2490552_1280.png", "anchor_text": "https://cdn.pixabay.com/photo/2017/07/10/16/07/thank-you-2490552_1280.png"}, {"url": "https://github.com/haryoa/note_music_generator", "anchor_text": "haryoa/note_music_generatorContribute to haryoa/note_music_generator development by creating an account on GitHub.github.com"}, {"url": "https://www.pcmag.com/encyclopedia/term/47014/midi", "anchor_text": "Encyclopedia( Musical Instrument Digital I nterface) A standard protocol for the interchange of musical information between musical\u2026www.pcmag.com"}, {"url": "https://newt.phys.unsw.edu.au/jw/notes.html", "anchor_text": "Note names, MIDI numbers and frequenciesNote names, MIDI numbers and frequenciesNote names, MIDI numbers and frequenciesnewt.phys.unsw.edu.au"}, {"url": "http://jalammar.github.io/illustrated-transformer/", "anchor_text": "The Illustrated TransformerIn the previous post, we looked at Attention - a ubiquitous method in modern deep learning models. Attention is a\u2026jalammar.github.io"}, {"url": "https://github.com/Skuldur/Classical-Piano-Composer", "anchor_text": "Skuldur/Classical-Piano-ComposerContribute to Skuldur/Classical-Piano-Composer development by creating an account on GitHub.github.com"}, {"url": "https://magenta.tensorflow.org/", "anchor_text": "MagentaA research project exploring the role of machine learning in the process of creating art and music.magenta.tensorflow.org"}, {"url": "https://cs224d.stanford.edu/reports/allenh.pdf", "anchor_text": "https://cs224d.stanford.edu/reports/allenh.pdf"}, {"url": "https://www.tensorflow.org/alpha/guide/effective_tf2", "anchor_text": "Effective TensorFlow 2.0 | TensorFlow | TensorFlowA common usage pattern in TensorFlow 1.X was the \"kitchen sink\" strategy, where the union of all possible computations\u2026www.tensorflow.org"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----80ac35cdbd2e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----80ac35cdbd2e---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----80ac35cdbd2e---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----80ac35cdbd2e---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----80ac35cdbd2e---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F80ac35cdbd2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----80ac35cdbd2e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F80ac35cdbd2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----80ac35cdbd2e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F80ac35cdbd2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F80ac35cdbd2e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----80ac35cdbd2e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----80ac35cdbd2e--------------------------------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Haryo Akbarianto Wibowo"}, {"url": "https://haryoaw.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "407 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d82e5d56c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=post_page-6d82e5d56c2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8ef926c2bc14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e&newsletterV3=6d82e5d56c2&newsletterV3Id=8ef926c2bc14&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}