{"url": "https://towardsdatascience.com/5-significant-object-detection-challenges-and-solutions-924cb09de9dd", "time": 1683000535.676032, "path": "towardsdatascience.com/5-significant-object-detection-challenges-and-solutions-924cb09de9dd/", "webpage": {"metadata": {"title": "5 Significant Object Detection Challenges and Solutions | by Kimberly Fessel | Towards Data Science", "h1": "5 Significant Object Detection Challenges and Solutions", "description": "The field of computer vision has experienced substantial progress recently, owing largely to advances in deep learning, specifically convolutional neural nets (CNNs). Image classification, where a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://cloud.google.com/vision/docs/drag-and-drop", "anchor_text": "Google", "paragraph_index": 1}, {"url": "https://www.ibm.com/watson/services/visual-recognition/", "anchor_text": "IBM", "paragraph_index": 1}, {"url": "https://www.quora.com/What-are-some-interesting-applications-of-object-detection", "anchor_text": "many different fields", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework", "anchor_text": "Viola and Jones", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1708.02002", "anchor_text": "RetinaNet", "paragraph_index": 2}, {"url": "https://www.thisismetis.com/blog/a-beginners-guide-to-object-detection", "anchor_text": "A Beginner\u2019s Guide to Object Detection", "paragraph_index": 2}, {"url": "https://arxiv.org/pdf/1504.08083.pdf", "anchor_text": "Fast R-CNN", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1311.2524.pdf", "anchor_text": "R-CNN", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1504.08083.pdf", "anchor_text": "Fast R-CNN", "paragraph_index": 7}, {"url": "https://arxiv.org/pdf/1506.01497.pdf", "anchor_text": "Faster R-CNN", "paragraph_index": 7}, {"url": "https://koen.me/research/pub/uijlings-ijcv2013-draft.pdf", "anchor_text": "selective search", "paragraph_index": 7}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf", "anchor_text": "YOLO", "paragraph_index": 8}, {"url": "https://arxiv.org/pdf/1804.02767.pdf", "anchor_text": "YOLOv3", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1612.03144.pdf", "anchor_text": "feature pyramid network (FPN)", "paragraph_index": 13}, {"url": "https://arxiv.org/pdf/1804.02767.pdf", "anchor_text": "its 3rd version", "paragraph_index": 13}, {"url": "https://github.com/pjreddie/darknet/blob/master/data/coco.names", "anchor_text": "80 different categories", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/1612.08242.pdf", "anchor_text": "second version of YOLO", "paragraph_index": 16}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet", "paragraph_index": 16}, {"url": "https://arxiv.org/abs/1708.02002", "anchor_text": "RetinaNet", "paragraph_index": 18}, {"url": "https://arxiv.org/pdf/1311.2524.pdf", "anchor_text": "Rich feature hierarchies for accurate object detection and semantic segmentation", "paragraph_index": 22}, {"url": "https://arxiv.org/pdf/1506.01497.pdf", "anchor_text": "Faster r-cnn: Towards real-time object detection with region proposal networks.", "paragraph_index": 23}, {"url": "https://arxiv.org/abs/1612.03144", "anchor_text": "Feature pyramid networks for object detection", "paragraph_index": 24}], "all_paragraphs": ["The field of computer vision has experienced substantial progress recently, owing largely to advances in deep learning, specifically convolutional neural nets (CNNs). Image classification, where a computer classifies or assigns labels to an image based on its content, can often see great results simply by leveraging pre-trained neural nets and fine-tuning the last few throughput layers.", "Classifying and finding an unknown number of individual objects within an image, however, was considered an extremely difficult problem only a few years ago. This task, called object detection, is now feasible and has even been productized by companies like Google and IBM. But all of this progress wasn\u2019t easy! Object detection presents many sizable challenges beyond what is required for image classification. After a brief introduction to the topic, let\u2019s take a deep dive into several of the interesting obstacles these problems pose along with various emerging solutions.", "The ultimate purpose of object detection is to locate important items, draw rectangular bounding boxes around them, and determine the class of each item discovered. Applications of object detection arise in many different fields including detecting pedestrians for self-driving cars, monitoring agricultural crops, and even real-time ball tracking for sports. Researchers have dedicated a substantial amount of work towards this goal over the years: from Viola and Jones\u2019s facial detection algorithm published in 2001 to RetinaNet, a fast, highly accurate one-state detection framework released in 2017. The introduction of CNNs marks a pivotal moment in object detection history, as nearly all modern systems use CNNs in some form. That said, the remainder of this post will focus on deep learning solutions for object detection, though similar challenges confront other approaches as well. To learn more about the basics of object detection, check out my post on the Metis blog: \u201cA Beginner\u2019s Guide to Object Detection.\u201d", "The first major complication of object detection is its added goal: not only do we want to classify image objects but also to determine the objects\u2019 positions, generally referred to as the object localization task. To address this issue, researchers most often use a multi-task loss function to penalize both misclassifications and localization errors.", "Regional-based CNNs represent one popular class of object detection frameworks. These methods consist of the generation of region proposals where objects are likely to be located followed by CNN processing to classify and further refine object locations. Ross Girshick et al. developed Fast R-CNN to improve upon their initial results with R-CNN. As its name implies, Fast R-CNN provides a dramatic speed-up, but accuracy also improves because the classification and localization tasks are optimized using one unified multi-task loss function. Each candidate region that may contain an object is compared to the image\u2019s true objects. Candidate regions then incur penalties for both false classifications and misalignment of the bounding boxes. Hence, the loss function consists of two kinds of terms:", "where the classification term imposes log loss on the predicted probability of the true object class u and the localization term is a smooth L\u2081 loss for the four positional components that define the rectangle. Note that the localization penalty does not apply to the background class when no object is present, u=0. Also note that the parameter \u03bb may be adjusted to prioritize either classification or localization more strongly.", "Object detection algorithms need to not only accurately classify and localize important objects, they also need to be incredibly fast at prediction time to meet the real-time demands of video processing. Several key enhancements over the years have boosted the speed of these algorithms, improving test time from the 0.02 frames per second (fps) of R-CNN to the impressive 155 fps of Fast YOLO.", "Fast R-CNN and Faster R-CNN aim to speed up the original R-CNN approach. R-CNN uses selective search to generate 2,000 candidate regions of interest (RoIs) and passes each RoI through a CNN base individually, which causes a massive bottleneck since the CNN processing is quite slow. Fast R-CNN instead sends the entire image through the CNN base just once and then matches the RoIs created with selective search to the CNN feature map, yielding a 20-fold reduction in processing time. While Fast R-CNN is much speedier than R-CNN, yet another speed barrier persists. It takes approximately 2.3 seconds for Fast R-CNN to perform object detection on a single image, and selective search accounts for a full 2 seconds of that time! Faster R-CNN replaces selective search with a separate sub-neural network to generate RoIs, creating another 10x speed up and thus testing at a rate of about 7\u201318 fps.", "Despite these impressive improvements, videos are typically shot at at least 24 fps, meaning Faster R-CNN will likely not keep pace. Regional-based methods consist of two separate phases: proposing regions and processing them. This task separation proves to be somewhat inefficient. Another major type of object detection systems relies on a unified one-state approach instead. These so-called single-shot detectors fully locate and classify objects during a single pass over the image, which substantially decreases test time. One such single-shot detector YOLO begins by laying out a grid over the image and allows each grid cell to detect a fixed number of objects of varying sizes. For each true object present in the image, the grid cell associated with the object\u2019s center is responsible for predicting this object. A complex, multi-term loss function then ensures that all localization and classification occurs within one process. One version of this method, Fast YOLO, has even achieved rates of 155 fps; however, classification and localization accuracy drops off sharply at this elevated speed.", "Ultimately, today\u2019s object detection algorithms attempt to strike a balance between speed and accuracy. Several design choices beyond the detection framework influence these outcomes. For example, YOLOv3 allows images of varying resolution: high-res images typically see better accuracy but slower processing times and vice versa for low-res images. The choice of the CNN base also affects the speed-accuracy tradeoff. Very deep networks like the 164 layers used in Inception-ResNet-V2 yield impressive accuracy, but pale in comparison to frameworks with VGG-16 in terms of speed. Object detection design choices must be made in context depending on whether speed or accuracy takes priority.", "For many applications of object detection, items of interest may appear in a wide range of sizes and aspect ratios. Practitioners leverage several techniques to ensure detection algorithms are able to capture objects at multiple scales and views.", "Instead of selective search, Faster R-CNN\u2019s updated region proposal network uses a small sliding window across the image\u2019s convolutional feature map to generate candidate RoIs. Multiple RoIs may be predicted at each position and are described relative to reference anchor boxes. The shapes and sizes of these anchor boxes are carefully chosen to span a range of different scales and aspect ratios. This allows various types of objects to be detected with the hopes that the bounding box coordinates need not be adjusted much during the localization task. Other frameworks, including single-shot detectors, also adopt anchor boxes to initialize regions of interest.", "Single-shot detectors must place special emphasis on the issue of multiple scales because they detect objects with a single pass through the CNN framework. If objects are detected from the final CNN layers alone, only large items will be found as smaller items may lose too much signal during downsampling in the pooling layers. To address this problem, single-shot detectors typically look for objects within multiple CNN layers including earlier layers where higher resolution remains. Despite the precaution of using multiple feature maps, single-shot detectors notoriously struggle to detect small objects, especially those in tight groupings like a flock of birds.", "The feature pyramid network (FPN) takes the concept of multiple feature maps one step further. Images first pass through the typical CNN pathway, yielding semantically rich final layers. Then to regain better resolution, FPN creates a top-down pathway by upsampling this feature map. While the top-down pathway helps detect objects of varying sizes, spatial positions may be skewed. Lateral connections are added between the original feature maps and the corresponding reconstructed layers to improve object localization. FPN currently provides one of the leading ways to detect objects at multiple scales, and YOLO was augmented with this technique in its 3rd version.", "The limited amount of annotated data currently available for object detection proves to be another substantial hurdle. Object detection datasets typically contain ground truth examples for about a dozen to a hundred classes of objects, while image classification datasets can include upwards of 100,000 classes. Furthermore, crowdsourcing often produces image classification tags for free (for example, by parsing the text of user-provided photo captions). Gathering ground truth labels along with accurate bounding boxes for object detection, however, remains incredibly tedious work.", "The COCO dataset, provided by Microsoft, currently leads as some of the best object detection data available. COCO contains 300,000 segmented images with 80 different categories of objects with very precise location labels. Each image contains about 7 objects on average, and items appear at very broad scales. As helpful as this dataset is, object types outside of these 80 select classes will not be recognized if training solely on COCO.", "A very interesting approach to alleviating data scarcity comes from YOLO9000, the second version of YOLO. YOLO9000 incorporates many important updates into YOLO, but it also aims to narrow the dataset gap between object detection and image classification. YOLO9000 trains simultaneously on both COCO and ImageNet, an image classification dataset with tens of thousands of object classes. COCO information helps precisely locate objects, while ImageNet increases YOLO\u2019s classification \u201cvocabulary.\u201d A hierarchical WordTree allows YOLO9000 to first detect an object\u2019s concept (such as \u201canimal/dog\u201d) and to then drill down into specifics (such as \u201cSiberian husky\u201d). This approach appears to work well for concepts known to COCO like animals but performs poorly on less prevalent concepts since RoI suggestion comes solely from the training with COCO.", "Class imbalance proves to be an issue for most classification problems, and object detection is no exception. Consider a typical photograph. More likely than not, the photograph contains a few main objects and the remainder of the image is filled with background. Recall that selective search in R-CNN produces 2,000 candidate RoIs per image\u2013just imagine how many of these regions do not contain objects and are considered negatives!", "A recent approach called focal loss is implemented in RetinaNet and helps diminish the impact of class imbalance. In the optimization loss function, focal loss replaces the traditional log loss when penalizing misclassifications:", "where p\u1d64 is the predicted class probability for the true class and \u03b3 > 0. The additional factor (*) reduces loss for well-classified examples with high probabilities, and the overall effect de-emphasizes classes with many examples that the model knows well, such as the background class. Objects of interest occupying minority classes, therefore, receive more significance and see improved accuracy.", "Object detection is customarily considered to be much harder than image classification, particularly because of these five challenges: dual priorities, speed, multiple scales, limited data, and class imbalance. Researchers have dedicated much effort to overcome these difficulties, yielding oftentimes amazing results; however, significant challenges still persist.", "Basically all object detection frameworks continue to struggle with small objects, especially those bunched together with partial occlusions. Real-time detection with top-level classification and localization accuracy remains challenging, and practitioners must often prioritize one or the other when making design decisions. Video tracking may see improvements in the future if some continuity between frames is assumed rather than processing each frame individually. Furthermore, an interesting enhancement that may see more exploration would extend the current two-dimensional bounding boxes into three-dimensional bounding cubes. Even though many object detection obstacles have seen creative solutions, these additional considerations\u2013and plenty more\u2013signal that object detection research is certainly not done!", "[2] R. Girshick, J. Donahue, T. Darrell, and J. Malik, Rich feature hierarchies for accurate object detection and semantic segmentation (2014), IEEE Conference on Computer Vision and Pattern Recognition (CVPR).", "[4] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. (2015) Neural Information Processing Systems (NIPS).", "[9] T.-Y. Lin, P. Dollar, R. Girshick, K. He, B. Hariharan, and S. Belongie, Feature pyramid networks for object detection (2017), Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science Educator. Applied Math PhD. Enthusiastic about data storytelling, data visualization, and NLP.."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F924cb09de9dd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kimberlyfessel?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kimberlyfessel?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "Kimberly Fessel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad4dcae70eec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&user=Kimberly+Fessel&userId=ad4dcae70eec&source=post_page-ad4dcae70eec----924cb09de9dd---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F924cb09de9dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F924cb09de9dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://cloud.google.com/vision/docs/drag-and-drop", "anchor_text": "Google"}, {"url": "https://www.ibm.com/watson/services/visual-recognition/", "anchor_text": "IBM"}, {"url": "https://www.quora.com/What-are-some-interesting-applications-of-object-detection", "anchor_text": "many different fields"}, {"url": "https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework", "anchor_text": "Viola and Jones"}, {"url": "https://arxiv.org/abs/1708.02002", "anchor_text": "RetinaNet"}, {"url": "https://www.thisismetis.com/blog/a-beginners-guide-to-object-detection", "anchor_text": "A Beginner\u2019s Guide to Object Detection"}, {"url": "https://arxiv.org/pdf/1504.08083.pdf", "anchor_text": "Fast R-CNN"}, {"url": "https://arxiv.org/pdf/1311.2524.pdf", "anchor_text": "R-CNN"}, {"url": "https://arxiv.org/pdf/1504.08083.pdf", "anchor_text": "Fast R-CNN"}, {"url": "https://arxiv.org/pdf/1506.01497.pdf", "anchor_text": "Faster R-CNN"}, {"url": "https://koen.me/research/pub/uijlings-ijcv2013-draft.pdf", "anchor_text": "selective search"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf", "anchor_text": "YOLO"}, {"url": "https://arxiv.org/pdf/1804.02767.pdf", "anchor_text": "YOLOv3"}, {"url": "https://arxiv.org/pdf/1512.02325.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/1612.03144.pdf", "anchor_text": "feature pyramid network (FPN)"}, {"url": "https://arxiv.org/pdf/1804.02767.pdf", "anchor_text": "its 3rd version"}, {"url": "https://arxiv.org/pdf/1612.03144.pdf", "anchor_text": "source"}, {"url": "https://github.com/pjreddie/darknet/blob/master/data/coco.names", "anchor_text": "80 different categories"}, {"url": "https://arxiv.org/pdf/1612.08242.pdf", "anchor_text": "second version of YOLO"}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet"}, {"url": "https://arxiv.org/pdf/1612.08242.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/abs/1708.02002", "anchor_text": "RetinaNet"}, {"url": "https://arxiv.org/abs/1708.02002", "anchor_text": "Focal loss for dense object detection"}, {"url": "https://arxiv.org/pdf/1311.2524.pdf", "anchor_text": "Rich feature hierarchies for accurate object detection and semantic segmentation"}, {"url": "https://arxiv.org/pdf/1504.08083.pdf", "anchor_text": "Fast R-CNN"}, {"url": "https://arxiv.org/pdf/1506.01497.pdf", "anchor_text": "Faster r-cnn: Towards real-time object detection with region proposal networks."}, {"url": "https://arxiv.org/abs/1506.02640", "anchor_text": "You only look once: Unified, real-time object detection"}, {"url": "https://arxiv.org/abs/1612.08242", "anchor_text": "Yolo9000: Better, faster, stronger"}, {"url": "https://arxiv.org/pdf/1804.02767.pdf", "anchor_text": "Yolov3: An incremental improvement"}, {"url": "https://arxiv.org/pdf/1512.02325.pdf", "anchor_text": "SSD: single shot multibox detector"}, {"url": "https://arxiv.org/abs/1612.03144", "anchor_text": "Feature pyramid networks for object detection"}, {"url": "https://arxiv.org/pdf/1405.0312.pdf", "anchor_text": "Microsoft coco: Common objects in context"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----924cb09de9dd---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/object-dete?source=post_page-----924cb09de9dd---------------object_dete-----------------", "anchor_text": "Object Dete"}, {"url": "https://medium.com/tag/yolo?source=post_page-----924cb09de9dd---------------yolo-----------------", "anchor_text": "Yolo"}, {"url": "https://medium.com/tag/r-cnn?source=post_page-----924cb09de9dd---------------r_cnn-----------------", "anchor_text": "R Cnn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F924cb09de9dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&user=Kimberly+Fessel&userId=ad4dcae70eec&source=-----924cb09de9dd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F924cb09de9dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&user=Kimberly+Fessel&userId=ad4dcae70eec&source=-----924cb09de9dd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F924cb09de9dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F924cb09de9dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----924cb09de9dd---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----924cb09de9dd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----924cb09de9dd--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----924cb09de9dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kimberlyfessel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kimberlyfessel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kimberly Fessel"}, {"url": "https://medium.com/@kimberlyfessel/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "243 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad4dcae70eec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&user=Kimberly+Fessel&userId=ad4dcae70eec&source=post_page-ad4dcae70eec--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc2620b9f107f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-significant-object-detection-challenges-and-solutions-924cb09de9dd&newsletterV3=ad4dcae70eec&newsletterV3Id=c2620b9f107f&user=Kimberly+Fessel&userId=ad4dcae70eec&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}