{"url": "https://towardsdatascience.com/how-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d", "time": 1682993472.491762, "path": "towardsdatascience.com/how-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d/", "webpage": {"metadata": {"title": "How to Build an Easy, Quick and Essentially Useless Chatbot Using Your Own Text Messages | by Kyle Gallatin | Towards Data Science", "h1": "How to Build an Easy, Quick and Essentially Useless Chatbot Using Your Own Text Messages", "description": "For those of you familiar with data science, one of the biggest challenges in the field is acquiring training data that doesn\u2019t suck. Having reliable \u201cground truth\u201d examples is what fuels good\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/RasaHQ/rasa_nlu", "anchor_text": "Rasa NLU", "paragraph_index": 3}, {"url": "https://www.anaconda.com/download/#macos", "anchor_text": "anaconda", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "wikipedia", "paragraph_index": 24}, {"url": "https://brew.sh/", "anchor_text": "here", "paragraph_index": 26}, {"url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/_introducing_the_query_language.html", "anchor_text": "Query DSL", "paragraph_index": 32}, {"url": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/", "anchor_text": "this dude has a great article", "paragraph_index": 38}, {"url": "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e", "anchor_text": "this article", "paragraph_index": 41}], "all_paragraphs": ["*Currently specific to iPhone and macOS", "For those of you familiar with data science, one of the biggest challenges in the field is acquiring training data that doesn\u2019t suck. Having reliable \u201cground truth\u201d examples is what fuels good machine learning. Especially for tasks like natural language processing (NLP), lots of data is required for machines to learn good word context, labels or general \u201cunderstanding\u201d.", "Well, as humans we generate training data all the time \u2014 and what better training data for a conversational bot than your own text messages? In this post, I\u2019ll show you how to build a very simple, easy and underachieving chatbot using python and your own text messages.", "More complex and advanced chatbots likely have an architecture that involves entity recognition, intent recognition, some kind of tailored response database, some LSTMs sprinkled on there etc\u2026but I\u2019m not going over any of that. If you\u2019re looking to build a business oriented chatbot from scratch to provide good information and answer questions, try something like Rasa NLU. If you\u2019re just looking to screw around for kicks, keep reading!", "*IMPORTANT* \u2014 Doing analysis on your texts is fun, but be conscious of the information in there. The model(s) we\u2019ll use will forever have access to messages from your friends, drunk nights out, lovers, hitmen, parents, drug dealers etc\u2026 Don\u2019t post your model(s), data or sensitive results anywhere so that someone can access your info. It isn\u2019t safe and it\u2019s a dick move to your friends. With that in mind, let\u2019s start to dive in.", "So there\u2019s plenty of easy ways to make a useless chatbot, but which way you should do it depends on your data. I\u2019ll outline two ways, and feel free to try both; however, which you choose depends on the amount of text message data you have. The post will split later on after the general preparation steps.", "For reference, I have ~100k text messages and the second option still doesn\u2019t work great, but feel free to see which one is best for you. They\u2019re both fun to pilot and see what you get.", "To start you should have python installed already (and definitely have some experience with it). I recommend installing anaconda if you don\u2019t but I won\u2019t be going through any basics. I\u2019ll be working in a jupyter notebook (a python notebook that lets you run blocks of code) but you can do whatever the hell you like. I\u2019ll be working in Python 2 (but it should work fine in 3).", "I\u2019ll go over the packages you\u2019ll for each option in their respective section of this post. Your python version should already have the sqlite3 and pandas packages installed which we\u2019ll need for the beginning.", "Before we grab the data, just plug your iPhone into your Mac so it\u2019s all backed up to the latest point. You\u2019ll want as much data as possible to improve the bot. With all that complete, let\u2019s get coding. First let\u2019s create a project directory. This is how I made mine:", "Then, we next need to get our data in an easier place. The location should be the same on your computer as it is mine. All of your backed up iPhone data should be in ~/Library/Application Support/MobileSync/Backup. Knowing that, let\u2019s copy the database file with our texts to a less ridiculous location than that awful path you can see below. In your terminal type:", "Last but not least, let\u2019s cd into our project directory and start jupyter (or a python shell if you prefer). Once jupyter pops up create a new notebook.", "Cool, now we\u2019re set to actually start getting to the fun parts in python. Let\u2019s import our first two packages. sqlite3 will let us read the data from our database file, and pandas will let us load it into a dataframe for easy operations.", "Here\u2019s where we read in the data. You have to specify the absolute path or it won\u2019t work, so you can\u2019t use the ~. In the code below, change kylegallatin to the name of your home directory. If you don\u2019t know what it is open a terminal and type ~.", "Now, we can use some basic SQL commands to get the data we need, and load it into pandas to work with it. We only need a few columns for this, so I\u2019ve specified what they are. text is the message itself, handle_id is the person you were texting in integer format, is_from_me is a binary flag \u2014 when it\u2019s 1 you sent the text, if 0 then the handle_id of that row did, and finally date is the date the text was sent. If you want to do a more in depth analysis of your social lifestyle, check the other columns you have available.", "You should see the earliest texts you have backed up. It should already be in chronological order which is necessary for the next part. If you aren\u2019t convinced, just run df = df.sort_values(by='date') to be sure. To check how many messages you have, you can run len(df).", "Next, we need to start thinking about the training data. We have a good amount of messages here, but nothing really in the form of conversational training data \u2014 their just in chronological order. Our goal for this post is to get a dataframe consisting of two columns: text and response so our chatbot has examples to \u201clearn\u201d from.", "We not only need to group the conversations by person (or handle_id), but a closer look at the data shows us that we can have multiple texts in a row from the same person \u2014 making it hard to tell what should be text and what should be response. We need to concatenate all simultaneous texts, then assign every df['text'][i] or text to its response, df['text'][i+1].", "Below isn\u2019t the most pythonic thing I\u2019ve ever written, but hey it runs quickly enough. Please feel free to offer improvements.", "Andddd finally the most minimal preprocessing:", "Now you may be thinking \u201cdude you\u2019re ignoring a ton of different cases\u201d \u2014 and you\u2019re probably right. What about group chats? How do you actually define the start and end of a conversation? There are tons of things to consider here, all of which I\u2019m going to ignore for this tutorial. This is a quick and dirty chatbot tutorial, not \u201c1 million if statements I had to write to create the perfect training data\u201d. If anyone wants to delve further into this so I don\u2019t have to \u2014 please do.", "That snag aside, we now have something that resembles training data. For each handle_id, we now have every text mapped to a response, and then every response becomes the next text. With our data in this format, we can now build a way to map things we will say to our bot back to a semi-appropriate response.", "Option 1 employs a keyword based search across our text column using anything we \u201ctext\u201d to the bot. By comparing our text with other texts, we can try to send an appropriate response back.", "Elasticsearch is a scalable search platform that uses an algorithm similar to TF-IDF, which standards for term frequency inverse document frequency.", "Essentially, it\u2019s a simple function often used within the search/similarity space that targets documents based on keywords. It also places less emphasis on words that appear frequently. For instance, because the word \u201cthe\u201d appears in so many texts, we don\u2019t want it to be considered an important part of our search query. TF-IDF takes this into account when comparing your query with documents. For a basic overview of it just check wikipedia.", "The actual comparison we run will be based on cosine similarity. Since TF-IDF will vectorize our text, the way we match it up to the \u201cmost similar\u201d text in our data will need to be based on this metric. It helps us find vectors that are closest together within whatever size vector space we have representing our documents.", "We could also use a package like sklearn to implement TF-IDF pretty easily, but elastic is way quicker/easier to setup, use and scale for our purposes. We\u2019ll need two things \u2014 both elasticsearch itself and the its client. To install the former we\u2019ll use the package manager homebrew. If you don\u2019t already have it, install it from here.", "Now that you have elasticsearch installed, you just need to start it. Homebrew should\u2019ve already added it to your path. This terminal command should start elastic on port 9200.", "That should be it! Now we can move back to the python notebook.", "In order to index and make our data in elastic, we can use the code below. We first import our packages, and then create an instance of our python client. Finally, the function we use to upload our data to elastic expects a dictionary format, so we convert our dataframe to a dictionary.", "I won\u2019t go in depth on this code/client and elasticsearch, but here all we did was manipulate our data a bit and create an index on our elasticsearch instance called textbot, which we can now query for information.", "Anddddd that\u2019s basically it! The only thing to do now is create a function to query our data.", "Below is just that. I have a simple function that runs a continuously loop. Each time, it prompts the user for an input, searches our data for the most relevant text information, and then returns the response from that same row. If the response is quit(), the program stops. The response variable we get back from the search is generated by the language elastic uses referred to as Query DSL. There is a ridiculous amount of stuff you can do with it but I\u2019m again sticking to the basics per our needs.", "The response will be a json that contains a bunch of info but we only want one value, so we just need to grab that and print it! I\u2019ve also introduced a randomness variable you can toggle. The purpose of this is so you don\u2019t necessarily get the same result every time you send a \u201ctext\u201d to your bot, since results come back in order. If there is nothing relevant in text records at index i that matches what query you send, then you\u2019ll just get back \u201cidk\u201d.", "Lit, now you can give it a shot.", "Below is just me typing some things to my bot as an example so you get what I get, feel free to play with the randomness or other parts of the code to improve your queries.", "The more fun and altogether less reliable option fundamentally based on 2 models: word2vec and doc2vec.", "To understand doc2vec you first need to look at word2vec. Originally created by a team of researchers led by Tomas Mikolov at Google, it\u2019s a model that attempts learns word context. For those familiar with neural networks the architecture can be seen below.", "It\u2019s a shallow neural network that takes text as training data. Essentially, it goes through iterations trying to predict either the probability of a subset of words occurring near a given word, or the probability of a word occurring given a window of nearby words (depending on which architecture you use). With every attempt you update the weights present in the hidden layer for each word. At the end, you discard the predictions but keep the weights from the hidden layer. Given enough text input, these weights should somewhat represent the context of words. Similar words should have similar weight vectors and can then be compared by cosine similarity. For more on word2vec this dude has a great article.", "Doc2vec is very similar, you just have another input which is sentences or full blocks of text instead of words. Additionally, unlike word2vec where you discard the predications, here we can choose assess a label. In word2vec, every word is already its own entity so there\u2019s no need for this. In doc2vec, we have sentences or paragraphs containing multiple entities, so we can attach labels to these groups to classify them.", "Just like option 1, the way we do this is with cosine similarity. Since doc2vec will give us weights for texts we send the bot and vectorize it, the way we match it up to the \u201cmost similar\u201d text in our data will need to be based on this metric. It helps us find vectors that are closest together within whatever size vector space we have representing our documents. The picture below should explain all the technical stuff perfectly.", "To read more about doc2vec check out this article.", "To hell with math and theory! Let\u2019s code this thing.", "We\u2019ll be using gensim, a package for easily employing the word2vec and doc2vec packages originally published by google. It\u2019s easily installed via pip on the command line.", "First we need to define how we to define how we feed our data to the model. Thus far, I haven\u2019t even been remotely conscious of the memory I\u2019m using since I only have 100k texts, and it really isn\u2019t that much data. However, here it\u2019s good practice to feed your data to the model one sentence at a time through an iterator.", "The simple_preprocess function just does simple things like lowercase the text to standardize it. The key thing here is the tags \u2014 which I set to be [i] instead of the actual response. While you could do the latter, this is also more memory friendly so we\u2019ll go with this and take care of the response later.", "%%time just times a jupyter cell so remove it if you\u2019re in a shell or something else. The assertion statment makes sure we have the c compiler so that it trains quickly, and setting the model to train on all cores makes sure it\u2019s even faster. Then, we initiate our model with mostly default parameters. The 200 is just the size of the word vectors we\u2019ll get back \u2014 feel free to mess all the other tuning parameters! We give doc2vec access to our corpus of words with the build_vocab function, then train the model on our texts for 15 epochs or iterations. The os package just lets us create a directory to save our model in for later.", "That\u2019s it! Mine only took 2 minutes given the size of my data/computer, I\u2019d assume yours to be the same or around there. Still \u2014 how do we know doc2vec did what it was supposed to?", "Both word2vec and doc2vec come with a convenient cosine similarity function for checking the \u201cdistance\u201d between words in our 200 dimensional space. Let\u2019s check a word or two.", "And what do I get back from my texts?", "Dope! Don\u2019t be discouraged if your results don\u2019t look the same \u2014 without enough training data, your bound to see some weird results. It\u2019s honestly just fun to see what your model has learned from you and your friends conversations.", "Looks like I have a propensity to drink during the workday. More accurately, looks like \u201cdrinks\u201d, \u201cbeers\u201d, and \u201clunch\u201d are all used similarly in my conversations. This makes sense, considering I\u2019d likely say \u201clet\u2019s grab a beer\u201d in the same way I\u2019d say \u201clet\u2019s grab lunch\u201d. The more data you have, the more likely it is that these word vectors will move further away from one another, and more synonymous words will take their place.", "At this point we\u2019re at the easy part. We just need to create a simple function that takes an input, tokenizes it, gets the most similar text and returns the appropriate response. Since our model may not have seen all inputs we might throw at it yet, we\u2019ll use the infer_vector function to vectorize our texts to our chatbot.", "Now run your chatbot and talk to it! See all the weird responses you get based on your conversations.", "That\u2019s all! If I\u2019ve missed anything or you have comments, feel free to be obnoxious. It\u2019s my first post, still figuring it out. Hope you liked it.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer for ML Infra. Building scalable, operationalized machine learning services. I don\u2019t represent my employer."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff2cb8b84c11d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kylegallatin?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kylegallatin?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "Kyle Gallatin"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51ff4b76ebf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&user=Kyle+Gallatin&userId=51ff4b76ebf4&source=post_page-51ff4b76ebf4----f2cb8b84c11d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff2cb8b84c11d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff2cb8b84c11d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwifrfPypvXbAhXuzVkKHZIxAtwQjRx6BAgBEAU&url=https%3A%2F%2Fnews.avclub.com%2Fsomebody-entered-rick-and-morty-s-pass-the-butter-rob-1798262493&psig=AOvVaw3GuiyWeHVTU0M9a3fHOzNv&ust=1530239069052435", "anchor_text": "Source"}, {"url": "https://github.com/RasaHQ/rasa_nlu", "anchor_text": "Rasa NLU"}, {"url": "https://www.anaconda.com/download/#macos", "anchor_text": "anaconda"}, {"url": "https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwi3wLDO0vTbAhWBwVkKHVmiCsgQjRx6BAgBEAU&url=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-elasticsearch-in-python-c3598e718380&psig=AOvVaw0ZOA6-YClhBdOpBVicklB7&ust=1530216375028069", "anchor_text": "Source"}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "wikipedia"}, {"url": "https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwic6L3k0vTbAhVOwFkKHZZKD7YQjRx6BAgBEAU&url=https%3A%2F%2Fdeeplearning4j.org%2Fbagofwords-tf-idf&psig=AOvVaw3AB8Lk_MHOxMWKOwoYSbRH&ust=1530216484519950\\", "anchor_text": "Source"}, {"url": "https://brew.sh/", "anchor_text": "here"}, {"url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/_introducing_the_query_language.html", "anchor_text": "Query DSL"}, {"url": "https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjqt8C90_TbAhUnw1kKHU2xCzoQjRx6BAgBEAU&url=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-skip-gram-model-part-1-intuition-78614e4d6e0b&psig=AOvVaw2DmHyP-jxAeBV8JivYx-Kn&ust=1530216676036317", "anchor_text": "Source"}, {"url": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/", "anchor_text": "this dude has a great article"}, {"url": "https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwim66Gm0fTbAhUlwFkKHd-pB8MQjRx6BAgBEAU&url=https%3A%2F%2Fblog.acolyer.org%2F2016%2F04%2F21%2Fthe-amazing-power-of-word-vectors%2F&psig=AOvVaw2bMrmv66FULeilCJ0iBKuh&ust=1530216084081260", "anchor_text": "Source"}, {"url": "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e", "anchor_text": "this article"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f2cb8b84c11d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----f2cb8b84c11d---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/nlp?source=post_page-----f2cb8b84c11d---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/chatbots?source=post_page-----f2cb8b84c11d---------------chatbots-----------------", "anchor_text": "Chatbots"}, {"url": "https://medium.com/tag/chatbot-development?source=post_page-----f2cb8b84c11d---------------chatbot_development-----------------", "anchor_text": "Chatbot Development"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff2cb8b84c11d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&user=Kyle+Gallatin&userId=51ff4b76ebf4&source=-----f2cb8b84c11d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff2cb8b84c11d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&user=Kyle+Gallatin&userId=51ff4b76ebf4&source=-----f2cb8b84c11d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff2cb8b84c11d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff2cb8b84c11d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f2cb8b84c11d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f2cb8b84c11d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kylegallatin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kylegallatin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kyle Gallatin"}, {"url": "https://medium.com/@kylegallatin/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.4K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51ff4b76ebf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&user=Kyle+Gallatin&userId=51ff4b76ebf4&source=post_page-51ff4b76ebf4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1e64fc6ee18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-easy-quick-and-essentially-useless-chatbot-using-your-own-text-messages-f2cb8b84c11d&newsletterV3=51ff4b76ebf4&newsletterV3Id=1e64fc6ee18e&user=Kyle+Gallatin&userId=51ff4b76ebf4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}