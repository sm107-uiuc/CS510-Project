{"url": "https://towardsdatascience.com/iclr-19-highlights-and-all-that-jazz-659c294f991d", "time": 1682996255.595071, "path": "towardsdatascience.com/iclr-19-highlights-and-all-that-jazz-659c294f991d/", "webpage": {"metadata": {"title": "ICLR 19 highlights (and all that Jazz) | by Inbar Naor | Towards Data Science", "h1": "ICLR 19 highlights (and all that Jazz)", "description": "We went to ICLR to present our work on debugging ML models using uncertainty and attention. Between cocktail parties and jazz shows in the wonderful New Orleans (can we do all conferences in NOLA\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=sLAi-H9J3nk", "anchor_text": "talk", "paragraph_index": 2}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=636", "anchor_text": "workshop", "paragraph_index": 8}, {"url": "https://www.facebook.com/iclr.cc/videos/1061645560700150/", "anchor_text": "talk", "paragraph_index": 8}, {"url": "http://www.pyoudeyer.com", "anchor_text": "Pierre-Yves Oudeyer", "paragraph_index": 8}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=634", "anchor_text": "workshop", "paragraph_index": 10}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=630", "anchor_text": "workshop", "paragraph_index": 11}, {"url": "https://debug-ml-iclr2019.github.io/", "anchor_text": "workshop", "paragraph_index": 12}, {"url": "https://deep-gen-struct.github.io/", "anchor_text": "workshop", "paragraph_index": 12}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=632", "anchor_text": "workshop", "paragraph_index": 12}, {"url": "https://people.csail.mit.edu/madry/", "anchor_text": "Aleksander Madry", "paragraph_index": 13}, {"url": "https://www.facebook.com/iclr.cc/videos/2261061694154984/", "anchor_text": "keynote", "paragraph_index": 15}, {"url": "https://fatconference.org/", "anchor_text": "FAT conference", "paragraph_index": 18}, {"url": "https://arxiv.org/abs/1904.05878", "anchor_text": "paper", "paragraph_index": 21}, {"url": "https://openreview.net/forum?id=HJlLKjR9FQ", "anchor_text": "Towards Understanding, Regularization in Batch Normalization ,", "paragraph_index": 31}, {"url": "https://openreview.net/forum?id=SyMDXnCcF7", "anchor_text": "A Mean Field Theory of Batch Normalization", "paragraph_index": 31}, {"url": "https://openreview.net/forum?id=rkxQ-nA9FX", "anchor_text": "Theoretical Analysis of Auto Rate-Tuning by Batch Normalization", "paragraph_index": 31}], "all_paragraphs": ["A joint post with Ofri Mann", "We went to ICLR to present our work on debugging ML models using uncertainty and attention. Between cocktail parties and jazz shows in the wonderful New Orleans (can we do all conferences in NOLA please?) we also saw a lot of interesting talks and posters. Below are our main takeaways from the conference.", "A good summary of the themes was in Ian Goodfellow\u2019s talk, in which he said that until around 2013 the ML community was focused on making ML work. Now that it\u2019s working on many different applications given enough data, the focus has shifted towards adding more capabilities to our models: we want them to comply to some fairness, accountability and transparency constraints, to be robust, use labels efficiently, adapt to different domains and so on.", "A slide on ML topics, from Ian Goodfellow\u2019s talk", "We noticed a few topics that got a lot of attention: Reinforcement Learning, GANs and adversarial examples, and Fairness were the most prominent ones. There was also a fair amount of work on training and optimization techniques, VAEs, quantization and understanding different behaviors of networks.", "While the last day of the conference displayed many papers about different NLP tasks, Computer Vision felt to us like a solved problem and there were very few applicative vision papers. However, most of the work on optimization, understanding networks, meta learning etc is in fact done on images. Even though the conference focuses on learning representations, there wasn\u2019t much work on learning representations for structured or tabular data.", "The notes below are grouped according to the main topics.", "There were three workshops and an entire poster session (~90 papers) dedicated to Reinforcement Learning.", "One of the prominent subjects discussed this year was sparse-reward or no-reward reinforcement learning. The subject was well represented with the Task-Agnostic Reinforcement Learning workshop, multiple posters and short talks, as well as a great talk by Pierre-Yves Oudeyer, discussing curiosity-driven learning, where information-gain is used as an intrinsic reward, allowing algorithms to explore their environments and focus on areas where information-gain is highest. These kinds of intrinsic rewards can later be combined with extrinsic ones to achieve tasks with almost no explicit practice. In his talk, Oudeyer demonstrated how robots learn to manipulate their environment and perform tasks with no prior practice, as well as a novel math-teaching method, where a curiosity-driven algorithm is used to personalize each child\u2019s curriculum, focusing on his/her weaker subjects.", "Two other workshops dealt with structure in RL:", "The Structure & Priors in Reinforcement Learning workshop focused on different ways to learn structure and introduce priors to RL tasks in order to allow them to learn from fewer examples and have a higher generalization power at a lower computational cost.", "The Deep Reinforcement Learning Meets Structured Prediction workshop suggested viewing structure prediction as a sequential decision making process and focused on papers that leverage the advances in deep RL to improve structured prediction.", "Besides Goodfellow\u2019s keynote talk, which focused on GAN\u2019s applications to different ML research areas, there was an entire poster session dedicated to GANs and adversarial examples. These also got a lot of attention in the Debugging ML models workshop, the Deep Generative Models for Highly Structured Data workshop and in the Safe Machine Learning: Specification, Robustness, and Assurance workshop.", "For example, in his talk \u201cA new Perspective on Adversarial Examples\u201d, Aleksander Madry claimed that models learn from robust features, which capture some interpretable meaning to humans, and non-robust features that are correlative with the labels. Since the non-robust features are just as good in order to maximize model\u2019s accuracy, models focus on them as well. Therefore, he claims, we cannot hope for post-training interpretability, since some of the model\u2019s predictive power comes from the non-robust features. We call those features adversarial examples, but from the model\u2019s perspective, there isn\u2019t a real difference between the robust and non-robust features. In order to improve interpretability Madry presented ways to force models to focus only on robust features during training.", "This year there was a lot of (not necessarily technical) talk about issues related to fairness, safety and AI for Social Good.", "Cynthia Dwark gave a great keynote about recent development in algorithmic fairness in which she presented two notions of fairness \u2014 group fairness, which address the relative treatment of different demographic groups, and individual fairness, which requires that people who are similar, with respect to a given classification task, should be treated similarly by classifiers for that task. She talked about the challenges related to the two notions and about recent work aiming at bridging the gap between them, with an emphasis on the notion of multi calibration \u2014 being calibrated on different groups, and fair ranking and scoring.", "Another talk that aimed at sparking discussion about possible dangers in ML was Zeynep Tufekci\u2019s \u201cWhile we\u2019re all worried about the failures of ML, what dangers lurk if it (mostly) works?\u201d.", "The AI for social good workshop focused on applying ML to solve problems important for society such as health care, education and agriculture. The Safe ML workshop, focused on specifying systems purpose, making them more robust and monitor them. The reproducibility in ML workshop and the Debugging ML workshop (where we presented our work on uncertanity and attention), mainly focused on fairness and interpretability.", "We read the high emphasis on Fairness, Accountability and Transparency (FAT) by the conference organizers as an open invitation to the community to participate in this important discussion as part of the main ML conferences. While most related papers are published in designated conferences like FAT conference and there weren\u2019t many related papers in the main track this year, we expect this to change in upcoming years.", "There were many other interesting papers on topics outside the themes mentioned above. It\u2019s hard to choose just a few out of the 500+ papers published in ICLR 19.", "We compiled a few for some topics we are interested in.", "A research group from the University of Illinois presented a very interesting paper, \u201cKnowledge Flow \u2014 Improve upon your teachers\u201d. The idea is a novel method of transfer learning \u2014 \u201cKnowledge Flow\u201d architecture.", "A \u201cstudent\u201d network, training on a novel task, uses the intermediate layer weights from one or more \u201cteacher\u201d networks, pre-trained on other tasks. By using trainable transformation matrices and weight vectors, the model learns how much each teacher contributes to the students in different parts of the network.", "In addition, the Knowledge Flow loss function includes the student\u2019s dependency on its teachers, which decreases as training progresses.", "Using this method, the teachers contribute heavily to the initial training steps, allowing for a quick \u201cwarm start\u201d of the student network. As the student trains on the novel task, the teacher\u2019s influence is diminished, until the final training steps, when the student becomes independent of its teachers, and uses only its own weight.", "This works on both supervised and reinforcement-learning tasks, and achieves top results and faster convergence on several test-sets.", "Another transfer learning paper we found interesting was K for the price of 1: Parameter efficient multi task and transfer learning.", "It shows a unified framework for both transfer and multitask learning. The idea is to use model patches \u2014 a set of small trainable layers specific to each task that are interleaved with existing layers.", "These patches can be used for transfer learning by fine-tuning only the patch parameters on the new task while making the rest of the pretrained layers unchanged. For multitask learning it means that the models share most of the weights except for the task specific patches.", "Bias-reduced uncertainty estimation for Deep Neural Networks, shows an \u201coverfitting\u201d-like phenomena with uncertainty estimations where on easier cases uncertainty estimation improve at the beginning of the training but after a number of iterations they degrade. In order to prevent this, averaging different checkpoints from training or early stopping is recommended.", "Modeling Uncertainty with Hedge Instance Embedding: What if instead of learning deterministic embeddings we\u2019ll learn probabilistic ones? Siamese networks are trained with constructive loss but instead of outputting z as usual, the output is expectation and standard deviation, defining the gaussian that represent the embedding. The size of the gaussian can later be treated as an uncertainty estimation.", "There we three papers worth mentioning shedding light into how batch normalization works: Towards Understanding, Regularization in Batch Normalization , A Mean Field Theory of Batch Normalization , and Theoretical Analysis of Auto Rate-Tuning by Batch Normalization", "The audience was a mix of academia and industry labs. A huge amount of papers came from industry research centers \u2014 DeepMind had around 50 papers, Google around 55, Microsoft and Facebook around 30 each. There was also a fair amount of work coming from industry companies.", "We had a lot of fun and came back with many ideas we can\u2019t wait to develop!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist at Taboola, working on Deep Learning applications for Recommendation Systems"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F659c294f991d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----659c294f991d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----659c294f991d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@inbarnaor?source=post_page-----659c294f991d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@inbarnaor?source=post_page-----659c294f991d--------------------------------", "anchor_text": "Inbar Naor"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d840e4443e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&user=Inbar+Naor&userId=5d840e4443e4&source=post_page-5d840e4443e4----659c294f991d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F659c294f991d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F659c294f991d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.youtube.com/watch?v=sLAi-H9J3nk", "anchor_text": "talk"}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=636", "anchor_text": "workshop"}, {"url": "https://www.facebook.com/iclr.cc/videos/1061645560700150/", "anchor_text": "talk"}, {"url": "http://www.pyoudeyer.com", "anchor_text": "Pierre-Yves Oudeyer"}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=634", "anchor_text": "workshop"}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=630", "anchor_text": "workshop"}, {"url": "https://debug-ml-iclr2019.github.io/", "anchor_text": "workshop"}, {"url": "https://deep-gen-struct.github.io/", "anchor_text": "workshop"}, {"url": "https://iclr.cc/Conferences/2019/Schedule?showEvent=632", "anchor_text": "workshop"}, {"url": "https://people.csail.mit.edu/madry/", "anchor_text": "Aleksander Madry"}, {"url": "https://www.facebook.com/iclr.cc/videos/2261061694154984/", "anchor_text": "keynote"}, {"url": "https://fatconference.org/", "anchor_text": "FAT conference"}, {"url": "https://arxiv.org/abs/1904.05878", "anchor_text": "paper"}, {"url": "https://engineering.taboola.com/using-uncertainty-interpret-model/", "anchor_text": "favourite"}, {"url": "https://openreview.net/forum?id=HJlLKjR9FQ", "anchor_text": "Towards Understanding, Regularization in Batch Normalization ,"}, {"url": "https://openreview.net/forum?id=SyMDXnCcF7", "anchor_text": "A Mean Field Theory of Batch Normalization"}, {"url": "https://openreview.net/forum?id=rkxQ-nA9FX", "anchor_text": "Theoretical Analysis of Auto Rate-Tuning by Batch Normalization"}, {"url": "https://medium.com/tag/fairness?source=post_page-----659c294f991d---------------fairness-----------------", "anchor_text": "Fairness"}, {"url": "https://medium.com/tag/gan?source=post_page-----659c294f991d---------------gan-----------------", "anchor_text": "Gan"}, {"url": "https://medium.com/tag/iclr?source=post_page-----659c294f991d---------------iclr-----------------", "anchor_text": "Iclr"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----659c294f991d---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/transfer-learning?source=post_page-----659c294f991d---------------transfer_learning-----------------", "anchor_text": "Transfer Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F659c294f991d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&user=Inbar+Naor&userId=5d840e4443e4&source=-----659c294f991d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F659c294f991d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&user=Inbar+Naor&userId=5d840e4443e4&source=-----659c294f991d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F659c294f991d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----659c294f991d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F659c294f991d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----659c294f991d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----659c294f991d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----659c294f991d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----659c294f991d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----659c294f991d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----659c294f991d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----659c294f991d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----659c294f991d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----659c294f991d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@inbarnaor?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@inbarnaor?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Inbar Naor"}, {"url": "https://medium.com/@inbarnaor/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "305 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d840e4443e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&user=Inbar+Naor&userId=5d840e4443e4&source=post_page-5d840e4443e4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F5d840e4443e4%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ficlr-19-highlights-and-all-that-jazz-659c294f991d&user=Inbar+Naor&userId=5d840e4443e4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}