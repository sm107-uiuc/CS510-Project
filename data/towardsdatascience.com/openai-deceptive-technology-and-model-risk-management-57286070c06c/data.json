{"url": "https://towardsdatascience.com/openai-deceptive-technology-and-model-risk-management-57286070c06c", "time": 1682995257.417335, "path": "towardsdatascience.com/openai-deceptive-technology-and-model-risk-management-57286070c06c/", "webpage": {"metadata": {"title": "OpenAI, Deceptive Technology, and Model Risk Management | by Dawn Graham | Towards Data Science", "h1": "OpenAI, Deceptive Technology, and Model Risk Management", "description": "This article includes OpenAI\u2019s GPT-2, the Digital Defense Playbook, destructive versus deceptive technology, malicious intent, deepfakes, verification and surveillance, and model risk management."}, "outgoing_paragraph_urls": [{"url": "https://blog.openai.com/better-language-models/", "anchor_text": "release of GPT-2", "paragraph_index": 1}, {"url": "https://thegradient.pub/openai-please-open-source-your-language-model/", "anchor_text": "open letter", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8", "anchor_text": "article", "paragraph_index": 8}, {"url": "https://www.smartdatacollective.com/how-ai-is-transforming-lending-and-loan-management/", "anchor_text": "loan applications", "paragraph_index": 11}, {"url": "https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/", "anchor_text": "court sentencing", "paragraph_index": 11}, {"url": "https://beamery.com/blog/ai-recruiting", "anchor_text": "personnel hiring", "paragraph_index": 11}, {"url": "https://www.technologyreview.com/s/610192/were-in-a-diversity-crisis-black-in-ais-founder-on-whats-poisoning-the-algorithms-in-our/", "anchor_text": "lack of diversity", "paragraph_index": 12}, {"url": "https://medium.com/@racheltho/im-an-ai-researcher-and-here-is-what-scares-me-about-ai-909a406e4a71", "anchor_text": "5 things", "paragraph_index": 13}, {"url": "https://towardsdatascience.com/from-faceapp-to-deepfakes-3d1048713da0", "anchor_text": "already written", "paragraph_index": 15}, {"url": "https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/will-deepfakes-detection-be-ready-for-2020", "anchor_text": "disrupt", "paragraph_index": 15}, {"url": "https://blog.openai.com/preparing-for-malicious-uses-of-ai/", "anchor_text": "malicious purposes", "paragraph_index": 17}, {"url": "https://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072", "anchor_text": "article", "paragraph_index": 19}, {"url": "https://www.wired.com/story/these-new-tricks-can-outsmart-deepfake-videosfor-now/", "anchor_text": "piece", "paragraph_index": 19}, {"url": "https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth", "anchor_text": "explains", "paragraph_index": 20}, {"url": "https://www.wired.com/story/zeynep-tufekci-facts-fake-news-verification/", "anchor_text": "suggests", "paragraph_index": 23}, {"url": "https://www.alliedmedia.org/news/2019/02/07/our-data-bodies-playbook-out", "anchor_text": "released", "paragraph_index": 26}, {"url": "https://www.facebook.com/data4blacklives/videos/300185840850038/", "anchor_text": "closing panel", "paragraph_index": 29}, {"url": "https://www.linkedin.com/in/srikrishnamurthy/", "anchor_text": "Sri Krishnamurthy", "paragraph_index": 32}, {"url": "https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm", "anchor_text": "SR 11\u20137", "paragraph_index": 33}, {"url": "https://slate.com/technology/2019/02/openai-gpt2-text-generating-algorithm-ai-dangerous.html", "anchor_text": "another piece", "paragraph_index": 35}, {"url": "http://dawngraham.github.io", "anchor_text": "dawngraham.github.io", "paragraph_index": 42}], "all_paragraphs": ["This article connects some dots as I sort through my own thoughts on releasing technology and information that could have adverse effects. It touches on the release of GPT-2 by OpenAI and the Digital Defense Playbook by Our Data Bodies, destructive versus deceptive technology, malicious intent, deepfakes, verification and surveillance, and model risk management. Enjoy!", "OpenAI recently caused a stir with their release of GPT-2, a language model that can take a human-written prompt and generate more than a page of coherent, \u201chuman quality\u201d text. I\u2019ve seen more interest in their release strategy than in the model itself. They chose not to release the full model, dataset, training code, or model weights, citing concerns about how it could be used. They explained:", "This decision, as well as our discussion of it, is an experiment: while we are not sure that it is the right decision today, we believe that the AI community will eventually need to tackle the issue of publication norms in a thoughtful way in certain research areas. Other disciplines such as biotechnology and cybersecurity have long had active debates about responsible publication in cases with clear misuse potential, and we hope that our experiment will serve as a case study for more nuanced discussions of model and code release decisions in the AI community.", "The reactions were swift, with many wondering about OpenAI\u2019s motivations. Others worried about the implications for the future of open source.", "The Gradient published an open letter by Hugh Zhang that called on OpenAI to make the full model available, making a distinction between destructive and deceptive technologies:", "Zhang goes on to say that the way to deal with a deceptive technology is to \u201cmake knowledge of its power as public as possible,\u201d while \u201csufficiently dangerous technologies of the destructive kind should never be made easily accessible.\u201d", "He does acknowledge that deceptive technologies can be dangerous and suggests using \u201ca small delay between paper publication and code release to prevent a fast-reacting malicious actor from swooping in before the public has had time to fully process the new results.\u201d", "While I can appreciate the argument being made, there is also a difference between making the knowledge public and the public being knowledgeable. Putting information out there does not guarantee that the general public will end up seeing it or have the time or interest to fully process it.", "In an article that takes a different stance on the release of GPT-2, Ryan Lowe asks a question of machine learning (ML) researchers:", "We are building things that affect people. Sooner or later, we\u2019ll cross a line where our research can be used maliciously to do bad things. Should we just wait until that happens to decide how we handle research that can have negative side effects?", "This echoes Zhang\u2019s reference to \u201ca fast-reacting malicious actor.\u201d My stomach turned as I read these lines though. One of the issues we have to grapple with is that the research is being used to do bad things \u2014 without people even trying to be malicious. Lowe does actually address this later in the article:", "ML research is already having an impact in the real world (e.g. to make decisions on loan applications, court sentencing, personnel hiring, etc.). The biases in these algorithms are now being exposed, but this is coming years after they were first implemented, and in the meantime they have made a serious impact on people\u2019s lives.", "Between a focus on innovation, lack of diversity in the field of artificial intelligence (AI), and likely plenty of other factors, new technologies are often introduced without serious consideration of potential adverse effects or unintended consequences.", "AI researcher and fast.ai co-founder Rachel Thomas explained 5 things that scare her about AI:", "None of the concern here is about malicious actors \u2014 rather, it is about the everyday implementation of AI. It seems like addressing these issues points to the importance of transparency and openness.", "What about actual malicious actors? I\u2019ve already written briefly about the concerns and damage caused by deepfakes. A lot of money and resources are being put into detecting them, with some expressing concerns about how deepfakes and similar technologies could be used to disrupt the 2020 elections (along with broader implications).", "Indeed, OpenAI referenced these technologies in their reasoning for not providing a full release of GPT-2:", "We can also imagine the application of these models for malicious purposes, including the following (or other applications we can\u2019t yet anticipate):", "Going back to Zhang\u2019s suggestion of \u201ca small delay between paper publication and code release\u201d for deceptive technologies, many researchers working to detect deepfakes have already spoken to the issue of sharing their findings.", "Computer scientist Siwei Lyu published an article in August 2018 explaining how his team had achieved an over 95 percent detection rate of deepfakes based off of blinking. But a follow-up piece revealed that only \u201ca few weeks after his team put a draft of their paper online, they got anonymous emails with links to deeply faked YouTube videos whose stars opened and closed their eyes more normally. The fake content creators had evolved.\u201d", "Hany Farid, a professor of computer science at University of California, uses forensic technology to detect deepfakes. He explains how combatting them has become harder due to machine learning and why he doesn\u2019t share new breakthroughs:", "All the programmer has to do is update the algorithm to look for, say, changes of color in the face that correspond with the heartbeat, and then suddenly, the fakes incorporate this once imperceptible sign. Once I spill on the research, all it takes is one asshole to add it to their system.", "While some people are calling for technologies that can generate fake media to be made open source, those working to detect fakes benefit in the so-called AI arms race by keeping their innovations under wraps.", "Rather than focusing on detecting fake media, some are looking at verifying real media instead. Techno-sociologist Zeynep Tufekci suggests that verification could come by way of spoof-proof metadata in cameras or blockchain databases. These solutions may help verify images or videos, but verification of text could prove more difficult. Tufekci also reminds us:", "An effective identification system, however, carries with it a worrisome truth: Every verification method carries the threat of surveillance.", "While she goes on to say there are ways to mitigate this concern, it\u2019s not one to be taken lightly.", "One week before OpenAI\u2019s release of GPT-2, there was another release that I cared more about, but that didn\u2019t get nearly as much attention as GPT-2. Our Data Bodies (ODB) released the Digital Defense Playbook: Community Power Tools for Reclaiming Data. The workbook is described as \u201ca set of tried-and-tested tools for diagnosing, dealing with, and healing the injustices of pervasive and punitive data collection and data-driven systems.\u201d", "The release goes on to say that \u201cODB hopes the Playbook will energize community involvement in tackling surveillance, profiling, and privacy problems rooted in social injustice.\u201d", "ODB is doing the work of trying to deal with the aftermath of some of the issues named earlier, including bias encoded into AI (both intentionally and unintentionally) and the fallout from unintended consequences.", "During the closing panel of the Data for Black Lives II conference at MIT Media Lab, organizer and ODB team member Tawana Petty informed the audience:", "Y\u2019all getting the Digital Defense Playbook, but we didn\u2019t tell you all their strategies and we never will. Because we want our community members to continue to survive and to thrive. So you\u2019ll get some stuff, but the stuff that\u2019s keeping them alive, we keepin\u2019 to ourselves.", "While the group created this resource in order to share knowledge, limiting what they share is just as important to their project. It also recalls Farid\u2019s tactic of explaining some aspects of his research but keeping others private to maintain an advantage.", "Last week, after I had already started trying to piece this article together, I attended a talk by Sri Krishnamurthy, founder of QuantUniversity.com, titled \u201cModel Governance in the age of Data Science and AI.\u201d He talked about the challenges surrounding reproducibility in code, as well as the importance of interpretability and transparency in codebase.", "I was especially interested to learn more about Model Risk Management as defined by the Federal Reserve\u2019s SR 11\u20137. The document defines \u201cmodel risk\u201d as \u201cthe potential for adverse consequences from decisions based on incorrect or misused model outputs and reports.\u201d Although the document is clearly geared towards financial institutions in its examples of adverse consequences (financial loss or \u201cdamage to a banking organization\u2019s reputation\u201d), it does provide guidelines for mitigating risk that could help inform practices elsewhere.", "If we shift thinking about adverse consequences in terms of impact on people instead of the impact on business, we might start heading in the right direction. (I can already hear the laughter at this line. This article could pivot in a whole other direction at this point, but I\u2019ll keep moving forward.)", "In yet another piece covering OpenAI\u2019s release of GPT-2, technology writer Aaron Mak restates the issue I was thinking through above:", "Machine learning practitioners have not yet established many widely accepted frameworks for considering the ethical implications of creating and releasing A.I.-enabled technologies.", "If recent history is any indication, trying to suppress or control the proliferation of A.I. tools may also be a losing battle. Even if there is a consensus around the ethics of disseminating certain algorithms, it might not be enough to stop people who disagree.", "While an agreement or widely adopted set of guidelines could help address unintended consequences and other issues discussed here, Mak is right in that it wouldn\u2019t stop actual malicious actors.", "Personally, I am glad OpenAI chose to bring this conversation into the public and find that more important than the model that they did or didn\u2019t release. While I also tend to land on the side of making things open source and sharing information \u2014 for the sake of democratization of technology, transparency, and accountability \u2014 I also understand why people would be wary of releasing technology and information that could be used in ways they didn\u2019t intend. (And I worry about other aspects of open source, but that\u2019s for another time.)", "Thank you for coming on this journey with me. I\u2019m still working to develop my understandings of these issues and clarify where I stand. I would love to hear your thoughts, questions, or feedback on any of this.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Educator | Advocate (Boston, MA) dawngraham.github.io"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F57286070c06c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@dawngraham", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----57286070c06c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----57286070c06c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dawngraham?source=post_page-----57286070c06c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dawngraham?source=post_page-----57286070c06c--------------------------------", "anchor_text": "Dawn Graham"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd54db465fc8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&user=Dawn+Graham&userId=d54db465fc8d&source=post_page-d54db465fc8d----57286070c06c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57286070c06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57286070c06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://blog.openai.com/better-language-models/#sample1", "anchor_text": "OpenAI"}, {"url": "https://blog.openai.com/better-language-models/", "anchor_text": "release of GPT-2"}, {"url": "https://thegradient.pub/openai-please-open-source-your-language-model/", "anchor_text": "open letter"}, {"url": "https://towardsdatascience.com/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8", "anchor_text": "article"}, {"url": "https://www.smartdatacollective.com/how-ai-is-transforming-lending-and-loan-management/", "anchor_text": "loan applications"}, {"url": "https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/", "anchor_text": "court sentencing"}, {"url": "https://beamery.com/blog/ai-recruiting", "anchor_text": "personnel hiring"}, {"url": "https://www.technologyreview.com/s/610192/were-in-a-diversity-crisis-black-in-ais-founder-on-whats-poisoning-the-algorithms-in-our/", "anchor_text": "lack of diversity"}, {"url": "https://medium.com/@racheltho/im-an-ai-researcher-and-here-is-what-scares-me-about-ai-909a406e4a71", "anchor_text": "5 things"}, {"url": "https://towardsdatascience.com/from-faceapp-to-deepfakes-3d1048713da0", "anchor_text": "already written"}, {"url": "https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/will-deepfakes-detection-be-ready-for-2020", "anchor_text": "disrupt"}, {"url": "https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/will-deepfakes-detection-be-ready-for-2020", "anchor_text": "IEEE Spectrum"}, {"url": "https://blog.openai.com/preparing-for-malicious-uses-of-ai/", "anchor_text": "malicious purposes"}, {"url": "https://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072", "anchor_text": "article"}, {"url": "https://www.wired.com/story/these-new-tricks-can-outsmart-deepfake-videosfor-now/", "anchor_text": "piece"}, {"url": "https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth", "anchor_text": "explains"}, {"url": "https://unsplash.com/@cdr6934?utm_source=medium&utm_medium=referral", "anchor_text": "Chris Ried"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.wired.com/story/zeynep-tufekci-facts-fake-news-verification/", "anchor_text": "suggests"}, {"url": "https://www.alliedmedia.org/news/2019/02/07/our-data-bodies-playbook-out", "anchor_text": "released"}, {"url": "https://www.facebook.com/data4blacklives/videos/300185840850038/", "anchor_text": "Data for Black Lives Facebook"}, {"url": "https://www.facebook.com/data4blacklives/videos/300185840850038/", "anchor_text": "closing panel"}, {"url": "https://www.linkedin.com/in/srikrishnamurthy/", "anchor_text": "Sri Krishnamurthy"}, {"url": "https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm", "anchor_text": "SR 11\u20137"}, {"url": "https://slate.com/technology/2019/02/openai-gpt2-text-generating-algorithm-ai-dangerous.html", "anchor_text": "another piece"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----57286070c06c---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----57286070c06c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deepfakes?source=post_page-----57286070c06c---------------deepfakes-----------------", "anchor_text": "Deepfakes"}, {"url": "https://medium.com/tag/openai?source=post_page-----57286070c06c---------------openai-----------------", "anchor_text": "OpenAI"}, {"url": "https://medium.com/tag/surveillance?source=post_page-----57286070c06c---------------surveillance-----------------", "anchor_text": "Surveillance"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57286070c06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&user=Dawn+Graham&userId=d54db465fc8d&source=-----57286070c06c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57286070c06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&user=Dawn+Graham&userId=d54db465fc8d&source=-----57286070c06c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57286070c06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----57286070c06c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F57286070c06c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----57286070c06c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----57286070c06c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----57286070c06c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----57286070c06c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----57286070c06c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----57286070c06c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----57286070c06c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----57286070c06c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----57286070c06c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dawngraham?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dawngraham?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dawn Graham"}, {"url": "https://medium.com/@dawngraham/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "160 Followers"}, {"url": "http://dawngraham.github.io", "anchor_text": "dawngraham.github.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd54db465fc8d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&user=Dawn+Graham&userId=d54db465fc8d&source=post_page-d54db465fc8d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe33867b165c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopenai-deceptive-technology-and-model-risk-management-57286070c06c&newsletterV3=d54db465fc8d&newsletterV3Id=e33867b165c4&user=Dawn+Graham&userId=d54db465fc8d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}