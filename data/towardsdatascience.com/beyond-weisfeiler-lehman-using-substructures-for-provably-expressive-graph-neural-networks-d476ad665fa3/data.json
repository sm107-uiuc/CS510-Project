{"url": "https://towardsdatascience.com/beyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3", "time": 1683010269.8940318, "path": "towardsdatascience.com/beyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3/", "webpage": {"metadata": {"title": "Beyond Weisfeiler-Lehman: using substructures for provably expressive graph neural networks | by Michael Bronstein | Towards Data Science", "h1": "Beyond Weisfeiler-Lehman: using substructures for provably expressive graph neural networks", "description": "This is the second in the series of posts on the expressivity of graph neural networks. See Part 1 describing the relation between graph neural networks and the Weisfeiler-Lehman graph isomorphism\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49", "anchor_text": "Part 1", "paragraph_index": 0}, {"url": "https://medium.com/@michael.bronstein/beyond-weisfeiler-lehman-approximate-isomorphisms-and-metric-embeddings-f7b816b75751", "anchor_text": "Part 3", "paragraph_index": 0}, {"url": "https://kazemnejad.com/blog/transformer_architecture_positional_encoding/#what-is-positional-encoding-and-why-do-we-need-it-in-the-first-place", "anchor_text": "positional encoding", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Reconstruction_conjecture", "anchor_text": "Graph Reconstruction Conjecture", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Cycle_(graph_theory)#:~:text=In%20graph%20theory%2C%20a%20cycle,is%20called%20an%20acyclic%20graph", "anchor_text": "cycles", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Path_(graph_theory)", "anchor_text": "paths", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Clique_(graph_theory)", "anchor_text": "cliques", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Cyclic_compound#:~:text=A%20cyclic%20compound%20(ring%20compound,connected%20to%20form%20a%20ring.", "anchor_text": "very frequent pattern", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Simple_aromatic_ring", "anchor_text": "aromatic ring", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Caffeine", "anchor_text": "caffeine", "paragraph_index": 13}, {"url": "https://aaai.org/ojs/index.php/AAAI/article/view/4384/4262", "anchor_text": "Weisfeiler and Leman go neural: Higher-order graph neural networks", "paragraph_index": 14}, {"url": "https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf", "anchor_text": "The reduction of a graph to canonical form and the algebra which appears therein", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1811.04801", "anchor_text": "On Weisfeiler-Leman invariance: subgraph counts and related graph properties", "paragraph_index": 16}, {"url": "https://arxiv.org/abs/2002.04025", "anchor_text": "Can graph neural networks count substructures?", "paragraph_index": 16}, {"url": "https://watermark.silverchair.com/bth436.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAq8wggKrBgkqhkiG9w0BBwagggKcMIICmAIBADCCApEGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM0dSVWoaQCCLbBJ-PAgEQgIICYnENSgyWT9FgCVosBTOeyyRmtWw4j9wHSvqt30AJoJBqzNoYzfJYrIdCyr1V7WepOWMZssTNQjPgiiBJGGsLDvzPnB7jfm4OF8X91JfMutgrioFxqvxaClQapirh65l4WBv9e9kqbErrMfahpd-Jx23l3jEx-KVHkneVqUEHqDNQngE1z4Y31EY8YirDNjscsBtpFcfvu4M0TaYX62WrNcUfUalAqhWBpA56gSrqffkSiG_htHXGjYLCyOI-TtyW8EmZ_y3QmTkyK8JN1eaZxeyXlxkB9xadNFWJP7bbl0PQKfJDYSwXm4jZWD9QUMsO9PaJc66VmksFv-J4B3dsMi5F2mPlE7_M-7lhLJHOgw46tJ6IuUmRS3la3pDtpqouN9n4kMXavOxavrFCiqH2t0QMw9pnuSnxYcD5ioohSs9WxO7gqS6BOiY6AP-Q7QjoX-ILY9haHSTOo90I3FTTjeIbD9zL3M6P4pBmaJzOzoyBLUsZtQRS-2vcqkJE-S36O-EaqWJeNP3keGYMT37chw3N62NzEmFTquuUqS3OTQM1z2p26GBqprknPKPy4FkowA_s67kHzYJFn860neEJCkoOm6-Dm--Dr7SuEXBfydf39XEBVpqC_IkaNl8hL630qr2MnKxDCwCsNt4aFum8hTuL89-EarI_YoBzq9zwIgQJyXZiNU7mVqlgq9LXGgcB-iTwtDHmoEc3JmEKv4zOaeXY4iGqUjbiQq5-14_Av-Kz0UujdV9oADUj2Q2kYagvQZMelDI7fIqRS-sk8VdRtRzeknChefIBp4j92dqbEdsJRAQ", "anchor_text": "Modeling Interactome: Scale-free or geometric?", "paragraph_index": 17}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2623288/", "anchor_text": "Uncovering biological network function via graphlet degree signatures", "paragraph_index": 19}, {"url": "http://proceedings.mlr.press/v5/shervashidze09a/shervashidze09a.pdf", "anchor_text": "Efficient graphlet kernels for large graph comparison", "paragraph_index": 19}, {"url": "https://arxiv.org/abs/1101.5211", "anchor_text": "The Weisfeiler-Lehman method and graph isomorphism testing", "paragraph_index": 22}, {"url": "https://www.infoq.cn/article/N49r0yKY3kQ6PxehJMFi", "anchor_text": "Chinese translation", "paragraph_index": 23}, {"url": "https://medium.com/@zhiyongliu", "anchor_text": "Zhiyong Liu", "paragraph_index": 23}, {"url": "https://towardsdatascience.com/graph-deep-learning/home", "anchor_text": "blog", "paragraph_index": 23}, {"url": "https://michael-bronstein.medium.com/subscribe", "anchor_text": "subscribe", "paragraph_index": 23}, {"url": "https://michael-bronstein.medium.com/membership", "anchor_text": "Medium membership", "paragraph_index": 23}, {"url": "https://twitter.com/mmbronstein", "anchor_text": "Twitter", "paragraph_index": 23}], "all_paragraphs": ["This is the second in the series of posts on the expressivity of graph neural networks. See Part 1 describing the relation between graph neural networks and the Weisfeiler-Lehman graph isomorphism test. In Part 3, I argue why we should abandon the graph isomorphism problem altogether.", "Recent groundbreaking papers [1\u20132] established the connection between graph neural networks and the graph isomorphism tests, observing the analogy between the message passing mechanism and the Weisfeiler-Lehman (WL) test [3]. WL test is a general name for a hierarchy of graph-theoretical polynomial-time iterative algorithms for determining graph isomorphism. The k-WL test recolours k-tuples of vertices of a graph at each step according to some neighbourhood aggregation rules and stops upon reaching a stable colouring. If the histograms of colours of the two graphs are not the same, the graphs are deemed not isomorphic; otherwise, the graphs are possibly (but not necessarily) isomorphic.", "Message passing neural networks are at most as powerful as the 1-WL test (also known as node colour refinement), and thus unable to distinguish between even very simple instances of non-isomorphic graphs. For example, message passing neural networks cannot count triangles [4], a motif known to play an important role in social networks where it is associated with the clustering coefficient indicative of how \u201ctightly knit\u201d the users are [5]. It is possible to design more expressive graph neural networks that replicate the increasingly more powerful k-WL tests [2,6]. However, such architectures result in high complexity and large number of parameters, but most importantly, typically require non-local operations that make them impractical.", "Thus, provably powerful graph neural networks based on the Weisfeiler-Lehman hierarchy are either not very powerful but practical, or powerful but impractical [7]. I argue that there is a different simple way to design efficient and provably powerful graph neural networks, which we proposed in a new paper with Giorgos Bouritsas and Fabrizio Frasca [8].", "Graph Substructure Networks. The idea is actually very simple and conceptually similar to positional encoding or graphlet descriptors [9]: we make the message passing mechanism aware of the local graph structure, allowing for computing messages differently depending on the topological relationship between the endpoint nodes. This is done by passing to message passing functions additional structural descriptors associated with each node [10], which are constructed by subgraph isomorphism counting. In this way, we can partition the nodes of the graph into different equivalence classes reflecting topological characteristics that are shared both between nodes in each graph individually and across different graphs.", "We call this architecture Graph Substructure Network (GSN). It has the same algorithmic design and memory and computational complexity as standard message passing neural networks, with an additional pre-computation step in which the structural descriptors are constructed. The choice of the substructures to count is crucial both to the expressive power of GSNs and the computational complexity of the pre-computation step.", "The worst-case complexity of counting substructures of size k in a graph with n nodes is \ud835\udcaa(n\u1d4f). Thus, it is similar to high-order graph neural network models or Morris [2] and Maron [6]. However, GSN has several advantages over these methods. First, for some types of substructures such as paths and cycles the counting can be done with significantly lower complexity. Secondly, the computationally expensive step is done only once as preprocessing and thus does not affect network training and inference that remain linear, the same way as in message-passing neural networks. The memory complexity in training and inference is linear as well. Thirdly and most importantly, the expressive power of GSN is different from k-WL tests and in some cases is stronger.", "How powerful are GSNs? The substructure counting endows GSN with more expressive power than the standard message-passing neural networks. First, it is important to clarify that the expressive power of GSN depends on the graph substructures used. Same way as we have a hierarchy of k-WL tests, we might have different variants of GSNs based on counting one or more structures. Using structures more complex than star graphs, GSNs can be made strictly more powerful than 1-WL (or the equivalent 2-WL) and thus also more powerful than standard message passing architectures. With 4-cliques, GSN is at least no less powerful than 3-WL, as shown by the following example of strongly regular graphs on which GSN succeeds while 3-WL fails:", "More generally speaking, for various substructures of \ud835\udcaa(1) size, as long as they cannot be counted by 3-WL, there exist graphs where GSN succeeds and 3-WL fails [11]. While we could not find examples to the contrary, they might in principle exist \u2014 that is why our statement about the power of GSN is of a weak form, \u201cat least not less powerful\u201d.", "This holds for larger k as well; a generalisation of strongly regular graphs in the above figure, called k-isoregular, are instances on which the (k+1)-WL test fails [12]. These examples can also be distinguished by GSN with appropriate structures. The expressive power of GSNs can thus be captured by the following figure:", "How powerful can GSN be in principle? This is still an open question. The Graph Reconstruction Conjecture [13] postulates the possibility of recovering a graph from all its node-deleted substructures. Thus, if the Reconstruction Conjecture is correct, a GSN with substructures of size n\u22121 would be able to correctly test isomorphism of any graphs. However, the Reconstruction Conjecture is currently proven only for graphs of size n\u226411 [14], and second, such large structures would be impractical.", "The more interesting question is whether a similar result exists for \u201csmall\u201d structures (of \ud835\udcaa(1) size independent of the number of nodes n). Our empirical results show that GSN with small substructures such as cycles, paths, and cliques work for strongly regular graphs, which are known to be a tough nut for the Weisfeiler-Lehman tests.", "Most importantly, GSN builds on top of standard message-passing architectures and thus inherits its locality and linear complexity. The hyperparameters of the method include the structures counted for the construction of the structural descriptors. It is likely that practical applications will be guided by the tradeoff between the required expressive power, the size of the structures that can guarantee it, and the complexity of computing them.", "In our experiments, we observed that different problems and datasets benefit from different substructures, so it is likely that this choice is problem-specific. Fortunately, we often know what substructures matter in some applications. For example, in social networks, triangles and higher-order cliques are common and have a clear \u201csociological\u201d interpretation. In chemistry, cycles are a very frequent pattern, such as 5- and 6-membered aromatic ring that appear in a plethora of organic molecules. The figure below shows an example most of us are familiar with, the molecule of caffeine, whose level in my bloodstream is alarmingly low. This sounds like the right moment to finish this post and make myself a cup of coffee.", "[2] C. Morris et al. Weisfeiler and Leman go neural: Higher-order graph neural networks (2019). Proc. AAAI.", "[3] B. Weisfeiler, A. Lehman, The reduction of a graph to canonical form and the algebra which appears therein, 1968 (English translation)", "[4] Consequently, two graphs with a different number of triangles would be considered possibly isomorphic by the 1-WL test, or equivalently, will have an identical embedding constructed by a message passing neural network. There have been substantial new results extending our understanding of what structures are invariant under WL tests, see e.g. V. Arvind et al. On Weisfeiler-Leman invariance: subgraph counts and related graph properties (2018) arXiv:1811.04801 and Z. Chen et al. Can graph neural networks count substructures? (2020) arXiv:2002.04025.", "[5] Graph substructures have been used in complex networks for decades now. In bioinformatics, the seminal papers of R. Milo et al. Network motifs: simple building blocks of complex networks (2002). Science 298 (5594):824\u2013827. and N. Pr\u017eulj et al. Modeling Interactome: Scale-free or geometric? (2004) Bioinformatics 20(18):3508\u20133515 introduced graph motifs and graphlets for the analysis of biological interaction networks. In social networks, the study of triangular motifs dates back to at least P. W. Holland and S. Leinhardt, Local structure in social networks (1976). Sociol. Methodol. 1\u201345.", "[7] The 3-WL-equivalent graph neural network architecture of Morris has \ud835\udcaa(n\u00b3) space- and \ud835\udcaa(n\u2074) time complexity. The architecture of Maron has a slightly better \ud835\udcaa(n\u00b2) space- and \ud835\udcaa(n\u00b3) time complexity. For a modestly-sized graph with 1M nodes this still translates into enormous 1TB of memory and an exaflop of computation.", "[9] Graph analysis approaches based on substructure counting obviously predate the recent works on graph deep learning. Notable examples include the graphlet signatures proposed in bioinformatics in T. Milenkovi\u00e6 and N. Pr\u017eulj, Uncovering biological network function via graphlet degree signatures (2008). Cancer Inform. 6:257\u2013273, or graphlet kernels N. Shervashidze et al. Efficient graphlet kernels for large graph comparison (2009). Proc. AISTATS.", "[10] We show the same mechanism for edges as well, which I omit here for brevity.", "[11] 3-WL appears to be rather weak in terms of substructure counting. For example, it can count motif cycles of up to 7 nodes, but fails to count induced 4-cycles or paths of length 4. It is currently not clear what substructure counting capabilities are obtained by going up in the WL-hierarchy.", "[12] B. L. Douglas, The Weisfeiler-Lehman method and graph isomorphism testing (2011). arXiv:1101.5211. Note that there is some level of confusion between what different references call \u201ck-WL\u201d. Douglas uses the term k-WL for what others call (k\u22121)-FWL (\u201cfolklore\u201d WL). In our terminology, k-WL fails on (k\u22121)-isoregular graphs. Strongly regular graphs are 2-isoregular.", "I am grateful to Luca Belli, Giorgos Bouritsas, and Fabrizio Frasca for their help with proofreading this post. A Chinese translation of this post is available courtesy of Zhiyong Liu. Interested in Graph Deep Learning? See my blog on Towards Data Science, subscribe to my posts, get Medium membership, or follow me on Twitter.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "DeepMind Professor of AI @Oxford. Serial startupper. ML for biochemistry, drug design, animal communication."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd476ad665fa3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://michael-bronstein.medium.com/?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": ""}, {"url": "https://michael-bronstein.medium.com/?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "Michael Bronstein"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b1129ddd572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&user=Michael+Bronstein&userId=7b1129ddd572&source=post_page-7b1129ddd572----d476ad665fa3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd476ad665fa3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd476ad665fa3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49", "anchor_text": "Part 1"}, {"url": "https://medium.com/@michael.bronstein/beyond-weisfeiler-lehman-approximate-isomorphisms-and-metric-embeddings-f7b816b75751", "anchor_text": "Part 3"}, {"url": "https://kazemnejad.com/blog/transformer_architecture_positional_encoding/#what-is-positional-encoding-and-why-do-we-need-it-in-the-first-place", "anchor_text": "positional encoding"}, {"url": "https://en.wikipedia.org/wiki/Strongly_regular_graph", "anchor_text": "strongly regular graphs"}, {"url": "https://mathematicaladd.wordpress.com/2017/02/06/visualizing-the-difference-between-the-4x4-rooks-graph-and-the-shrikhande-graph/", "anchor_text": "Shrikhande graph"}, {"url": "https://en.wikipedia.org/wiki/Reconstruction_conjecture", "anchor_text": "Graph Reconstruction Conjecture"}, {"url": "https://en.wikipedia.org/wiki/Cycle_(graph_theory)#:~:text=In%20graph%20theory%2C%20a%20cycle,is%20called%20an%20acyclic%20graph", "anchor_text": "cycles"}, {"url": "https://en.wikipedia.org/wiki/Path_(graph_theory)", "anchor_text": "paths"}, {"url": "https://en.wikipedia.org/wiki/Clique_(graph_theory)", "anchor_text": "cliques"}, {"url": "https://en.wikipedia.org/wiki/Cyclic_compound#:~:text=A%20cyclic%20compound%20(ring%20compound,connected%20to%20form%20a%20ring.", "anchor_text": "very frequent pattern"}, {"url": "https://en.wikipedia.org/wiki/Simple_aromatic_ring", "anchor_text": "aromatic ring"}, {"url": "https://en.wikipedia.org/wiki/Caffeine", "anchor_text": "caffeine"}, {"url": "https://en.wikipedia.org/wiki/Caffeine", "anchor_text": "1,3,7-Trimethylxanthine"}, {"url": "https://arxiv.org/abs/1810.00826", "anchor_text": "How powerful are graph neural networks?"}, {"url": "https://aaai.org/ojs/index.php/AAAI/article/view/4384/4262", "anchor_text": "Weisfeiler and Leman go neural: Higher-order graph neural networks"}, {"url": "https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf", "anchor_text": "The reduction of a graph to canonical form and the algebra which appears therein"}, {"url": "https://arxiv.org/abs/1811.04801", "anchor_text": "On Weisfeiler-Leman invariance: subgraph counts and related graph properties"}, {"url": "https://arxiv.org/abs/2002.04025", "anchor_text": "Can graph neural networks count substructures?"}, {"url": "https://watermark.silverchair.com/bth436.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAq8wggKrBgkqhkiG9w0BBwagggKcMIICmAIBADCCApEGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM0dSVWoaQCCLbBJ-PAgEQgIICYnENSgyWT9FgCVosBTOeyyRmtWw4j9wHSvqt30AJoJBqzNoYzfJYrIdCyr1V7WepOWMZssTNQjPgiiBJGGsLDvzPnB7jfm4OF8X91JfMutgrioFxqvxaClQapirh65l4WBv9e9kqbErrMfahpd-Jx23l3jEx-KVHkneVqUEHqDNQngE1z4Y31EY8YirDNjscsBtpFcfvu4M0TaYX62WrNcUfUalAqhWBpA56gSrqffkSiG_htHXGjYLCyOI-TtyW8EmZ_y3QmTkyK8JN1eaZxeyXlxkB9xadNFWJP7bbl0PQKfJDYSwXm4jZWD9QUMsO9PaJc66VmksFv-J4B3dsMi5F2mPlE7_M-7lhLJHOgw46tJ6IuUmRS3la3pDtpqouN9n4kMXavOxavrFCiqH2t0QMw9pnuSnxYcD5ioohSs9WxO7gqS6BOiY6AP-Q7QjoX-ILY9haHSTOo90I3FTTjeIbD9zL3M6P4pBmaJzOzoyBLUsZtQRS-2vcqkJE-S36O-EaqWJeNP3keGYMT37chw3N62NzEmFTquuUqS3OTQM1z2p26GBqprknPKPy4FkowA_s67kHzYJFn860neEJCkoOm6-Dm--Dr7SuEXBfydf39XEBVpqC_IkaNl8hL630qr2MnKxDCwCsNt4aFum8hTuL89-EarI_YoBzq9zwIgQJyXZiNU7mVqlgq9LXGgcB-iTwtDHmoEc3JmEKv4zOaeXY4iGqUjbiQq5-14_Av-Kz0UujdV9oADUj2Q2kYagvQZMelDI7fIqRS-sk8VdRtRzeknChefIBp4j92dqbEdsJRAQ", "anchor_text": "Modeling Interactome: Scale-free or geometric?"}, {"url": "https://arxiv.org/abs/1905.11136", "anchor_text": "Provably powerful graph neural networks"}, {"url": "https://arxiv.org/abs/2006.09252", "anchor_text": "Improving graph neural network expressivity via subgraph isomorphism counting"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2623288/", "anchor_text": "Uncovering biological network function via graphlet degree signatures"}, {"url": "http://proceedings.mlr.press/v5/shervashidze09a/shervashidze09a.pdf", "anchor_text": "Efficient graphlet kernels for large graph comparison"}, {"url": "https://arxiv.org/abs/1101.5211", "anchor_text": "The Weisfeiler-Lehman method and graph isomorphism testing"}, {"url": "https://projecteuclid.org/download/pdf_1/euclid.pjm/1103043674", "anchor_text": "A congruence theorem for trees"}, {"url": "https://www.infoq.cn/article/N49r0yKY3kQ6PxehJMFi", "anchor_text": "Chinese translation"}, {"url": "https://medium.com/@zhiyongliu", "anchor_text": "Zhiyong Liu"}, {"url": "https://towardsdatascience.com/graph-deep-learning/home", "anchor_text": "blog"}, {"url": "https://michael-bronstein.medium.com/subscribe", "anchor_text": "subscribe"}, {"url": "https://michael-bronstein.medium.com/membership", "anchor_text": "Medium membership"}, {"url": "https://twitter.com/mmbronstein", "anchor_text": "Twitter"}, {"url": "https://medium.com/tag/graph-neural-networks?source=post_page-----d476ad665fa3---------------graph_neural_networks-----------------", "anchor_text": "Graph Neural Networks"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d476ad665fa3---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/graph-theory?source=post_page-----d476ad665fa3---------------graph_theory-----------------", "anchor_text": "Graph Theory"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d476ad665fa3---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----d476ad665fa3---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd476ad665fa3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&user=Michael+Bronstein&userId=7b1129ddd572&source=-----d476ad665fa3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd476ad665fa3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&user=Michael+Bronstein&userId=7b1129ddd572&source=-----d476ad665fa3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd476ad665fa3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd476ad665fa3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d476ad665fa3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d476ad665fa3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d476ad665fa3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d476ad665fa3--------------------------------", "anchor_text": ""}, {"url": "https://michael-bronstein.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://michael-bronstein.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Michael Bronstein"}, {"url": "https://michael-bronstein.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.7K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b1129ddd572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&user=Michael+Bronstein&userId=7b1129ddd572&source=post_page-7b1129ddd572--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F936a58357100&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3&newsletterV3=7b1129ddd572&newsletterV3Id=936a58357100&user=Michael+Bronstein&userId=7b1129ddd572&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}