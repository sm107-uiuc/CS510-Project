{"url": "https://towardsdatascience.com/pyspark-demand-forecasting-data-science-project-dae14b5319cc", "time": 1683001036.144563, "path": "towardsdatascience.com/pyspark-demand-forecasting-data-science-project-dae14b5319cc/", "webpage": {"metadata": {"title": "Pyspark \u2013 demand forecasting data science project | by Alexandre Wrg | Towards Data Science", "h1": "Pyspark \u2013 demand forecasting data science project", "description": "In this article, we will build a step-by-step demand forecasting project with Pyspark. Here, the list of tasks: First we will import our data with a predefined schema. I work on a virtual machine on\u2026"}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/docs/2.1.2/api/java/org/apache/spark/mllib/linalg/VectorUDT.html", "anchor_text": "VectorUDT", "paragraph_index": 7}, {"url": "https://spark.apache.org/docs/latest/ml-features#stringindexer", "anchor_text": "String Indexer", "paragraph_index": 16}, {"url": "https://spark.apache.org/docs/latest/ml-features#onehotencoder", "anchor_text": "OneHotEncoder", "paragraph_index": 17}, {"url": "http://en.wikipedia.org/wiki/One-hot", "anchor_text": "One-hot encoding", "paragraph_index": 17}, {"url": "https://spark.apache.org/docs/latest/ml-features.html#stringindexer", "anchor_text": "StringIndexer", "paragraph_index": 17}, {"url": "https://github.com/AlexWarembourg/Medium", "anchor_text": "https://github.com/AlexWarembourg/Medium", "paragraph_index": 28}], "all_paragraphs": ["In this article, we will build a step-by-step demand forecasting project with Pyspark. Here, the list of tasks:", "First we will import our data with a predefined schema. I work on a virtual machine on google cloud platform data comes from a bucket on cloud storage. Let\u2019s import it.", "Then we will apply some filters, we will only work on hypermarkets and make sure that there are no negative quantities or missing date in the data for example.", "Then, we will define some variables that will be useful for modeling, such as date derivatives.", "Now we will calculate the reference quantity for each store i.e. the quantity that was sold for the same day 1 year ago. Nevertheless, it may happen that there has been no sale for this day so we will average a 7-day period around this reference date. this function will be more complex and requires numpy. It\u2019s indeed possible to articulate numpy and spark, let\u2019s see how.", "First, a user-defined function must be defined to extract the time series from each store in a vectorized and sparse way. We will define one that will create a sparse vector indexed with the days of the year and in values the associated quantities", "All right, let\u2019s take a break, he has a few things to explain here.", "The whole thing is passed through an UDF and expected to be a VectorUDT to be concise this is a type of vector that can be manipulated by UDF.", "Then, to respond to the inputs requested by the function we will create an aggregated dataframe per year, store and apply a collect_list to the days and quantities. As you can see below, we recover all the day-quantity values of the store for its year. These two lists enter our UDF to create the desired vector, now we can work in numpy on this vector!", "Now we can define a function that will work on this vector and put it in a UDF again.", "Let\u2019s detail this function, first it tries to find the exact reference day, we have attached our dataframe on itself with its previous year so we want the current days to be equal to the index days in the vector and get the value. In case it is not possible to retrieve this value then we will define a window around this key date and average the values of this window.", "But instead of leaving them hard coded like that, we\u2019re going to wrap everything in a Spark Pipeline. To do this we will create a class template that inherits from the Spark Transformer object like the one below and we will repeat this template for each variable. I\u2019m not going to write the whole feature\u2019s pipeline in this article but you can find it in the code on github. We will see at the end of this article how to put together this feature\u2019s pipeline and insert it into the process.", "Let\u2019s check if there\u2019s some missing values.", "There may not be any more but there could be some after the insertion of our new variables so we will define an Imputer that will come after the variable creation pipeline.", "From this table extract below I will show you how we will proceed for the rest of the data transformations before insertion into the forecast algorithm.", "We will do the whole process in one go at the very end only.", "Spark String Indexerencodes a string column of labels to a column of label indices. The indices are in [0, numLabels) the mapping is done by the highest frequency first.", "Spark\u2019s OneHotEncoder One-hot encoding maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. For string type input data, it is common to encode categorical features using StringIndexer first.", "Before executing our pipeline, let\u2019s check if there are any missing values that can be annoying in our process. Before running our dimensional reduction algorithm we must pass all our variables in a vector assembler that will return a sparse representation of all our data. Then the PCA algorithm will take this vector to \u201creduce\u201d it and return another sparse representation in a dataframe column.", "We saw how to index, one-hot encode our data, apply an PCA and put everything in a vector ready to be modeled. There are obviously other possibilities to Standardize, normalize\u2026etc. nevertheless the global principle remains the same. Now our feature Inpure have the good shape to be modeled througout a Pyspark Algorithm.", "We will train a gradient boosted trees model to do a regression on total qty sold by day by store.", "We will define a python object that we use as a basis to evaluate our model on different metrics.", "Model seems not bad we will try to improve it.", "We will try to optimize our GBDT with different parameters and make a kfold to ensure its robustness.", "I only got 0.3 more points but that\u2019s enough! :)", "N.B : In the features_utils package there are all the classes associated with the features pipeline.", "This article concludes my very brief guide on the various bricks of Pyspark for a data science project. I hope they will help even one person in his work. Pyspark is a very powerful tool on large volumes. He does not have the merit of having at his disposal a battery of algorithms like sklearn but he has the main ones and many resources.", "Feel free to let me know about anything you would like me to do with Pyspark and thank you !", "You can find the code here : https://github.com/AlexWarembourg/Medium", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist at Auchan Retail Data"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdae14b5319cc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@alexandrewrg?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexandrewrg?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "Alexandre Wrg"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa5f80e627a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&user=Alexandre+Wrg&userId=a5f80e627a47&source=post_page-a5f80e627a47----dae14b5319cc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdae14b5319cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdae14b5319cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg", "anchor_text": "https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg"}, {"url": "https://spark.apache.org/docs/2.1.2/api/java/org/apache/spark/mllib/linalg/VectorUDT.html", "anchor_text": "VectorUDT"}, {"url": "https://towardsdatascience.com/pyspark-wrap-your-feature-engineering-in-a-pipeline-ee63bdb913", "anchor_text": "https://towardsdatascience.com/pyspark-wrap-your-feature-engineering-in-a-pipeline-ee63bdb913"}, {"url": "https://spark.apache.org/docs/latest/ml-features#stringindexer", "anchor_text": "String Indexer"}, {"url": "https://spark.apache.org/docs/latest/ml-features#onehotencoder", "anchor_text": "OneHotEncoder"}, {"url": "http://en.wikipedia.org/wiki/One-hot", "anchor_text": "One-hot encoding"}, {"url": "https://spark.apache.org/docs/latest/ml-features.html#stringindexer", "anchor_text": "StringIndexer"}, {"url": "https://github.com/AlexWarembourg/Medium", "anchor_text": "https://github.com/AlexWarembourg/Medium"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dae14b5319cc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dae14b5319cc---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/spark?source=post_page-----dae14b5319cc---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/python?source=post_page-----dae14b5319cc---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/big-data?source=post_page-----dae14b5319cc---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdae14b5319cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&user=Alexandre+Wrg&userId=a5f80e627a47&source=-----dae14b5319cc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdae14b5319cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&user=Alexandre+Wrg&userId=a5f80e627a47&source=-----dae14b5319cc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdae14b5319cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdae14b5319cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dae14b5319cc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dae14b5319cc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dae14b5319cc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dae14b5319cc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexandrewrg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexandrewrg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alexandre Wrg"}, {"url": "https://medium.com/@alexandrewrg/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "354 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa5f80e627a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&user=Alexandre+Wrg&userId=a5f80e627a47&source=post_page-a5f80e627a47--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7c3751d086ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpyspark-demand-forecasting-data-science-project-dae14b5319cc&newsletterV3=a5f80e627a47&newsletterV3Id=7c3751d086ca&user=Alexandre+Wrg&userId=a5f80e627a47&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}