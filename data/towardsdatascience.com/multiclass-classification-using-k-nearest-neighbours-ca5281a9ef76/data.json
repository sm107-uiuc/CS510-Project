{"url": "https://towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76", "time": 1683016035.515187, "path": "towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76/", "webpage": {"metadata": {"title": "MultiClass Classification Using K-Nearest Neighbours | by Vatsal Sheth | Towards Data Science", "h1": "MultiClass Classification Using K-Nearest Neighbours", "description": "Classification is a classic machine learning application. Classification basically categorises your output in two classes i.e. your output can be one of two things. For example, a bank wants to know\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Classification is a classic machine learning application. Classification basically categorises your output in two classes i.e. your output can be one of two things. For example, a bank wants to know whether a customer will be able pay his/her monthly investments or not? We can use machine learning algorithms to determine the output of this problem, which will be either Yes or No(Two classes). But what if you want to classify something that has more than 2 categories and isn\u2019t as simple as a yes/no problem?", "This is where multi-class classification comes in. MultiClass classification can be defined as the classifying instances into one of three or more classes. In this article we are going to do multi-class classification using K Nearest Neighbours. KNN is a super simple algorithm, which assumes that similar things are in close proximity of each other. So if a datapoint is near to another datapoint, it assumes that they both belong to similar classes. To know more deeply about KNN algorithms, I would suggest you go check out this article:", "Now, that we are through all the basics, let\u2019s get to some implementation. We are going to use multiple python libraries like pandas(To read our dataset), Sklearn(To train our dataset and implement our model) and libraries like Seaborn and Matplotlib(To visualise our data). If you don\u2019t already have this libraries install you can install them using pip or Anaconda on your pc/laptop. Or another way that I would personally suggest, use google colab to perform the experiment online with all the libraries pre-installed. The dataset that we are going to be using is called the IRIS flower dataset and it basically has 4 features for it\u2019s 150 data points and is categorised into 3 different species i.e. 50 flowers of each species.The dataset can be downloaded from the following link:", "Now as we get started with our code, the first step to do is to import all the libraries in our code.", "Once you\u2019ve imported the libraries the next step is to read the data.We will use the pandas library for this function. While reading, we will also check if there are any null values as well as the number of different species in the data. (Should be 3 as our dataset has 3 species). We will also assign all the three species categories a particular number, 0,1 and 2.", "Once, that we are now done with importing libraries and our CSV file, the next step we do is exploratory data analysis(EDA). EDA is necessary for any problem as it helps us visualise the data and infer some conclusions initially just by looking at the data and not performing any algorithms. We perform correlations between all the features using the library seaborn as well as plot a scatterplot of all the datasets using the same library.", "After the EDA and before training our model on the dataset, the one last thing left to do is normalisation. Normalisation is basically bringing all the values of different features on a same scale. As different features has different scale, normalising helps us and the model to optimise it\u2019s parameters more efficiently. We normalise all our input from scale: 0 to 1. Here, X is our inputs(hence dropping the classified species) and Y is our output(3 classes).", "Finally, we have reached to the point of training the dataset. We use the built-in KNN algorithm from sci-kit learn. We split the our input and output data into training and testing data, as to train the model on training data and testing model\u2019s accuracy on the testing model. We choose a 80%\u201320% split for our training and testing data.", "Here, we see that the classifier chose 5 as the optimum number of nearest neighbours to classify the data best. Now that we have built the model, our final step is to visualise the results. We calculate the confusion matrix, the precision recall parameters and the overall accuracy of the model.", "We successfully implemented a KNN algorithm for the IRIS datset. We found out the most impactful deatures through out EDA and normalised our dataset for improved accuracy. We got an accuracy of 96.67% with our algorithm as well as we got the confusion matrix and the classification report. From the classification report and the confusion matrix we can see that it misidentifies versicolor as virginica.", "That is how one can do multi-class classification using KNN algorithm. Hope you learned something new and meaningful today.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A lifelong learner! A human being who likes to write and read(a lot!). A technology enthusiast, an inquisitive mind and always eager to learn something new."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fca5281a9ef76&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://vatsalsheth002.medium.com/?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": ""}, {"url": "https://vatsalsheth002.medium.com/?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "Vatsal Sheth"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F526d0233db8b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&user=Vatsal+Sheth&userId=526d0233db8b&source=post_page-526d0233db8b----ca5281a9ef76---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca5281a9ef76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca5281a9ef76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral", "anchor_text": "Markus Spiske"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761", "anchor_text": "Machine Learning Basics with the K-Nearest Neighbors AlgorithmThe k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can\u2026towardsdatascience.com"}, {"url": "https://www.kaggle.com/arshid/iris-flower-dataset", "anchor_text": "Iris Flower DatasetIris flower data set used for multi-class classification.www.kaggle.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ca5281a9ef76---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ca5281a9ef76---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/classification?source=post_page-----ca5281a9ef76---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/knn-algorithm?source=post_page-----ca5281a9ef76---------------knn_algorithm-----------------", "anchor_text": "Knn Algorithm"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fca5281a9ef76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&user=Vatsal+Sheth&userId=526d0233db8b&source=-----ca5281a9ef76---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fca5281a9ef76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&user=Vatsal+Sheth&userId=526d0233db8b&source=-----ca5281a9ef76---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca5281a9ef76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fca5281a9ef76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ca5281a9ef76---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ca5281a9ef76--------------------------------", "anchor_text": ""}, {"url": "https://vatsalsheth002.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://vatsalsheth002.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Vatsal Sheth"}, {"url": "https://vatsalsheth002.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "50 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F526d0233db8b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&user=Vatsal+Sheth&userId=526d0233db8b&source=post_page-526d0233db8b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa081cf1fb389&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulticlass-classification-using-k-nearest-neighbours-ca5281a9ef76&newsletterV3=526d0233db8b&newsletterV3Id=a081cf1fb389&user=Vatsal+Sheth&userId=526d0233db8b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}