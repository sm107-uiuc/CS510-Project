{"url": "https://towardsdatascience.com/how-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042", "time": 1683007088.101613, "path": "towardsdatascience.com/how-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042/", "webpage": {"metadata": {"title": "How to Automate Multiple Excel Workbooks and Perform Analysis | by Shravankumar Suvarna | Towards Data Science", "h1": "How to Automate Multiple Excel Workbooks and Perform Analysis", "description": "Imagine you have been assigned with a task to study suppliers of Mircosoft or Apple and perform analysis for better decision making. This means to study hundreds of suppliers with different formats\u2026"}, "outgoing_paragraph_urls": [{"url": "https://help.pentaho.com/Documentation/7.1/0L0/0Y0/0K0/ETL_Metadata_Injection/Steps_Supporting_MDI", "anchor_text": "here", "paragraph_index": 26}], "all_paragraphs": ["Imagine you have been assigned with a task to study suppliers of Mircosoft or Apple and perform analysis for better decision making. This means to study hundreds of suppliers with different formats, structure, names, etc. Now, that\u2019s a very time-consuming process to collate information from various vendors, standardize and perform analysis on the same, right?", "Besides, we will have to perform the same activity after a certain frequency to understand the newer trends.", "That\u2019s a good use case for us to automate and build a data pipeline. There are multiple approaches which are being used in industry today. Some write python/java programs, some use VBA Macros, some use ETL tools and so on and so forth.", "We will use Pentaho Data Integration (Kettle) a powerful ETL tool to perform this activity. If you are new to this tool, then I would recommend you to go through the post on building the first data pipeline using PDI, here\u2019s the link.", "Let\u2019s write our user stories for the said use case. Writing user stories and creating a storyboard is a good practice to track the status or understand the entire flow using plain English. This helps us in defining the architecture as well.", "As mentioned in the previous piece, user stories are written from a user perspective and below are live examples for our use case.", "These are three simple user stories. However, not an easy use case for most of the programs out there. So, let\u2019s understand how to implement the same using the below step-by-step guide.", "Let\u2019s understand our various suppliers and input data. This will help us design the data pipeline flow.", "Well, you see both these data structures, column order, naming convention are different. However, both are very clean and this will not be the case in a real-world scenario.", "Let\u2019s define our test cases for this pipeline.", "Let\u2019s create the skeleton for our project. We will create the following folders and files. I prefer to store all the work-related stuff in one common folder named Work.", "So, the structure should look like below.", "If you have any difficulty understanding the above steps or Spoon (desktop app), then request you to go through the below link.", "We have read multiple files within multiple folders as per the story. So, let\u2019s do the same. The idea is to loop through each file and perform operations at each file level, makes sense?", "Now, double-click on the widget or right-click and choose edit for adding our custom properties. PDI gives us a lot of configuration options.", "This plugin will give us the list of folders and files within the directory specified; in our case the Input directory.", "Let\u2019s quickly check if it\u2019s giving the desired output by clicking on Preview rows button. Your preview rows should look like below. If it matches, then you can click Close on previous rows and OK on the step to save the changes.", "As you may have observed, we see both files and folders. We require only files for further processing. So, let\u2019s filter the same using \u2018Filter rows\u2019 plugin; again the same process search for the same in Design tab and double-click to directly create hop.", "PDI has named the plugins in the best way possible so that there\u2019s no ambiguity in the same.", "\u2018Filter rows\u2019 is a step used to apply conditional logic and in our case, we want to pass only the rows which are files and not folders. If you observe Preview rows output of our previous step (Get file names), PDI gives us the \u2018type\u2019 column for each row; we can use the same for our logic.", "Now that we have a list of filenames we need to pass this to another transformation, where we will further process the same.", "Here, we need to use the step \u2018Copy rows to result\u2019 plugin/step to copy the list in the memory. Search for the step name and double click the same. We don\u2019t need to add any further configuration.", "We can now save and execute the transformation for unit testing this reading files module.", "We need to create a blank template with all the steps/plugins that we want to use for our data manipulations. So, for our use case, we require only two steps one is the excel reader and other is the excel writer. We need to use ProcessEachInputFile.ktr file here and perform the below steps.", "We will use \u2018Microsoft Excel input\u2019, \u2018Select value\u2019, and \u2018Microsoft Excel writer\u2019 plugins for the same.", "That\u2019s it, we are ready with the template. We don\u2019t need to add any additional properties, we will be injecting the properties like file path, sheet name, field names etc at runtime.", "Please note, all the PDI plugins do not support metadata injection. You can check the plugins/steps which support here.", "We need to create metadata for reading and writing files. Metadata is \u201cdata that describe other data\u201d, in case the information which describes our excel inputs and outputs. We will be storing all the configurable properties in an excel file (this can be sourced from the database as well).", "We will create Metadata.xlsx file in our Metadata Folder with two tabs as mentioned below.", "Please note, that PDI reads files as per the row and column index starting from 0. So we need to make the sure the metadata information is proper as per the input file.", "As mentioned in our user story, we will receive multiple file-formats but for easy workflow maintenance purpose; we would like to build a generalized data pipeline to handle all such scenarios.", "Here, I would like to introduce to the extremely powerful feature of PDI; ETL Metadata Injection.", "Metadata injection - as the name suggests injects metadata/configurable properties to our core logic step. Essentially, it helps to inject properties like which files to read (filename), from where to read (start and end rows/columns), what to do (manipulation), how to save..so on and so forth.", "We will use InjectMetadata.ktr file for injecting meta information as shown below.", "That should be it for the injector transformation. Let\u2019s consolidate and execute the same.", "Finally, we are here at the very last step of connecting the various pieces and executing the main job. As shown above, we will use a job file (Main.kjb) to do the same.", "Jobs should always start with a Step/plugin named \u2018Start\u2019 and end with \u2018Success\u2019 step. Let\u2019s drag these steps with two \u2018Transformation\u2019 steps; one for ReadInputFiles.ktr and another for InjectMetadata.ktr (since we have used our ProcessEachInputFile.ktr within the injector step). Oh yes! I can connect relations now.", "Execute every input row will create our main loop for each file inject metadata and process the same.", "Let\u2019s get the ball rolling and execute our data pipeline.", "We can now check our file in the output directory. Let\u2019s perform testing using the test cases.", "We can now analyze the data as per our requirements.", "Automating multiple excel spreadsheets can be a fun activity. The above implementation is not perfect but will solve our problem statement. We can further generalize this pipeline by adding variables instead of hard-coded values. We can similarly build/customize this pipeline as per our requirements We will take downloading data from email use case next.", "If you like similar content, then I would recommend you to subscribe using the below link.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Constantly learning about new technologies. Nobody."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F13e8aa5a2042&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@shravankumar.suvarna?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shravankumar.suvarna?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "Shravankumar Suvarna"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F77216d1e856b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&user=Shravankumar+Suvarna&userId=77216d1e856b&source=post_page-77216d1e856b----13e8aa5a2042---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13e8aa5a2042&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13e8aa5a2042&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@kmuza?utm_source=medium&utm_medium=referral", "anchor_text": "Carlos Muza"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/swlh/build-your-first-data-pipeline-in-just-ten-minutes-2a490867b901", "anchor_text": "Build Your First Data Pipeline in just Ten MinutesStep-by-step process to build your first data pipeline with a real-world use case using PDI.medium.com"}, {"url": "https://medium.com/ai-in-plain-english/what-is-the-pdi-client-spoon-in-pentaho-data-integration-kettle-df65b33879ac", "anchor_text": "What is the PDI Client (Spoon) in Pentaho Data Integration (Kettle)?Understanding the various features of the Spoon - PDI desktop application. Drag & drop UI helps in reducing the\u2026medium.com"}, {"url": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions", "anchor_text": "regular expression"}, {"url": "https://help.pentaho.com/Documentation/7.1/0L0/0Y0/0K0/ETL_Metadata_Injection/Steps_Supporting_MDI", "anchor_text": "here"}, {"url": "https://wryteex.com/", "anchor_text": "WryteEx - Development, Data Engineering, Project Management and moreI write blogs on Data Engineering, Finance, Python, Python Django, Project Management, Web Development and Many More\u2026wryteex.com"}, {"url": "https://medium.com/tag/data?source=post_page-----13e8aa5a2042---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/programming?source=post_page-----13e8aa5a2042---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----13e8aa5a2042---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/data-science?source=post_page-----13e8aa5a2042---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----13e8aa5a2042---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F13e8aa5a2042&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&user=Shravankumar+Suvarna&userId=77216d1e856b&source=-----13e8aa5a2042---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F13e8aa5a2042&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&user=Shravankumar+Suvarna&userId=77216d1e856b&source=-----13e8aa5a2042---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13e8aa5a2042&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F13e8aa5a2042&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----13e8aa5a2042---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----13e8aa5a2042--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shravankumar.suvarna?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shravankumar.suvarna?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Shravankumar Suvarna"}, {"url": "https://medium.com/@shravankumar.suvarna/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "156 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F77216d1e856b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&user=Shravankumar+Suvarna&userId=77216d1e856b&source=post_page-77216d1e856b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3bf0723f2733&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-automate-multiple-excel-workbooks-and-perform-analysis-13e8aa5a2042&newsletterV3=77216d1e856b&newsletterV3Id=3bf0723f2733&user=Shravankumar+Suvarna&userId=77216d1e856b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}