{"url": "https://towardsdatascience.com/principal-component-analysis-3c39fbf5cb9d", "time": 1683014859.644369, "path": "towardsdatascience.com/principal-component-analysis-3c39fbf5cb9d/", "webpage": {"metadata": {"title": "Principal Component Analysis. Step by step intuition, mathematical\u2026 | by Andrea Grianti | Towards Data Science", "h1": "Principal Component Analysis", "description": "Hi, everybody, my name is Andrea Grianti in Milan, Italy. I wrote this to share my thoughts after many books and papers read on the subject. This is not a textbook but a starting point for further\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Hi, everybody, my name is Andrea Grianti in Milan, Italy. I wrote this to share my thoughts after many books and papers read on the subject. This is not a textbook but a starting point for further understanding of the topic. As the math/algebra behind is rather tough I divided it into four parts:", "If you have a large data sets with thousands/millions of observations (rows) and hundreds of different variables (columns) one of the first objectives is verifying if it\u2019s possible simplifying and reducing the dataset in order to facilitate the analysis work on a much smaller subset of the original data.", "Direct elimination of variables is the obvious way but it has clearly impact on the information content of your data set. Too much or a wrong eliminations and your data set becomes useless, too less and the data set remains large and difficult to analyse.", "The term \u2018information\u2019 is quite a generic subject and it\u2019s difficult to define it. It depends on the data set. A data set could contain information for me and nothing to others and vice versa.", "We could try to define the quantity of information in a data set using concepts like \u201cInformation Content\u201d which is a concept bound to the probability that a specific value, among all those possible in the context of a variable of a data set, happens.", "Following this concept, as much variety of possible outcomes a variable x has, lower is the probability to predict its value and therefore higher the information content is.", "This is our first assumption to keep in mind: higher variance => higher information content. Only the context and our data can tell if this assumption holds.", "Before focusing on the high variance data concept we must deal with a second assumption: correlation between variables is a form of data redundancy. If there\u2019s a clear defined relation between two variables like for example angles in degrees and angles in radians, or temperature in centigrades or farenheit, then one of the two variables are useless and can be eliminated directly from the data set. When instead the dependencies are less clear direct elimination is not recomended and one can try to manage the lack of evidence for correlation through a third assumption.", "The third assumption is: we assume that whatever is the correlation between the variables, this is linear.", "So to recap we are assuming that:", "Why these two assumptions are important ? Because to reduce the dimensionality of a data set we should evaluate the contribution of each variable to the overall variance(=information) of the dataset in order to choose those with the greatest contribution and discard those with lowest contribution.", "The battlefield for this operation is the Covariance Matrix or its brother the Correlation Matrix. Because the Correlation Matrix is strictly bound to the Covariance Matrix by the same relation who binds simple Covariance and Correlation between two variables, I will work with the Covariance Matrix as the choice is not relevant in relation to the understanding of the math principles behind.", "In any case for those who prefer a simple refresh of the covariance and correlation concepts in order to understand the relationship here it is:", "We know that for two variables covariance formula is (in case our dataset is a sample of data taken out of a population):", "Covariance represents a dispersion measure that include the concept of linear \u201csynchronicity\u201d between two variables in relation to their respective means.", "That means measuring, for each point, how the difference between <the x coordinate of a point> and <the mean of all the x points>, is \u201cin synch\u201d with the difference between <the y coordinate for the same point> and <the mean of all the y points> and then averaging that number.", "It\u2019s interesting to note in sample picture above that there are the same number of points on the left and on the right of the average (for dimension x) and there are the same number of points above and below the average (for dimension y).", "This simple example gives you the idea that the covariance is important for the sign. When the result gives you a positive sign or negative sign it gives you an idea of the quadrants where the direction of the synch is. Note also that having the same sign it doesn\u2019t tell you anything about the slope of the direction, but just the quadrants where the direction is.", "If the points instead of going from low-left to up-right, were going from up-left to low-right (reflected along the horizontal line of the means) the covariance would have been the same value but with a negative sign before it.", "If you leave apart for the moment the constant in the above covariance formula, the rest of the equation is the sum of a product of a difference which should remind you (at least for the sum of a product) of the dot product concept in algebra.", "To make it like a dot product between two vectors we can center the data points (you subtract from each variable values the mean of that variable) and we have both the means = 0 while the variance remains unchanged (because shifting all points do not change the distance between the points and dispersion remains the same).", "The covariance formula in that case for centered data simplifies to:", "which contains the definition of the dot product we know is:", "but we know from geometry that the dot product can also be written as:", "Considering that when centered dataalso the variance formula simplifies to:", "Relationship between simple covariance and correlation for two centered variables: sigmas being their standard deviations and rho being the correlation coefficient. At an extreme where correlation is zero, covariance is zero. At the other when correlation is maximum rho=1 or rho=-1, covariance is the product of the standard deviations of each variable.", "Considering that the covariance formula above was just for 2 variables we can see the covariance matrix as the \u201cbig picture\u201d of all the covariances between all of the variables in our data set.", "When we calculate the Variance/Covariance Matrix of our original dataset (we call the original dataset X as a collection of many column vectors X1, X2\u2026Xn) we see the variances along the diagonal but we also see the joint covariances in the off diagonal elements which are a (difficult to interpret) measure of the magnitude of the \u2018synchronicity\u2019 between one variable and the others.", "Because of course we cannot modify our original data X in order to eliminate the correlations between variables (unless we remove completely a variable which is always possible but risky because we could unwillingly remove important information), we can try to find a way to \u2018transform\u2019 X into a different data set Y having special (special=eigen in german language\u2026) link with X but built in a way that the new variables of Y(Y1,Y2\u2026Yn) would have a different Covariance matrix Cy where variances of these variables would be \u201cisolated\u201d from the interefences (correlations) of the other variables (=> covariances = 0).", "This operation is the magic of the eigen decomposition equation. By solving that equation we will find a way to transform the original X data set and by consequence the covariance matrix Cx into a new dataset Y and by consequence a diagonalized covariance matrix Cy using a special transformation matrix we call B. B will be the way we use to go back and forth from X to Y and viceversa.", "Assuming we are able to solve that eigen decomposition equation\u2026 so what ? If using original data X, I was forced to work with Cx with the problem of being unable to isolate single variables contributions to overall variance based on the presence of correlations, now, solving that equation, I could work with a new Y data set whose covariance matrix is Cy and it\u2019s diagonal so the variance contribution of every variable of Y is clearly defined and not impacted from joint intereferences/correlations. With that we can later decide, based on the values of their variances, where to cut the Y data set to keep a subset of the most important Y variables based on the weight of their contribution with respect to the sum of the values of the variances in Cy.", "What\u2019s the price to pay when we work with Y instead of X? Because variables of the new Y data set (we will see this) are a linear combination of the original X data , their meaining is undefined. So to give a contextual meaning to the y variables it\u2019s required a certain acumen to make them \u2018talking\u2019 from a practical stand point. Of course the matter is a bit complex and there are many details we skip here about how to name the new found variables, but to frame the problem and solution this is it.", "In any case to go from X to Y (and from Cx to Cy) we need to understand the logic of the transformation (through a still to be defined B matrix) we can do on our original data. So we need to talk (study) about projections and linear transformations as they are strictly connected.", "Projection concept: in short what we draw in charts depends on the system of coordinates we use to represent the data. Think to perspective in art: it\u2019s a projection of real life measures transformed according to specific rules.", "In 3 dimensions for example we use the cartesian system which is represented by a matrix (E) of orthonormal vectors (orthogonal/perpendicular vectors of length=1).", "When we have for example a data set X (measures are in 3 dimensions: column vectors x1,x2,x3), to calculate the variance of variable x1 we apply the usual formula for variance. But what we actually do is to project the coordinates of each data point of X on the 3 directions in E through a dot product.", "So in general we have X\uff65E=X. This projection operation is \u201ctransparent\u201d with cartesian system and we don\u2019t even realize to do a projection as it is \u201cautomatic\u201d in our minds.", "But if we decide to move away from Cartesian system we can build a similar set of orthonormal vectors that define a new basis B made of b1, b2, b3 (instead of E made of e1, e2, e3) like this:", "And if we dot multiply (for example) a generic row vector of our data set X containing the coordinates of a single data point (single observation if you prefer):", "where each element of this vector has new \u201cmeasures\u201d/\u201dcoordinates\u201d given by:", "In algebra terms and in general in our case we change basis simply with:", "where X is the original data matrix (m rows by n columns) in basis E , B is a new orthonormal basis (n by n),Y (m by n) is the resulting new data matrix with the measures transposed in the new basis B.", "Note that y1,y2,y3 are new variables, whose meaning is NOT related to x1,x2,x3 but they are new and a new meaning must be semantically defined as they are linear combinations of all the X variables weighted by the corresponding components of the b1,b2,b3 vectors of B respectively. That is:", "So if we find a solution for B we could work with the y\u2019s new variables. But what B should we use to reach of our objective to find Y with a Cy diagonal matrix?", "B can be built progressively if we understand that it exists a unique direction that maximizes the variance of the X projected along that direction. We can project a dataset X along the x axis of the cartesian system, but in that case probably the variance is not maximized. Therefore we need to find which is that particular direction. Once we find both the direction and the value of max variance we know we have found the first eigen vector and the first eigen value. In general we can say that we have found the first principal component PC1: y1=X.b1 whose strength is the eigenvalue 1 (lambda 1).", "To evaluate y1 in terms of how much variance explains, at this stage you can divide lambda1 by the sum of the diagonal elements of the covariance matrix Cx because the sum of the total variance does not change from Cx to Cy.", "Then with the same principle we can find the second direction b2 (second eigenvector) as the one that maximize the variance (second eigenvalue) between all the possible projections of X along a second direction of unitary length and orthogonal to b1. When found this is the second principal component: PC2: y2=X.b2", "Then the third direction b3 maximize the variance of X along a third direction defined again by a unit vector that must also be orthogonal to both b2 and b1. When found this is the third principal component: PC3: y3=X.b3", "At the end of these iterations we would have built a special B=[b1*,b2*,b3*] (eigenvector matrix), a new dataset Y =[y1=X.b1, y2=X.b2, y3=X.b3] made of 3 \u2018principal components\u2019 ranked by strength of variance, a special vector of eigenvalues lambdas=(lambda1, lambda2, lambda3) where each lambda is the variance of each y1,y2,y3.", "Of course the iteration can go on up to n dimensions. At the end we have all the elements to reduce Y according to the corresponding weight of every variance over the total variance sum(lambda1,lambda2,lambda3). Hopefully with few variables of Y we can \u201cexplain\u201d a large percentage of the total variance in a way that we can reduce the number of variables but not the amount of information it contains..", "The above was the verbose part to explain a manual iterative procedure to solve the eigen decomposition equation. Now we take a look at the whole mathematical procedure from the start to the solution of the eigen decomposition equation.", "We call X the original data set (m rows x n columns) where each variable in columns have been already \u201ccentered\u201d around their respective means, Cx is the covariance matrix of X, b1 is an unknown vector of n elements and first columns of the to-be B transformation matrix, y1 is a projection of X along a still unknown vector b1: y1=X.b1", "There are many examples and libraries around but here I want to use Python just to show with just numpy code snippets that you can quickly try your sample small dataset and understand what\u2019s going on by looking at the results. I skipped the print statements as you can work on console and check yourself the content of the variables. Even charting is omitted but you can do that as you like with matplotlib or similar. Here the point is not building an app, but showing the understanding of the logic.", "One note on Loadings: Loadings are useful when you want to understand the results. Recall that each new variable of Y is a linear combination of all the X variables. Loadings matrix represents vertically how much of the variance of each PC is explained by each variable x of X: in fact the sum of each column is equal to L, and horizontally how much of the variance of each x is explained by each PC: infact the sum by row is equal to variance of x. An example of using the loadings is given in another story I wrote about FIFA 21 players. Check that out if you want. It\u2019s more fun than this in the end:-).", "Loadings are important for trying to define a name of the PCs in relation to the names of the most relevant x that contribute to the values (scores)of the Principal Components.", "Hi everybody my name is Andrea Grianti, I spent my professionial life in IT and Data Warehousing but I became later more and more passionate with data science and analytics topics.", "Please consider following me in order for me to reach the threshold of number of followers so that Medium platform consider me in their partner program.", "IT Senior Manager and Consultant. Data Warehouse and Business Intelligence expertise in design and build. Freelance."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3c39fbf5cb9d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://andrea-grianti.medium.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Andrea Grianti"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97c02e346ef2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&user=Andrea+Grianti&userId=97c02e346ef2&source=post_page-97c02e346ef2----3c39fbf5cb9d---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c39fbf5cb9d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&user=Andrea+Grianti&userId=97c02e346ef2&source=-----3c39fbf5cb9d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c39fbf5cb9d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&source=-----3c39fbf5cb9d---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3c39fbf5cb9d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----3c39fbf5cb9d---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/unsupervised-learning?source=post_page-----3c39fbf5cb9d---------------unsupervised_learning-----------------", "anchor_text": "Unsupervised Learning"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----3c39fbf5cb9d---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/analytics?source=post_page-----3c39fbf5cb9d---------------analytics-----------------", "anchor_text": "Analytics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c39fbf5cb9d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&user=Andrea+Grianti&userId=97c02e346ef2&source=-----3c39fbf5cb9d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c39fbf5cb9d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&user=Andrea+Grianti&userId=97c02e346ef2&source=-----3c39fbf5cb9d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c39fbf5cb9d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97c02e346ef2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&user=Andrea+Grianti&userId=97c02e346ef2&source=post_page-97c02e346ef2----3c39fbf5cb9d---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa34758c3bc04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&newsletterV3=97c02e346ef2&newsletterV3Id=a34758c3bc04&user=Andrea+Grianti&userId=97c02e346ef2&source=-----3c39fbf5cb9d---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Written by Andrea Grianti"}, {"url": "https://andrea-grianti.medium.com/followers?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "91 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97c02e346ef2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&user=Andrea+Grianti&userId=97c02e346ef2&source=post_page-97c02e346ef2----3c39fbf5cb9d---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa34758c3bc04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprincipal-component-analysis-3c39fbf5cb9d&newsletterV3=97c02e346ef2&newsletterV3Id=a34758c3bc04&user=Andrea+Grianti&userId=97c02e346ef2&source=-----3c39fbf5cb9d---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/cosine-similarity-matrix-using-broadcasting-in-python-2b1998ab3ff3?source=author_recirc-----3c39fbf5cb9d----0---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=author_recirc-----3c39fbf5cb9d----0---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=author_recirc-----3c39fbf5cb9d----0---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Andrea Grianti"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3c39fbf5cb9d----0---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/cosine-similarity-matrix-using-broadcasting-in-python-2b1998ab3ff3?source=author_recirc-----3c39fbf5cb9d----0---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Cosine Similarity Matrix using broadcasting in PythonLearn how to code a (almost) one liner python function to calculate cosine similarity or correlation matrix used in data science."}, {"url": "https://towardsdatascience.com/cosine-similarity-matrix-using-broadcasting-in-python-2b1998ab3ff3?source=author_recirc-----3c39fbf5cb9d----0---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "7 min read\u00b7Dec 7, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2b1998ab3ff3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcosine-similarity-matrix-using-broadcasting-in-python-2b1998ab3ff3&user=Andrea+Grianti&userId=97c02e346ef2&source=-----2b1998ab3ff3----0-----------------clap_footer----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/cosine-similarity-matrix-using-broadcasting-in-python-2b1998ab3ff3?source=author_recirc-----3c39fbf5cb9d----0---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b1998ab3ff3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcosine-similarity-matrix-using-broadcasting-in-python-2b1998ab3ff3&source=-----3c39fbf5cb9d----0-----------------bookmark_preview----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c39fbf5cb9d----1---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3c39fbf5cb9d----1---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3c39fbf5cb9d----1---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3c39fbf5cb9d----1---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c39fbf5cb9d----1---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c39fbf5cb9d----1---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3c39fbf5cb9d----1---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----3c39fbf5cb9d----1-----------------bookmark_preview----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3c39fbf5cb9d----2---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----3c39fbf5cb9d----2---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----3c39fbf5cb9d----2---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3c39fbf5cb9d----2---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3c39fbf5cb9d----2---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3c39fbf5cb9d----2---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3c39fbf5cb9d----2---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----3c39fbf5cb9d----2-----------------bookmark_preview----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/euclidean-distance-matrix-4c3e1378d87f?source=author_recirc-----3c39fbf5cb9d----3---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=author_recirc-----3c39fbf5cb9d----3---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=author_recirc-----3c39fbf5cb9d----3---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Andrea Grianti"}, {"url": "https://medium.com/swlh?source=author_recirc-----3c39fbf5cb9d----3---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "The Startup"}, {"url": "https://medium.com/swlh/euclidean-distance-matrix-4c3e1378d87f?source=author_recirc-----3c39fbf5cb9d----3---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "Euclidean Distance MatrixStep by step explanation to code a \u201cone liner\u201d EDM with basic algebra operations"}, {"url": "https://medium.com/swlh/euclidean-distance-matrix-4c3e1378d87f?source=author_recirc-----3c39fbf5cb9d----3---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": "8 min read\u00b7May 9, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fswlh%2F4c3e1378d87f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Feuclidean-distance-matrix-4c3e1378d87f&user=Andrea+Grianti&userId=97c02e346ef2&source=-----4c3e1378d87f----3-----------------clap_footer----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/euclidean-distance-matrix-4c3e1378d87f?source=author_recirc-----3c39fbf5cb9d----3---------------------0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c3e1378d87f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Feuclidean-distance-matrix-4c3e1378d87f&source=-----3c39fbf5cb9d----3-----------------bookmark_preview----0ee1ff2f_7437_4056_9d3d_b3b02e640b71-------", "anchor_text": ""}, {"url": "https://andrea-grianti.medium.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "See all from Andrea Grianti"}, {"url": "https://towardsdatascience.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://cdanielaam.medium.com/how-to-compare-and-evaluate-unsupervised-clustering-methods-84f3617e3769?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://cdanielaam.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://cdanielaam.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Carla Martins"}, {"url": "https://cdanielaam.medium.com/how-to-compare-and-evaluate-unsupervised-clustering-methods-84f3617e3769?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "How to Compare and Evaluate Unsupervised Clustering Methods?Using Python, Scikit-Learn, and Google Colab"}, {"url": "https://cdanielaam.medium.com/how-to-compare-and-evaluate-unsupervised-clustering-methods-84f3617e3769?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "\u00b720 min read\u00b7Feb 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F84f3617e3769&operation=register&redirect=https%3A%2F%2Fcdanielaam.medium.com%2Fhow-to-compare-and-evaluate-unsupervised-clustering-methods-84f3617e3769&user=Carla+Martins&userId=a1022761a1b&source=-----84f3617e3769----0-----------------clap_footer----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://cdanielaam.medium.com/how-to-compare-and-evaluate-unsupervised-clustering-methods-84f3617e3769?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F84f3617e3769&operation=register&redirect=https%3A%2F%2Fcdanielaam.medium.com%2Fhow-to-compare-and-evaluate-unsupervised-clustering-methods-84f3617e3769&source=-----3c39fbf5cb9d----0-----------------bookmark_preview----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/3-easy-steps-to-perform-dimensionality-reduction-using-principal-component-analysis-pca-79121998b991?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Rukshan Pramoditha"}, {"url": "https://medium.com/data-science-365?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Data Science 365"}, {"url": "https://medium.com/data-science-365/3-easy-steps-to-perform-dimensionality-reduction-using-principal-component-analysis-pca-79121998b991?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "3 Easy Steps to Perform Dimensionality Reduction Using Principal Component Analysis (PCA)Running the PCA algorithm twice is the most effective way of performing PCA"}, {"url": "https://medium.com/data-science-365/3-easy-steps-to-perform-dimensionality-reduction-using-principal-component-analysis-pca-79121998b991?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "\u00b711 min read\u00b7Jan 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-365%2F79121998b991&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2F3-easy-steps-to-perform-dimensionality-reduction-using-principal-component-analysis-pca-79121998b991&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----79121998b991----1-----------------clap_footer----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/3-easy-steps-to-perform-dimensionality-reduction-using-principal-component-analysis-pca-79121998b991?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79121998b991&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2F3-easy-steps-to-perform-dimensionality-reduction-using-principal-component-analysis-pca-79121998b991&source=-----3c39fbf5cb9d----1-----------------bookmark_preview----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/dimensionality-reduction-for-linearly-inseparable-data-5030f0dc0f5e?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Rukshan Pramoditha"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/dimensionality-reduction-for-linearly-inseparable-data-5030f0dc0f5e?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Dimensionality Reduction for Linearly Inseparable DataNon-linear dimensionality reduction using kernel PCA"}, {"url": "https://towardsdatascience.com/dimensionality-reduction-for-linearly-inseparable-data-5030f0dc0f5e?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "\u00b77 min read\u00b7Dec 20, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5030f0dc0f5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdimensionality-reduction-for-linearly-inseparable-data-5030f0dc0f5e&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----5030f0dc0f5e----0-----------------clap_footer----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/dimensionality-reduction-for-linearly-inseparable-data-5030f0dc0f5e?source=read_next_recirc-----3c39fbf5cb9d----0---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5030f0dc0f5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdimensionality-reduction-for-linearly-inseparable-data-5030f0dc0f5e&source=-----3c39fbf5cb9d----0-----------------bookmark_preview----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/everything-about-linear-discriminant-analysis-lda-c22adc8f5ea0?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://ithinkbot.com/?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://ithinkbot.com/?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Dr. Mandar Karhade, MD. PhD."}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/everything-about-linear-discriminant-analysis-lda-c22adc8f5ea0?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Everything about Linear Discriminant Analysis (LDA)All you need to know to conduct Linear Discriminant Analysis."}, {"url": "https://medium.com/geekculture/everything-about-linear-discriminant-analysis-lda-c22adc8f5ea0?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "\u00b76 min read\u00b7Dec 10, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Fc22adc8f5ea0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Feverything-about-linear-discriminant-analysis-lda-c22adc8f5ea0&user=Dr.+Mandar+Karhade%2C+MD.+PhD.&userId=aa38fec37f51&source=-----c22adc8f5ea0----1-----------------clap_footer----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/everything-about-linear-discriminant-analysis-lda-c22adc8f5ea0?source=read_next_recirc-----3c39fbf5cb9d----1---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc22adc8f5ea0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Feverything-about-linear-discriminant-analysis-lda-c22adc8f5ea0&source=-----3c39fbf5cb9d----1-----------------bookmark_preview----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/standard-deviation-vs-standard-error-whats-the-difference-ae969f48adef?source=read_next_recirc-----3c39fbf5cb9d----2---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://aaron-zhu.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----2---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://aaron-zhu.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----2---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Aaron Zhu"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3c39fbf5cb9d----2---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/standard-deviation-vs-standard-error-whats-the-difference-ae969f48adef?source=read_next_recirc-----3c39fbf5cb9d----2---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Standard Deviation vs Standard Error: What\u2019s the Difference?Twins from Different Universes"}, {"url": "https://towardsdatascience.com/standard-deviation-vs-standard-error-whats-the-difference-ae969f48adef?source=read_next_recirc-----3c39fbf5cb9d----2---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "\u00b77 min read\u00b7Nov 1, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fae969f48adef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstandard-deviation-vs-standard-error-whats-the-difference-ae969f48adef&user=Aaron+Zhu&userId=fbd30d6294e5&source=-----ae969f48adef----2-----------------clap_footer----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/standard-deviation-vs-standard-error-whats-the-difference-ae969f48adef?source=read_next_recirc-----3c39fbf5cb9d----2---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae969f48adef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstandard-deviation-vs-standard-error-whats-the-difference-ae969f48adef&source=-----3c39fbf5cb9d----2-----------------bookmark_preview----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3c39fbf5cb9d----3---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----3---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----3c39fbf5cb9d----3---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Erdogan Taskesen"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3c39fbf5cb9d----3---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3c39fbf5cb9d----3---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "From Data to Clusters; When is Your Clustering Good Enough?Sensible clusters and hidden gems can be found using clustering approaches but you need the right cluster evaluation method!"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3c39fbf5cb9d----3---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": "\u00b717 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----5895440a978a----3-----------------clap_footer----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3c39fbf5cb9d----3---------------------367df68a_96ec_4cb1_9555_bf80eacf7f03-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&source=-----3c39fbf5cb9d----3-----------------bookmark_preview----367df68a_96ec_4cb1_9555_bf80eacf7f03-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----3c39fbf5cb9d--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}