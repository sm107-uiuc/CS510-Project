{"url": "https://towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609", "time": 1683005481.5624452, "path": "towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609/", "webpage": {"metadata": {"title": "Stylistic differences between R and Python in modelling data through regression analysis | by Nicola Giordano | Towards Data Science", "h1": "Stylistic differences between R and Python in modelling data through regression analysis", "description": "How to code in R and Python to model data through different types of regressions and produce predictions according to different types of target variables"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-neural-networks-1156627ed07e", "anchor_text": "Neural Networks", "paragraph_index": 0}, {"url": "https://levelup.gitconnected.com/stylistic-differences-between-r-and-python-in-modelling-data-through-decision-trees-ea6f7c98e6e8", "anchor_text": "Decision Trees", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-the-na\u00efve-bayes-classifier-b7a30e6a1715", "anchor_text": "Bayes Theorem", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Regression_analysis", "anchor_text": "Wikipedia", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Ordinary_least_squares", "anchor_text": "Wikipedia", "paragraph_index": 5}, {"url": "https://statisticsbyjim.com/regression/ols-linear-regression-assumptions/", "anchor_text": "source", "paragraph_index": 6}], "all_paragraphs": ["A core step in a data science methodology is to model data through either a classification, clustering or estimation task. At that end, there is a wide array of methods and algorithms to explore. This blog gives a basic introduction in R and Python to different types of regression analysis which is an important addition to other approaches presented before (Neural Networks, Decision Trees, Bayes Theorem). Regression analysis is a task that helps us to approximate the relationship between different types of predictors and target variables according to a set of statistical consideration.", "In statistical modelling, regression analysis is a set of statistical processes for estimating the relationships between a dependent variable (often called the \u2018outcome variable\u2019) and one or more independent variables (often called \u2018predictors\u2019, \u2018covariates\u2019, or \u2018features\u2019). (Wikipedia)", "Regression models can be used for causal analysis and cross-validation, which represent two very different scopes. In absence of an experiment, a regression cannot lead to a statement of causality yet it can be used for cross-validation purposes, which improves the predictive accuracy of a relationship and the internal validity of a model. Causal inference would instead require a model that includes all relevant predictors instead of an observational study with a limited set of explanatory factors. Therefore, a simple lag variable or one correlated with an outcome could produce a model validated in multiple samples without necessarily leading to causal inference.", "In other words, a regression analysis can be used for cross-validation to ensure the repeatability in predictions. On the other hand a regression analysis can establish causal links on a wider population and relates to the external validity of an experiment. Causal inference would require a sample structure mirroring an experimental design and clear logical connectors underpinned by thematic expertise.", "A regression can be simple or multiple. A simple regression only considers one predictor whereas a multiple expands the analysis to include more than one factor. A linear multiple regression is a parametric model, defined by the equation shown below where x represent the predictor variables and the various \u03b2etas represent the unknown model parameters, whose values are estimated using the available evidence.", "The Ordinary least squares (OLS) notation defines a linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of predictors by the principle of least squares. OLS minimizes the sum of the squares of the differences between the observed target variable in a given dataset and those predicted by the linear function. The formula below shows the residual for the i-th observation y measures the vertical distance between the data point (xi, yi) and the hyperplane. This formula is meant to assess the degree of fit between the actual data and the model. The formula below shows the residual for the i-th observation y measures the vertical distance between the data point (xi, yi) and the hyperplane.(Wikipedia) This formula is meant to assess the degree of fit between the actual data and the model.", "In addition, the application of OLS relies on the following assumptions which are necessary to validate the use of this method (adapted from this source):1. The regression model is linear in the coefficients and the error term, which means that its functional form follows a set of parameters rather than the ability to model curvature2. The error term has a population mean of zero, a constant in the regression model forces the mean of the residuals to equal zero3. All independent variables are uncorrelated with the error term therefore a OLS model does not attribute any variance to its error4. Observations of the error term are uncorrelated with each other and information does not predict the error term for a subsequent observation5. The error term has a constant variance (no heteroscedasticity) as it does not change for each observation or for a range of observations6. No independent variable is a perfect linear function of other explanatory variables (absence of multicollinearity)7. The error term is normally distributed, if the residuals follow the line on a normal probability plot it means they are normally distributed", "The following example is based on a random generated dataset so might not fulfill the following assumptions but still worth to consider in order to learn the code behind various computations in regression modelling. Yet, analysing the behaviour of the distribution and of the mean for a specific target variable would inform the type of regression to utilise.", "The starting point in Python to start building a OLS regression is to upload the relevant libraries, among which statsmodels.api represents the most defining one to produce the regression results. Statsmodels allows users to explore data, estimate statistical models, and perform statistical tests. An extensive list of descriptive statistics, statistical tests, plotting functions, and result statistics are available for different types of data and each estimator", "Secondly, uploading or creating a relevant dataframe is the basis to carry out the analysis. In the case of a regression analysis it would be best to select variables based on thematic relevance. In this example, the prediction of how much assistance is received (Y) is explored as a function of a combination of predictors like type of shock, location and duration.", "In order to build a OLS model, it is necessary to convert all categorical variables into numerical ones by encoding their labels. The command to achieve this conversion in Python would be le.fit_transform. In addition, we can split the dataframe by using the train_test_split command into a train and test one to ease the validation process of the estimations.", "Once the dataframe is uploaded or generated, we would need to define the predictor variables and the target one. In Python, this can be simply done by specifying the predict variables and the target one between two square brackets. Once the variables are clearly defined, we would need to add a constant value to the regression through sm.add_constant. Then, the regression results can be easily retrieved by running the sm.OLS command. The output is well detailed and provides a range of statistical values that can be subject to further interpretation. In this case, the model is created out of a random generation of values therefore it has very limited explanatory power.", "To validate the analysis from the whole dataset, we can run the same regression on a test dataset. In Python, we would be using a similar code with the only difference of extracting the variables from df_test. The results appear to be similar. None of the variables have a significant coefficient, underlining that this output is just meant to exemplify the code to be used.", "Differently, from the previous example in Python in R we do not have to upload a number of packages to produce a OLS output. Therefore, the first step in R is the creation or the upload of a relevant dataframe as the basis to carry out the analysis. Like in the previous example, the prediction of assistance received (Y) is going to be explored as a function of a series of predictors. We can also transform a numeric target variable into a categorical one by specifying attributes through the commands as .", "To transform the target variable into a zero and one value, we can rely on a double transformation as.numeric to as.factor in order express the variable in a viable form to run a regression. Subsequently, we can split the dataframe into a test and training one through the command runif.", "Once the dataframe is ready and the relevant variables are encoded into numerical factors, the formula does not need to externalise the specification of the variables. In R, the lm command prompts the option to define all relevant variables and dataframe directly within the formula. On the other hand, the output is less detailed and does not specify a range of other statistical parameters like the one in Python. Again, the model does not yield any significant coefficient since it is a random generation.", "To validate the analysis, we can run the same regression on a test dataset. Similarly to Python, also in R we would be using a similar code with the only difference of extracting the variables from df_testinside the function. The result of the model appears to be similar. None of the variables have a significant coefficient and the R square is only slightly higher.", "The regression models can be evaluated by looking at various dimensions like the mean absolute error, the prediction of the target variable given a set of parameters and the square root of the scale parameter of the model. All these derivations can indicate the position of a predictive element or its behaviour.", "In order to generate predictions (estimates) for the target variable, a simple predict command in Python can generate the series of estimated value.", "After the generation of the predictor, in Python we can calculate the mean absolute error through the mean_absolute_error command in sklearn.metrics. The mean absolute error takes the distance between the actual and predicted values of y and finds the average of these distances. This is an important metric suggests that if there is a small MAE the model is great at prediction, while a large MAE suggests that your model may have trouble in certain areas. A MAE approximating 0 means that your model is a perfect fit for the predictor of the outputs. In this case the MAE is very high, which implicates the model is not sufficiently adequate.", "In order to verify in Python the estimation of a target variable according to a specific set of parameters, the np.column_stackproduces an array that once inserted in the predict command yields the target value according to the position provided for each parameter. In this case the parameters would be represented by: value of the constant (1), duration (from 0 to 12), income loss amount(from 0 to 1000), location (0,1) and type of shock (0,1,2).", "Finally, Python also allows us to easily calculate the positive square-root of an array through the np.sqrt command applied to the regression model in order to calculate the standard error. The mean square error of an estimator measures the average of the squares of the errors \u2014 that is, the average squared difference between the estimated values and the actual value. This is another important proxy of fitness and can be used to analyse whether the error in the regression is accurate, especially if approximates zero.", "In R, the generation of predictions for the target variable can be activated through the predict command. This is very similar to Python, the stylistic difference here, as observed in other cases, is to internalise within brackets the specification of the various parameters.", "In R, the computation of the MAE is contained in the homonym command MAE applied to the predicted and true target values. This is very similar to the sklearn.metric in Python. To conduct a model estimation this value can be compared between the training and test dataset to confirm its validity. The output below the code only represents the one for the whole dataset.", "To calculate the standard error, the lm output in R already has this detail. In fact, as it can be seen below, the residual standard error is part of the visual output generated by the model itself. This is a special feature in R and cannot be found in the same way in Python.", "In addition, R also has the option to run a stepwise regression while Python does not have this pre-coded command. This is a method of fitting regression models in which the choice of predictive variables is carried out by an automatic procedure. In each step, a variable is considered for addition to or subtraction from the set of explanatory variables based on some pre-specified criterion. The output shows the Akaike Information Criterion (AIC) which is an estimator of out-of-sample prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection.", "In addition to linear regression models, there are another set of regression models that take into account of different types of target variables. The OLS models are usually suitable for continuous variables whilst GLM are suitable when the predictor is either a binary or a numeric discrete response. When the target variable has a normal distribution for each set of predictor variable values then we can use a linear regression model.", "On the other hand, if we are trying to predict a binary response variable (like a Yes or No scenario), the link function for a binary response set to a linear predictor would be a logarithmic function as expressed in the equation below.", "Then, to isolate the mean we could use an exponential function normalised in a way to yield a value always between 0 and 1. In other words, the value of a regression model should be used as probability of the target variable to be 1.", "Working backwards we would then be able to formulate a model in parametric form by equating the target variable with the extension of the full notation of the exponential function. This formula represents therefore the logistic regression suitable for a binary target value.", "As an example of a logistic regression in Python, we can specify one binary variable like location (1=Urban, 0= Rural) and a set of numerical predictors. Then, the sm.Logit command activates the generation of an output that in this case although does not lead to a powerful model in explanatory terms it can still be used as an example for reference.", "In R, a similar formula as before and the target variable is a binary one. In this case, we would specify glm before the brackets and the family type. This specification seems quite important since it also provides the opportunity to adjust to other types of regression models based on the nature of the target variable without changing the formula in a significant way. Importantly, there is no mention of a pseudo R-adjusted value or log likelihood. Instead, the output underlines the AIC and the deviance distribution unlike in Python.", "Another type of target variable could be the count of events, for example, how many months or how many times something happened. The distribution of this variable will be therefore the count of occurrences with a minimum value of zero. The regression model for this type of target variable is Poisson. Below, the various mathematical steps to derive the regression equation. Initially, we would equate the linear predictor with a logarithmic function meant to normalise the distribution. Then, after isolating the mean we are in a position to derive a full parametric function for Poisson regression by using the exponential expression.", "In Python we can easily run a Poisson regression by specifying the target variable in this case as duration in months. Then the specification of the regression seems quite different than the logistic type. We would need to import stattools , then placesm.GL before the bracket and finally declare the family sm.families.Poisson() as part of the regression parameters. The results below shows a strong significance, but should not interpret these values too much since it is a randomly generated dataset.", "In R, the Poisson regression is a simple change of variables and specification of a new family type, namely poisson. No further changes from the previous example in modelling for a logistic regression seem necessary. The output, differently from Python in stattools, leads to more information about the deviance and its behaviour. The output does not show significant relationships with any predictor and as previously stated, this is a randomly generated dataset just for illustrative purposes.", "The various regressions illustrate different types of models that can be chosen depending on the different nature of the target variable. There are many other considerations to develop an effective model, for example how the target variable is distributed across the various predictors and how the error behaves in different scenarios and over multiple iterations. As well, it is critical to choose variables that are thematically relevant and backed up by technical expertise of previous research. What shown so far should just represent a foundation to keep experimenting with different regression models and learn from the data you have at hands!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Cultivating an interest in applying data science to international humanitarian work and social sciences."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F23fbac7e8609&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nicola1giordano.medium.com/?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": ""}, {"url": "https://nicola1giordano.medium.com/?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "Nicola Giordano"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fadb15a4025fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&user=Nicola+Giordano&userId=adb15a4025fb&source=post_page-adb15a4025fb----23fbac7e8609---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23fbac7e8609&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23fbac7e8609&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/data-science-stylistics", "anchor_text": "D"}, {"url": "https://towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-neural-networks-1156627ed07e", "anchor_text": "Neural Networks"}, {"url": "https://levelup.gitconnected.com/stylistic-differences-between-r-and-python-in-modelling-data-through-decision-trees-ea6f7c98e6e8", "anchor_text": "Decision Trees"}, {"url": "https://towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-the-na\u00efve-bayes-classifier-b7a30e6a1715", "anchor_text": "Bayes Theorem"}, {"url": "https://pixabay.com/illustrations/artificial-intelligence-brain-think-4469138/", "anchor_text": "source 1"}, {"url": "https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svghttps://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg", "anchor_text": "source 2"}, {"url": "https://en.wikipedia.org/wiki/Linear_regression#/media/File:Thiel-Sen_estimator.svg", "anchor_text": "source 3"}, {"url": "https://en.wikipedia.org/wiki/Regression_analysis", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Ordinary_least_squares", "anchor_text": "Wikipedia"}, {"url": "https://statisticsbyjim.com/regression/ols-linear-regression-assumptions/", "anchor_text": "source"}, {"url": "https://medium.com/tag/regression?source=post_page-----23fbac7e8609---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/tag/python?source=post_page-----23fbac7e8609---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/r?source=post_page-----23fbac7e8609---------------r-----------------", "anchor_text": "R"}, {"url": "https://medium.com/tag/data-science-stylistics?source=post_page-----23fbac7e8609---------------data_science_stylistics-----------------", "anchor_text": "Data Science Stylistics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----23fbac7e8609---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F23fbac7e8609&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&user=Nicola+Giordano&userId=adb15a4025fb&source=-----23fbac7e8609---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F23fbac7e8609&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&user=Nicola+Giordano&userId=adb15a4025fb&source=-----23fbac7e8609---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F23fbac7e8609&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F23fbac7e8609&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----23fbac7e8609---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----23fbac7e8609--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----23fbac7e8609--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----23fbac7e8609--------------------------------", "anchor_text": ""}, {"url": "https://nicola1giordano.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nicola1giordano.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nicola Giordano"}, {"url": "https://nicola1giordano.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "32 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fadb15a4025fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&user=Nicola+Giordano&userId=adb15a4025fb&source=post_page-adb15a4025fb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe1fd4032bc28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstylistic-differences-between-r-and-python-in-modelling-data-through-regression-analysis-23fbac7e8609&newsletterV3=adb15a4025fb&newsletterV3Id=e1fd4032bc28&user=Nicola+Giordano&userId=adb15a4025fb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}