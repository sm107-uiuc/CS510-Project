{"url": "https://towardsdatascience.com/mathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f", "time": 1683002651.716585, "path": "towardsdatascience.com/mathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f/", "webpage": {"metadata": {"title": "Mathematical Analysis of Reinforcement Learning \u2014 Bellman Optimality Equation | by Vaibhav Kumar | Towards Data Science", "h1": "Mathematical Analysis of Reinforcement Learning \u2014 Bellman Optimality Equation", "description": "Reinforcement learning has achieved remarkable results in playing games like StarCraft (AlphaStar) and Go (AlphaGO). At the core of all these successful projects lies \u2014 The Bellman optimality\u2026"}, "outgoing_paragraph_urls": [{"url": "https://brilliant.org/wiki/cauchy-sequences/", "anchor_text": "this website", "paragraph_index": 19}, {"url": "https://en.wikipedia.org/wiki/L-infinity", "anchor_text": "L-infinity", "paragraph_index": 37}, {"url": "https://towardsdatascience.com/reinforcement-learning-temporal-difference-sarsa-q-learning-expected-sarsa-on-python-9fecfda7467e#eccc", "anchor_text": "Reinforcement learning: Temporal-Difference, SARSA, Q-Learning & Expected SARSA in python", "paragraph_index": 44}, {"url": "https://github.com/TimeTraveller-San/RL_from_scratch", "anchor_text": "RL_from_scratch", "paragraph_index": 44}], "all_paragraphs": ["Reinforcement learning has achieved remarkable results in playing games like StarCraft (AlphaStar) and Go (AlphaGO). At the core of all these successful projects lies \u2014 The Bellman optimality equation for Markov decision processes (MDPs).", "The Bellman optimality equation is a recursive equation that can be solved using dynamic programming (DP) algorithms to find the optimal value function and the optimal policy. In this article, I will try to explain why the Bellman optimality equation can solve every MDP by providing an optimal policy and perform an easy (hopefully) mathematical analysis of the same.", "Despite my best efforts, the analysis is going to be fairly rigorous and I assume the readers to be familiar with the following perquisites:", "If you have studied RL and MDPs, you must\u2019ve encountered the claim: \u201cFor each MDP, there is always at least one policy that is better than or equal to all other policies.\u201d This occurs both in Sutton and Barto\u2019s book as well as in the lecture series by David Silver. Reading/Hearing this makes the claim pretty intuitive, however, I had to dig in deeper and understand this in a more concrete manner. Therefore, in this article, I will mathematically prove the following theorem:", "Theorem: For any finite MDP, there exists an optimal policy \u03c0* such that it is better than or equal to every other possible policy \u03c0.", "Before finding the best policy, we need to understand the ordering of policies. When is one policy (\u03c01) considered better than the other (\u03c02)?", "If the value of a state derived using \u03c01 is better than or equal the value of a state derived using \u03c02 for every state in the environment, then the policy \u03c01 is said to be better than policy \u03c02. Mathematically, this can be written as follows:", "Now that we know how to compare policies, we need to prove that there always exists a policy that is better than all other policies.", "We are going to prove this using the Banach fixed point theorem by showing that the Bellman optimality operator is a contraction over a complete metric space of real numbers with metric L-infinity norm. For this, we will first discuss the fixed point problem and complete metric spaces with respect to the Cauchy sequence.", "The above paragraph sounds very intimidating but its actually going to be pretty easy and intuitive once we get past the basic terminologies. We will be discussing everything that is in bold in the above paragraph. Let\u2019s follow a bottom-up approach and learn each concept and conquer our fears:", "I am sure most of us are familiar with the problem of finding the roots of an equation. We solve for x such that a function f(x) = 0. However, in a fixed point problem, we solve for x such that f(x) = x. As the name suggests, x is a fixed point, it does not change even on the application of the function. A fixed point problem can be converted into a problem of finding roots by forming another function g(x) = f(x)-x = 0. In fact, even root finding problems can also be converted back to fixed point problems. However, it\u2019s really easy to solve fixed point problems (for special cases) and that is what makes them incredibly interesting and useful (sans the computational overhead).", "To solve a fixed point problem, choose a random starting value of x and repeatedly apply f(x) infinite times. If the function is convergent and you\u2019re lucky, you will find the solution.", "Mathematically, it\u2019s pretty simple, lets first describe a notation:", "Now, if the function is convergent then it must converge to some value, say, x*. This value, x* is indeed the solution to the fixed point problem as shown below:", "Let's choose some arbitrary value x0 and apply the function f(.) on x0 for infinite times to get x*, and then use that to solve the fixed point problem:", "The intuition behind this is pretty simple, if a function has converged at some point then the value of this function at that convergent point will be the convergent point itself. Therefore, the convergent point is the fixed point itself.", "This can also be observed empirically through the notebook below:", "A metric space is simply a set with a metric defined to measure the distance between any two elements of the set. For example, the Euclidean space is a metric space with distance defined as the Euclidean distance in the set of real numbers. Therefore, a metric space M is represented as (X, d) where X is the set and d is some sort of metric. The metric d must satisfy the following properties:", "For a metric space (X, d) the sequence of elements of the set X, (x1, x2, x3\u2026. xn) is a Cauchy sequence if, for every positive real number \u03b5, there exists an integer N such that the following equation holds:", "The mathematical explanation here isn\u2019t very intuitive and needlessly complex. In simple words, a sequence of elements of a metric space is Cauchy if this sequence converges at some point (the distance between them becomes constant). Another great explanation for this is given by this website and goes as follows: \u201cfor any small distance, there is a certain index past which any two terms are within that distance of each other, which captures the intuitive idea of the terms becoming close.\u201d The idea of \u201cterms become close\u201d is the basic intuition behind convergence or the limit of the series.", "A metric space (X, d) is complete if every possible Cauchy sequence of the elements in the set X converges to an element that also belongs to the set X. That is to say, the convergent limit of every Cauchy sequence of the elements of set lies in the set itself. Which is why it\u2019s called \u201ccomplete\u201d.", "A function (or operator or mapping) defined on the elements of the metric space (X, d) is a contraction (or contractor) if there exists some constant \u03b3\u2208[0,1) such that for any two elements of the metric space x1 and x2, the following condition holds:", "This means that after applying the mapping f(.) on the elements x1 and x2, they got closer to each other by at least a factor \u03b3. Also, the smallest value of such a constant \u03b3 is called the Lipschitz constant (this is an important constant for generative adversarial networks). Also, if \u03b3=1, the mapping is no more a contraction but rather a short mapping. Intuitively, it can be observed that the sequential values of the elements are getting closer after applying the contraction mapping.", "This is the heart and soul of our proof. Informally, this theorem says that for a complete metric space, the application of a contractor on the elements of the set, again and again, would eventually get us to an optimal, unique value. We know:", "Formally, this theorem can be formulated as:", "Theorem: Let (X, d) be a complete metric space and a function f: X->X be a contractor then, f has a unique fixed point x*\u2208 X (i.e. f(x*)=x*) such that the sequence f(f(f(\u2026f(x)))) converges to x*.", "Now, to prove this mathematically, we need to prove both the uniqueness and existence of x*.", "Also, note that f is a contractor so it must hold the following property:", "Now since \u03b3\u2208[0,1), it\u2019s impossible to satisfy both equation 1 and 2 simultaneously. Therefore our assumption must be wrong. Hence, by contradiction, x* must be unique.", "2. Existence: Now that we\u2019ve proved that x* is unique, we need to prove that x* exists. Let (x1, x2, x3, \u2026. xn) be the sequence formed by repeatedly applying the contractor.", "If we assume that the sequence (x1, x2, x3, \u2026. xn) is Cauchy, we know for certain that this sequence will converge to some point, say, x*. Also, since the metric space is complete, this convergent point,x* will belong to the metric space (X,d). Now, we just need to prove that this sequence is Cauchy. We will do this by taking two elements of the set xn and xm such that m>>n and, m is very large, then by repeatedly applying the triangular inequality property of the metric d, we have:", "Now, since f is a contractor, we know that:", "We can further reduce d(xm, xn) as follows:", "Now, by choosing n to be sufficiently large, we can make the RHS of the above equation less than any positive real number \u03b5. Hence, the sequence (x1, x2, x3, \u2026. xn) is Cauchy and an optimal x*\u2208X exists. This concludes the proof of the Banach fixed point theorem.", "For the value function, V(s) we define a new operator, the optimal Bellman operator,B which takes in a value function and returns another value function. We define this operator as follows:", "It can easily be observed, B is a recursive operator. Therefore, this will generate a sequence of value functions. If we can show that B is indeed a contractor for some metric space (X,d) then by the Banach fixed point theorem, we can conclude that the repeated application of the optimal Bellman operator will eventually give a unique optimal value function using which an optimal (best) policy can be derived. Therefore, all our work now reduces to proving that B is a contractor. First, let's define the metric space as follows:", "Metric space (X,d): The set X is the set of real numbers defined as follows:", "For the metric, we use the L-infinity norm defined as follows:", "According to this metric, the distance between the two value functions will be equal to the highest element-wise absolute difference between the two. Also, for finite MDPs with finite rewards, the value functions will always stay in the real space. It is impossible for the value function to not be in the real space, therefore, this finite space will always be complete.", "Theorem: Bellman operator B is a contraction mapping in the finite space (R, L-infinity)", "Proof: Let V1 and V2 be two value functions. Then:", "Finally, for the Bellman optimality equation, since \u03b3\u2208[0,1) (let's ignore the possibility of \u03b3=1 for now), the Bellman operator is, therefore, a contractor.", "Hence, by the Banach fixed point theorem, we conclude that there exists a unique optimal value function V* for every MDP. Using this V*, we can derive the optimal policy \u03c0*.", "Hence proved, for any finite MDP, there exists an optimal policy \u03c0* such that it is better than or equal to every other possible policy \u03c0.", "Now, how to find this optimal policy and value function? One way is to just repeatedly apply the Bellman operator to a random initial value function to get the optimal function. But, this is computationally very expensive and often downright infeasible. Therefore, we use iterative methods like value and policy iteration or temporal difference methods like Q-Learning or SARSA. For more on this, please refer to my blog Reinforcement learning: Temporal-Difference, SARSA, Q-Learning & Expected SARSA in python or just view these algorithms on my Github: RL_from_scratch.", "We learned some basic mathematical tools like metric spaces, complete metric spaces, Cauchy sequences, contraction mapping and the Banach fixed point theorem. Building upon all of this, we mathematically proved the unique optimality of the Bellman optimality equation for every MDP.", "I have tried to explain everything in as simple words as possible. If I was unclear or if I made some mistakes, please let me know in the responses. Also, there might be some mistakes in the latex equations. Please let me know if you find them. Last but not least, thanks for reading!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "An actual Time Traveller from the past"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fac9f0954e19f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@timetraveller1998?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@timetraveller1998?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "Vaibhav Kumar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30121c857f6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&user=Vaibhav+Kumar&userId=30121c857f6c&source=post_page-30121c857f6c----ac9f0954e19f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac9f0954e19f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac9f0954e19f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://brilliant.org/wiki/cauchy-sequences/", "anchor_text": "this website"}, {"url": "https://en.wikipedia.org/wiki/L-infinity", "anchor_text": "L-infinity"}, {"url": "https://towardsdatascience.com/reinforcement-learning-temporal-difference-sarsa-q-learning-expected-sarsa-on-python-9fecfda7467e#eccc", "anchor_text": "Reinforcement learning: Temporal-Difference, SARSA, Q-Learning & Expected SARSA in python"}, {"url": "https://github.com/TimeTraveller-San/RL_from_scratch", "anchor_text": "RL_from_scratch"}, {"url": "https://latex.codecogs.com/eqneditor/editor.php", "anchor_text": "https://latex.codecogs.com/eqneditor/editor.php"}, {"url": "https://www.cs.cmu.edu/~ninamf/courses/401sp18/prev.shtml", "anchor_text": "CMU 15\u2013781"}, {"url": "http://therisingsea.org/notes/mast30026/lecture14.pdf", "anchor_text": "notes"}, {"url": "https://www.youtube.com/watch?v=gsM7PPBx16k", "anchor_text": "video"}, {"url": "https://www.youtube.com/channel/UCZvMhJ3EaNvpacdlMmm3VKA", "anchor_text": "The free NPTEL course"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ac9f0954e19f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----ac9f0954e19f---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ac9f0954e19f---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----ac9f0954e19f---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac9f0954e19f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&user=Vaibhav+Kumar&userId=30121c857f6c&source=-----ac9f0954e19f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac9f0954e19f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&user=Vaibhav+Kumar&userId=30121c857f6c&source=-----ac9f0954e19f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac9f0954e19f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fac9f0954e19f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ac9f0954e19f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ac9f0954e19f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@timetraveller1998?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@timetraveller1998?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Vaibhav Kumar"}, {"url": "https://medium.com/@timetraveller1998/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "419 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30121c857f6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&user=Vaibhav+Kumar&userId=30121c857f6c&source=post_page-30121c857f6c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe2e0c2d3e1ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f&newsletterV3=30121c857f6c&newsletterV3Id=e2e0c2d3e1ba&user=Vaibhav+Kumar&userId=30121c857f6c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}