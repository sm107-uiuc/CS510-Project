{"url": "https://towardsdatascience.com/understanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708", "time": 1683006027.061364, "path": "towardsdatascience.com/understanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708/", "webpage": {"metadata": {"title": "Why Gradient Descent Works for Linear Regression | by Trisha Ray | Towards Data Science", "h1": "Why Gradient Descent Works for Linear Regression", "description": "When I first started self-teaching myself machine learning, I was surprised to learn that I already had some background in it. I had only taken one intro level computer science class in college, so I\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab", "anchor_text": "3Blue1Brown linear algebra series", "paragraph_index": 0}, {"url": "https://web.stanford.edu/~boyd/cvxbook/", "anchor_text": "Convex Optimization textbook", "paragraph_index": 1}], "all_paragraphs": ["When I first started self-teaching myself machine learning, I was surprised to learn that I already had some background in it. I had only taken one intro level computer science class in college, so I was expecting a much higher learning curve. My past linear algebra class was coming in handy as well as the 3Blue1Brown linear algebra series (highly recommend). What I wasn\u2019t expecting to come in handy was my class on optimization. This is probably because I took that class before I knew anything about machine learning and therefore immediately forgot any of the obvious relationships between the two that were mentioned in class. But when I started learning about linear regression, I still remember seeing the words \u201cgradient descent\u201d and thinking, \u201cwait, I already know what this is.\u201d The theory of convexity made it easy to understand why we could use gradient descent to solve the linear regression cost function. In this post, I hope to cover the basics of that theory and offer a deeper understanding of linear regression.", "Let\u2019s start by defining convexity through convex sets and convex functions. Stephen Boyd\u2019s Convex Optimization textbook is a great resource for this topic. A convex set is defined as follows:", "Intuitively, in two dimensions, we can think of a convex set as a shape where no matter what line you draw connecting two points in the set, no part of the line will be outside of the set.", "This definition of a convex set plays right into the definition of a convex function shown below:", "As stated in the Convex Optimization textbook, you can intuitively think of a convex function as one where if you draw a line from (x,f(x)) to (y,f(y)), then the graph of the convex function will be below that line. Below are three examples where we apply this intuition to determine if the function is convex.", "We can see that the graph in the middle is not convex because when we draw a line segment connecting two points on the graph, there are some points (x,f(x)) were f(x) is greater than the corresponding point on the line segment.", "The graphs on the left and right are both convex. Whatever line segment you draw on these graphs, that line segment is always above or equal to the function graph. The graph on the right has many minimizers while the graph on the left has an unique minimizer. An unique minimizer means that there is only one point at which the function is at a minimum. Since the graph on the left is a quadratic function, the unique minimizer can easily be found by taking the derivative of the function.", "Now that we have some intuition and understanding of convex sets and convex functions, let\u2019s turn to linear regression and see where convexity plays a role.", "The purpose of linear regression is to fit the best linear model to a set of data. Let\u2019s say there are m data samples that are in n-dimensional space. Each of these samples have n features that map to a single output value. We have access to the input and output data, but we want to figure out if there is a linear relationship that maps the input data to the output data. This is where the linear regression model comes in. This model is written in the form:", "Now the way we determine the best linear model is to solve for the coefficients of the model that minimize the error between our estimated output values and the real output values. We can use linear least squares to achieve this. Therefore, our cost function is as follows:", "We call this function a \u201ccost\u201d function because we are calculating the total error or cost between our estimate and the real value. Since the linear least squares problem is a quadratic function, we could minimize this cost function analytically. However, with a large dataset, it is often computationally faster to use an iterative method known as gradient descent to find the best coefficients. A breakdown of how gradient descent is used to minimize the cost function is shown below:", "Now let\u2019s get into some convex optimization theory. Gradient descent, as shown above, is applied to find a global minimum to the cost function. But how do we know a global minimum exists? When minimizing a function, a convex function ensures that if a minimum exists, it will be the global minimum. We saw earlier that a quadratic function is a convex function. Since we know that the linear least squares problem is a quadratic function, we also know that it is a convex function.", "What is more is that a quadratic function, such as the linear least squares problem, is strongly convex. This mean that the function has a unique minimum and that minimum is the global minimum. Therefore, when we apply the gradient descent algorithm, we can be confident that it will converge on the correct minimizer. If the function we were trying to minimize was non-convex, such as the one shown in the image above, gradient descent might instead converge on a local minimum instead of the global minimum. This is why non-convex can be much more difficult to work with. This is important because many machine learning models, most notably neural networks, are non-convex. Below you can see an example of how gradient descent, in its simplest form, doesn\u2019t find the global minimizer.", "Optimization lies at the heart of machine learning. While applying gradient descent to a quadratic function might seem intuitive, it is interesting to see how the theory of convex analysis can prove that intuition. This theory can be expanded to analyze any machine learning model to understand how difficult it might be to solve. As I continue on my machine learning journey, I\u2019m excited to learn about other ways optimization can help illuminate different machine learning concepts.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Master\u2019s Student interested in climate change, power systems, machine learning, and optimization"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faaf763308708&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----aaf763308708--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----aaf763308708--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@trisha14.ray?source=post_page-----aaf763308708--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@trisha14.ray?source=post_page-----aaf763308708--------------------------------", "anchor_text": "Trisha Ray"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8b7062f75cd3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&user=Trisha+Ray&userId=8b7062f75cd3&source=post_page-8b7062f75cd3----aaf763308708---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faaf763308708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faaf763308708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@asarodger?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Asa Rodger"}, {"url": "https://unsplash.com/s/photos/falling-hill?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab", "anchor_text": "3Blue1Brown linear algebra series"}, {"url": "https://web.stanford.edu/~boyd/cvxbook/", "anchor_text": "Convex Optimization textbook"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----aaf763308708---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----aaf763308708---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/gradient-descent?source=post_page-----aaf763308708---------------gradient_descent-----------------", "anchor_text": "Gradient Descent"}, {"url": "https://medium.com/tag/convexity?source=post_page-----aaf763308708---------------convexity-----------------", "anchor_text": "Convexity"}, {"url": "https://medium.com/tag/optimizaiton?source=post_page-----aaf763308708---------------optimizaiton-----------------", "anchor_text": "Optimizaiton"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faaf763308708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&user=Trisha+Ray&userId=8b7062f75cd3&source=-----aaf763308708---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faaf763308708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&user=Trisha+Ray&userId=8b7062f75cd3&source=-----aaf763308708---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faaf763308708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----aaf763308708--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Faaf763308708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----aaf763308708---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----aaf763308708--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----aaf763308708--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----aaf763308708--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----aaf763308708--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----aaf763308708--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----aaf763308708--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----aaf763308708--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----aaf763308708--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@trisha14.ray?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@trisha14.ray?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Trisha Ray"}, {"url": "https://medium.com/@trisha14.ray/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "11 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8b7062f75cd3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&user=Trisha+Ray&userId=8b7062f75cd3&source=post_page-8b7062f75cd3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6ee765f0f024&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-convexity-why-gradient-descent-works-for-linear-regression-aaf763308708&newsletterV3=8b7062f75cd3&newsletterV3Id=6ee765f0f024&user=Trisha+Ray&userId=8b7062f75cd3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}