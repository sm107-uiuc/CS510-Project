{"url": "https://towardsdatascience.com/the-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca", "time": 1683000892.613812, "path": "towardsdatascience.com/the-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca/", "webpage": {"metadata": {"title": "The Unexpected Lesson Within A Jelly Bean Jar | by Victor Saenger | Towards Data Science", "h1": "The Unexpected Lesson Within A Jelly Bean Jar", "description": "A short essay on Collective Computation and Wisdom of the Crowds."}, "outgoing_paragraph_urls": [{"url": "https://diggy.wordpress.com/2007/03/07/how-to-win-a-jellybean-counting-contest/", "anchor_text": "before", "paragraph_index": 3}, {"url": "https://playground.tensorflow.org/", "anchor_text": "this Google Playground", "paragraph_index": 13}, {"url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0226-y", "anchor_text": "Deep-learning: investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data", "paragraph_index": 23}, {"url": "https://www.linkedin.com/in/victor-saenger/", "anchor_text": "https://www.linkedin.com/in/victor-saenger/", "paragraph_index": 25}], "all_paragraphs": ["On a livestock fair in late Victorian Plymouth, England, a statistician with the name of Francis Galton asked around 800 attendees to guess the weight of an ox that was on display. He then calculated the median of all estimates, which ended up being 1207 lbs\u00b9. To his surprise, the measured weight of said ox was 1198 lbs, which put the median estimation at ~0.01% off from the real weight. As Galton himself noted\u00b9:", "\u2026the middlemost estimate expresses the vox populi, every other estimate being condemned as too low or too high by a majority of the voters", "This effectively means that as a group, or as a collection of independent thinkers, we are very, very good estimators.", "As I love Data and Science, I wanted to replicate this experiment myself, so not so long ago I did so at my office in my own way. I conducted the Jelly Bean Jar Game, you might have heard of it before.", "I bought a jar and filled it with exactly 490 beans (yes, I counted them all). Then, like Sir Francis Galton did, I asked 30 of my co-workers to give an estimate of the amount of Jelly Beans in the jar. To my surprise, the distribution of estimates looked like this:", "With a mean estimate of 487, only three Jelly Beans off from the ground truth! With this simple experiment, I was getting more and more convinced that the vox populi or Wisdom of the Crowds\u00b9 \u00b2 is a real thing.", "As a group, we are very good estimators, individually, not so much.", "NOTE: Patient individuals outperformed those that made wild guesses. In my experiment, some individuals measured the volume of the jar and estimated the volume of each jellybean to then extrapolate this to the amount of jellybeans within the jar. Other simply went and said \u201cHmm I don\u2019t know\u2026 1000\u201d (see the figure). Nonetheless all estimations were centered around one value, being the ground truth. Keep this in mind.", "In the rest of this essay I will compare this vox populi principle with one that has kept my interest for a long time. It might sound crazy, but I think Artificial Neural Networks\u00b3 share a common ground with it. Especially because in both cases a collection of parts is given one single task and work together to solve it. I hope that you too feel this way by the end of the text.", "A good way to start this comparison is probably by providing a definition of what neurons do in Artificial Neural Networks. I found this description to be rather compelling and simple to understand\u2074:", "Each neuron receives one or more input signals x 1, x 2, \u2026, x m and outputs a value y to neurons of the next layer and so forth. The output y is a nonlinear weighted sum of input signals.", "Under this point of view then, neurons in an ANN are the individuals of a collective thinking. In fact, the de facto architecture of ANN\u2019s is a collection of connected individual regressors\u00b3. The output of a neuron with n input neurons is defined by\u2075 :", "Each output h then is a function with parameters W and b of the sum of individual linear regressions from all inputs x, which in turn will be the input (after an activation function, usually non-linear\u00b3 \u2076) of the next layer. The neurons collectively and only collectively, solve tasks. Try building an ANN classifier for a complex task with one neuron, you must probably going to fail. This will be like Galton asking one single person to give an estimate of the ox\u2019s weight. The estimation is probably going to be wrong. It is here where ANN\u2019s really work collectively. This concept can be visualized in the next example:", "In the image above the trained NN is taking as input 784 features from the image of a \u201c2\" and will classify it accordingly. The complexity of the system increases drastically with each added neuron, but in turn increases the amount of possible feature permutations that effectively pushes up the performance of the classifier. Add too many though and you will be a victim of overfitting\u2077. I recommend you to visit this Google Playground to understand these and other concepts better where you can see the effect each added (or removed) neuron has on a simple classifier. Try training the model with only the first two features (X\u00b9 and X\u00b2) and see the results. Now do it with more. can you find the minimum amount of neurons needed to get good results? Do you need many neurons/layers to do simple tasks? The answer is no. Will get back to this in a moment.", "Going back to oxen and jelly beans, this will be like finding the minimum amount of individuals required for a very good estimation. Surely asking 10,000 people about the weight of the ox will reduce the error, but at 800 we are already 99% around the ground truth. Increasing the complexity of an algorithm is useful only when the desired output has not been satisfied. From here, computationally speaking will be best to reduce the amount of estimators to find the minimum required to reach the desired performance. The vox populi reduces the cost of the computation once this balance is found. To understand this, we can look at the next figure I quickly made in Python:", "We can create a set of random normal distributions with \u03bc = 1 and \u03c3 = 0.1 while increasing the amount of samples from 10 to 1000. Because we know that the mean ground truth is by design equal to 1, we can then compute the average across these distributions and see how close it gets to \u03bc. As you might have guessed, the more data we have the better, meaning that our estimation gets closer and closer to our ground truth. After infinite samples we reach \u03bc, but this is unpractical for obvious reasons. It might even be that that 1000 samples is too costly for whatever reason and we decide to use the set with 500 points for our analysis, which yields an error that satisfy our needs. It is our sweet spot: general enough to maximize performance, but specific enough to minimize error. Artificial Neural Networks follow a similar (albeit not identical, mind you) principle.", "Although there are some general rules on how many neurons and layers you should use\u2078, choosing these limits is a common problem that I frequently encounter while building Deep Neural Networks. Too many neurons and/or layers for a rather simple problem will probably cause severe overfitting (asking 10,000 individuals about the ox\u2019s weight or using 1000 points or more in our previous example). Too little and you would not be able to generalize your model for blind testing. In a way then (and very generally speaking), ANN\u2019s feel comfortable with a balance of simplicity and complexity.", "Going back to Google\u2019s TensorFlow Playground, we can see that the time it takes for a simple ANN to reach low loss values is short in a very simple classification task:", "Although trivial, this exemplifies perfectly the point I am trying to convey. Test an Training loss reach ~0.05 in about 350 epochs (see values just above the scatter). Now let see what happens with an overly complex ANN classifying the same data and using the same parameters:", "Not even 200 epochs and loss values are still not at the same levels as in the previous example. If we wait long enough though, the network does the job. Following our normal distribution example from previous paragraphs, you could use thousands of points to get a \u201cbetter\u201destimation of \u03bc, but the error would not compensate for the high cost. In this example, the same is happening. Not even thinking about other overfitting problems\u2079, the latter architecture is too costly for such a task. The first architecture does the job perfectly with very low cost, so choosing it over the other is the wiser decision.", "I like to think of AI models, and specifically Deep Neural Networks, as complex systems that should be built as simple as possible. Believe it or not, my Jelly Bean Jar experiment helped understand this principle. Both cases require to partition a certain task (just enough) to collectively solve it. This seems to be the best solution. As Albert Einstein himself noted on a lecture in 1933\u00b9\u2070:", "It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience .", "I can\u2019t argue with that. Can you?", "[4] Koutsoukas, A., Monaghan, K. J., Li, X., & Huan, J. Deep-learning: investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data (2017), Journal of cheminformatics, 9(1), 42.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Specialist settled in Barcelona | PhD in Computer Science | Make Complex Look Simple. LinkedIn: https://www.linkedin.com/in/victor-saenger/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1b6de9c40cca&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@saenger.v?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saenger.v?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "Victor Saenger"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9cd6756abf8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&user=Victor+Saenger&userId=9cd6756abf8c&source=post_page-9cd6756abf8c----1b6de9c40cca---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b6de9c40cca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b6de9c40cca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@patrickian4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Patrick Fore"}, {"url": "https://diggy.wordpress.com/2007/03/07/how-to-win-a-jellybean-counting-contest/", "anchor_text": "before"}, {"url": "https://gfycat.com/altruisticinferiorfantail", "anchor_text": "here"}, {"url": "https://playground.tensorflow.org/", "anchor_text": "this Google Playground"}, {"url": "https://playground.tensorflow.org/", "anchor_text": "TensorFlow Playground"}, {"url": "https://playground.tensorflow.org/", "anchor_text": "TensorFlow Playground"}, {"url": "https://www.nature.com/articles/075450a0", "anchor_text": "Vox populi"}, {"url": "https://towardsdatascience.com/on-the-wisdom-of-crowds-collective-predictive-analytics-302b7ca1c513", "anchor_text": "https://towardsdatascience.com/on-the-wisdom-of-crowds-collective-predictive-analytics-302b7ca1c513"}, {"url": "https://towardsdatascience.com/nns-aynk-c34efe37f15a", "anchor_text": "https://towardsdatascience.com/nns-aynk-c34efe37f15a"}, {"url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0226-y", "anchor_text": "Deep-learning: investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data"}, {"url": "http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/", "anchor_text": "http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/"}, {"url": "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6", "anchor_text": "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6"}, {"url": "https://www.jeremyjordan.me/deep-neural-networks-preventing-overfitting/", "anchor_text": "https://www.jeremyjordan.me/deep-neural-networks-preventing-overfitting/"}, {"url": "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw", "anchor_text": "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw"}, {"url": "https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a", "anchor_text": "https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a"}, {"url": "https://www.nature.com/articles/d41586-018-05004-4", "anchor_text": "Did Einstein really say that?"}, {"url": "https://medium.com/tag/statistics?source=post_page-----1b6de9c40cca---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/visualization?source=post_page-----1b6de9c40cca---------------visualization-----------------", "anchor_text": "Visualization"}, {"url": "https://medium.com/tag/intuition?source=post_page-----1b6de9c40cca---------------intuition-----------------", "anchor_text": "Intuition"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----1b6de9c40cca---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/probability?source=post_page-----1b6de9c40cca---------------probability-----------------", "anchor_text": "Probability"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b6de9c40cca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&user=Victor+Saenger&userId=9cd6756abf8c&source=-----1b6de9c40cca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b6de9c40cca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&user=Victor+Saenger&userId=9cd6756abf8c&source=-----1b6de9c40cca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b6de9c40cca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1b6de9c40cca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1b6de9c40cca---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1b6de9c40cca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saenger.v?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saenger.v?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Victor Saenger"}, {"url": "https://medium.com/@saenger.v/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "87 Followers"}, {"url": "https://www.linkedin.com/in/victor-saenger/", "anchor_text": "https://www.linkedin.com/in/victor-saenger/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9cd6756abf8c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&user=Victor+Saenger&userId=9cd6756abf8c&source=post_page-9cd6756abf8c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F9cd6756abf8c%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-unexpected-lesson-within-a-jelly-bean-jar-1b6de9c40cca&user=Victor+Saenger&userId=9cd6756abf8c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}