{"url": "https://towardsdatascience.com/want-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41", "time": 1683007233.214377, "path": "towardsdatascience.com/want-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41/", "webpage": {"metadata": {"title": "Want to Build Effective Machine Learning Models? | by Mo Daoud | Towards Data Science", "h1": "Want to Build Effective Machine Learning Models?", "description": "AWS ML Best Practices"}, "outgoing_paragraph_urls": [{"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "The Official White Paper on AWS ML Best Practices", "paragraph_index": 0}], "all_paragraphs": ["Less than a month ago (Early April 2020) AWS announced the release of The Official White Paper on AWS ML Best Practices. It\u2019s a 78 pages long white paper full of useful information covering all aspects of machine learning best practices, all the way from defining the problem to analyzing the ML model results.", "In this article, I will summarize the AWS ML Best Practices white paper in a 15-minutes-read article. If you don\u2019t have time to read the full 78 pages white paper then this article is for you. If you\u2019re a beginner in machine learning or professional data scientist or preparing for the AWS ML specialty exam then this article is also for you. I made sure to write this article in a simple easy-to-read and no-jargon language so it can suit everyone.", "Disclaimer: I recommend reading the original white paper to get the full benefit.", "The official AWS ML Best Practices white paper is divided into 3 major parts.", "Together we will go through each of the above-mentioned parts and understand them, here we go.", "The ML Stack can be divided into 3 buckets as shown in the figure below. AWS wants to cater to all expertise levels and democratize ML.", "Bucket 1 AI Services are pre-built services like AWS translate, transcribe, Polly, Rekognition, etc. Users don\u2019t need any ML knowledge to use these services, simple API call and they get their answer.", "Bucket 2 ML services are mainly all flavors of AWS SageMaker, AWS\u2019s ML flagship, users need ML knowledge to use SageMaker\u2019s tools to label data, build, train, deploy, and operate custom ML models. AWS SageMaker is fully managed which means users don\u2019t need to worry about infrastructure because AWS will do the heavy lifting.", "Bucket 3 ML Frameworks & infrastructure which is meant for advanced users. AWS will provide them with containers and compute infrastructure pre-loaded with major open-source frameworks like TensorFlow, PyTorch, MXNet, etc. and they can build their own models from the ground up.", "The ML workload is the end-to-end machine learning process as shown below.", "AWS\u2019s white paper detailed best practices for each step in the process. The first 3 steps are about the business needs, defining the ML question, and collecting data.", "The first step is Business Goal Identification which is basically to take a step back and ask yourself why you are you doing this, is ML even needed here, what Key Performance Indicators (KPI) should you monitor.", "Then comes the ML Problem Framing Step where you define the inputs to give you ML model and the desired output. At this step, you should know if it\u2019s a classification or regression or clustering problem, etc.", "The Data Collection Step follows where you confirm the data availability and gather it in a data lake. I summarized the AWS best practices for these steps in the below figure.", "Once you gathered the data for your ML model it\u2019s time for Data Preparation Step. This step is very important and you should spend a lot of time on it because", "ML models are only as good as the data used to train them.", "Here you should utilize the AWS services like AWS SageMaker to label and prepare your data or AWS GroundTruth which labels raw data and produce high-quality training datasets. You could also utilize AWS Glue which is a fully-managed Extract, Transform, and Load (ETL) service. If you need Hadoop or ApacheSpark or HBase frameworks then you could use AWS EMR.", "Once your data is prepared, the Visualize & Analysis Step is here to help you better understand and identify your data patterns. AWS provides a suite of visualization tools like AWS SageMaker where you can host your Jupyter notebook and use libraries like seaborn or matplotlib or plotly. AWS Athena is a fully managed service that can query your S3 data lake, AWS Kinesis Data Analytics provides real-time analytic capabilities. Finally, AWS QuickSight is a Business Intelligence (BI) tool that offers secure sharing and collaboration for a storyboard.", "Now comes the Feature Engineering Step where you consider every attribute in your dataset and decide how relevant it\u2019s to your model, does it need transformation or extraction. In this step, you could get hit with the curse of dimensionality where you have a big number of relevant features and want to reduce them. Feature engineering is best done with Jupyter notebook withing AWS SageMaker or the built-in data processing containers in SageMaker Processing.", "AWS best practices for these 3 steps are summarized below.", "The last 3 steps of the ML building process are the fun ones, here you will get to see the result of all your hard work.", "By now you have a clean dataset so it\u2019s time for Model Training Step where you select ML algorithm that\u2019s appropriate for your business problem. You will have to tune your model\u2019s hyperparameters to achieve low training error and avoid overfitting & underfitting. Some examples of commonly used hyperparameters are Learning Rate, Number of Epochs, Hidden Layers, Hidden Units, and Activation Functions. You will do all of this using AWS SageMaker where all your data is in an S3 data lake and you can call SageMaker\u2019s API for training. You can also leverage AWS SageMaker debugger to warn you of model training issues like gradient values getting too large or too small. Depending on your expertise level you could use AWS Deep Learning AMI or Deep Learning Containers and run open-source frameworks on them like TensorFlow, PyTorch, MXNet, Horovod, and Keras.", "The step before last is Model & Business Evaluation which are used to determine if the model\u2019s performance and accuracy enable you to achieve your business goals. You could evaluate your model using historical data or live data. In both cases, your model will see data it never saw before during training. For evaluation, you should utilize AWS SageMaker, AWS Deep Learning AMI, or AWS EMR. You could always fine-tune and re-train your model if you\u2019re not satisfied with the results. After you\u2019re satisfied with your model\u2019s results it\u2019s time to deploy it in production.", "Lastly, it\u2019s the time for inference, your model is in deployment and you want to get a prediction from it. Model deployment options include AWS SageMaker where you can API call for inference, you could use AWS SageMaker Inference Pipelines which is very flexible and customizable. Don\u2019t forget to use SageMaker Model Monitor which continuously monitors your ML models in production for input data drifts and deviation on model quality. If you\u2019re using edge or Internet Of Things (IoT) devices then leverage AWS SageMaker Neo to compile on edge devices. You can also use AWS Elastic Inference which allows you to attach a low-cost GPU inference acceleration to any EC2 or SageMaker you\u2019re using.", "AWS best practices of the last 3 steps of the ML process are summarized below.", "In this section of the paper, AWS identifies a set of general design principles to facilitate good ML cloud designs. Let\u2019s look at them.", "The paper then moves to some common scenarios and show their AWS reference architecture implementation. I will break down each scenario into a business problem, implementation, and reference architecture.", "Business Problem Retail store wants to capture and analyze customer demographics with the goal of improving customer engagement and experience.", "Implementation using multiple AWS AI services layer which requires little to no knowledge of ML.", "Reference Architecture leveraging AWS Rekognition for facial analysis sending data to AWS Athena for analyzing facial attribute data, and finally AWS QuickSight for visualization of the analyzed data. Notice here that all of these are fully managed AWS AI services with pre-trained models. The reference architecture shown below can also be applied for text or audio analysis but in these cases instead of AWS Rekognition, you should use AWS Transcribe (audio analysis)or AWS Comprehend (text analysis).", "Built on the same reference architecture is a media analysis use case. Let\u2019s say you want to upload a media file and use multiple AWS AI services to do video & audio analysis. The end goal is a searchable metadata library. The folks at AWS recommend the below reference architecture where they used AWS Step Function to orchestrate the media analysis process and AWS ElasticSearch to make the content searchable.", "Business Problem You want to build your own model on AWS since none of the AWS AI Services fits your need. You want to control the steps of data preparation & analysis, model training & evaluation, and model inference.", "Implementation AWS SageMaker can do all these functionality end-to-end while being fully managed by AWS. AWS Lambda supports event-driven architecture and connects different phases of the ML process together.", "Reference Architecture Assuming Amazon S3 acts as a data lake for raw, modeled, enhanced, and transformed data. AWS recommends the below reference architecture for building your own model and flow from ingestion to inference.", "Business Problem You are launching a targeted marketing campaign and want to send messages to consumers using emails and SMS. You need an ML model to identify correct customers based on historical consumer purchase patterns.", "Implementation AWS Pinpoint is a managed service that can send targeted messages via various channels. Leverage Spark or Hadoop on AWS EMR.", "Reference Architecture The AWS recommended flow using multiple services is shown below.", "Business Problem Think IoT and devices at the edge where you have limited computational power. For example, you want to build a bird species identification on the Edge.", "Implementation AWS IoT Greengrass enables machine learning on edge devices. AWS IoT Greengrass makes it easy to perform ML inference locally on devices, using models that are created, trained, and optimized in the cloud.", "Reference Architecture Shows AWS DeepLens which is AWS\u2019s camera with pre-trained ML models. Keep in mind that AWS supports multiple hardware platforms such as Intel and Invidia through AWS SageMaker Neo, check\u2019s AWS\u2019s website for IoT supported devices. SageMaker Neo has a compiler and a runtime. optimized for certain hardware.", "Business Problem After building your model you should have an easy way to infer the model and get predictions.", "Implementation Use AWS SageMaker Endpoints, these are HTTPS endpoints you can use to make API calls to your model.", "Reference Architecture AWS recommends 4 deployment models according to your needs, I summarized them below.", "AWS has 5 pillars for well-architected frameworks in the cloud in general, this part of the paper looks at these 5 pillars from Machine Learning perspective. I will summarize each of them in a Q&A format.", "This is the ability to run, monitor, and gain insights into systems to deliver business value and to continually improve supporting processes and procedures.", "Best practices for ensuring ML models are effectively integrated into production environments and meet business objectives include ensuring cross-collaboration between teams and training all resources responsible for supporting and maintaining machine learning workloads at base proficiency levels.", "To add clarity for supporting and working with the model version, document the model creation process especially as it relates to assumptions made, the data pre/post-processing required for the model as well as for integrating systems or applications with the model version. SageMaker Notebooks and SageMaker Studio provide managed notebook environments where data scientists can document their development process and experiments. These notebooks can be integrated with source control systems and become a standard part of the documentation created for each model deployed.", "SageMaker Experiments allow you to organize and track iterations of ML models. SageMaker Experiments automatically captures input parameters, configurations, and output artifacts for each model and stores them as experiments. This avoids using manual tracking or building custom tracking solutions to manage the numerous versions of input and output artifacts created and utilized for each iteration of model development.", "The general guideline for creating pipelines includes using an orchestration layer, such as AWS CodePipeline, combined with a logic that is responsible for executing the stages within the pipeline. Use AWS Lambda to create and execute the function-based logic due to its low operational overhead with no servers to manage.", "SageMaker automatically monitors core system metrics and also includes capabilities to setup automatic scaling capabilities for your hosted model to dynamically adjust underlying compute supporting an endpoint based on demand. SageMaker Model Monitor provides the capability to monitor your ML models in production and provides alerts when data quality issues appear. Best practice includes creating a mechanism to aggregate and analyze model prediction endpoint metrics using services, such as Amazon Elasticsearch with built-in support for Kibana for dashboards and visualization.", "Best practices are defined metrics that are indicative of model performance and accuracy, ensuring that there is a mechanism in place to regularly capture those metrics for analysis and alert based on metric thresholds, and assessing whether it\u2019s appropriate to retrain the model. SageMaker Model Monitor can detect model drift when the distribution of data has changed and publish metrics using AWS CloudWatch.", "This includes model evaluation across all dimensions: Business evaluation, ML model evaluation, and system evaluation. Providing centralized visibility to key operational metrics collected allows teams to continuously review and perform a retrospective analysis of your operations over time.", "This is the ability to protect information, systems, and assets while delivering business value.", "Access to all resources used across the various phases of the ML process, including data, algorithms, hyperparameters, trained model artifacts, and infrastructure, must be tightly controlled with least-privileged based access. This can be easily done using AWS IAM.", "A centralized data lake is implemented using AWS Lake Formation on Amazon S3. Securing and monitoring a data lake on Amazon S3 is achieved using a combination of various services and capabilities to encrypt data in transit and at rest and monitor access including granular AWS IAM policies, S3 bucket policies, S3 access logs, AWS CloudWatch, and CloudTrail. Building Big Data Storage Solutions (Data Lakes) for Maximum Flexibility discusses using these various capabilities to build a secure data lake.", "ML model generated at the end of the training phase is typically persisted in Amazon S3. Upload models trained within your VPC to Amazon S3 using a private VPC endpoint. This ensures that the model is transferred to Amazon S3 securely within the AWS network. When a model is trained using Amazon SageMaker, the service encrypts model artifacts and other system artifacts in transit and at rest. SageMaker hosted endpoints provide the added security of protecting your models and invocations using IAM. This enables you to control which IAM users, IAM roles, source VPCs, or IPs can perform inference against your model.", "This is the ability of the system to recover from any kind of service disruption by dynamically acquiring compute resources to mitigate the issue.", "Create a mechanism to enable traceability of changes made to your model as well as changes to prediction endpoints. This allows for faster troubleshooting and reverting to a previous model version if a newer model is not performing as expected. When deploying new models AWS recommends the standard A/B testing strategy. Use AWS Elastic Container Registry (ECR) to host all your container images.", "Follow a defined change management strategy to introduce changes and communicate them to impacted teams and enable traceability of those changes. Manage the deployment of new model versions in the same way that application-level changes are governed and controlled. A change management strategy for ML models must account for how changes are communicated and deployed to help avoid interruptions in service and degradation of model performance and accuracy.", "You must include monitoring on endpoints to identify a threshold that triggers the addition or removal of resources to support current demand. Once a trigger to scale is received, a solution must be in place to scale backend resources supporting that endpoint. Perform load testing against endpoints to be able to validate their ability to scale effectively and serve predictions reliably.", "Accidental deletion is a problem and to protect a model artifact from inadvertent deletion ensure that the model artifact is protected by allowing the only minimum required privileges to use the artifact, implementing additional mechanisms such as MFA for delete by privileged users, and storing a secondary copy of the artifact as required by your defined Disaster Recovery strategy. Also, implementing an artifact versioning strategy allows for the recovery of the specific versioned artifact.", "The best practice is to ensure that an endpoint responsible for hosting model predictions is fully recoverable to a specific version or point in time as defined by your business. The ability to recover a model endpoint requires that all components and configuration used to create that endpoint are included in a managed version control strategy to enable complete recovery pending the unavailability of any component.", "This focuses on the efficient use of computing resources to meet requirements and how to maintain that efficiency as demand changes and technologies evolve.", "Data size, data type, and the selection of an algorithm can have a noticeable effect on which configuration is most effective. When training the same model repeatedly, it\u2019s highly recommended to perform initial testing across a spectrum of instance types to discover configurations that are performant and cost-effective. GPU instances are recommended for the majority of deep learning purposes as training new models is faster on a GPU than a CPU. You can scale sublinearly when you have multi-GPU instances or if you use distributed training across many instances with GPUs. However, it\u2019s important to note that algorithms that train most efficiently on GPUs might not necessarily require GPUs for efficient inference.", "SageMaker manages your production compute infrastructure on your behalf to perform health checks, apply security patches, and conduct other routine maintenance, all with built-in CloudWatch monitoring and logging. SageMaker Model Monitor continuously monitors ML models in production, detects deviations such as data drift that can degrade model performance over time, and alerts you to take remedial actions. Also, SageMaker hosting automatically scales to the performance needed for your application using Application Auto Scaling.", "You have the option of scaling with Amazon Elastic Inference (EI), to increase throughput and decrease the latency for real-time inferences against your deep learning models. Amazon Elastic Inference enables you to attach GPU-powered inference acceleration to any Amazon EC2 instance.", "This is the ability to build and operate cost-aware systems that achieve business outcomes and minimize costs, thus allowing your business to maximize its return on investment.", "Leverage AWS SageMaker Ground Truth which simplifies data labeling tasks using human annotators through Amazon Mechanical Turk, third-party vendors, or their own employees. SageMaker Ground Truth learns from these human annotations in real-time and applies active learning to automatically label much of the remaining dataset, reducing the need for human review. This reduces cost compared to solely human annotation.", "SageMaker notebook instances provide a hosted Jupyter environment that can be used to explore small samples of data. Stop the notebook instances when you are not actively using them. Where practical, commit your work, stop them, and restart them when you need them again. Storage is persisted and you can use lifecycle configuration to automate package installation or repository synchronization.", "Review AWS Marketplace for Machine Learning that offers an ever-growing catalog of machine learning algorithms and models. Models from AWS Marketplace are deployed directly to Amazon SageMaker and allow you to build ML applications quickly. This saves you both the cost and time associated with model development.", "Use SageMaker Training API to create a cluster of managed instances. Using multiple instances in your training cluster enables distributed training which results in faster training time. All instances in the training cluster are automatically terminated when training is complete. When dealing with large volumes of training data, Amazon SageMaker Pipe mode offers significantly better read throughput than the Amazon SageMaker File mode.", "Start by taking into consideration latency, throughput, and cost. Once again, it\u2019s recommended that you start small, scale-out first, and then scale up. Utilize automatic scaling for inference endpoints. Use batch predictions when your model doesn\u2019t need real-time predictions.", "Finally, This was a comprehensive summary of the first AWS ML Well-Architected Frameworks. I tried to summarize it in an easy-read format to suit all ML expertise levels from beginner to advanced. ML could be fun yet complicated, however, following these AWS recommended best practices will help you build better models, further understand ML, and become a better ML specialist. I hope you enjoyed reading this article.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Works in technology, AI enthusiast, loves weightlifting and traveling."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb11f52cd9a41&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mohamed-daoud214.medium.com/?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": ""}, {"url": "https://mohamed-daoud214.medium.com/?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "Mo Daoud"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc60e14ace830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&user=Mo+Daoud&userId=c60e14ace830&source=post_page-c60e14ace830----b11f52cd9a41---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb11f52cd9a41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb11f52cd9a41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "The Official White Paper on AWS ML Best Practices"}, {"url": "https://unsplash.com/photos/1K6IQsQbizI", "anchor_text": "Unsplash"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "AWS ML White Paper"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "AWS ML White Paper"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "AWS ML White Paper"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "AWS ML White Paper"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "AWS ML White Paper"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "AWS ML White Paper"}, {"url": "https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf", "anchor_text": "AWS ML White Paper"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b11f52cd9a41---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/aws?source=post_page-----b11f52cd9a41---------------aws-----------------", "anchor_text": "AWS"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b11f52cd9a41---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----b11f52cd9a41---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/aws-machine-learning?source=post_page-----b11f52cd9a41---------------aws_machine_learning-----------------", "anchor_text": "Aws Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb11f52cd9a41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&user=Mo+Daoud&userId=c60e14ace830&source=-----b11f52cd9a41---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb11f52cd9a41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&user=Mo+Daoud&userId=c60e14ace830&source=-----b11f52cd9a41---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb11f52cd9a41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb11f52cd9a41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b11f52cd9a41---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b11f52cd9a41--------------------------------", "anchor_text": ""}, {"url": "https://mohamed-daoud214.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mohamed-daoud214.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mo Daoud"}, {"url": "https://mohamed-daoud214.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "45 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc60e14ace830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&user=Mo+Daoud&userId=c60e14ace830&source=post_page-c60e14ace830--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2218298b9f0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-to-build-effective-machine-learning-models-aws-recommends-these-steps-to-follow-b11f52cd9a41&newsletterV3=c60e14ace830&newsletterV3Id=2218298b9f0e&user=Mo+Daoud&userId=c60e14ace830&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}