{"url": "https://towardsdatascience.com/the-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929", "time": 1683001081.301502, "path": "towardsdatascience.com/the-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929/", "webpage": {"metadata": {"title": "Game Theory to Interpret Machine Learning Models and Predictions \u2014 The Ultimate Guide | by Marcos Silva | Towards Data Science", "h1": "Game Theory to Interpret Machine Learning Models and Predictions \u2014 The Ultimate Guide", "description": "In this guide you will learn how to use Game Theory to understand what your Machine Learning model is doing inside, as well as give insights into Feature Engineering and debugging."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/interpreting-machine-learning-model-70fa49d20af1", "anchor_text": "Introduction to Interpretability", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/statistical-modeling-the-full-pragmatic-guide-7aeb56e38b36", "anchor_text": "Statistical Modeling \u2014 The Full Pragmatic Guide", "paragraph_index": 1}, {"url": "https://medium.com/swlh/data-science-and-the-data-scientist-db200aac4ea0", "anchor_text": "What is the scope of data science", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/a-brief-history-of-statistics-36cfdac9439f", "anchor_text": "A Brief History of Statistics", "paragraph_index": 2}, {"url": "https://pt.wikipedia.org/wiki/Theory_of_Games_and_Economic_Behavior", "anchor_text": "The Theory of Games and Economic Behavior", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Stable_marriage_problem", "anchor_text": "Stable Marriage Problem", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Airport_problem", "anchor_text": "Airport Problem", "paragraph_index": 9}, {"url": "http://papers.nips.cc/author/scott-m-lundberg-10119", "anchor_text": "Scott M. Lundberg", "paragraph_index": 15}, {"url": "http://papers.nips.cc/author/su-in-lee-8534", "anchor_text": "Su-in Lee", "paragraph_index": 15}, {"url": "http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions", "anchor_text": "article", "paragraph_index": 15}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP", "paragraph_index": 15}, {"url": "https://www.kaggle.com/sn3fru/interpreting-ml-model-with-shapley-value?scriptVersionId=22551189", "anchor_text": "codes available here", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/statistical-modeling-the-full-pragmatic-guide-7aeb56e38b36", "anchor_text": "part 2", "paragraph_index": 18}, {"url": "https://www.kaggle.com/sn3fru/interpreting-ml-model-with-shapley-value?scriptVersionId=22614010", "anchor_text": "kaggle", "paragraph_index": 51}], "all_paragraphs": ["This is the sixth part of the Interpreting ML tutorial. In previous posts we have presented several ways to interpret machine learning models. Of the highly interpretable models, all had their problems, high bias models like Regressions or high variance models as decision trees. We solved the trade-off between bias and variance basically combining several models, especially high variance models, so we had the best models, low bias and low variance and the price to pay is that we no longer have control over how the model is making its decisions or how are the relationships between the variables, ie the model became a BlackBox.", "Part 1 \u2014 Introduction to InterpretabilityPart 2 \u2014Statistical Modeling \u2014 The Full Pragmatic GuidePart 3 \u2014 Interpreting low bias and high variance models.Part 4 \u2014 Is it possible to resolve the trade-off between bias and variance?Part 5 \u2014 Local Methods of Interpretability.Part 6 \u2014 (this post) Global Methods of Interpretability.", "Optionals:What is the scope of data scienceA Brief History of Statistics", "In the last post (part 5) we saw some local methods of interpretability of BlackBox models. In this post we will look at more robust and sophisticated global methods that can bring together the best of both worlds, the interpretability of statistical models and the flexibility of Machine Learning models.Our blackbox model rep will be xgboost but it could be any other deep neural network or ensemble and our global interpretability model rep will be Shapley Value that has no competitors yet.", "First a bit of history and context.", "Game theory is a branch of mathematics that studies how agents choose between different strategies taking into account conflict and cooperation. It is a bit reminiscent of the definition of economic science, which is the study of how people make decisions when they have scarce goods (such as time or money) between competing goals, like waking up early and reading an article in Medium or getting some more sleep. Not surprisingly, game theory was \u201cprofessionalized\u201d within economics with the publication of The Theory of Games and Economic Behavior by John Von Neumann (Brilliant Mathematician) and Oskar Morgenstern (Economist).", "So what\u2019s the difference between Game Theory (hereafter only GT) and Economics? Game Theory is yet another tool that economists have to understand how societies make choices, while GT not only studies choices in society, it is used in dozens of areas such as Computing, Logic, Politics, Philosophy, Journalism, Marketing and many others as evolutionary biology to explain how altruistic behavior in Darwinian evolution. Game theory is the area that studies how agents make the best decisions possible given how they interact. Here it starts to interest us more, because one of the problems with Machine Learning models was the complex interaction between variables. Let\u2019s continue.", "Game theory, like almost all science, has a historical evolution and several parents. Waldegrave in 1713, Cournot in 1838 were already talking about it, but it was Neumann who systematized and expanded the area in the 1930s. Many know quite another genius in the area, John Nash for an important contribution (equilibria in sub-games) that earned him a Nobel Prize in 1994, but what interests us here is the 2012 Nobel Prize from Shapley and Alvim Roth. Shapley is considered the greatest theorist in the field, his life is mixed with the evolution of JW, he has contributed in different areas such as the Stable Marriage Problem. In the work of 1953, He studies how it would be fair to share the costs of a \u201cwork\u201d when agents have different interests/needs. Shapley solves this problem, but the question remains, what does it have to do with interpreting Machine Learning models?", "To convey the Shapley Value (the so-called fair value), let\u2019s make a relationship between the two areas: Shapley\u2019s cooperating / competing agents will be our model (X) variables. The \u201cwork\u201d they are planning to apportion will be the variance of our target (y) and the fair value to be paid by each agent / variable is the weight / importance of this variable in the prediction.", "In the original article, the famous Airport Problem is used where one has to decide what size Airport runway to build and how much each agent will pay for this runway. I will excuse myself from mathematical rigor and create a problem closer to our reality (unless you have a plane). In our example,We live in a building with 99 residents and decided to build a swimming pool. Hence two doubts: 1) What is the size of the pool to be built;2) How much each should contribute.", "The most traditional way to solve this problem is to vote, whether the pool will be built and how large and if it is built, we split the cost equally, regardless of whether you can swim or not.", "Imagine we have 3 groups of people living in this building.- A) The first group doesn\u2019t like swimming very much and would like a small pool, say 20 meters.- B) The second group are recreational swimmers and used the pool normally, they would like a 30 meter swimming pool.- C) The last group is made up of Michael Phelps and his friends and they need an Olympic pool in the 50 meter condo.", "Each meter of the pool will cost the same unit, $ 1. So if we did the average we would have a 33 meter pool that will cost $33, whereas if we did the 50 meter pool, group A and B would pay much more than would be ideal. Shapley identified that this was an unfair way of dividing costs and inefficient for pool size. For this he thought of the following strategy. And if we consider, instead of the Total Cost, only the Marginal Cost, that is, just what is being overpaid since other people have already paid a portion. Since the money order interferes with the results, we must start at the desired minimum level of these marginal costs. Because if Group C comes in first, it will pay most and Groups A and B would pay nothing (and the same thing happens in Machine Learning!). When we calculate this, Eureca! Shapley Value and the Fair Price!", "Anyone who wanted a 20 meter pool will have a 50m pool paying for 6.67, one who wanted a 30 meter pool will pay 11.67 and In that case Michael Phelps and his friends will pay 31.67 for a 50m pool. Everyone wins and this is the fair value to be paid.", "In Machine Learning, since the variables are always all correlated with each other, the order that the variables enter the contribution makes a big difference. In a decision tree, for example, we might randomly choose a minor variable before a very important variable, which will increase the importance of the wrong variable. To solve this we will average the marginal contributions of all possible permutations / orders and this will be the fair value of the contribution. That\u2019s why features Importances are so risky to use. Here is my warning not to use them, they are usually unstable and often make no sense with human intuition.", "The theory is not so complicated, but it is an insight that had to wait for a genius to be thought, our problem is now computational.A theory known for over 60 years and why we haven\u2019t applied it since then? The big problem is that she is very expensive computationally and we need to wait for a second genius and charitable soul to solve this problem and share with the community. These people exist, they are Scott M. Lundberg andSu-in Lee who wrote the excellent article that explains how to calculate Shapley Value and also made the code available on the SHAP (SHapley Additive exPlanations). We can now calculate the fair amounts of variables supported by a Nobel Prize and an Open Source package. What a world we live!", "Let\u2019s use a dataset with house price and features as an example to illustrate our ideas (codes available here).", "Let\u2019s take a look at the Correlations with a HeatMap and a Correlation Graph to get an idea of \u200b\u200bwhat the Linear order of importance is:", "The first mistake is to get carried away by the simple correlation. We already saw in part 2 that the variables are all correlated with each other and that when we run a model, what matters is how much the variables explain independently of each other, so the variables that explain most are probably explaining the same variance as the target / y variance. Sometimes variables that are less correlated are so different from the rest of the variables (ie, more exogenous) that they become more important. One way to analyze it is with Linear Regression:", "Now we need to be careful, the estimated Beta value (coef column of the tables above) cannot be interpreted as variable weight since it depends on the X variance. For example the latitude variable has a huge coefficient 6.74e5 but the variable It ranges from 47,155933 to 47,7777624.While the size_house variable has a smaller coefficient, it ranges from 290 to 13540. One way to weigh the importance of the variables here is to look at the t-test, the larger (in absolute value) the more important is the variable, or, as I prefer to normalize the data before running the regression (right summary).Note that all metrics are exactly the same, the R\u00b2, the error, the t-tests, everything except the coefficient value as we normalize the data and the value can be compared directly without loss of generality. It is not common to normalize Linear Regressions because we have lost some sensitivity to read the estimated coefficients. Normalization is only necessary if we are using Regularization methods.", "Also, remember that linear regressions do not understand how variables interact with each other unless explicitly passed, so they may have variables that even with poor correlation help change the weight of other variables by making the model more explanatory and by last our Achilles heel, this is a linear model, therefore any nonlinearity must be explicitly passed or it will become a bias. All of this is best explored in part 2 of this series.", "Let\u2019s use our Megazord Algorithms XGBoost, which fixes just about all of these problems as it is a low bias algorithm (due to tree construction, see part 3) and low variance since it is a very clever single tree emsemble ( see part 4) and below our 5 feature importance produced by XGBoost:", "Which one to use? I could write a long text explaining the mechanics of each, its advantages and disadvantages but it will be much more efficient if we say: Don\u2019t use it and we\u2019ll learn Shapley Value soon!", "Here we will remove all parameterization of the algorithm to focus only on SHAP, but all steps of controlling the trade-off between bias and variance, imputation, balancing and other steps must be done, or the model can interpret the wrong variables. After training the model we do the following:", "To run shap just two lines:", "And after that the magic happens, first our feature importance", "Here\u2019s our expanded Feature Importance, with some interesting insights:", "This chart is scary the first time you see it, but let\u2019s look at its different dimensions.", "It is made up of dots (these colored dots), each observation in the dataset generates a dot for each variable, even if the variable is null and is represented by a gray dot. Note that the order of the variables is the same as the Feature Importance order and this is no accident, it is formed by summing all the weights of the color chart.", "Another dimension is the shape of the distribution, when you have a large mass of dots, it piles the balls in this format of lying violin.", "The third dimension is the position of the points, note that there is a vertical axis at zero, points on this axis indicate that the variable is not positively or negatively impacting, if the point is to the right of this line, it positively impacts the target, and left, negatively, the farther from the axis, the greater the impact.", "The fourth and last dimension is the color of the balls, but this is easier, blue dots indicate low values \u200b\u200band red dots high values, this is done for each of the variables.", "Understanding the different dimensions let\u2019s analyze the results. Firstly, we have the size_house variable, as normalized regression tells us, and large houses have a positive impact on price and small houses have a negative impact, quite obvious, but we go further. Note that the distribution on the right of axis 0 has a long tail, Already blue is all concentrated near zero, this indicates a nonlinearity, large houses impact a lot, but by decreasing the size of the house the model is no longer sensitive to the size of the house, as if the size only mattered after a threshold.", "The is_waterfront variable also has this interpretation, but in this case it is a dummy (only takes the value 0 and 1), in a linear regression we should have only one impact value for this variable but when analyzing the summary we have different values. Why? Because the model allows variables to interact with each other by changing their values.", "Another great advantage of this package is the ability to explain to us a particular prediction, let\u2019s take a single dataset house and predict its price:", "Here the predicted value is 240097 dollars for the house with these features. Each variable is represented by a colored bar and the impact it has had on the prediction. Blue bars decrease the predicted value and red bars increase the value.", "A second example would be this:", "And one would think, and if we rotate these predictions for all observations and stack these bars like a tower, we get a macro view of how the variables behave. The authors also thought about it, but they turned this tower 90 degrees:", "An interesting feature of this chart is that it is interactive, you can filter specific variables, sort by different impacts, and get rich insights into how the variables work in your model.", "And the best was for the end, the dependency graph between the variables.", "These graphs display how variables interact with each other, changing the value of each other. Let\u2019s focus on the upper right graph. The size of the house. Note that it is growing, even reminiscent of linear growth, but why are there different impacts on the prediction for the same house size value? Let\u2019s focus on 4000u size houses. Impacts have a huge variance, because the other variables are interacting with size. Especially the latitude variable (which gives the color to the points). Note that for houses up to 2000u lower (blue) latitudes increase the value of houses, and after 2000u this reverses,high latitudes increase the value of houses of the same size. When we analyze the data more carefully we notice that the higher latitudes are the houses on the edge of the lake, in the center of the city and as the latitude decreases the houses become field houses, much larger land.", "If we had a linear model, these points would have to be arranged on a line. But since this is a low bias model, he can understand these complex behaviors. To take the real test, let\u2019s run the same XGBoost but with a max_depth = 1, thus the model can still understand nonlinearities but cannot interact with variables, and the result, as expected, removes the variance of predictions for the same value of X:", "We have already said that this is the only fair way to divide the weight of variables supported by a solid theory. But what is the exact interpretation of this number anyway?", "The Shapley Value is the feature\u2019s contribution to the difference between the forecast and the mean value, ie all numbers we have analyzed so far must be interpreted against the mean. This is easy to see in the individual prediction graphs, because for a house price forecast, we had few variables impacting the price because in reality they were changing the average value of the forecasts.", "The possible uses for this are very large, and in the author\u2019s github repository he gives other very cool uses like sorting, natural language and Image, below are some examples taken from there:", "Does SHAP only work for boosting models?", "No, SHAP can work with deep neural networks applied to different contexts!", "Now that you\u2019re armed with this great tool for opening the black box of Machine Learning algorithms, don\u2019t just make passive predictions, you can now explain to your manager what are the best levers for moving your business. A real example I had to develop was with Fraud Prediction where it was not enough to show the likelihood of a contract being fraudulent, I needed to explain why the contact was considered a fraud and SHAP helped me with that. This can be an input to understanding, for example, how to guard against future fraud.", "Another use I constantly use for shap is in statistical modeling. We can run a model like XGBoost to understand the behavior of variables, which ones interact more with which ones to get back to our time-saving linear model.", "The last use I use for SHAP is to understand if my model has Leakages, ie information leaks as variables of the future. This is quite common when we are modeling the data and we have no control over the construction of the tables, as null values \u200b\u200bthat explain the most are evident when plotting the summary, A series of gray dots appear in one corner of the Shap Value.", "That is, you can use SHAP to: \u2014 Understand what your model is doing and thus trust it more; \u2014 Feature Engineering debugging; \u2014 Helping the decision making of humans applying these predictions. Example, if the probability of the employee leaving the company is high,The solutions are quite different if the explanatory variables can be salary or its manager. \u2014 Helps model a Causal Inference model as Linear Regression.", "All codes used in this post are available in kaggle", "See also our series of posts about:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Economist and data scientist venturing into education."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc384cbb6929&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c384cbb6929--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c384cbb6929--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@marcos.silva0?source=post_page-----c384cbb6929--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcos.silva0?source=post_page-----c384cbb6929--------------------------------", "anchor_text": "Marcos Silva"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb59f47e127f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&user=Marcos+Silva&userId=b59f47e127f9&source=post_page-b59f47e127f9----c384cbb6929---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc384cbb6929&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc384cbb6929&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/interpreting-machine-learning-model-70fa49d20af1", "anchor_text": "Introduction to Interpretability"}, {"url": "https://towardsdatascience.com/statistical-modeling-the-full-pragmatic-guide-7aeb56e38b36", "anchor_text": "Statistical Modeling \u2014 The Full Pragmatic Guide"}, {"url": "https://medium.com/swlh/data-science-and-the-data-scientist-db200aac4ea0", "anchor_text": "What is the scope of data science"}, {"url": "https://towardsdatascience.com/a-brief-history-of-statistics-36cfdac9439f", "anchor_text": "A Brief History of Statistics"}, {"url": "https://pt.wikipedia.org/wiki/Theory_of_Games_and_Economic_Behavior", "anchor_text": "The Theory of Games and Economic Behavior"}, {"url": "https://en.wikipedia.org/wiki/Stable_marriage_problem", "anchor_text": "Stable Marriage Problem"}, {"url": "https://en.wikipedia.org/wiki/Airport_problem", "anchor_text": "Airport Problem"}, {"url": "http://papers.nips.cc/author/scott-m-lundberg-10119", "anchor_text": "Scott M. Lundberg"}, {"url": "http://papers.nips.cc/author/su-in-lee-8534", "anchor_text": "Su-in Lee"}, {"url": "http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions", "anchor_text": "article"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "https://www.kaggle.com/sn3fru/interpreting-ml-model-with-shapley-value?scriptVersionId=22551189", "anchor_text": "codes available here"}, {"url": "https://towardsdatascience.com/statistical-modeling-the-full-pragmatic-guide-7aeb56e38b36", "anchor_text": "part 2"}, {"url": "https://www.kaggle.com/sn3fru/interpreting-ml-model-with-shapley-value?scriptVersionId=22614010", "anchor_text": "kaggle"}, {"url": "http://a%20brief%20history%20of%20statistics/", "anchor_text": "A Brief History of Statistics"}, {"url": "https://towardsdatascience.com/how-to-become-a-data-scientist-2a02ed565336", "anchor_text": "Recommendation of Books, Courses and Movies for Data Scientists."}, {"url": "https://medium.com/swlh/data-science-and-the-data-scientist-db200aac4ea0", "anchor_text": "What is the scope of data science"}, {"url": "https://medium.com/beacon-insight/ci%C3%AAncia-de-dados-e-o-cientista-de-dados-72634fcc1a4c", "anchor_text": ";"}, {"url": "https://towardsdatascience.com/interpreting-machine-learning-model-70fa49d20af1", "anchor_text": "Interpreting Machine Learning."}, {"url": "https://www.linkedin.com/in/marcosviniciusenator/", "anchor_text": "LinkedIn"}, {"url": "https://github.com/sn3fru/datascience_course", "anchor_text": "GitHub"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c384cbb6929---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/technology?source=post_page-----c384cbb6929---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/programming?source=post_page-----c384cbb6929---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----c384cbb6929---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c384cbb6929---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc384cbb6929&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&user=Marcos+Silva&userId=b59f47e127f9&source=-----c384cbb6929---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc384cbb6929&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&user=Marcos+Silva&userId=b59f47e127f9&source=-----c384cbb6929---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc384cbb6929&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c384cbb6929--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc384cbb6929&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c384cbb6929---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c384cbb6929--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c384cbb6929--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c384cbb6929--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c384cbb6929--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c384cbb6929--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c384cbb6929--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c384cbb6929--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c384cbb6929--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcos.silva0?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcos.silva0?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marcos Silva"}, {"url": "https://medium.com/@marcos.silva0/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb59f47e127f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&user=Marcos+Silva&userId=b59f47e127f9&source=post_page-b59f47e127f9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F12c43fd32cfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-guide-using-game-theory-to-interpret-machine-learning-c384cbb6929&newsletterV3=b59f47e127f9&newsletterV3Id=12c43fd32cfa&user=Marcos+Silva&userId=b59f47e127f9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}