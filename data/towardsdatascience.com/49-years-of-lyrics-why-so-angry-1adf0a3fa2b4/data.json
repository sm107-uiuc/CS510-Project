{"url": "https://towardsdatascience.com/49-years-of-lyrics-why-so-angry-1adf0a3fa2b4", "time": 1682994261.6976151, "path": "towardsdatascience.com/49-years-of-lyrics-why-so-angry-1adf0a3fa2b4/", "webpage": {"metadata": {"title": "49 Years of Lyrics: A Python based study of the change in language for popular music from 1970 to 2018. | by Carl Sharpe | Towards Data Science", "h1": "49 Years of Lyrics: A Python based study of the change in language for popular music from 1970 to 2018.", "description": "This article describes how to use web scraping techniques and API calls to collect data, prepare it for analysis, train a Neural Network to detect aggressive speech, and visualize the outcomes."}, "outgoing_paragraph_urls": [{"url": "https://slate.com/technology/2014/08/musical-nostalgia-the-psychology-and-neuroscience-for-song-preference-and-the-reminiscence-bump.html", "anchor_text": "There\u2019s an excellent Slate article on Neural Nostalgia here that talks about it in detail", "paragraph_index": 0}, {"url": "http://www.spacy.io", "anchor_text": "SpaCy", "paragraph_index": 2}, {"url": "https://github.com/sharpie-007/dataAndMusic", "anchor_text": "github here.", "paragraph_index": 3}, {"url": "http://www.billboard.com", "anchor_text": "billboard.com", "paragraph_index": 7}, {"url": "http://www.bobborst.com/", "anchor_text": "bobborst.com/", "paragraph_index": 7}, {"url": "http://www.bobborst.com/", "anchor_text": "http://www.bobborst.com/", "paragraph_index": 8}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "anchor_text": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "paragraph_index": 9}, {"url": "https://genius.com/", "anchor_text": "https://genius.com/", "paragraph_index": 11}, {"url": "https://github.com/johnwmillr/LyricsGenius", "anchor_text": "LyricsGenius", "paragraph_index": 12}, {"url": "https://seaborn.pydata.org/", "anchor_text": "seaborn", "paragraph_index": 14}, {"url": "https://spacy.io/usage/models", "anchor_text": "primer here.", "paragraph_index": 19}, {"url": "https://github.com/amueller/word_cloud", "anchor_text": "wordcloud", "paragraph_index": 31}, {"url": "https://www.freewebheaders.com/bad-words-list-and-page-moderation-words-list-for-facebook/", "anchor_text": "www.freewebheaders.com", "paragraph_index": 38}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "scikit-learn\u2019s Counter Vectorizer", "paragraph_index": 41}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model", "anchor_text": "Bag of Words", "paragraph_index": 41}, {"url": "https://www.tensorflow.org/tutorials/keras/basic_classification", "anchor_text": "here", "paragraph_index": 41}], "all_paragraphs": ["This article originally started out as an argument about whether popular music was better or worse today than it was several years ago. There are several theories on why certain time ranges of music resonate with us, which can definitely affect our impartiality when it comes to something as subjective as music and the arts in general. There\u2019s an excellent Slate article on Neural Nostalgia here that talks about it in detail.", "For me though, as a data driven person, I thought some level of quantitative analysis could be brought to bear. If I was able to go through music from 1970 to 2018 and investigate the lyrics from a Natural Language Processing (NLP) perspective, what could I discover? I mean, I know late 90s music was the best music of all time (see Neural Nostalgia article above), but how could I prove/disprove that? How could I measure something so subjective?", "I also wanted to provide other researchers/data scientists/hobbyists with some examples of how open source web-page based data could be collected, structured, and then used to feed API calls. Further I wanted to show how one could use SpaCy to tokenize the lyrics so they could be fed through a trained ANN. I used Requests, BeautifulSoup, and SpaCy for collection and data preparation tasks, matplotlib and seaborn for the visualizations, and Keras with Tensorflow (GPU) to train the ANN and then predict with it.", "You\u2019ll also see from a lot of the code in the github repo that I focused on linearity and readability so that others could pick and choose the parts of code that suit their purpose. It generally isn\u2019t optimized for performance, I really focused on investigation. You can find all the source code on github here.", "After much more arguing, we came up with the following measurements that would be tested against lyrics to see how they\u2019ve changed over a 49 year period:", "I will also iterate through the lyrical data to see when specific new terms show up in lyrics that have not been seen before. Term such as \u201cInternet, Blackberry, iPhone, Terrorism, Recession\u201d and the like (coming at a future date).", "There are three datasets we\u2019re using to run this experiment:", "I couldn\u2019t find any ready sets of lyrics data to use for this experiment online, so I took a look at billboard.com\u2019s year end top 100 songs. While they do have records going back before the 70s there are a lot of gaps in their datasets, including no top 100 lists from 1991 to 2006. Luckily there\u2019s another website (bobborst.com/) that was curated by a genuine music lover and all the content pre-2017 can be found there.", "So the majority of the seed data will be collected from http://www.bobborst.com/ and the remainder from billboard.", "I used Python\u2019s request library to pull in the data and then the BeautifulSoup (https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to perform the collection. It\u2019s an interesting task because one website is organized by html tables and the other by divs, so I needed two different transforms. The collected data was then stored in a pandas dataframe called \u201call_songs.\u201d", "See the following function on Github for the full snippet.", "With the initial data collection complete, I now had the Artist, Rank, Song Title, and Year for 4900 songs. As I was really focused on the lyrics though, I didn\u2019t have what I needed for the experiment. This is where https://genius.com/ comes into play.", "A quick Google search lands us on a library called LyricsGenius that gives a nice wrapper around the genius.com API. We can then use a loop to iterate through all_songs in order to collect the lyrics from each song. This API also gives us the album, the release date, any associated URLs, the song writer(s), and any featured artists on the song. A snippet of how this works is below (see Github for the full code).", "We need to use try/except here because there are often discrepancies between how Billboard/Bob Borst store artists/songs vs how genius.com stores them (e.g. and vs &, prefacing Beatles with The, etc). I handled a few of these upon inspecting some of the misses, but overall decided to see how much I got from the original intake of 4900 songs. The API calls aren\u2019t very fast, so iterating through the entire set took around 2 1/2 hours to complete.", "Of the 4900 songs I threw at the genius API, I got 3473 back. I used pandas and seaborn to visualize the distribution of songs from year to year to see how many misses there were and whether or not it could have an outsize effect on the rest of the experiments.", "I ran the API collection twice, once without any substitutions and once substituting Beatles, Jackson 5, and &. The results are below:", "Some manual further inspection shows that there are several song titles that just don\u2019t match up across the two datasets. We could spend more time going through the exceptions, but we\u2019ll proceed with the knowledge that we don\u2019t have 100% of the dataset.", "You can see from the above that we have the most amount of data coming in in 1990 and the least amount in 2010. We\u2019ll keep this in mind as we proceed.", "For data preparation there are three things we want to get, 2 for characteristic purposes (that will help our lightweight assessment of language complexity), and the more crucial one is the extraction of nouns, verbs, adverbs, stop words and special characters from the lyrics in order to perform some more core analytics.", "SpaCy is a pretty industrialized series of NLP libraries that really fast tracks data preparation and can be used for all kinds of other text analytics based on it\u2019s pre trained models. I highly suggest reading the primer here.", "For this experiment, I\u2019ve written a function that grabs the verb, adverb, noun, and stop word Parts of Speech (POS) tokens and pushes them into a new dataset. We then extract them out and return them into an enriched dataset that enables us to further investigate the data and have it ready to pass through our profanity checks and our aggression ANN. Check out the function called:", "I also use split and set to count the number of words and number of unique words in each dataset. Let\u2019s take a look at the newly enriched data.", "We can now see our enriched dataset with more detail:", "We see here that we have verbs, nouns, adverbs, corpus, word counts, and unique word counts are now available to us. We remove out the stop words in this case because they typically do not have much meaning on their own, and we\u2019d like to focus on the words that have impact. Let\u2019s take a look at the word breakdowns further.", "We\u2019re going to map out word frequencies (total and unique), as well average frequency of words that are used across every year to see if we can prove our complexity increase and nouns evolution over the 49 year spread.", "We can see from the chart above that the amounts of words in each song has been trending upwards from 1970 to 2018, and that generally speaking, unique words tick upwards with the increase in overall number of words. We can also see that the overall number of songs collected doesn\u2019t seem to have a direct effect on either. We can look at this with a stacked barchart as well to see if there are any more insights.", "This helps us determine that the lowest number of unique words happened in 1978, and also supports the hypothesis that (by measure of uniqueness and word counts) that lyrics have gotten more complex over time. We can also look at these with matplotlib\u2019s subplot feature to overlay multiple dimensions. This will help us visualize if there are any overt correlations.", "From this view, we can indeed see that unique words and total words follow each other closely, and that the number of songs collected do not appear to have a clear bearing on those values. In fact, when some of the most complex lyrics appear, the collection is actually relatively low. As we\u2019re averaging both word count and unique word count, if there was an outsize problem caused by the data, we would see dips where we saw collection misses.", "It looks like our most complex year lyric wise was 2004, 2005. Let\u2019s take a look at them below.", "We can see here that in both cases the top 5 are Rap/Hip-Hop songs, which makes sense in this case as both of those genres are word heavy vs some of the more Pop songs of the time. You can check the code for more ways to interact with the data, but suffice it to say the results with unique words are similar. I didn\u2019t have the ability to collect genre information with the songs, but I would think you\u2019d see these genres were quite popular in this time frame, which would again support the increase of the word counts.", "Let\u2019s look at a word cloud or two.", "I wrote a function that wraps the wordcloud library into a format and font package I like and have pushed some of the years of data through it here. I actually use word clouds a lot in day to day investigations to identify outliers and terms that could bias models that I build. They can also be quite pretty. PLEASE NOTE: as some of the lyrics can contain profanity, that may show up in the word clouds.", "We\u2019ll take a look at the lowest complexity and highest complexity years to see what\u2019s most common within each.", "In the word clouds above, it looks like Verse show up a lot. That\u2019s because they\u2019re in the lyrics as place markers. We could go back and treat them as stop words, but as it appears to be consistent across the data, we can probably proceed. If we come back again we may want to clean it up. Word clouds are great for this.", "Now for the most common terms across years.", "From the visualization above, it looks like love peaked in 1993, and then was replaced by baby, which was then succeeded by what, but that\u2019s really a pronoun so we can fall to time. Baby had a good run in 2012. This supports our hypothesis that the topics of lyrics have changed over time, even if we limit it to words seen in all years.", "Now we understand the data, we know word counts have climbed, and that topics have changed, and it looks like our collection doesn\u2019t have a lot of bias due to the variance in records per year. We can now proceed to our analysis of the frequency of profanity in the lyrics.", "The dictionary we\u2019re using to detect profanity is based on present day texts, conversations, and mediums, so it may have a bias towards more modern day songs. We can intuit that songs organically have more overt profanity today, but I didn\u2019t have a list of older, more covert forms of profanity to access for this experiment. With that in mind, let\u2019s continue.", "I loaded a dictionary from www.freewebheaders.com that includes their list of no-no words for sites like facebook. you can read more on the link, but only really open the file if you\u2019re not easily offended, it contains some pretty terrible language. I then iterated through the dataset to see when these words showed up, stored them alongside the lyrics, and then counted the frequency of occurences. The outcomes are visualized in the chart below.", "This chart supports our hypothesis that there\u2019s more profanity in recent years, but there are three interesting points here:", "For the aggression analysis I found a dataset on Kaggle that has short messages that are tagged as aggressive/not aggressive. I looked for one that had covert/overt/non aggressive, but didn\u2019t have any luck.", "The dataset has 20,001 messages in it, and after a brief SpaCy treatment (the same approach as used for the lyrics) the data was prepared to be passed into scikit-learn\u2019s Counter Vectorizer and then, Bag of Words data ready, passed to a Keras sequential model. You can find a nice lightweight tutorial on getting started with Keras here.", "I tried several different configurations for the model, but the most positive impact occurred when I limited the features down to 250, which makes sense given the short nature of the source data and the lack of topical complexity. It may not classify as many songs as aggressive as we would like in a perfect world, but we\u2019re looking for an upward tick in aggression, and the model will applied across all data equally.", "The Keras model is pretty deep, and I\u2019ve added multiple dropout layers to help avoid overfitting. When I added more layers to the model, I would get slightly improving accuracy, and the dataset is small enough that it was fairly easy to test.", "There are two Jupyter notebooks in the git repo, one has the collection and analysis code and the other has the ANN training code. If you run this on your own please make sure to train the ANN first before you try to load it into the analysis code. There are examples on how to save, load, and pipeline your models in there.", "Let\u2019s see what our ANN predicted.", "We can see above that our aggression prediction model thinks a lot of songs are aggressive, but the trend on it\u2019s own looks like it goes down a bit, which it contrary to our hypothesis. We can look at them overlayed by again using matplotlib\u2019s subplot/multi axis feature.", "Here we can see that when you scale both plots that songs, given the number of songs collected vs the number found aggressive, have been climbing and inverted in 2002. We can rightfully be sceptical of our models overall accuracy at prediction, but this kind of lightweight approach on a distant but available dataset (cyberbullying messages) can help inform us. In this case I think there\u2019s enough indicators to make me want to look for richer datasets, and more complex approaches, to building an aggression detection model.", "So here we are. We\u2019ve collected our own seed data, used it to pull more data from an API, prepped the data for text analysis, checked against a dictionary of profane words, built an ANN to detect aggression, and then ran it against our data. Let\u2019s revisit our hypothesis to see what we\u2019ve learned.", "Thanks for reading, let me know what else you\u2019d like to see!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m passionate about helping people gain insight through the exploration and responsible use of Data."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1adf0a3fa2b4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@carlsharpe_71327?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@carlsharpe_71327?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "Carl Sharpe"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fdf75fc8075&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&user=Carl+Sharpe&userId=5fdf75fc8075&source=post_page-5fdf75fc8075----1adf0a3fa2b4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1adf0a3fa2b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1adf0a3fa2b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://slate.com/technology/2014/08/musical-nostalgia-the-psychology-and-neuroscience-for-song-preference-and-the-reminiscence-bump.html", "anchor_text": "There\u2019s an excellent Slate article on Neural Nostalgia here that talks about it in detail"}, {"url": "http://www.spacy.io", "anchor_text": "SpaCy"}, {"url": "https://github.com/sharpie-007/dataAndMusic", "anchor_text": "github here."}, {"url": "https://www.freewebheaders.com/bad-words-list-and-page-moderation-words-list-for-facebook/", "anchor_text": "www.freewebheaders.com"}, {"url": "https://www.kaggle.com/dataturks/dataset-for-detection-of-cybertrolls", "anchor_text": "Kaggle"}, {"url": "http://www.billboard.com", "anchor_text": "billboard.com"}, {"url": "http://www.bobborst.com/", "anchor_text": "bobborst.com/"}, {"url": "http://www.bobborst.com/", "anchor_text": "http://www.bobborst.com/"}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "anchor_text": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"}, {"url": "https://genius.com/", "anchor_text": "https://genius.com/"}, {"url": "https://github.com/johnwmillr/LyricsGenius", "anchor_text": "LyricsGenius"}, {"url": "https://seaborn.pydata.org/", "anchor_text": "seaborn"}, {"url": "https://spacy.io/usage/models", "anchor_text": "primer here."}, {"url": "https://github.com/amueller/word_cloud", "anchor_text": "wordcloud"}, {"url": "https://www.freewebheaders.com/bad-words-list-and-page-moderation-words-list-for-facebook/", "anchor_text": "www.freewebheaders.com"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "scikit-learn\u2019s Counter Vectorizer"}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model", "anchor_text": "Bag of Words"}, {"url": "https://www.tensorflow.org/tutorials/keras/basic_classification", "anchor_text": "here"}, {"url": "https://medium.com/tag/music?source=post_page-----1adf0a3fa2b4---------------music-----------------", "anchor_text": "Music"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1adf0a3fa2b4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----1adf0a3fa2b4---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1adf0a3fa2b4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----1adf0a3fa2b4---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1adf0a3fa2b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&user=Carl+Sharpe&userId=5fdf75fc8075&source=-----1adf0a3fa2b4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1adf0a3fa2b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&user=Carl+Sharpe&userId=5fdf75fc8075&source=-----1adf0a3fa2b4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1adf0a3fa2b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1adf0a3fa2b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1adf0a3fa2b4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1adf0a3fa2b4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@carlsharpe_71327?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@carlsharpe_71327?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Carl Sharpe"}, {"url": "https://medium.com/@carlsharpe_71327/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "23 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fdf75fc8075&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&user=Carl+Sharpe&userId=5fdf75fc8075&source=post_page-5fdf75fc8075--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F5fdf75fc8075%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F49-years-of-lyrics-why-so-angry-1adf0a3fa2b4&user=Carl+Sharpe&userId=5fdf75fc8075&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}