{"url": "https://towardsdatascience.com/data-science-crash-course-6d8e03390f6b", "time": 1683002692.671125, "path": "towardsdatascience.com/data-science-crash-course-6d8e03390f6b/", "webpage": {"metadata": {"title": "Data Science Crash Course. Let\u2019s learn Data Science in 2020 | by Przemek Chojecki | Towards Data Science", "h1": "Data Science Crash Course", "description": "2020 is here and it\u2019s time to learn Data Science! This Data Science Crash Course is a quick way to start your journey with Data Science. Our goal is to start programming right away on whatever\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.anaconda.com/", "anchor_text": "www.anaconda.com", "paragraph_index": 15}, {"url": "https://pythonprogramming.net/reading-csv-files-python-3/", "anchor_text": "Python Programming", "paragraph_index": 43}, {"url": "https://realpython.com/python-csv/", "anchor_text": "Real Python", "paragraph_index": 43}, {"url": "https://docs.scipy.org/doc/numpy/user/index.html", "anchor_text": "an official documentation", "paragraph_index": 47}, {"url": "https://pandas.pydata.org/", "anchor_text": "Pandas", "paragraph_index": 48}, {"url": "https://docs.python.org/3/tutorial/datastructures.html", "anchor_text": "Have a look here to see how many there are", "paragraph_index": 51}, {"url": "https://pypi.org/project/requests/2.7.0/", "anchor_text": "requests", "paragraph_index": 54}, {"url": "https://pypi.org/project/beautifulsoup4/", "anchor_text": "BeautifulSoup", "paragraph_index": 54}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "anchor_text": "BeautifulSoup documentation", "paragraph_index": 61}, {"url": "https://www.gutenberg.org/", "anchor_text": "Project Gutenberg", "paragraph_index": 64}, {"url": "https://developer.twitter.com/", "anchor_text": "Twitter API", "paragraph_index": 65}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle", "paragraph_index": 66}, {"url": "https://en.wikipedia.org/wiki/Statistical_classification", "anchor_text": "Classification", "paragraph_index": 72}, {"url": "https://en.wikipedia.org/wiki/Regression_analysis", "anchor_text": "Regression", "paragraph_index": 73}, {"url": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm", "anchor_text": "K-Nearest Neighbours (KNN)", "paragraph_index": 74}, {"url": "https://scikit-learn.org/stable/modules/neighbors.html", "anchor_text": "Have a look at this implementation of KNN, when K=2, using sklearn", "paragraph_index": 74}, {"url": "https://scikit-learn.org/stable/modules/naive_bayes.html", "anchor_text": "You can implement it using sklearn again", "paragraph_index": 75}, {"url": "https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f", "anchor_text": "Linear Regression with Python", "paragraph_index": 78}, {"url": "https://scikit-learn.org/stable/modules/tree.html", "anchor_text": "the plane into two regions using sklearn", "paragraph_index": 80}, {"url": "https://xgboost.readthedocs.io/en/latest/", "anchor_text": "XGBoost", "paragraph_index": 82}, {"url": "https://xgboost.readthedocs.io/en/latest/", "anchor_text": "Official Documentation reads", "paragraph_index": 82}, {"url": "https://scikit-learn.org/stable/modules/clustering.html", "anchor_text": "Again sklearn will come helpful", "paragraph_index": 86}, {"url": "https://en.wikipedia.org/wiki/Elbow_method_(clustering)", "anchor_text": "see elbow method for example", "paragraph_index": 87}, {"url": "https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html", "anchor_text": "For example this would be the result of 3 cluster", "paragraph_index": 87}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html", "anchor_text": "a simple k-means use case", "paragraph_index": 88}, {"url": "https://scikit-learn.org/stable/modules/clustering.html#dbscan", "anchor_text": "Following sklearn", "paragraph_index": 90}, {"url": "https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/", "anchor_text": "have a look here for Credit Card dataset", "paragraph_index": 91}, {"url": "http://kaggle.com/", "anchor_text": "Kaggle", "paragraph_index": 92}, {"url": "https://keras.io/", "anchor_text": "Keras", "paragraph_index": 98}, {"url": "https://keras.io/", "anchor_text": "Keras", "paragraph_index": 98}, {"url": "https://github.com/tensorflow/tensorflow", "anchor_text": "TensorFlow", "paragraph_index": 98}, {"url": "https://en.wikipedia.org/wiki/Multilayer_perceptron", "anchor_text": "multilayer", "paragraph_index": 102}, {"url": "https://en.wikipedia.org/wiki/Feedforward_neural_network", "anchor_text": "feedforward", "paragraph_index": 102}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "Backpropagation", "paragraph_index": 102}, {"url": "https://en.wikipedia.org/wiki/Gradient_descent", "anchor_text": "gradient descent", "paragraph_index": 102}, {"url": "https://keras.io/getting-started/sequential-model-guide/", "anchor_text": "Multilayer Perceptron this time built with Keras", "paragraph_index": 104}, {"url": "https://nextjournal.com/gkoehler/digit-recognition-with-keras", "anchor_text": "here\u2019s a great tutorial for that", "paragraph_index": 107}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html", "anchor_text": "Let\u2019s look at a sklearn code for a simple PCA", "paragraph_index": 111}, {"url": "https://scikit-learn.org/stable/modules/manifold.html", "anchor_text": "Manifold learning", "paragraph_index": 114}, {"url": "https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne", "anchor_text": "you can read more about it in sklearn documentation", "paragraph_index": 114}, {"url": "https://plot.ly/python/", "anchor_text": "you can create with plotly", "paragraph_index": 121}, {"url": "https://plot.ly/dash/", "anchor_text": "Dash", "paragraph_index": 123}, {"url": "https://dash-gallery.plotly.host/Portal/", "anchor_text": "what is possible with Dash here", "paragraph_index": 123}, {"url": "https://www.youtube.com/channel/UCEq0oQsS-voRnSWbcviIDGA?sub_confirmation=1", "anchor_text": "a video version of this course, have a look at my YouTube channel", "paragraph_index": 130}, {"url": "https://amzn.to/3aQVTjs", "anchor_text": "Data Science Job: How to become a Data Scientist", "paragraph_index": 132}], "all_paragraphs": ["2020 is here and it\u2019s time to learn Data Science! This Data Science Crash Course is a quick way to start your journey with Data Science. Our goal is to start programming right away on whatever computer you have right now. Just by reading this text, you\u2019ll learn all the necessary terms to start coding and analysing data. Let\u2019s go!", "Python is a perfect language for beginners and experts alike, due to its popularity and clear structure. It\u2019s easy to pick up and thanks to the community you\u2019ll be able to use it both for your first experiments as well as the most recent machine learning research.", "First of all, I\u2019ll talk about setting up your environment. In our case, that means installing Anaconda on your computer, which will allow you to quickly run Jupyter Notebooks and there you\u2019ll be running short Python programs straight away from your browser. So from now until your first program you probably need like 15 minutes.", "Then to do data science you will need a little bit of mathematics. I will review basic terms from linear algebra and statistics that you will need along the way. Those include:", "Then we can go directly to processing data:", "I will also discuss how and where you can get interesting data. Because Data Science is about Data, so you should find a dataset which is exciting to you. Some examples include:", "Having data is the first step to Data Science and once we have data we can start working with. Standard techniques include:", "Classification: we have 2 or more categories (labels) and we want to classify objects according to these labels. We talk here about supervised learning and standard techniques, including KNN, Naive Bayes, Decision Trees, XGBoost, neural networks.", "Clustering: we don\u2019t have any labels but still we want to classify our data. We cluster our data by different measures of similarity, thus creating labels. We talk here about unsupervised learning and standard techniques, including k-means and DBSCAN.", "Neural Networks is a separate topic in itself. The basic idea behind them is simplifying a problem into smaller pieces which can be processed separately by \u2018neurons\u2019. I\u2019ll cover basic frameworks like Keras and Tensorflow, and then also discuss MNIST and other problems which are great to start with.", "Dimensionality Reduction is a must if you want to visualize data or better understand it. Sometimes you just want to plot your 4D data in 2D and then you have to transform it to still capture the essence of information. Standard techniques include PCA and SVM.", "Visualizing Data is important when it comes to business applications of Data Science. In the end, you want to convey your findings to others, and the best way to do that is by presenting them with a nice graph, where everything is clear. We\u2019ll talk about plotly and Dash.", "After this Crash Course, you\u2019ll be prepared to tackle basic Data Science problems and learn more by yourself.", "Anaconda is a free, open-source distribution of both Python and R programming languages for data science and machine learning applications. It aims to simplify package management and deployment.", "Ok, that might sound complicated but the truth is, it\u2019s all about giving you a framework where you can code. You need a compiler to run Python code, think text editor which \u2018runs\u2019 your program, and Anaconda gives you that plus much more. It gives you all the packages you might want to use and Jupyter Notebooks.", "But let\u2019s start with installation. Let\u2019s go to www.anaconda.com and download the most recent version:", "Now that you have it, it\u2019s time to get into more explanations how it all works.", "If you open Anaconda now you\u2019ll see this screen:", "Let\u2019s now go to Jupyter Notebooks. We can forget for now about the rest. Let\u2019s open Jupyter Notebook, you\u2019ll see the following screen:", "Click in the right corner on New and choose Python3. You\u2019ll see", "and\u2026 you\u2019re good to go! This is the command line where you can start writing code in Python and then execute by clicking Run.", "Jupyter Notebooks are an extremely handy way of writing code and keeping track of different experiments. It\u2019s not suited well for bigger projects, but for running quick experiments with data or training neural networks, it\u2019s perfect.", "You usually start by importing packages/libraries by \u2018import \u2026.\u2019. Packages are ready-to-use pieces of code which allow you to save time by not having to write everything yourself. There are packages for everything:", "So it\u2019s often the case that before you do everything yourself you should check whether there\u2019s a relevant package already available. Of course, sometimes you\u2019ll want to do it yourself anyway, just to learn.", "On the ending note, JupyterLab is also a great tool, it\u2019s basically just a way to manage multiple Jupyter Notebooks at one time and thus it\u2019s very useful if you want to organize your code.", "Now you have everything you need to write your first Data Science experiment in Python.", "Now we\u2019re going to review mathematics needed for Data Science.", "Linear algebra is all about manipulations with vectors and matrices. It\u2019s both notation and useful way of manipulating an object. Vector at its core is just a tuple of number written in a column (or a row):", "You can perform operations on vectors like adding by adding each respective term \u2014 they need to have the same length. You can multiply a vector by a scalar, that is a real number, by multiplying each of the entries by this real number.", "Now usually vectors are considered in certain larger space, for example like [1,2] on a plane, where they denote coordinates. Suddenly it becomes all very visual. Also, it becomes evident that you can measure distance between vectors (it\u2019s a distance between points on a plane) or try to compute the angle between two vectors.", "It\u2019s really useful in Data Science when you write your data as vectors and then perform operations on them in order to measure them. Linear Algebraic methods are necessary to do that.", "Vectors generalize to matrices, n by m arrays, which has n times m entries written in rows and columns:", "Again you can add matrices of the same shape, multiply them by a scalar and perform other operations. For example you can multiply matrices of certain compatible shapes. This is crucial for many applications in Data Science, so you definitely should practise multiplying matrices before going any further.", "That\u2019ll be all you need from Linear Algebra in the beginning. At some point it\u2019s worth reading about tensors which are a generalization of matrices to higher dimensions.", "Statistics is about collection, organization, displaying, analysis, interpretation and presentation of data. That comes together with probability with theory, because you\u2019ll need to model unknown data by sampling it from certain distributions.", "Crucial concepts are variance and bias. Following Wikipedia:", "In other words bias is related to having too small of a sample of data compared to the whole set and variance is related to being too focused on each small change in our data. There\u2019s a trade off between those two concepts and it\u2019s often a case how much bias we trade for how much variance.", "In order to start operating with machine learning models, you need to learn the basics of probability theory like", "Those concepts are crucial for understanding the basic mathematics behind Data Science and Machine Learning. The best way to learn them is do a couple of exercises and compute actual probabilities and matrices in particular cases. There are plenty of books and materials online so I won\u2019t copy that here.", "Let\u2019s finally do something in Python with Data. I\u2019ll review basic techniques for processing data. How can you store information. We\u2019ve already learned we want to represent our data as vectors and matrices.", "We can start by importing files. You might have on your computer already", "And you can put it all to work, by importing it into Jupyter Notebook.", "Most of it is done with \u2018open (\u2026)\u2019 for example like this:", "Have a look at Python Programming or Real Python to read more about it.", "The same goes for other forms of files.", "We already know that we want to represent our data in form of arrays (matrices, vectors), so let\u2019s see how we can do it in Python.", "Now the question is how to store them. There are a couple of standard ways to do it.", "Numpy Arrays is an easy way to represent arrays and NumPy is one of the best libraries for doing Data Science. Have a look here for an official documentation. And here\u2019s a snippet from Jupyter Notebook if you want to define a vector [1,2,3]:", "Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools.", "DataFrame, a spreadsheet tabular format, is a part of Pandas and also allows to play with Data. This example shows how to use it to create a simple spreadsheet:", "It\u2019s really efficient and it\u2019s great to use, especially if you have used extensively Excel before, this will all be very familiar.", "Apart from those two very efficient packages, Python itself is coming with plethora of data structures. Have a look here to see how many there are. Just to number a couple which comes in handy when it comes to manipulating data:", "The best way to learn is to play around with it, so open your Jupyter Notebook now!", "Data is crucial for doing Data Science. Often we have to clean it first in order to start using it. Let\u2019s discuss how to do it.", "If you don\u2019t have any interesting data on your computer, then the best way is to just scrape information from the web. It\u2019s pretty easy with Python with packages like \u2018requests\u2019 and \u2018BeautifulSoup\u2019 (to clean data).", "Most websites are easily scraped using requests and it\u2019s all just a matter cleaning.", "You can download useful data from the web. We\u2019re living in digital world, where virtually anything is available online. Most of data can be accessed from different websites by scraping. This way of getting data is very satisfactory but takes time, because you have to clean HTML code along the way.", "Especially financial data is great to get. You can analyse it with tools like Pandas DataFrames and NumPy Arrays which we discussed in the last post.", "Let\u2019s say you want to get information from Nasdaq. With GET you can get HTML code right away:", "However as you can see this is far from readable. The next step would be to use BeautifulSoup to make it pretty:", "This is more readable but still you need to put in the work to extract some informations from it. That\u2019s a great way to start though.", "Have a look at BeautifulSoup documentation for more details.", "Scraping is great, because you can learn Data Science by playing around with more information about your hobby. Say if you like video games and want to analyse different statistics then scraping is the best option. You\u2019ll learn more about particular websites of interest to you.", "Other way to get data is to access already prepared datasets. There countless of examples of them and I\u2019ll just discuss some major datasets here.", "Project Gutenberg is a great source for downloading books. You can access older books for which copyrights expired. Think Shakespeare.", "Twitter API is another fantastic source. Register a Developer account and then you can start playing around with automation. For example you can pull data about a single hashtag and how people are responding to recent events. This is especially great for research in social sciences or marketing.", "Kaggle is a fantastic resource for Data Science competitions but also for ready-to-use datasets which you can download directly, for free, from their website. Major companies often announce their competitions there so you\u2019ll see already what\u2019s of interest in a wider Data Science community.", "On top of that there are a bunch of datasets which are used for benchmarking machine learning models. I won\u2019t go into details here, but I want to just to direct you to a couple which simply are worth knowing:", "That\u2019s all in this lecture. Now it\u2019s time to open your Jupyter Notebooks and play with your favourite dataset.", "Practice is always the best way to learn Data Science.", "We have already learned about storing data and where to get data from. Let\u2019s now cover standard techniques for classifying data, which is the basic application of Data Science.", "Imagine you have data with labels attached. Think images of animals with a description whether it\u2019s a cat or a dog (classification problem). Another example is data about customers in an ecommerce with information like age group, occupation, past shopping (regression problem). Supervised learning deals with this type of problems, where you have labels attached to data so that you can \u2018supervise\u2019 the learning process of your algorithms using those labels as a guidance.", "Classification is the problem of identifying to which label (category) a new object belongs, on the basis of a training set of data containing objects whose labels are known. Examples are assigning a given email to the \u201cspam\u201d or \u201cnon-spam\u201d class, and assigning a diagnosis to a given patient based on observed characteristics of the patient.", "Regression is a statistical process of estimating a value (\u2018continuous label\u2019) based on other features or variables.", "K-Nearest Neighbours (KNN) is the most standard example for both classification and regression. We\u2019re looking at objects closest to a given example we start with and attach a label based on that. K stands for a number of neighbours we\u2019re looking at. Have a look at this implementation of KNN, when K=2, using sklearn, where we want to understand 6 points on a plane:", "Naive Bayes is a standard approach. You simplify a situation and assume that actions/objects in your data are independent (in a probabilistic sense) and hence you can compute probabilities using Bayes theorem. Formally \u201cNaive Bayes methods are a set of supervised learning algorithms based on applying Bayes\u2019 theorem with the \u201cnaive\u201d assumption of conditional independence between every pair of features given the value of the class variable.\u201d You can implement it using sklearn again, for example with this example using a standard dataset of irises and modeling conditional probability using normal distribution (GaussianNB):", "Regression is used when you try to predict a precise value of a label. So it\u2019s a continuous variant of a classification problem. This would be perfect for trying to determine an income of a person based on people living close to him.", "Linear regressions is the simplest \u2014 where you assume your data can be modeled by a linear function. There are plethora of regressions modeled after various functions, the most popular being sigmoid and ReLu (rectified linear function).", "Again Linear Regression is easy to implement with sklearn. Have a look at this tutorial to learn about using Linear Regression with Python.", "Another classification technique is decision trees, where you try to have a Q&A format of data like:", "Trees can be built automatically. For example you can build a simple decision tree to divide the plane into two regions using sklearn:", "Building trees is great because then you can join a couple of trees into a larger model via voting. Decision of each decision tree is taken into account and all decisions are weighted (arithmetic mean in the simplest case). This kind of methods are called ensemble learning.", "XGBoost is another standard technique, worth reading about. Official Documentation reads: \u201cXGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.\u201d You can think about XGBoost as more advanced decision trees.", "Neural networks are the ultimate tool often, when it comes to supervised learning. You build an architecture which is able to learn labels based on past examples. I will talk about them soon but first I\u2019ll explain what to do when you don\u2019t have labels a priori, that is how one go about unsupervised learning or clustering.", "We learned about supervised learning and what to do when you have a dataset with labels. Let\u2019s now look at datasets with no labels provided and talk about unsupervised learning.", "Imagine we have raw data like social statistics related to marketing. For example, you\u2019re trying to understand who has bought a MacBook from your ecommerce and you\u2019d like to find people who are similar. Or you\u2019re selling tickets through an online platform and you try to group your clients into different categories so that you can have a coherent message to each group.", "In order to cluster data or group your data into categories (which are not given a priori!), you have to use one of clustering algorithms. Again sklearn will come helpful. Let\u2019s review two basic methods with a code example from sklearn.", "k-means is the basic technique in clustering. \u201cK\u201d here stands for a number of clusters you want to have. This is arbitrary, you choose this parameter, but there are methods (see elbow method for example), where you can automatically infer the best number of clusters. You can use sklearn to group the famous Iris dataset into groups. For example this would be the result of 3 cluster:", "If you want to have a simple k-means use case then you can simply cluster into 2 groups points on a plane.", "The key to k-means and other technique is having a metric, so a well-defined distance by which we can measure how similar are objects in our dataset. In most practical data coming from spreadsheets, metric is easy to define, we just take the usual distance between vectors in a space as data is purely numeric. Of course you can make it more involved, especially if your data is noisy or you are trying to extract really implicit data, but you don\u2019t have to think for example how to embed a word into a vector space.", "Another Data Clustering Algorithms is Density-based spatial clustering of applications with noise or DBSCAN for short. Following sklearn: \u201cThe DBSCAN algorithm views clusters as areas of high density separated by areas of low density. Due to this rather generic view, clusters found by DBSCAN can be any shape, as opposed to k-means which assumes that clusters are convex shaped. The central component to the DBSCAN is the concept of core samples, which are samples that are in areas of high density. A cluster is therefore a set of core samples, each close to each other (measured by some distance measure) and a set of non-core samples that are close to a core sample (but are not themselves core samples).\u201d This is also one of standard techniques, it might sounds complicated at first but the principle is easy:", "If you want to know how to implement DBSCAN on an example, have a look here for Credit Card dataset and a short tutorial.", "The best way to learn is practice, so I highly recommend you open your Jupyter Notebook now, go on Kaggle and search for a database which you can use in experiments. There are great datasets in those examples above:", "and you can find plenty of other datasets online, ready to use \u2014 both cleaned and raw.", "Clustering often appears in nature and you\u2019re certainly will use it if you were to work for a larger organization like a bank or an insurance company. It\u2019s just natural that you are trying to group unlabeled data into categories which can be explained. Then if you managed to build categories by clustering, you\u2019re going back to classification problem with new data as you try to put new objects into already existing groups which came from clustering.", "In the end Data Science is about classifying and clustering and extracting information from that. It just takes time to master.", "We\u2019re going to talk about Neural Networks and how to use them to classify data. It\u2019s going to be a gentle introduction to neural networks as I\u2019m assuming you have never used them.", "Neural Networks start with perceptrons, modeled on a single neuron in a human brain. You can think about it as a couple of functions composed one by one. You have the input data, then you apply an activation function \u2014 that can be a linear function, ReLu or a sigmoid function, or anything else \u2014 then you pass the data to the next node and again apply the activation function at a given node. It all goes in layers like that (this is more general feedforward network depicted):", "So let\u2019s start with a perceptron example. We have a look at how they are implemented with sklearn, but then we switch to Keras framework. Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow. TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML-powered applications.", "Here\u2019s a simple example with sklearn where we try to fit numbers using perceptron:", "As you can see, code is short and simple, but details are in mathematics. At this point, you should go back to some linear algebra in order to understand what\u2019s going on.", "The following paragraph is more technical, but I tried to put all the terms together (with links so you can read more about each concept):", "Formally a multilayer perceptron is a class of feedforward neural network. A feedforward neural network is a neural network wherein connections between the nodes do not form a cycle. Backpropagation is an algorithm in training feedforward neural networks for supervised learning. Backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input/output example. In this context it\u2019s also important to understand gradient descent, which is an algorithm used to find a local minimum of a function.", "Let me note here that deep learning is machine learning but with neural networks of at least 3 layers of a neural network we use.", "Now let\u2019s go back to examples. As I\u2019ve mentioned Keras and Tensorflow are most prevalent machine learning frameworks currently and Keras is especially easy to pick up. It\u2019s a bit like Lego when you build sequential models. Let\u2019s have a look at this example to see again Multilayer Perceptron this time built with Keras:", "I won\u2019t get into details here, but what is happening here:", "All in all this is how neural networks and machine learning work in a nutshell:", "As Data Science is practical and it\u2019s all about testing and trying, now it\u2019s your turn. Open your Jupyter Notebook and play with data. I also recommend reading about how to use Keras with MNIST dataset \u2014 here\u2019s a great tutorial for that.", "Let\u2019s talk about how to reduce a number of dimensions in our data, so that it can be visualised and better understood.", "Imagine you want to plot data but your data has too many dimensions to do that right away. Here comes Dimensionality Reduction. These methods allow you to look only at certain dimensions which have the most relevant information for you.", "Standard technique is PCA, Principal Component Analysis, which is looking at eigenvectors (singular values) and projecting to those which capture the most of data. So you can transform for example 4D into 2D, by projecting onto 2D space spanned by two largest singular values.", "Let\u2019s look at a sklearn code for a simple PCA use with a NumPy array:", "Here we just use PCA with 2 components and we get singular values for our space. To really understand what\u2019s going on, you should read a couple of sources:", "Dimensionality reduction is important because you want to get rid of unnecessary data, irrelevant columns in spreadsheets, in order to apply data science algorithms in the most efficient way. Less parameters are easier to control and manipulate.", "There are many other methods used for dimensionality reduction. More advanced include for example Manifold Learning. Manifold learning is an approach to non-linear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artificially high. t-SNE is one of the most well-known technique of manifold learning and you can read more about it in sklearn documentation.", "All in all, how you\u2019re going to reduce dimensions depend entirely on data you\u2019re working with. Sometimes it\u2019ll be obvious from the start that you should ignore a couple of columns or rows to get better results. Sometimes it\u2019ll be hard to see what is really important and then you\u2019ll have to try a bunch of dimensionality reduction algorithms to unwind the data and dependencies between objects.", "But that is why Data Science is practical \u2014 there\u2019s no understanding without playing around with data.", "Finally I\u2019m going to discuss how to present a Data Science project so that it\u2019s appealing and instructive to others. In other words, let\u2019s talk about visualisation.", "I start by writing that a well-documented Jupyter Notebook is perfect for a visualisation, especially if you want to show your work to someone with technical background. This is often what employers expect from you to send, when you do a test problem for a job interview.", "Otherwise, if you\u2019re talking with non-technical people, you will need more visual ways to show what you have achieved like:", "Here\u2019s an example of a simple plot using matplotlib:", "In general it\u2019s amazing what you can create with plotly. Below you can find a sample of visualisations from plotly, all done in Python:", "A good command of plotly will allow you to do really great things.", "Going even further with plotly is Dash, by plotly, which allows you to build web-apps from Python. So it\u2019s really great to show to anyone really, whether a technical or non-technical. You can have a look at what is possible with Dash here. For example this interactive dashboard was done in Dash:", "As you can see, Python gives you amazing options for visualising and presenting your work. Now it\u2019s your turn to play with it in Jupyter Notebook.", "The best way to share your projects is definitely Github. Upload your code with a well-written documentation and share it with your colleagues to get feedback. Of course you can\u2019t really do it, if you\u2019re working for a company, but if you\u2019re working towards your own open-source project then Github is a perfect way to share your work. Data Science has a great community so you\u2019re definitely going to hear feedback and learn more from others.", "And that\u2019s all for this Data Science Crash Course.", "I hope you\u2019ve enjoyed it and learned useful things and you\u2019re ready to tackle some data science problems now.", "Let me know in the comments about your feedback and what else would you like to learn in the future.", "Good Luck with your Data Science journey!", "P.S. If you want to see a video version of this course, have a look at my YouTube channel:", "P.S.S. If you want to read more about Data Science here are some texts I\u2019ve written which might be useful:", "Finally, if you want to have an overview of what it means to be a Data Scientist, then have a look at my book Data Science Job: How to become a Data Scientist which will guide you through the process.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI & crypto, PhD in mathematics, Forbes 30 under 30, former Oxford fellow."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6d8e03390f6b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://pchojecki.medium.com/?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": ""}, {"url": "https://pchojecki.medium.com/?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "Przemek Chojecki"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F88e3e673aa8b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&user=Przemek+Chojecki&userId=88e3e673aa8b&source=post_page-88e3e673aa8b----6d8e03390f6b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d8e03390f6b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d8e03390f6b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://datasciencerush.com/data-science-crash-course/", "anchor_text": "If you want to see the complete set of lecture notes for this course together with video lectures have a look at Data Science Rush website."}, {"url": "http://gutenberg.org/", "anchor_text": "Project Gutenberg"}, {"url": "http://kaggle.com/", "anchor_text": "Kaggle"}, {"url": "http://www.anaconda.com/", "anchor_text": "www.anaconda.com"}, {"url": "https://pythonprogramming.net/reading-csv-files-python-3/", "anchor_text": "Python Programming"}, {"url": "https://realpython.com/python-csv/", "anchor_text": "Real Python"}, {"url": "https://docs.scipy.org/doc/numpy/user/index.html", "anchor_text": "an official documentation"}, {"url": "https://pandas.pydata.org/", "anchor_text": "Pandas"}, {"url": "https://docs.python.org/3/tutorial/datastructures.html", "anchor_text": "Have a look here to see how many there are"}, {"url": "https://pypi.org/project/requests/2.7.0/", "anchor_text": "requests"}, {"url": "https://pypi.org/project/beautifulsoup4/", "anchor_text": "BeautifulSoup"}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "anchor_text": "BeautifulSoup documentation"}, {"url": "https://www.gutenberg.org/", "anchor_text": "Project Gutenberg"}, {"url": "https://developer.twitter.com/", "anchor_text": "Twitter API"}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle"}, {"url": "http://www.cs.toronto.edu/~kriz/cifar.html", "anchor_text": "CIFAR-10"}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet"}, {"url": "http://ai.stanford.edu/~amaas/data/sentiment/", "anchor_text": "IMDB Reviews"}, {"url": "https://nlp.cs.nyu.edu/wikipedia-data/", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Statistical_classification", "anchor_text": "Classification"}, {"url": "https://en.wikipedia.org/wiki/Regression_analysis", "anchor_text": "Regression"}, {"url": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm", "anchor_text": "K-Nearest Neighbours (KNN)"}, {"url": "https://scikit-learn.org/stable/modules/neighbors.html", "anchor_text": "Have a look at this implementation of KNN, when K=2, using sklearn"}, {"url": "https://scikit-learn.org/stable/modules/naive_bayes.html", "anchor_text": "You can implement it using sklearn again"}, {"url": "https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f", "anchor_text": "Linear Regression with Python"}, {"url": "https://scikit-learn.org/stable/modules/tree.html", "anchor_text": "the plane into two regions using sklearn"}, {"url": "https://xgboost.readthedocs.io/en/latest/", "anchor_text": "XGBoost"}, {"url": "https://xgboost.readthedocs.io/en/latest/", "anchor_text": "Official Documentation reads"}, {"url": "https://scikit-learn.org/stable/modules/clustering.html", "anchor_text": "Again sklearn will come helpful"}, {"url": "https://en.wikipedia.org/wiki/Elbow_method_(clustering)", "anchor_text": "see elbow method for example"}, {"url": "https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html", "anchor_text": "For example this would be the result of 3 cluster"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html", "anchor_text": "a simple k-means use case"}, {"url": "https://scikit-learn.org/stable/modules/clustering.html#dbscan", "anchor_text": "Following sklearn"}, {"url": "https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/", "anchor_text": "have a look here for Credit Card dataset"}, {"url": "http://kaggle.com/", "anchor_text": "Kaggle"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "https://github.com/tensorflow/tensorflow", "anchor_text": "TensorFlow"}, {"url": "https://en.wikipedia.org/wiki/Multilayer_perceptron", "anchor_text": "multilayer"}, {"url": "https://en.wikipedia.org/wiki/Feedforward_neural_network", "anchor_text": "feedforward"}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "Backpropagation"}, {"url": "https://en.wikipedia.org/wiki/Gradient_descent", "anchor_text": "gradient descent"}, {"url": "https://keras.io/getting-started/sequential-model-guide/", "anchor_text": "Multilayer Perceptron this time built with Keras"}, {"url": "https://nextjournal.com/gkoehler/digit-recognition-with-keras", "anchor_text": "here\u2019s a great tutorial for that"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html", "anchor_text": "Let\u2019s look at a sklearn code for a simple PCA"}, {"url": "https://intoli.com/blog/pca-and-svd/", "anchor_text": "Have a look here for a thorough discussion"}, {"url": "https://www.math.umd.edu/~petersd/666/html/iris_pca.html", "anchor_text": "this text on how to apply PCA to Iris dataset"}, {"url": "https://towardsdatascience.com/principal-component-analysis-for-dimensionality-reduction-115a3d157bad", "anchor_text": "Have a look here for how to do it with wine data"}, {"url": "https://scikit-learn.org/stable/modules/manifold.html", "anchor_text": "Manifold learning"}, {"url": "https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne", "anchor_text": "you can read more about it in sklearn documentation"}, {"url": "https://plot.ly/python/heatmaps/", "anchor_text": "create a heatmap"}, {"url": "https://plot.ly/python/", "anchor_text": "you can create with plotly"}, {"url": "https://plot.ly/dash/", "anchor_text": "Dash"}, {"url": "https://dash-gallery.plotly.host/Portal/", "anchor_text": "what is possible with Dash here"}, {"url": "https://dash-gallery.plotly.host/dash-oil-and-gas/", "anchor_text": "You can access it here"}, {"url": "https://www.youtube.com/channel/UCEq0oQsS-voRnSWbcviIDGA?sub_confirmation=1", "anchor_text": "a video version of this course, have a look at my YouTube channel"}, {"url": "https://medium.com/me/stats/post/358f70e1d9b2?source=main_stats_page", "anchor_text": "Data Science Books you should read in 2020"}, {"url": "https://towardsdatascience.com/best-data-science-courses-on-coursera-in-2020-f7de4ab414ff", "anchor_text": "Best Data Science Courses on Coursera in 2020"}, {"url": "https://medium.com/me/stats/post/2483a5f83770?source=main_stats_page", "anchor_text": "Practical guide to become a Data Scientist"}, {"url": "https://medium.com/me/stats/post/1e08bc54688d?source=main_stats_page", "anchor_text": "Complete guide to become a Data Scientist"}, {"url": "https://amzn.to/3aQVTjs", "anchor_text": "Data Science Job: How to become a Data Scientist"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6d8e03390f6b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6d8e03390f6b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----6d8e03390f6b---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/python?source=post_page-----6d8e03390f6b---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/technology?source=post_page-----6d8e03390f6b---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6d8e03390f6b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&user=Przemek+Chojecki&userId=88e3e673aa8b&source=-----6d8e03390f6b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6d8e03390f6b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&user=Przemek+Chojecki&userId=88e3e673aa8b&source=-----6d8e03390f6b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d8e03390f6b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6d8e03390f6b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6d8e03390f6b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6d8e03390f6b--------------------------------", "anchor_text": ""}, {"url": "https://pchojecki.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://pchojecki.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Przemek Chojecki"}, {"url": "https://pchojecki.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "6.7K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F88e3e673aa8b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&user=Przemek+Chojecki&userId=88e3e673aa8b&source=post_page-88e3e673aa8b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbd30f25c7966&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-crash-course-6d8e03390f6b&newsletterV3=88e3e673aa8b&newsletterV3Id=bd30f25c7966&user=Przemek+Chojecki&userId=88e3e673aa8b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}