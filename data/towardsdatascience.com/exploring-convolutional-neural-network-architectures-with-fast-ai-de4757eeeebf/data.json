{"url": "https://towardsdatascience.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf", "time": 1683017420.508628, "path": "towardsdatascience.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf/", "webpage": {"metadata": {"title": "Exploring Convolutional Neural Network Architectures with fast.ai | by Kenichi Nakanishi | Towards Data Science", "h1": "Exploring Convolutional Neural Network Architectures with fast.ai", "description": "In Part 1: Building an Image Database, we\u2019ve scraped the web for information on plants and how toxic they are to pets, cross-referenced the fields against a second database, then downloaded unique\u2026"}, "outgoing_paragraph_urls": [{"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-a29587f3f04c", "anchor_text": "Part 1: Building an Image Database", "paragraph_index": 0}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/targeting-and-removing-bad-training-data-8ccdac5e7cc3", "anchor_text": "Part 3: Targeting and Removing Bad Training Data", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1803.09820", "anchor_text": "largest batch size you could fit on memory", "paragraph_index": 6}, {"url": "https://arxiv.org/abs/1609.04836", "anchor_text": "recent research", "paragraph_index": 6}, {"url": "https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/", "anchor_text": "vary depending on the nature of the CNN architecture chosen", "paragraph_index": 7}, {"url": "https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/160147", "anchor_text": "post by Chris Deotte on Kaggle", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "Kaiming He et al. in 2015", "paragraph_index": 9}, {"url": "https://arxiv.org/abs/1603.05027", "anchor_text": "2016", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/backpropagation-in-a-convolutional-layer-24c8d64d8509", "anchor_text": "backpropagations", "paragraph_index": 11}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf", "anchor_text": "ResNet paper", "paragraph_index": 15}, {"url": "http://arxiv.org/abs/1502.03167", "anchor_text": "batch normalization", "paragraph_index": 16}, {"url": "https://www.kaggle.com/keras/resnet50", "anchor_text": "ResNet50", "paragraph_index": 17}, {"url": "https://fastai1.fast.ai/vision.models.html", "anchor_text": "implemented by default in fast.ai", "paragraph_index": 25}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_TorchVision_Models.ipynb", "anchor_text": "github repo", "paragraph_index": 26}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness", "paragraph_index": 27}, {"url": "https://arxiv.org/abs/1812.01187", "anchor_text": "Bag of Tricks for Image Classification with Convolutional Neural Networks", "paragraph_index": 29}, {"url": "https://docs.fast.ai/vision.models.xresnet", "anchor_text": "A wide range of xResNets are implemented", "paragraph_index": 32}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness", "paragraph_index": 35}, {"url": "https://forums.fast.ai/t/xresnet-transfer-learning/77537", "anchor_text": "quality of the pre-trained weights currently available", "paragraph_index": 36}, {"url": "https://medium.com/@lessw/how-we-beat-the-fastai-leaderboard-score-by-19-77-a-cbb2338fab5c", "anchor_text": "training from scratch", "paragraph_index": 36}, {"url": "https://github.com/osmr/imgclsmob", "anchor_text": "Sandbox for training convolutional networks for computer vision", "paragraph_index": 42}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_PyTorchCV_Models.ipynb", "anchor_text": "github repo", "paragraph_index": 48}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness", "paragraph_index": 49}, {"url": "https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202", "anchor_text": "Inception", "paragraph_index": 54}, {"url": "https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8", "anchor_text": "ResNet", "paragraph_index": 55}, {"url": "https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160", "anchor_text": "AlexNet", "paragraph_index": 56}, {"url": "https://github.com/osmr/imgclsmob", "anchor_text": "Sandbox for training convolutional networks for computer vision", "paragraph_index": 58}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_PyTorchCV_Models.ipynb", "anchor_text": "github repo", "paragraph_index": 62}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness", "paragraph_index": 63}, {"url": "https://github.com/osmr/imgclsmob", "anchor_text": "Sandbox for training convolutional networks for computer vision", "paragraph_index": 66}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_PyTorchCV_Models.ipynb", "anchor_text": "github repo", "paragraph_index": 70}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness", "paragraph_index": 71}, {"url": "https://arxiv.org/abs/1709.01507v4", "anchor_text": "squeeze-and-excitation", "paragraph_index": 75}, {"url": "https://medium.com/@neuralnets/swish-activation-function-by-google-53e1ea86f820#:~:text=So%20Google%20Brain%20Team%20has,number%20of%20challenging%20data%20sets.", "anchor_text": "Swish", "paragraph_index": 84}, {"url": "https://github.com/rwightman/gen-efficientnet-pytorch", "anchor_text": "(Generic) EfficientNets for PyTorch", "paragraph_index": 85}, {"url": "https://medium.com/@nainaakash012/self-training-with-noisy-student-f33640edbab2", "anchor_text": "Noisy Student", "paragraph_index": 85}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_Geffnet_Models.ipynb", "anchor_text": "github repo", "paragraph_index": 89}, {"url": "https://medium.com/@nainaakash012/self-training-with-noisy-student-f33640edbab2", "anchor_text": "Noisy Student", "paragraph_index": 90}], "all_paragraphs": ["In Part 1: Building an Image Database, we\u2019ve scraped the web for information on plants and how toxic they are to pets, cross-referenced the fields against a second database, then downloaded unique images for each class.", "In Part 2: Training with Controlled Randomness, we trained neural networks using the fast.ai framework to identify the species of plant based on a picture. We implemented a way to seed randomness across the NumPy, PyTorch and random packages and flexible methods for marking images as training or validation samples across separate training runs. This allows us to fairly compare the effects of changing the other aspects of our classifier.", "In Part 3: Targeting and Removing Bad Training Data, we targeted images that are bad for training (e.g. incorrectly labelled or bad examples of the class.) using optical character recognition, analysis of tonal distribution and examining the results of neural networks trained on the uncleaned dataset. We then measured the effect of their removal on the overall training accuracy, and found marked improvements in accuracy after each cleaning step.", "Now that we have a good set of data to use, let\u2019s take the next step and play with some of the convolutional neural network architectures available to us when using the fast.ai framework to train an image classifier.", "The main goal herein will be examining the effects of changing the convolutional neural network architecture in an exploratory way to examine the effects on the accuracy of our image classifier. We won\u2019t be attempting to optimize each hyperparameter for every network \u2014 rather, we will be walking through their intuition, implementation and results, having a quick glance as opposed to maximising the potential results of each architecture.", "Note that all training runs have the following details unless otherwise specified:", "Note that batch sizes here were fixed at 64 unless the memory on the GPU was insufficient due to the sizes of the larger CNN\u2019s. It is generally regarded that there is (unfortunately) no magic number \u2014 it depends on the complexity of the task, and the GPU constraints you have. Leslie N. Smith, father of the learning rate finder, advocated for the largest batch size you could fit on memory (when using the one-cycle-policy), in order to speed up convergence. More recent research has suggested that too large batch sizes can degrate the quality of the model, and small batch sizes will improve the ability of the model to generalize, increasing regularization through noise injection. However, this is at the cost of increased training times and the possibility of poor results if the task is particularly difficult to learn.", "Additionally, the \u2018expected\u2019 input image size can vary depending on the nature of the CNN architecture chosen. Here we\u2019ve chosen to use 224x224 px for every image regardness of network, as each are fully convolutional networks capable of taking any input size. The relevance of the expected input size has more to do with the sizes of patterns the pre-trained weights have been optimized to find, which can have an impact on accuracy \u2014 but doesn\u2019t disqualify us from using any given set of pretrained weights. For a more detailed explanation, please see this post by Chris Deotte on Kaggle.", "To kick this off, we\u2019ll be looking at one of the most important breakthroughs in CNN architecture design \u2014 ResNets.", "ResNets are powerful deep neural networks that emerged from the work done by Kaiming He et al. in 2015 and 2016, whose breakthroughs have enabled the training of hundreds or even thousands of layers with good performance. ResNets achieve excellent generalization performance on recognition tasks, and quickly became one of the most popular architectures in various computer vision tasks.", "Prior to the development of ResNets, stacking layers together to increase the depth of a neural network eventually caused the performance of the network to plateau or rapidly degrade. This was due to the vanishing gradient problem, which occurs because many activation functions (such as the sigmoid) reduce a large input space to a much smaller output (e.g. between 0 and 1 for the sigmoid). Because large changes in the input are reduced to small changes in the output, the derivative naturally becomes much smaller.", "This is important because the goal of the stacked layers is typically to find the ideal weights and biases (those resulting in the best network performance) through successive forward passes, error calculations and backpropagations. The backpropagation process finds the derivatives of the network by moving layer by layer from the final layer to the initial one. By the chain rule, the derivatives of each layer are multiplied down the network (from the final layer to the initial) to compute the derivatives of the initial layers. This repeated multiplication can make the gradient infinitely small, which means that the weights and biases of the initial layers would not be updated effectively with each training session. Since these initial layers are crucial to recognizing the core elements of the input data, it can lead to inaccuracy in the whole network.", "ResNets: Add the input back onto the output so gradients won\u2019t vanish as fast.", "The key idea behind ResNets is the introduction of residual blocks that contain an \u201cidentity shortcut connection\u201d skipping one or more layers.", "This residual block changes the goal of the stacked layers from fitting the ideal weights and biases H(x to fitting the output of the ResBlock, H(x) = F(x) + x. Rearranging this expression, we get F(x) = H(x) - x, revealing that the ResBlock is really attempting to fit the input minus the output, i.e. the residual function F(x)\u2014 hence the name Residual Block. Intuitively, we can think of each block as now fine-tuning the output of a previous block, instead of having to generate a desired output from scratch.", "The ResNet paper empirically demonstrated that optimization of these residual networks was much easier. The addition of skip connections enabled the propagation of larger gradients to initial layers, mitigating the effects of the vanishing gradient problem and improving the accuracy of the deeper residual networks over their shallower counterparts.", "It should also be noted that the liberal use of batch normalization throughout the ResNet structure improves the stability of the network by re-centering and re-scaling the data as it passes through.", "The key components of ResNet50 are illustrated below. The CNN begins with an input stem followed by four stages that each have similar patterns.", "The first section is known as the input stem, which begins with a 7x7 convolution layer with a feature map size of 64 and a stride of 2, which is run against the input with a padding of 3. As seen below, this convolution reduces the image size from 224 to 112, while increasing the channel depth from 3 to 64.", "This is followed by a 3x3 max-pooling layer, again with stride 2, run against the output of the 7x7 conv with a padding of 1. Again, this reduces the image size \u2014 now down to 56x56 pixels.", "The output volume from the input stem is passed into Stage 1, which contains 3 residual blocks (ResBlock) each with 3 layers. Each convolutional step in the residual block has a stride of (1,1), resulting in no change in the output size but contains a bottleneck that reduces the depth of the feature map (number of channels) before restoring it. To do this, a 3x3 convolution is sandwiched between 1x1 convolutions that have differing numbers of feature maps, which reduce then expand the channel depth of the outputs. The main result is that we can apply more filters to the feature map in the same amount of time by reducing the computational load when calculating the 3x3 convolution.", "In each of Stages 2\u20134, the process is similar excepting the first residual block, which additionally downsamples the feature map, reducing the size of the input, using a 1x1 convolution with a stride of (2,2). This downsampling and bottlenecking block (Path A) can also be seen in the diagram below.", "However, there is now a mismatch in shape between the input and output volumes (256x56x56 vs 512x28x28 in the above example), which means we now need to adjust the all-important identity connection! This is done with a 1x1 convolution with stride (2,2), while increasing the depth by 2 to match the output. This is illustrated below, and the output volumes are added together at the end of the first ResBlock.", "In this way, as we progress from one stage to another, the channel width is doubled and the size of the input is reduced to half.", "This is a lot of detail into the precise structure of ResNets and ResBlocks, but will be necessary to understand the modern evolutions of ResNets!", "Pretrained ResNets 18 to 152 are implemented by default in fast.ai, which draw from the pretrained models available in torchvision. To use a pretrained ResNet34, for example, we can simply pass model=\u2019resnet34\u2019 and pretrained=true to the cnn_learner convenience function.", "See this github repo for a detailed working implementation of the ResNet models.", "Let\u2019s use the code prepared in Training with Controlled Randomness to train our clean dataset on a variety of ResNets and compare the results.", "As the size of the ResNet increases, we tend to see an increase in the accuracy of our predictions alongside an increase in the total training time. Let\u2019s now take a look at how more modern neural network architectures have evolved the ResNet.", "XResNets were introduced by Tong He of Amazon Web Services, building on the idea of ResNets by introducing a \u2018Bag of Tricks for Image Classification with Convolutional Neural Networks\u2019. xResNets simply feature three different tweaks, each with different names, focusing on improving three separate convolutional steps present in the ResNet architecture.", "xResNets: ResNets are great, but let\u2019s stop throwing away data and speed up the first convolution.", "xResNets simply feature three different tweaks, each with different names, focusing on three separate convolutional steps present in the ResNet architecture.", "A wide range of xResNets are implemented by default in fast.ai, however pretrained weights only exist for xResNet50. To use the architecture, we need import them into the global namespace using", "then set the specifics of the xResNet you want to use, where sa refers to the use of self-attention and n_out refers to the number of classes:", "before passing the model to the learner convenience function.", "Again, using the code set up in Training with Controlled Randomness, let\u2019s train our data using the pretrained xResNet50 architecture.", "Unfortunately the results of training using xResNet fall far short of the standard ResNets due to the quality of the pre-trained weights currently available. Nevertheless, xResNets have shown favourable results when compared to ResNets when training from scratch, and the kinds tweaks used in xResNet show how important the small details of layer choice in a CNN can theoretically improve performance.", "All CNNs use convolutional filters to extract information from images at different levels of detail. Layers near the input of a CNN find edges or gradients, while upper layers can detect progressively more complex geometrical shapes and patterns. As the data passes through the CNN, the spatial and channel information are fused through the use of multi-channel filters, the differences in output coming from the learned weights in each kernel. Crucially, each of the input channels are weighed equally when creating the output feature maps (for now).", "Squeeze-and-Excitation Nets \u2014 Not all channels are equally important, so let\u2019s give them weights.", "SE-Nets attempt to bias the allocation of available computational resources towards the most informative components of a signal by adding a mechanism to weight each channel. This weighting is done through a side network that parameterizes the weights and applies them to the feature map at the end of the block. This side network:", "Using this structure, a corresponding SE block can be created for any transformative CNN block, adding in feature recalibration for very little computational cost.", "The authors show that by adding SE-blocks to ResNet-50 enabled the model to deliver the same accuracy as ResNet-101, with minimal additional computational cost (around 1%)! Let\u2019s see for ourselves.", "To implement SE-ResNets, in the fast.ai ecosystem \u2014 we want the CNN architectures available as PyTorch nn.Sequentials. Oleg S\u00e9mery\u2019s github repo \u2018Sandbox for training convolutional networks for computer vision\u2019 provides a huge range of pre-trained models in the required PyTorch format, which is where we\u2019ll be sourcing all of our SE-ResNets.", "In Google Colabs, we can install and import the package using,", "From there, we can import models into the global namespace using,", "In this library, the model features are encapsulated in model.features, as a nn.Sequential. Each model head is actually in the model.output, so the above code grabs the model body while omitting the head. In this case, the last layer of SE-ResNet50 is just AvgPool2d, waiting for the appropriate head to be added for your classification task.", "In fast.ai, we can simply pass this pretrained model through to the cnn_learner helper function which does a few things behind the scenes. Namely,", "From there, we can train our newly created learner.", "See this github repo for a detailed working implementation of the SE-ResNet Models.", "Again, using the code set up in Training with Controlled Randomness, let\u2019s train our pretrained SE-ResNet architectures on our plant image dataset.", "Note that as a consequence of the larger model size, SE-ResNet152 had to be run with a batch size of 62 to prevent us from running out of GPU memory.", "As with ResNets, as the size of the SE-ResNet increases, we see an increase in the accuracy of our predictions alongside an increase in the total training time. Impressively, SE-ResNet50 has exceeded the accuracy of ResNet50 with significantly less training time (26 vs. 36 minutes).", "Developed by UC San Diego and Facebook AI Research (FAIR) in 2017, ResNeXt introduces the next dimension in convolutional neural network architectures \u2014 \u201ccardinality\u201d.", "ResNeXt \u2014 Taking ResNets to the next dimension with a split-transform-merge strategy.", "ResNeXt inherits the identity shortcut connection from ResNet and adapts the split-transform-merge strategy of Inception to increase the \u2018width\u2019 of a network by using multiple filters operating on the same level in a multi-branch architecture. Cardinality in this context controls the size of the set of transformations, i.e. the number of branches.", "Pictured above, each ResNeXt block splits their input into a number (equal to the cardinality) of lower-dimensional embeddings, each of which are then transformed by a identical set of filters (following the bottleneck design of the ResNet block), before being merged and subsequently added to the identity skip connection.", "In reality, the multi-branch blocks are replaced by functionally equivalent grouped convolutions (similar to AlexNet), due to their superior computational efficiency. Increasing cardinality has been shown to be a more effective way of increasing accuracy than going deeper or wider, especially when depth and width starts to give diminishing returns for existing models.", "The names of ResNeXt models reflect their cardinality and width of the bottleneck within each of the branching paths. For example, ResNeXt50_32x4d has a cardinality of 32 and bottleneck width of 4.", "To implement ResNeXts in the fast.ai ecosystem we again use Oleg S\u00e9mery\u2019s github repo \u2018Sandbox for training convolutional networks for computer vision\u2019. The pre-trained ResNeXt neural networks are provided as PyTorch nn.Sequentials for easy implementation.", "In Google Colabs, we can install and import the package using,", "We can then import models into the global namespace using,", "From there, the implementation is identical to the SE-ResNet example, where we can simply pass this pretrained model through to the cnn_learner helper function which will cut the network at the last pooling layer and append a Kaiming initialized fast.ai vision classification head.", "See this github repo for a detailed working implementation of the ResNeXt models.", "Again, using the code set up in Training with Controlled Randomness, let\u2019s train the pretrained SE-ResNet architectures on our plant image dataset.", "Under these training conditions, the ResNeXt architectures have comparable results to the SE-ResNet models. Here we feel the diminishing marginal returns on network size, with the significantly longer training times offering little improvement. However, without more hyperparameter optimization we can\u2019t conclusively say much about the potential performance of the larger ResNeXt101.", "SE-ResNeXts are (as you may expect) ResNeXt networks with an added squeeze-and-excitation step.", "Pre-trained SE-ResNeXt models are sourced from Oleg S\u00e9mery\u2019s github repo \u2018Sandbox for training convolutional networks for computer vision\u2019.", "In Google Colabs, we can install and import the package using,", "We can then import models into the global namespace by requesting them,", "From there, the implementation is identical to the SE-ResNet and ResNeXt examples, where we can simply pass this pretrained model through to the cnn_learner helper function which will cut the network at the last pooling layer and append a Kaiming initialized fast.ai vision classification head.", "See this github repo for a detailed working implementation of the SE-ResNeXt models.", "Again, using the code set up in Training with Controlled Randomness, let\u2019s train the pretrained SE-ResNeXt architectures on our plant image dataset.", "Combining the improvements of squeeze-and-excitation and ResNeXt architectures, the SE-ResNeXt models have slightly improved the accuracy of our results. SE-ResNeXt101 gives us the best overall results so far, without any further optimzation!", "EfficientNets were born from the marriage of two very simple ideas: use the best baseline network architecture we can find (EfficientNet-B0), and enhance the predictive capacity of the networks by scaling the base network\u2019s underlying network structure to increase accuracy in the most computationally efficient way possible (compound scaling).", "EfficientNets: Let\u2019s design the best network and scale it efficiently.", "The baseline neural network, EfficientNet-B0, was created by the authors using a multi-objective neural architecture search that optimizes both accuracy and FLOPS. The main building block of EfficientNet-B0 is the MBConv (mobile inverted bottleneck convolution) to which squeeze-and-excitation optimization is added.", "In a traditional ResBlock, the number of channels follows a wide/narrow/wide structure (also known as a bottleneck) along with the identity skip connection. The input has a high number of channels, which are compressed with a 1x1 convolution. The number of channels is then increased again with a 1x1 convolution so the identity skip connection can be added.", "The Inverted Residual Block, as the name suggests, uses a narrow/wide/narrow approach. A shallow input is widened using a 1x1 convolution before a 3x3 depthwise convolution is applied (greatly reducing the number of parameters). A 1x1 convolution is again used to reduce the number of channels so the identity skip connection can be added.", "This structure decreases the overall number of operations and model size, while still allowing EfficientNet-B0 to have a comparable Top-5 accuracy with ResNet-34 despite having a quarter of the trainable parameters and requiring nearly an order of magnitude less FLOPs to train.", "All convolutional neural networks (CNNs) have three dimensions: width, depth, and resolution. Depth refers to the number of layers, width refers to the number of channels (e.g. 3 channels in RGB) and the resolution refers to the number of pixels in an image. Each of these dimensions can be scaled, and each raise the accuracy of the CNN up to a point:", "The researchers found that balancing the amount of scaling in each of the dimensions of network width, depth, and resolution was necessary to extract the most amount of benefit with minimal increase in computational cost.", "In a CNN, the convolutional operations are the most computationally costly part of the network. Furthermore, the number of floating point operations (FLOPs) per convolutional operation are approximately proportional to d, w\u00b2, r\u00b2 i.e. doubling the depth will double the FLOPs whereas doubling the width or resolution will quadruple the FLOPs required. Based on these assumptions, the authors proposed a simple scaling technique that uses a compound coefficient \u0278 (related to the amount of available resources) to determine how to scale \u03b1, \u03b2, and \u03b3 (network width, depth, and resolution) in an efficient way.", "As discussed, this relationship states that scaling the network (in either depth, width or resolution) will increase the total FLOPS by (\u03b1\u00d7\u03b2\u00b2\u00d7\u03b3\u00b2)^\u0278 . The constraint (\u03b1\u00d7\u03b2\u00b2\u00d7\u03b3\u00b2)\u22482 is applied in order to make sure that the total FLOPs don\u2019t exceed 2^\u0278. Hence, we can use the compound coefficient \u0278 to scale the FLOPs required by the CNN by a known amount (2^\u0278).", "A baseline network EfficientNet-B0 was used to perform a grid-search with the compound coefficient \u0278 fixed at 1, resulting in the optimal values \u03b1 =1.2, \u03b2 = 1.1, and \u03b3 = 1.15. Then, fixing the optimal values \u03b1, \u03b2 and \u03b3 the researchers scaled the amount of available resources \u0278 to create the bigger EfficientNet-B1 to B7.", "One other interesting aspect is the use of the Swish activation function instead of ReLU, a small change that affords close to percentage increase in accuracy across a number of challenging datasets.", "To implement EfficientNets in the fast.ai ecosystem we turn to Ross Wightman\u2019s github repo \u2018(Generic) EfficientNets for PyTorch\u2019 , which specializes in providing a range of pre-trained EfficientNet and MobileNet models in the required PyTorch format. One of the main reasons we\u2019re using this repository is the provision of EfficientNets that have been self-trained with Noisy Student, that show a greater accuracy on the ImageNet-1K dataset.", "In Google Colabs, we can install and import the package using,", "We can then import models into the global namespace by requesting them,", "From there, the implementation is identical to any of the ResNet-based examples, where we can simply pass this pretrained model through to the cnn_learner helper function which will cut the network at the last pooling layer and append a Kaiming initialized fast.ai vision classification head.", "See this github repo for a detailed working implementation of the EfficientNet models.", "Note that EfficientNets using pre-trained weights obtained from self-training with Noisy Student are denoted with *ns.", "Interestingly, the EfficientNet models using pre-trained weights ported from TensorFlow have relatively poor results, possibly due to the pre-training on a different input image size or the influence of changing batch size. However, when the NoisyStudent pre-trained weights are used, the results of our transfer learning improve significantly. Indeed, each of the EfficientNet-b3 and b5 models perform best for their given amount of training time, with EfficientNet-b5 out-performing SE-ResNeXt101 on the given task.", "It\u2019s important to note that all the results shown here have no tuning of important hyperparameters such as learning rate or number of epochs. Indeed, in most cases the training and validation losses both have a downwards trend at the end of training, indicating that the models have further capacity for learning. Additionally, there is no k-fold cross validation, and the presented results are from a single run for each model.", "Regardless, we can still see a general pattern of improvement in the accuracy of our classifier as we move from model to model, each of which implement a few tweaks and advancements in convolutional neural network architecture.", "Next, we will be using these learners to explore some new optimizers, activation functions and regularization techniques!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fde4757eeeebf&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kenichinakanishi.medium.com/?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": ""}, {"url": "https://kenichinakanishi.medium.com/?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "Kenichi Nakanishi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9d8da6789697&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&user=Kenichi+Nakanishi&userId=9d8da6789697&source=post_page-9d8da6789697----de4757eeeebf---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde4757eeeebf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde4757eeeebf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/petsafe-plants-fastai", "anchor_text": "Classifying Pet-Safe Plants with fast.ai"}, {"url": "https://unsplash.com/@pixelkisses?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Siobh\u00e1n Polizzi"}, {"url": "https://unsplash.com/s/photos/puppy-plant?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-a29587f3f04c", "anchor_text": "Part 1: Building an Image Database"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Part 2: Training with Controlled Randomness"}, {"url": "https://towardsdatascience.com/targeting-and-removing-bad-training-data-8ccdac5e7cc3", "anchor_text": "Part 3: Targeting and Removing Bad Training Data"}, {"url": "https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6#e4a2", "anchor_text": "Deterministic learner"}, {"url": "https://arxiv.org/abs/1803.09820", "anchor_text": "largest batch size you could fit on memory"}, {"url": "https://arxiv.org/abs/1609.04836", "anchor_text": "recent research"}, {"url": "https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/", "anchor_text": "vary depending on the nature of the CNN architecture chosen"}, {"url": "https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/160147", "anchor_text": "post by Chris Deotte on Kaggle"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "Kaiming He et al. in 2015"}, {"url": "https://arxiv.org/abs/1603.05027", "anchor_text": "2016"}, {"url": "https://towardsdatascience.com/backpropagation-in-a-convolutional-layer-24c8d64d8509", "anchor_text": "backpropagations"}, {"url": "https://arxiv.org/pdf/1512.03385.pdf", "anchor_text": "original ResNet paper"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf", "anchor_text": "ResNet paper"}, {"url": "http://arxiv.org/abs/1502.03167", "anchor_text": "batch normalization"}, {"url": "https://www.kaggle.com/keras/resnet50", "anchor_text": "ResNet50"}, {"url": "https://arxiv.org/abs/1812.01187", "anchor_text": "xResNet paper"}, {"url": "http://pabloruizruiz10.com/resources/CNNs/Convolution_Pooling.pdf", "anchor_text": "Pablo Ruiz"}, {"url": "http://pabloruizruiz10.com/resources/CNNs/Convolution_Pooling.pdf", "anchor_text": "Pablo Ruiz"}, {"url": "https://fastai1.fast.ai/vision.models.html", "anchor_text": "implemented by default in fast.ai"}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_TorchVision_Models.ipynb", "anchor_text": "github repo"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness"}, {"url": "https://arxiv.org/abs/1812.01187", "anchor_text": "Bag of Tricks for Image Classification with Convolutional Neural Networks"}, {"url": "https://arxiv.org/abs/1812.01187", "anchor_text": "xResNet paper"}, {"url": "https://docs.fast.ai/vision.models.xresnet", "anchor_text": "A wide range of xResNets are implemented"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness"}, {"url": "https://forums.fast.ai/t/xresnet-transfer-learning/77537", "anchor_text": "quality of the pre-trained weights currently available"}, {"url": "https://medium.com/@lessw/how-we-beat-the-fastai-leaderboard-score-by-19-77-a-cbb2338fab5c", "anchor_text": "training from scratch"}, {"url": "https://www.robots.ox.ac.uk/~vgg/publications/2018/Hu18/hu18.pdf", "anchor_text": "original research paper"}, {"url": "https://github.com/osmr/imgclsmob", "anchor_text": "Sandbox for training convolutional networks for computer vision"}, {"url": "https://towardsdatascience.com/understand-kaiming-initialization-and-implementation-detail-in-pytorch-f7aa967e9138", "anchor_text": "Kaiming initialization"}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_PyTorchCV_Models.ipynb", "anchor_text": "github repo"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness"}, {"url": "https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202", "anchor_text": "Inception"}, {"url": "https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8", "anchor_text": "ResNet"}, {"url": "https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160", "anchor_text": "AlexNet"}, {"url": "https://github.com/osmr/imgclsmob", "anchor_text": "Sandbox for training convolutional networks for computer vision"}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_PyTorchCV_Models.ipynb", "anchor_text": "github repo"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness"}, {"url": "https://github.com/osmr/imgclsmob", "anchor_text": "Sandbox for training convolutional networks for computer vision"}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_PyTorchCV_Models.ipynb", "anchor_text": "github repo"}, {"url": "https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6", "anchor_text": "Training with Controlled Randomness"}, {"url": "https://arxiv.org/abs/1709.01507v4", "anchor_text": "squeeze-and-excitation"}, {"url": "https://medium.com/@neuralnets/swish-activation-function-by-google-53e1ea86f820#:~:text=So%20Google%20Brain%20Team%20has,number%20of%20challenging%20data%20sets.", "anchor_text": "Swish"}, {"url": "https://github.com/rwightman/gen-efficientnet-pytorch", "anchor_text": "(Generic) EfficientNets for PyTorch"}, {"url": "https://medium.com/@nainaakash012/self-training-with-noisy-student-f33640edbab2", "anchor_text": "Noisy Student"}, {"url": "https://github.com/kenichinakanishi/houseplant_classifier/blob/master/Part_4_Geffnet_Models.ipynb", "anchor_text": "github repo"}, {"url": "https://medium.com/@nainaakash012/self-training-with-noisy-student-f33640edbab2", "anchor_text": "Noisy Student"}, {"url": "https://cv-tricks.com/keras/understand-implement-resnets/#:~:text=Every%20ResNet%20architecture%20performs%20the,blocks%20containing%203%20layers%20each", "anchor_text": "Detailed Guide to Understand and Implement ResNets"}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "An Overview of ResNet and its Variants"}, {"url": "https://medium.com/@waya.ai/deep-residual-learning-9610bb62c355", "anchor_text": "Understand Deep Residual Networks"}, {"url": "https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8", "anchor_text": "Understanding and visualizing ResNets"}, {"url": "https://towardsdatascience.com/xresnet-from-scratch-in-pytorch-e64e309af722", "anchor_text": "xResNet From Scratch in Pytorch"}, {"url": "https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7", "anchor_text": "Squeeze-and-Excitation Networks"}, {"url": "https://towardsdatascience.com/review-senet-squeeze-and-excitation-network-winner-of-ilsvrc-2017-image-classification-a887b98b2883", "anchor_text": "Review: SENet \u2014 Squeeze-and-Excitation Network, Winner of ILSVRC 2017 (Image Classification)"}, {"url": "https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7", "anchor_text": "Squeeze-and-Excitation Networks"}, {"url": "https://arxiv.org/abs/1611.05431", "anchor_text": "Aggregated Residual Transformations for Deep Neural Networks"}, {"url": "https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac", "anchor_text": "Review: ResNeXt \u2014 1st Runner Up in ILSVRC 2016 (Image Classification)"}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "An Overview of ResNet and its Variants"}, {"url": "https://medium.com/@lessw/efficientnet-from-google-optimally-scaling-cnn-model-architectures-with-compound-scaling-e094d84d19d4", "anchor_text": "EfficientNet from Google \u2014 Optimally Scaling CNN model architectures with \u201ccompound scaling\u201d"}, {"url": "https://towardsdatascience.com/efficientnet-scaling-of-convolutional-neural-networks-done-right-3fde32aef8ff", "anchor_text": "EfficientNet: Scaling of Convolutional Neural Networks done right"}, {"url": "https://towardsdatascience.com/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c", "anchor_text": "State-Of-The-Art Image Classification Algorithm: FixEfficientNet-L2"}, {"url": "https://arxiv.org/abs/1905.11946", "anchor_text": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"url": "https://medium.com/tag/petsafe-plants-fastai?source=post_page-----de4757eeeebf---------------petsafe_plants_fastai-----------------", "anchor_text": "Petsafe Plants Fastai"}, {"url": "https://medium.com/tag/fastai?source=post_page-----de4757eeeebf---------------fastai-----------------", "anchor_text": "Fastai"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----de4757eeeebf---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/image-classification?source=post_page-----de4757eeeebf---------------image_classification-----------------", "anchor_text": "Image Classification"}, {"url": "https://medium.com/tag/resnet?source=post_page-----de4757eeeebf---------------resnet-----------------", "anchor_text": "Resnet"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fde4757eeeebf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&user=Kenichi+Nakanishi&userId=9d8da6789697&source=-----de4757eeeebf---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fde4757eeeebf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&user=Kenichi+Nakanishi&userId=9d8da6789697&source=-----de4757eeeebf---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde4757eeeebf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fde4757eeeebf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----de4757eeeebf---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----de4757eeeebf--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----de4757eeeebf--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----de4757eeeebf--------------------------------", "anchor_text": ""}, {"url": "https://kenichinakanishi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kenichinakanishi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kenichi Nakanishi"}, {"url": "https://kenichinakanishi.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "33 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9d8da6789697&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&user=Kenichi+Nakanishi&userId=9d8da6789697&source=post_page-9d8da6789697--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F46e23b30274b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf&newsletterV3=9d8da6789697&newsletterV3Id=46e23b30274b&user=Kenichi+Nakanishi&userId=9d8da6789697&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}