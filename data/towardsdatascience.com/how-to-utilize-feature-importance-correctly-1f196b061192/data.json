{"url": "https://towardsdatascience.com/how-to-utilize-feature-importance-correctly-1f196b061192", "time": 1683018370.265656, "path": "towardsdatascience.com/how-to-utilize-feature-importance-correctly-1f196b061192/", "webpage": {"metadata": {"title": "Python Feature Importance detection | Towards Data Science", "h1": "How to utilize Feature Importance correctly", "description": "Feature Importance is a critical strategy to determine a good model in machine learning. Detecting the correct ones improves the performance significantly."}, "outgoing_paragraph_urls": [{"url": "http://from sklearn.feature_selection import SelectFromModel X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html", "anchor_text": "detail", "paragraph_index": 6}, {"url": "https://scikit-learn.org/stable/modules/permutation_importance.html", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston", "anchor_text": "source", "paragraph_index": 8}], "all_paragraphs": ["In training a machine learning model, the ideal thing is to condense the training features into a set of variables that contain as much information as possible. There are 3 reasons for this. 1, reducing the number of features means narrowing down the dimension, reducing sparsity, and increasing the statistical significance of the training result. If we have too many features, we will also need a larger number of samples representative enough for training. 2, reducing sparsity helps to prevent the over-fitting problem (the more the number of features, the more complex the model becomes, hence more tendency to be over-fitting). 3, which is obvious, is the efficient saving of computation power while achieving acceptable performance.", "Thus, feature selection is an important step in preprocessing data. Among popular approaches, feature importance is one of the most popular ones. However, choosing features through Feature Importance is not always as straight as an arrow. It is indeed required some techniques to make the right decision for selection.", "However, from my experience, I usually use feature importance after conducting other data cleaning, preprocessing steps as below.", "There are several ways to express Feature Importance. It can be score representing the features\u2019 relevancy (using algorithm-based Feature Importance, such as tree-based Random Forest, XGBoost,..), dimension reduction from original features to synthesize all the information to a lower dimension (like Autoencoder or PCA), or domain knowledge selection (aka selection based on your own knowledge). With the variety of choices like this, which one should we choose? Even when we choose to use PCA, selecting the right number of remaining features seems to demand great exertion. Don\u2019t you think we should go with the Feature Importance score or testing everything and see which performs the best?", "Yes, it\u2019s correct, testing everything is the accurate answer. From my experience, I usually set the baseline as the original model without any selection, then try PCA with different drop-out ratios and check the metric. Then drop original features (mainly because I want to limit the amount of collected data needed, as well as optimize the training time while maintain or improve the performance). So Dimension Reduction is my first choice and the Feature Importance is the next essential step. But using only the Feature Importance score is hardly a good choice. Let me show you why.", "Feature Importance score here means any score generated from the trained model representing the weight or relevancy of the features to the prediction of the target feature.", "Below are the feature importance scores of Random Forest calculated based on RandomForestRegressor model (detail of formula is here), selecting feature with SelectFromModel (detail), and permutation score (detail of formula is here). Data used for demonstration is California housing in sklearn.", "Looking at the above, how confident are you in deciding to keep only MedInc and drop others (based on the first graph) or to retain MedInc, Latitude, Longitude, and AveOccup based on the second one, or even just drop AveBedrms and Population? If I were you, I merely can make any decision with this. Why? Because dropping this or that does not ensure better performance, it even leads to a worse one if you choose unconsciously.", "The selection from the Permutation score slightly improves from the original dataset. Let\u2019s see another experiment with the Boston dataset (source).", "This looks more consistent than the California dataset, doesn\u2019t it? I guess the decision to keeping \u2018RM\u2019 and \u2018LSTAT\u2019 features is much more confident now. Let see how the performance changes if the model is trained on these 2 features.", "None of these selections performs equally on par with the original model, which means reducing features does not work here. These 2 examples show different strategies on how to reduce the number of features, and either the metric or the score can help us decide here.", "\u201cNo, we need a different approach!\u201d", "There is one way to decide better which features should be removed. This technique is traditional but effective and holistic.", "We decide by seeing the performance of the model after dropping features.", "First let\u2019s drop each feature one at a time, then drop one after another, measure their performance, and decide the elbow or the level that is sufficient.", "Dropping any among HouseAge, AveRooms, Population and AveBedrms obviously retain the performance at the same level with the original. However, removing MedInc surprisingly lowers the test MSE.", "When dropping them cumulatively from the least relevant feature to the most relevant (based on Feature Importance score), we can clearly see that the elbow in train MSE appeared when removing Latitude and other features prior to it, but the overfitting issue was worsened at the time dropping Longitude. Hence, we have more confidence to condense the model into 4 features: \u201cLongitude\u201d, \u201cLatitude\u201d, \u201cAveOccup\u201d, \u201cMedInc\u201d.", "Let\u2019s take a look at the Boston dataset.", "Removing either RM, LSTAT or DIS worsens the performance, and if we only keep RM, LSTAT or DIS in the model, not only the train MSE but also test MSE significantly picked up. From looking at this, we can decide to keep NOX, CRIM, DIS, LSTAT, and RM.", "The score is not the only way to go. Using only the score to decide the approach in feature selection seems to be subjective and empirical. Using the appropriate method is like deciding the right metric for your model. Knowing exactly why you do that and what effect it brings to the model are keys to the next success for your machine learning.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1f196b061192&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1f196b061192--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1f196b061192--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@hoanganhquynhnhu?source=post_page-----1f196b061192--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hoanganhquynhnhu?source=post_page-----1f196b061192--------------------------------", "anchor_text": "Nhu Hoang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffd0309208c7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&user=Nhu+Hoang&userId=fd0309208c7b&source=post_page-fd0309208c7b----1f196b061192---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1f196b061192&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1f196b061192&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@vonshnauzer", "anchor_text": "Egor Myznik"}, {"url": "https://unsplash.com/photos/DRs9XsNlAZw", "anchor_text": "Unsplash"}, {"url": "http://from sklearn.feature_selection import SelectFromModel X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html", "anchor_text": "detail"}, {"url": "https://scikit-learn.org/stable/modules/permutation_importance.html", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston", "anchor_text": "source"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1f196b061192---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/feature-engineering?source=post_page-----1f196b061192---------------feature_engineering-----------------", "anchor_text": "Feature Engineering"}, {"url": "https://medium.com/tag/feature-importance?source=post_page-----1f196b061192---------------feature_importance-----------------", "anchor_text": "Feature Importance"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1f196b061192---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/metrics?source=post_page-----1f196b061192---------------metrics-----------------", "anchor_text": "Metrics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1f196b061192&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&user=Nhu+Hoang&userId=fd0309208c7b&source=-----1f196b061192---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1f196b061192&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&user=Nhu+Hoang&userId=fd0309208c7b&source=-----1f196b061192---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1f196b061192&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1f196b061192--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1f196b061192&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1f196b061192---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1f196b061192--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1f196b061192--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1f196b061192--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1f196b061192--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1f196b061192--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1f196b061192--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1f196b061192--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1f196b061192--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hoanganhquynhnhu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hoanganhquynhnhu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nhu Hoang"}, {"url": "https://medium.com/@hoanganhquynhnhu/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "74 Followers"}, {"url": "http://M.Sc", "anchor_text": "M.Sc"}, {"url": "http://linkedin.com/in/nhu-hoang/", "anchor_text": "linkedin.com/in/nhu-hoang/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffd0309208c7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&user=Nhu+Hoang&userId=fd0309208c7b&source=post_page-fd0309208c7b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7bf4dd50274&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-utilize-feature-importance-correctly-1f196b061192&newsletterV3=fd0309208c7b&newsletterV3Id=e7bf4dd50274&user=Nhu+Hoang&userId=fd0309208c7b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}