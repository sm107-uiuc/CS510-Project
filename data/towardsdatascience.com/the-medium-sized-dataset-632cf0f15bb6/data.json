{"url": "https://towardsdatascience.com/the-medium-sized-dataset-632cf0f15bb6", "time": 1683006931.7775328, "path": "towardsdatascience.com/the-medium-sized-dataset-632cf0f15bb6/", "webpage": {"metadata": {"title": "The Medium-Sized Dataset. Too big for RAM, too small for a\u2026 | by Jo\u00e3o Paulo Figueira | Towards Data Science", "h1": "The Medium-Sized Dataset", "description": "Small datasets are cool. You can load them into memory and manipulate them at will, no sweat. Massive datasets are also cool. They have lots of data and the promise of exciting models and analyses\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.sqlite.org/index.html", "anchor_text": "SQLite", "paragraph_index": 2}, {"url": "https://sqlitestudio.pl/", "anchor_text": "SQLiteStudio", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1905.02081", "anchor_text": "Vehicle Energy Dataset", "paragraph_index": 5}, {"url": "https://github.com/gsoh/VED", "anchor_text": "GitHub repository", "paragraph_index": 6}, {"url": "https://github.com/joaofig/ved-explore", "anchor_text": "GitHub repository", "paragraph_index": 7}, {"url": "https://github.com/joaofig/ved-explore/blob/master/1-download-ved.ipynb", "anchor_text": "Jupyter notebook", "paragraph_index": 11}, {"url": "https://github.com/joaofig/ved-explore", "anchor_text": "GitHub repository", "paragraph_index": 11}, {"url": "https://github.com/joaofig/ved-explore/blob/master/2-import-data.ipynb", "anchor_text": "second notebook", "paragraph_index": 17}, {"url": "https://github.com/joaofig/ved-explore", "anchor_text": "GitHub repository", "paragraph_index": 17}, {"url": "https://python-visualization.github.io/folium/", "anchor_text": "Folium", "paragraph_index": 33}, {"url": "https://python-visualization.github.io/folium/modules.html?highlight=polyline#folium.vector_layers.PolyLine", "anchor_text": "PolyLine", "paragraph_index": 33}, {"url": "https://arxiv.org/abs/1905.02081", "anchor_text": "Vehicle Energy Dataset (VED), A Large-scale Dataset for Vehicle Energy Consumption Research", "paragraph_index": 36}, {"url": "http://tblx.io", "anchor_text": "tblx.io", "paragraph_index": 38}], "all_paragraphs": ["Small datasets are cool. You can load them into memory and manipulate them at will, no sweat. Massive datasets are also cool. They have lots of data and the promise of exciting models and analyses. You gladly pay the price of the required cluster just to handle all that goodness. Medium-sized datasets are a pain. They are either small enough to fit your RAM but too cumbersome to handle or just a bit larger than your memory but not worthy of the cluster cost. How do you tackle such a scenario?", "There are several solutions to handle medium-sized datasets, and my favorite is to use a local database. You can fit the data in local storage and just bring into memory what you need to handle. An old but proven solution.", "My regular setup is the Jupyter notebook supported by the Python machine learning and data analysis ecosystem. A natural local database choice for such an environment is SQLite. The Python distribution comes packaged with an implementation of this database with a straightforward and intuitive API.", "In this article, I illustrate such use with a dataset of vehicle fuel and electric energy consumption, which is medium-size, as described above.", "Before we move along, I advise you to install an SQLite database editor such as SQLiteStudio. Tools such as this one will make your life easier when creating and inspecting your dataset, and I have found their use to be invaluable.", "In 2019 G. S. Oh, David J. Leblanc, and Huei Peng published a paper on the Vehicle Energy Dataset (VED) containing one year\u2019s worth of vehicle trajectory and energy consumption data. These data were collected from November 2017 to November 2018 in Ann Arbor and refer to a sample of 383 vehicles of diverse types and power sources. Please see the paper for an official description of the dataset and its contents.", "The dataset is distributed from the authors\u2019 GitHub repository and consists of two subsets named dynamic and static data. The former contains all the collected signal data, while the latter consists of two Microsoft Excel files containing information about the studied vehicles. Two compressed files contain the whole dynamic dataset.", "All the code illustrated below is available on the article\u2019s GitHub repository.", "To download the data, we can simply clone the repository to the local storage. This process is quite easy to do:", "Once cloned, the newly created local directory contains the license file, a documentation file, and a data directory with both datasets. Before proceeding, we must first decompress the dynamic data files with a specific tool:", "Please note that you may have to install the appropriate file compression tool for the above command lines to work. Once completed, the local data directory will have 55 CSV files with the weekly dynamic data. We are now ready to read them and insert them into an SQLite database.", "You can find the download and decompression process implemented as the first Jupyter notebook in the accompanying GitHub repository.", "Before we can use it, we must first create the SQLite database through the provided Python API. To make the whole process more straightforward and more comfortable to manage, I created a higher level class to interface with the database. To access it, you just need to instantiate an object:", "The object instantiation executes several tasks behind the scenes, such as opening the database file and, if it does not yet exist, create it along with a baseline structure. The code creates the database tables and indexes using externally stored SQL scripts such as the one below that creates the table containing all vehicles.", "An external JSON file encodes the execution order for these files. This setup allows for a straightforward extension of both SQL files and their execution order. Here is a sample of the JSON file\u2019s contents at the time of this writing:", "The \u201csequence\u201d tag contains a list with the names of the JSON tags to execute in order, so in this case, we start by creating the tables and then the indexes. Each entry in the \u201ctables\u201d list is the relative path to the SQL script to execute. The base path is a default constructor parameter.", "With the database ready to use, we can start importing the data from the downloaded VED data files.", "The VED dynamic data lives in several manageable CSV files, so we can read them one at a time into a Pandas DataFrame and batch insert the data into the database. The Pandas library makes it quite easy to read CSV files, so we can use it to ease reading the data into memory. Here\u2019s the code to do so (please refer to the second notebook in the GitHub repository):", "The function that inserts signals also uses a SQL script that is externally stored. To manage these external references, I created a class that loads the SQL scripts from storage on-demand and stores them in memory using a dictionary. This solution has the advantage of allowing you to change the SQL script without changing the Python code, and the memory caching means that you only take a small performance hit when loading the text file the first time. The next time will have a near-zero performance impact. Here is how the function looks:", "As you might have guessed, the script\u2019s key name is the file\u2019s relative pathname without the extension.", "The same process applies to the static dataset, but this time using Panda\u2019s functions to read Excel files into DataFrames.", "To illustrate how to explore the dataset using the SQLite interface, let us start by profiling the types of vehicles that generated data. We start by issuing a query and storing the result in a Pandas DataFrame:", "With all the vehicle data loaded into DataFrame, we can use the standard query methods to reveal the data structure:", "This command produces the following output:", "We can also run quick inspections through the head and tail functions, like this:", "We can now proceed to some more sophisticated and insightful analyses using the simple tools described above. The presence of high-frequency location data in the dataset allows us to perform trajectory analyses to help characterize the vehicle behaviors. Detecting individual vehicle trips, between known stop locations, is usually a complicated process. Fortunately, we are in luck with this dataset, as the data anonymization process baked that for us.", "The data collection process for the VED ensured driver anonymization through a relatively simple three-step approach. This process turned out to be quite relevant to this study as it produced, as a by-product, a critical piece of information: individualized vehicle trajectories. To anonymize the driver information, the study authors applied techniques of Random Fogging, Geo-fencing, and Major Intersection Bounding. The random fogging method removes observed locations near the start and the end of the trip. The geo-fencing technique clips observations outside a bounding box defined around the city\u2019s boundaries. The authors also clipped trips around the first and last significant intersections. Besides driver anonymization, these procedures also have the benefit of producing individual trajectories that are readily usable.", "After some cursory inspection, it is easy to realize that we can identify trips using two features only, namely the \u201cday number\u201d and the vehicle identifier. Let us first count the number of different individual vehicle trips.", "There are over thirty-two thousand trips in the dataset. Knowing how to identify vehicle trips uniquely, we can create a table containing summary information about each one. This table will prove its usefulness as an index into the signal table when iterating over trips and also help in aggregating trips per vehicle.", "The database startup code created an extra table named \u201cmove\u201d to store each trip identifier. We can fill this table using a more complex query:", "You can try running this from the notebook using the \u201cquery\u201d function or use a ready-made shortcut in the database interface object:", "This function illustrates the principle of decoupling the SQL script from the Python code. It starts by loading the text through the SQL script caching object and then executes it. The result is a table with all the unique trips for each vehicle. If we need to inspect the journeys of a single car, we can do so using simple queries with joins to the signal table to pull up the necessary detailed information. Let us illustrate this using a map.", "To extract the geographic information of an arbitrary trip, we can use the \u201cmove\u201d table as a selector into the \u201csignal\u201d table.", "There are two things to note about the code above. First, I selected an arbitrary trip through its unique identifier. A more realistic scenario would involve selecting a vehicle and a period for a trip inspection. Second, this version of the query function returns a list of tuples with the same order as declared in the SQL text. This arrangement is quite convenient as we can immediately feed the query\u2019s return to the map object of choice, a Folium PolyLine.", "In this article, I showed how to use SQLite as a partial alternative to Pandas when it comes to managing medium-sized datasets. This approach can be especially practical when you are short in RAM. By mixing the familiar Pandas API with a bit of SQL, you can perform compelling analyses on datasets that would not comfortably fit in your main memory.", "I will follow up on this article with more in-depth analyses of the VED, as it is such an intriguing dataset, mixing geographic information with vehicle energy performance data. Stay tuned for the forthcoming articles.", "[1] G. S. Oh, David J. Leblanc, Huei Peng. Vehicle Energy Dataset (VED), A Large-scale Dataset for Vehicle Energy Consumption Research.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Addicted to math and data, slightly off-centered. Data Scientist at tblx.io"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F632cf0f15bb6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@joao.figueira?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joao.figueira?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "Jo\u00e3o Paulo Figueira"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F64bc009cedeb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&user=Jo%C3%A3o+Paulo+Figueira&userId=64bc009cedeb&source=post_page-64bc009cedeb----632cf0f15bb6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F632cf0f15bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F632cf0f15bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral", "anchor_text": "Martin Sanchez"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.sqlite.org/index.html", "anchor_text": "SQLite"}, {"url": "https://sqlitestudio.pl/", "anchor_text": "SQLiteStudio"}, {"url": "https://arxiv.org/abs/1905.02081", "anchor_text": "Vehicle Energy Dataset"}, {"url": "https://github.com/gsoh/VED", "anchor_text": "GitHub repository"}, {"url": "https://github.com/joaofig/ved-explore", "anchor_text": "GitHub repository"}, {"url": "https://github.com/gsoh/VED.git", "anchor_text": "https://github.com/gsoh/VED.git"}, {"url": "https://github.com/joaofig/ved-explore/blob/master/1-download-ved.ipynb", "anchor_text": "Jupyter notebook"}, {"url": "https://github.com/joaofig/ved-explore", "anchor_text": "GitHub repository"}, {"url": "https://github.com/joaofig/ved-explore/blob/master/2-import-data.ipynb", "anchor_text": "second notebook"}, {"url": "https://github.com/joaofig/ved-explore", "anchor_text": "GitHub repository"}, {"url": "https://python-visualization.github.io/folium/", "anchor_text": "Folium"}, {"url": "https://python-visualization.github.io/folium/modules.html?highlight=polyline#folium.vector_layers.PolyLine", "anchor_text": "PolyLine"}, {"url": "https://arxiv.org/abs/1905.02081", "anchor_text": "Vehicle Energy Dataset (VED), A Large-scale Dataset for Vehicle Energy Consumption Research"}, {"url": "https://github.com/joaofig/ved-explore", "anchor_text": "GitHub repository"}, {"url": "https://sqlitestudio.pl/", "anchor_text": "SQLiteStudio"}, {"url": "https://towardsdatascience.com/geographic-clustering-with-hdbscan-ef8cb0ed6051", "anchor_text": "Geographic Clustering with HDBSCANHow to explore geographic data with HDBSCAN, H3, graph theory, and OSM.towardsdatascience.com"}, {"url": "https://www.linkedin.com/in/joao-paulo-figueira/", "anchor_text": "Jo\u00e3o Paulo Figueira - Data Scientist - tb.lx by Daimler Trucks & Buses | LinkedInView Jo\u00e3o Paulo Figueira's profile on LinkedIn, the world's largest professional community. Jo\u00e3o Paulo has 1 job listed\u2026www.linkedin.com"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----632cf0f15bb6---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----632cf0f15bb6---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/sqlite?source=post_page-----632cf0f15bb6---------------sqlite-----------------", "anchor_text": "Sqlite"}, {"url": "https://medium.com/tag/pandas?source=post_page-----632cf0f15bb6---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/vehicle-tracking?source=post_page-----632cf0f15bb6---------------vehicle_tracking-----------------", "anchor_text": "Vehicle Tracking"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F632cf0f15bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&user=Jo%C3%A3o+Paulo+Figueira&userId=64bc009cedeb&source=-----632cf0f15bb6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F632cf0f15bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&user=Jo%C3%A3o+Paulo+Figueira&userId=64bc009cedeb&source=-----632cf0f15bb6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F632cf0f15bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F632cf0f15bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----632cf0f15bb6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----632cf0f15bb6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joao.figueira?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joao.figueira?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jo\u00e3o Paulo Figueira"}, {"url": "https://medium.com/@joao.figueira/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "491 Followers"}, {"url": "http://tblx.io", "anchor_text": "tblx.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F64bc009cedeb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&user=Jo%C3%A3o+Paulo+Figueira&userId=64bc009cedeb&source=post_page-64bc009cedeb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F33fec95e18df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-medium-sized-dataset-632cf0f15bb6&newsletterV3=64bc009cedeb&newsletterV3Id=33fec95e18df&user=Jo%C3%A3o+Paulo+Figueira&userId=64bc009cedeb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}