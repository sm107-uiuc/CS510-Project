{"url": "https://towardsdatascience.com/uncovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14", "time": 1683003362.183653, "path": "towardsdatascience.com/uncovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14/", "webpage": {"metadata": {"title": "Uncovering the Cosmos: Machine Learning Approach to Finding Exoplanet Candidates and Other Anomalies | by Glenn Kroegel | Towards Data Science", "h1": "Uncovering the Cosmos: Machine Learning Approach to Finding Exoplanet Candidates and Other Anomalies", "description": "The field of astronomy is increasingly becoming a big data problem, with data entering the terabyte range and trending upward with larger surveys and more precise instruments. This is even more true\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=gypAjPp6eps", "anchor_text": "KIC 8462852 (Tabby\u2019s Star)", "paragraph_index": 8}, {"url": "https://github.com/facebookresearch/faiss/", "anchor_text": "Faiss", "paragraph_index": 50}, {"url": "https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index", "anchor_text": "here", "paragraph_index": 52}, {"url": "https://www.linkedin.com/in/glenn-kroegel/", "anchor_text": "LinkedIn", "paragraph_index": 73}], "all_paragraphs": ["The purpose of a beacon or lighthouse is to show others the way in the darkness. There\u2019s some troubling implications when we observe the vast ocean of the night and nobody has lit one. \u2014 Issac Arthur", "The field of astronomy is increasingly becoming a big data problem, with data entering the terabyte range and trending upward with larger surveys and more precise instruments. This is even more true in the broader field of physics. Every hour, The Large Hadron Collider obtains more data than Facebook does in an entire year. Feedback can therefore be slow and discoveries can exist in datasets for years before they are uncovered.", "I outline a machine learning based method that allows us to do:", "I then apply this method to real astronomical data obtained from recent satellite observations.", "We currently do not have the resolution to be able to visually distinguish fine details of neighboring solar systems. However, we have a good understanding of physics to understand what is going on through indirect measurements. One of these is the stars brightness.", "If a phenomena (natural or otherwise) is taking place around a star, we can expect its indirect effects to be present in the brightness of the star over time. Stars dim if an object gets in the way with the dimming proportional to the apparent size of that object relative to the star. Based on the profile of the brightness curve, we can infer properties about the object such as its size and how close it is to the star. This is the primary method used to find exoplanets and is known as the transit method.", "There are several things to keep in mind when analyzing this sort of data. Particularly for searching for natural phenomena like planets.", "Ultimately the goal is to analyze the time series information from transit method measurements to find objects of interest.", "Despite being limited to objects in the same plane as the solar system, the vast quantity of stars in the galaxy is so enormous that this still results in hundreds of thousands or millions of light curves just from one survey. Each measurement would also have thousands of data points and additional information. Dashboards have been developed for citizen scientists to assist in helping astronomers process the data. The now famous KIC 8462852 (Tabby\u2019s Star) was discovered this way. This approach does mean data can be stored in the back-end narrowing computational requirements to one place. But the following problems still exist:", "A method that gives us fast feedback is useful especially if we want to do follow up measurements with other instruments. If the amount of data in a survey is trending upwards, solutions to the above problems need to be cheap, fast and scalable.", "This is where several useful machine learning concepts can be introduced.", "Most people not in the field understand the concept of a machine learning model making a class prediction whether that be binary (yes or no) or multi-class. Unfortunately, in many real world cases these labels might not be available or reliable. Even if you have the time and resources, the correct labeling of data might not even be that useful, and not every practitioner interested in the data would be interested in the same labels. What we want is to utilize the potential of deep learning architectures to understand complex structures and return insights in an unsupervised way.", "Consider the following. If I was to ask a person whether two paintings were similar, there often wouldn\u2019t (just) be a few distinct features that would make them so. Our language can sometimes be insufficient to describe why they are similar but you know they are in a hand-wavy kind of way that has to do with style etc. This is because we have a complex higher order understanding (or feeling) of what we\u2019re seeing than we can necessarily write down or communicate.", "Deep learning models work by understanding an input in the form of an array of numbers or vector representation. Even if we do a classification problem, all we are doing is converting the final layer of the network from this vector representation to an explicit output. Because of all the non-linearities in the network these representations are generally not human interpretable.", "With our light curves, we don\u2019t want to do a prediction, but rather make the model turn the light curve into one of these vector representations that captures all of its structure. When we want insights or do searches, we eventually will just be working with this representation.", "Now that we have a way of representing the complexity of all of our light curves in the same way, we can perform clustering and evaluate similarity. We also can decide how large we want this representation to be thus making it a useful for compression.", "If we imagine each vector as a point in space, where each number corresponds to a coordinate like a latitude or longitude, we can extract information by its location as well as distance and orientation relative to other points. This is essentially the basis of similarity.", "Often the orientation of two data points relative to each other is more revealing than their euclidean (L2) distance. If we have a vector representation of our data the orientation of two vectors is just their normalized (by magnitude) dot product.", "Since the operation is simple, the calculation is extremely fast even in high level languages as they often run arithmetic operations in C under the hood.", "For pure software minded people there is a temptation to logically think as the summations as a group of for loops. But processors actually have special arithmetic operations on a very low level known as a fused multiply-add, which combines the operations and is faster than doing a multiplication and an addition separately. So for a similarity search, we want to exploit this arithmetic if we want to maximize speed. Doing this will be orders of magnitude faster than any manual implementation in a high level language. This is another reason we want to convert the data into a latent vector representation. Understanding this is the key to doing similarity searches on the scale of billions with reasonable hardware.", "However, there are some caveats to this metric that need to be discussed as the concept of similarity in time series is not straight forward like other data types. There are similarity metrics that are arguably more suited to time series similarity including:", "While keeping this in mind for future work, I demonstrate later that cosine similarity is still adequate for the problem we are trying to solve.", "In order to obtain a model that gives us the vector representations we need to train a neural network. Even though we are doing this unsupervised, we still need to give the model a task to solve.", "An auto-encoder is a type of architecture consisting of two parts \u2014 the encoder and decoder. The encoder reduces the data to a vector representation of our choice, and the decoder attempts to reconstruct the signal from this representation. Because they are trained together the encoder will attempt to find the most meaningful representation such that the decoder can create the most accurate reconstruction.", "Since we are dealing with time series there are two types of input reconstruction we can use for training:", "Interpolation \u2014 Given a time series with values in the interval [t\u2080, t\u2099] we condition on a subset of the points with a probability of say 10\u201350% and then attempt to reconstruct the full signal within that same range.", "Extrapolation \u2014 Given a time series with values in the interval [t\u2080, t\u2082\u2099]we encode the first half of the signal [t\u2080, t\u2099] and try reconstruct the second half [t\u2099, t\u2082\u2099]. Like interpolation, we can condition on a subset of the points on the first interval.", "For the purpose of getting an encoding for a light curve I opted for the interpolation method given our goal is to compare signals and not necessarily forecast.", "Recurrent Neural Networks (RNNs) are the dominant type of architecture for time series due to their ability to capture long term dependency. However, if the time series is irregularly sampled, various workarounds are generally used. Until recently, a common approach to handling this problem was to pass time step information as an input feature alongside the signal, impute values at missing points, or do a fixed time discretization at a resolution greater than the largest gaps and aggregate the values.", "Recent developments in the area of Neural Ordinary Differential Equations has allowed us to fit missing time points better by turning RNNs into continuous time models. This was explored in the paper Latent ODEs for Irregularly-Sampled Time Series and is referred to as an ODE-RNN.", "The ability to handle irregularly sampled time series is an extremely useful ability for our encoder as our vector representations will be more indicative of the true dynamics of the light curves. This is particularly useful if there are several follow up measurements with time gaps in between. We can use this as our networks encoder.", "Launched in 2018, TESS is the first space-borne mission to the search the entire sky for exoplanets. It does this by dividing the sky into 13 observation sectors per hemisphere. Each sector is observed for 27 days, recording a measurement every 2 minutes before re-orientating to repeat the process for the next sector. The focus is on nearby stars, with each sector observing approximately 200,000 stars. At the time of writing, 17 out of the 26 intended sectors for the primary mission were completed with the data available to the public. The time series data for each sector is approximately 40GB so I focused my analysis on the two most recent (16 and 17).", "The TESS data contains object ids and various measurements with an associated timestamp. I grouped the timestamp and flux (brightness) by object id. The following pre-processing steps were then implemented:", "I trained a multi-layer ODE-RNN but made the following modifications to the Latent ODE repository as I found they gave better results for my task:", "Training was done on a random subset of 5000 from the total dataset using a batch size of 10. The Adamax optimizer was used with a fixed learning rate of 1e-3. The selected latent dimension was 40. Training was done on a NVIDIA GTX 1070 with 12GB GDDR5 RAM.", "After training, the goal is to then convert all of our light curves into our latent representation.", "Although training the encoder and decoder together, we only use the encoder to calculate the latent representation of each light curve during inference. This only needs to do be done once and is a lot faster in evaluating results than during training as we are not updating any gradients, nor do we have to keep all the gradients in memory. Despite this, the speed of evaluation will be a function of how many parameters the encoder has.", "We only have to load a batch at a time into memory before saving the result to disk. In my case, I was able to evaluate about 2500 latent representations per second on a laptop CPU. On completion we can then do our main analysis.", "Even though reducing each light curve into 40 numbers is much less information to process than thousands of data points, on a glance it is definitely not obvious what the implications of the given values are. Being able to visually see all the data at once gives us a general idea on the number of different types of measurements we can expect to see.", "t-distributed Stochastic Neighbor Embedding (t-SNE) is a useful algorithm that reduces the dimensionality of data into a size of our choice. This algorithm is not just a projection of the higher dimensional space onto a lower dimension. In simple terms, values are assigned by estimating the conditional probability that one point would pick another as its neighbor. By doing this you are basically preserving as much information is possible from the higher dimensions.", "The implication of selecting a two dimensional output is that we can now visualize a complete light curve measurement as a single point on an x-y plane. Points closer to each other are measurements that are similar to each other. What emerges are clusters that can be investigated.", "We can see from our t-SNE plot that there are clear clusters, you could basically draw a circle around them yourself. Some appear to contain common measurements, and others rarer measurements. Honing in on small islands is clearly beneficial for identifying more unique types of observations quickly. However, from a computational point of view we may want to skip the visualization entirely and go straight from latent representation to a cluster label.", "Although t-SNE does a good job at grouping measurements together (as well as providing the obvious benefits of a visualization) we do sometimes have to be careful about it\u2019s interpretation. The reduction to two dimensions might still hide the true variety of measurements. Often it does make sense to cluster directly on the 40 dimensional latent space vector.", "There are several different types of clustering algorithms and each approach the problem quite differently. Unfortunately, most types of clustering algorithms make an assumption to do with similarity measures, cluster sizes or geometry of the dataset. Annoyingly, there only exists a handful of algorithms that don\u2019t require specifying the total number of clusters.", "If we have to make any of these compromises it almost defeats the purpose of trying to do this to begin with. This is because we don\u2019t necessarily know what we\u2019re expecting to see. And since the dataset is large we want to get useful feedback as quickly as possible.", "Given these challenges, our criteria for a useful clustering algorithm on astronomical observations would be one that is capable of:", "Despite dozens of clustering algorithms, the Hieracheal Density Based Spatial Clustering of Applications with Noise (HDBSCAN) algorithm gives few compromises and achieves all of the above criteria.", "Applying this algorithm on the TESS dataset returned 300 clusters. Some did seem closely correlated with subtle differences, but in general were quite distinct. The counts in each varied from a handful to a few hundred in each. Below is a sample of three light curves from three different clusters.", "If we want a shortlist to do follow up measurements on, starting at a cluster level can make this decision easier as we can now quantify how common a type of observation is due to the size of its cluster.", "The ability to search for similar brightness curves in a fast way can be achieved if we exploit the similarity metrics discussed earlier. A useful library for this is Faiss.", "Faiss is a library optimized for fast and efficient similarity search. It is written in C++ with a python wrapper, thus making it accessible and easy to use. It assumes similarity can be assessed on L2 distance or dot products and has GPU support.", "Faiss offers many choices of index to tailor towards memory consumption, speed and precision requirements. In this case I can fit all of my vectors in memory and want precise results so I selected an index referred to as \u201cFlat Inner Product\u201d. A Flat index makes no calculation simplifications or assumptions about the structure of the database. The latter is not required as the search is exhaustive.", "The memory consumption is 4 x d bytes per vector, where d is the dimension of our latent representation (40 in my case). A side benefit of this approach is that it\u2019s possible to design a whole pipeline to work on any hardware by selecting the right d and making appropriate trade-offs. The Faiss documentation has a useful guide on index selection here. But as a side note, if we were to include the whole TESS dataset in this analysis it might not fit in memory and it might be desirable to (but not necessarily) use a GPU for speed and select an index to optimize for memory.", "Faiss will only do the dot product of two vectors. In order to obtain cosine similarity we need to do L2 normalization on each sample when adding them to the database. We then also do this on the input vector which results in the dot product of two L2 normalized vectors thus giving us their cosine similarity.", "Since the goal is to get quick results it is important to note the time complexity of such a process. To find the top 5 most similar light curves among the whole database took less than 1 millisecond. In addition, this scales well regardless of the number of results we want. Switching to the top 1000 results does not greatly affect the query time.", "After getting query results it\u2019s then possible to plot the results either by looking up the object id or using the decoder component of the model to reconstruct the original light curve from the latent representation. I manually selected a few curves who seem a bit unique at face value and did a search. I show the input curve and the top 3 results below. Despite the caveats about cosine similarity I mentioned above we can see that the latent representations capture a lot of the properties we would use to regard two time series as similar.", "It is important to note that our input vector does not have to come from within the database. For example, we might have a theoretical model of what a particular phenomena would look like already but were unable to find an existing vector in the database to find similar objects from. If we know how to express the expected light curve mathematically or have a result from a simulation, we just have to input the time series into the encoder to obtain the representation. This becomes our input vector to query the database.", "As a side note, it\u2019s useful to mention how this can assist in the search for extraterrestrial intelligence. Generally searches look for unusual radio or optical laser pulse emissions. However, given the potential size of structures such as solar sails, solar shades, orbital habitats or anything deliberately designed to announce their presence, this opens up the transit method as a valid method for this search. There has been research and suggestions as to what one of these unnatural light curves would also look like.", "A paper by Luc. F. A. Arnold titled Transiting Lightcurve Signatures of Artificial Objects examines what we would expect to see from objects that are not expected to exist naturally including 1) An equilateral triangle 2) two-screen and 3) louvre-like six screen. It reminds us that it is also important to simulate cases where there are single objects, multiple objects and if they are rotating. It is noted that it is still possible to confuse some objects with things such as ringed planets if measurements are below a certain resolution. So results are therefore given as the magnitude difference compared to an equivalently sized spherical object rather than the original light curve.", "There could be a deliberate intention by an alien civilization to create an obviously artificial, repeating beacon. The candidates for such a signal are many but one example would be the first few digits of pi in binary. However, it is probably unlikely that this would be done in the visual spectrum as this is not energy efficient. But it is arguable that a civilization trying to attract attention might do so by trying to be visible to others during their regular astronomical observations. If this is the case, a series of objects to create an obvious unnatural light curve during transit method observations could be worth searching for.", "The takeaway is that given a theorized light curve (natural or artificial) we can use this method to quickly find candidates in an acceptable time.", "Rather than comparing one vector to the whole database it is also possible to have a batch of input vectors. Predictably, this is quicker than doing one at a time and scales well.", "One method to find strange light curves is to do a complete pairwise similarity search across the whole database, which is possible since we can do a batch of inputs. Since Faiss returns the similarity scores of the top results, we can infer the strangest light curves as those whose top similarity scores are still low (finding the minimum maximums). This can be done by thresh-holding, or simply sorting from lowest to highest by score from a database batch query returning the k=1 most similar results.", "Below are the top 20 most dissimilar light curves for TESS sectors 16 and 17. The operation took 1.1 seconds:", "Some observations about this result \u2014 there are 4 or 5 observations that could be glitches with large spikes at the start of the measurement. Apart from that we have various combinations of short period and high variation curves.", "For those not familiar with physics, what we can see with our eyes is only a tiny fraction of the broader electromagnetic (EM) spectrum. In essence, what we are seeing are photons at different wavelengths (or energy levels) where each wavelength is a different color. At long wavelengths we have the radio spectrum, while visible light, infrared, X-ray and gamma rays make up the shorter wavelengths. It is possible to observe non-visible wavelengths with dedicated hardware and is common to do so in astronomy. The reason for this is that the EM emissions reveal a lot about physical processes, and some objects are only visible in these wavelengths. Below is a comparison between the visible and infrared observation on the constellation of Orion.", "The TESS satellite observes in the visible and near infrared range (600nm-1000nm) as this is deemed a good range to find earth-like exoplanets. The real potential in the method used above lies in the broader EM spectrum.", "One advantage of machine learning methods is that we can train an encoder to take many inputs and give us one combined vector representation for each object. A vector database using this encoder can then be built following the same process. Like above, we can query for expected light curves based on what we would expect across the whole EM spectrum. For example, a star with strong infrared excess but no visible light may either be surrounded by dust or enclosed by a structure.", "Another benefit is that it is also possible to handle missing data from some of the inputs if observed measurements from a source are not available. This may be the case if inputs come from different observatories where access is limited or observations were coordinated at different times. A network can generalize to be expressive enough despite gaps in different parts of the input, and ODE-RNNs potentially handle this well.", "While maybe taking longer to train, this shouldn\u2019t reduce performance during inference time or increase memory consumption as we are still working with the same size vector during the visualization, clustering and search processes.", "I\u2019ve demonstrated that if we use auto-encoders to encode transit light curve measurements into a latent space representation it opens up the possibility of doing fast and efficient analysis on large datasets with reasonable hardware requirements. Recent developments in Neural Ordinary Differential Equations have allowed us to handle irregularly sampled time series and variable length measurements in a precise way.", "Even as our hardware improves and we start accurately accumulating billions (or trillions) of objects we certainly have the ability to quickly query the data. Plenty of improvements can continue to be made in the encoder and decoder architectures, as well as clustering algorithms.", "Additionally, there is great opportunity to apply such methods in the broader field of physics and cosmology where time series analysis is key.", "If you would like to reach out, feel free to contact me at glenn.kroegel@gmail.com or message me on LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa3ab8e180b14&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@glenn.kroegel?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@glenn.kroegel?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "Glenn Kroegel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8cd6e0bf64d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&user=Glenn+Kroegel&userId=8cd6e0bf64d9&source=post_page-8cd6e0bf64d9----a3ab8e180b14---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3ab8e180b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3ab8e180b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://www.spaceengine.org", "anchor_text": "spaceengine.org"}, {"url": "https://www.youtube.com/watch?v=gypAjPp6eps", "anchor_text": "KIC 8462852 (Tabby\u2019s Star)"}, {"url": "https://github.com/YuliaRubanova/latent_ode", "anchor_text": "latent ode"}, {"url": "https://github.com/rtqichen/torchdiffeq", "anchor_text": "torchdiffeq"}, {"url": "https://github.com/facebookresearch/faiss/", "anchor_text": "Faiss"}, {"url": "https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/glenn-kroegel/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/astronomy?source=post_page-----a3ab8e180b14---------------astronomy-----------------", "anchor_text": "Astronomy"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a3ab8e180b14---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/exoplanets?source=post_page-----a3ab8e180b14---------------exoplanets-----------------", "anchor_text": "Exoplanets"}, {"url": "https://medium.com/tag/search-algorithm?source=post_page-----a3ab8e180b14---------------search_algorithm-----------------", "anchor_text": "Search Algorithm"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----a3ab8e180b14---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3ab8e180b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&user=Glenn+Kroegel&userId=8cd6e0bf64d9&source=-----a3ab8e180b14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa3ab8e180b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&user=Glenn+Kroegel&userId=8cd6e0bf64d9&source=-----a3ab8e180b14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa3ab8e180b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa3ab8e180b14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a3ab8e180b14---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a3ab8e180b14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@glenn.kroegel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@glenn.kroegel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Glenn Kroegel"}, {"url": "https://medium.com/@glenn.kroegel/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "11 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8cd6e0bf64d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&user=Glenn+Kroegel&userId=8cd6e0bf64d9&source=post_page-8cd6e0bf64d9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff84d9f7d7ced&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funcovering-the-cosmos-machine-learning-approach-to-finding-exoplanet-candidates-and-other-a3ab8e180b14&newsletterV3=8cd6e0bf64d9&newsletterV3Id=f84d9f7d7ced&user=Glenn+Kroegel&userId=8cd6e0bf64d9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}