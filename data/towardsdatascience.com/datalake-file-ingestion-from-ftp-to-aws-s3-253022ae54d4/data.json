{"url": "https://towardsdatascience.com/datalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4", "time": 1683007143.254035, "path": "towardsdatascience.com/datalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4/", "webpage": {"metadata": {"title": "Datalake File Ingestion: From FTP to AWS S3 | by Furqan Butt | Towards Data Science", "h1": "Datalake File Ingestion: From FTP to AWS S3", "description": "Hello everyone. When developing Datalake pipe lines, data ingestion is an important step in the entire process. We need a reliable, secure and fault tolerant method to bring our files from\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/furqanshahid85-python/Python-FTP-File-Ingestion", "anchor_text": "repository", "paragraph_index": 2}, {"url": "https://www.python.org/downloads/", "anchor_text": "link", "paragraph_index": 5}], "all_paragraphs": ["Hello everyone. When developing Datalake pipe lines, data ingestion is an important step in the entire process. We need a reliable, secure and fault tolerant method to bring our files from source(client FTP server) to our target( AWS S3). Considering how important this step is, I developed an implementation in python that can be used to ingest files from an FTP server to AWS s3. I have designed the code in such manner that it can be used in a managed(AWS Glue) or un-managed(local machine) environment to transfer files from an FTP server to AWS s3.", "In this article I will explain how we can transfer files present on an FTP server such as FileZilla to Amazon s3 using the Paramiko Library in Python.", "The file ingestion code can be found on my GitHub repository. The file ingestion code does the following things:", "I will do a step by step walk through of each section of the code for better understanding. So lets get started.", "Before we get started we need to do a little installation setup on our local machine and a directory setup on our FTP server.", "I\u2019m assuming you guys have python already installed on you machines. Visit this link to install python on your machine if you haven\u2019t already.Before getting towards the code we need to make sure we have the following modules installed:", "Since we\u2019ll be uploading files to s3 we will be needing the boto3 client.", "We need to create a few directories on our FTP server that we\u2019ll be using in the implementation.", "Note: this directory setup is a one time thing and we won\u2019t have to do it every single time.", "Connect to your FTP sever. I\u2019m using FileZilla in my case. Goto site manager. Select the SFTP option in the protocol drop down menu. Enter your host, ip, username and password and press connect.", "Once you are connected create two directories on your FTP server:", "After doing the above two steps we now we have all the necessary modules installed and directory structure setup. We can now get started with the actual implementation.", "Let\u2019s first briefly go through the two files that are in the git repository.", "Our entire FTPIngestion class implementation is as follows. I\u2019ll explain each section of the code one by one.", "Note: I called it a python glue job because we can run the same code in a AWS Glue python shell environment and achieve the same FTP file transfer functionality using AWS Glue.", "This file is being to define all our configurations such as host-name, IP, port, username, password, s3 bucket name, ftp directory paths etc. It is a good programming practice to keep all the configurations in a separate file. This makes our code more manageable.", "We use this file by importing it in our python_glue_ingestion_job.py file. Our config.py file looks as follows:", "After having a brief overview of both of our files let\u2019s dive into each section of the code.", "Our code kicks off from the main method. We first create an object ftp_obj of Our FTPIngestion class. On object creation the __init(self)__ method is called which sets up all the configuration values.", "The ftp_obj then calls the initiate_ingestion(self) method which will first create an ssh connection with our FTP server using the create_ssh_connection(self) method. On successful connection, an SFTP connection is then created using the create_sftp_connection(self) method which we will use to access the FTP server.", "Once SFTP connection is established we do the following", "Lets now discuss each section of our FTPIngestion class in some detail.", "This is the init method also called as the constructor of our class. When we create an object of our FTPIngestion class all the attributes get set at object creation time. Values for each attribute are being fetched from the config.py class where we have defined their values. We import the config.py file as cfg and set each attribute with its corresponding value.", "Recommendation: instead of using the config.py class we can use AWS SSM where we define our key value pairs for each of our attribute just like we did in our config.py file. Using SSM is more robust and secure.", "This method creates a secure ssh connection with our FTP server using the given credentials. On successful connection it sets the self.ssh_ok attribute to True and returns. Otherwise self.ssh_ok is set to False and returned.", "one thing to notice in this method is the self.ssh_client.set_missing_host_key_policy( paramiko.AutoAddPolicy()). We configured it to set the missing host keys with a auto generated policy. If you\u2019re going to run this in AWS Glue as python shell job, instead of adding the auto add policy, use the host policies. For this, do the following in the code", "This method calls the create_ssh_connection method creates the ssh connection and then proceeds to open the SFTP connection. On successful connection it sets the self.sftp_ok to True and on failure sets it to False and returns the value.", "This method is called in the initiate_ingestion method after the file is successfully uploaded to s3. This method take the file name as argument. Sets the source and destination paths on the FTP server as src and dest, and then executes the following command which will move the file from the src path to the dest path.", "Our move_files_to_processed method is as follows:", "This method creates the s3 partition structure. The partition consists of root directory name followed by year, month,day,hour. In this way we can have a time based partitioned data.", "This method uploads the files to the specified s3 bucket. It uses the TransferConfig class to handle the multipart upload. We specify the configurations for TransferConfig as follows:", "We pass this config object to our s3.upload_fileobj as parameter", "The TransferConfig class automatically checks whether to upload the file as a single part or via multipart. It automatically handles the failed uploads and takes care of retries in case of failures.", "This method initiates the calls to establish ssh and sftp connections. Changes FTP directory path to specified path where the files reside. Gets list of all the files in the FTP specified path and starts upload to s3. Files Successfully uploaded to S3 gets moved into the processed directory on FTP server. Once all files are uploaded closes all the connections.", "This mehtod is used to close the ssh and sftp connections.", "As mentioned earlier, the same implementation can be used in a managed environment such as AWS Glue. If user has files arriving on the FTP server at a certain time period (hour, day, month etc) he can schedule the job to run at a specific time to ingest all the files from the FTP server to s3.", "We have to modify a few things in our code to be able to run this implementation as an AWS Glue Python shell job", "what we are doing is instead of using an auto generated policy we are using the host keys of the environment we are in.", "After doing above steps we can run this code in as a Python shell job in AWS Glue.", "In this article, we looked at how can perform the data ingestion step of a Datalake pipeline. We learned how we can use the paramiko library to create a secure ssh SFTP connection with a FTP server and upload files from the server to our AWS S3 buckets. We also briefly looked at how we can use the given implementation in a managed environment such as AWS Glue.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F253022ae54d4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----253022ae54d4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----253022ae54d4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://furqan-butt.medium.com/?source=post_page-----253022ae54d4--------------------------------", "anchor_text": ""}, {"url": "https://furqan-butt.medium.com/?source=post_page-----253022ae54d4--------------------------------", "anchor_text": "Furqan Butt"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faa25ef82854a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&user=Furqan+Butt&userId=aa25ef82854a&source=post_page-aa25ef82854a----253022ae54d4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F253022ae54d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F253022ae54d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/furqanshahid85-python/Python-FTP-File-Ingestion", "anchor_text": "repository"}, {"url": "https://www.python.org/downloads/", "anchor_text": "link"}, {"url": "https://github.com/furqanshahid85-python/Python-FTP-File-Ingestion", "anchor_text": "furqanshahid85-python/Python-FTP-File-IngestionThis module provides the functionality of uploading files to s3 from a FTP server. An SFTP connection is created with\u2026github.com"}, {"url": "https://medium.com/tag/data-lake?source=post_page-----253022ae54d4---------------data_lake-----------------", "anchor_text": "Data Lake"}, {"url": "https://medium.com/tag/python?source=post_page-----253022ae54d4---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/ftp?source=post_page-----253022ae54d4---------------ftp-----------------", "anchor_text": "Ftp"}, {"url": "https://medium.com/tag/big-data?source=post_page-----253022ae54d4---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/aws?source=post_page-----253022ae54d4---------------aws-----------------", "anchor_text": "AWS"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F253022ae54d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&user=Furqan+Butt&userId=aa25ef82854a&source=-----253022ae54d4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F253022ae54d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&user=Furqan+Butt&userId=aa25ef82854a&source=-----253022ae54d4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F253022ae54d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----253022ae54d4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F253022ae54d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----253022ae54d4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----253022ae54d4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----253022ae54d4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----253022ae54d4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----253022ae54d4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----253022ae54d4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----253022ae54d4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----253022ae54d4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----253022ae54d4--------------------------------", "anchor_text": ""}, {"url": "https://furqan-butt.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://furqan-butt.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Furqan Butt"}, {"url": "https://furqan-butt.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "228 Followers"}, {"url": "https://www.linkedin.com/in/furqan-butt-3aab8a191/", "anchor_text": "https://www.linkedin.com/in/furqan-butt-3aab8a191/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faa25ef82854a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&user=Furqan+Butt&userId=aa25ef82854a&source=post_page-aa25ef82854a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb7f353dea7bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdatalake-file-ingestion-from-ftp-to-aws-s3-253022ae54d4&newsletterV3=aa25ef82854a&newsletterV3Id=b7f353dea7bc&user=Furqan+Butt&userId=aa25ef82854a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}