{"url": "https://towardsdatascience.com/random-forests-for-complete-beginners-2014d9ed91c0", "time": 1682995751.91484, "path": "towardsdatascience.com/random-forests-for-complete-beginners-2014d9ed91c0/", "webpage": {"metadata": {"title": "Random Forests for Complete Beginners | by Victor Zhou | Towards Data Science", "h1": "Random Forests for Complete Beginners", "description": "Last month, I wrote an introduction to Neural Networks for complete beginners. This post will adopt the same strategy, meaning it again assumes ZERO prior knowledge of machine learning. We\u2019ll learn\u2026"}, "outgoing_paragraph_urls": [{"url": "https://victorzhou.com/blog/intro-to-neural-networks/", "anchor_text": "introduction to Neural Networks for complete beginners", "paragraph_index": 1}, {"url": "https://victorzhou.com/blog/gini-impurity/", "anchor_text": "an entire blog post about one way to do this using a metric called Gini Impurity", "paragraph_index": 16}, {"url": "https://victorzhou.com/blog/gini-impurity/", "anchor_text": "my Gini Impurity post", "paragraph_index": 17}, {"url": "https://victorzhou.com/blog/gini-impurity/", "anchor_text": "my Gini Impurity post", "paragraph_index": 24}, {"url": "https://en.wikipedia.org/wiki/Bootstrap_aggregating", "anchor_text": "bootstrap aggregating", "paragraph_index": 40}, {"url": "https://en.wikipedia.org/wiki/Bootstrapping_(statistics)", "anchor_text": "bootstrap", "paragraph_index": 40}, {"url": "https://victorzhou.com/tag/machine-learning", "anchor_text": "writing about Machine Learning", "paragraph_index": 47}, {"url": "https://victorzhou.com/subscribe/?src=intro-to-random-forests-medium", "anchor_text": "subscribe", "paragraph_index": 47}, {"url": "https://victorzhou.com", "anchor_text": "https://victorzhou.com", "paragraph_index": 49}], "all_paragraphs": ["In my opinion, most Machine Learning tutorials aren\u2019t beginner-friendly enough.", "Last month, I wrote an introduction to Neural Networks for complete beginners. This post will adopt the same strategy, meaning it again assumes ZERO prior knowledge of machine learning. We\u2019ll learn what Random Forests are and how they work from the ground up.", "A Random Forest \ud83c\udf32\ud83c\udf32\ud83c\udf32 is actually just a bunch of Decision Trees \ud83c\udf32 bundled together (ohhhhh \ud83d\udca1 that\u2019s why it\u2019s called a forest). We need to talk about trees before we can get into forests.", "If I told you that there was a new point with an x coordinate of 1, what color do you think it\u2019d be?", "You just evaluated a decision tree in your head:", "That\u2019s a simple decision tree with one decision node that tests x<2. If the test passes (x<2), we take the left branch and pick Blue. If the test fails (x\u22652), we take the right branch and pick Green.", "Decision Trees are often used to answer that kind of question: given a labelled dataset, how should we classify new samples?", "Labelled: Our dataset is labelled because each point has a class (color): blue or green.", "Classify: To classify a new datapoint is to assign a class (color) to it.", "Here\u2019s a dataset that has 3 classes now instead of 2:", "Our old decision tree doesn\u2019t work so well anymore. Given a new point (x, y),", "We need to add another decision node to our decision tree:", "Pretty simple, right? That\u2019s the basic idea behind decision trees.", "Let\u2019s start training a decision tree! We\u2019ll use the 3 class dataset again:", "Our first task is to determine the root decision node in our tree. Which feature (x or y) will it test on, and what will the test threshold be? For example, the root node in our tree from earlier used the x feature with a test threshold of 2:", "Intuitively, we want a decision node that makes a \u201cgood\u201d split, where \u201cgood\u201d can be loosely defined as separating different classes as much as possible. The root node above makes a \u201cgood\u201d split: all the greens are on the right, and no greens are on the left.", "Thus, our goal is now to pick a root node that gives us the \u201cbest\u201d split possible. But how do we quantify how good a split is? It\u2019s complicated. I wrote an entire blog post about one way to do this using a metric called Gini Impurity. \u2190 I recommend reading it right now before you continue \u2014 we\u2019ll be using those concepts later in this post.", "Hopefully, you just read my Gini Impurity post. If you didn\u2019t, here\u2019s a very short TL;DR: We can use Gini Impurity to calculate a value called Gini Gain for any split. A better split has higher Gini Gain.", "Back to the problem of determining our root decision node. Now that we have a way to evaluate splits, all we have to do to is find the best split possible! For the sake of simplicity, we\u2019re just going to try every possible split and use the best one (the one with the highest Gini Gain). This is not the fastest way to find the best split, but it is the easiest to understand.", "For example, here are the thresholds we might select if we wanted to use the x coordinate:", "Let\u2019s do an example Gini Gain calculation for the x=0.4 split.", "First, we calculate the Gini Impurity of the whole dataset:", "Then, we calculate the Gini Impurities of the two branches:", "Finally, we calculate Gini Gain by subtracting the weighted branch impurities from the original impurity:", "Confused about what just happened? I told you you should\u2019ve read my Gini Impurity post. It\u2019ll explain all of this Gini stuff.", "We can calculate Gini Gain for every possible split in the same way:", "After trying all thresholds for both x and y, we\u2019ve found that the x=2 split has the highest Gini Gain, so we\u2019ll make our root decision node use the x feature with a threshold of 2. Here\u2019s what we\u2019ve got so far:", "Time to make our second decision node. Let\u2019s (arbitrarily) go to the left branch. We\u2019re now only using the datapoints that would take the left branch (i.e. the datapoints satisfying x<2), specifically the 3 blues and 3 reds.", "To build our second decision node, we just do the same thing! We try every possible split for the 6 datapoints we have and realize that y=2 is the best split. We make that into a decision node and now have this:", "Our decision tree is almost done\u2026", "Let\u2019s keep it going and try to make a third decision node. We\u2019ll use the right branch from the root node this time. The only datapoints in that branch are the 3 greens.", "Again, we try all the possible splits, but they all", "It doesn\u2019t makes sense to add a decision node here because doing so wouldn\u2019t improve our decision tree. Thus, we\u2019ll make this node a leaf node and slap the Green label on it. This means that we\u2019ll classify any datapoint that reaches this node as Green.", "If we continue to the 2 remaining nodes, the same thing will happen: we\u2019ll make the bottom left node our Blue leaf node, and we\u2019ll make the bottom right node our Red leaf node. That brings us to the final result:", "Once all possible branches in our decision tree end in leaf nodes, we\u2019re done. We\u2019ve trained a decision tree!", "We\u2019re finally ready to talk about Random Forests. Remember what I said earlier?", "A Random Forest is actually just a bunch of Decision Trees bundled together.", "That\u2019s true, but is a bit of a simplification.", "Consider the following algorithm to train a bundle of decision trees given a dataset of n points:", "To make a prediction using this model with tt trees, we aggregate the predictions from the individual decision trees and either", "This technique is called bagging, or bootstrap aggregating. The sampling with replacement we did is known as a bootstrap sample.", "Bagged decision trees are very close to Random Forests \u2014 they\u2019re just missing one thing\u2026", "Bagged decision trees have only one parameter: t, the number of trees.", "Random Forests have a second parameter that controls how many features to try when finding the best split. Our simple dataset for this tutorial only had 2 features (x and y), but most datasets will have far more (hundreds or thousands).", "Suppose we had a dataset with pp features. Instead of trying all features every time we make a new decision node, we only try a subset of the features\u200b. We do this primarily to inject randomness that makes individual trees more unique and reduces correlation between trees, which improves the forest\u2019s performance overall. This technique is sometimes referred to as feature bagging.", "That\u2019s a beginner\u2019s introduction to Random Forests! A quick recap of what we did:", "A few things you could do from here:", "That concludes this tutorial. I like writing about Machine Learning (but also other topics), so subscribe if you want to get notified about new posts.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "CS @ Princeton University. I write about web development, machine learning, and more at https://victorzhou.com."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2014d9ed91c0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://victorczhou.medium.com/?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "Victor Zhou"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd190d205cab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&user=Victor+Zhou&userId=dd190d205cab&source=post_page-dd190d205cab----2014d9ed91c0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2014d9ed91c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2014d9ed91c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://victorzhou.com/blog/intro-to-neural-networks/", "anchor_text": "introduction to Neural Networks for complete beginners"}, {"url": "https://victorzhou.com/blog/gini-impurity/", "anchor_text": "an entire blog post about one way to do this using a metric called Gini Impurity"}, {"url": "https://victorzhou.com/blog/gini-impurity/", "anchor_text": "my Gini Impurity post"}, {"url": "https://victorzhou.com/blog/gini-impurity/", "anchor_text": "my Gini Impurity post"}, {"url": "https://en.wikipedia.org/wiki/Bootstrap_aggregating", "anchor_text": "bootstrap aggregating"}, {"url": "https://en.wikipedia.org/wiki/Bootstrapping_(statistics)", "anchor_text": "bootstrap"}, {"url": "https://victorzhou.com/blog/gini-impurity/", "anchor_text": "Gini Impurity"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html", "anchor_text": "DecisionTreeClassifier"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "RandomForestClassifier"}, {"url": "https://twitter.com/victorczhou", "anchor_text": "tweet at me"}, {"url": "https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting", "anchor_text": "Gradient Boosted Decision Trees"}, {"url": "https://xgboost.readthedocs.io/en/latest/", "anchor_text": "XGBoost"}, {"url": "https://en.wikipedia.org/wiki/Random_forest#ExtraTrees", "anchor_text": "ExtraTrees"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html", "anchor_text": "ExtraTreesClassifier"}, {"url": "https://victorzhou.com/tag/machine-learning", "anchor_text": "writing about Machine Learning"}, {"url": "https://victorzhou.com/subscribe/?src=intro-to-random-forests-medium", "anchor_text": "subscribe"}, {"url": "https://victorzhou.com/blog/intro-to-random-forests/", "anchor_text": "victorzhou.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2014d9ed91c0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/random-forest?source=post_page-----2014d9ed91c0---------------random_forest-----------------", "anchor_text": "Random Forest"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----2014d9ed91c0---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/tutorial?source=post_page-----2014d9ed91c0---------------tutorial-----------------", "anchor_text": "Tutorial"}, {"url": "https://medium.com/tag/decision-tree?source=post_page-----2014d9ed91c0---------------decision_tree-----------------", "anchor_text": "Decision Tree"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2014d9ed91c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&user=Victor+Zhou&userId=dd190d205cab&source=-----2014d9ed91c0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2014d9ed91c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&user=Victor+Zhou&userId=dd190d205cab&source=-----2014d9ed91c0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2014d9ed91c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2014d9ed91c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2014d9ed91c0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2014d9ed91c0--------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Victor Zhou"}, {"url": "https://victorczhou.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "925 Followers"}, {"url": "https://victorzhou.com", "anchor_text": "https://victorzhou.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd190d205cab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&user=Victor+Zhou&userId=dd190d205cab&source=post_page-dd190d205cab--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb8d9c8575861&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forests-for-complete-beginners-2014d9ed91c0&newsletterV3=dd190d205cab&newsletterV3Id=b8d9c8575861&user=Victor+Zhou&userId=dd190d205cab&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}