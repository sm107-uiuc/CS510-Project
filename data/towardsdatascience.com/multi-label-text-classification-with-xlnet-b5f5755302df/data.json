{"url": "https://towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df", "time": 1683001272.649853, "path": "towardsdatascience.com/multi-label-text-classification-with-xlnet-b5f5755302df/", "webpage": {"metadata": {"title": "Multi-Label Text Classification with XLNet | by Josh Xin Jie Lee | Towards Data Science", "h1": "Multi-Label Text Classification with XLNet", "description": "At the time of its publication on 19 June 2019, XLNet achieved state-of-the-art results on 18 tasks including text classification, question-answering, natural language inference, sentiment analysis\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1906.08237", "anchor_text": "XLNet", "paragraph_index": 2}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "Transformers", "paragraph_index": 6}, {"url": "https://medium.com/@kaushaltrivedi", "anchor_text": "Kaushal Trivedi", "paragraph_index": 7}, {"url": "https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d", "anchor_text": "tutorial", "paragraph_index": 7}, {"url": "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview", "anchor_text": "Toxic Comment Classification Challenge,", "paragraph_index": 8}, {"url": "https://colab.research.google.com/drive/1o3cv-YSPGiKftCvFnCiMcygARqdaxrM7", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://colab.research.google.com/drive/1o3cv-YSPGiKftCvFnCiMcygARqdaxrM7", "anchor_text": "here", "paragraph_index": 44}], "all_paragraphs": ["At the time of its publication on 19 June 2019, XLNet achieved state-of-the-art results on 18 tasks including text classification, question-answering, natural language inference, sentiment analysis, and document ranking.", "It even outperformed BERT on 20 tasks!", "Developed by Carnegie Mellon University and Google Brain, XLNet is a permutation-based auto-regressive language model.", "We will not delve too much into the inner workings of the model as there are a lot of great resources out there for this purpose. Rather, this article will focus on the application of XLNet to the problem of multi-label and multi-class text classification.", "Let\u2019s do a quick recap. In a multi-class classification problem, there are multiple classes, but any given text sample will be assigned a single class.", "On the other hand, in a multi-label text classification problem, a text sample can be assigned to multiple classes.", "We will be using the Transformers library developed by HuggingFace. The Transformers library provides easy to use implementations of numerous state-of-the-art language models : BERT, XLNet, GPT-2, RoBERTa, CTRL, etc.", "In addition, I will like to give a shout-out to Kaushal Trivedi, whose amazing tutorial on BERT for multi-label classification served as the basis for the code here.", "We will tackle Kaggle\u2019s Toxic Comment Classification Challenge, for which we need to predict a probability for each of the six possible categories of comment toxicity for online comments.", "As a quick note, there is a base version and a large version of XLNet:", "We will be training our model on Google Colab, which provides a 16 GB Tesla P100 for free!", "Due to the GPU memory limitations of the Tesla P100, we will be using XLNet Base for our task.", "We will not be training the model from scratch, but rather fine-tune a pre-trained model. This concept is known as transfer learning.", "Without further a due, let\u2019s begin!", "Click here for the Colab notebook accompanying this article.", "First, let\u2019s install the necessary library, actually just transformers.", "Next, we import the necessary libraries.", "Check if the GPU is available.", "Mount your google drive to your Colab notebook.", "For our example, we will create a Data folder in our google drive and put the datasets there.", "Let\u2019s do some quick EDA. Analyzing the distribution of the labels, we note that the labels are imbalanced.", "Before feeding a piece of text into the model, the text has to be tokenized into the appropriate sub-words. We can use HuggingFace\u2019s XLNetTokenizer for this purpose.", "Theoretically, an XLNet base model is able to handle sequences of up to 512 sub-words. However to decrease the training time and also to account for the limited GPU memory, we will choose a smaller sequence size.", "We can analyze the distribution of the number of sub-words for the comments.", "Since most comments have less than 250 sub-words, we can truncate or pad all comments to 250 sub-words.", "Convert the input text sequence into the appropriate numeric token ids.", "Next we will create the attention masks, which instruct the model on the appropriate tokens to perform attention on. The objective is to prevent our model from performing attention on padding tokens.", "Append the tokenized numeric inputs and the attention masks to the dataframe.", "We will perform a train and validation split for the purpose of cross-validation.", "Create the features, masks and labels arrays and convert them to torch tensors.", "Next, create the Dataloaders for the train and validation sets. We will use a batch size of 32.", "If Colab assigns a 12 GB Tesla K80 for your runtime, you might consider decreasing the batch size to 16 to avoid running out of GPU memory.", "Let\u2019s define our XLNet classification model.", "Since the input sequence has 250 tokens, XLNet will produce 250 output vectors, with each vector having a dimension of 768. We will perform a mean-pooling of the output vectors and produce a single vector with a dimension of 768. This vector will be the input to the fully-connected layer that will predict the 6 comment toxicity labels.", "You can definitely explore other ways to pool the output, such as concatenating the outputs into a single large vector, or even using the outputs from the last few hidden layers of XLNet.", "Next, we initialize the optimizer. We will be using the AdamW optimizer. If desired, you can also set up a learning rate schedule.", "We will now define the training function. During training, the function will save the model whenever it achieves the lowest validation loss.", "A single epoch of training takes around 1 hour 30 minutes on a Tesla P100.", "After our model is trained, we can generate the predictions for the 153,164 test examples.", "If we try to predict the labels for all test examples at one go, our GPU is likely to run out of memory. The solution to this will be to generate predictions for every 32 test examples and concatenate them together.", "Of course, the batch size of 32 can be changed depending on the amount of GPU memory.", "Submitting the results to Kaggle, we achieved a public score of 0.98182 and a private score of 0.98323 after a single epoch of fine-tune training. Not too shabby!", "Note that we did not perform any parameter tuning or feature engineering.", "If you want the hard labels for your predictions instead of their soft probabilities, simply round the soft probabilities to the nearest integer (0 or 1).", "That\u2019s it! The link to the Colab notebook can be found here.", "Thank you for reading this article! If you have any thoughts or feedback, leave a comment below or send me an email at leexinjie@gmail.com. I\u2019d loved to hear from you!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Aspiring ML practitioner @ AI Singapore -> The only true reward is existence and non-existence, everything else is a corollary of that \ud83c\udf0e"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb5f5755302df&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b5f5755302df--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b5f5755302df--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@joshxinjielee?source=post_page-----b5f5755302df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joshxinjielee?source=post_page-----b5f5755302df--------------------------------", "anchor_text": "Josh Xin Jie Lee"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa26bab2a7024&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&user=Josh+Xin+Jie+Lee&userId=a26bab2a7024&source=post_page-a26bab2a7024----b5f5755302df---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5f5755302df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5f5755302df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@cgower", "anchor_text": "Christopher Gower"}, {"url": "https://unsplash.com/photos/m_HRfLhgABo", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/abs/1906.08237", "anchor_text": "XLNet"}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "Transformers"}, {"url": "https://medium.com/@kaushaltrivedi", "anchor_text": "Kaushal Trivedi"}, {"url": "https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d", "anchor_text": "tutorial"}, {"url": "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview", "anchor_text": "Toxic Comment Classification Challenge,"}, {"url": "https://colab.research.google.com/drive/1o3cv-YSPGiKftCvFnCiMcygARqdaxrM7", "anchor_text": "here"}, {"url": "https://colab.research.google.com/drive/1o3cv-YSPGiKftCvFnCiMcygARqdaxrM7", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b5f5755302df---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b5f5755302df---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/nlp?source=post_page-----b5f5755302df---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b5f5755302df---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----b5f5755302df---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb5f5755302df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&user=Josh+Xin+Jie+Lee&userId=a26bab2a7024&source=-----b5f5755302df---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb5f5755302df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&user=Josh+Xin+Jie+Lee&userId=a26bab2a7024&source=-----b5f5755302df---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5f5755302df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b5f5755302df--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb5f5755302df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b5f5755302df---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b5f5755302df--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b5f5755302df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b5f5755302df--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b5f5755302df--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b5f5755302df--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b5f5755302df--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b5f5755302df--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b5f5755302df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joshxinjielee?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@joshxinjielee?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Josh Xin Jie Lee"}, {"url": "https://medium.com/@joshxinjielee/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "221 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa26bab2a7024&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&user=Josh+Xin+Jie+Lee&userId=a26bab2a7024&source=post_page-a26bab2a7024--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F896a0c77555f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-text-classification-with-xlnet-b5f5755302df&newsletterV3=a26bab2a7024&newsletterV3Id=896a0c77555f&user=Josh+Xin+Jie+Lee&userId=a26bab2a7024&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}