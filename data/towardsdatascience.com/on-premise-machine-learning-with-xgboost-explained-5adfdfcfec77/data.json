{"url": "https://towardsdatascience.com/on-premise-machine-learning-with-xgboost-explained-5adfdfcfec77", "time": 1682994606.183202, "path": "towardsdatascience.com/on-premise-machine-learning-with-xgboost-explained-5adfdfcfec77/", "webpage": {"metadata": {"title": "On-Premise Machine Learning with XGBoost Explained | by Andrej Baranovskij | Towards Data Science", "h1": "On-Premise Machine Learning with XGBoost Explained", "description": "XGBoost is a top ML algorithm for enterprise tabular data. In this article we discuss how to run XGBoost on your own environment with Docker container from Jupyter"}, "outgoing_paragraph_urls": [{"url": "https://hub.docker.com/r/jupyter/datascience-notebook", "anchor_text": "image", "paragraph_index": 3}, {"url": "https://xgboost.ai/", "anchor_text": "XGBoost", "paragraph_index": 4}, {"url": "https://github.com/abaranovskis-redsamurai/automation-repo", "anchor_text": "GitHub", "paragraph_index": 7}, {"url": "https://medium.com/@andrejusb/machine-learning-date-feature-transformation-explained-4feb774c9dbe", "anchor_text": "Machine Learning \u2014 Date Feature Transformation Explained", "paragraph_index": 7}, {"url": "https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/", "anchor_text": "Avoid Overfitting By Early Stopping With XGBoost In Python", "paragraph_index": 21}, {"url": "https://github.com/abaranovskis-redsamurai/automation-repo/blob/master/invoice-risk-model-local.ipynb", "anchor_text": "GitHub", "paragraph_index": 22}, {"url": "https://github.com/abaranovskis-redsamurai/automation-repo/blob/master/invoice_data_prog_processed.csv", "anchor_text": "here", "paragraph_index": 22}], "all_paragraphs": ["You can run Machine Learning (ML) models on Cloud (Amazon SageMaker, Google Cloud Machine Learning, etc.). I believe it is important to understand how to run Machine Learning in your own environment too. Without this knowledge ML skills set would not be complete. There are multiple reasons for this. Not everyone is using Cloud and you must provide on-premise solution. Without getting your hands dirty and configuring environment yourself, you would miss an exciting opportunity to learn more about ML.", "On-premise ML model training is not only related to environment install and setup. When you are training ML model in Cloud \u2014 you would use vendor API (Amazon SageMaker, Google, etc.), this API usually helps to solve the problem quicker, but it hides some interesting bits from you \u2014 which would help to understand ML process better. In this post, I will go step by step through ML model which can be trained without using Cloud API, but using API which comes from open source libraries directly.", "Let\u2019s dive in. The first thing you would need to start on-premise ML\u2014 Docker image (while you could configure ML environment without Docker, I would recommend going with Docker for better maintenance and simpler setup).", "Go with official Jupyter Notebook Data Science Stack image. Create a container with docker run command (check all available parameters in image docs). I would recommend paying attention where you map working directory with -v parameter. The first part of this parameter points towards folder on your OS and the second part after : points to a folder in Docker container (usually /home/jovyan/work).", "XGBoost installation in Jupyter Notebook container.", "You must enter into Docker container prompt with this command docker exec -it containername bash, to run below commands:", "With XGBoost installed, we can move on to ML model \u2014 the core part of any ML implementation. I\u2019m using Jupyter Notebook to build and train ML model, that's why my choice was Docker image from Jupyter. Jupyter notebook provides a structured way into Python code implementation, a developer could re-run each notebook section separately, this gives great flexibility, especially when coding and debugging Python code \u2014 no need to re-run entire Python code all the time. First, we start with imports. I would recommend keeping all imports at the beginning of the notebook (yes, you can do import in any section of the notebook). This way it improves code readability \u2014 always clear what imports are being used:", "The first step is to read training data with Pandas library. Download training data (invoice_data_prog_processed.csv) used in this example from my GitHub repo. Read more about data structure in my previous post \u2014 Machine Learning \u2014 Date Feature Transformation Explained. Data contains information about invoice payment, it indicates if the invoice was paid on time and if it was delayed \u2014 how long was the delay. Decision column is assigned with 0 if the invoice was paid on time or delay was small.", "After data was loaded from the file into Pandas data frame, we should check data structure \u2014 how decision column values are distributed:", "XGBoost works with numerical (continuous) data. Categorical features must be translated to numeric representation. Pandas library provide get_dummies function which helps to encode categorical data into an array of (0,1). Here we translate categorical feature customer_id:", "After encoding \u2014 data structure contains 44 columns.", "Before running model training, is useful to see how features are correlated with decision feature. In our case, as expected the most correlated/influential features are dates and total. This is a good sign, meaning that ML model should be trained properly:", "Next, we need to identify X/Y pair. Y is a decision feature, which is a first column in the dataset. All other columns are used to identify the decision feature. This means we need to split data into X/Y as follows:", "Here we split data into train/test datasets. Using train_test_split function sklearn library. Data set is small, so using a larger part of it for training \u2014 90%. Dataset is constructed with stratify option, to make sure decision feature is well represented in both training and test collections. Function train_test_split conveniently returns X/Y data into separate variables:", "And here is the moment of truth. Running ML model training step with XGBoost. %%time prints time spent on training. XGBoost supports both classification and regression, here we are using classification with XGBClassifier. Parameters depend on the dataset and with different dataset you will need to adjust them. The ones included are the ones to pay attention for, based on my findings (read more about each parameter in XGBoost documentation).", "We are not simply running model training, but using XGBoost feature of training self-evaluation and early stopping to avoid overfitting. Along with training data, passing test data too into ML model build function \u2014 model.fit. The function is assigned with 10 early stopping rounds. If there is no improvement in 10 rounds, training will stop and choose the most optimal model. Using logloss metric to evaluate training quality. Training is running with verbose=True flag to print detail output for each training iteration:", "Based on the output from model training you can see that the best iteration was Nr. 71.", "To evaluate training accuracy, we execute model.predict function and passing X testing data frame. The function returns an array of predictions per each row for X set. Then we match each row from prediction array with actual decision feature value. This is how accuracy is calculated:", "We executed model.predict with test data. But how to execute model.predict with new data? Here is the example below, which feeds model.predict with Pandas data frame constructed from static data. Payment is by one day late (payment after 4 days since invoice vs. 3 days of expected payment), but since the amount is less than 80 \u2014 such payment delay is not considered risky. XGBoost model.predict returns decision, but often it might be useful to call model.predict_proba instead, which returns probabilities for the decision:", "Once the model is trained, it is good practice to save it. In my next post, I will explain how to access trained model through Flask REST interface from the outside and expose ML functionality to Web app with Node.js and JavaScript. Model can be saved using pickle library:", "Finally, we are drawing training results based on the output for logloss and classification error. This helps to understand if training iteration which was selected as the best one was actually a good choice. Based on the plot we can see that iteration 71 was one of the most optimal in terms of training and testing errors. This means XGBoost decision to peek this iteration was good:", "A solution for XGBoost early stopping and results plotting was inspired by this blog post \u2014 Avoid Overfitting By Early Stopping With XGBoost In Python.", "Complete Jupyter notebook for this post can be downloaded from my GitHub repo. Training data can be downloaded from here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5adfdfcfec77&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://andrejusb.medium.com/?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": ""}, {"url": "https://andrejusb.medium.com/?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "Andrej Baranovskij"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbbd1211c851b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&user=Andrej+Baranovskij&userId=bbd1211c851b&source=post_page-bbd1211c851b----5adfdfcfec77---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5adfdfcfec77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5adfdfcfec77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://hub.docker.com/r/jupyter/datascience-notebook", "anchor_text": "image"}, {"url": "https://xgboost.ai/", "anchor_text": "XGBoost"}, {"url": "https://github.com/abaranovskis-redsamurai/automation-repo", "anchor_text": "GitHub"}, {"url": "https://medium.com/@andrejusb/machine-learning-date-feature-transformation-explained-4feb774c9dbe", "anchor_text": "Machine Learning \u2014 Date Feature Transformation Explained"}, {"url": "https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/", "anchor_text": "Avoid Overfitting By Early Stopping With XGBoost In Python"}, {"url": "https://github.com/abaranovskis-redsamurai/automation-repo/blob/master/invoice-risk-model-local.ipynb", "anchor_text": "GitHub"}, {"url": "https://github.com/abaranovskis-redsamurai/automation-repo/blob/master/invoice_data_prog_processed.csv", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5adfdfcfec77---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/xgboost?source=post_page-----5adfdfcfec77---------------xgboost-----------------", "anchor_text": "Xgboost"}, {"url": "https://medium.com/tag/docker?source=post_page-----5adfdfcfec77---------------docker-----------------", "anchor_text": "Docker"}, {"url": "https://medium.com/tag/jupyter-notebook?source=post_page-----5adfdfcfec77---------------jupyter_notebook-----------------", "anchor_text": "Jupyter Notebook"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----5adfdfcfec77---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5adfdfcfec77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&user=Andrej+Baranovskij&userId=bbd1211c851b&source=-----5adfdfcfec77---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5adfdfcfec77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&user=Andrej+Baranovskij&userId=bbd1211c851b&source=-----5adfdfcfec77---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5adfdfcfec77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5adfdfcfec77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5adfdfcfec77---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5adfdfcfec77--------------------------------", "anchor_text": ""}, {"url": "https://andrejusb.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://andrejusb.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andrej Baranovskij"}, {"url": "https://andrejusb.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://github.com/katanaml", "anchor_text": "https://github.com/katanaml"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbbd1211c851b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&user=Andrej+Baranovskij&userId=bbd1211c851b&source=post_page-bbd1211c851b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd22cc5338107&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-premise-machine-learning-with-xgboost-explained-5adfdfcfec77&newsletterV3=bbd1211c851b&newsletterV3Id=d22cc5338107&user=Andrej+Baranovskij&userId=bbd1211c851b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}