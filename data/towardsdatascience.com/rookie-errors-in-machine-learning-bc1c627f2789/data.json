{"url": "https://towardsdatascience.com/rookie-errors-in-machine-learning-bc1c627f2789", "time": 1683004332.974029, "path": "towardsdatascience.com/rookie-errors-in-machine-learning-bc1c627f2789/", "webpage": {"metadata": {"title": "Avoiding rookie errors in machine learning | by Archy de Berker | Towards Data Science", "h1": "Avoiding rookie errors in machine learning", "description": "This is a written version of a talk I gave at McGill University in January 2019. Subsequently, Andrej Karpathy wrote an excellent post, somewhat more technical and deep-learning specific but with\u2026"}, "outgoing_paragraph_urls": [{"url": "http://karpathy.github.io/2019/04/25/recipe/", "anchor_text": "here.", "paragraph_index": 0}, {"url": "https://www.theguardian.com/australia-news/2016/sep/07/airasia-pilot-flies-melbourne-malaysia-navigation-error", "anchor_text": "AirAsia pilot who ended up in Melbourne rather than Malaysia", "paragraph_index": 6}, {"url": "https://www.verywellmind.com/what-is-a-confirmation-bias-2795024", "anchor_text": "confirmation bias", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1606.01781.pdf", "anchor_text": "frequently used as a classification task by top labs.", "paragraph_index": 22}, {"url": "https://machinelearningmastery.com/calculate-bleu-score-for-text-python/", "anchor_text": "BLEU", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/ROUGE_(metric)", "anchor_text": "ROUGE", "paragraph_index": 23}, {"url": "http://lime-ml.readthedocs.io/", "anchor_text": "LIME", "paragraph_index": 36}, {"url": "https://eli5.readthedocs.io", "anchor_text": "Eli5", "paragraph_index": 36}, {"url": "https://medium.com/@jrzech/what-are-radiological-deep-learning-models-actually-learning-f97a546c5b98", "anchor_text": "excellent article", "paragraph_index": 36}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda", "anchor_text": "Keras Lambda layers", "paragraph_index": 40}, {"url": "https://www.google.com/search?client=safari&rls=en&q=chase+roberts+unit+tests+ml&ie=UTF-8&oe=UTF-8", "anchor_text": "this post from Chase Roberts on unit testing ML code.", "paragraph_index": 48}, {"url": "https://github.com/keithito/tacotron/blob/master/models/tacotron.py", "anchor_text": "beautiful Tacotron implementation from Keith Ito", "paragraph_index": 50}, {"url": "http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/", "anchor_text": "here", "paragraph_index": 57}, {"url": "https://www.tensorflow.org/tutorials/load_data/tfrecord", "anchor_text": "Tensorflow Records", "paragraph_index": 60}, {"url": "https://torchtext.readthedocs.io/en/latest/", "anchor_text": "torchtext", "paragraph_index": 62}, {"url": "https://pytorch.org/docs/stable/torchvision/index.html", "anchor_text": "torchvision", "paragraph_index": 62}, {"url": "https://github.com/PyTorchLightning/pytorch-lightning", "anchor_text": "Pytorch Lightning", "paragraph_index": 62}], "all_paragraphs": ["This is a written version of a talk I gave at McGill University in January 2019. Subsequently, Andrej Karpathy wrote an excellent post, somewhat more technical and deep-learning specific but with overlapping content \u2014 check that out here.", "You can track your deepening expertise of a topic by the quality and quantity of the mistakes you make. This post catalogues some of the more repetitive errors that I and the people around me have made in machine learning, in the hope of accelerating your progress out of the shallow waters of inexpertise and into the deep dark waters where really interesting mistakes are made. This is not an introductory post: you\u2019ll need to have already broken a few models in Pytorch or Tensorflow to keep up.", "I\u2019ve tried to categorize the kinds of errors we see in ML into three broad classes, of increasing severity.", "These kind of errors are regrettable, but survivable. In deep learning, the dreaded shape error is the most common, arising when you try and multiply together matrices of incompatible size.", "I\u2019m not going to talk much about these errors, because they are typically explicit: the program fails, and you have to figure out why. You know you\u2019ve made a mistake. You fix it, find a new error, and the cycle repeats. Nobody gets hurt.", "This is a more costly kind of mistake to make, because you end up making poor decisions.", "Consider the story of the AirAsia pilot who ended up in Melbourne rather than Malaysia because of a wonky GPS. If your navigation is faulty, you\u2019ll quickly end up somewhere you don\u2019t want to be.", "For example, if you implement a new feature which adds a bunch of parameters and compare it to the performance of an existing model without redoing a hyperparameter search, you might incorrectly conclude that your new feature makes things worse. In fact, you probably need to regularize more heavily to reveal the benefit of your more expressive model.", "Errors that lead to inaccurate experimentation accrue over time, and thus spotting them early is valuable.", "The big boss of errors: making a mistake which leads you to overestimate performance. These are hard to spot because we\u2019re biased against seeing them: when the model performs surprising badly, we\u2019re inclined to take a second look, but when it performs surpisingly well we\u2019re more likely to congratulate ourselves on our superb intuition (essentially a form of confirmation bias).", "Common causes of overestimation are overfitting to your test set, your data not being representative of the real world, or simply screwing up your metrics. (more on these below).", "If you take away just one thing from this post, it should be this. Nothing is more embarrassing or demoralizing than realizing your model is much worse than you thought.", "Most machine learning is captured by the sausage-making diagram above. You take some data, you pass it through a model, and you quantify the output with some metrics. Let\u2019s see what opportunities exist to make ourselves look silly at each stage.", "Machine learning can be boiled down to trying to reduce the value of your loss function.", "However, the loss function is never exactly what you want to optimize: it\u2019s some approximation. This is even true in the vanilla case when you\u2019re training a classification task: you\u2019re optimizing for train or validation set cross-entropy but you actually care about test set accuracy (or F1/AUC). In cases where the actual objective is something fluffy and non-differentiable (like \u201cproducing a chatbot that sounds like a human\u201d), the problem of low-fidelity approximation is even more acute.", "Whatever your context, if your loss function is not representative of the model\u2019s true performance, you\u2019re in trouble. Here\u2019s a grab bag of ways to mess up here:", "Mixing training data into your validation or test set is easy to do, and will produce superb model performance \u2014 as assessed by your dodgy test set \u2014 and terrible performance in the real world.", "Of course, your train/val/test should be disjoint \u2014 containing different examples. Sometimes you need to think carefully about what exactly constitutes a disjoint set. This can determine what kinds of generalization you are quantifying by test-set performance. For instance, if we are trying to extract the total value from a receipt, obviously the test set should contain never-before-seen receipts. But should it also include never-before-seen merchants, to reassure us that we\u2019re not overfitting to specific shops?", "Sometimes you need to think carefully about what exactly constitutes a disjoint set. This can determine what kinds of generalization you are quantifying by test-set performance.", "It\u2019s good practice to split your data into train, validation, and test set once, and then put them in separate folders in the filesystem. Wherever you read in data, make the naming super-explicit: TrainDataLoader and TestDataLoader, for instance.", "This is quite hard to do, because most of the frameworks will take care of loss function specification for you.", "However, there are plenty of ways to abuse the rock-solid implementations you\u2019re given. The two most common errors I\u2019ve seen here are confusing whether the loss function expects to receive probability distributions or logits (i.e. whether you need to add a softmax), and mixing up regression and classification.", "The latter is surprisingly common, even in academia. For instance, the Amazon Reviews Dataset, which contains reviews along with star ratings, is frequently used as a classification task by top labs. This is clearly not-quite-right, because a 5 star review is more similar to a 4 star one than it is a 1 star (the data is ordinal).", "Whilst loss functions for deep learning have to be differentiable, we often use a different suite of non-differentiable metrics to articulate performance at test time. For instance, in machine translation and summarization we use BLEU or ROUGE respectively, and for other tasks we might use accuracy, precision, or recall.", "Often, these are more human-interpretable than the value of your loss function, which can be difficult to understand (handy tip: cross-entropy should be -log[n_classes] when you start training, if the dataset is balanced). It\u2019s, therefore, a good idea to log as many test set metrics during training as you can, rather than waiting to only use them at test time. This will give you a better feel for how training is progressing and prevent you discovering problems only after you\u2019ve finished training.", "Be careful about choosing your test functions. For instance, you can\u2019t use accuracy to describe performance of sequence models by counting the number of characters that match, because any misalignment between sequences will produce zero accuracy. Therefore you need to use edit distance instead. Choosing the wrong metric to evaluate your model is a painful, and memorable, experience.", "Staying with the sequence modelling example: make sure you understand the special characters \u2014 typically start of sequence (SOS), end of sequence (EOS) and padding. If you forget to exclude them from your calculations, you can end up with models that appear superb \u2014 but are just really good at predicting long sequences full of padding.", "I once did some work on semantic parsing, where the aim was to convert natural language statements to database queries that could be evaluated to answer questions like \u201cHow many flights are there from Montreal to Atlanta tomorrow?\u201d. To characterize its accuracy, we sent the candidate database queries to a database, and checked whether what came back matched what we sent the true database query. In one of my more spectacular screw ups, I set up a situation where the database failed silently if you sent it nonsensical queries, returning an \u2018error\u2019 string \u2014 and then I sent corrupted versions of both the predicted and true database queries. Both of which returned the string \u2018error\u2019 \u2014 which was then tallied up as 100% accurate.", "This leads to the guiding principle to try and set things up such that any mistakes you\u2019ve made can only make performance worse and to always look at the predictions your model is actually making, not just the metrics.", "This is what random looks like. If your model is performing surprisingly well without any training, you\u2019ve screwed up.", "ML is a quantitative discipline, but statistics lie. Your eyes rarely do. Yes, you should log all the numbers you can think of, but you should also log predictions of the model in a human-readable way.", "In NLP, this usually means inverting your tokenisation, which can be a pain \u2014 but it\u2019s 100% worth it. It can also give you valuable insights into the qualitative aspect of model training. For instance, language models typically start by learning to output strings like eeeeeeeeee<PAD><PAD><PAD>, because those are the most frequent characters in the data.", "If you work with images, logging stuff can be more of a pain because you can\u2019t just output images to a text file or the terminal. My colleagues use ASCII art to overcome this, allowing them to visualize the inputs to their Optical Character Recognition models during training:", "Use your test metrics to identify the best and worst performing samples in the set. Get to know them. Do they match your intuitions about where the model should be performing well, and when it should struggle? If you have some way of quantifying confidence, like a softmax, you can explore situations where the model was super confident \u2014 and wrong.", "In regression, studying residuals is good. Remember that averages can be misleading, as articulated by Anscombe\u2019s Quartet:", "If you have a multi-dimensional problem, try and plot errors vs. individual features. Are there regions of the input space where you\u2019re doing particularly poorly? If so, you may need to collect more data or augment in that region.", "Consider ablating or perturbing certain features and checking how it affects performance. Tools like LIME and Eli5 make this straightforward for machine learning models. This excellent article describes how perturbation analysis revealed that CNN\u2019s for x-ray classification were using tags introduced by the x-ray machine itself to decide whether patients had pneumonia or not because there was a correlation between the type of x-ray machine used and prevalence of pneumonia.", "Most of the classes you take and the interviews you attend will focus upon the modelling aspect of machine learning. In reality, your career as a machine learning practitioner will mostly be spent worrying about data and metrics, and not about exotic implementations of attention mechanisms.", "The vast majority of deep learning errors are shape errors, which, as mentioned above, is a wonderful thing: they cause explicit failures which are relatively easy to fix.", "More subtle ways in which to break your models include:", "In deep learning models, everything has to be end-to-end differentiable for backprop to work. You might expect, therefore, for non-differentiable operations in deep learning frameworks like Tensorflow to be clearly signposted. You\u2019d be wrong. I\u2019ve seen particular confusion with the Keras Lambda layers which have a flair for breaking backprop. The antidote to that particular poison is to check with model.summary() to verify that the majority of your parameters are trainable \u2014 if you see layers with untrainable parameters, you\u2019ve probably broken the autodifferentiation.", "If you see layers with untrainable parameters, you\u2019ve probably broken the autodifferentiation.", "2. Failing to turn off dropout at test time", "Dropout needs to be turned off at test time, otherwise, you\u2019re going to get stochastic results. This can be very confusing, particularly for the person who is deploying your model and trying to write tests for it.", "In most frameworks, this is handled by setting a model mode to eval . Note also that during training, dropout can produce a surprising phenomenon whereby your validation loss is better than your training loss because when evaluating the former you\u2019ve got dropout off. When you first see this it looks like the opposite of overfitting, and can cause some headscratching.", "Different frameworks offer different conventions in terms of arranging common dimensions such as batch size, sequence length, and number of channels. Some give you the choice to flip things around, and others will simply fail silently if you get it wrong.", "Failing to correctly order your dimensions can produce weird and subtle behaviours. For instance, if you confuse batch size and sequence length, you\u2019ll end up bleeding information across examples in your batch and failing to preserve information over time", "Modelling errors can be avoided primarily by well-structured code and unit testing, which go hand in hand.", "By breaking up your model into discrete chunks with clearly defined roles, you\u2019ll be able to test them effectively. Your tests should focus on verifying dimensionality is as you\u2019d expect under conditions of varying batch and input size. I really liked this post from Chase Roberts on unit testing ML code.", "I like to sprinkle assertions about dimensionality into my ML code. This makes it crystal clear to the reader which dimensions should be changing and which shouldn\u2019t \u2014 and of course, it throws an error if something unexpected happens.", "At the very least, try to get into the habit of adding comments about dimensionality to your code, to limit the working memory load for the reader. Check out this beautiful Tacotron implementation from Keith Ito for an example of superly commented Tensorflow code.", "3. Overfitting simple models with small data", "This is another Karpathy tip that I learned the value of very early on. You should make sure that your model overfits a tiny portion of your dataset.", "For bonus points, make your models easily configurable via a config file, and specify a test config which has a minimal number of parameters. Then add a step to your CI/CD where you check that this small model is capable of overfitting to a really tiny dataset, and run it automatically. This will help catch any changes to the codebase which break either the model or the training pipeline.", "Before you even start modelling, you should be sick and tired of looking at the data.", "Most of the ML we do attempts to replicate some of the pattern recognition abilities of the human brain. Make your life easy by exercising those abilities before you start writing code! Understanding your dataset will help you think about architectures and metrics, and swiftly understand where problems with performance might arise.", "Frequently, it will also flag problems in the data itself: imbalances in classes, file type problems, or biases. The latter can be hard to assess algorithmically because to spot them you\u2019d need a model just as clever as the one you\u2019re trying to train. For instance, you\u2019re going to need to look at your data to notice stuff like \u201call of my pictures of cats are taken indoors and all of my pictures of dogs are outdoors, so perhaps I\u2019m training an indoor/outdoor classifier rather than a cat/dog one?\u201d.", "It can be worth investing significant effort in building software to help you view, slice, and dice the data, as Andrej Karpathy discusses here. When I saw him talk at KDD in London in 2018 he stressed that many of the ML engineers at Uber aren\u2019t writing code to optimize models; they\u2019re writing code to optimize labelling of data.", "To understand your data, you need to gain intuitions about three distributions:", "Loading and preprocessing data effectively is one of the more painful parts of machine learning engineering. I\u2019ve generally found there to be a tradeoff between efficiency and transparency.", "At one end of the spectrum, dedicated datastructures like Tensorflow Records allow you to serialize your data into large packets and prevent frequent read/write to disc. However, what you gain in efficiency you lose in transparency: these structures are hard to interrogate and if you decide you want to add or remove files you have to reserialize.", "At the other end of the spectrum, simply reading directly from disc into a list and iterating through it isn\u2019t going to win any awards for speed, but it is completely clear what\u2019s going on.", "Nowadays I find the Pytorch Dataset andDatasetLoader utilities are a good compromise between control and efficiency. There are dedicated packages for handling text (torchtext) and image (torchvision) datasets, which provide relatively efficient ways to load, pad, and batch data in each domain. I\u2019ve also heard good things about Pytorch Lightning but I\u2019m yet to use it.", "Here are a collection of interesting ways I\u2019ve managed how to get this wrong in the past.", "It\u2019s surprisingly easy to end up missing data, or loading the same data repeatedly. Here are some ways I\u2019ve managed this:", "Don\u2019t put all of your data in a single directory.", "If you have 1'000'000 text files and put them all in a single folder, your life is going to be painful because any operations on that folder will take ages. There are lots of times when you just want to grab a few files to look at or calculate something and you\u2019ll end up drastically slowing down your workflows by waiting for massive folders to load. This is exacerbated if your data is stored remotely in a datacentre and you\u2019ve mounted directories using sshfs .", "A second pitfall is failing to make copies of your data when you apply expensive preprocessing steps. It\u2019s a good idea to save the results of time-consuming pre-processing to disc so you don\u2019t have to redo the work each time your model runs, but it\u2019s important not to overwrite the original data, and to be able to keep track of which preprocessing code was run on what data.", "Something like the following usually works well:", "It\u2019s quite easy, particularly in NLP, to end up abusing your data in preprocessing.", "Incorrect handling of non-ASCII characters can be a huge painpoint, and they often appear sufficiently infrequently that it can be hard to spot.", "Tokenization brings with it lots of possibilities for mistakes. If you\u2019re performing word-based tokenization it\u2019s easy to end up forming your vocabulary on one dataset and then using it on another (or the same one before or after some preprocessing), resulting in lots of out of vocabulary words. This is a pernicious silent error \u2014 your model won\u2019t break, it just won\u2019t work very well.", "Gross differences in vocabulary between train and test sets can produce problems here, because you\u2019re not going to be able to learn anything about words that are in the test set but not the training set. Again, knowing your data well and spotting these issues early is very worthwhile.", "Make sure that every time you transform your data you\u2019re logging examples during training. You shouldn\u2019t just be logging what\u2019s coming out of your models, you should be logging what\u2019s going in.", "You should be very familiar with the following statistics:", "Again, you can and should log these things, or you can sprinkle in someassert statements to make sure that everything adds up.", "Some preprocessing steps require or create artifacts, and you need to be diligent about saving these. For instance, if you\u2019re normalizing numerical data by the mean and variance of the training set, you need to save that mean and variance so you can apply the same transformation at test time. Similarly, if you don\u2019t save your training vocabulary, you\u2019re not going to be able to tokenize in the same way at test time \u2014 forming a new vocabulary on your test and retokenizing will produce nonsense results as each word will receive a completely different token.", "When you have datasets consisting of large files such as images and audio, it can be tempting to feed them into your neural network with minimal preprocessing in the hope that the network will learn whatever preprocessing works best.", "If you have infinite time and compute, this might be a good way to go, but in the real world some judicious downsampling can go a long way. You probably don\u2019t need full HD images to train a dog/cat classifier, and although you can use dilated convolutions to learn a downsampler your time and gradient descent is going to be better spent if you just downsample in the traditional manner before doing any learning.", "Downsampling allows you to go through the loop of model fitting, model assessment, and model fiddling faster, and is thus a good investment of time.", "To wrap up, 5 guiding principles to live by in your machine learning adventures:", "Product manager & data scientist. Writing about AI, building things, and climate change."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbc1c627f2789&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://archydeberker.medium.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Archy de Berker"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff651916e4a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&user=Archy+de+Berker&userId=f651916e4a3f&source=post_page-f651916e4a3f----bc1c627f2789---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbc1c627f2789&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&user=Archy+de+Berker&userId=f651916e4a3f&source=-----bc1c627f2789---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc1c627f2789&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&source=-----bc1c627f2789---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://images.unsplash.com/photo-1508115821155-4f380ea5eaa9?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=900&q=60", "anchor_text": "Source: John T on Unsplash"}, {"url": "http://karpathy.github.io/2019/04/25/recipe/", "anchor_text": "here."}, {"url": "http://gnuplot.sourceforge.net/demo/transparent.html", "anchor_text": "Image source."}, {"url": "https://www.theguardian.com/australia-news/2016/sep/07/airasia-pilot-flies-melbourne-malaysia-navigation-error", "anchor_text": "AirAsia pilot who ended up in Melbourne rather than Malaysia"}, {"url": "https://www.verywellmind.com/what-is-a-confirmation-bias-2795024", "anchor_text": "confirmation bias"}, {"url": "https://lossfunctions.tumblr.com", "anchor_text": "https://lossfunctions.tumblr.com"}, {"url": "https://pbs.twimg.com/media/D3SwgeEWAAAaSEv.jpg", "anchor_text": "Source"}, {"url": "https://arxiv.org/pdf/1606.01781.pdf", "anchor_text": "frequently used as a classification task by top labs."}, {"url": "https://machinelearningmastery.com/calculate-bleu-score-for-text-python/", "anchor_text": "BLEU"}, {"url": "https://en.wikipedia.org/wiki/ROUGE_(metric)", "anchor_text": "ROUGE"}, {"url": "https://www.hackerearth.com/practice/notes/beautiful-python-a-simple-ascii-art-generator-from-images/", "anchor_text": "Source"}, {"url": "https://en.wikipedia.org/wiki/Anscombe's_quartet#/media/File:Anscombe%27s_quartet_3.svg", "anchor_text": "Source"}, {"url": "http://lime-ml.readthedocs.io/", "anchor_text": "LIME"}, {"url": "https://eli5.readthedocs.io", "anchor_text": "Eli5"}, {"url": "https://medium.com/@jrzech/what-are-radiological-deep-learning-models-actually-learning-f97a546c5b98", "anchor_text": "excellent article"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda", "anchor_text": "Keras Lambda layers"}, {"url": "https://www.google.com/search?client=safari&rls=en&q=chase+roberts+unit+tests+ml&ie=UTF-8&oe=UTF-8", "anchor_text": "this post from Chase Roberts on unit testing ML code."}, {"url": "https://github.com/keithito/tacotron/blob/master/models/tacotron.py", "anchor_text": "Keith Ito"}, {"url": "https://github.com/keithito/tacotron/blob/master/models/tacotron.py", "anchor_text": "beautiful Tacotron implementation from Keith Ito"}, {"url": "http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/", "anchor_text": "Source"}, {"url": "http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/", "anchor_text": "here"}, {"url": "https://www.tensorflow.org/tutorials/load_data/tfrecord", "anchor_text": "Tensorflow Records"}, {"url": "https://torchtext.readthedocs.io/en/latest/", "anchor_text": "torchtext"}, {"url": "https://pytorch.org/docs/stable/torchvision/index.html", "anchor_text": "torchvision"}, {"url": "https://github.com/PyTorchLightning/pytorch-lightning", "anchor_text": "Pytorch Lightning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----bc1c627f2789---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----bc1c627f2789---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----bc1c627f2789---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/coding?source=post_page-----bc1c627f2789---------------coding-----------------", "anchor_text": "Coding"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----bc1c627f2789---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbc1c627f2789&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&user=Archy+de+Berker&userId=f651916e4a3f&source=-----bc1c627f2789---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbc1c627f2789&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&user=Archy+de+Berker&userId=f651916e4a3f&source=-----bc1c627f2789---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc1c627f2789&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff651916e4a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&user=Archy+de+Berker&userId=f651916e4a3f&source=post_page-f651916e4a3f----bc1c627f2789---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1754fbd1852&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&newsletterV3=f651916e4a3f&newsletterV3Id=b1754fbd1852&user=Archy+de+Berker&userId=f651916e4a3f&source=-----bc1c627f2789---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Written by Archy de Berker"}, {"url": "https://archydeberker.medium.com/followers?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "321 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff651916e4a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&user=Archy+de+Berker&userId=f651916e4a3f&source=post_page-f651916e4a3f----bc1c627f2789---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1754fbd1852&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frookie-errors-in-machine-learning-bc1c627f2789&newsletterV3=f651916e4a3f&newsletterV3Id=b1754fbd1852&user=Archy+de+Berker&userId=f651916e4a3f&source=-----bc1c627f2789---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/predicting-the-performance-of-deep-learning-models-9cb50cf0b62a?source=author_recirc-----bc1c627f2789----0---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=author_recirc-----bc1c627f2789----0---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=author_recirc-----bc1c627f2789----0---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Archy de Berker"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----bc1c627f2789----0---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/predicting-the-performance-of-deep-learning-models-9cb50cf0b62a?source=author_recirc-----bc1c627f2789----0---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Predicting the performance of deep learning modelsPower-law scaling explains how a model\u2019s performance will change as we feed it more data"}, {"url": "https://towardsdatascience.com/predicting-the-performance-of-deep-learning-models-9cb50cf0b62a?source=author_recirc-----bc1c627f2789----0---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "\u00b76 min read\u00b7Apr 14, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&user=Archy+de+Berker&userId=f651916e4a3f&source=-----9cb50cf0b62a----0-----------------clap_footer----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/predicting-the-performance-of-deep-learning-models-9cb50cf0b62a?source=author_recirc-----bc1c627f2789----0---------------------9960218b_a268_4536_9cbb_daed26040906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=-----bc1c627f2789----0-----------------bookmark_preview----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----bc1c627f2789----1---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----bc1c627f2789----1---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----bc1c627f2789----1---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----bc1c627f2789----1---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----bc1c627f2789----1---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----bc1c627f2789----1---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----bc1c627f2789----1---------------------9960218b_a268_4536_9cbb_daed26040906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----bc1c627f2789----1-----------------bookmark_preview----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----bc1c627f2789----2---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----bc1c627f2789----2---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----bc1c627f2789----2---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----bc1c627f2789----2---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----bc1c627f2789----2---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----bc1c627f2789----2---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----bc1c627f2789----2---------------------9960218b_a268_4536_9cbb_daed26040906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----bc1c627f2789----2-----------------bookmark_preview----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://medium.com/element-ai-research-lab/multithreaded-predictions-with-tensorflow-estimators-eb041861da07?source=author_recirc-----bc1c627f2789----3---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=author_recirc-----bc1c627f2789----3---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=author_recirc-----bc1c627f2789----3---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Archy de Berker"}, {"url": "https://medium.com/element-ai-research-lab?source=author_recirc-----bc1c627f2789----3---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Element AI Lab"}, {"url": "https://medium.com/element-ai-research-lab/multithreaded-predictions-with-tensorflow-estimators-eb041861da07?source=author_recirc-----bc1c627f2789----3---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "Multithreaded predictions with TensorFlow EstimatorsCaching estimators to speed up inference by >100x"}, {"url": "https://medium.com/element-ai-research-lab/multithreaded-predictions-with-tensorflow-estimators-eb041861da07?source=author_recirc-----bc1c627f2789----3---------------------9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": "6 min read\u00b7Jun 18, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Felement-ai-research-lab%2Feb041861da07&operation=register&redirect=https%3A%2F%2Fmedium.com%2Felement-ai-research-lab%2Fmultithreaded-predictions-with-tensorflow-estimators-eb041861da07&user=Archy+de+Berker&userId=f651916e4a3f&source=-----eb041861da07----3-----------------clap_footer----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://medium.com/element-ai-research-lab/multithreaded-predictions-with-tensorflow-estimators-eb041861da07?source=author_recirc-----bc1c627f2789----3---------------------9960218b_a268_4536_9cbb_daed26040906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feb041861da07&operation=register&redirect=https%3A%2F%2Fmedium.com%2Felement-ai-research-lab%2Fmultithreaded-predictions-with-tensorflow-estimators-eb041861da07&source=-----bc1c627f2789----3-----------------bookmark_preview----9960218b_a268_4536_9cbb_daed26040906-------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "See all from Archy de Berker"}, {"url": "https://towardsdatascience.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----bc1c627f2789----0-----------------bookmark_preview----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Rukshan Pramoditha"}, {"url": "https://medium.com/data-science-365?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Data Science 365"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Determining the Right Batch Size for a Neural Network to Get Better and Faster ResultsGuidelines for choosing the right batch size to maintain optimal training speed and accuracy while saving computer resources"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "\u00b74 min read\u00b7Sep 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-365%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----7a8662830f15----1-----------------clap_footer----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&source=-----bc1c627f2789----1-----------------bookmark_preview----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://billatnapier.medium.com/similarity-hashing-and-perceptial-hashes-963fba36c8b5?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://billatnapier.medium.com/?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://billatnapier.medium.com/?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Prof Bill Buchanan OBE"}, {"url": "https://billatnapier.medium.com/similarity-hashing-and-perceptial-hashes-963fba36c8b5?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Similarity Hashing and Perceptual HashesSean McKeown [here] and myself have just published a paper to arXiv that will be presented at DFRWS (Digital Forensics Research Conference)\u2026"}, {"url": "https://billatnapier.medium.com/similarity-hashing-and-perceptial-hashes-963fba36c8b5?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "\u00b79 min read\u00b7Dec 17, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F963fba36c8b5&operation=register&redirect=https%3A%2F%2Fbillatnapier.medium.com%2Fsimilarity-hashing-and-perceptial-hashes-963fba36c8b5&user=Prof+Bill+Buchanan+OBE&userId=e680fcaf274b&source=-----963fba36c8b5----0-----------------clap_footer----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://billatnapier.medium.com/similarity-hashing-and-perceptial-hashes-963fba36c8b5?source=read_next_recirc-----bc1c627f2789----0---------------------49238ad9_b838_436b_b682_2619a2eece7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F963fba36c8b5&operation=register&redirect=https%3A%2F%2Fbillatnapier.medium.com%2Fsimilarity-hashing-and-perceptial-hashes-963fba36c8b5&source=-----bc1c627f2789----0-----------------bookmark_preview----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://salvatore-raieli.medium.com/?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://salvatore-raieli.medium.com/?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Salvatore Raieli"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "META\u2019S SAM: A Unique Model to Segment AnythingSegmentation needs a foundation model: why is it important?"}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "\u00b714 min read\u00b7Apr 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fc3a956bf5d62&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fmetas-sam-a-unique-model-to-segment-anything-c3a956bf5d62&user=Salvatore+Raieli&userId=f1a08d9452cd&source=-----c3a956bf5d62----1-----------------clap_footer----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----bc1c627f2789----1---------------------49238ad9_b838_436b_b682_2619a2eece7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc3a956bf5d62&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fmetas-sam-a-unique-model-to-segment-anything-c3a956bf5d62&source=-----bc1c627f2789----1-----------------bookmark_preview----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----bc1c627f2789----2---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://medium.com/@iamleonie?source=read_next_recirc-----bc1c627f2789----2---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://medium.com/@iamleonie?source=read_next_recirc-----bc1c627f2789----2---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Leonie Monigatti"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----bc1c627f2789----2---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----bc1c627f2789----2---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "A Visual Guide to Learning Rate Schedulers in PyTorchLR decay and annealing strategies for Deep Learning in Python"}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----bc1c627f2789----2---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "\u00b79 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24bbb262c863&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863&user=Leonie+Monigatti&userId=3a38da70d8dc&source=-----24bbb262c863----2-----------------clap_footer----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863?source=read_next_recirc-----bc1c627f2789----2---------------------49238ad9_b838_436b_b682_2619a2eece7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24bbb262c863&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-guide-to-learning-rate-schedulers-in-pytorch-24bbb262c863&source=-----bc1c627f2789----2-----------------bookmark_preview----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----bc1c627f2789----3---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----bc1c627f2789----3---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----bc1c627f2789----3---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----bc1c627f2789----3---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----bc1c627f2789----3---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----bc1c627f2789----3---------------------49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----3-----------------clap_footer----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----bc1c627f2789----3---------------------49238ad9_b838_436b_b682_2619a2eece7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----bc1c627f2789----3-----------------bookmark_preview----49238ad9_b838_436b_b682_2619a2eece7d-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----bc1c627f2789--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}