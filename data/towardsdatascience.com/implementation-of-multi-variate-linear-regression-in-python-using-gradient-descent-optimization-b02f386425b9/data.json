{"url": "https://towardsdatascience.com/implementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9", "time": 1682994380.661073, "path": "towardsdatascience.com/implementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9/", "webpage": {"metadata": {"title": "Implementation of Multi-Variate Linear Regression in Python using Gradient Descent Optimization from scratch | by Navoneel Chakrabarty | Towards Data Science", "h1": "Implementation of Multi-Variate Linear Regression in Python using Gradient Descent Optimization from scratch", "description": "Most Practical Applications of Machine Learning involve Multiple Features on which the Target Outcome depends upon. Similarly in Regression Analysis Problems, there are instances where the Target\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Most Practical Applications of Machine Learning involve Multiple Features on which the Target Outcome depends upon. Similarly in Regression Analysis Problems, there are instances where the Target Outcome depends on numerous features. Multi-Variate Linear Regression is a possible solution to tackle such problems. In this article, I will be discussing the Multi-Variate (multiple features) Linear Regression, its Python Implementation from Scratch, Application on a Practical Problem and Performance Analysis.", "As it is a \u201clinear\u201d Regression Technique, only linear term of each feature will be taken in the framing of the hypothesis. Let, x_1, x_2, \u2026 x_n, be the features on which the Target Outcome depends upon. Then, the hypothesis for Multi-Variate Linear Regression:", "Also, the above hypothesis can be re-framed in terms of Vector Algebra too:", "There is also a cost function (or loss function) associated with the hypothesis dependent upon parameters, theta_0, theta_1, theta_2, \u2026 ,theta_n.", "The cost function here is the same as in the case of Polynomial Regression [1].", "So, these parameters, theta_0, theta_1, theta_2, \u2026, theta_n have to assume such values for which the cost function (or simply cost) reaches to its minimum value possible. In other words, the minima of the Cost Function have to be found out.", "Batch Gradient Descent can be used as the Optimization Strategy in this case.", "Implementation of Multi-Variate Linear Regression using Batch Gradient Descent:", "The implementation is done by creating 3 modules each used for performing different operations in the Training Process.", "=> hypothesis(): It is the function that calculates and outputs the hypothesis value of the Target Variable, given theta (theta_0, theta_1, theta_2, theta_3, \u2026., theta_n), Features in a matrix, X of dimension [m X (n+1)] where m is the number of samples and n is the number of features. The implementation of hypothesis() is given below:", "=>BGD(): It is the function that performs the Batch Gradient Descent Algorithm taking current value of theta (theta_0, theta_1,\u2026, theta_n), learning rate (alpha), number of iterations (num_iters), list of hypothesis values of all samples (h), feature set (X), Target Variable set (y) and Number of Features (n) as input and outputs the optimized theta (theta_0, theta_1, theta_2, theta_3, \u2026, theta_n) and the cost history or cost which contains the value of the cost function over all the iterations. The implementation of BGD() is given below:", "=>linear_regression(): It is the principal function that takes the features matrix (X), Target Variable Vector (y), learning rate (alpha) and number of iterations (num_iters) as input and outputs the final optimized theta i.e., the values of [theta_0, theta_1, theta_2, theta_3,\u2026.,theta_n] for which the cost function almost achieves minima following Batch Gradient Descent, and cost which stores the value of cost for every iteration.", "Now, let\u2019s move on to the Application of the Multi-Variate Linear Regression on a Practical Practice Data-Set.", "Let us consider a Housing Price Data-Set of Portland, Oregon. It contains size of the house (in square feet) and number of bedrooms as features and price of the house as the Target Variable. The Data-Set is available at,", "Problem Statement: \u201cGiven the size of the house and number of bedrooms, analyze and predict the possible price of the house\u201d", "Data Reading into Numpy Arrays :", "This involves scaling the features for fast and efficient computation.", "where u is the Mean and sigma is the Standard Deviation:", "The cost has been reduced in the course of Batch Gradient Descent iteration-by-iteration. The reduction in the cost is shown with the help of Line Curve.", "Side-by-Side Visualization of Features and Target Variable Actual and Prediction using 3-D Scatter Plots :", "One thing to be noted, is that the Mean Absolute Error, Mean Square Error and Root Mean Square Error is not unit free. To make them unit-free, before Training the Model, the Target Label can be scaled in the same way, the features were scaled. Other than that, a descent R-Square-Score of 0.7329 is also obtained.", "That\u2019s all about the Implementation of Multi-Variate Linear Regression in Python using Gradient Descent from scratch.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Mining | Data Analytics | Machine Learning | Financial Data Science | Natural Language Processing | Deep Learning"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb02f386425b9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b02f386425b9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b02f386425b9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nc2012.medium.com/?source=post_page-----b02f386425b9--------------------------------", "anchor_text": ""}, {"url": "https://nc2012.medium.com/?source=post_page-----b02f386425b9--------------------------------", "anchor_text": "Navoneel Chakrabarty"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7384b8693848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&user=Navoneel+Chakrabarty&userId=7384b8693848&source=post_page-7384b8693848----b02f386425b9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb02f386425b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb02f386425b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/navoneel1092283/multivariate_regression.git", "anchor_text": "navoneel1092283/multivariate_regressionContribute to navoneel1092283/multivariate_regression development by creating an account on GitHub.github.com"}, {"url": "https://towardsdatascience.com/implementation-of-uni-variate-linear-regression-in-python-using-gradient-descent-optimization-from-3491a13ca2b0", "anchor_text": "https://towardsdatascience.com/implementation-of-uni-variate-linear-regression-in-python-using-gradient-descent-optimization-from-3491a13ca2b0"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b02f386425b9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----b02f386425b9---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/python3?source=post_page-----b02f386425b9---------------python3-----------------", "anchor_text": "Python3"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b02f386425b9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/calculus?source=post_page-----b02f386425b9---------------calculus-----------------", "anchor_text": "Calculus"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb02f386425b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&user=Navoneel+Chakrabarty&userId=7384b8693848&source=-----b02f386425b9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb02f386425b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&user=Navoneel+Chakrabarty&userId=7384b8693848&source=-----b02f386425b9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb02f386425b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b02f386425b9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb02f386425b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b02f386425b9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b02f386425b9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b02f386425b9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b02f386425b9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b02f386425b9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b02f386425b9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b02f386425b9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b02f386425b9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b02f386425b9--------------------------------", "anchor_text": ""}, {"url": "https://nc2012.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nc2012.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Navoneel Chakrabarty"}, {"url": "https://nc2012.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "255 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7384b8693848&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&user=Navoneel+Chakrabarty&userId=7384b8693848&source=post_page-7384b8693848--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6e8a2f5e5fc0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-of-multi-variate-linear-regression-in-python-using-gradient-descent-optimization-b02f386425b9&newsletterV3=7384b8693848&newsletterV3Id=6e8a2f5e5fc0&user=Navoneel+Chakrabarty&userId=7384b8693848&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}