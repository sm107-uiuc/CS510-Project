{"url": "https://towardsdatascience.com/categorical-feature-encoding-547707acf4e5", "time": 1683018195.370175, "path": "towardsdatascience.com/categorical-feature-encoding-547707acf4e5/", "webpage": {"metadata": {"title": "Categorical Feature Encoding. A beginner\u2019s guide to addressing\u2026 | by Joseph Cohen | Towards Data Science", "h1": "Categorical Feature Encoding", "description": "Categorical feature encoding is often a key part of the data science process and can be done in multiple ways leading to different results and a different understanding of input data. Today\u2019s post\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/shivam2503/diamonds", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://www.kaggle.com/shivam2503/diamonds", "anchor_text": "kaggle", "paragraph_index": 6}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html", "anchor_text": "here", "paragraph_index": 12}, {"url": "https://contrib.scikit-learn.org/category_encoders/targetencoder.html", "anchor_text": "here", "paragraph_index": 18}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html", "anchor_text": "documentation", "paragraph_index": 21}], "all_paragraphs": ["Categorical feature encoding is often a key part of the data science process and can be done in multiple ways leading to different results and a different understanding of input data. Today\u2019s post will address this topic and run some models to point out the differences in my three favorite categorical feature encoding methods.", "Naturally, the first topic to be addressed is the definition of what categorical data actually is and what other types of data one normally encounters looks like. Categorical data is non-numeric and often can be characterized into categories or groups. A simple example is is color; red, blue, and yellow are all distinct colors. Another example could be age groups or other interval-type data. Like 1\u201325 years old, 25\u201350 years old, and so on. The data used represents numbers, but the intervals themselves are categorical. Discrete data is similar, but is still numeric. An example of discrete data is the sum of two dice thrown. There are a finite and known set of outcomes, but these outcomes are represented numerically. Continuous data concerns data that can take on infinite values between any two points. A good example that really proves this point is that there are infinite values between 1 and 1.01. Continuous data is generally numeric, like in our example above, but can sometimes be represented in date-time format.", "We encode categorical data numerically because math is generally done using numbers. A big part of natural language processing is converting text to numbers. Just like that, our algorithms cannot run and process data if that data is not numerical. Therefore, data scientists need to have tools at their disposal to transform colors like red, yellow, and blue into numbers like 1, 2, and 3 for all the backend math to take place. Now that we know what categorical data looks like and have seen some examples, we will examine three common methods to turn our categorical data into numeric data.", "Before me move forward, we\u2019ll need some data to work with to show what categorical feature encoding looks like in python and how different methods affect model efficiency. My data comes from kaggle.com, concerns diamond pricing, and can be found here. We will do some basic data preparation just to get a clean data set. Afterwards, using our three methods of categorical feature encoding, we will create three distinct data sets and see which one leads to the best models. The target feature is continuous, so will be predicted via regressor-like methods.", "One-hot encoding is a method of identifying whether a unique categorical value from a categorical feature is present or not. What I mean by this is that if our feature is primary color (and each row has only one primary color), one-hot encoding would represent whether the color present in each row is red, blue, or yellow. This is accomplished by adding a new column for each possible color. With these three columns representing color in place for every row of the data, we go through each row and assign the value 1 to the column representing the color present in our current row and fill in the other color columns of that row with a 0 to represent their absence. Let\u2019s look at how we can do this in python and the benefits and drawbacks to this method.", "There are a couple ways to accomplish this task in python, and I\u2019ll focus on what I believe to be the two easiest methods.", "We see above that row two has a clarity rating of \u201cSI1\u201d (look at kaggle for more information on what this means) and that row one has a cut rating of \u201cideal.\u201d", "One obvious benefit of one-hot encoding is that you notice if any particular unique values within a set of values have an outsized or strong impact in either a positive or negative direction. For example, I used one-hot encoding on a recent project I worked on to measure the likeliness of getting a deal on Shark Tank given the presence of each shark during a particular pitch. Unlike other types of encoding, with one-hot encoding you maintain information on the values of each variable. With label encoding, as we will see below, we get a good measure of the impact of a particular feature on models, but not the specific impacts of unique values of that feature.", "While it\u2019s nice to know the impact, positive or negative, of each unique occurrence in categorical data, it could sometimes make models less accurate. More importantly though, if some unique values are far more common than others, we may erroneously assume that these values are very important when they actually are not. For example, let\u2019s say that you work in a building with the same 1000 people coming in and out every day. One day, someone who has never been to the building walks in, we\u2019ll call him Joseph (my name), and the power in the building goes out. It would be pretty silly to blame Joseph for the power outage, but our data does in fact indicate that 100% of the time Joseph is in the building, we witness a power outage. For this reason, I like using one-hot encoding for features when there aren\u2019t an overwhelming amount of unique values and/or the distribution of unique values is relatively balanced. Similarly, the size of the data set should be large enough so the amount of unique values and their distributions won\u2019t be problematic. One other problem is that since we delete our feature once encoding it, the feature itself\u2019s effect may be somewhat lost as we shift our attention to the values of the feature and not the feature itself.", "Label encoding is probably the most basic type of categorical feature encoding method after one-hot encoding. Label encoding doesn\u2019t add any extra columns to the data but instead assigns a number to each unique value in a feature. Let\u2019s use the colors example again. Instead of adding a column for red, another one for blue, and one more for yellow, we just assign each value a number. Red is 1, blue is 2, and yellow is 3. We saved a lot of room and don\u2019t add more columns to our data, resulting in a much cleaner look for the data. The numbers assigned for red, blue, and yellow are arbitrary and their labels have no actual meaning, but they are simple to deal with. Ordinal encoding is a slightly-advanced form of label encoding; we assign labels based on an order or hierarchy. For colors, I am not an artist, so I see no reason to not assign numbers to color at random. However, if we are dealing with cuts of diamonds, as the data for this blog deals with, we may want to set up a system where the worse cuts are either assigned a higher or lower number. In the code below we will use both label and ordinal encoding.", "For label encoding, we have a very simple and easy python function whose documentation can be found here", "We will once again run a loop and save the data as label_encoded_df", "For ordinal encoding, python has a package whose documentation can be found here. I personally like to perform ordinal encoding using dictionary mapping though. Even if you were to use the python package there is still some manual work to be done, therefore I will present a function for ordinal encoding below", "Let\u2019s quickly see one example of this strategy", "An obvious benefit to label encoding is that it\u2019s quick, easy, and doesn\u2019t create a messy data frame in the way that one-hot encoding adds a lot of columns. Ordinal encoding, which I consider to be an extension of label encoding, imposes extra meaning to the labels assigned through label encoding.", "In label encoding, one major drawback is that our labels are rather arbitrary. Even in ordinal encoding, who\u2019s to say that the step between rank 4 and 5 is the same as a step between 2 and 3? Maybe the difference between what we call 4 and 5 is marginal, while the difference between what we call 2 and 3 is huge. As mentioned above, one other drawback is that while we can find how strong or weak the impact of a particular feature is, we lose all information on unique values within that feature (this is moderately addressed with ordinal encoding, but the effect is marginal). Finally, this method may not work well with outliers as there is the possibility that certain labels may not appear in similar frequencies to the other labels. We see this same problem with target encoding.", "Target encoding happens to be my favorite method of encoding as I find it most often produces the strongest models. Target encoding aligns unique categorical values with the target feature based on the average relationship. Say we are presented with a data set trying to predict a house\u2019s price range based on color. Like above, our colors are red, yellow, and blue. Let\u2019s also say our price ranges for houses are 1, 2, 3, and 4 and our features include basic housing things like square footage and other features (but also color). If we see that red houses tend to fall on average at a 3.35, it means red houses are slightly above a 3 but far below a 4. We then assign every occurrence of the value red to 3.35 as that is the mean target value. This is taking label and ordinal encoding to the next level. We introduce meaningful numbers to take the place of colors as opposed to arbitrary numbers. Also, if blue houses fall at 3.34, or even at 3.35 like red, we have no problem and can assign the number 3.34 or 3.35 to blue. This \u201cdouble-labeling\u201d (that\u2019s what I have decided to call it) would be impossible with label or ordinal encoding.", "Target encoding, like other encoders has a python package. It\u2019s a user-friendly package and I will show how to use it. I will also, however, add a more descriptive function to give you further insight into the backend of target encoding.", "First, the python package whose documentation can be found here.", "Target encoding is the most meaningful way I can think of to attach numbers to categorical values. It\u2019s a simple concept and is easy and expedient to apply. I also find that it usually generates the best models.", "Just like label and ordinal encoding, we lose the name of the actual values for each particular feature. A far greater drawback, however, is the fact that as its name implies, we can only use target encoding when dealing with labeled data. If we don\u2019t know what the target is, then this all goes out the window. I also believe that when you have very few features in a dataset, target encoding may lead to overfitting as you are integrating the target column into your data directly and this may have an overpowering effect with few unique features or relatively few unique values per feature.", "Before I run the models, I want to quickly apply max-absolute scaling so that we can compare coefficients of different magnitudes. More information on max-absolute scaling can be found at the documentation. I should re-iterate that this will not affect our models in any extreme way as the accuracy remains basically the same even without scaling but the coefficients cannot be compared at different scales.", "Next, I\u2019ll make a function to run and evaluate models.", "Interestingly, one-hot performed best in this setting. I also like using one-hot encoding here due to the fact there are few unique categorical values. Another interesting observation is the difference in clarity\u2019s effect between label and target encoding. I\u2019m a little perplexed by what I see in the one-hot model coefficients, and definitely will have to investigate this further.", "This post served as introduction to the problem categorical data represents in data science and we addressed the benefits and drawbacks of various common methods available. We also ran some models to see each method in action. I hope this post will help readers think of creative and strategic ways to address categorical data in their future projects.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist and machine learning engineer with a passion for telling data-driven stories and solving real world problems using data."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F547707acf4e5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----547707acf4e5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----547707acf4e5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@arieljosephcohen?source=post_page-----547707acf4e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arieljosephcohen?source=post_page-----547707acf4e5--------------------------------", "anchor_text": "Joseph Cohen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd1d523a49c4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&user=Joseph+Cohen&userId=d1d523a49c4e&source=post_page-d1d523a49c4e----547707acf4e5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F547707acf4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F547707acf4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@alexblock", "anchor_text": "Alex Block"}, {"url": "https://unsplash.com/photos/vWI1kTcMcDI", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/shivam2503/diamonds", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html", "anchor_text": "documentation"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html", "anchor_text": "here"}, {"url": "https://www.kaggle.com/shivam2503/diamonds", "anchor_text": "kaggle"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html", "anchor_text": "here"}, {"url": "https://contrib.scikit-learn.org/category_encoders/targetencoder.html", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html", "anchor_text": "documentation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html", "anchor_text": "documentation"}, {"url": "https://unsplash.com/@kevin_butz", "anchor_text": "Kevin Butz"}, {"url": "https://unsplash.com/photos/6hsfmat-t7k", "anchor_text": "Unsplash"}, {"url": "https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/what-are-categorical-discrete-and-continuous-variables/#:~:text=Categorical%20variables%20contain%20a%20finite,not%20have%20a%20logical%20order.&text=Continuous%20variables%20are%20numeric%20variables,be%20numeric%20or%20date%2Ftime", "anchor_text": "https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/what-are-categorical-discrete-and-continuous-variables/#:~:text=Categorical%20variables%20contain%20a%20finite,not%20have%20a%20logical%20order.&text=Continuous%20variables%20are%20numeric%20variables,be%20numeric%20or%20date%2Ftime"}, {"url": "https://www.kaggle.com/shivam2503/diamonds", "anchor_text": "https://www.kaggle.com/shivam2503/diamonds"}, {"url": "https://medium.com/analytics-vidhya/target-encoding-vs-one-hot-encoding-with-simple-examples-276a7e7b3e64#:~:text=Limitations%20of%20Target%20Encoding,improvements%20some%20of%20the%20time", "anchor_text": "https://medium.com/analytics-vidhya/target-encoding-vs-one-hot-encoding-with-simple-examples-276a7e7b3e64#:~:text=Limitations%20of%20Target%20Encoding,improvements%20some%20of%20the%20time"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F547707acf4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&user=Joseph+Cohen&userId=d1d523a49c4e&source=-----547707acf4e5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F547707acf4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&user=Joseph+Cohen&userId=d1d523a49c4e&source=-----547707acf4e5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F547707acf4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----547707acf4e5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F547707acf4e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----547707acf4e5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----547707acf4e5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----547707acf4e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----547707acf4e5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----547707acf4e5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----547707acf4e5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----547707acf4e5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----547707acf4e5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----547707acf4e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arieljosephcohen?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arieljosephcohen?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Joseph Cohen"}, {"url": "https://medium.com/@arieljosephcohen/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "45 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd1d523a49c4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&user=Joseph+Cohen&userId=d1d523a49c4e&source=post_page-d1d523a49c4e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F102db26a100d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcategorical-feature-encoding-547707acf4e5&newsletterV3=d1d523a49c4e&newsletterV3Id=102db26a100d&user=Joseph+Cohen&userId=d1d523a49c4e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}