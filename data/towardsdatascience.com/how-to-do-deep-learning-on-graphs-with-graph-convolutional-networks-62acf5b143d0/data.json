{"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0", "time": 1682994719.332459, "path": "towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0/", "webpage": {"metadata": {"title": "How to do Deep Learning on Graphs with Graph Convolutional Networks | by Tobias Skovgaard Jepsen | Towards Data Science", "h1": "How to do Deep Learning on Graphs with Graph Convolutional Networks", "description": "Machine learning on graphs is a difficult task due to the highly complex, but also informative graph structure. This post is the second in a series on how to do deep learning on graphs with Graph\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Semi-supervised_learning", "anchor_text": "semi-supervised learning", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "my previous post", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Diagonal_matrix", "anchor_text": "diagonal matrix", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Semi-supervised_learning", "anchor_text": "semi-supervised learning", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Transduction_(machine_learning)", "anchor_text": "transductive", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Homophily", "anchor_text": "homophily", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "the previous post", "paragraph_index": 25}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "the previous post", "paragraph_index": 26}, {"url": "https://github.com/TobiasSkovgaardJepsen/posts/tree/master/HowToDoDeepLearningOnGraphsWithGraphConvolutionalNetworks/Part2_SemiSupervisedLearningWithSpectralGraphConvolutions", "anchor_text": "here", "paragraph_index": 27}, {"url": "https://en.wikipedia.org/wiki/Zachary%27s_karate_club", "anchor_text": "Zachary\u2019s Karate Club", "paragraph_index": 28}, {"url": "https://mxnet.apache.org/", "anchor_text": "MXNet", "paragraph_index": 29}, {"url": "https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0", "anchor_text": "efficient", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "logistic regression", "paragraph_index": 36}, {"url": "https://en.wikipedia.org/wiki/Sigmoid_function", "anchor_text": "sigmoid function", "paragraph_index": 36}, {"url": "https://github.com/TobiasSkovgaardJepsen/posts/blob/master/HowToDoDeepLearningOnGraphsWithGraphConvolutionalNetworks/Part2_SemiSupervisedLearningWithSpectralGraphConvolutions/notebook.ipynb", "anchor_text": "the accompanying Jupyter notebook", "paragraph_index": 37}, {"url": "https://en.wikipedia.org/wiki/Identity_matrix", "anchor_text": "identity matrix", "paragraph_index": 42}, {"url": "https://twitter.com/TobiasSJepsen", "anchor_text": "Twitter", "paragraph_index": 53}, {"url": "https://www.linkedin.com/in/tobias-skovgaard-jepsen/", "anchor_text": "LinkedIn", "paragraph_index": 54}, {"url": "https://twitter.com/TobiasSJepsen", "anchor_text": "Twitter", "paragraph_index": 54}, {"url": "https://arxiv.org/abs/1609.02907", "anchor_text": "Paper", "paragraph_index": 55}], "all_paragraphs": ["Machine learning on graphs is a difficult task due to the highly complex, but also informative graph structure. This post is the second in a series on how to do deep learning on graphs with Graph Convolutional Networks (GCNs), a powerful type of neural network designed to work directly on graphs and leverage their structural information. I will provide a brief recap of the previous post, but you can find the other parts of the series here:", "In the previous post, I gave a high-level introduction to GCNs and showed how a nodes representation is updated based on its neighbors representation. In this post, we first gain a deeper understanding of the aggregation performed during the rather simple graph convolutions discussed in the previous post. Then we move on to a recently published graph convolutional propagation rule and I show how to implement and use it for semi-supervised learning on a community prediction task in Zachary\u2019s Karate Club, a small social network. As shown below, the GCN is able to learn latent feature representations for each node that separates the two communities into two reasonably cohesive and separated clusters despite using only one training example for each community.", "In my previous post on GCNs, we a saw a simple mathematical framework for expressing propagation in GCNs. In short, given an N \u00d7 F\u2070 feature matrix X and a matrix representation of the graph structure, e.g., the N \u00d7 N adjacency matrix A of G, each hidden layer in the GCN can be expressed as H\u2071 = f(H\u2071\u207b\u00b9, A)) where H\u2070 = X and f is a propagation rule. Each layer H\u2071 corresponds to an N \u00d7 F\u2071 feature matrix where each row is a feature representation of a node.", "We saw propagation rules of the form", "These rules compute the feature representation of a node as an aggregate of the feature representations of its neighbors before it is transformed by applying the weights W\u2071 and activation function \u03c3. We can make the aggregation and transformation steps more explicit by expressing propagation rules 1 and 2 above as f(H\u2071, A) = transform(aggregate(A,H\u2071), W\u2071) where transform(M, W\u2071) = \u03c3(MW\u2071) and aggregate(A,H\u2071) = AH\u2071 for rule 1 and aggregate(A,H\u2071) = D\u207b\u00b9\u00c2 H\u2071 for rule 2.", "As we discussed in the previous post, aggregation in rule 1 represents a node as a sum of its neighbors feature representations which has two significant shortcomings:", "To fix these two issues, rule 2 first enforces self loops by adding the identity matrix to A and aggregate on using the transformed adjacency matrix \u00c2 = A + I. Next, the feature representations are normalized by multiplication with the inverse degree matrix D\u207b\u00b9, turning the aggregate into a mean where the scale of the aggregated feature representation is invariant to node degree.", "In the following I will refer to rule 1 as the sum rule and rule 2 as the mean rule.", "A recent paper by Kipf and Welling proposes fast approximate spectral graph convolutions using a spectral propagation rule [1]:", "Compared to the sum and mean rules discussed in the previous post, the spectral rule differs only in the choice of aggregate function. Although it is somewhat similar to the mean rule in that it normalizes the aggregate using the degree matrix D raised to a negative power, the normalization is asymmetric. Let\u2019s try it out and see what it does.", "We can understand the aggregation functions I\u2019ve presented thus far as weighted sums where each aggregation rule differ only in their choice of weights. We\u2019ll first see how we can express the relatively simple sum and mean rules as weighted sums before moving on to the spectral rule.", "The Sum RuleTo see how the aggregate feature representation of the ith node is computed using the sum rule, we see how the ith row in the aggregate is computed.", "As shown above in Equation 1a, we can compute the aggregate feature representation of the ith node as a vector-matrix product. We can formulate this vector-matrix product as a simple weighted sum, as shown in Equation 1b, where we sum over each of the N rows in X.", "The contribution of the jth node in the aggregate in Equation 1b is determined by the value of the jth column of the ith row of A. Since A is an adjacency matrix, this value is 1 if the jth node is a neighbor of the ith node, and is otherwise 0. Thus, Equation 1b corresponds to summing up the feature representations of the neighbors of the ith node. This confirms the informal observations from the previous post.", "In conclusion, the contribution of each neighbor depends solely on the neighborhood defined by the adjacency matrix A.", "The Mean RuleTo see how the mean rule aggregates node representations, we again see how the ith row in the aggregate is computed, now using the mean rule. For simplicity, we only consider the mean rule on the \u201craw\u201c adjacency matrix without addition between A and the identity matrix I which simply corresponds to adding self-loops to the graph.", "As seen in the equations above, the derivation is now slightly longer. In Equation 2a we now first transform the adjacency matrix A by multiplying it with the inverse of degree matrix D. This computation is made more explicit in Equation 2b. The inverse degree matrix is a diagonal matrix where the values along the diagonal are inverse node degrees s.t. the value at position (i, i) is the inverse degree of the ith node. Thus, we can remove one of the summation signs yielding Equation 2c. Equation 2c can be further reduced yielding Equations 2d and 2e.", "As shown by Equation 2e, we now again sum over each of the N rows in the adjacency matrix A. As mentioned during the discussion of the sum rule, this corresponds to summing over each the ith node\u2019s neighbors. However, the weights in the weighted sum in Equation 2e are now guaranteed to sum to 1 by with the degree of the ith node. Thus, Equation 2e corresponds to a mean over the feature representations of the neighbors of the ith node.", "Whereas the sum rule depends solely on the neighborhood defined by the adjacency matrix A, the mean rule also depends on node degrees.", "The Spectral RuleWe now have a useful framework in place to analyse the spectral rule. Let\u2019s see where it takes us!", "As with the mean rule, we transform the adjacency matrix A using the degree matrix D. However, as shown in Equation 3a, we raise the degree matrix to the power of -0.5 and multiply it on each side of A. This operation can be broken down as shown in Equation 3b. Recall again, that degree matrices (and powers thereof) are diagonal. We can therefore simplify Equation 3b further, until we reach the expression in Equation 3d.", "Equation 3e shows something quite interesting. When computing the aggregate feature representation of the ith node, we not only take into consideration the degree of the ith node, but also the degree of the jth node.", "Similar to the mean rule, the spectral rule normalizes the aggregate s.t. the aggregate feature representation remains roughly on the same scale as the input features. However, the spectral rule weighs neighbor in the weighted sum higher if they have a low-degree and lower if they have a high-degree. This may be useful when low-degree neighbors provide more useful information than high-degree neighbors.", "In addition to the spectral rule, Kipf and Welling demonstrate how GCNs can be used for semi-supervised classification [1]. In semi-supervised learning we wish to make use of both labeled and unlabeled examples. So far we have implicitly assumed that the entire graph is available, i.e., that we are in a transductive setting. In other words, we know all the nodes, but not all the node labels.", "In all the rules we\u2019ve seen, we aggregate over node neighborhoods, and thus nodes that share neighbors tend to have similar feature representations. This property is very useful if the graph exhibits homophily, i.e., that connected nodes tend to be similar (e.g. have the same label). Homophily occurs in many real networks, and particularly social networks exhibit strong homophily.", "As we saw in the previous post, even a randomly initialized GCN can achieve good separation between the feature representations of nodes in a homophilic graph just by using the graph structure. We can take this a step further by training the GCN on the labeled nodes, effectively propagating the node label information to unlabelled nodes by updating weight matrices that are shared across all nodes. This can be done as follows [1]:", "Let\u2019s see how the spectral rule propagates node label information to unlabeled nodes using semi-supervised learning. As in the previous post, we will use Zachary\u2019s Karate Club as an example.", "If you want to follow along, you can find the data set along with a Jupyter notebook containing the code to train and evaluate the GCN here.", "Briefly, Zachary\u2019s Karate Club is a small social network where a conflict arises between the administrator and instructor in a karate club. The task is to predict which side of the conflict each member of the karate club chooses. The graph representation of the network can be seen below. Each node represents a member of the karate club and a link between members indicate that they interact outside the club. The Administrator and Instructor marked with A and I, respectively.", "I implement the spectral rule in MXNet, an easy-to-use and efficient deep learning framework. The implementation is as follows:", "__init__ takes as input an adjacency matrix A along with the input and output dimensionality of each node\u2019s feature representation from the graph convolutional layer;in_units, and out_units, respectively. Self-loops are added to the adjacency matrix A through addition with the identity matrix I, calculate the degree matrix D, and transform the adjacency matrix A to A_hat as specified by the spectral rule. This transformation is not strictly necessary, but is more computationally efficient since the transformation would otherwise be performed during each forward pass of the layer.", "Finally, in the with clause in __init__, we store two model parameters \u2014 A_hat is stored as a constant and the weight matrix W is stored as a trainable parameter.", "hybrid_forward is where the magic happens. In the forward pass we execute this method with the following inputs: X, the output of the previous layer, and the parameters A_hat and W that we defined in the constructor __init__.", "Now that we have an implementation of the spectral rule, we can stack such layers on top of each other . We use a two-layer architecture similar to the one in the previous post, where the first hidden layer has 4 units and the second hidden layer has 2 units. This architecture makes it easy visualize the resulting 2-dimensional embeddings. It differs from the architecture in the previous post in three ways:", "Finally, we add a logistic regression layer on top of the GCN for node classification.", "The Python implementation of the above architecture is as follows.", "I have separated the feature learning part of the network that contains the graph convolutional layers into a features component and the classification part into the classifier component. The separate features component makes it easier to visualise the activations of these layers later. The LogisticRegressoras a classification layer that performs logistic regression by summing over the features of each node provided by the last graph convolutional layer and applying the sigmoid function on this sum.", "You can find the code to construct the features component and the code for the LogisticRegressor in the accompanying Jupyter notebook.", "The code for training the GCN model can be seen below. In brief, I initialize a binary cross entropy loss function, cross_entropy, and an SGD optimizer, trainer to learn the network parameters. Then the model is trained for a specified number of epochs where the loss is calculated for each training example and the error is backpropagated using loss.backward(). trainer.step is then invoked to update the model parameters. After each epoch, the feature representation constructed by the GCN layer is stored in the feature_representations list which we shall inspect shortly.", "Crucially, only the labels of the instructor and administrator are labeled and the remaining nodes in the network are known, but unlabeled! The GCN can find representations for both labeled and unlabeled nodes during graph convolution and can leverage both sources of information during training to perform semi-supervised learning.", "Specifically, semi-supervised learning in takes place in the GCN as it produces latent feature representation of a node by aggregating both the labeled and unlabeled neighbors of the node. During training, we then backpropagate the supervised binary cross entropy loss to update the weights shared across all nodes. However, this loss depends on the latent feature representations of labeled nodes which in turn depends on both labeled and unlabeled nodes. Thus the learning becomes semi-supervised.", "As mentioned above, the feature representations at each epoch are stored which allows us to see how the feature representations changes during training. In the following I consider two input feature representations.", "Representation 1In the first representation, we simply use the sparse 34 \u00d7 34 identity matrix, I, as the feature matrix X, i.e., a one-hot encoding of each node in the graph. This representation has the advantage that it can be used in any graphs, but results in an input parameter for each node in the network which requires a substantial amount of memory and computional power for training on large networks and may result in overfitting. Thankfully, the karate club network is quite small. The network is trained for 5000 epochs using this representation.", "By collectively classifying all nodes in the network, we get the distribution of errors in the network shown on above. Here, black indicates misclassification. Although a nearly half (41%) of the nodes are misclassified, the nodes that are closely connected to either the administrator or instructor (but not both!) tend to be correctly classified.", "To the left, I have illustrated how the feature representation changes during training. The nodes are initially closely clustered, but as training progresses the instructor and administrator are pulled apart, dragging some nodes with them.", "Although the administrator and instructor are given quite different representations, the nodes they drag with them do not necessarily belong to their community. This is because the graph convolutions embed nodes that share neighbors closely together in the feature space, but two nodes that share neighbors may not be equally connected to the administrator and instructor. In particular, using the identity matrix as the feature matrix results in highly local representations of each node, i.e., nodes that belong to the same area of the graph are likely to be embedded closely together. This makes it difficult for the network to share common knowledge between distant areas in an inductive fashion.", "Representation 2We will improve representation 1 by adding two features that are not specific to any node or area of the network, but measures the connectedness to the administrator and instructor. To this end, we compute the shortest path distance from each node in the network to both the administrator and instructor and concatenate these two features to the previous representation.", "On might perhaps consider this cheating a little bit, since we inject global information about the location of each node in the graph; information which should (ideally) be captured by the graph convolutional layers in the features component. However, the graph convolutional layers always have a local perspective and has a limited capacity to capture such information. Still, it serves as a useful tool for understanding GCNs.", "As before, we collectively classify all nodes in the network and plot the distribution of errors in the network shown on above. This time, only four nodes are misclassified; a significant improvement over representation 1! Upon closer inspection of the feature matrix, these nodes are either equidistant (in a shortest path sense) to the instructor and administrator or are closer to the administrator but belong in the instructor community. The GCN is trained for 250 epochs using representation 2.", "As shown on the left, the nodes are again clustered quite closely together initially, but are somewhat separated into communities before training even begins! As training progresses the distance between the communities increases.", "In this post, I have given an in-depth explanation on how aggregation in GCNs is performed and shown how it can be expressed as a weighted sum, using the mean, sum, and spectral rules as examples. My sincere hope is that you will find this framework useful to consider which weights you might want during aggregation in your own graph convolutional network.", "I have also shown how to implement and train a GCN in MXNet to perform semi-supervised classification on graphs using spectral graph convolutions with Zachary\u2019s Karate Club as a simple example network. We saw how just using two labeled nodes, it was still possible for the GCN to achieve a high degree of separation between the two network communities in the representation space.", "Although there is much more to learn about graph convolutional networks which I hope to have the time to share with you in the future, this is (for now) the final post in the series. If you are interested in further reading, I would like to conclude with the following papers which I have found quite interesting:", "Liked what you read? Consider following me on Twitter where I share papers, videos, and articles related to the practice, theory, and ethics of data science and machine learning that I find interesting in addition to my own posts.", "For professional inquiries, please contact me on LinkedIn or by direct message on Twitter.", "[1] Paper called Semi-Supervised Classification with Graph Convolutional Networks by Thomas Kipf and Max Welling.", "Doing data science and machine learning both professionally and as a hobby."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F62acf5b143d0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Tobias Skovgaard Jepsen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F565f7254b058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=post_page-565f7254b058----62acf5b143d0---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F62acf5b143d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=-----62acf5b143d0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F62acf5b143d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&source=-----62acf5b143d0---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "A High-Level Introduction to Graph Convolutional Networks"}, {"url": "https://en.wikipedia.org/wiki/Semi-supervised_learning", "anchor_text": "semi-supervised learning"}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "my previous post"}, {"url": "https://en.wikipedia.org/wiki/Diagonal_matrix", "anchor_text": "diagonal matrix"}, {"url": "https://en.wikipedia.org/wiki/Semi-supervised_learning", "anchor_text": "semi-supervised learning"}, {"url": "https://en.wikipedia.org/wiki/Transduction_(machine_learning)", "anchor_text": "transductive"}, {"url": "https://en.wikipedia.org/wiki/Homophily", "anchor_text": "homophily"}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "the previous post"}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "the previous post"}, {"url": "https://github.com/TobiasSkovgaardJepsen/posts/tree/master/HowToDoDeepLearningOnGraphsWithGraphConvolutionalNetworks/Part2_SemiSupervisedLearningWithSpectralGraphConvolutions", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Zachary%27s_karate_club", "anchor_text": "Zachary\u2019s Karate Club"}, {"url": "https://mxnet.apache.org/", "anchor_text": "MXNet"}, {"url": "https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0", "anchor_text": "efficient"}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "logistic regression"}, {"url": "https://en.wikipedia.org/wiki/Sigmoid_function", "anchor_text": "sigmoid function"}, {"url": "https://github.com/TobiasSkovgaardJepsen/posts/blob/master/HowToDoDeepLearningOnGraphsWithGraphConvolutionalNetworks/Part2_SemiSupervisedLearningWithSpectralGraphConvolutions/notebook.ipynb", "anchor_text": "the accompanying Jupyter notebook"}, {"url": "https://en.wikipedia.org/wiki/Identity_matrix", "anchor_text": "identity matrix"}, {"url": "https://arxiv.org/abs/1706.02216", "anchor_text": "Inductive Representation Learning on Large Graphs"}, {"url": "https://arxiv.org/pdf/1801.10247.pdf", "anchor_text": "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling"}, {"url": "https://arxiv.org/pdf/1802.08888.pdf", "anchor_text": "N-GCN: Multi-scale Graph Convolution for Semi-supervised Node Classification"}, {"url": "https://medium.com/@binny.iitkgp", "anchor_text": "Binny Mathew"}, {"url": "https://twitter.com/TobiasSJepsen", "anchor_text": "Twitter"}, {"url": "https://www.linkedin.com/in/tobias-skovgaard-jepsen/", "anchor_text": "LinkedIn"}, {"url": "https://twitter.com/TobiasSJepsen", "anchor_text": "Twitter"}, {"url": "https://arxiv.org/abs/1609.02907", "anchor_text": "Paper"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----62acf5b143d0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----62acf5b143d0---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----62acf5b143d0---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/data-science?source=post_page-----62acf5b143d0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----62acf5b143d0---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F62acf5b143d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=-----62acf5b143d0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F62acf5b143d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=-----62acf5b143d0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F62acf5b143d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F565f7254b058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=post_page-565f7254b058----62acf5b143d0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9f2ca467b832&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&newsletterV3=565f7254b058&newsletterV3Id=9f2ca467b832&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=-----62acf5b143d0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Written by Tobias Skovgaard Jepsen"}, {"url": "https://medium.com/@tobiasskovgaardjepsen/followers?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F565f7254b058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=post_page-565f7254b058----62acf5b143d0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9f2ca467b832&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0&newsletterV3=565f7254b058&newsletterV3Id=9f2ca467b832&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=-----62acf5b143d0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=author_recirc-----62acf5b143d0----0---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=author_recirc-----62acf5b143d0----0---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=author_recirc-----62acf5b143d0----0---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Tobias Skovgaard Jepsen"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----62acf5b143d0----0---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=author_recirc-----62acf5b143d0----0---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "How to do Deep Learning on Graphs with Graph Convolutional NetworksPart 1: A High-Level Introduction to Graph Convolutional Networks"}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=author_recirc-----62acf5b143d0----0---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "9 min read\u00b7Sep 18, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7d2250723780&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=-----7d2250723780----0-----------------clap_footer----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780?source=author_recirc-----62acf5b143d0----0---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "61"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d2250723780&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780&source=-----62acf5b143d0----0-----------------bookmark_preview----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----62acf5b143d0----1---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----62acf5b143d0----1---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----62acf5b143d0----1---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----62acf5b143d0----1---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----62acf5b143d0----1---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----62acf5b143d0----1---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----62acf5b143d0----1---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----62acf5b143d0----1-----------------bookmark_preview----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----62acf5b143d0----2---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----62acf5b143d0----2---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----62acf5b143d0----2---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----62acf5b143d0----2---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----62acf5b143d0----2---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----62acf5b143d0----2---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----62acf5b143d0----2---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----62acf5b143d0----2-----------------bookmark_preview----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/running-jupyter-notebooks-on-remote-servers-603fbcc256b3?source=author_recirc-----62acf5b143d0----3---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=author_recirc-----62acf5b143d0----3---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=author_recirc-----62acf5b143d0----3---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Tobias Skovgaard Jepsen"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----62acf5b143d0----3---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/running-jupyter-notebooks-on-remote-servers-603fbcc256b3?source=author_recirc-----62acf5b143d0----3---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "Running Jupyter Notebooks on Remote ServersJupyter Notebook are a staple tool in many data scientists toolkit. Jupyter Notebook makes it easy to perform and visualize data analysis\u2026"}, {"url": "https://towardsdatascience.com/running-jupyter-notebooks-on-remote-servers-603fbcc256b3?source=author_recirc-----62acf5b143d0----3---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": "6 min read\u00b7Mar 4, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F603fbcc256b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-jupyter-notebooks-on-remote-servers-603fbcc256b3&user=Tobias+Skovgaard+Jepsen&userId=565f7254b058&source=-----603fbcc256b3----3-----------------clap_footer----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/running-jupyter-notebooks-on-remote-servers-603fbcc256b3?source=author_recirc-----62acf5b143d0----3---------------------bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F603fbcc256b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frunning-jupyter-notebooks-on-remote-servers-603fbcc256b3&source=-----62acf5b143d0----3-----------------bookmark_preview----bf1a1a32_cf5e_4339_a946_4d4bc3e859f8-------", "anchor_text": ""}, {"url": "https://medium.com/@tobiasskovgaardjepsen?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "See all from Tobias Skovgaard Jepsen"}, {"url": "https://towardsdatascience.com/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/graph-embeddings-explained-f0d8d1c49ec?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://vatsal12-p.medium.com/?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://vatsal12-p.medium.com/?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Vatsal"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/graph-embeddings-explained-f0d8d1c49ec?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Graph Embeddings ExplainedOverview and Python Implementation of Node, Edge and Graph Embedding Methods"}, {"url": "https://towardsdatascience.com/graph-embeddings-explained-f0d8d1c49ec?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "\u00b77 min read\u00b7Nov 7, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff0d8d1c49ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-embeddings-explained-f0d8d1c49ec&user=Vatsal&userId=1c849b1a8ec0&source=-----f0d8d1c49ec----0-----------------clap_footer----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/graph-embeddings-explained-f0d8d1c49ec?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff0d8d1c49ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-embeddings-explained-f0d8d1c49ec&source=-----62acf5b143d0----0-----------------bookmark_preview----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/graphs-with-python-overview-and-best-libraries-a92aa485c2f8?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://medium.com/@andimid?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://medium.com/@andimid?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Dmytro Nikolaiev (Dimid)"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/graphs-with-python-overview-and-best-libraries-a92aa485c2f8?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Graphs with Python: Overview and Best LibrariesGraph analysis, interactive visualizations, and graph machine learning"}, {"url": "https://towardsdatascience.com/graphs-with-python-overview-and-best-libraries-a92aa485c2f8?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "\u00b711 min read\u00b7Dec 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa92aa485c2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraphs-with-python-overview-and-best-libraries-a92aa485c2f8&user=Dmytro+Nikolaiev+%28Dimid%29&userId=97b5279dad26&source=-----a92aa485c2f8----1-----------------clap_footer----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/graphs-with-python-overview-and-best-libraries-a92aa485c2f8?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa92aa485c2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraphs-with-python-overview-and-best-libraries-a92aa485c2f8&source=-----62acf5b143d0----1-----------------bookmark_preview----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----0-----------------clap_footer----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----62acf5b143d0----0---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----62acf5b143d0----0-----------------bookmark_preview----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----62acf5b143d0----1---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----62acf5b143d0----1-----------------bookmark_preview----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----62acf5b143d0----2---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----62acf5b143d0----2---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----62acf5b143d0----2---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----62acf5b143d0----2---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----62acf5b143d0----2---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----62acf5b143d0----2---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----2-----------------clap_footer----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----62acf5b143d0----2---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----62acf5b143d0----2-----------------bookmark_preview----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----62acf5b143d0----3---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://shawhin.medium.com/?source=read_next_recirc-----62acf5b143d0----3---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://shawhin.medium.com/?source=read_next_recirc-----62acf5b143d0----3---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Shawhin Talebi"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----62acf5b143d0----3---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----62acf5b143d0----3---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "The Wavelet TransformAn Introduction and Example"}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----62acf5b143d0----3---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": "\u00b76 min read\u00b7Dec 21, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9cfa85d7b34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-wavelet-transform-e9cfa85d7b34&user=Shawhin+Talebi&userId=f3998e1cd186&source=-----e9cfa85d7b34----3-----------------clap_footer----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----62acf5b143d0----3---------------------54ea2e75_0519_4683_9376_bfbf2235ed67-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9cfa85d7b34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-wavelet-transform-e9cfa85d7b34&source=-----62acf5b143d0----3-----------------bookmark_preview----54ea2e75_0519_4683_9376_bfbf2235ed67-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----62acf5b143d0--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}