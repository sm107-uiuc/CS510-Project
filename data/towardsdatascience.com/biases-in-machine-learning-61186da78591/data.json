{"url": "https://towardsdatascience.com/biases-in-machine-learning-61186da78591", "time": 1683009966.480472, "path": "towardsdatascience.com/biases-in-machine-learning-61186da78591/", "webpage": {"metadata": {"title": "Biases in Machine Learning. Most common reasons why biases get\u2026 | by Nitin Aggarwal | Towards Data Science", "h1": "Biases in Machine Learning", "description": "Whether you like it or not, the impact of machine learning on your life is growing very rapidly. Machine learning algorithms determine whether you would get the mortgage for your dream home, or if\u2026"}, "outgoing_paragraph_urls": [{"url": "https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf", "anchor_text": "paper", "paragraph_index": 4}, {"url": "https://qz.com/1427621/companies-are-on-the-hook-if-their-hiring-algorithms-are-biased/", "anchor_text": "Amazon study", "paragraph_index": 5}, {"url": "https://github.com/google/ml-fairness-gym", "anchor_text": "ml-fairness-gym", "paragraph_index": 7}, {"url": "https://www.amazon.com/Mechanical-Intelligence-Collected-Works-Turing/dp/0444880585", "anchor_text": "Allen Turing said", "paragraph_index": 8}, {"url": "https://www.youtube.com/watch?v=fMym_BKWQzk", "anchor_text": "talk", "paragraph_index": 10}], "all_paragraphs": ["Whether you like it or not, the impact of machine learning on your life is growing very rapidly. Machine learning algorithms determine whether you would get the mortgage for your dream home, or if your resume would be shortlisted for your next job. It is also changing our workforce rapidly. Robots are taking over warehouses and factories, and self driving cars are threatening to disrupt the jobs of millions of professional drivers across the world. Even law enforcement agencies are increasingly using machine learning to screen for potential criminal leads and assess risks.", "Unfortunately, all these advancements in technology may be perpetuating and exacerbating the biases ailing our society. In one of the early examples of algorithmic bias, 60 women and ethnic minorities were denied entry to St. George\u2019s Hospital Medical School per year from 1982 to 1986, because of a new computer-guidance assessment system that denied entry to women and men with \u201cforeign-sounding names\u201d based on historical trends in admissions. Or more recently, in 2016, TayTweets, a chat bot trained by Microsoft on Twitter data started spouting racist tweets.", "All these advancements are raising very valid questions about how machine learning practitioners can ensure fairness in their algorithms. What is fair is an age old question. Thankfully, a lot of research has been going on in this area. In this post, I am going to talk about the most common set of problems you might run when trying to ensure that your machine learning model is bias free.", "One of the most common causes of bias in machine learning algorithms is that the training data is missing samples for underrepresented groups/categories. This is the reason why Siri frequently has a hard time understanding people with accents. This is also what caused the famous Google photos incident where black people were tagged as gorillas. So it is really important to make sure the training data has representation from all the underrepresented groups. Another way to easily detect this early is to deploy a second algorithm which predicts whether the data in production is close to the training data and intervene early if that is not the case.", "A recent OpenAI paper about their groundbreaking language model found that \u201coccupations in general have a higher probability of being followed by a male gender identifier than a female one\u201d. There have been numerous cases in the press where biases in the training data are inherited by the models. There have been experiments which conclude that higher paying job ads are only shown to men or ads for houses in white neighborhoods are only shown to white people. Various language models trained on text data from the internet tend to attach negative connotations to women or people of color. This happens, because our existing social biases reflect in the training data. This kind of bias is very hard to correct as in most cases because it\u2019s really hard to get unbiased data. One simple strategy to mitigate this is to find data points which represent positive historical data for the marginalized group and upsample those records in the training data.", "One common solution to make sure the data doesn\u2019t train on sensitive attributes is by removing the features from training data altogether. But there might still be correlated attributes which might cause the model to discriminate against underserved communities. For example, zip code might be correlated to race, and name might be correlated to both race and gender, etc. It\u2019s often observed that machine learning models trained on resumes learn to value male names more than female names. An Amazon study found that the name \u201cJared\u201d is very good to get shortlisted for a job.", "Blindly removing the sensitive attributes features from the training data might even cause harm in some cases. For example, women are less likely to cause accidents, hence in some places, it is legal to use gender to determine insurance quotes. In recidivism studies, it\u2019s found that women are less likely to re-offend. In such cases where the disadvantaged category actually does better than the dominant category, it might be better to include this as a feature in the training data.", "It\u2019s very unlikely this will be a problem but adding this here to be comprehensive. Let\u2019s say your model decides whether to provide a loan to an individual based on their credit score and if the individual pays back the loan, their score increases, otherwise it decreases. And your long term objective is to increase the average credit score of the population. In this case, to compensate for bias you might want to change the threshold to approve more loans for a certain section of the population. But if you overcompensate so much that the number of defaults are higher than the number of successful paybacks, the average credit score might decrease for this section of the population and ends up hurting them. Google provides a library called ml-fairness-gym which can help with simulating such long run effects of enforcing fairness in machine learning models.", "Allen Turing said that if a machine is expected to be infallible, it cannot also be intelligent. But everyday another critical piece of social infrastructure is adding \u201cartificial intelligence\u201d to its decision making process without any legal checks and balances. It\u2019s very easy for various biases to slip into a machine learning model, unless you are extremely cautious. Also, our legal systems haven\u2019t caught up with the new technology, which continues to deeply affect our lives. Hence right now, it\u2019s the responsibility of people working on these models to ensure that the models are fair and free from biases.", "Fortunately, people in research are paying attention to this issue and adjacent issues like explainability of machine learning models.", "But these tools are nowhere close to being enough or perfect. There is a very strong need for much more rigorous tools and research in this area. Technology has been used both for good and bad. It\u2019s the responsibility of the creators of the technology to make sure that the their products make the world a better place for all of us. I really liked this famous talk by Kate Crawford at NIPS 2017, where she calls upon the industry to invest more in understanding the social impact of artificial intelligence.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "CTO/Co-Founder @ RunX. IITD CS. Previously Google, Lyft, Stripe. Interested in systems, dev productivity, ML."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F61186da78591&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----61186da78591--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----61186da78591--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nitinagg?source=post_page-----61186da78591--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nitinagg?source=post_page-----61186da78591--------------------------------", "anchor_text": "Nitin Aggarwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff6d89b7a55ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&user=Nitin+Aggarwal&userId=f6d89b7a55ab&source=post_page-f6d89b7a55ab----61186da78591---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F61186da78591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F61186da78591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf", "anchor_text": "paper"}, {"url": "https://qz.com/1427621/companies-are-on-the-hook-if-their-hiring-algorithms-are-biased/", "anchor_text": "Amazon study"}, {"url": "https://github.com/google/ml-fairness-gym", "anchor_text": "ml-fairness-gym"}, {"url": "https://www.amazon.com/Mechanical-Intelligence-Collected-Works-Turing/dp/0444880585", "anchor_text": "Allen Turing said"}, {"url": "https://www.tensorflow.org/tfx/guide/fairness_indicators", "anchor_text": "fairness indicators"}, {"url": "https://www.microsoft.com/en-us/research/theme/fate/", "anchor_text": "FATE"}, {"url": "https://aif360.mybluemix.net/", "anchor_text": "AI fairness 360"}, {"url": "https://arxiv.org/abs/1803.04383", "anchor_text": "Delayed Impact of Fair Machine Learning"}, {"url": "https://www.youtube.com/watch?v=fMym_BKWQzk", "anchor_text": "talk"}, {"url": "https://xkcd.com/1277/", "anchor_text": "https://xkcd.com/1277/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----61186da78591---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/machine-learning-ai?source=post_page-----61186da78591---------------machine_learning_ai-----------------", "anchor_text": "Machine Learning Ai"}, {"url": "https://medium.com/tag/fairness?source=post_page-----61186da78591---------------fairness-----------------", "anchor_text": "Fairness"}, {"url": "https://medium.com/tag/bias?source=post_page-----61186da78591---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----61186da78591---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F61186da78591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&user=Nitin+Aggarwal&userId=f6d89b7a55ab&source=-----61186da78591---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F61186da78591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&user=Nitin+Aggarwal&userId=f6d89b7a55ab&source=-----61186da78591---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F61186da78591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----61186da78591--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F61186da78591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----61186da78591---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----61186da78591--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----61186da78591--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----61186da78591--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----61186da78591--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----61186da78591--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----61186da78591--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----61186da78591--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----61186da78591--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nitinagg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nitinagg?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nitin Aggarwal"}, {"url": "https://medium.com/@nitinagg/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "701 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff6d89b7a55ab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&user=Nitin+Aggarwal&userId=f6d89b7a55ab&source=post_page-f6d89b7a55ab--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F63bf226f2f53&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbiases-in-machine-learning-61186da78591&newsletterV3=f6d89b7a55ab&newsletterV3Id=63bf226f2f53&user=Nitin+Aggarwal&userId=f6d89b7a55ab&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}